{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-5\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 1e-05 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-05\n",
      "Fold: 1  Epoch: 1  Training loss = 3.2571  Validation loss = 3.4733  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.2540  Validation loss = 3.4678  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.2522  Validation loss = 3.4646  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.2501  Validation loss = 3.4609  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.2475  Validation loss = 3.4563  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.2448  Validation loss = 3.4513  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.2423  Validation loss = 3.4470  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.2400  Validation loss = 3.4429  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.2375  Validation loss = 3.4384  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.2347  Validation loss = 3.4333  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.2327  Validation loss = 3.4296  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.2294  Validation loss = 3.4236  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.2270  Validation loss = 3.4195  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.2248  Validation loss = 3.4155  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.2230  Validation loss = 3.4122  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.2209  Validation loss = 3.4083  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.2183  Validation loss = 3.4035  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.2160  Validation loss = 3.3992  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.2132  Validation loss = 3.3942  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.2114  Validation loss = 3.3907  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.2093  Validation loss = 3.3868  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.2064  Validation loss = 3.3815  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.2036  Validation loss = 3.3763  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.2010  Validation loss = 3.3717  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.1991  Validation loss = 3.3681  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.1966  Validation loss = 3.3634  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.1940  Validation loss = 3.3586  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.1917  Validation loss = 3.3543  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.1899  Validation loss = 3.3509  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.1874  Validation loss = 3.3463  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.1850  Validation loss = 3.3418  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.1829  Validation loss = 3.3378  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.1813  Validation loss = 3.3349  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.1789  Validation loss = 3.3304  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.1769  Validation loss = 3.3266  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.1751  Validation loss = 3.3232  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.1737  Validation loss = 3.3204  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.1717  Validation loss = 3.3167  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.1696  Validation loss = 3.3127  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.1680  Validation loss = 3.3096  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.1657  Validation loss = 3.3052  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.1639  Validation loss = 3.3019  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.1619  Validation loss = 3.2979  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.1602  Validation loss = 3.2947  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.1583  Validation loss = 3.2910  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.1566  Validation loss = 3.2879  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.1548  Validation loss = 3.2843  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.1530  Validation loss = 3.2808  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.1517  Validation loss = 3.2784  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.1490  Validation loss = 3.2733  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.1466  Validation loss = 3.2685  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.1444  Validation loss = 3.2643  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.1414  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.1395  Validation loss = 3.2548  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.1374  Validation loss = 3.2507  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.1352  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.1333  Validation loss = 3.2423  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.1315  Validation loss = 3.2390  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.1295  Validation loss = 3.2350  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.1275  Validation loss = 3.2311  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.1247  Validation loss = 3.2254  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.1230  Validation loss = 3.2222  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.1209  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.1187  Validation loss = 3.2136  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.1169  Validation loss = 3.2101  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.1151  Validation loss = 3.2064  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.1129  Validation loss = 3.2020  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.1114  Validation loss = 3.1989  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.1093  Validation loss = 3.1948  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.1072  Validation loss = 3.1906  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.1051  Validation loss = 3.1863  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.1036  Validation loss = 3.1833  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.1019  Validation loss = 3.1798  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.1004  Validation loss = 3.1769  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.0983  Validation loss = 3.1726  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.0965  Validation loss = 3.1688  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.0947  Validation loss = 3.1653  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.0926  Validation loss = 3.1611  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.0899  Validation loss = 3.1555  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.0879  Validation loss = 3.1513  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.0862  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.0845  Validation loss = 3.1443  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.0827  Validation loss = 3.1407  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.0815  Validation loss = 3.1381  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.0802  Validation loss = 3.1354  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.0785  Validation loss = 3.1318  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.0773  Validation loss = 3.1295  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.0754  Validation loss = 3.1256  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.0745  Validation loss = 3.1237  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.0734  Validation loss = 3.1214  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.0718  Validation loss = 3.1181  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.0705  Validation loss = 3.1153  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.0682  Validation loss = 3.1106  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.0667  Validation loss = 3.1074  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.0644  Validation loss = 3.1025  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.0626  Validation loss = 3.0987  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.0615  Validation loss = 3.0962  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.0601  Validation loss = 3.0933  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.0581  Validation loss = 3.0892  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.0558  Validation loss = 3.0842  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.0540  Validation loss = 3.0805  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.0517  Validation loss = 3.0755  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.0499  Validation loss = 3.0718  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.0489  Validation loss = 3.0695  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.0469  Validation loss = 3.0654  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.0450  Validation loss = 3.0611  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.0431  Validation loss = 3.0572  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.0416  Validation loss = 3.0540  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.0398  Validation loss = 3.0499  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.0383  Validation loss = 3.0468  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.0364  Validation loss = 3.0426  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.0347  Validation loss = 3.0390  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.0329  Validation loss = 3.0351  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.0314  Validation loss = 3.0319  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.0306  Validation loss = 3.0300  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.0289  Validation loss = 3.0263  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.0272  Validation loss = 3.0227  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.0260  Validation loss = 3.0201  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.0241  Validation loss = 3.0156  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.0227  Validation loss = 3.0128  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.0207  Validation loss = 3.0082  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.0187  Validation loss = 3.0038  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.0174  Validation loss = 3.0009  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.0157  Validation loss = 2.9971  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.0148  Validation loss = 2.9952  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.0133  Validation loss = 2.9918  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.0116  Validation loss = 2.9880  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.0106  Validation loss = 2.9859  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.0094  Validation loss = 2.9830  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.0074  Validation loss = 2.9786  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.0062  Validation loss = 2.9759  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.0045  Validation loss = 2.9721  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.0023  Validation loss = 2.9672  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.0009  Validation loss = 2.9641  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 2.9999  Validation loss = 2.9617  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 2.9986  Validation loss = 2.9587  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 2.9969  Validation loss = 2.9549  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 2.9955  Validation loss = 2.9518  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 2.9942  Validation loss = 2.9489  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 2.9927  Validation loss = 2.9454  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 2.9912  Validation loss = 2.9420  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 2.9903  Validation loss = 2.9398  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 2.9893  Validation loss = 2.9376  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 2.9882  Validation loss = 2.9350  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 2.9870  Validation loss = 2.9321  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 2.9860  Validation loss = 2.9300  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 2.9845  Validation loss = 2.9263  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 2.9827  Validation loss = 2.9223  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 2.9813  Validation loss = 2.9191  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 2.9801  Validation loss = 2.9163  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 2.9791  Validation loss = 2.9139  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 2.9777  Validation loss = 2.9106  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 2.9762  Validation loss = 2.9069  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 2.9747  Validation loss = 2.9036  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 2.9733  Validation loss = 2.9003  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 2.9719  Validation loss = 2.8970  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 2.9705  Validation loss = 2.8937  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 2.9690  Validation loss = 2.8903  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 2.9679  Validation loss = 2.8876  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 2.9668  Validation loss = 2.8850  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 2.9656  Validation loss = 2.8821  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 2.9646  Validation loss = 2.8798  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 2.9635  Validation loss = 2.8772  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 2.9625  Validation loss = 2.8748  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 2.9615  Validation loss = 2.8725  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 2.9606  Validation loss = 2.8703  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 2.9595  Validation loss = 2.8675  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 2.9585  Validation loss = 2.8652  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 2.9572  Validation loss = 2.8622  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 2.9558  Validation loss = 2.8589  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 2.9547  Validation loss = 2.8562  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 2.9534  Validation loss = 2.8531  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 2.9526  Validation loss = 2.8512  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 2.9512  Validation loss = 2.8479  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 2.9499  Validation loss = 2.8445  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 2.9487  Validation loss = 2.8416  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 2.9478  Validation loss = 2.8394  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 2.9456  Validation loss = 2.8340  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 2.9445  Validation loss = 2.8315  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 2.9435  Validation loss = 2.8289  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 2.9418  Validation loss = 2.8246  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 2.9404  Validation loss = 2.8213  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 2.9391  Validation loss = 2.8181  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 2.9378  Validation loss = 2.8150  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 2.9368  Validation loss = 2.8124  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 2.9354  Validation loss = 2.8089  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 2.9343  Validation loss = 2.8062  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 2.9330  Validation loss = 2.8030  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 2.9320  Validation loss = 2.8003  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 2.9313  Validation loss = 2.7988  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 2.9302  Validation loss = 2.7960  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 2.9291  Validation loss = 2.7932  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 2.9273  Validation loss = 2.7886  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 2.9260  Validation loss = 2.7853  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 2.9253  Validation loss = 2.7835  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 2.9246  Validation loss = 2.7817  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 2.9235  Validation loss = 2.7790  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 2.9223  Validation loss = 2.7760  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 2.9215  Validation loss = 2.7740  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 2.9206  Validation loss = 2.7716  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 2.9194  Validation loss = 2.7686  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 2.9184  Validation loss = 2.7660  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 2.9171  Validation loss = 2.7627  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 2.9157  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 2.9151  Validation loss = 2.7576  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 2.9139  Validation loss = 2.7545  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 2.9126  Validation loss = 2.7510  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 2.9120  Validation loss = 2.7495  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 2.9114  Validation loss = 2.7479  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 2.9110  Validation loss = 2.7470  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 2.9103  Validation loss = 2.7451  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 2.9089  Validation loss = 2.7416  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 2.9078  Validation loss = 2.7387  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 2.9069  Validation loss = 2.7364  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 2.9056  Validation loss = 2.7330  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 2.9046  Validation loss = 2.7304  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 2.9036  Validation loss = 2.7279  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 2.9026  Validation loss = 2.7252  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 2.9013  Validation loss = 2.7219  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 2.9008  Validation loss = 2.7203  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 2.9002  Validation loss = 2.7189  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 2.8990  Validation loss = 2.7158  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 2.8985  Validation loss = 2.7144  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 2.8982  Validation loss = 2.7135  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 2.8975  Validation loss = 2.7118  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 2.8964  Validation loss = 2.7087  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 2.8957  Validation loss = 2.7069  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 2.8943  Validation loss = 2.7034  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 2.8934  Validation loss = 2.7010  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 2.8924  Validation loss = 2.6982  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 2.8911  Validation loss = 2.6947  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 2.8900  Validation loss = 2.6917  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 2.8888  Validation loss = 2.6885  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 2.8883  Validation loss = 2.6873  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 2.8872  Validation loss = 2.6842  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 2.8862  Validation loss = 2.6815  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 2.8857  Validation loss = 2.6801  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 2.8851  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 2.8842  Validation loss = 2.6762  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 2.8833  Validation loss = 2.6737  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 2.8819  Validation loss = 2.6700  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 2.8809  Validation loss = 2.6675  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 2.8797  Validation loss = 2.6641  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 2.8789  Validation loss = 2.6619  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 2.8781  Validation loss = 2.6598  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 2.8772  Validation loss = 2.6572  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 2.8760  Validation loss = 2.6540  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 2.8749  Validation loss = 2.6511  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 2.8741  Validation loss = 2.6488  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 2.8730  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 2.8721  Validation loss = 2.6432  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 2.8708  Validation loss = 2.6397  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 2.8696  Validation loss = 2.6365  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 2.8688  Validation loss = 2.6343  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 2.8681  Validation loss = 2.6323  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 2.8676  Validation loss = 2.6307  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 2.8665  Validation loss = 2.6278  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 2.8651  Validation loss = 2.6239  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 2.8643  Validation loss = 2.6215  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 2.8637  Validation loss = 2.6199  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 2.8631  Validation loss = 2.6182  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 2.8625  Validation loss = 2.6166  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 2.8621  Validation loss = 2.6155  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 2.8613  Validation loss = 2.6132  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 2.8599  Validation loss = 2.6092  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 2.8588  Validation loss = 2.6063  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 2.8579  Validation loss = 2.6038  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 2.8572  Validation loss = 2.6016  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 2.8564  Validation loss = 2.5993  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 2.8554  Validation loss = 2.5964  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 2.8548  Validation loss = 2.5949  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 2.8540  Validation loss = 2.5927  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 2.8534  Validation loss = 2.5908  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 2.8525  Validation loss = 2.5883  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 2.8517  Validation loss = 2.5860  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 2.8502  Validation loss = 2.5817  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 2.8490  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 2.8484  Validation loss = 2.5766  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 2.8478  Validation loss = 2.5746  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 2.8472  Validation loss = 2.5729  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 2.8454  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 2.8445  Validation loss = 2.5652  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 2.8440  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 2.8434  Validation loss = 2.5621  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 2.8425  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 2.8419  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 2.8413  Validation loss = 2.5558  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 2.8409  Validation loss = 2.5548  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 2.8398  Validation loss = 2.5515  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 2.8391  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 2.8386  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 2.8383  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 2.8376  Validation loss = 2.5450  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 2.8362  Validation loss = 2.5409  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 2.8355  Validation loss = 2.5386  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 2.8345  Validation loss = 2.5358  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 2.8342  Validation loss = 2.5347  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 2.8332  Validation loss = 2.5319  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 2.8325  Validation loss = 2.5298  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 2.8313  Validation loss = 2.5262  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 2.8304  Validation loss = 2.5234  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 2.8298  Validation loss = 2.5215  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 2.8291  Validation loss = 2.5195  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 2.8283  Validation loss = 2.5171  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 2.8276  Validation loss = 2.5150  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 2.8270  Validation loss = 2.5132  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 2.8266  Validation loss = 2.5121  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 2.8262  Validation loss = 2.5106  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 2.8256  Validation loss = 2.5089  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 2.8249  Validation loss = 2.5069  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 2.8241  Validation loss = 2.5043  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 2.8237  Validation loss = 2.5033  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 2.8226  Validation loss = 2.4999  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 2.8218  Validation loss = 2.4973  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 2.8211  Validation loss = 2.4952  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 2.8201  Validation loss = 2.4922  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 2.8196  Validation loss = 2.4907  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 2.8190  Validation loss = 2.4887  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 2.8188  Validation loss = 2.4881  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 2.8176  Validation loss = 2.4845  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 2.8171  Validation loss = 2.4830  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 2.8165  Validation loss = 2.4810  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 2.8153  Validation loss = 2.4773  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 2.8147  Validation loss = 2.4753  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 2.8137  Validation loss = 2.4724  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 2.8132  Validation loss = 2.4705  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 2.8123  Validation loss = 2.4679  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 2.8117  Validation loss = 2.4661  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 2.8112  Validation loss = 2.4643  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 2.8105  Validation loss = 2.4622  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 2.8096  Validation loss = 2.4593  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 2.8093  Validation loss = 2.4582  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 2.8084  Validation loss = 2.4555  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 2.8075  Validation loss = 2.4525  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 2.8069  Validation loss = 2.4508  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 2.8064  Validation loss = 2.4490  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 2.8062  Validation loss = 2.4484  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 2.8059  Validation loss = 2.4476  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 2.8045  Validation loss = 2.4429  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 2.8037  Validation loss = 2.4406  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 2.8034  Validation loss = 2.4395  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 2.8026  Validation loss = 2.4370  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 2.8022  Validation loss = 2.4357  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 2.8017  Validation loss = 2.4339  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 2.8006  Validation loss = 2.4303  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 2.7999  Validation loss = 2.4283  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 2.7988  Validation loss = 2.4247  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 2.7983  Validation loss = 2.4230  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 2.7978  Validation loss = 2.4213  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 2.7969  Validation loss = 2.4184  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 2.7967  Validation loss = 2.4177  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 2.7963  Validation loss = 2.4164  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 2.7959  Validation loss = 2.4151  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 2.7953  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 2.7946  Validation loss = 2.4107  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 2.7938  Validation loss = 2.4080  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 2.7936  Validation loss = 2.4075  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 2.7931  Validation loss = 2.4059  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 2.7922  Validation loss = 2.4029  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 2.7913  Validation loss = 2.3999  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 2.7909  Validation loss = 2.3986  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 2.7906  Validation loss = 2.3974  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 2.7896  Validation loss = 2.3940  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 2.7889  Validation loss = 2.3919  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 2.7885  Validation loss = 2.3906  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 2.7878  Validation loss = 2.3880  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 2.7874  Validation loss = 2.3867  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 2.7871  Validation loss = 2.3857  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 2.7863  Validation loss = 2.3830  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 2.7858  Validation loss = 2.3813  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 2.7854  Validation loss = 2.3798  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 2.7845  Validation loss = 2.3769  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 2.7838  Validation loss = 2.3743  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 2.7828  Validation loss = 2.3712  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 2.7822  Validation loss = 2.3690  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 2.7812  Validation loss = 2.3655  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 2.7811  Validation loss = 2.3652  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 2.7803  Validation loss = 2.3625  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 2.7797  Validation loss = 2.3605  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 2.7794  Validation loss = 2.3593  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 2.7787  Validation loss = 2.3570  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 2.7778  Validation loss = 2.3540  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 2.7775  Validation loss = 2.3527  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 2.7769  Validation loss = 2.3506  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 2.7762  Validation loss = 2.3482  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 2.7752  Validation loss = 2.3446  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 2.7745  Validation loss = 2.3422  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 2.7739  Validation loss = 2.3403  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 2.7735  Validation loss = 2.3389  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 2.7727  Validation loss = 2.3360  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 2.7722  Validation loss = 2.3340  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 2.7713  Validation loss = 2.3308  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 2.7707  Validation loss = 2.3286  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 2.7702  Validation loss = 2.3268  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 2.7695  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 2.7692  Validation loss = 2.3234  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 2.7687  Validation loss = 2.3215  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 2.7676  Validation loss = 2.3178  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 2.7669  Validation loss = 2.3152  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 2.7667  Validation loss = 2.3143  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 2.7659  Validation loss = 2.3116  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 2.7657  Validation loss = 2.3106  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 2.7646  Validation loss = 2.3067  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 2.7642  Validation loss = 2.3051  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 2.7637  Validation loss = 2.3036  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 2.7631  Validation loss = 2.3011  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 2.7623  Validation loss = 2.2983  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 2.7617  Validation loss = 2.2961  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 2.7617  Validation loss = 2.2960  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 2.7610  Validation loss = 2.2936  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 2.7605  Validation loss = 2.2916  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 2.7602  Validation loss = 2.2905  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 2.7599  Validation loss = 2.2895  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 2.7596  Validation loss = 2.2883  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 2.7596  Validation loss = 2.2881  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 2.7592  Validation loss = 2.2869  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 2.7588  Validation loss = 2.2851  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 2.7583  Validation loss = 2.2833  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 2.7579  Validation loss = 2.2818  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 2.7575  Validation loss = 2.2802  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 2.7569  Validation loss = 2.2782  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 2.7566  Validation loss = 2.2771  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 2.7560  Validation loss = 2.2749  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 2.7553  Validation loss = 2.2721  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 2.7548  Validation loss = 2.2700  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 2.7546  Validation loss = 2.2693  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 2.7540  Validation loss = 2.2672  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 2.7533  Validation loss = 2.2645  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 2.7531  Validation loss = 2.2637  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 2.7525  Validation loss = 2.2616  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 2.7518  Validation loss = 2.2589  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 2.7512  Validation loss = 2.2566  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 2.7506  Validation loss = 2.2543  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 2.7501  Validation loss = 2.2524  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 2.7495  Validation loss = 2.2499  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 2.7489  Validation loss = 2.2476  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 2.7485  Validation loss = 2.2461  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 2.7477  Validation loss = 2.2429  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 2.7471  Validation loss = 2.2406  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 2.7469  Validation loss = 2.2396  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 2.7465  Validation loss = 2.2383  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 2.7459  Validation loss = 2.2360  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 2.7456  Validation loss = 2.2345  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 2.7450  Validation loss = 2.2323  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 2.7446  Validation loss = 2.2307  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 2.7444  Validation loss = 2.2299  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 2.7439  Validation loss = 2.2278  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 2.7435  Validation loss = 2.2264  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 2.7434  Validation loss = 2.2258  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 2.7429  Validation loss = 2.2240  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 2.7422  Validation loss = 2.2210  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 2.7418  Validation loss = 2.2195  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 2.7410  Validation loss = 2.2161  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 2.7406  Validation loss = 2.2148  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 2.7400  Validation loss = 2.2124  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 2.7394  Validation loss = 2.2099  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 2.7390  Validation loss = 2.2080  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 2.7387  Validation loss = 2.2071  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 2.7386  Validation loss = 2.2066  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 2.7385  Validation loss = 2.2063  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 2.7380  Validation loss = 2.2044  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 2.7375  Validation loss = 2.2021  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 2.7369  Validation loss = 2.1996  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 2.7367  Validation loss = 2.1989  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 2.7363  Validation loss = 2.1972  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 2.7362  Validation loss = 2.1967  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 2.7357  Validation loss = 2.1947  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 2.7355  Validation loss = 2.1939  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 2.7352  Validation loss = 2.1928  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 2.7343  Validation loss = 2.1891  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 2.7340  Validation loss = 2.1877  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 2.7333  Validation loss = 2.1845  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 2.7328  Validation loss = 2.1828  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 2.7326  Validation loss = 2.1817  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 2.7321  Validation loss = 2.1798  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 2.7318  Validation loss = 2.1783  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 2.7316  Validation loss = 2.1775  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 2.7311  Validation loss = 2.1756  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 2.7308  Validation loss = 2.1741  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 2.7303  Validation loss = 2.1720  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 2.7298  Validation loss = 2.1700  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 2.7297  Validation loss = 2.1696  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 2.7293  Validation loss = 2.1680  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 2.7289  Validation loss = 2.1663  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 2.7287  Validation loss = 2.1655  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 2.7283  Validation loss = 2.1637  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 2.7280  Validation loss = 2.1622  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 2.7278  Validation loss = 2.1616  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 2.7278  Validation loss = 2.1614  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 2.7272  Validation loss = 2.1589  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 2.7270  Validation loss = 2.1582  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 2.7265  Validation loss = 2.1559  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 2.7258  Validation loss = 2.1529  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 2.7255  Validation loss = 2.1515  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 2.7250  Validation loss = 2.1493  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 2.7247  Validation loss = 2.1479  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 2.7243  Validation loss = 2.1463  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 2.7236  Validation loss = 2.1431  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 2.7233  Validation loss = 2.1420  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 2.7228  Validation loss = 2.1393  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.6299  Validation loss = 2.1288  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.6292  Validation loss = 2.1267  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.6286  Validation loss = 2.1254  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.6286  Validation loss = 2.1254  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.6281  Validation loss = 2.1242  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.6277  Validation loss = 2.1229  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.6271  Validation loss = 2.1213  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.6268  Validation loss = 2.1207  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.6265  Validation loss = 2.1198  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.6261  Validation loss = 2.1185  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.6258  Validation loss = 2.1177  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.6252  Validation loss = 2.1161  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.6250  Validation loss = 2.1153  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.6245  Validation loss = 2.1139  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.6243  Validation loss = 2.1129  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.6239  Validation loss = 2.1120  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.6234  Validation loss = 2.1105  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.6228  Validation loss = 2.1091  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.6227  Validation loss = 2.1088  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.6225  Validation loss = 2.1083  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.6223  Validation loss = 2.1077  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.6220  Validation loss = 2.1069  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.6217  Validation loss = 2.1059  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.6215  Validation loss = 2.1054  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.6211  Validation loss = 2.1045  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.6205  Validation loss = 2.1028  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.6202  Validation loss = 2.1020  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.6195  Validation loss = 2.1001  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.6191  Validation loss = 2.0990  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.6188  Validation loss = 2.0984  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.6184  Validation loss = 2.0973  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.6184  Validation loss = 2.0971  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.6182  Validation loss = 2.0965  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.6179  Validation loss = 2.0958  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.6176  Validation loss = 2.0947  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.6173  Validation loss = 2.0938  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.6172  Validation loss = 2.0934  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.6171  Validation loss = 2.0929  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.6169  Validation loss = 2.0923  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.6165  Validation loss = 2.0912  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.6164  Validation loss = 2.0911  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.6159  Validation loss = 2.0896  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.6156  Validation loss = 2.0886  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.6152  Validation loss = 2.0875  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.6148  Validation loss = 2.0865  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.6145  Validation loss = 2.0855  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.6141  Validation loss = 2.0845  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.6136  Validation loss = 2.0830  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.6131  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.6129  Validation loss = 2.0810  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.6127  Validation loss = 2.0802  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.6126  Validation loss = 2.0799  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.6122  Validation loss = 2.0789  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.6119  Validation loss = 2.0780  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.6116  Validation loss = 2.0773  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.6115  Validation loss = 2.0769  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.6110  Validation loss = 2.0754  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.6106  Validation loss = 2.0744  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.6106  Validation loss = 2.0745  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.6103  Validation loss = 2.0738  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.6100  Validation loss = 2.0731  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.6094  Validation loss = 2.0714  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.6093  Validation loss = 2.0712  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.6090  Validation loss = 2.0701  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.6088  Validation loss = 2.0693  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.6087  Validation loss = 2.0691  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.6087  Validation loss = 2.0692  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.6086  Validation loss = 2.0690  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.6084  Validation loss = 2.0687  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.6079  Validation loss = 2.0672  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.6075  Validation loss = 2.0660  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.6072  Validation loss = 2.0652  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.6070  Validation loss = 2.0646  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.6066  Validation loss = 2.0634  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.6062  Validation loss = 2.0624  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.6060  Validation loss = 2.0616  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.6057  Validation loss = 2.0610  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.6055  Validation loss = 2.0602  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.6053  Validation loss = 2.0597  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.6051  Validation loss = 2.0593  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.6047  Validation loss = 2.0579  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.6043  Validation loss = 2.0567  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.6038  Validation loss = 2.0556  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.6038  Validation loss = 2.0557  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.6032  Validation loss = 2.0539  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.6027  Validation loss = 2.0524  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.6024  Validation loss = 2.0514  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.6022  Validation loss = 2.0507  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.6018  Validation loss = 2.0493  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.6018  Validation loss = 2.0496  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.6016  Validation loss = 2.0491  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.6012  Validation loss = 2.0480  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.6010  Validation loss = 2.0473  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.6008  Validation loss = 2.0469  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.6005  Validation loss = 2.0457  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.6002  Validation loss = 2.0447  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.5996  Validation loss = 2.0430  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.5993  Validation loss = 2.0421  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.5992  Validation loss = 2.0419  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.5991  Validation loss = 2.0415  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.5988  Validation loss = 2.0405  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.5988  Validation loss = 2.0407  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.5985  Validation loss = 2.0396  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.5981  Validation loss = 2.0385  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.5978  Validation loss = 2.0378  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.5976  Validation loss = 2.0370  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.5974  Validation loss = 2.0364  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.5970  Validation loss = 2.0353  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.5964  Validation loss = 2.0334  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.5961  Validation loss = 2.0325  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.5959  Validation loss = 2.0319  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.5958  Validation loss = 2.0315  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.5956  Validation loss = 2.0310  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.5954  Validation loss = 2.0306  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.5952  Validation loss = 2.0301  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.5950  Validation loss = 2.0293  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.5948  Validation loss = 2.0286  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.5945  Validation loss = 2.0277  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.5945  Validation loss = 2.0279  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.5944  Validation loss = 2.0277  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.5942  Validation loss = 2.0268  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.5941  Validation loss = 2.0265  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.5938  Validation loss = 2.0257  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.5935  Validation loss = 2.0247  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.5936  Validation loss = 2.0250  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.5933  Validation loss = 2.0241  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.5929  Validation loss = 2.0228  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.5926  Validation loss = 2.0219  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.5922  Validation loss = 2.0206  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.5920  Validation loss = 2.0203  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.5918  Validation loss = 2.0196  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.5916  Validation loss = 2.0189  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.5915  Validation loss = 2.0185  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.5912  Validation loss = 2.0174  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.5909  Validation loss = 2.0163  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.5908  Validation loss = 2.0161  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.5907  Validation loss = 2.0157  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.5905  Validation loss = 2.0152  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.5904  Validation loss = 2.0148  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.5899  Validation loss = 2.0131  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.5892  Validation loss = 2.0112  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.5891  Validation loss = 2.0109  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.5886  Validation loss = 2.0092  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.5884  Validation loss = 2.0085  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.5879  Validation loss = 2.0069  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.5877  Validation loss = 2.0062  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.5870  Validation loss = 2.0041  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.5867  Validation loss = 2.0031  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.5865  Validation loss = 2.0026  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.5861  Validation loss = 2.0013  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.5859  Validation loss = 2.0006  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.5855  Validation loss = 1.9994  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.5854  Validation loss = 1.9994  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.5852  Validation loss = 1.9991  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.5852  Validation loss = 1.9993  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.5849  Validation loss = 1.9979  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.5847  Validation loss = 1.9972  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.5846  Validation loss = 1.9970  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.5844  Validation loss = 1.9964  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.5841  Validation loss = 1.9955  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.5838  Validation loss = 1.9947  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.5836  Validation loss = 1.9939  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.5834  Validation loss = 1.9933  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.5833  Validation loss = 1.9927  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.5832  Validation loss = 1.9925  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.5831  Validation loss = 1.9924  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.5829  Validation loss = 1.9912  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.5825  Validation loss = 1.9901  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.5823  Validation loss = 1.9890  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.5819  Validation loss = 1.9880  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.5816  Validation loss = 1.9866  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.5815  Validation loss = 1.9864  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.5814  Validation loss = 1.9858  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.5812  Validation loss = 1.9854  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.5810  Validation loss = 1.9848  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.5810  Validation loss = 1.9846  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.5807  Validation loss = 1.9840  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.5807  Validation loss = 1.9839  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.5805  Validation loss = 1.9834  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.5805  Validation loss = 1.9836  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.5803  Validation loss = 1.9830  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.5800  Validation loss = 1.9820  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.5799  Validation loss = 1.9815  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.5796  Validation loss = 1.9805  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.5796  Validation loss = 1.9804  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.5791  Validation loss = 1.9789  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.5787  Validation loss = 1.9774  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.5785  Validation loss = 1.9766  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.5784  Validation loss = 1.9764  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.5784  Validation loss = 1.9764  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.5783  Validation loss = 1.9762  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.5782  Validation loss = 1.9761  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.5781  Validation loss = 1.9758  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.5781  Validation loss = 1.9759  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.5780  Validation loss = 1.9756  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.5778  Validation loss = 1.9745  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.5775  Validation loss = 1.9738  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.5774  Validation loss = 1.9734  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.5773  Validation loss = 1.9733  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.5770  Validation loss = 1.9721  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.5768  Validation loss = 1.9717  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.5766  Validation loss = 1.9708  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.5764  Validation loss = 1.9700  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.5763  Validation loss = 1.9696  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.5762  Validation loss = 1.9692  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.5762  Validation loss = 1.9690  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.5761  Validation loss = 1.9688  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.5758  Validation loss = 1.9678  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.5756  Validation loss = 1.9671  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.5754  Validation loss = 1.9666  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.5754  Validation loss = 1.9668  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.5752  Validation loss = 1.9662  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.5753  Validation loss = 1.9665  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.5749  Validation loss = 1.9653  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.5748  Validation loss = 1.9652  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.5748  Validation loss = 1.9650  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.5748  Validation loss = 1.9649  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.5747  Validation loss = 1.9647  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.5745  Validation loss = 1.9637  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.5744  Validation loss = 1.9638  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.5743  Validation loss = 1.9636  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.5741  Validation loss = 1.9626  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.5740  Validation loss = 1.9621  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.5739  Validation loss = 1.9617  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.5737  Validation loss = 1.9612  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.5734  Validation loss = 1.9603  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.5733  Validation loss = 1.9596  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.5733  Validation loss = 1.9597  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.5732  Validation loss = 1.9595  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.5732  Validation loss = 1.9599  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.5731  Validation loss = 1.9596  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.5730  Validation loss = 1.9596  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.5726  Validation loss = 1.9579  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.5726  Validation loss = 1.9580  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.5724  Validation loss = 1.9574  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.5723  Validation loss = 1.9572  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.5719  Validation loss = 1.9558  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.5718  Validation loss = 1.9552  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.5716  Validation loss = 1.9547  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.5713  Validation loss = 1.9537  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.5712  Validation loss = 1.9534  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.5711  Validation loss = 1.9529  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.5709  Validation loss = 1.9524  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.5709  Validation loss = 1.9522  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.5707  Validation loss = 1.9518  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.5705  Validation loss = 1.9511  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.5702  Validation loss = 1.9499  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.5702  Validation loss = 1.9503  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.5702  Validation loss = 1.9503  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.5702  Validation loss = 1.9504  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.5702  Validation loss = 1.9505  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.5701  Validation loss = 1.9506  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.5701  Validation loss = 1.9504  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.5700  Validation loss = 1.9502  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.5700  Validation loss = 1.9501  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.5697  Validation loss = 1.9492  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.5696  Validation loss = 1.9487  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.5692  Validation loss = 1.9474  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.5689  Validation loss = 1.9468  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.5689  Validation loss = 1.9467  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.5689  Validation loss = 1.9467  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.5688  Validation loss = 1.9467  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.5687  Validation loss = 1.9468  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.5685  Validation loss = 1.9460  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.5683  Validation loss = 1.9452  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.5684  Validation loss = 1.9455  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.5680  Validation loss = 1.9442  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.5680  Validation loss = 1.9443  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.5677  Validation loss = 1.9431  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.5675  Validation loss = 1.9423  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.5676  Validation loss = 1.9427  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.5673  Validation loss = 1.9415  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.5671  Validation loss = 1.9411  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.5669  Validation loss = 1.9402  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.5667  Validation loss = 1.9394  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.5666  Validation loss = 1.9391  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.5663  Validation loss = 1.9378  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.5661  Validation loss = 1.9372  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.5661  Validation loss = 1.9373  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.5661  Validation loss = 1.9372  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.5658  Validation loss = 1.9363  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.5658  Validation loss = 1.9360  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.5656  Validation loss = 1.9354  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.5652  Validation loss = 1.9337  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.5651  Validation loss = 1.9336  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.5650  Validation loss = 1.9331  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.5649  Validation loss = 1.9326  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.5648  Validation loss = 1.9324  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.5646  Validation loss = 1.9319  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.5646  Validation loss = 1.9317  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.5644  Validation loss = 1.9309  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.5641  Validation loss = 1.9299  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.5639  Validation loss = 1.9286  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.5637  Validation loss = 1.9278  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.5638  Validation loss = 1.9286  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.5638  Validation loss = 1.9289  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.5637  Validation loss = 1.9285  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.5634  Validation loss = 1.9275  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.5634  Validation loss = 1.9273  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.5632  Validation loss = 1.9266  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.5631  Validation loss = 1.9261  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.5631  Validation loss = 1.9258  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.5630  Validation loss = 1.9255  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.5629  Validation loss = 1.9255  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.5627  Validation loss = 1.9247  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.5625  Validation loss = 1.9240  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.5624  Validation loss = 1.9235  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.5624  Validation loss = 1.9234  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.5623  Validation loss = 1.9235  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.5623  Validation loss = 1.9234  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.5621  Validation loss = 1.9226  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.5620  Validation loss = 1.9219  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.5620  Validation loss = 1.9218  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.5619  Validation loss = 1.9213  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.5618  Validation loss = 1.9212  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.5615  Validation loss = 1.9201  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.5613  Validation loss = 1.9190  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.5613  Validation loss = 1.9192  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.5612  Validation loss = 1.9186  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.5612  Validation loss = 1.9191  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.5612  Validation loss = 1.9191  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.5611  Validation loss = 1.9189  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.5608  Validation loss = 1.9176  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.5607  Validation loss = 1.9173  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.5606  Validation loss = 1.9170  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.5604  Validation loss = 1.9164  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.5603  Validation loss = 1.9159  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.5601  Validation loss = 1.9154  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.5601  Validation loss = 1.9155  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.5598  Validation loss = 1.9141  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.5598  Validation loss = 1.9140  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.5596  Validation loss = 1.9130  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.5594  Validation loss = 1.9122  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.5593  Validation loss = 1.9122  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.5592  Validation loss = 1.9119  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.5593  Validation loss = 1.9125  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.5592  Validation loss = 1.9121  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.5592  Validation loss = 1.9126  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.5592  Validation loss = 1.9126  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.5591  Validation loss = 1.9126  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.5590  Validation loss = 1.9124  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.5588  Validation loss = 1.9116  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.5587  Validation loss = 1.9114  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.5587  Validation loss = 1.9112  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.5584  Validation loss = 1.9101  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.5582  Validation loss = 1.9090  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.5582  Validation loss = 1.9090  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.5579  Validation loss = 1.9081  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.5579  Validation loss = 1.9080  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.5577  Validation loss = 1.9074  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.5577  Validation loss = 1.9073  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.5577  Validation loss = 1.9073  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.5576  Validation loss = 1.9072  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.5575  Validation loss = 1.9070  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.5573  Validation loss = 1.9058  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.5573  Validation loss = 1.9057  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.5572  Validation loss = 1.9057  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.5572  Validation loss = 1.9056  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.5570  Validation loss = 1.9047  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.5570  Validation loss = 1.9050  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.5566  Validation loss = 1.9029  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.5565  Validation loss = 1.9025  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.5564  Validation loss = 1.9025  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.5564  Validation loss = 1.9026  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.5563  Validation loss = 1.9025  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.5563  Validation loss = 1.9025  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.5560  Validation loss = 1.9014  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.5558  Validation loss = 1.9003  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.5557  Validation loss = 1.8999  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.5556  Validation loss = 1.9000  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.5555  Validation loss = 1.8996  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.5554  Validation loss = 1.8992  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.5554  Validation loss = 1.8990  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.5552  Validation loss = 1.8980  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.5551  Validation loss = 1.8981  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.5550  Validation loss = 1.8976  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.5550  Validation loss = 1.8976  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.5550  Validation loss = 1.8981  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.5549  Validation loss = 1.8976  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.5548  Validation loss = 1.8976  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.5547  Validation loss = 1.8968  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.5547  Validation loss = 1.8970  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.5545  Validation loss = 1.8963  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.5544  Validation loss = 1.8958  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.5544  Validation loss = 1.8961  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.5544  Validation loss = 1.8960  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.5544  Validation loss = 1.8961  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.5541  Validation loss = 1.8948  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.5540  Validation loss = 1.8946  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.5539  Validation loss = 1.8939  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.5539  Validation loss = 1.8939  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.5536  Validation loss = 1.8928  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.5535  Validation loss = 1.8922  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.5535  Validation loss = 1.8922  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.5533  Validation loss = 1.8915  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.5532  Validation loss = 1.8910  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.5532  Validation loss = 1.8910  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.5530  Validation loss = 1.8903  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.5529  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.5527  Validation loss = 1.8886  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.5525  Validation loss = 1.8879  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.5524  Validation loss = 1.8874  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.5522  Validation loss = 1.8865  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.5521  Validation loss = 1.8864  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.5521  Validation loss = 1.8865  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.5521  Validation loss = 1.8868  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.5520  Validation loss = 1.8864  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.5519  Validation loss = 1.8861  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.5520  Validation loss = 1.8865  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.5520  Validation loss = 1.8865  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.5519  Validation loss = 1.8862  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.5517  Validation loss = 1.8855  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.5517  Validation loss = 1.8852  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.5516  Validation loss = 1.8847  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.5515  Validation loss = 1.8846  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.5515  Validation loss = 1.8850  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.5514  Validation loss = 1.8846  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.5512  Validation loss = 1.8840  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.5511  Validation loss = 1.8836  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.5509  Validation loss = 1.8828  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.5509  Validation loss = 1.8827  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.5507  Validation loss = 1.8823  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.5505  Validation loss = 1.8813  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.5504  Validation loss = 1.8804  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.5503  Validation loss = 1.8802  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.5501  Validation loss = 1.8797  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.5501  Validation loss = 1.8796  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.5500  Validation loss = 1.8790  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.5497  Validation loss = 1.8775  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.5495  Validation loss = 1.8764  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.5494  Validation loss = 1.8763  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.5493  Validation loss = 1.8761  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.5493  Validation loss = 1.8764  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.5492  Validation loss = 1.8762  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.5493  Validation loss = 1.8766  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.5491  Validation loss = 1.8760  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.5491  Validation loss = 1.8758  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.5490  Validation loss = 1.8759  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.5489  Validation loss = 1.8757  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.5490  Validation loss = 1.8758  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.5488  Validation loss = 1.8755  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.5488  Validation loss = 1.8760  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.5488  Validation loss = 1.8761  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.5487  Validation loss = 1.8759  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.5485  Validation loss = 1.8753  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.5484  Validation loss = 1.8745  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.5483  Validation loss = 1.8748  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.5483  Validation loss = 1.8747  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.5481  Validation loss = 1.8740  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.5480  Validation loss = 1.8737  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.5480  Validation loss = 1.8736  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.5479  Validation loss = 1.8736  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.5480  Validation loss = 1.8740  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.5478  Validation loss = 1.8731  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.5475  Validation loss = 1.8713  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.5475  Validation loss = 1.8718  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.5473  Validation loss = 1.8707  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.5470  Validation loss = 1.8692  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.5469  Validation loss = 1.8688  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.5469  Validation loss = 1.8686  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.5468  Validation loss = 1.8684  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.5467  Validation loss = 1.8679  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.5466  Validation loss = 1.8673  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.5465  Validation loss = 1.8666  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.5463  Validation loss = 1.8663  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.5463  Validation loss = 1.8662  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.5461  Validation loss = 1.8653  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.5460  Validation loss = 1.8650  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.5460  Validation loss = 1.8653  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.5460  Validation loss = 1.8652  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.5459  Validation loss = 1.8647  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.5458  Validation loss = 1.8645  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.5457  Validation loss = 1.8642  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.5456  Validation loss = 1.8641  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.5455  Validation loss = 1.8639  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.5454  Validation loss = 1.8630  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.5453  Validation loss = 1.8626  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.5452  Validation loss = 1.8619  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.5451  Validation loss = 1.8620  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.5449  Validation loss = 1.8606  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.5449  Validation loss = 1.8610  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.5446  Validation loss = 1.8596  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.5444  Validation loss = 1.8586  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.5444  Validation loss = 1.8585  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.5444  Validation loss = 1.8586  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.5443  Validation loss = 1.8581  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.5442  Validation loss = 1.8578  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.5441  Validation loss = 1.8577  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.5441  Validation loss = 1.8580  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.5441  Validation loss = 1.8579  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.5441  Validation loss = 1.8578  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.5439  Validation loss = 1.8569  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.5440  Validation loss = 1.8571  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.5439  Validation loss = 1.8568  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.5438  Validation loss = 1.8567  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.5437  Validation loss = 1.8560  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.5437  Validation loss = 1.8563  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.5435  Validation loss = 1.8556  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.5433  Validation loss = 1.8548  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.5433  Validation loss = 1.8545  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.5187  Validation loss = 2.8031  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.5186  Validation loss = 2.8036  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.5185  Validation loss = 2.8030  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.5184  Validation loss = 2.8032  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.5184  Validation loss = 2.8032  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.5183  Validation loss = 2.8031  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.5181  Validation loss = 2.8035  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.5181  Validation loss = 2.8035  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.5180  Validation loss = 2.8040  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.5179  Validation loss = 2.8044  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.5177  Validation loss = 2.8048  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 3  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.5685  Validation loss = 4.0002  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.5684  Validation loss = 3.9998  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.5683  Validation loss = 3.9996  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.5682  Validation loss = 3.9987  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.5681  Validation loss = 3.9981  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.5680  Validation loss = 3.9970  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.5679  Validation loss = 3.9968  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.5678  Validation loss = 3.9963  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.5677  Validation loss = 3.9954  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.5676  Validation loss = 3.9947  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.5675  Validation loss = 3.9950  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.5674  Validation loss = 3.9943  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.5673  Validation loss = 3.9937  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.5672  Validation loss = 3.9926  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.5671  Validation loss = 3.9924  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.5670  Validation loss = 3.9920  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.5670  Validation loss = 3.9927  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.5669  Validation loss = 3.9927  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.5668  Validation loss = 3.9920  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.5667  Validation loss = 3.9913  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.5666  Validation loss = 3.9913  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.5665  Validation loss = 3.9911  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.5665  Validation loss = 3.9917  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.5664  Validation loss = 3.9914  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.5663  Validation loss = 3.9907  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.5661  Validation loss = 3.9904  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.5660  Validation loss = 3.9891  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.5659  Validation loss = 3.9886  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.5658  Validation loss = 3.9881  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.5657  Validation loss = 3.9876  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.5656  Validation loss = 3.9872  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.5655  Validation loss = 3.9867  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.5654  Validation loss = 3.9873  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.5653  Validation loss = 3.9866  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.5652  Validation loss = 3.9856  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.5651  Validation loss = 3.9859  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.5650  Validation loss = 3.9855  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.5649  Validation loss = 3.9851  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.5648  Validation loss = 3.9855  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.5647  Validation loss = 3.9846  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.5646  Validation loss = 3.9840  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.5645  Validation loss = 3.9838  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.5644  Validation loss = 3.9840  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.5643  Validation loss = 3.9845  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.5642  Validation loss = 3.9840  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.5641  Validation loss = 3.9838  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.5640  Validation loss = 3.9843  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.5639  Validation loss = 3.9838  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.5638  Validation loss = 3.9829  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.5637  Validation loss = 3.9836  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.5636  Validation loss = 3.9838  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.5635  Validation loss = 3.9836  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.5635  Validation loss = 3.9825  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.5633  Validation loss = 3.9814  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.5632  Validation loss = 3.9809  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.5630  Validation loss = 3.9797  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.5629  Validation loss = 3.9787  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.5629  Validation loss = 3.9783  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.5628  Validation loss = 3.9775  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.5627  Validation loss = 3.9782  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.5626  Validation loss = 3.9783  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.5625  Validation loss = 3.9778  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.5625  Validation loss = 3.9781  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.5624  Validation loss = 3.9781  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.5623  Validation loss = 3.9768  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.5621  Validation loss = 3.9761  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.5620  Validation loss = 3.9758  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.5619  Validation loss = 3.9755  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.5618  Validation loss = 3.9754  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.5618  Validation loss = 3.9749  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.5616  Validation loss = 3.9742  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.5615  Validation loss = 3.9729  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.5614  Validation loss = 3.9725  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.5612  Validation loss = 3.9718  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.5612  Validation loss = 3.9721  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.5611  Validation loss = 3.9719  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.5610  Validation loss = 3.9714  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.5609  Validation loss = 3.9707  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.5607  Validation loss = 3.9699  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.5606  Validation loss = 3.9693  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.5605  Validation loss = 3.9696  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.5605  Validation loss = 3.9700  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.5604  Validation loss = 3.9691  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.5603  Validation loss = 3.9683  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.5601  Validation loss = 3.9683  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.5600  Validation loss = 3.9678  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.5599  Validation loss = 3.9674  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.5598  Validation loss = 3.9674  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.5597  Validation loss = 3.9670  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.5597  Validation loss = 3.9672  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.5596  Validation loss = 3.9667  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.5595  Validation loss = 3.9670  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.5594  Validation loss = 3.9660  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.5593  Validation loss = 3.9645  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.5592  Validation loss = 3.9643  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.5591  Validation loss = 3.9643  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.5590  Validation loss = 3.9634  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.5589  Validation loss = 3.9640  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.5589  Validation loss = 3.9632  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.5587  Validation loss = 3.9625  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.5587  Validation loss = 3.9618  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.5585  Validation loss = 3.9605  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.5584  Validation loss = 3.9597  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.5583  Validation loss = 3.9592  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.5583  Validation loss = 3.9594  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.5582  Validation loss = 3.9600  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.5581  Validation loss = 3.9595  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.5580  Validation loss = 3.9593  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.5579  Validation loss = 3.9594  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.5578  Validation loss = 3.9592  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.5577  Validation loss = 3.9590  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.5576  Validation loss = 3.9592  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.5575  Validation loss = 3.9598  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.5574  Validation loss = 3.9591  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.5574  Validation loss = 3.9594  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.5573  Validation loss = 3.9592  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.5572  Validation loss = 3.9595  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.5571  Validation loss = 3.9587  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.5570  Validation loss = 3.9588  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.5569  Validation loss = 3.9584  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.5568  Validation loss = 3.9575  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.5567  Validation loss = 3.9580  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.5566  Validation loss = 3.9573  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.5566  Validation loss = 3.9577  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.5564  Validation loss = 3.9570  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.5563  Validation loss = 3.9565  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.5563  Validation loss = 3.9571  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.5562  Validation loss = 3.9570  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.5561  Validation loss = 3.9566  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.5560  Validation loss = 3.9560  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.5559  Validation loss = 3.9552  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.5558  Validation loss = 3.9550  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.5557  Validation loss = 3.9539  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.5555  Validation loss = 3.9536  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.5555  Validation loss = 3.9532  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.5554  Validation loss = 3.9533  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.5553  Validation loss = 3.9534  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.5553  Validation loss = 3.9533  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.5552  Validation loss = 3.9528  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.5551  Validation loss = 3.9522  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.5550  Validation loss = 3.9515  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.5549  Validation loss = 3.9505  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.5547  Validation loss = 3.9503  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.5546  Validation loss = 3.9503  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.5546  Validation loss = 3.9502  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.5545  Validation loss = 3.9494  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.5544  Validation loss = 3.9486  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.5543  Validation loss = 3.9487  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.5542  Validation loss = 3.9486  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.5541  Validation loss = 3.9485  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.5540  Validation loss = 3.9487  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.5539  Validation loss = 3.9474  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.5538  Validation loss = 3.9476  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.5537  Validation loss = 3.9470  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.5536  Validation loss = 3.9464  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.5535  Validation loss = 3.9457  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.5534  Validation loss = 3.9454  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.5533  Validation loss = 3.9452  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.5532  Validation loss = 3.9454  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.5531  Validation loss = 3.9449  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.5530  Validation loss = 3.9445  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.5530  Validation loss = 3.9447  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.5528  Validation loss = 3.9450  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.5527  Validation loss = 3.9442  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.5526  Validation loss = 3.9442  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.5525  Validation loss = 3.9439  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.5525  Validation loss = 3.9438  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.5524  Validation loss = 3.9435  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.5523  Validation loss = 3.9427  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.5522  Validation loss = 3.9421  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.5521  Validation loss = 3.9421  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.5520  Validation loss = 3.9421  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.5519  Validation loss = 3.9418  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.5518  Validation loss = 3.9415  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.5517  Validation loss = 3.9419  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.5516  Validation loss = 3.9416  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.5515  Validation loss = 3.9416  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.5515  Validation loss = 3.9414  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.5514  Validation loss = 3.9413  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.5513  Validation loss = 3.9407  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.5512  Validation loss = 3.9404  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.5511  Validation loss = 3.9408  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.5510  Validation loss = 3.9404  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.5509  Validation loss = 3.9399  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.5508  Validation loss = 3.9388  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.5506  Validation loss = 3.9377  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.5506  Validation loss = 3.9378  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.5505  Validation loss = 3.9383  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.5504  Validation loss = 3.9370  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.5503  Validation loss = 3.9374  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.5502  Validation loss = 3.9372  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.5501  Validation loss = 3.9370  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.5500  Validation loss = 3.9369  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.5500  Validation loss = 3.9369  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.5499  Validation loss = 3.9364  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.5498  Validation loss = 3.9362  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.5497  Validation loss = 3.9360  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.5497  Validation loss = 3.9361  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.5496  Validation loss = 3.9360  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.5495  Validation loss = 3.9360  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.5494  Validation loss = 3.9362  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.5493  Validation loss = 3.9355  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.5492  Validation loss = 3.9357  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.5492  Validation loss = 3.9353  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.5491  Validation loss = 3.9347  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.5490  Validation loss = 3.9340  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.5489  Validation loss = 3.9334  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.5488  Validation loss = 3.9333  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.5486  Validation loss = 3.9326  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.5485  Validation loss = 3.9327  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.5485  Validation loss = 3.9325  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.5484  Validation loss = 3.9319  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.5483  Validation loss = 3.9323  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.5483  Validation loss = 3.9333  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.5482  Validation loss = 3.9330  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.5481  Validation loss = 3.9328  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.5480  Validation loss = 3.9320  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.5479  Validation loss = 3.9315  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.5478  Validation loss = 3.9313  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.5477  Validation loss = 3.9307  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.5477  Validation loss = 3.9298  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.5476  Validation loss = 3.9297  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.5474  Validation loss = 3.9286  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.5473  Validation loss = 3.9282  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.5473  Validation loss = 3.9285  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.5472  Validation loss = 3.9286  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.5471  Validation loss = 3.9286  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.5470  Validation loss = 3.9284  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.5469  Validation loss = 3.9281  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.5468  Validation loss = 3.9279  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.5467  Validation loss = 3.9276  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.5466  Validation loss = 3.9268  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.5465  Validation loss = 3.9258  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.5464  Validation loss = 3.9250  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.5463  Validation loss = 3.9241  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.5461  Validation loss = 3.9239  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.5460  Validation loss = 3.9234  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.5459  Validation loss = 3.9235  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.5458  Validation loss = 3.9230  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.5457  Validation loss = 3.9227  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.5457  Validation loss = 3.9228  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.5456  Validation loss = 3.9223  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.5455  Validation loss = 3.9215  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.5454  Validation loss = 3.9211  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.5453  Validation loss = 3.9210  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.5453  Validation loss = 3.9212  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.5452  Validation loss = 3.9206  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.5451  Validation loss = 3.9197  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.5450  Validation loss = 3.9192  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.5449  Validation loss = 3.9186  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.5449  Validation loss = 3.9183  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.5448  Validation loss = 3.9191  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.5447  Validation loss = 3.9186  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.5446  Validation loss = 3.9182  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.5445  Validation loss = 3.9177  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.5444  Validation loss = 3.9172  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.5443  Validation loss = 3.9162  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.5442  Validation loss = 3.9156  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.5441  Validation loss = 3.9154  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.5440  Validation loss = 3.9151  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.5439  Validation loss = 3.9150  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.5439  Validation loss = 3.9142  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.5438  Validation loss = 3.9139  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.5436  Validation loss = 3.9129  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.5435  Validation loss = 3.9125  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.5434  Validation loss = 3.9120  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.5433  Validation loss = 3.9111  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.5432  Validation loss = 3.9100  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.5430  Validation loss = 3.9096  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.5429  Validation loss = 3.9095  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.5428  Validation loss = 3.9089  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.5427  Validation loss = 3.9083  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.5426  Validation loss = 3.9077  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.5425  Validation loss = 3.9077  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.5424  Validation loss = 3.9073  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.5423  Validation loss = 3.9062  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.5422  Validation loss = 3.9059  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.5421  Validation loss = 3.9054  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.5420  Validation loss = 3.9041  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.5420  Validation loss = 3.9042  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.5419  Validation loss = 3.9047  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.5418  Validation loss = 3.9052  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.5417  Validation loss = 3.9037  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.5416  Validation loss = 3.9044  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.5415  Validation loss = 3.9032  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.5414  Validation loss = 3.9030  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.5413  Validation loss = 3.9019  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.5411  Validation loss = 3.9011  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.5411  Validation loss = 3.9023  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.5410  Validation loss = 3.9024  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.5410  Validation loss = 3.9026  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.5409  Validation loss = 3.9020  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.5408  Validation loss = 3.9026  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.5408  Validation loss = 3.9027  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.5407  Validation loss = 3.9037  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 288  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.7724  Validation loss = 3.6393  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.7720  Validation loss = 3.6376  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.7716  Validation loss = 3.6361  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.7713  Validation loss = 3.6352  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.7711  Validation loss = 3.6341  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.7706  Validation loss = 3.6323  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.7703  Validation loss = 3.6308  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.7700  Validation loss = 3.6295  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.7695  Validation loss = 3.6274  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.7688  Validation loss = 3.6242  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.7684  Validation loss = 3.6224  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.7683  Validation loss = 3.6221  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.7682  Validation loss = 3.6222  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.7678  Validation loss = 3.6205  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.7675  Validation loss = 3.6192  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.7672  Validation loss = 3.6178  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.7668  Validation loss = 3.6162  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.7665  Validation loss = 3.6148  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.7662  Validation loss = 3.6137  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.7659  Validation loss = 3.6122  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.7656  Validation loss = 3.6111  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.7654  Validation loss = 3.6106  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.7651  Validation loss = 3.6093  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.7648  Validation loss = 3.6075  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.7644  Validation loss = 3.6063  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.7641  Validation loss = 3.6053  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.7638  Validation loss = 3.6043  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.7637  Validation loss = 3.6038  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.7633  Validation loss = 3.6024  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.7630  Validation loss = 3.6014  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.7628  Validation loss = 3.6006  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.7625  Validation loss = 3.5990  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.7622  Validation loss = 3.5979  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.7621  Validation loss = 3.5979  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.7619  Validation loss = 3.5974  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.7617  Validation loss = 3.5969  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.7615  Validation loss = 3.5961  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.7612  Validation loss = 3.5951  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.7608  Validation loss = 3.5931  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.7605  Validation loss = 3.5916  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.7603  Validation loss = 3.5911  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.7601  Validation loss = 3.5903  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.7597  Validation loss = 3.5890  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.7594  Validation loss = 3.5872  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.7591  Validation loss = 3.5863  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.7587  Validation loss = 3.5841  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.7583  Validation loss = 3.5821  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.7579  Validation loss = 3.5800  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.7577  Validation loss = 3.5793  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.7574  Validation loss = 3.5782  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.7569  Validation loss = 3.5757  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.7565  Validation loss = 3.5737  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.7561  Validation loss = 3.5725  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.7558  Validation loss = 3.5713  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.7556  Validation loss = 3.5705  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.7555  Validation loss = 3.5704  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.7554  Validation loss = 3.5700  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.7551  Validation loss = 3.5692  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.7549  Validation loss = 3.5684  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.7546  Validation loss = 3.5671  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.7543  Validation loss = 3.5653  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.7541  Validation loss = 3.5649  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.7539  Validation loss = 3.5639  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.7536  Validation loss = 3.5629  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.7534  Validation loss = 3.5625  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.7533  Validation loss = 3.5624  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.7530  Validation loss = 3.5615  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.7526  Validation loss = 3.5593  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.7522  Validation loss = 3.5579  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.7520  Validation loss = 3.5571  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.7516  Validation loss = 3.5549  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.7514  Validation loss = 3.5544  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.7512  Validation loss = 3.5534  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.7509  Validation loss = 3.5521  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.7507  Validation loss = 3.5518  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.7503  Validation loss = 3.5500  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.7500  Validation loss = 3.5488  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 1.7498  Validation loss = 3.5484  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 1.7497  Validation loss = 3.5484  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 1.7497  Validation loss = 3.5486  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 1.7495  Validation loss = 3.5480  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 1.7493  Validation loss = 3.5473  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 1.7489  Validation loss = 3.5454  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 1.7487  Validation loss = 3.5447  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 1.7484  Validation loss = 3.5438  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 1.7482  Validation loss = 3.5428  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 1.7478  Validation loss = 3.5411  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 1.7476  Validation loss = 3.5397  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 1.7473  Validation loss = 3.5390  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 1.7471  Validation loss = 3.5383  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 1.7468  Validation loss = 3.5372  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 1.7466  Validation loss = 3.5357  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 1.7462  Validation loss = 3.5338  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 1.7458  Validation loss = 3.5324  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 1.7455  Validation loss = 3.5309  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 1.7453  Validation loss = 3.5305  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 1.7450  Validation loss = 3.5290  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 1.7447  Validation loss = 3.5273  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 1.7445  Validation loss = 3.5265  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 1.7442  Validation loss = 3.5248  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 1.7438  Validation loss = 3.5236  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 1.7435  Validation loss = 3.5222  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 1.7432  Validation loss = 3.5209  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 1.7431  Validation loss = 3.5208  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 1.7429  Validation loss = 3.5200  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 1.7427  Validation loss = 3.5193  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 1.7425  Validation loss = 3.5190  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 1.7423  Validation loss = 3.5178  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 1.7422  Validation loss = 3.5176  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 1.7419  Validation loss = 3.5163  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 1.7416  Validation loss = 3.5158  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 1.7415  Validation loss = 3.5148  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 1.7413  Validation loss = 3.5138  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 1.7411  Validation loss = 3.5131  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 1.7407  Validation loss = 3.5115  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 1.7406  Validation loss = 3.5107  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 1.7404  Validation loss = 3.5103  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 1.7401  Validation loss = 3.5088  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 1.7399  Validation loss = 3.5082  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 1.7397  Validation loss = 3.5071  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 1.7395  Validation loss = 3.5069  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 1.7393  Validation loss = 3.5057  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 1.7391  Validation loss = 3.5046  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 1.7389  Validation loss = 3.5044  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 1.7387  Validation loss = 3.5035  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 1.7385  Validation loss = 3.5024  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 1.7383  Validation loss = 3.5017  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 1.7381  Validation loss = 3.5010  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 1.7378  Validation loss = 3.4998  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 1.7377  Validation loss = 3.4999  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 1.7374  Validation loss = 3.4984  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 1.7371  Validation loss = 3.4974  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 1.7369  Validation loss = 3.4966  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 1.7366  Validation loss = 3.4957  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 1.7364  Validation loss = 3.4949  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 1.7361  Validation loss = 3.4936  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 1.7359  Validation loss = 3.4935  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 1.7357  Validation loss = 3.4922  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 1.7353  Validation loss = 3.4899  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 1.7352  Validation loss = 3.4897  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 1.7349  Validation loss = 3.4887  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 1.7346  Validation loss = 3.4873  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 1.7343  Validation loss = 3.4855  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 1.7340  Validation loss = 3.4842  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 1.7338  Validation loss = 3.4835  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 1.7334  Validation loss = 3.4820  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 1.7332  Validation loss = 3.4811  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 1.7330  Validation loss = 3.4800  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 1.7327  Validation loss = 3.4785  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 1.7325  Validation loss = 3.4778  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 1.7322  Validation loss = 3.4761  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 1.7320  Validation loss = 3.4754  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 1.7318  Validation loss = 3.4750  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 1.7315  Validation loss = 3.4734  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 1.7312  Validation loss = 3.4726  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 1.7310  Validation loss = 3.4714  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 1.7306  Validation loss = 3.4698  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 1.7303  Validation loss = 3.4681  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 1.7301  Validation loss = 3.4678  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 1.7299  Validation loss = 3.4676  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 1.7297  Validation loss = 3.4663  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 1.7295  Validation loss = 3.4656  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 1.7292  Validation loss = 3.4639  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 1.7291  Validation loss = 3.4634  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 1.7289  Validation loss = 3.4634  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 1.7289  Validation loss = 3.4639  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 1.7286  Validation loss = 3.4626  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 1.7283  Validation loss = 3.4613  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 1.7281  Validation loss = 3.4607  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 1.7279  Validation loss = 3.4599  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 1.7275  Validation loss = 3.4582  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 1.7272  Validation loss = 3.4563  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 1.7270  Validation loss = 3.4560  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 1.7269  Validation loss = 3.4560  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 1.7266  Validation loss = 3.4546  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 1.7264  Validation loss = 3.4544  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 1.7262  Validation loss = 3.4533  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 1.7260  Validation loss = 3.4519  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 1.7258  Validation loss = 3.4510  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 1.7255  Validation loss = 3.4499  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 1.7253  Validation loss = 3.4494  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 1.7251  Validation loss = 3.4484  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 1.7249  Validation loss = 3.4480  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 1.7246  Validation loss = 3.4468  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 1.7245  Validation loss = 3.4466  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 1.7242  Validation loss = 3.4455  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 1.7240  Validation loss = 3.4449  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 1.7237  Validation loss = 3.4434  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 1.7235  Validation loss = 3.4426  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 1.7232  Validation loss = 3.4410  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 1.7230  Validation loss = 3.4404  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 1.7227  Validation loss = 3.4395  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 1.7225  Validation loss = 3.4384  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 1.7223  Validation loss = 3.4376  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 1.7221  Validation loss = 3.4367  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 1.7217  Validation loss = 3.4346  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 1.7215  Validation loss = 3.4341  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 1.7213  Validation loss = 3.4336  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 1.7212  Validation loss = 3.4339  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 1.7210  Validation loss = 3.4327  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 1.7207  Validation loss = 3.4317  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 1.7205  Validation loss = 3.4307  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 1.7202  Validation loss = 3.4297  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 1.7200  Validation loss = 3.4286  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 1.7197  Validation loss = 3.4275  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 1.7194  Validation loss = 3.4263  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 1.7192  Validation loss = 3.4250  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 1.7188  Validation loss = 3.4227  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 1.7186  Validation loss = 3.4218  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 1.7184  Validation loss = 3.4212  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 1.7183  Validation loss = 3.4212  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 1.7181  Validation loss = 3.4209  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 1.7178  Validation loss = 3.4189  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 1.7175  Validation loss = 3.4176  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 1.7173  Validation loss = 3.4171  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 1.7172  Validation loss = 3.4171  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 1.7171  Validation loss = 3.4167  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 1.7169  Validation loss = 3.4162  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 1.7168  Validation loss = 3.4158  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 1.7165  Validation loss = 3.4149  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 1.7163  Validation loss = 3.4143  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 1.7161  Validation loss = 3.4138  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 1.7159  Validation loss = 3.4132  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 1.7156  Validation loss = 3.4118  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 1.7154  Validation loss = 3.4109  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 1.7152  Validation loss = 3.4100  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 1.7150  Validation loss = 3.4091  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 1.7149  Validation loss = 3.4092  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 1.7146  Validation loss = 3.4082  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 1.7144  Validation loss = 3.4073  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 1.7142  Validation loss = 3.4068  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 1.7140  Validation loss = 3.4055  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 1.7138  Validation loss = 3.4050  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 1.7137  Validation loss = 3.4050  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 1.7135  Validation loss = 3.4046  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 1.7133  Validation loss = 3.4041  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 1.7131  Validation loss = 3.4034  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 1.7128  Validation loss = 3.4022  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 1.7126  Validation loss = 3.4016  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 1.7125  Validation loss = 3.4017  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 1.7123  Validation loss = 3.4007  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 1.7122  Validation loss = 3.4003  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 1.7120  Validation loss = 3.3992  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 1.7118  Validation loss = 3.3989  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 1.7116  Validation loss = 3.3986  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 1.7114  Validation loss = 3.3975  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 1.7111  Validation loss = 3.3962  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 1.7110  Validation loss = 3.3959  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 1.7108  Validation loss = 3.3956  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 1.7106  Validation loss = 3.3943  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 1.7104  Validation loss = 3.3937  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 1.7101  Validation loss = 3.3925  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 1.7099  Validation loss = 3.3915  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 1.7096  Validation loss = 3.3900  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 1.7094  Validation loss = 3.3894  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 1.7092  Validation loss = 3.3882  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 1.7089  Validation loss = 3.3869  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 1.7087  Validation loss = 3.3857  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 1.7085  Validation loss = 3.3855  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 1.7083  Validation loss = 3.3846  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 1.7081  Validation loss = 3.3839  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 1.7079  Validation loss = 3.3832  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 1.7076  Validation loss = 3.3819  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 1.7073  Validation loss = 3.3798  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 1.7072  Validation loss = 3.3800  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 1.7071  Validation loss = 3.3798  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 1.7068  Validation loss = 3.3781  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 1.7065  Validation loss = 3.3772  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 1.7064  Validation loss = 3.3773  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 1.7060  Validation loss = 3.3761  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 1.7057  Validation loss = 3.3747  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 1.7054  Validation loss = 3.3735  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 1.7053  Validation loss = 3.3728  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 1.7050  Validation loss = 3.3713  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 1.7048  Validation loss = 3.3714  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 1.7047  Validation loss = 3.3713  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 1.7046  Validation loss = 3.3711  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 1.7044  Validation loss = 3.3703  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 1.7043  Validation loss = 3.3703  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 1.7041  Validation loss = 3.3694  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 1.7040  Validation loss = 3.3696  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 1.7037  Validation loss = 3.3686  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 1.7035  Validation loss = 3.3677  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 1.7033  Validation loss = 3.3671  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 1.7030  Validation loss = 3.3660  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 1.7028  Validation loss = 3.3652  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 1.7025  Validation loss = 3.3636  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 1.7022  Validation loss = 3.3622  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 1.7020  Validation loss = 3.3610  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 1.7018  Validation loss = 3.3605  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 1.7016  Validation loss = 3.3597  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 1.7014  Validation loss = 3.3592  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 1.7011  Validation loss = 3.3582  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 1.7009  Validation loss = 3.3574  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 1.7007  Validation loss = 3.3566  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 1.7006  Validation loss = 3.3567  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 1.7004  Validation loss = 3.3560  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 1.7002  Validation loss = 3.3553  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 1.7000  Validation loss = 3.3544  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 1.6997  Validation loss = 3.3529  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 1.6995  Validation loss = 3.3524  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 1.6993  Validation loss = 3.3512  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 1.6991  Validation loss = 3.3509  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 1.6988  Validation loss = 3.3496  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 1.6987  Validation loss = 3.3489  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 1.6985  Validation loss = 3.3481  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 1.6982  Validation loss = 3.3460  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 1.6979  Validation loss = 3.3449  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 1.6977  Validation loss = 3.3438  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 1.6974  Validation loss = 3.3423  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 1.6972  Validation loss = 3.3415  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 1.6970  Validation loss = 3.3404  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 1.6967  Validation loss = 3.3397  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 1.6965  Validation loss = 3.3386  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 1.6963  Validation loss = 3.3381  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 1.6962  Validation loss = 3.3381  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 1.6959  Validation loss = 3.3364  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 1.6956  Validation loss = 3.3351  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 1.6955  Validation loss = 3.3349  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 1.6953  Validation loss = 3.3352  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 1.6951  Validation loss = 3.3345  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 1.6950  Validation loss = 3.3345  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 1.6947  Validation loss = 3.3330  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 1.6944  Validation loss = 3.3312  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 1.6943  Validation loss = 3.3304  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 1.6940  Validation loss = 3.3291  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 1.6938  Validation loss = 3.3288  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 1.6936  Validation loss = 3.3284  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 1.6935  Validation loss = 3.3284  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 1.6932  Validation loss = 3.3270  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 1.6929  Validation loss = 3.3256  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 1.6928  Validation loss = 3.3248  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 1.6926  Validation loss = 3.3240  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 1.6923  Validation loss = 3.3226  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 1.6922  Validation loss = 3.3225  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 1.6920  Validation loss = 3.3218  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 1.6918  Validation loss = 3.3211  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 1.6917  Validation loss = 3.3213  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 1.6915  Validation loss = 3.3203  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 1.6914  Validation loss = 3.3197  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 1.6910  Validation loss = 3.3174  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 1.6907  Validation loss = 3.3156  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 1.6906  Validation loss = 3.3153  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 1.6904  Validation loss = 3.3144  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 1.6901  Validation loss = 3.3127  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 1.6899  Validation loss = 3.3125  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 1.6898  Validation loss = 3.3120  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 1.6896  Validation loss = 3.3113  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 1.6895  Validation loss = 3.3117  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 1.6892  Validation loss = 3.3098  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 1.6890  Validation loss = 3.3087  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 1.6887  Validation loss = 3.3077  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 1.6886  Validation loss = 3.3076  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 1.6884  Validation loss = 3.3066  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 1.6881  Validation loss = 3.3051  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 1.6879  Validation loss = 3.3046  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 1.6878  Validation loss = 3.3044  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 1.6874  Validation loss = 3.3032  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 1.6873  Validation loss = 3.3030  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 1.6872  Validation loss = 3.3032  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 1.6870  Validation loss = 3.3025  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 1.6869  Validation loss = 3.3025  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 1.6867  Validation loss = 3.3019  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 1.6866  Validation loss = 3.3026  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 1.6863  Validation loss = 3.3012  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 1.6862  Validation loss = 3.3016  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 1.6861  Validation loss = 3.3015  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 1.6859  Validation loss = 3.3008  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 1.6856  Validation loss = 3.2997  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 1.6855  Validation loss = 3.2989  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 1.6852  Validation loss = 3.2976  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 1.6850  Validation loss = 3.2973  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 1.6848  Validation loss = 3.2957  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 1.6845  Validation loss = 3.2944  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 1.6844  Validation loss = 3.2949  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 1.6842  Validation loss = 3.2944  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 1.6839  Validation loss = 3.2929  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 1.6838  Validation loss = 3.2923  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 1.6835  Validation loss = 3.2910  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 1.6832  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 1.6831  Validation loss = 3.2891  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 1.6829  Validation loss = 3.2886  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 1.6827  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 1.6825  Validation loss = 3.2878  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 1.6823  Validation loss = 3.2873  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 1.6821  Validation loss = 3.2867  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 1.6818  Validation loss = 3.2851  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 1.6816  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 1.6814  Validation loss = 3.2842  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 1.6812  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 1.6810  Validation loss = 3.2831  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 1.6808  Validation loss = 3.2825  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 1.6807  Validation loss = 3.2828  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 1.6804  Validation loss = 3.2818  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 1.6803  Validation loss = 3.2822  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 1.6802  Validation loss = 3.2813  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 1.6800  Validation loss = 3.2812  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 1.6798  Validation loss = 3.2799  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 1.6796  Validation loss = 3.2788  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 1.6794  Validation loss = 3.2789  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 1.6793  Validation loss = 3.2781  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 1.6791  Validation loss = 3.2781  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 1.6789  Validation loss = 3.2771  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 1.6787  Validation loss = 3.2761  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 1.6786  Validation loss = 3.2762  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 1.6784  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 1.6781  Validation loss = 3.2735  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 1.6779  Validation loss = 3.2737  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 1.6777  Validation loss = 3.2731  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 1.6775  Validation loss = 3.2723  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 1.6773  Validation loss = 3.2712  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 1.6771  Validation loss = 3.2707  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 1.6768  Validation loss = 3.2691  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 1.6768  Validation loss = 3.2702  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 1.6765  Validation loss = 3.2690  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 1.6763  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 1.6760  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 1.6758  Validation loss = 3.2661  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 1.6755  Validation loss = 3.2642  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 1.6753  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 1.6750  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 1.6750  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 1.6748  Validation loss = 3.2630  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 1.6746  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 1.6744  Validation loss = 3.2610  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 1.6742  Validation loss = 3.2596  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 1.6740  Validation loss = 3.2596  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 1.6738  Validation loss = 3.2592  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 1.6735  Validation loss = 3.2570  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 1.6734  Validation loss = 3.2576  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 1.6731  Validation loss = 3.2560  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 1.6729  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 1.6727  Validation loss = 3.2541  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 1.6725  Validation loss = 3.2535  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 1.6724  Validation loss = 3.2537  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 1.6721  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 1.6719  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 1.6718  Validation loss = 3.2520  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 1.6715  Validation loss = 3.2509  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 1.6713  Validation loss = 3.2504  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 1.6709  Validation loss = 3.2483  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 1.6707  Validation loss = 3.2473  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 1.6706  Validation loss = 3.2474  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 1.6704  Validation loss = 3.2460  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 1.6702  Validation loss = 3.2455  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 1.6701  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 1.6699  Validation loss = 3.2450  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 1.6698  Validation loss = 3.2441  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 1.6695  Validation loss = 3.2434  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 1.6693  Validation loss = 3.2425  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 1.6691  Validation loss = 3.2422  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 1.6689  Validation loss = 3.2413  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 1.6686  Validation loss = 3.2395  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 1.6684  Validation loss = 3.2385  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 1.6682  Validation loss = 3.2373  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 1.6679  Validation loss = 3.2358  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 1.6677  Validation loss = 3.2348  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 1.6675  Validation loss = 3.2344  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 1.6674  Validation loss = 3.2344  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 1.6672  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 1.6669  Validation loss = 3.2330  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 1.6667  Validation loss = 3.2326  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 1.6666  Validation loss = 3.2323  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 1.6664  Validation loss = 3.2317  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 1.6662  Validation loss = 3.2309  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 1.6659  Validation loss = 3.2299  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 1.6657  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 1.6655  Validation loss = 3.2279  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 1.6653  Validation loss = 3.2272  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 1.6651  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 1.6649  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 1.6647  Validation loss = 3.2238  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 1.6644  Validation loss = 3.2220  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 1.6643  Validation loss = 3.2210  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 1.6641  Validation loss = 3.2206  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 1.6639  Validation loss = 3.2198  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 1.6637  Validation loss = 3.2187  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 1.6635  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 1.6633  Validation loss = 3.2175  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 1.6630  Validation loss = 3.2167  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 1.6629  Validation loss = 3.2156  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 1.6626  Validation loss = 3.2146  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 1.6623  Validation loss = 3.2129  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 1.6622  Validation loss = 3.2115  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 1.6620  Validation loss = 3.2116  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 1.6618  Validation loss = 3.2112  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 1.6616  Validation loss = 3.2111  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 1.6614  Validation loss = 3.2105  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 1.6613  Validation loss = 3.2100  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 1.6611  Validation loss = 3.2098  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 1.6609  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 1.6608  Validation loss = 3.2091  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 1.6606  Validation loss = 3.2074  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 1.6604  Validation loss = 3.2073  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 1.6602  Validation loss = 3.2058  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 1.6600  Validation loss = 3.2044  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 1.6598  Validation loss = 3.2034  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 1.6595  Validation loss = 3.2024  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 1.6593  Validation loss = 3.2016  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 1.6591  Validation loss = 3.2005  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.7881  Validation loss = 1.1245  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.7876  Validation loss = 1.1232  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.7871  Validation loss = 1.1219  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.7861  Validation loss = 1.1190  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.7855  Validation loss = 1.1173  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.7848  Validation loss = 1.1155  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.7840  Validation loss = 1.1133  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.7836  Validation loss = 1.1126  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.7827  Validation loss = 1.1098  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.7823  Validation loss = 1.1090  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.7818  Validation loss = 1.1075  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.7809  Validation loss = 1.1047  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.7805  Validation loss = 1.1039  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.7801  Validation loss = 1.1034  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 1.7795  Validation loss = 1.1020  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 1.7791  Validation loss = 1.1009  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 1.7786  Validation loss = 1.0997  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 1.7780  Validation loss = 1.0978  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 1.7775  Validation loss = 1.0964  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 1.7768  Validation loss = 1.0942  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 1.7762  Validation loss = 1.0925  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 1.7755  Validation loss = 1.0908  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 1.7749  Validation loss = 1.0893  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 1.7742  Validation loss = 1.0875  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 1.7739  Validation loss = 1.0869  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 1.7734  Validation loss = 1.0858  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 1.7729  Validation loss = 1.0841  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 1.7724  Validation loss = 1.0832  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 1.7719  Validation loss = 1.0822  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 1.7712  Validation loss = 1.0804  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 1.7706  Validation loss = 1.0792  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 1.7699  Validation loss = 1.0776  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 1.7694  Validation loss = 1.0765  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 1.7688  Validation loss = 1.0751  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 1.7685  Validation loss = 1.0748  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 1.7679  Validation loss = 1.0733  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 1.7671  Validation loss = 1.0714  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 1.7664  Validation loss = 1.0690  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 1.7659  Validation loss = 1.0678  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 1.7654  Validation loss = 1.0672  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 1.7649  Validation loss = 1.0657  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 1.7645  Validation loss = 1.0649  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 1.7640  Validation loss = 1.0639  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 1.7635  Validation loss = 1.0631  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 1.7629  Validation loss = 1.0619  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 1.7624  Validation loss = 1.0605  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 1.7621  Validation loss = 1.0601  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 1.7615  Validation loss = 1.0586  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 1.7606  Validation loss = 1.0557  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 1.7599  Validation loss = 1.0541  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 1.7595  Validation loss = 1.0531  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 1.7589  Validation loss = 1.0514  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 1.7584  Validation loss = 1.0502  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 1.7580  Validation loss = 1.0493  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 1.7576  Validation loss = 1.0486  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 1.7573  Validation loss = 1.0482  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 1.7570  Validation loss = 1.0476  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 1.7563  Validation loss = 1.0460  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 1.7557  Validation loss = 1.0441  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 1.7551  Validation loss = 1.0431  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 1.7545  Validation loss = 1.0408  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 1.7540  Validation loss = 1.0397  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 1.7535  Validation loss = 1.0385  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 1.7529  Validation loss = 1.0372  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 1.7524  Validation loss = 1.0361  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 1.7519  Validation loss = 1.0351  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 1.7514  Validation loss = 1.0341  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 1.7508  Validation loss = 1.0324  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 1.7502  Validation loss = 1.0307  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 1.7497  Validation loss = 1.0295  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 1.7491  Validation loss = 1.0278  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 1.7486  Validation loss = 1.0264  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 1.7482  Validation loss = 1.0259  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 1.7478  Validation loss = 1.0252  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 1.7473  Validation loss = 1.0231  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 1.7466  Validation loss = 1.0211  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 1.7460  Validation loss = 1.0198  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 1.7454  Validation loss = 1.0183  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 1.7450  Validation loss = 1.0170  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 1.7444  Validation loss = 1.0160  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 1.7440  Validation loss = 1.0156  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 1.7435  Validation loss = 1.0147  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 1.7432  Validation loss = 1.0145  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 1.7429  Validation loss = 1.0139  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 1.7426  Validation loss = 1.0138  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 1.7423  Validation loss = 1.0137  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 1.7415  Validation loss = 1.0114  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 1.7411  Validation loss = 1.0107  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 1.7406  Validation loss = 1.0100  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 1.7402  Validation loss = 1.0090  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 1.7395  Validation loss = 1.0065  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 1.7390  Validation loss = 1.0058  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 1.7383  Validation loss = 1.0039  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 1.7378  Validation loss = 1.0027  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 1.7374  Validation loss = 1.0023  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 1.7369  Validation loss = 1.0007  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 1.7364  Validation loss = 0.9994  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 1.7360  Validation loss = 0.9984  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 1.7355  Validation loss = 0.9974  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 1.7348  Validation loss = 0.9952  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 1.7344  Validation loss = 0.9943  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 1.7339  Validation loss = 0.9936  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 1.7335  Validation loss = 0.9925  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 1.7331  Validation loss = 0.9918  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 1.7327  Validation loss = 0.9910  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 1.7322  Validation loss = 0.9900  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 1.7316  Validation loss = 0.9890  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 1.7312  Validation loss = 0.9884  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 1.7309  Validation loss = 0.9879  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 1.7303  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 1.7301  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 1.7298  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 1.7293  Validation loss = 0.9849  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 1.7290  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 1.7285  Validation loss = 0.9831  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 1.7279  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 1.7275  Validation loss = 0.9805  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 1.7270  Validation loss = 0.9793  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 1.7263  Validation loss = 0.9770  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 1.7259  Validation loss = 0.9763  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 1.7255  Validation loss = 0.9756  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 1.7248  Validation loss = 0.9739  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 1.7242  Validation loss = 0.9719  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 1.7238  Validation loss = 0.9714  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 1.7232  Validation loss = 0.9699  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 1.7229  Validation loss = 0.9698  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 1.7224  Validation loss = 0.9687  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 1.7218  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 1.7215  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 1.7210  Validation loss = 0.9655  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 1.7206  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 1.7201  Validation loss = 0.9637  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 1.7195  Validation loss = 0.9625  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 1.7192  Validation loss = 0.9618  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 1.7188  Validation loss = 0.9610  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 1.7183  Validation loss = 0.9599  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 1.7179  Validation loss = 0.9594  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 1.7174  Validation loss = 0.9587  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 1.7167  Validation loss = 0.9571  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 1.7161  Validation loss = 0.9555  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 1.7155  Validation loss = 0.9536  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 1.7152  Validation loss = 0.9534  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 1.7147  Validation loss = 0.9522  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 1.7142  Validation loss = 0.9504  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 1.7138  Validation loss = 0.9496  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 1.7133  Validation loss = 0.9488  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 1.7128  Validation loss = 0.9476  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 1.7123  Validation loss = 0.9463  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 1.7119  Validation loss = 0.9455  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 1.7112  Validation loss = 0.9438  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 1.7108  Validation loss = 0.9429  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 1.7105  Validation loss = 0.9421  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 1.7100  Validation loss = 0.9408  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 1.7097  Validation loss = 0.9402  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 1.7093  Validation loss = 0.9397  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 1.7089  Validation loss = 0.9389  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 1.7084  Validation loss = 0.9380  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 1.7079  Validation loss = 0.9364  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 1.7073  Validation loss = 0.9350  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 1.7070  Validation loss = 0.9346  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 1.7065  Validation loss = 0.9334  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 1.7059  Validation loss = 0.9313  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 1.7054  Validation loss = 0.9297  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 1.7049  Validation loss = 0.9289  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 1.7044  Validation loss = 0.9279  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 1.7038  Validation loss = 0.9259  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 1.7032  Validation loss = 0.9247  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 1.7028  Validation loss = 0.9239  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 1.7023  Validation loss = 0.9232  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 1.7020  Validation loss = 0.9228  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 1.7017  Validation loss = 0.9225  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 1.7013  Validation loss = 0.9216  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 1.7009  Validation loss = 0.9207  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 1.7004  Validation loss = 0.9197  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 1.6998  Validation loss = 0.9183  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 1.6994  Validation loss = 0.9180  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 1.6990  Validation loss = 0.9173  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 1.6987  Validation loss = 0.9167  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 1.6983  Validation loss = 0.9163  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 1.6976  Validation loss = 0.9143  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 1.6971  Validation loss = 0.9133  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 1.6966  Validation loss = 0.9123  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 1.6962  Validation loss = 0.9115  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 1.6960  Validation loss = 0.9114  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 1.6957  Validation loss = 0.9111  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 1.6952  Validation loss = 0.9103  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 1.6947  Validation loss = 0.9091  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 1.6944  Validation loss = 0.9083  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 1.6938  Validation loss = 0.9068  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 1.6935  Validation loss = 0.9065  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 1.6930  Validation loss = 0.9052  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 1.6925  Validation loss = 0.9039  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 1.6921  Validation loss = 0.9036  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 1.6917  Validation loss = 0.9027  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 1.6913  Validation loss = 0.9022  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 1.6911  Validation loss = 0.9017  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 1.6907  Validation loss = 0.9006  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 1.6903  Validation loss = 0.8994  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 1.6898  Validation loss = 0.8981  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 1.6893  Validation loss = 0.8970  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 1.6886  Validation loss = 0.8951  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 1.6883  Validation loss = 0.8952  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 1.6880  Validation loss = 0.8946  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 1.6876  Validation loss = 0.8933  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 1.6871  Validation loss = 0.8919  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 1.6868  Validation loss = 0.8920  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 1.6865  Validation loss = 0.8915  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 1.6862  Validation loss = 0.8913  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 1.6859  Validation loss = 0.8909  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 1.6856  Validation loss = 0.8908  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 1.6852  Validation loss = 0.8899  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 1.6847  Validation loss = 0.8889  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 1.6841  Validation loss = 0.8873  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 1.6838  Validation loss = 0.8866  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 1.6834  Validation loss = 0.8862  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 1.6832  Validation loss = 0.8861  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 1.6829  Validation loss = 0.8853  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 1.6825  Validation loss = 0.8845  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 1.6820  Validation loss = 0.8837  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 1.6815  Validation loss = 0.8826  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 1.6810  Validation loss = 0.8816  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 1.6805  Validation loss = 0.8805  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 1.6802  Validation loss = 0.8801  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 1.6801  Validation loss = 0.8801  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 1.6796  Validation loss = 0.8789  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 1.6791  Validation loss = 0.8776  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 1.6786  Validation loss = 0.8763  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 1.6782  Validation loss = 0.8754  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 1.6777  Validation loss = 0.8745  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 1.6772  Validation loss = 0.8737  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 1.6768  Validation loss = 0.8728  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 1.6763  Validation loss = 0.8716  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 1.6761  Validation loss = 0.8714  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 1.6757  Validation loss = 0.8710  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 1.6754  Validation loss = 0.8705  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 1.6749  Validation loss = 0.8695  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 1.6746  Validation loss = 0.8695  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 1.6741  Validation loss = 0.8682  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 1.6736  Validation loss = 0.8674  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 1.6733  Validation loss = 0.8670  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 1.6730  Validation loss = 0.8664  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 1.6728  Validation loss = 0.8664  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 1.6722  Validation loss = 0.8651  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 1.6717  Validation loss = 0.8644  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 1.6712  Validation loss = 0.8630  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 1.6708  Validation loss = 0.8618  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 1.6704  Validation loss = 0.8614  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 1.6698  Validation loss = 0.8602  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 1.6692  Validation loss = 0.8587  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 1.6688  Validation loss = 0.8579  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 1.6684  Validation loss = 0.8577  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 1.6679  Validation loss = 0.8566  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 1.6675  Validation loss = 0.8556  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 1.6673  Validation loss = 0.8558  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 1.6669  Validation loss = 0.8557  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 1.6666  Validation loss = 0.8553  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 1.6663  Validation loss = 0.8549  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 1.6657  Validation loss = 0.8533  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 1.6651  Validation loss = 0.8517  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 1.6648  Validation loss = 0.8514  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 1.6645  Validation loss = 0.8510  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 1.6641  Validation loss = 0.8503  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 1.6636  Validation loss = 0.8492  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 1.6630  Validation loss = 0.8474  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 1.6626  Validation loss = 0.8469  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 1.6622  Validation loss = 0.8459  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 1.6617  Validation loss = 0.8452  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 1.6611  Validation loss = 0.8437  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 1.6606  Validation loss = 0.8426  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 1.6603  Validation loss = 0.8420  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 1.6598  Validation loss = 0.8411  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 1.6595  Validation loss = 0.8406  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 1.6590  Validation loss = 0.8399  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 1.6586  Validation loss = 0.8389  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 1.6582  Validation loss = 0.8383  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 1.6577  Validation loss = 0.8369  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 1.6573  Validation loss = 0.8364  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 1.6569  Validation loss = 0.8361  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 1.6564  Validation loss = 0.8349  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 1.6562  Validation loss = 0.8348  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 1.6559  Validation loss = 0.8348  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 1.6556  Validation loss = 0.8344  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 1.6551  Validation loss = 0.8332  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 1.6548  Validation loss = 0.8331  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 1.6544  Validation loss = 0.8323  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 1.6541  Validation loss = 0.8325  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 1.6537  Validation loss = 0.8317  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 1.6533  Validation loss = 0.8306  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 1.6529  Validation loss = 0.8296  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 1.6525  Validation loss = 0.8287  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 1.6521  Validation loss = 0.8275  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 1.6518  Validation loss = 0.8269  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 1.6515  Validation loss = 0.8263  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 1.6510  Validation loss = 0.8255  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 1.6507  Validation loss = 0.8257  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 1.6504  Validation loss = 0.8254  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 1.6499  Validation loss = 0.8241  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 1.6496  Validation loss = 0.8233  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 1.6491  Validation loss = 0.8222  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 1.6486  Validation loss = 0.8209  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 1.6481  Validation loss = 0.8199  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 1.6477  Validation loss = 0.8191  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 1.6474  Validation loss = 0.8183  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 1.6468  Validation loss = 0.8169  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 1.6463  Validation loss = 0.8158  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 1.6459  Validation loss = 0.8146  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 1.6456  Validation loss = 0.8146  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 1.6453  Validation loss = 0.8143  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 1.6449  Validation loss = 0.8132  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 1.6446  Validation loss = 0.8130  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 1.6443  Validation loss = 0.8130  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 1.6439  Validation loss = 0.8122  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 1.6435  Validation loss = 0.8114  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 1.6432  Validation loss = 0.8112  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 1.6428  Validation loss = 0.8104  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 1.6425  Validation loss = 0.8095  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 1.6420  Validation loss = 0.8088  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 1.6416  Validation loss = 0.8079  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 1.6411  Validation loss = 0.8070  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 1.6407  Validation loss = 0.8061  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 1.6404  Validation loss = 0.8054  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 1.6400  Validation loss = 0.8047  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 1.6397  Validation loss = 0.8044  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 1.6394  Validation loss = 0.8045  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 1.6389  Validation loss = 0.8034  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 1.6385  Validation loss = 0.8028  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 1.6380  Validation loss = 0.8022  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 1.6376  Validation loss = 0.8020  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 1.6374  Validation loss = 0.8017  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 1.6371  Validation loss = 0.8019  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 1.6366  Validation loss = 0.8004  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 1.6362  Validation loss = 0.7999  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 1.6360  Validation loss = 0.8002  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 1.6355  Validation loss = 0.7994  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 1.6350  Validation loss = 0.7984  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 1.6348  Validation loss = 0.7987  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 1.6345  Validation loss = 0.7981  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 1.6341  Validation loss = 0.7977  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 1.6337  Validation loss = 0.7970  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 1.6335  Validation loss = 0.7965  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 1.6331  Validation loss = 0.7958  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 1.6329  Validation loss = 0.7954  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 1.6326  Validation loss = 0.7946  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 1.6322  Validation loss = 0.7944  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 1.6319  Validation loss = 0.7945  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 1.6316  Validation loss = 0.7942  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 1.6312  Validation loss = 0.7938  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 1.6309  Validation loss = 0.7932  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 1.6307  Validation loss = 0.7932  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 1.6304  Validation loss = 0.7929  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 1.6301  Validation loss = 0.7926  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 1.6298  Validation loss = 0.7924  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 1.6292  Validation loss = 0.7912  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 1.6289  Validation loss = 0.7904  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 1.6286  Validation loss = 0.7895  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 1.6281  Validation loss = 0.7887  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 1.6278  Validation loss = 0.7892  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 1.6273  Validation loss = 0.7879  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 1.6270  Validation loss = 0.7879  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 1.6265  Validation loss = 0.7864  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 1.6262  Validation loss = 0.7868  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 1.6256  Validation loss = 0.7857  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 1.6254  Validation loss = 0.7861  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 1.6248  Validation loss = 0.7850  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 1.6245  Validation loss = 0.7846  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 1.6242  Validation loss = 0.7838  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 1.6236  Validation loss = 0.7826  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 1.6233  Validation loss = 0.7820  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 1.6229  Validation loss = 0.7811  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 1.6224  Validation loss = 0.7802  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 1.6221  Validation loss = 0.7799  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 1.6216  Validation loss = 0.7786  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 1.6213  Validation loss = 0.7782  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 1.6206  Validation loss = 0.7769  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 1.6203  Validation loss = 0.7765  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 1.6199  Validation loss = 0.7762  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 1.6196  Validation loss = 0.7755  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 1.6193  Validation loss = 0.7752  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 1.6189  Validation loss = 0.7745  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 1.6185  Validation loss = 0.7740  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 1.6182  Validation loss = 0.7729  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 1.6175  Validation loss = 0.7713  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 1.6172  Validation loss = 0.7714  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 1.6169  Validation loss = 0.7709  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 1.6163  Validation loss = 0.7701  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 1.6159  Validation loss = 0.7692  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 1.6156  Validation loss = 0.7689  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 1.6153  Validation loss = 0.7689  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 1.6151  Validation loss = 0.7690  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 1.6147  Validation loss = 0.7681  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 1.6144  Validation loss = 0.7677  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 1.6139  Validation loss = 0.7670  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 1.6135  Validation loss = 0.7661  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 1.6131  Validation loss = 0.7658  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 1.6127  Validation loss = 0.7651  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 1.6123  Validation loss = 0.7648  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 1.6119  Validation loss = 0.7639  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 1.6115  Validation loss = 0.7636  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 1.6110  Validation loss = 0.7626  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 1.6105  Validation loss = 0.7617  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 1.6101  Validation loss = 0.7611  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 1.6098  Validation loss = 0.7613  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 1.6096  Validation loss = 0.7611  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 1.6093  Validation loss = 0.7609  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 1.6090  Validation loss = 0.7608  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 1.6085  Validation loss = 0.7601  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 1.6081  Validation loss = 0.7597  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 1.6077  Validation loss = 0.7589  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 1.6072  Validation loss = 0.7582  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 1.6068  Validation loss = 0.7575  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 1.6063  Validation loss = 0.7568  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 1.6060  Validation loss = 0.7563  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 1.6056  Validation loss = 0.7555  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 1.6052  Validation loss = 0.7547  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 1.6050  Validation loss = 0.7551  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 1.6046  Validation loss = 0.7547  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 1.6042  Validation loss = 0.7536  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 1.6038  Validation loss = 0.7531  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 1.6035  Validation loss = 0.7527  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 1.6031  Validation loss = 0.7526  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 1.6028  Validation loss = 0.7518  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 1.6025  Validation loss = 0.7513  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 1.6020  Validation loss = 0.7507  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 1.6018  Validation loss = 0.7509  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 1.6015  Validation loss = 0.7502  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 1.6011  Validation loss = 0.7495  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 1.6007  Validation loss = 0.7493  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 1.6004  Validation loss = 0.7489  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 1.6000  Validation loss = 0.7486  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 1.5998  Validation loss = 0.7488  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 1.5996  Validation loss = 0.7492  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 1.5993  Validation loss = 0.7492  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 1.5988  Validation loss = 0.7487  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 1.5985  Validation loss = 0.7481  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 1.5981  Validation loss = 0.7475  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 1.5977  Validation loss = 0.7473  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 1.5973  Validation loss = 0.7466  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 1.5970  Validation loss = 0.7464  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 1.5964  Validation loss = 0.7447  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 1.5960  Validation loss = 0.7443  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 1.5956  Validation loss = 0.7439  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 1.5954  Validation loss = 0.7438  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 1.5950  Validation loss = 0.7433  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 1.5947  Validation loss = 0.7425  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 1.5945  Validation loss = 0.7430  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 1.5942  Validation loss = 0.7429  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 1.5939  Validation loss = 0.7425  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 1.5935  Validation loss = 0.7416  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 1.5930  Validation loss = 0.7409  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 1.5925  Validation loss = 0.7401  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 1.5921  Validation loss = 0.7394  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 1.5918  Validation loss = 0.7393  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 1.5916  Validation loss = 0.7395  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 1.5913  Validation loss = 0.7393  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 1.5909  Validation loss = 0.7387  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 1.5907  Validation loss = 0.7385  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 1.5902  Validation loss = 0.7377  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 1.5899  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 1.5895  Validation loss = 0.7365  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 1.5890  Validation loss = 0.7360  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 1.5884  Validation loss = 0.7351  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 1.5882  Validation loss = 0.7351  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 1.5878  Validation loss = 0.7342  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 1.5874  Validation loss = 0.7332  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 1.5869  Validation loss = 0.7321  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 1.5865  Validation loss = 0.7316  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 1.5861  Validation loss = 0.7306  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 1.5857  Validation loss = 0.7299  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 1.5854  Validation loss = 0.7292  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 1.5852  Validation loss = 0.7289  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 1.5848  Validation loss = 0.7287  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 1.5846  Validation loss = 0.7286  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 1.5843  Validation loss = 0.7281  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 1.5840  Validation loss = 0.7282  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 1.5836  Validation loss = 0.7272  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 1.5831  Validation loss = 0.7262  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 1.5827  Validation loss = 0.7258  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 1.5825  Validation loss = 0.7252  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 1.5822  Validation loss = 0.7248  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 1.5818  Validation loss = 0.7238  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 1.5815  Validation loss = 0.7238  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 1.5811  Validation loss = 0.7235  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 1.5809  Validation loss = 0.7236  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 1.5806  Validation loss = 0.7227  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 1.5803  Validation loss = 0.7225  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 1.5799  Validation loss = 0.7217  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 1.5795  Validation loss = 0.7210  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 1.5792  Validation loss = 0.7203  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 1.5788  Validation loss = 0.7197  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 1.5785  Validation loss = 0.7196  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 1.5782  Validation loss = 0.7194  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 1.5778  Validation loss = 0.7184  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 1.5772  Validation loss = 0.7177  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 1.5769  Validation loss = 0.7174  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 1.5765  Validation loss = 0.7166  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 1.5762  Validation loss = 0.7161  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 1.5759  Validation loss = 0.7153  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 1.5754  Validation loss = 0.7149  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 1.5749  Validation loss = 0.7143  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 1.5745  Validation loss = 0.7135  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.5177  Validation loss = 0.8473  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.5174  Validation loss = 0.8470  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.5169  Validation loss = 0.8460  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.5166  Validation loss = 0.8455  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.5163  Validation loss = 0.8456  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.5158  Validation loss = 0.8447  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.5156  Validation loss = 0.8445  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.5153  Validation loss = 0.8449  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.5149  Validation loss = 0.8444  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.5145  Validation loss = 0.8444  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.5141  Validation loss = 0.8437  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.5139  Validation loss = 0.8439  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.5133  Validation loss = 0.8433  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.5128  Validation loss = 0.8430  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.5125  Validation loss = 0.8431  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.5120  Validation loss = 0.8424  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.5118  Validation loss = 0.8428  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.5115  Validation loss = 0.8424  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.5111  Validation loss = 0.8419  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.5106  Validation loss = 0.8413  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.5101  Validation loss = 0.8416  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.5097  Validation loss = 0.8407  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 1.5091  Validation loss = 0.8399  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 1.5088  Validation loss = 0.8401  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 1.5086  Validation loss = 0.8398  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 1.5083  Validation loss = 0.8394  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 1.5078  Validation loss = 0.8379  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 1.5074  Validation loss = 0.8380  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 1.5070  Validation loss = 0.8370  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 1.5067  Validation loss = 0.8365  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 1.5064  Validation loss = 0.8367  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 1.5060  Validation loss = 0.8360  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 1.5057  Validation loss = 0.8357  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 1.5053  Validation loss = 0.8343  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 1.5051  Validation loss = 0.8347  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 1.5045  Validation loss = 0.8338  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 1.5041  Validation loss = 0.8333  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 1.5036  Validation loss = 0.8330  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 1.5034  Validation loss = 0.8330  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 1.5032  Validation loss = 0.8328  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 1.5028  Validation loss = 0.8328  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 1.5023  Validation loss = 0.8323  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 1.5018  Validation loss = 0.8319  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 1.5015  Validation loss = 0.8316  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 1.5012  Validation loss = 0.8314  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 1.5009  Validation loss = 0.8313  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 1.5005  Validation loss = 0.8310  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 1.5003  Validation loss = 0.8315  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 1.4999  Validation loss = 0.8311  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 1.4995  Validation loss = 0.8309  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 1.4993  Validation loss = 0.8314  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 1.4989  Validation loss = 0.8310  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 1.4985  Validation loss = 0.8306  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 1.4983  Validation loss = 0.8315  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 1.4980  Validation loss = 0.8309  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 1.4978  Validation loss = 0.8312  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 1.4974  Validation loss = 0.8304  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 1.4970  Validation loss = 0.8304  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 1.4964  Validation loss = 0.8291  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 1.4960  Validation loss = 0.8287  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 1.4956  Validation loss = 0.8279  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 1.4953  Validation loss = 0.8282  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 1.4950  Validation loss = 0.8281  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 1.4947  Validation loss = 0.8276  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 1.4944  Validation loss = 0.8277  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 1.4940  Validation loss = 0.8279  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 1.4938  Validation loss = 0.8275  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 1.4932  Validation loss = 0.8266  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 1.4929  Validation loss = 0.8268  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 1.4925  Validation loss = 0.8264  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 1.4921  Validation loss = 0.8259  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 1.4917  Validation loss = 0.8254  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 1.4912  Validation loss = 0.8239  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 1.4907  Validation loss = 0.8230  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 1.4904  Validation loss = 0.8224  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 1.4900  Validation loss = 0.8227  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 1.4897  Validation loss = 0.8229  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 1.4894  Validation loss = 0.8229  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 1.4891  Validation loss = 0.8225  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 1.4886  Validation loss = 0.8218  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 1.4882  Validation loss = 0.8211  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 1.4879  Validation loss = 0.8211  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 1.4877  Validation loss = 0.8210  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 1.4875  Validation loss = 0.8212  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 1.4873  Validation loss = 0.8213  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 1.4870  Validation loss = 0.8212  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 1.4866  Validation loss = 0.8210  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 1.4864  Validation loss = 0.8212  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 1.4860  Validation loss = 0.8213  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 1.4858  Validation loss = 0.8214  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 83  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.4397  Validation loss = 5.5514  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.4394  Validation loss = 5.5506  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.4391  Validation loss = 5.5502  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.4387  Validation loss = 5.5483  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.4384  Validation loss = 5.5486  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.4381  Validation loss = 5.5476  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.4377  Validation loss = 5.5454  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.4374  Validation loss = 5.5447  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.4370  Validation loss = 5.5440  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.4367  Validation loss = 5.5439  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.4363  Validation loss = 5.5431  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.4359  Validation loss = 5.5415  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.4356  Validation loss = 5.5405  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.4352  Validation loss = 5.5392  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.4349  Validation loss = 5.5390  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.4344  Validation loss = 5.5378  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.4340  Validation loss = 5.5368  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.4338  Validation loss = 5.5358  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.4335  Validation loss = 5.5360  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 1.4331  Validation loss = 5.5351  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 1.4327  Validation loss = 5.5335  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 1.4323  Validation loss = 5.5324  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 1.4321  Validation loss = 5.5318  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 1.4317  Validation loss = 5.5307  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 1.4314  Validation loss = 5.5299  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 1.4312  Validation loss = 5.5302  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 1.4311  Validation loss = 5.5297  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 1.4308  Validation loss = 5.5281  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 1.4306  Validation loss = 5.5279  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 1.4302  Validation loss = 5.5267  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 1.4299  Validation loss = 5.5256  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 1.4295  Validation loss = 5.5248  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 1.4293  Validation loss = 5.5246  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 1.4289  Validation loss = 5.5232  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 1.4285  Validation loss = 5.5227  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 1.4282  Validation loss = 5.5220  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 1.4279  Validation loss = 5.5210  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 1.4275  Validation loss = 5.5191  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 1.4272  Validation loss = 5.5186  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 1.4267  Validation loss = 5.5175  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 1.4263  Validation loss = 5.5162  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 1.4259  Validation loss = 5.5155  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 1.4255  Validation loss = 5.5143  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 1.4252  Validation loss = 5.5128  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 1.4250  Validation loss = 5.5127  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 1.4246  Validation loss = 5.5122  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 1.4244  Validation loss = 5.5118  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 1.4240  Validation loss = 5.5109  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 1.4237  Validation loss = 5.5101  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 1.4235  Validation loss = 5.5090  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 1.4232  Validation loss = 5.5080  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 1.4229  Validation loss = 5.5080  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 1.4225  Validation loss = 5.5073  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 1.4223  Validation loss = 5.5075  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 1.4220  Validation loss = 5.5080  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 1.4217  Validation loss = 5.5064  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 1.4214  Validation loss = 5.5055  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 1.4213  Validation loss = 5.5063  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 1.4210  Validation loss = 5.5057  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 1.4207  Validation loss = 5.5044  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 1.4204  Validation loss = 5.5034  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 1.4200  Validation loss = 5.5023  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 1.4197  Validation loss = 5.5017  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 1.4194  Validation loss = 5.5007  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 1.4190  Validation loss = 5.4991  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 1.4188  Validation loss = 5.4981  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 1.4184  Validation loss = 5.4966  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 1.4181  Validation loss = 5.4958  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 1.4178  Validation loss = 5.4953  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 1.4175  Validation loss = 5.4943  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 1.4173  Validation loss = 5.4929  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 1.4169  Validation loss = 5.4921  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 1.4166  Validation loss = 5.4908  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 1.4163  Validation loss = 5.4901  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 1.4162  Validation loss = 5.4911  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 1.4159  Validation loss = 5.4913  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 1.4157  Validation loss = 5.4903  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 1.4155  Validation loss = 5.4897  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 1.4151  Validation loss = 5.4885  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 1.4148  Validation loss = 5.4888  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 1.4145  Validation loss = 5.4868  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 1.4143  Validation loss = 5.4869  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 1.4141  Validation loss = 5.4867  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 1.4139  Validation loss = 5.4864  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 1.4135  Validation loss = 5.4859  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 1.4132  Validation loss = 5.4845  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 1.4129  Validation loss = 5.4832  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 1.4124  Validation loss = 5.4816  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 1.4122  Validation loss = 5.4814  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 1.4119  Validation loss = 5.4805  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 1.4115  Validation loss = 5.4797  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 1.4111  Validation loss = 5.4782  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 1.4109  Validation loss = 5.4781  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 1.4107  Validation loss = 5.4796  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 1.4104  Validation loss = 5.4787  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 1.4101  Validation loss = 5.4786  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 1.4099  Validation loss = 5.4781  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 1.4097  Validation loss = 5.4773  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 1.4093  Validation loss = 5.4760  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 1.4091  Validation loss = 5.4762  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 1.4088  Validation loss = 5.4762  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 1.4086  Validation loss = 5.4757  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 1.4083  Validation loss = 5.4750  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 1.4080  Validation loss = 5.4735  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 1.4077  Validation loss = 5.4721  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 1.4075  Validation loss = 5.4707  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 1.4072  Validation loss = 5.4702  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 1.4069  Validation loss = 5.4691  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 1.4066  Validation loss = 5.4683  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 1.4063  Validation loss = 5.4672  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 1.4060  Validation loss = 5.4663  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 1.4057  Validation loss = 5.4662  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 1.4055  Validation loss = 5.4660  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 1.4054  Validation loss = 5.4660  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 1.4052  Validation loss = 5.4650  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 1.4049  Validation loss = 5.4638  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 1.4045  Validation loss = 5.4623  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 1.4041  Validation loss = 5.4615  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 1.4038  Validation loss = 5.4609  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 1.4036  Validation loss = 5.4603  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 1.4033  Validation loss = 5.4590  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 1.4031  Validation loss = 5.4592  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 1.4028  Validation loss = 5.4588  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 1.4026  Validation loss = 5.4589  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 1.4022  Validation loss = 5.4578  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 1.4019  Validation loss = 5.4572  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 1.4016  Validation loss = 5.4569  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 1.4015  Validation loss = 5.4575  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 1.4011  Validation loss = 5.4561  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 1.4008  Validation loss = 5.4553  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 1.4006  Validation loss = 5.4545  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 1.4002  Validation loss = 5.4539  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 1.3999  Validation loss = 5.4535  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 1.3996  Validation loss = 5.4529  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 1.3993  Validation loss = 5.4532  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 1.3990  Validation loss = 5.4527  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 1.3987  Validation loss = 5.4519  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 1.3986  Validation loss = 5.4532  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 1.3982  Validation loss = 5.4526  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 1.3978  Validation loss = 5.4513  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 1.3976  Validation loss = 5.4519  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 1.3973  Validation loss = 5.4512  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 1.3971  Validation loss = 5.4505  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 1.3967  Validation loss = 5.4484  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 1.3963  Validation loss = 5.4467  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 1.3960  Validation loss = 5.4465  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 1.3958  Validation loss = 5.4459  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 1.3955  Validation loss = 5.4454  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 1.3952  Validation loss = 5.4438  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 1.3949  Validation loss = 5.4426  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 1.3946  Validation loss = 5.4423  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 1.3942  Validation loss = 5.4411  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 1.3939  Validation loss = 5.4401  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 1.3935  Validation loss = 5.4383  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 1.3932  Validation loss = 5.4387  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 1.3929  Validation loss = 5.4379  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 1.3926  Validation loss = 5.4370  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 1.3923  Validation loss = 5.4364  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 1.3920  Validation loss = 5.4358  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 1.3917  Validation loss = 5.4344  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 1.3915  Validation loss = 5.4343  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 1.3913  Validation loss = 5.4337  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 1.3909  Validation loss = 5.4319  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 1.3907  Validation loss = 5.4310  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 1.3903  Validation loss = 5.4295  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 1.3899  Validation loss = 5.4293  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 1.3897  Validation loss = 5.4288  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 1.3895  Validation loss = 5.4293  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 1.3893  Validation loss = 5.4298  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 1.3890  Validation loss = 5.4296  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 1.3887  Validation loss = 5.4298  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 1.3885  Validation loss = 5.4289  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 1.3882  Validation loss = 5.4284  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 1.3878  Validation loss = 5.4286  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 1.3874  Validation loss = 5.4270  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 1.3872  Validation loss = 5.4272  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 1.3869  Validation loss = 5.4264  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 1.3866  Validation loss = 5.4254  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 1.3864  Validation loss = 5.4242  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 1.3861  Validation loss = 5.4246  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 1.3858  Validation loss = 5.4245  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 1.3856  Validation loss = 5.4236  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 1.3853  Validation loss = 5.4225  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 1.3849  Validation loss = 5.4221  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 1.3846  Validation loss = 5.4210  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 1.3843  Validation loss = 5.4203  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 1.3843  Validation loss = 5.4209  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 1.3840  Validation loss = 5.4204  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 1.3837  Validation loss = 5.4192  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 1.3834  Validation loss = 5.4191  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 1.3832  Validation loss = 5.4188  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 1.3830  Validation loss = 5.4183  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 1.3826  Validation loss = 5.4183  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 1.3822  Validation loss = 5.4172  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 1.3819  Validation loss = 5.4166  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 1.3818  Validation loss = 5.4171  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 1.3815  Validation loss = 5.4171  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 1.3813  Validation loss = 5.4165  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 1.3810  Validation loss = 5.4156  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 1.3809  Validation loss = 5.4161  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 1.3808  Validation loss = 5.4164  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 1.3804  Validation loss = 5.4162  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 1.3801  Validation loss = 5.4156  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 1.3797  Validation loss = 5.4145  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 1.3795  Validation loss = 5.4147  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 1.3791  Validation loss = 5.4133  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 1.3788  Validation loss = 5.4143  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 1.3787  Validation loss = 5.4142  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 1.3783  Validation loss = 5.4132  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 1.3781  Validation loss = 5.4126  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 1.3778  Validation loss = 5.4116  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 1.3775  Validation loss = 5.4110  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 1.3772  Validation loss = 5.4108  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 1.3770  Validation loss = 5.4101  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 1.3768  Validation loss = 5.4097  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 1.3765  Validation loss = 5.4098  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 1.3762  Validation loss = 5.4099  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 1.3759  Validation loss = 5.4094  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 1.3757  Validation loss = 5.4091  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 1.3754  Validation loss = 5.4097  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 1.3751  Validation loss = 5.4082  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 1.3748  Validation loss = 5.4077  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 1.3746  Validation loss = 5.4076  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 1.3743  Validation loss = 5.4075  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 1.3740  Validation loss = 5.4072  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 1.3738  Validation loss = 5.4071  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 1.3735  Validation loss = 5.4061  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 1.3732  Validation loss = 5.4052  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 1.3729  Validation loss = 5.4037  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 1.3725  Validation loss = 5.4016  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 1.3721  Validation loss = 5.4010  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 1.3719  Validation loss = 5.4012  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 1.3716  Validation loss = 5.4002  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 1.3713  Validation loss = 5.3990  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 1.3711  Validation loss = 5.3985  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 1.3709  Validation loss = 5.3977  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 1.3706  Validation loss = 5.3972  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 1.3704  Validation loss = 5.3964  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 1.3702  Validation loss = 5.3959  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 1.3700  Validation loss = 5.3953  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 1.3698  Validation loss = 5.3953  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 1.3693  Validation loss = 5.3938  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 1.3690  Validation loss = 5.3922  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 1.3687  Validation loss = 5.3923  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 1.3684  Validation loss = 5.3923  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 1.3682  Validation loss = 5.3928  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 1.3680  Validation loss = 5.3918  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 1.3677  Validation loss = 5.3918  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 1.3675  Validation loss = 5.3921  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 1.3671  Validation loss = 5.3912  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 1.3669  Validation loss = 5.3909  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 1.3667  Validation loss = 5.3921  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 1.3664  Validation loss = 5.3913  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 1.3662  Validation loss = 5.3912  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 1.3658  Validation loss = 5.3895  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 1.3654  Validation loss = 5.3876  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 1.3651  Validation loss = 5.3867  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 1.3648  Validation loss = 5.3863  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 1.3646  Validation loss = 5.3870  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 1.3643  Validation loss = 5.3866  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 1.3640  Validation loss = 5.3848  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 1.3638  Validation loss = 5.3848  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 1.3634  Validation loss = 5.3832  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 1.3632  Validation loss = 5.3835  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 1.3629  Validation loss = 5.3829  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 1.3627  Validation loss = 5.3823  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 1.3625  Validation loss = 5.3811  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 1.3621  Validation loss = 5.3806  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 1.3619  Validation loss = 5.3803  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 1.3617  Validation loss = 5.3792  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 1.3614  Validation loss = 5.3793  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 1.3612  Validation loss = 5.3790  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 1.3610  Validation loss = 5.3788  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 1.3606  Validation loss = 5.3772  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 1.3603  Validation loss = 5.3758  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 1.3601  Validation loss = 5.3750  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 1.3598  Validation loss = 5.3738  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 1.3595  Validation loss = 5.3725  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 1.3591  Validation loss = 5.3721  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 1.3588  Validation loss = 5.3717  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 1.3584  Validation loss = 5.3705  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 1.3582  Validation loss = 5.3714  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 1.3580  Validation loss = 5.3713  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 1.3578  Validation loss = 5.3698  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 1.3575  Validation loss = 5.3684  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 1.3574  Validation loss = 5.3687  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 1.3572  Validation loss = 5.3697  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 1.3570  Validation loss = 5.3701  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 1.3569  Validation loss = 5.3702  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 1.3567  Validation loss = 5.3707  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 1.3564  Validation loss = 5.3697  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 1.3562  Validation loss = 5.3684  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 1.3559  Validation loss = 5.3666  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 1.3556  Validation loss = 5.3655  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 1.3554  Validation loss = 5.3652  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 1.3552  Validation loss = 5.3644  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 1.3549  Validation loss = 5.3627  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 1.3546  Validation loss = 5.3613  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 1.3544  Validation loss = 5.3613  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 1.3542  Validation loss = 5.3614  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 1.3540  Validation loss = 5.3610  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 1.3538  Validation loss = 5.3619  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 1.3536  Validation loss = 5.3621  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 1.3534  Validation loss = 5.3614  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 1.3531  Validation loss = 5.3603  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 1.3529  Validation loss = 5.3605  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 1.3526  Validation loss = 5.3589  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 1.3523  Validation loss = 5.3591  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 1.3520  Validation loss = 5.3585  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 1.3518  Validation loss = 5.3589  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 1.3515  Validation loss = 5.3588  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 1.3512  Validation loss = 5.3578  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 1.3510  Validation loss = 5.3579  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 1.3509  Validation loss = 5.3589  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 1.3506  Validation loss = 5.3578  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 1.3504  Validation loss = 5.3564  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 1.3501  Validation loss = 5.3559  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 1.3499  Validation loss = 5.3554  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 1.3496  Validation loss = 5.3541  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 1.3494  Validation loss = 5.3543  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 1.3490  Validation loss = 5.3541  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 1.3488  Validation loss = 5.3543  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 1.3485  Validation loss = 5.3526  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 1.3482  Validation loss = 5.3527  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 1.3480  Validation loss = 5.3521  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 1.3478  Validation loss = 5.3529  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 1.3476  Validation loss = 5.3528  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 1.3474  Validation loss = 5.3536  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 1.3472  Validation loss = 5.3529  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 1.3469  Validation loss = 5.3518  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 1.3467  Validation loss = 5.3528  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 1.3464  Validation loss = 5.3519  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 1.3462  Validation loss = 5.3509  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 1.3459  Validation loss = 5.3511  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 1.3457  Validation loss = 5.3497  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 1.3455  Validation loss = 5.3500  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 1.3453  Validation loss = 5.3498  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 1.3450  Validation loss = 5.3493  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 1.3447  Validation loss = 5.3491  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 1.3446  Validation loss = 5.3489  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 1.3444  Validation loss = 5.3473  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 1.3441  Validation loss = 5.3465  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 1.3439  Validation loss = 5.3457  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 1.3439  Validation loss = 5.3461  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 1.3436  Validation loss = 5.3444  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 1.3434  Validation loss = 5.3451  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 1.3431  Validation loss = 5.3450  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 1.3428  Validation loss = 5.3437  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 1.3426  Validation loss = 5.3427  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 1.3424  Validation loss = 5.3416  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 1.3422  Validation loss = 5.3412  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 1.3419  Validation loss = 5.3410  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 1.3417  Validation loss = 5.3402  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 1.3415  Validation loss = 5.3385  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 1.3413  Validation loss = 5.3369  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 1.3410  Validation loss = 5.3354  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 1.3406  Validation loss = 5.3341  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 1.3404  Validation loss = 5.3335  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 1.3403  Validation loss = 5.3331  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 1.3402  Validation loss = 5.3337  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 1.3399  Validation loss = 5.3329  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 1.3397  Validation loss = 5.3320  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 1.3393  Validation loss = 5.3313  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 1.3391  Validation loss = 5.3308  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 1.3389  Validation loss = 5.3300  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 1.3388  Validation loss = 5.3304  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 1.3386  Validation loss = 5.3303  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 1.3385  Validation loss = 5.3292  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 1.3384  Validation loss = 5.3300  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 1.3381  Validation loss = 5.3294  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 1.3379  Validation loss = 5.3299  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 1.3377  Validation loss = 5.3294  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 1.3375  Validation loss = 5.3277  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 1.3372  Validation loss = 5.3277  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 1.3370  Validation loss = 5.3264  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 1.3368  Validation loss = 5.3257  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 1.3365  Validation loss = 5.3253  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 1.3363  Validation loss = 5.3250  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 1.3360  Validation loss = 5.3244  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 1.3357  Validation loss = 5.3229  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 1.3355  Validation loss = 5.3221  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 1.3353  Validation loss = 5.3212  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 1.3350  Validation loss = 5.3212  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 1.3347  Validation loss = 5.3192  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 1.3346  Validation loss = 5.3202  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 1.3344  Validation loss = 5.3198  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 1.3342  Validation loss = 5.3180  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 1.3340  Validation loss = 5.3186  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 1.3337  Validation loss = 5.3183  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 1.3335  Validation loss = 5.3179  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 1.3332  Validation loss = 5.3176  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 1.3331  Validation loss = 5.3160  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 1.3327  Validation loss = 5.3146  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 1.3325  Validation loss = 5.3139  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 1.3323  Validation loss = 5.3124  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 1.3320  Validation loss = 5.3116  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 1.3317  Validation loss = 5.3101  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 1.3315  Validation loss = 5.3103  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 1.3313  Validation loss = 5.3099  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 1.3312  Validation loss = 5.3104  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 1.3309  Validation loss = 5.3094  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 1.3307  Validation loss = 5.3084  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 1.3304  Validation loss = 5.3084  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 1.3302  Validation loss = 5.3075  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 1.3301  Validation loss = 5.3071  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 1.3298  Validation loss = 5.3067  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 1.3296  Validation loss = 5.3053  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 1.3295  Validation loss = 5.3053  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 1.3293  Validation loss = 5.3062  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 1.3291  Validation loss = 5.3065  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 1.3288  Validation loss = 5.3059  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 1.3286  Validation loss = 5.3054  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 1.3283  Validation loss = 5.3038  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 1.3280  Validation loss = 5.3039  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 1.3278  Validation loss = 5.3039  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 1.3276  Validation loss = 5.3025  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 1.3275  Validation loss = 5.3037  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 1.3273  Validation loss = 5.3041  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 1.3270  Validation loss = 5.3038  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 1.3268  Validation loss = 5.3039  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 1.3266  Validation loss = 5.3027  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 1.3263  Validation loss = 5.3026  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 1.3262  Validation loss = 5.3013  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 1.3259  Validation loss = 5.3006  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 1.3257  Validation loss = 5.2989  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 1.3254  Validation loss = 5.2995  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 1.3253  Validation loss = 5.2981  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 1.3251  Validation loss = 5.2987  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 1.3248  Validation loss = 5.2967  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 1.3246  Validation loss = 5.2959  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 1.3244  Validation loss = 5.2962  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 1.3241  Validation loss = 5.2966  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 1.3239  Validation loss = 5.2965  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 1.3236  Validation loss = 5.2956  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 1.3234  Validation loss = 5.2941  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 1.3233  Validation loss = 5.2949  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 1.3231  Validation loss = 5.2951  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 1.3229  Validation loss = 5.2942  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 1.3228  Validation loss = 5.2941  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 1.3225  Validation loss = 5.2951  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 1.3223  Validation loss = 5.2944  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 1.3221  Validation loss = 5.2937  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 1.3219  Validation loss = 5.2932  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 1.3217  Validation loss = 5.2936  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 1.3214  Validation loss = 5.2925  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 1.3213  Validation loss = 5.2921  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 1.3211  Validation loss = 5.2906  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 1.3208  Validation loss = 5.2901  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 1.3206  Validation loss = 5.2883  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 1.3203  Validation loss = 5.2879  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 1.3201  Validation loss = 5.2868  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 1.3200  Validation loss = 5.2868  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 1.3198  Validation loss = 5.2874  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 1.3196  Validation loss = 5.2871  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 1.3195  Validation loss = 5.2872  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 1.3192  Validation loss = 5.2872  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 1.3190  Validation loss = 5.2874  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 1.3188  Validation loss = 5.2862  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 1.3186  Validation loss = 5.2864  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 1.3183  Validation loss = 5.2848  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 1.3181  Validation loss = 5.2839  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 1.3179  Validation loss = 5.2829  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 1.3177  Validation loss = 5.2828  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 1.3175  Validation loss = 5.2822  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 1.3173  Validation loss = 5.2814  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 1.3170  Validation loss = 5.2812  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 1.3168  Validation loss = 5.2825  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 1.3166  Validation loss = 5.2799  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 1.3164  Validation loss = 5.2782  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 1.3162  Validation loss = 5.2788  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 1.3160  Validation loss = 5.2787  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 1.3158  Validation loss = 5.2777  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 1.3155  Validation loss = 5.2776  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 1.3152  Validation loss = 5.2764  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 1.3150  Validation loss = 5.2758  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 1.3147  Validation loss = 5.2753  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 1.3145  Validation loss = 5.2766  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 1.3144  Validation loss = 5.2773  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 1.3142  Validation loss = 5.2774  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 1.3139  Validation loss = 5.2776  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 1.3137  Validation loss = 5.2766  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 1.3135  Validation loss = 5.2778  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 476  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.8380  Validation loss = 8.0872  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.8373  Validation loss = 8.0841  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.8364  Validation loss = 8.0809  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.8357  Validation loss = 8.0783  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.8352  Validation loss = 8.0762  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.8347  Validation loss = 8.0745  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.8342  Validation loss = 8.0722  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.8332  Validation loss = 8.0691  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.8327  Validation loss = 8.0671  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.8322  Validation loss = 8.0656  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.8318  Validation loss = 8.0637  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.8313  Validation loss = 8.0621  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.8307  Validation loss = 8.0599  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.8302  Validation loss = 8.0581  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.8301  Validation loss = 8.0576  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.8296  Validation loss = 8.0558  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.8290  Validation loss = 8.0538  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.8286  Validation loss = 8.0522  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.8280  Validation loss = 8.0500  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.8275  Validation loss = 8.0483  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.8273  Validation loss = 8.0473  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.8267  Validation loss = 8.0452  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.8262  Validation loss = 8.0438  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 1.8252  Validation loss = 8.0401  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 1.8247  Validation loss = 8.0380  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 1.8243  Validation loss = 8.0370  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 1.8240  Validation loss = 8.0359  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 1.8236  Validation loss = 8.0342  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 1.8227  Validation loss = 8.0310  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 1.8222  Validation loss = 8.0288  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 1.8215  Validation loss = 8.0263  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 1.8210  Validation loss = 8.0248  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 1.8209  Validation loss = 8.0244  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 1.8204  Validation loss = 8.0223  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 1.8195  Validation loss = 8.0190  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 1.8192  Validation loss = 8.0181  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 1.8190  Validation loss = 8.0172  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 1.8184  Validation loss = 8.0151  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 1.8183  Validation loss = 8.0146  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 1.8181  Validation loss = 8.0140  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 1.8180  Validation loss = 8.0135  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 1.8177  Validation loss = 8.0127  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 1.8175  Validation loss = 8.0122  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 1.8169  Validation loss = 8.0101  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 1.8163  Validation loss = 8.0079  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 1.8163  Validation loss = 8.0077  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 1.8160  Validation loss = 8.0066  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 1.8155  Validation loss = 8.0051  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 1.8152  Validation loss = 8.0039  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 1.8144  Validation loss = 8.0009  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 1.8143  Validation loss = 8.0009  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 1.8137  Validation loss = 7.9988  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 1.8136  Validation loss = 7.9983  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 1.8132  Validation loss = 7.9970  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 1.8127  Validation loss = 7.9950  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 1.8125  Validation loss = 7.9945  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 1.8123  Validation loss = 7.9935  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 1.8117  Validation loss = 7.9916  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 1.8112  Validation loss = 7.9897  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 1.8107  Validation loss = 7.9879  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 1.8105  Validation loss = 7.9872  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 1.8102  Validation loss = 7.9865  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 1.8099  Validation loss = 7.9854  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 1.8094  Validation loss = 7.9834  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 1.8091  Validation loss = 7.9825  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 1.8086  Validation loss = 7.9804  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 1.8081  Validation loss = 7.9787  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 1.8078  Validation loss = 7.9777  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 1.8072  Validation loss = 7.9754  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 1.8069  Validation loss = 7.9743  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 1.8065  Validation loss = 7.9729  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 1.8061  Validation loss = 7.9714  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 1.8056  Validation loss = 7.9694  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 1.8052  Validation loss = 7.9679  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 1.8047  Validation loss = 7.9659  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 1.8044  Validation loss = 7.9643  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 1.8038  Validation loss = 7.9624  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 1.8035  Validation loss = 7.9613  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 1.8034  Validation loss = 7.9607  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 1.8030  Validation loss = 7.9592  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 1.8029  Validation loss = 7.9590  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 1.8022  Validation loss = 7.9562  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 1.8020  Validation loss = 7.9553  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 1.8015  Validation loss = 7.9532  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 1.8013  Validation loss = 7.9522  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 1.8008  Validation loss = 7.9501  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 1.8004  Validation loss = 7.9486  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 1.8000  Validation loss = 7.9469  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 1.7998  Validation loss = 7.9458  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 1.7994  Validation loss = 7.9441  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 1.7991  Validation loss = 7.9428  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 1.7987  Validation loss = 7.9413  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 1.7984  Validation loss = 7.9400  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 1.7981  Validation loss = 7.9386  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 1.7978  Validation loss = 7.9373  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 1.7976  Validation loss = 7.9366  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 1.7972  Validation loss = 7.9349  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 1.7966  Validation loss = 7.9327  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 1.7961  Validation loss = 7.9310  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 1.7957  Validation loss = 7.9293  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 1.7954  Validation loss = 7.9282  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 1.7952  Validation loss = 7.9270  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 1.7948  Validation loss = 7.9256  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 1.7945  Validation loss = 7.9248  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 1.7941  Validation loss = 7.9232  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 1.7938  Validation loss = 7.9219  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 1.7933  Validation loss = 7.9198  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 1.7930  Validation loss = 7.9192  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 1.7928  Validation loss = 7.9181  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 1.7926  Validation loss = 7.9178  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 1.7923  Validation loss = 7.9164  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 1.7920  Validation loss = 7.9154  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 1.7915  Validation loss = 7.9135  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 1.7911  Validation loss = 7.9114  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 1.7907  Validation loss = 7.9102  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 1.7903  Validation loss = 7.9081  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 1.7899  Validation loss = 7.9065  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 1.7895  Validation loss = 7.9047  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 1.7891  Validation loss = 7.9032  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 1.7887  Validation loss = 7.9013  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 1.7884  Validation loss = 7.9005  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 1.7883  Validation loss = 7.9000  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 1.7880  Validation loss = 7.8986  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 1.7877  Validation loss = 7.8973  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 1.7874  Validation loss = 7.8961  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 1.7872  Validation loss = 7.8955  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 1.7870  Validation loss = 7.8946  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 1.7865  Validation loss = 7.8926  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 1.7861  Validation loss = 7.8905  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 1.7859  Validation loss = 7.8901  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 1.7854  Validation loss = 7.8880  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 1.7849  Validation loss = 7.8858  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 1.7845  Validation loss = 7.8837  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 1.7840  Validation loss = 7.8817  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 1.7838  Validation loss = 7.8808  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 1.7834  Validation loss = 7.8793  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 1.7831  Validation loss = 7.8782  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 1.7830  Validation loss = 7.8774  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 1.7824  Validation loss = 7.8750  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 1.7821  Validation loss = 7.8735  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 1.7818  Validation loss = 7.8729  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 1.7813  Validation loss = 7.8709  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 1.7809  Validation loss = 7.8689  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 1.7804  Validation loss = 7.8669  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 1.7801  Validation loss = 7.8659  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 1.7797  Validation loss = 7.8642  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 1.7794  Validation loss = 7.8628  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 1.7792  Validation loss = 7.8619  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 1.7788  Validation loss = 7.8601  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 1.7786  Validation loss = 7.8598  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 1.7781  Validation loss = 7.8578  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 1.7778  Validation loss = 7.8568  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 1.7774  Validation loss = 7.8549  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 1.7773  Validation loss = 7.8544  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 1.7770  Validation loss = 7.8535  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 1.7767  Validation loss = 7.8523  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 1.7765  Validation loss = 7.8516  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 1.7762  Validation loss = 7.8505  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 1.7757  Validation loss = 7.8479  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 1.7753  Validation loss = 7.8459  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 1.7750  Validation loss = 7.8445  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 1.7747  Validation loss = 7.8434  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 1.7744  Validation loss = 7.8426  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 1.7741  Validation loss = 7.8408  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 1.7737  Validation loss = 7.8394  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 1.7735  Validation loss = 7.8381  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 1.7731  Validation loss = 7.8370  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 1.7729  Validation loss = 7.8364  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 1.7726  Validation loss = 7.8348  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 1.7725  Validation loss = 7.8344  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 1.7722  Validation loss = 7.8337  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 1.7721  Validation loss = 7.8333  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 1.7718  Validation loss = 7.8318  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 1.7714  Validation loss = 7.8305  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 1.7711  Validation loss = 7.8293  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 1.7709  Validation loss = 7.8285  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 1.7707  Validation loss = 7.8277  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 1.7704  Validation loss = 7.8261  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 1.7700  Validation loss = 7.8248  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 1.7697  Validation loss = 7.8232  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 1.7694  Validation loss = 7.8221  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 1.7690  Validation loss = 7.8203  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 1.7689  Validation loss = 7.8197  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 1.7687  Validation loss = 7.8193  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 1.7685  Validation loss = 7.8183  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 1.7681  Validation loss = 7.8166  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 1.7678  Validation loss = 7.8153  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 1.7676  Validation loss = 7.8152  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 1.7674  Validation loss = 7.8143  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 1.7669  Validation loss = 7.8120  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 1.7666  Validation loss = 7.8108  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 1.7665  Validation loss = 7.8104  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 1.7661  Validation loss = 7.8087  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 1.7658  Validation loss = 7.8075  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 1.7655  Validation loss = 7.8062  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 1.7654  Validation loss = 7.8055  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 1.7653  Validation loss = 7.8060  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 1.7648  Validation loss = 7.8035  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 1.7646  Validation loss = 7.8026  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 1.7646  Validation loss = 7.8035  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 1.7642  Validation loss = 7.8019  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 1.7636  Validation loss = 7.7994  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 1.7634  Validation loss = 7.7980  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 1.7632  Validation loss = 7.7976  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 1.7631  Validation loss = 7.7972  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 1.7629  Validation loss = 7.7962  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 1.7627  Validation loss = 7.7950  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 1.7624  Validation loss = 7.7940  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 1.7619  Validation loss = 7.7916  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 1.7617  Validation loss = 7.7905  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 1.7614  Validation loss = 7.7887  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 1.7612  Validation loss = 7.7881  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 1.7608  Validation loss = 7.7862  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 1.7607  Validation loss = 7.7859  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 1.7604  Validation loss = 7.7843  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 1.7600  Validation loss = 7.7826  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 1.7597  Validation loss = 7.7809  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 1.7594  Validation loss = 7.7800  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 1.7592  Validation loss = 7.7788  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 1.7590  Validation loss = 7.7782  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 1.7589  Validation loss = 7.7778  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 1.7588  Validation loss = 7.7779  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 1.7585  Validation loss = 7.7761  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 1.7582  Validation loss = 7.7753  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 1.7579  Validation loss = 7.7743  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 1.7578  Validation loss = 7.7735  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 1.7575  Validation loss = 7.7727  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 1.7574  Validation loss = 7.7726  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 1.7571  Validation loss = 7.7707  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 1.7570  Validation loss = 7.7709  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 1.7567  Validation loss = 7.7695  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 1.7561  Validation loss = 7.7665  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 1.7558  Validation loss = 7.7651  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 1.7553  Validation loss = 7.7628  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 1.7549  Validation loss = 7.7613  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 1.7546  Validation loss = 7.7596  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 1.7542  Validation loss = 7.7579  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 1.7538  Validation loss = 7.7559  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 1.7535  Validation loss = 7.7543  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 1.7531  Validation loss = 7.7517  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 1.7527  Validation loss = 7.7502  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 1.7524  Validation loss = 7.7490  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 1.7520  Validation loss = 7.7474  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 1.7519  Validation loss = 7.7468  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 1.7515  Validation loss = 7.7446  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 1.7514  Validation loss = 7.7439  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 1.7511  Validation loss = 7.7431  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 1.7508  Validation loss = 7.7414  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 1.7505  Validation loss = 7.7398  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 1.7503  Validation loss = 7.7398  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 1.7501  Validation loss = 7.7388  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 1.7498  Validation loss = 7.7379  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 1.7498  Validation loss = 7.7381  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 1.7496  Validation loss = 7.7373  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 1.7493  Validation loss = 7.7365  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 1.7490  Validation loss = 7.7353  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 1.7490  Validation loss = 7.7357  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 1.7488  Validation loss = 7.7351  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 1.7486  Validation loss = 7.7345  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 1.7484  Validation loss = 7.7338  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 1.7481  Validation loss = 7.7326  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 1.7479  Validation loss = 7.7318  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 1.7478  Validation loss = 7.7314  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 1.7474  Validation loss = 7.7297  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 1.7472  Validation loss = 7.7292  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 1.7470  Validation loss = 7.7283  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 1.7468  Validation loss = 7.7273  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 1.7466  Validation loss = 7.7267  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 1.7462  Validation loss = 7.7250  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 1.7459  Validation loss = 7.7234  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 1.7456  Validation loss = 7.7226  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 1.7453  Validation loss = 7.7208  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 1.7451  Validation loss = 7.7204  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 1.7449  Validation loss = 7.7200  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 1.7447  Validation loss = 7.7192  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 1.7444  Validation loss = 7.7182  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 1.7441  Validation loss = 7.7166  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 1.7438  Validation loss = 7.7153  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 1.7434  Validation loss = 7.7133  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 1.7433  Validation loss = 7.7127  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 1.7430  Validation loss = 7.7116  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 1.7427  Validation loss = 7.7103  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 1.7424  Validation loss = 7.7092  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 1.7424  Validation loss = 7.7095  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 1.7420  Validation loss = 7.7080  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 1.7418  Validation loss = 7.7069  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 1.7418  Validation loss = 7.7076  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 1.7415  Validation loss = 7.7064  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 1.7413  Validation loss = 7.7055  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 1.7410  Validation loss = 7.7039  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 1.7408  Validation loss = 7.7034  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 1.7406  Validation loss = 7.7020  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 1.7403  Validation loss = 7.7009  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 1.7402  Validation loss = 7.7003  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 1.7399  Validation loss = 7.6990  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 1.7398  Validation loss = 7.6991  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 1.7396  Validation loss = 7.6984  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 1.7395  Validation loss = 7.6978  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 1.7391  Validation loss = 7.6961  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 1.7390  Validation loss = 7.6960  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 1.7388  Validation loss = 7.6953  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 1.7385  Validation loss = 7.6936  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 1.7381  Validation loss = 7.6916  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 1.7380  Validation loss = 7.6919  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 1.7377  Validation loss = 7.6905  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 1.7376  Validation loss = 7.6900  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 1.7373  Validation loss = 7.6884  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 1.7369  Validation loss = 7.6868  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 1.7369  Validation loss = 7.6868  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 1.7365  Validation loss = 7.6851  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 1.7362  Validation loss = 7.6837  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 1.7360  Validation loss = 7.6826  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 1.7356  Validation loss = 7.6806  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 1.7352  Validation loss = 7.6788  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 1.7349  Validation loss = 7.6774  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 1.7348  Validation loss = 7.6772  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 1.7346  Validation loss = 7.6765  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 1.7342  Validation loss = 7.6747  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 1.7340  Validation loss = 7.6738  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 1.7337  Validation loss = 7.6725  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 1.7335  Validation loss = 7.6713  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 1.7331  Validation loss = 7.6692  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 1.7328  Validation loss = 7.6677  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 1.7326  Validation loss = 7.6665  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 1.7324  Validation loss = 7.6660  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 1.7321  Validation loss = 7.6642  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 1.7318  Validation loss = 7.6631  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 1.7316  Validation loss = 7.6624  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 1.7313  Validation loss = 7.6610  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 1.7310  Validation loss = 7.6594  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 1.7306  Validation loss = 7.6572  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 1.7304  Validation loss = 7.6561  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 1.7303  Validation loss = 7.6554  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 1.7298  Validation loss = 7.6531  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 1.7297  Validation loss = 7.6527  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 1.7294  Validation loss = 7.6515  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 1.7293  Validation loss = 7.6514  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 1.7291  Validation loss = 7.6507  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 1.7288  Validation loss = 7.6492  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 1.7284  Validation loss = 7.6475  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 1.7282  Validation loss = 7.6467  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 1.7278  Validation loss = 7.6446  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 1.7274  Validation loss = 7.6419  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 1.7270  Validation loss = 7.6401  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 1.7266  Validation loss = 7.6382  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 1.7263  Validation loss = 7.6369  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 1.7260  Validation loss = 7.6360  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 1.7258  Validation loss = 7.6344  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 1.7256  Validation loss = 7.6339  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 1.7253  Validation loss = 7.6325  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 1.7252  Validation loss = 7.6323  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 1.7249  Validation loss = 7.6307  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 1.7246  Validation loss = 7.6286  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 1.7243  Validation loss = 7.6268  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 1.7241  Validation loss = 7.6254  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 1.7238  Validation loss = 7.6243  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 1.7235  Validation loss = 7.6227  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 1.7233  Validation loss = 7.6220  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 1.7231  Validation loss = 7.6215  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 1.7229  Validation loss = 7.6209  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 1.7225  Validation loss = 7.6189  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 1.7222  Validation loss = 7.6175  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 1.7219  Validation loss = 7.6173  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 1.7216  Validation loss = 7.6156  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 1.7213  Validation loss = 7.6141  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 1.7210  Validation loss = 7.6130  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 1.7208  Validation loss = 7.6122  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 1.7205  Validation loss = 7.6112  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 1.7203  Validation loss = 7.6102  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 1.7202  Validation loss = 7.6100  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 1.7200  Validation loss = 7.6088  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 1.7198  Validation loss = 7.6072  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 1.7195  Validation loss = 7.6055  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 1.7193  Validation loss = 7.6049  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 1.7190  Validation loss = 7.6037  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 1.7187  Validation loss = 7.6026  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 1.7185  Validation loss = 7.6029  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 1.7185  Validation loss = 7.6034  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 1.7182  Validation loss = 7.6024  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 1.7180  Validation loss = 7.6019  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 1.7177  Validation loss = 7.6005  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 1.7176  Validation loss = 7.5999  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 1.7174  Validation loss = 7.5989  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 1.7173  Validation loss = 7.5987  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 1.7170  Validation loss = 7.5972  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 1.7168  Validation loss = 7.5963  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 1.7164  Validation loss = 7.5936  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 1.7162  Validation loss = 7.5932  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 1.7158  Validation loss = 7.5903  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 1.7155  Validation loss = 7.5895  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 1.7152  Validation loss = 7.5877  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 1.7149  Validation loss = 7.5865  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 1.7145  Validation loss = 7.5845  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 1.7141  Validation loss = 7.5824  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 1.7138  Validation loss = 7.5816  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 1.7137  Validation loss = 7.5814  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 1.7134  Validation loss = 7.5804  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 1.7132  Validation loss = 7.5796  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 1.7130  Validation loss = 7.5780  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 1.7126  Validation loss = 7.5762  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 1.7125  Validation loss = 7.5760  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 1.7123  Validation loss = 7.5749  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 1.7120  Validation loss = 7.5741  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 1.7119  Validation loss = 7.5742  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 1.7118  Validation loss = 7.5738  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 1.7116  Validation loss = 7.5724  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 1.7114  Validation loss = 7.5719  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 1.7110  Validation loss = 7.5701  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 1.7109  Validation loss = 7.5702  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 1.7106  Validation loss = 7.5688  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 1.7104  Validation loss = 7.5680  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 1.7101  Validation loss = 7.5665  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 1.7098  Validation loss = 7.5649  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 1.7097  Validation loss = 7.5646  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 1.7096  Validation loss = 7.5645  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 1.7093  Validation loss = 7.5634  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 1.7089  Validation loss = 7.5615  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 1.7086  Validation loss = 7.5605  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 1.7085  Validation loss = 7.5602  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 1.7082  Validation loss = 7.5587  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 1.7079  Validation loss = 7.5578  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 1.7077  Validation loss = 7.5570  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 1.7075  Validation loss = 7.5563  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 1.7073  Validation loss = 7.5557  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 1.7071  Validation loss = 7.5550  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 1.7069  Validation loss = 7.5541  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 1.7067  Validation loss = 7.5535  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 1.7064  Validation loss = 7.5520  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 1.7062  Validation loss = 7.5510  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 1.7059  Validation loss = 7.5500  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 1.7057  Validation loss = 7.5487  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 1.7054  Validation loss = 7.5480  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 1.7051  Validation loss = 7.5462  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 1.7050  Validation loss = 7.5459  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 1.7047  Validation loss = 7.5442  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 1.7044  Validation loss = 7.5437  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 1.7042  Validation loss = 7.5425  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 1.7038  Validation loss = 7.5401  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 1.7035  Validation loss = 7.5388  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 1.7032  Validation loss = 7.5373  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 1.7029  Validation loss = 7.5360  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 1.7028  Validation loss = 7.5360  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 1.7025  Validation loss = 7.5346  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 1.7022  Validation loss = 7.5330  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 1.7020  Validation loss = 7.5325  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 1.7018  Validation loss = 7.5311  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 1.7015  Validation loss = 7.5296  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 1.7014  Validation loss = 7.5293  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 1.7010  Validation loss = 7.5283  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 1.7008  Validation loss = 7.5276  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 1.7007  Validation loss = 7.5271  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 1.7004  Validation loss = 7.5254  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 1.7000  Validation loss = 7.5237  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 1.6998  Validation loss = 7.5230  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 1.6996  Validation loss = 7.5226  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 1.6994  Validation loss = 7.5207  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 1.6991  Validation loss = 7.5190  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 1.6988  Validation loss = 7.5180  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 1.6987  Validation loss = 7.5184  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 1.6985  Validation loss = 7.5177  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 1.6984  Validation loss = 7.5169  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 1.6981  Validation loss = 7.5169  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 1.6978  Validation loss = 7.5145  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 1.6975  Validation loss = 7.5136  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 1.6973  Validation loss = 7.5129  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 1.6971  Validation loss = 7.5134  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 1.6969  Validation loss = 7.5120  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 1.6967  Validation loss = 7.5110  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 1.6966  Validation loss = 7.5105  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 1.6962  Validation loss = 7.5080  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 1.6960  Validation loss = 7.5080  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 1.6958  Validation loss = 7.5070  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 1.6955  Validation loss = 7.5061  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 1.6955  Validation loss = 7.5064  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 1.6952  Validation loss = 7.5051  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 1.6949  Validation loss = 7.5038  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 1.6947  Validation loss = 7.5031  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 1.6944  Validation loss = 7.5019  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 1.6942  Validation loss = 7.5016  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 1.6939  Validation loss = 7.4995  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 1.6938  Validation loss = 7.4984  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 1.6933  Validation loss = 7.4956  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 1.6930  Validation loss = 7.4937  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 1.6928  Validation loss = 7.4925  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 1.6928  Validation loss = 7.4931  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 1.6926  Validation loss = 7.4925  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 1.6922  Validation loss = 7.4902  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 1.6921  Validation loss = 7.4907  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 1.6918  Validation loss = 7.4884  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 1.6917  Validation loss = 7.4881  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 1.6915  Validation loss = 7.4870  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 1.6913  Validation loss = 7.4868  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 1.6911  Validation loss = 7.4851  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 1.6907  Validation loss = 7.4831  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 1.6906  Validation loss = 7.4827  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 1.6903  Validation loss = 7.4815  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 1.6901  Validation loss = 7.4823  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 1.6900  Validation loss = 7.4820  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 1.6897  Validation loss = 7.4811  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 1.6894  Validation loss = 7.4794  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.4591  Validation loss = 3.0879  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.4579  Validation loss = 3.0843  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.4570  Validation loss = 3.0817  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.4561  Validation loss = 3.0788  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.4557  Validation loss = 3.0772  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.4546  Validation loss = 3.0724  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.4538  Validation loss = 3.0688  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.4527  Validation loss = 3.0563  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.4512  Validation loss = 3.0346  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.4500  Validation loss = 3.0191  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.4492  Validation loss = 3.0143  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.4484  Validation loss = 3.0100  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.4472  Validation loss = 3.0034  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.4460  Validation loss = 2.9995  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 2.4452  Validation loss = 2.9971  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.4442  Validation loss = 2.9938  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 2.4424  Validation loss = 2.9881  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 2.4412  Validation loss = 2.9847  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 2.4404  Validation loss = 2.9826  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.4392  Validation loss = 2.9790  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 2.4381  Validation loss = 2.9763  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 2.4375  Validation loss = 2.9749  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 2.4367  Validation loss = 2.9726  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 2.4358  Validation loss = 2.9701  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 2.4345  Validation loss = 2.9668  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 2.4336  Validation loss = 2.9646  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 2.4328  Validation loss = 2.9625  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 2.4318  Validation loss = 2.9597  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 2.4309  Validation loss = 2.9573  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 2.4297  Validation loss = 2.9539  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 2.4285  Validation loss = 2.9506  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 2.4275  Validation loss = 2.9481  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 2.4260  Validation loss = 2.9439  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 2.4254  Validation loss = 2.9424  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 2.4238  Validation loss = 2.9377  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 2.4229  Validation loss = 2.9355  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 2.4221  Validation loss = 2.9334  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 2.4209  Validation loss = 2.9303  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 2.4189  Validation loss = 2.9243  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 2.4180  Validation loss = 2.9221  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 2.4164  Validation loss = 2.9173  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 2.4148  Validation loss = 2.9113  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 2.4130  Validation loss = 2.9022  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 2.4093  Validation loss = 2.8745  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 2.4083  Validation loss = 2.8717  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 2.4069  Validation loss = 2.8676  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 2.4054  Validation loss = 2.8635  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 2.4048  Validation loss = 2.8621  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 2.4032  Validation loss = 2.8578  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 2.4022  Validation loss = 2.8548  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 2.4016  Validation loss = 2.8531  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 2.4008  Validation loss = 2.8510  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 2.3997  Validation loss = 2.8482  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 2.3984  Validation loss = 2.8449  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 2.3973  Validation loss = 2.8417  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 2.3962  Validation loss = 2.8392  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 2.3961  Validation loss = 2.8389  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 2.3950  Validation loss = 2.8359  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 2.3941  Validation loss = 2.8335  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 2.3935  Validation loss = 2.8321  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 2.3923  Validation loss = 2.8288  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 2.3909  Validation loss = 2.8249  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 2.3900  Validation loss = 2.8222  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 2.3895  Validation loss = 2.8211  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 2.3886  Validation loss = 2.8187  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 2.3881  Validation loss = 2.8174  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 2.3871  Validation loss = 2.8151  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 2.3860  Validation loss = 2.8120  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 2.3846  Validation loss = 2.8079  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 2.3835  Validation loss = 2.8050  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 2.3830  Validation loss = 2.8039  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 2.3814  Validation loss = 2.7993  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 2.3804  Validation loss = 2.7966  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 2.3792  Validation loss = 2.7933  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 2.3774  Validation loss = 2.7878  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 2.3765  Validation loss = 2.7854  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 2.3752  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 2.3745  Validation loss = 2.7800  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 2.3730  Validation loss = 2.7757  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 2.3724  Validation loss = 2.7743  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 2.3712  Validation loss = 2.7711  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 2.3704  Validation loss = 2.7691  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 2.3696  Validation loss = 2.7667  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 2.3687  Validation loss = 2.7650  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 2.3676  Validation loss = 2.7619  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 2.3670  Validation loss = 2.7604  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 2.3666  Validation loss = 2.7597  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 2.3658  Validation loss = 2.7574  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 2.3650  Validation loss = 2.7555  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 2.3640  Validation loss = 2.7526  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 2.3627  Validation loss = 2.7492  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 2.3616  Validation loss = 2.7463  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 2.3608  Validation loss = 2.7441  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 2.3599  Validation loss = 2.7413  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 2.3586  Validation loss = 2.7379  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 2.3573  Validation loss = 2.7344  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 2.3570  Validation loss = 2.7341  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 2.3564  Validation loss = 2.7326  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 2.3552  Validation loss = 2.7291  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 2.3542  Validation loss = 2.7261  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 2.3539  Validation loss = 2.7257  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 2.3528  Validation loss = 2.7228  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 2.3519  Validation loss = 2.7202  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 2.3509  Validation loss = 2.7177  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 2.3503  Validation loss = 2.7162  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 2.3492  Validation loss = 2.7128  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 2.3478  Validation loss = 2.7090  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 2.3470  Validation loss = 2.7068  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 2.3461  Validation loss = 2.7043  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 2.3449  Validation loss = 2.7008  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 2.3443  Validation loss = 2.6994  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 2.3436  Validation loss = 2.6979  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 2.3428  Validation loss = 2.6960  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 2.3417  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 2.3408  Validation loss = 2.6902  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 2.3405  Validation loss = 2.6897  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 2.3389  Validation loss = 2.6850  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 2.3385  Validation loss = 2.6840  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 2.3376  Validation loss = 2.6820  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 2.3368  Validation loss = 2.6799  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 2.3355  Validation loss = 2.6762  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 2.3344  Validation loss = 2.6734  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 2.3335  Validation loss = 2.6709  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 2.3330  Validation loss = 2.6696  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 2.3317  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 2.3309  Validation loss = 2.6642  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 2.3296  Validation loss = 2.6608  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 2.3292  Validation loss = 2.6598  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 2.3277  Validation loss = 2.6555  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 2.3268  Validation loss = 2.6532  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 2.3259  Validation loss = 2.6507  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 2.3251  Validation loss = 2.6484  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 2.3241  Validation loss = 2.6461  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 2.3232  Validation loss = 2.6439  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 2.3223  Validation loss = 2.6420  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 2.3212  Validation loss = 2.6388  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 2.3206  Validation loss = 2.6375  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 2.3192  Validation loss = 2.6338  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 2.3187  Validation loss = 2.6321  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 2.3175  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 2.3168  Validation loss = 2.6272  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 2.3160  Validation loss = 2.6251  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 2.3154  Validation loss = 2.6238  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 2.3147  Validation loss = 2.6218  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 2.3137  Validation loss = 2.6189  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 2.3125  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 2.3118  Validation loss = 2.6143  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 2.3113  Validation loss = 2.6131  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 2.3107  Validation loss = 2.6116  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 2.3089  Validation loss = 2.6063  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 2.3078  Validation loss = 2.6034  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 2.3064  Validation loss = 2.5989  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 2.3050  Validation loss = 2.5952  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 2.3046  Validation loss = 2.5941  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 2.3025  Validation loss = 2.5884  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 2.3022  Validation loss = 2.5878  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 2.3015  Validation loss = 2.5864  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 2.3000  Validation loss = 2.5819  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 2.2986  Validation loss = 2.5782  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 2.2981  Validation loss = 2.5771  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 2.2967  Validation loss = 2.5735  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 2.2961  Validation loss = 2.5717  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 2.2951  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 2.2947  Validation loss = 2.5694  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 2.2938  Validation loss = 2.5670  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 2.2932  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 2.2921  Validation loss = 2.5619  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 2.2912  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 2.2900  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 2.2894  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 2.2890  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 2.2882  Validation loss = 2.5527  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 2.2872  Validation loss = 2.5500  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 2.2875  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 2.2867  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 2.2858  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 2.2840  Validation loss = 2.5428  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 2.2834  Validation loss = 2.5417  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 2.2829  Validation loss = 2.5405  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 2.2823  Validation loss = 2.5388  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 2.2816  Validation loss = 2.5367  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 2.2811  Validation loss = 2.5357  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 2.2797  Validation loss = 2.5317  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 2.2787  Validation loss = 2.5290  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 2.2781  Validation loss = 2.5276  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 2.2770  Validation loss = 2.5242  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 2.2762  Validation loss = 2.5221  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 2.2753  Validation loss = 2.5202  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 2.2744  Validation loss = 2.5179  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 2.2735  Validation loss = 2.5158  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 2.2726  Validation loss = 2.5144  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 2.2720  Validation loss = 2.5132  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 2.2713  Validation loss = 2.5112  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 2.2702  Validation loss = 2.5084  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 2.2694  Validation loss = 2.5065  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 2.2687  Validation loss = 2.5042  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 2.2683  Validation loss = 2.5033  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 2.2672  Validation loss = 2.5002  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 2.2664  Validation loss = 2.4980  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 2.2653  Validation loss = 2.4952  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 2.2647  Validation loss = 2.4944  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 2.2637  Validation loss = 2.4917  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 2.2627  Validation loss = 2.4894  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 2.2622  Validation loss = 2.4882  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 2.2609  Validation loss = 2.4844  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 2.2607  Validation loss = 2.4847  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 2.2597  Validation loss = 2.4827  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 2.2588  Validation loss = 2.4803  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 2.2583  Validation loss = 2.4791  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 2.2577  Validation loss = 2.4780  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 2.2571  Validation loss = 2.4766  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 2.2559  Validation loss = 2.4736  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 2.2552  Validation loss = 2.4721  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 2.2542  Validation loss = 2.4698  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 2.2528  Validation loss = 2.4661  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 2.2520  Validation loss = 2.4638  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 2.2514  Validation loss = 2.4620  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 2.2508  Validation loss = 2.4602  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 2.2498  Validation loss = 2.4573  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 2.2488  Validation loss = 2.4555  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 2.2479  Validation loss = 2.4525  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 2.2466  Validation loss = 2.4496  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 2.2458  Validation loss = 2.4484  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 2.2449  Validation loss = 2.4463  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 2.2436  Validation loss = 2.4429  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 2.2431  Validation loss = 2.4421  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 2.2423  Validation loss = 2.4398  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 2.2418  Validation loss = 2.4385  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 2.2410  Validation loss = 2.4364  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 2.2404  Validation loss = 2.4351  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 2.2398  Validation loss = 2.4335  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 2.2386  Validation loss = 2.4301  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 2.2378  Validation loss = 2.4282  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 2.2360  Validation loss = 2.4229  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 2.2355  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 2.2344  Validation loss = 2.4191  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 2.2340  Validation loss = 2.4181  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 2.2329  Validation loss = 2.4154  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 2.2325  Validation loss = 2.4151  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 2.2310  Validation loss = 2.4115  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 2.2285  Validation loss = 2.4082  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 2.2276  Validation loss = 2.4056  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 2.2262  Validation loss = 2.4012  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 2.2252  Validation loss = 2.3985  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 2.2247  Validation loss = 2.3975  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 2.2242  Validation loss = 2.3963  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 2.2232  Validation loss = 2.3935  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 2.2224  Validation loss = 2.3921  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 2.2213  Validation loss = 2.3886  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 2.2209  Validation loss = 2.3878  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 2.2199  Validation loss = 2.3852  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 2.2193  Validation loss = 2.3837  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 2.2184  Validation loss = 2.3818  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 2.2179  Validation loss = 2.3804  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 2.2167  Validation loss = 2.3768  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 2.2157  Validation loss = 2.3746  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 2.2147  Validation loss = 2.3714  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 2.2138  Validation loss = 2.3693  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 2.2128  Validation loss = 2.3667  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 2.2125  Validation loss = 2.3659  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 2.2120  Validation loss = 2.3648  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 2.2110  Validation loss = 2.3621  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 2.2104  Validation loss = 2.3614  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 2.2101  Validation loss = 2.3615  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 2.2092  Validation loss = 2.3590  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 2.2081  Validation loss = 2.3558  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 2.2075  Validation loss = 2.3544  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 2.2068  Validation loss = 2.3523  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 2.2057  Validation loss = 2.3491  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 2.2051  Validation loss = 2.3475  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 2.2039  Validation loss = 2.3447  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 2.2037  Validation loss = 2.3447  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 2.2030  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 2.2028  Validation loss = 2.3423  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 2.2019  Validation loss = 2.3405  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 2.2013  Validation loss = 2.3388  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 2.2009  Validation loss = 2.3382  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 2.2002  Validation loss = 2.3365  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 2.1990  Validation loss = 2.3331  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 2.1982  Validation loss = 2.3315  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 2.1976  Validation loss = 2.3304  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 2.1972  Validation loss = 2.3297  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 2.1968  Validation loss = 2.3286  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 2.1966  Validation loss = 2.3284  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 2.1959  Validation loss = 2.3263  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 2.1950  Validation loss = 2.3244  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 2.1945  Validation loss = 2.3234  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 2.1940  Validation loss = 2.3229  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 2.1932  Validation loss = 2.3213  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 2.1925  Validation loss = 2.3198  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 2.1922  Validation loss = 2.3192  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 2.1911  Validation loss = 2.3157  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 2.1907  Validation loss = 2.3140  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 2.1900  Validation loss = 2.3118  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 2.1894  Validation loss = 2.3089  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 2.1885  Validation loss = 2.3014  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 2.1878  Validation loss = 2.2915  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 2.1873  Validation loss = 2.2911  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 2.1870  Validation loss = 2.2898  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 2.1862  Validation loss = 2.2849  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 2.1833  Validation loss = 2.2012  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 2.1828  Validation loss = 2.1980  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 2.1824  Validation loss = 2.1976  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 2.1812  Validation loss = 2.1939  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 2.1806  Validation loss = 2.1929  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 2.1803  Validation loss = 2.1926  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 2.1797  Validation loss = 2.1910  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 2.1790  Validation loss = 2.1888  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 2.1782  Validation loss = 2.1872  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 2.1777  Validation loss = 2.1865  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 2.1771  Validation loss = 2.1851  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 2.1764  Validation loss = 2.1832  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 2.1756  Validation loss = 2.1810  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 2.1752  Validation loss = 2.1804  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 2.1745  Validation loss = 2.1784  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 2.1737  Validation loss = 2.1763  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 2.1730  Validation loss = 2.1743  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 2.1724  Validation loss = 2.1729  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 2.1718  Validation loss = 2.1711  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 2.1716  Validation loss = 2.1713  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 2.1704  Validation loss = 2.1671  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 2.1697  Validation loss = 2.1652  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 2.1691  Validation loss = 2.1635  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 2.1686  Validation loss = 2.1626  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 2.1683  Validation loss = 2.1622  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 2.1679  Validation loss = 2.1619  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 2.1676  Validation loss = 2.1613  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 2.1668  Validation loss = 2.1595  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 2.1661  Validation loss = 2.1573  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 2.1657  Validation loss = 2.1565  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 2.1655  Validation loss = 2.1562  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 2.1650  Validation loss = 2.1551  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 2.1642  Validation loss = 2.1526  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 2.1635  Validation loss = 2.1516  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 2.1627  Validation loss = 2.1494  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 2.1622  Validation loss = 2.1482  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 2.1615  Validation loss = 2.1467  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 2.1609  Validation loss = 2.1454  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 2.1601  Validation loss = 2.1438  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 2.1596  Validation loss = 2.1424  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 2.1591  Validation loss = 2.1418  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 2.1587  Validation loss = 2.1407  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 2.1580  Validation loss = 2.1382  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 2.1575  Validation loss = 2.1373  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 2.1567  Validation loss = 2.1352  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 2.1558  Validation loss = 2.1336  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 2.1554  Validation loss = 2.1332  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 2.1552  Validation loss = 2.1331  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 2.1548  Validation loss = 2.1323  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 2.1540  Validation loss = 2.1307  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 2.1533  Validation loss = 2.1290  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 2.1531  Validation loss = 2.1292  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 2.1524  Validation loss = 2.1276  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 2.1524  Validation loss = 2.1281  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 2.1514  Validation loss = 2.1253  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 2.1509  Validation loss = 2.1246  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 2.1503  Validation loss = 2.1225  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 2.1492  Validation loss = 2.1192  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 2.1490  Validation loss = 2.1180  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 2.1482  Validation loss = 2.1164  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 2.1480  Validation loss = 2.1156  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 2.1477  Validation loss = 2.1148  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 2.1466  Validation loss = 2.1118  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 2.1463  Validation loss = 2.1110  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 2.1453  Validation loss = 2.1080  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 2.1448  Validation loss = 2.1072  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 2.1447  Validation loss = 2.1076  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 2.1439  Validation loss = 2.1052  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 2.1432  Validation loss = 2.1040  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 2.1430  Validation loss = 2.1037  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 2.1424  Validation loss = 2.1028  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 2.1420  Validation loss = 2.1015  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 2.1416  Validation loss = 2.0996  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 2.1412  Validation loss = 2.0984  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 2.1402  Validation loss = 2.0953  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 2.1398  Validation loss = 2.0942  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 2.1392  Validation loss = 2.0932  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 2.1390  Validation loss = 2.0925  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 2.1385  Validation loss = 2.0915  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 2.1383  Validation loss = 2.0915  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 2.1375  Validation loss = 2.0894  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 2.1371  Validation loss = 2.0878  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 2.1368  Validation loss = 2.0873  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 2.1364  Validation loss = 2.0872  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 2.1361  Validation loss = 2.0872  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 2.1354  Validation loss = 2.0858  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 2.1345  Validation loss = 2.0838  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 2.1338  Validation loss = 2.0828  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 2.1330  Validation loss = 2.0802  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 2.1328  Validation loss = 2.0798  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 2.1320  Validation loss = 2.0770  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 2.1317  Validation loss = 2.0764  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 2.1310  Validation loss = 2.0743  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 2.1306  Validation loss = 2.0743  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 2.1307  Validation loss = 2.0753  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 2.1301  Validation loss = 2.0738  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 2.1293  Validation loss = 2.0717  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 2.1287  Validation loss = 2.0703  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 2.1280  Validation loss = 2.0683  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 2.1275  Validation loss = 2.0670  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 2.1266  Validation loss = 2.0646  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 2.1258  Validation loss = 2.0619  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 2.1253  Validation loss = 2.0613  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 2.1244  Validation loss = 2.0589  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 2.1235  Validation loss = 2.0572  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 2.1232  Validation loss = 2.0561  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 2.1230  Validation loss = 2.0566  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 2.1226  Validation loss = 2.0553  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 2.1218  Validation loss = 2.0544  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 2.1209  Validation loss = 2.0516  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 2.1206  Validation loss = 2.0516  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 2.1203  Validation loss = 2.0508  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 2.1197  Validation loss = 2.0499  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 2.1191  Validation loss = 2.0480  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 2.1185  Validation loss = 2.0470  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 2.1178  Validation loss = 2.0451  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 2.1174  Validation loss = 2.0443  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 2.1169  Validation loss = 2.0441  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 2.1165  Validation loss = 2.0426  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 2.1160  Validation loss = 2.0424  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 2.1156  Validation loss = 2.0416  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 2.1149  Validation loss = 2.0398  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 2.1142  Validation loss = 2.0379  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 2.1138  Validation loss = 2.0377  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 2.1130  Validation loss = 2.0356  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 2.1126  Validation loss = 2.0352  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 2.1118  Validation loss = 2.0334  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 2.1110  Validation loss = 2.0311  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 2.1103  Validation loss = 2.0291  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 2.1095  Validation loss = 2.0273  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 2.1089  Validation loss = 2.0261  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 2.1081  Validation loss = 2.0238  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 2.1073  Validation loss = 2.0224  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 2.1067  Validation loss = 2.0210  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 2.1064  Validation loss = 2.0205  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 2.1059  Validation loss = 2.0198  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 2.1051  Validation loss = 2.0176  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 2.1047  Validation loss = 2.0162  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 2.1039  Validation loss = 2.0149  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 2.1036  Validation loss = 2.0144  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 2.1029  Validation loss = 2.0130  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 2.1025  Validation loss = 2.0123  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 2.1020  Validation loss = 2.0115  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 2.1017  Validation loss = 2.0112  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 2.1011  Validation loss = 2.0094  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 2.1004  Validation loss = 2.0079  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 2.1000  Validation loss = 2.0069  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 2.0997  Validation loss = 2.0064  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 2.0995  Validation loss = 2.0060  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 2.0989  Validation loss = 2.0046  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 2.0984  Validation loss = 2.0040  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 2.0976  Validation loss = 2.0025  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 2.0968  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 2.0962  Validation loss = 2.0000  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 2.0957  Validation loss = 1.9986  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 2.0946  Validation loss = 1.9956  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 2.0941  Validation loss = 1.9946  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 2.0937  Validation loss = 1.9940  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 2.0934  Validation loss = 1.9938  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 2.0929  Validation loss = 1.9927  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 2.0923  Validation loss = 1.9909  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 2.0914  Validation loss = 1.9887  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 2.0907  Validation loss = 1.9874  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 2.0900  Validation loss = 1.9860  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 2.0897  Validation loss = 1.9853  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 2.0892  Validation loss = 1.9847  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 2.0885  Validation loss = 1.9828  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 2.0880  Validation loss = 1.9817  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 2.0873  Validation loss = 1.9804  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 2.0874  Validation loss = 1.9816  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 2.0869  Validation loss = 1.9804  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 2.0865  Validation loss = 1.9791  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 2.0857  Validation loss = 1.9773  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 2.0849  Validation loss = 1.9761  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 2.0842  Validation loss = 1.9752  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 2.0836  Validation loss = 1.9737  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 2.0832  Validation loss = 1.9731  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 2.0827  Validation loss = 1.9724  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 2.0823  Validation loss = 1.9714  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 2.0819  Validation loss = 1.9706  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 2.0812  Validation loss = 1.9691  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 2.0805  Validation loss = 1.9674  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 2.0799  Validation loss = 1.9652  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 2.0794  Validation loss = 1.9640  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 2.0787  Validation loss = 1.9626  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 2.0779  Validation loss = 1.9609  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 2.0775  Validation loss = 1.9604  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 2.0770  Validation loss = 1.9597  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 2.0761  Validation loss = 1.9581  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 2.0760  Validation loss = 1.9585  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 2.0755  Validation loss = 1.9569  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 2.0747  Validation loss = 1.9554  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 2.0742  Validation loss = 1.9547  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 2.0734  Validation loss = 1.9528  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 2.0730  Validation loss = 1.9523  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 2.0724  Validation loss = 1.9498  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 2.0720  Validation loss = 1.9499  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 2.0716  Validation loss = 1.9494  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 2.0708  Validation loss = 1.9473  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 2.0702  Validation loss = 1.9459  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 2.0870  Validation loss = 1.1685  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 2.0859  Validation loss = 1.1708  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 2.0854  Validation loss = 1.1696  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 2.0841  Validation loss = 1.1715  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 2.0833  Validation loss = 1.1729  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 2.0824  Validation loss = 1.1748  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 2.0817  Validation loss = 1.1736  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 2.0806  Validation loss = 1.1736  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 2.0796  Validation loss = 1.1763  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 2.0788  Validation loss = 1.1749  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 2.0780  Validation loss = 1.1763  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 2.0772  Validation loss = 1.1803  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 1  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 2.0681  Validation loss = 1.1360  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.0677  Validation loss = 1.1365  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 2.0668  Validation loss = 1.1359  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.0664  Validation loss = 1.1392  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 2.0658  Validation loss = 1.1383  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.0650  Validation loss = 1.1375  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 2.0643  Validation loss = 1.1395  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 2.0633  Validation loss = 1.1378  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.0627  Validation loss = 1.1347  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 2.0620  Validation loss = 1.1336  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 2.0618  Validation loss = 1.1367  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 2.0614  Validation loss = 1.1342  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 2.0613  Validation loss = 1.1349  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 2.0605  Validation loss = 1.1347  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 2.0600  Validation loss = 1.1327  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 2.0597  Validation loss = 1.1329  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 2.0592  Validation loss = 1.1340  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 2.0589  Validation loss = 1.1350  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 2.0583  Validation loss = 1.1344  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 2.0575  Validation loss = 1.1333  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 2.0567  Validation loss = 1.1330  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 2.0564  Validation loss = 1.1349  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 2.0561  Validation loss = 1.1349  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 2.0550  Validation loss = 1.1331  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 2.0542  Validation loss = 1.1329  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 2.0539  Validation loss = 1.1343  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 2.0534  Validation loss = 1.1351  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 15  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.0430  Validation loss = 2.6607  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.0424  Validation loss = 2.6599  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.0413  Validation loss = 2.6544  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.0407  Validation loss = 2.6513  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 2.0400  Validation loss = 2.6495  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 2.0395  Validation loss = 2.6470  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 2.0385  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 2.0380  Validation loss = 2.6390  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 2.0371  Validation loss = 2.6338  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 2.0364  Validation loss = 2.6284  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 2.0354  Validation loss = 2.6217  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 2.0346  Validation loss = 2.6179  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.0336  Validation loss = 2.6152  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.0331  Validation loss = 2.6129  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.0328  Validation loss = 2.6108  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.0324  Validation loss = 2.6115  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 2.0316  Validation loss = 2.6076  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 2.0308  Validation loss = 2.6030  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 2.0304  Validation loss = 2.6020  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 2.0300  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 2.0285  Validation loss = 2.5975  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.0285  Validation loss = 2.5991  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.0285  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 2.0272  Validation loss = 2.6010  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.0268  Validation loss = 2.6011  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 2.0263  Validation loss = 2.5988  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 2.0258  Validation loss = 2.5966  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 2.0251  Validation loss = 2.5935  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 2.0242  Validation loss = 2.5909  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 2.0239  Validation loss = 2.5902  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 2.0235  Validation loss = 2.5915  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 2.0230  Validation loss = 2.5898  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 2.0228  Validation loss = 2.5892  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 2.0222  Validation loss = 2.5876  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 2.0211  Validation loss = 2.5775  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 2.0198  Validation loss = 2.5714  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 2.0193  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 2.0187  Validation loss = 2.5669  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 2.0176  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 2.0172  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 2.0168  Validation loss = 2.5586  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 2.0166  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 2.0160  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 2.0149  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 2.0138  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 2.0135  Validation loss = 2.5496  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 2.0129  Validation loss = 2.5469  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 2.0125  Validation loss = 2.5474  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 2.0123  Validation loss = 2.5491  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 2.0118  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 2.0114  Validation loss = 2.5472  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 2.0109  Validation loss = 2.5461  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 2.0104  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 2.0101  Validation loss = 2.5457  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 2.0094  Validation loss = 2.5429  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 2.0090  Validation loss = 2.5401  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 2.0087  Validation loss = 2.5417  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 2.0077  Validation loss = 2.5353  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 2.0072  Validation loss = 2.5329  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 2.0069  Validation loss = 2.5302  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 2.0064  Validation loss = 2.5297  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 2.0060  Validation loss = 2.5255  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 2.0056  Validation loss = 2.5260  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 2.0054  Validation loss = 2.5262  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 2.0049  Validation loss = 2.5251  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 2.0047  Validation loss = 2.5257  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 2.0042  Validation loss = 2.5224  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 2.0036  Validation loss = 2.5169  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 2.0034  Validation loss = 2.5168  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 2.0030  Validation loss = 2.5155  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 2.0027  Validation loss = 2.5154  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 2.0024  Validation loss = 2.5124  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 2.0019  Validation loss = 2.5121  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 2.0013  Validation loss = 2.5122  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 2.0009  Validation loss = 2.5120  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 2.0007  Validation loss = 2.5112  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 2.0001  Validation loss = 2.5086  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 2.0000  Validation loss = 2.5105  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 1.9995  Validation loss = 2.5081  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 1.9994  Validation loss = 2.5083  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 1.9992  Validation loss = 2.5077  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 1.9987  Validation loss = 2.5046  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 1.9984  Validation loss = 2.5030  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 1.9980  Validation loss = 2.5003  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 1.9975  Validation loss = 2.5000  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 1.9971  Validation loss = 2.5025  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 1.9968  Validation loss = 2.5031  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 1.9960  Validation loss = 2.4977  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 1.9954  Validation loss = 2.4955  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 1.9949  Validation loss = 2.4952  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 1.9943  Validation loss = 2.4935  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 1.9938  Validation loss = 2.4903  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 1.9931  Validation loss = 2.4874  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 1.9925  Validation loss = 2.4850  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 1.9920  Validation loss = 2.4800  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 1.9917  Validation loss = 2.4793  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 1.9914  Validation loss = 2.4787  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 1.9910  Validation loss = 2.4779  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 1.9908  Validation loss = 2.4754  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 1.9903  Validation loss = 2.4753  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 1.9898  Validation loss = 2.4740  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 1.9893  Validation loss = 2.4738  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 1.9891  Validation loss = 2.4733  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 1.9887  Validation loss = 2.4715  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 1.9882  Validation loss = 2.4694  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 1.9870  Validation loss = 2.4704  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 1.9864  Validation loss = 2.4702  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 1.9859  Validation loss = 2.4696  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 1.9855  Validation loss = 2.4676  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 1.9851  Validation loss = 2.4646  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 1.9849  Validation loss = 2.4638  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 1.9844  Validation loss = 2.4606  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 1.9836  Validation loss = 2.4572  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 1.9834  Validation loss = 2.4562  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 1.9829  Validation loss = 2.4535  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 1.9824  Validation loss = 2.4554  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 1.9819  Validation loss = 2.4554  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 1.9817  Validation loss = 2.4566  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 1.9814  Validation loss = 2.4538  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 1.9810  Validation loss = 2.4565  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 1.9806  Validation loss = 2.4528  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 1.9803  Validation loss = 2.4492  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 1.9800  Validation loss = 2.4520  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 1.9795  Validation loss = 2.4491  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 1.9791  Validation loss = 2.4501  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 1.9787  Validation loss = 2.4483  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 1.9783  Validation loss = 2.4467  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 1.9777  Validation loss = 2.4414  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 1.9775  Validation loss = 2.4392  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 1.9771  Validation loss = 2.4427  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 1.9767  Validation loss = 2.4441  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 1.9761  Validation loss = 2.4433  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 1.9758  Validation loss = 2.4394  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 1.9756  Validation loss = 2.4396  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 1.9749  Validation loss = 2.4373  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 1.9743  Validation loss = 2.4365  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 1.9739  Validation loss = 2.4350  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 1.9733  Validation loss = 2.4323  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 1.9729  Validation loss = 2.4291  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 1.9726  Validation loss = 2.4271  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 1.9719  Validation loss = 2.4258  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 1.9717  Validation loss = 2.4256  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 1.9711  Validation loss = 2.4241  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 1.9708  Validation loss = 2.4221  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 1.9707  Validation loss = 2.4199  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 1.9704  Validation loss = 2.4188  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 1.9699  Validation loss = 2.4204  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 1.9698  Validation loss = 2.4224  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 1.9691  Validation loss = 2.4230  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 1.9691  Validation loss = 2.4259  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 146  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.0530  Validation loss = 6.0844  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.0519  Validation loss = 6.0801  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.0509  Validation loss = 6.0769  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.0498  Validation loss = 6.0720  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.0490  Validation loss = 6.0677  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.0485  Validation loss = 6.0651  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.0480  Validation loss = 6.0623  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.0472  Validation loss = 6.0583  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.0462  Validation loss = 6.0557  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.0453  Validation loss = 6.0518  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.0449  Validation loss = 6.0511  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.0438  Validation loss = 6.0472  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.0431  Validation loss = 6.0437  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.0426  Validation loss = 6.0429  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.0419  Validation loss = 6.0402  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.0419  Validation loss = 6.0399  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.0405  Validation loss = 6.0333  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 2.0401  Validation loss = 6.0316  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.0394  Validation loss = 6.0296  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.0391  Validation loss = 6.0305  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.0388  Validation loss = 6.0288  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 2.0388  Validation loss = 6.0305  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 2.0392  Validation loss = 6.0287  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 2.0380  Validation loss = 6.0272  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 2.0376  Validation loss = 6.0261  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 2.0369  Validation loss = 6.0230  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 2.0364  Validation loss = 6.0210  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 2.0361  Validation loss = 6.0204  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 2.0357  Validation loss = 6.0165  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.0348  Validation loss = 6.0145  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 2.0340  Validation loss = 6.0114  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 2.0339  Validation loss = 6.0106  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 2.0333  Validation loss = 6.0090  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 2.0326  Validation loss = 6.0062  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 2.0324  Validation loss = 6.0045  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 2.0321  Validation loss = 6.0043  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 2.0319  Validation loss = 6.0029  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 2.0316  Validation loss = 6.0015  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 2.0306  Validation loss = 5.9961  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 2.0301  Validation loss = 5.9940  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 2.0292  Validation loss = 5.9897  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 2.0288  Validation loss = 5.9874  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 2.0286  Validation loss = 5.9867  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 2.0280  Validation loss = 5.9871  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 2.0271  Validation loss = 5.9819  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 2.0247  Validation loss = 5.9806  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 2.0194  Validation loss = 5.9771  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 2.0187  Validation loss = 5.9737  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 2.0178  Validation loss = 5.9702  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 2.0167  Validation loss = 5.9650  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 2.0163  Validation loss = 5.9635  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 2.0163  Validation loss = 5.9643  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 2.0158  Validation loss = 5.9616  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 2.0148  Validation loss = 5.9581  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 2.0145  Validation loss = 5.9565  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 2.0141  Validation loss = 5.9542  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 2.0135  Validation loss = 5.9517  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 2.0134  Validation loss = 5.9522  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 2.0126  Validation loss = 5.9491  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 2.0119  Validation loss = 5.9461  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 2.0109  Validation loss = 5.9414  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 2.0102  Validation loss = 5.9389  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 2.0095  Validation loss = 5.9346  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 2.0091  Validation loss = 5.9326  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 2.0085  Validation loss = 5.9301  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 2.0082  Validation loss = 5.9281  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 2.0076  Validation loss = 5.9255  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 2.0069  Validation loss = 5.9233  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 2.0067  Validation loss = 5.9222  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 2.0061  Validation loss = 5.9198  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 2.0057  Validation loss = 5.9183  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 2.0056  Validation loss = 5.9196  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 2.0053  Validation loss = 5.9174  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 2.0047  Validation loss = 5.9147  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 2.0039  Validation loss = 5.9104  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 2.0034  Validation loss = 5.9081  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 2.0027  Validation loss = 5.9060  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 2.0024  Validation loss = 5.9032  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 2.0017  Validation loss = 5.9002  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 2.0013  Validation loss = 5.8982  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 2.0009  Validation loss = 5.8949  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 2.0004  Validation loss = 5.8932  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 2.0002  Validation loss = 5.8910  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 1.9994  Validation loss = 5.8875  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 1.9989  Validation loss = 5.8837  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 1.9982  Validation loss = 5.8805  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 1.9979  Validation loss = 5.8786  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 1.9973  Validation loss = 5.8751  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 1.9969  Validation loss = 5.8725  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 1.9961  Validation loss = 5.8712  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 1.9958  Validation loss = 5.8696  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 1.9947  Validation loss = 5.8678  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 1.9935  Validation loss = 5.8644  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 1.9930  Validation loss = 5.8633  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 1.9926  Validation loss = 5.8609  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 1.9921  Validation loss = 5.8583  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 1.9913  Validation loss = 5.8542  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 1.9909  Validation loss = 5.8530  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 1.9903  Validation loss = 5.8503  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 1.9899  Validation loss = 5.8486  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 1.9890  Validation loss = 5.8455  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 1.9884  Validation loss = 5.8446  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 1.9881  Validation loss = 5.8398  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 1.9872  Validation loss = 5.8378  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 1.9873  Validation loss = 5.8380  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 1.9867  Validation loss = 5.8364  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 1.9857  Validation loss = 5.8311  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 1.9854  Validation loss = 5.8319  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 1.9851  Validation loss = 5.8289  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 1.9848  Validation loss = 5.8287  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 1.9845  Validation loss = 5.8280  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 1.9839  Validation loss = 5.8259  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 1.9830  Validation loss = 5.8216  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 1.9825  Validation loss = 5.8179  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 1.9819  Validation loss = 5.8154  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 1.9818  Validation loss = 5.8158  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 1.9815  Validation loss = 5.8161  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 1.9811  Validation loss = 5.8145  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 1.9803  Validation loss = 5.8095  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 1.9796  Validation loss = 5.8068  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 1.9792  Validation loss = 5.8050  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 1.9789  Validation loss = 5.8045  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 1.9786  Validation loss = 5.8037  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 1.9784  Validation loss = 5.8022  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 1.9776  Validation loss = 5.7992  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 1.9771  Validation loss = 5.7973  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 1.9764  Validation loss = 5.7930  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 1.9764  Validation loss = 5.7941  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 1.9761  Validation loss = 5.7910  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 1.9756  Validation loss = 5.7882  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 1.9756  Validation loss = 5.7883  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 1.9754  Validation loss = 5.7871  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 1.9751  Validation loss = 5.7862  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 1.9748  Validation loss = 5.7838  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 1.9744  Validation loss = 5.7802  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 1.9738  Validation loss = 5.7793  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 1.9737  Validation loss = 5.7776  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 1.9735  Validation loss = 5.7758  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 1.9733  Validation loss = 5.7758  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 1.9728  Validation loss = 5.7709  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 1.9724  Validation loss = 5.7711  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 1.9722  Validation loss = 5.7703  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 1.9718  Validation loss = 5.7691  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 1.9713  Validation loss = 5.7681  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 1.9708  Validation loss = 5.7678  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 1.9706  Validation loss = 5.7687  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 1.9703  Validation loss = 5.7686  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 1.9697  Validation loss = 5.7647  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 1.9689  Validation loss = 5.7600  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 1.9685  Validation loss = 5.7592  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 1.9678  Validation loss = 5.7549  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 1.9674  Validation loss = 5.7520  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 1.9671  Validation loss = 5.7509  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 1.9671  Validation loss = 5.7512  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 1.9668  Validation loss = 5.7499  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 1.9662  Validation loss = 5.7440  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 1.9660  Validation loss = 5.7423  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 1.9657  Validation loss = 5.7392  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 1.9653  Validation loss = 5.7390  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 1.9648  Validation loss = 5.7374  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 1.9643  Validation loss = 5.7347  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 1.9638  Validation loss = 5.7304  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 1.9633  Validation loss = 5.7276  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 1.9628  Validation loss = 5.7260  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 1.9623  Validation loss = 5.7260  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 1.9615  Validation loss = 5.7210  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 1.9613  Validation loss = 5.7200  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 1.9610  Validation loss = 5.7196  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 1.9605  Validation loss = 5.7185  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 1.9599  Validation loss = 5.7154  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 1.9598  Validation loss = 5.7160  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 1.9596  Validation loss = 5.7146  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 1.9587  Validation loss = 5.7101  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 1.9585  Validation loss = 5.7090  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 1.9579  Validation loss = 5.7070  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 1.9576  Validation loss = 5.7043  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 1.9568  Validation loss = 5.7002  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 1.9565  Validation loss = 5.6983  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 1.9563  Validation loss = 5.6969  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 1.9560  Validation loss = 5.6952  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 1.9558  Validation loss = 5.6958  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 1.9556  Validation loss = 5.6950  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 1.9553  Validation loss = 5.6944  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 1.9550  Validation loss = 5.6908  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 1.9547  Validation loss = 5.6909  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 1.9543  Validation loss = 5.6886  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 1.9538  Validation loss = 5.6865  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 1.9533  Validation loss = 5.6837  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 1.9534  Validation loss = 5.6848  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 1.9527  Validation loss = 5.6805  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 1.9524  Validation loss = 5.6785  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 1.9520  Validation loss = 5.6777  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 1.9517  Validation loss = 5.6745  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 1.9514  Validation loss = 5.6742  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 1.9513  Validation loss = 5.6734  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 1.9513  Validation loss = 5.6747  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 1.9509  Validation loss = 5.6721  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 1.9506  Validation loss = 5.6717  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 1.9506  Validation loss = 5.6731  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 1.9505  Validation loss = 5.6719  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 1.9502  Validation loss = 5.6696  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 1.9497  Validation loss = 5.6677  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 1.9492  Validation loss = 5.6659  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 1.9489  Validation loss = 5.6649  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 1.9483  Validation loss = 5.6604  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 1.9481  Validation loss = 5.6589  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 1.9474  Validation loss = 5.6543  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 1.9471  Validation loss = 5.6528  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 1.9468  Validation loss = 5.6498  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 1.9465  Validation loss = 5.6487  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 1.9462  Validation loss = 5.6485  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 1.9461  Validation loss = 5.6479  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 1.9459  Validation loss = 5.6460  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 1.9457  Validation loss = 5.6439  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 1.9454  Validation loss = 5.6437  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 1.9448  Validation loss = 5.6397  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 1.9445  Validation loss = 5.6372  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 1.9441  Validation loss = 5.6359  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 1.9439  Validation loss = 5.6355  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 1.9435  Validation loss = 5.6344  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 1.9430  Validation loss = 5.6319  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 1.9426  Validation loss = 5.6307  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 1.9425  Validation loss = 5.6323  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 1.9424  Validation loss = 5.6323  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 1.9422  Validation loss = 5.6314  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 1.9420  Validation loss = 5.6290  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 1.9422  Validation loss = 5.6291  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 1.9416  Validation loss = 5.6269  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 1.9412  Validation loss = 5.6249  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 1.9413  Validation loss = 5.6248  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 1.9409  Validation loss = 5.6233  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 1.9403  Validation loss = 5.6214  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 1.9395  Validation loss = 5.6162  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 1.9394  Validation loss = 5.6164  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 1.9392  Validation loss = 5.6155  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 1.9389  Validation loss = 5.6129  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 1.9381  Validation loss = 5.6070  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 1.9376  Validation loss = 5.6042  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 1.9374  Validation loss = 5.6018  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 1.9370  Validation loss = 5.6005  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 1.9369  Validation loss = 5.5999  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 1.9367  Validation loss = 5.5979  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 1.9362  Validation loss = 5.5951  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 1.9359  Validation loss = 5.5925  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 1.9357  Validation loss = 5.5954  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 1.9354  Validation loss = 5.5916  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 1.9352  Validation loss = 5.5914  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 1.9348  Validation loss = 5.5898  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 1.9347  Validation loss = 5.5888  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 1.9345  Validation loss = 5.5883  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 1.9341  Validation loss = 5.5887  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 1.9338  Validation loss = 5.5837  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 1.9333  Validation loss = 5.5843  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 1.9329  Validation loss = 5.5816  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 1.9329  Validation loss = 5.5799  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 1.9326  Validation loss = 5.5762  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 1.9321  Validation loss = 5.5742  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 1.9316  Validation loss = 5.5746  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 1.9311  Validation loss = 5.5712  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 1.9310  Validation loss = 5.5694  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 1.9308  Validation loss = 5.5666  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 1.9305  Validation loss = 5.5636  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 1.9301  Validation loss = 5.5617  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 1.9300  Validation loss = 5.5615  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 1.9294  Validation loss = 5.5571  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 1.9292  Validation loss = 5.5556  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 1.9285  Validation loss = 5.5529  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 1.9282  Validation loss = 5.5520  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 1.9281  Validation loss = 5.5516  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 1.9279  Validation loss = 5.5479  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 1.9274  Validation loss = 5.5451  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 1.9267  Validation loss = 5.5438  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 1.9265  Validation loss = 5.5402  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 1.9261  Validation loss = 5.5394  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 1.9259  Validation loss = 5.5381  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 1.9256  Validation loss = 5.5356  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 1.9251  Validation loss = 5.5339  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 1.9247  Validation loss = 5.5321  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 1.9246  Validation loss = 5.5282  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 1.9244  Validation loss = 5.5260  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 1.9243  Validation loss = 5.5274  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 1.9238  Validation loss = 5.5246  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 1.9234  Validation loss = 5.5230  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 1.9233  Validation loss = 5.5213  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 1.9229  Validation loss = 5.5188  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 1.9225  Validation loss = 5.5172  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 1.9220  Validation loss = 5.5105  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 1.9218  Validation loss = 5.5081  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 1.9217  Validation loss = 5.5049  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 1.9216  Validation loss = 5.5029  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 1.9214  Validation loss = 5.4994  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 1.9213  Validation loss = 5.4960  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 1.9208  Validation loss = 5.4980  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 1.9201  Validation loss = 5.4949  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 1.9196  Validation loss = 5.4948  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 1.9193  Validation loss = 5.4964  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 1.9190  Validation loss = 5.4946  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 1.9188  Validation loss = 5.4920  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 1.9184  Validation loss = 5.4920  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 1.9179  Validation loss = 5.4910  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 1.9178  Validation loss = 5.4895  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 1.9178  Validation loss = 5.4903  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 1.9182  Validation loss = 5.4913  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 1.9171  Validation loss = 5.4892  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 1.9164  Validation loss = 5.4842  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 1.9162  Validation loss = 5.4828  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 1.9160  Validation loss = 5.4828  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 1.9154  Validation loss = 5.4813  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 1.9151  Validation loss = 5.4802  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 1.9145  Validation loss = 5.4776  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 1.9144  Validation loss = 5.4747  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 1.9143  Validation loss = 5.4763  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 1.9140  Validation loss = 5.4742  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 1.9135  Validation loss = 5.4720  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 1.9129  Validation loss = 5.4686  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 1.9126  Validation loss = 5.4663  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 1.9125  Validation loss = 5.4644  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 1.9123  Validation loss = 5.4629  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 1.9124  Validation loss = 5.4627  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 1.9124  Validation loss = 5.4600  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 1.9118  Validation loss = 5.4565  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 1.9116  Validation loss = 5.4567  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 1.9111  Validation loss = 5.4553  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 1.9109  Validation loss = 5.4551  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 1.9105  Validation loss = 5.4556  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 1.9102  Validation loss = 5.4517  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 1.9100  Validation loss = 5.4485  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 1.9098  Validation loss = 5.4467  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 1.9097  Validation loss = 5.4421  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 1.9094  Validation loss = 5.4374  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 1.9087  Validation loss = 5.4372  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 1.9084  Validation loss = 5.4369  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 1.9081  Validation loss = 5.4345  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 1.9078  Validation loss = 5.4366  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 1.9081  Validation loss = 5.4348  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 1.9083  Validation loss = 5.4315  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 1.9077  Validation loss = 5.4318  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 1.9074  Validation loss = 5.4316  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 1.9073  Validation loss = 5.4293  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 1.9071  Validation loss = 5.4266  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 1.9073  Validation loss = 5.4253  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 1.9066  Validation loss = 5.4261  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 1.9059  Validation loss = 5.4254  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 1.9056  Validation loss = 5.4253  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 1.9052  Validation loss = 5.4240  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 1.9049  Validation loss = 5.4247  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 1.9045  Validation loss = 5.4256  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 1.9043  Validation loss = 5.4227  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 1.9040  Validation loss = 5.4204  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 1.9039  Validation loss = 5.4175  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 1.9033  Validation loss = 5.4159  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 1.9027  Validation loss = 5.4163  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 1.9016  Validation loss = 5.4142  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 1.9003  Validation loss = 5.4122  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 1.8997  Validation loss = 5.4126  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 1.8993  Validation loss = 5.4115  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 1.8989  Validation loss = 5.4097  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 1.8986  Validation loss = 5.4081  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 1.8983  Validation loss = 5.4076  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 1.8981  Validation loss = 5.4082  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 1.8978  Validation loss = 5.4064  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 1.8978  Validation loss = 5.4066  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 1.8973  Validation loss = 5.4024  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 1.8970  Validation loss = 5.4015  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 1.8969  Validation loss = 5.4015  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 1.8968  Validation loss = 5.3977  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 1.8962  Validation loss = 5.3947  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 1.8959  Validation loss = 5.3927  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 1.8957  Validation loss = 5.3936  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 1.8953  Validation loss = 5.3903  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 1.8954  Validation loss = 5.3925  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 1.8949  Validation loss = 5.3897  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 1.8946  Validation loss = 5.3882  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 1.8942  Validation loss = 5.3847  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 1.8942  Validation loss = 5.3855  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 1.8937  Validation loss = 5.3816  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 1.8932  Validation loss = 5.3765  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 1.8936  Validation loss = 5.3805  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 1.8930  Validation loss = 5.3778  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 1.8934  Validation loss = 5.3783  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 1.8930  Validation loss = 5.3769  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 1.8950  Validation loss = 5.3798  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 1.8932  Validation loss = 5.3800  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 1.8930  Validation loss = 5.3788  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 1.8922  Validation loss = 5.3742  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 1.8919  Validation loss = 5.3717  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 1.8919  Validation loss = 5.3723  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 1.8916  Validation loss = 5.3706  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 1.8913  Validation loss = 5.3685  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 1.8908  Validation loss = 5.3663  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 1.8908  Validation loss = 5.3656  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 1.8908  Validation loss = 5.3658  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 1.8909  Validation loss = 5.3651  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 1.8900  Validation loss = 5.3609  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 1.8890  Validation loss = 5.3560  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 1.8890  Validation loss = 5.3568  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 1.8890  Validation loss = 5.3572  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 1.8893  Validation loss = 5.3578  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 1.8885  Validation loss = 5.3532  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 1.8881  Validation loss = 5.3514  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 1.8876  Validation loss = 5.3484  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 1.8872  Validation loss = 5.3474  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 1.8868  Validation loss = 5.3442  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 1.8865  Validation loss = 5.3421  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 1.8864  Validation loss = 5.3418  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 1.8860  Validation loss = 5.3401  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 1.8861  Validation loss = 5.3422  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 1.8859  Validation loss = 5.3413  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 1.8858  Validation loss = 5.3413  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 1.8855  Validation loss = 5.3390  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 1.8852  Validation loss = 5.3351  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 1.8847  Validation loss = 5.3347  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 1.8846  Validation loss = 5.3312  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 1.8844  Validation loss = 5.3295  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 1.8840  Validation loss = 5.3287  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 1.8837  Validation loss = 5.3270  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 1.8832  Validation loss = 5.3225  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 1.8831  Validation loss = 5.3206  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 1.8828  Validation loss = 5.3213  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 1.8823  Validation loss = 5.3169  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 1.8820  Validation loss = 5.3135  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 1.8819  Validation loss = 5.3115  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 1.8819  Validation loss = 5.3132  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 1.8816  Validation loss = 5.3107  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 1.8813  Validation loss = 5.3070  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 1.8810  Validation loss = 5.3036  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 1.8807  Validation loss = 5.3044  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 1.8802  Validation loss = 5.3036  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 1.8802  Validation loss = 5.3041  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 1.8797  Validation loss = 5.3009  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 1.8794  Validation loss = 5.2990  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 1.8793  Validation loss = 5.3000  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 1.8793  Validation loss = 5.2998  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 1.8788  Validation loss = 5.2971  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 1.8786  Validation loss = 5.2966  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 1.8786  Validation loss = 5.2970  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 1.8787  Validation loss = 5.2970  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 1.8785  Validation loss = 5.2969  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 1.8779  Validation loss = 5.2942  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 1.8777  Validation loss = 5.2926  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 1.8774  Validation loss = 5.2920  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 1.8770  Validation loss = 5.2898  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 1.8767  Validation loss = 5.2871  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 1.8773  Validation loss = 5.2911  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 1.8773  Validation loss = 5.2908  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 1.8768  Validation loss = 5.2885  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 1.8769  Validation loss = 5.2878  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 1.8762  Validation loss = 5.2832  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 1.8759  Validation loss = 5.2816  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 1.8753  Validation loss = 5.2795  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 1.8752  Validation loss = 5.2790  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 1.8749  Validation loss = 5.2773  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 1.8749  Validation loss = 5.2770  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 1.8748  Validation loss = 5.2777  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 1.8745  Validation loss = 5.2756  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 1.8740  Validation loss = 5.2724  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 1.8737  Validation loss = 5.2698  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 1.8734  Validation loss = 5.2666  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 1.8733  Validation loss = 5.2681  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 1.8730  Validation loss = 5.2662  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 1.8727  Validation loss = 5.2645  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 1.8725  Validation loss = 5.2612  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 1.8724  Validation loss = 5.2609  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 1.8721  Validation loss = 5.2590  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 1.8720  Validation loss = 5.2605  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 1.8719  Validation loss = 5.2606  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 1.8717  Validation loss = 5.2595  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 1.8714  Validation loss = 5.2578  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 1.8710  Validation loss = 5.2554  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 1.8708  Validation loss = 5.2534  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 1.8706  Validation loss = 5.2521  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 1.8705  Validation loss = 5.2508  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 1.8703  Validation loss = 5.2497  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 1.8699  Validation loss = 5.2473  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 1.8698  Validation loss = 5.2461  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 1.8697  Validation loss = 5.2443  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 1.8696  Validation loss = 5.2428  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 1.8695  Validation loss = 5.2433  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 1.8695  Validation loss = 5.2431  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 1.8694  Validation loss = 5.2429  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 1.8690  Validation loss = 5.2384  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 1.8690  Validation loss = 5.2350  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 1.8687  Validation loss = 5.2354  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 1.8684  Validation loss = 5.2346  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 1.8681  Validation loss = 5.2324  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 1.8679  Validation loss = 5.2320  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 1.8677  Validation loss = 5.2308  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 1.8676  Validation loss = 5.2318  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 1.8672  Validation loss = 5.2291  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 1.8671  Validation loss = 5.2251  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 1.8671  Validation loss = 5.2225  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 1.8668  Validation loss = 5.2223  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 1.8668  Validation loss = 5.2226  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 1.8664  Validation loss = 5.2213  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 1.8662  Validation loss = 5.2219  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 1.8660  Validation loss = 5.2222  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 1.8657  Validation loss = 5.2202  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 1.8656  Validation loss = 5.2180  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 1.8653  Validation loss = 5.2156  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 1.8649  Validation loss = 5.2150  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.2580  Validation loss = 5.4256  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.2572  Validation loss = 5.4248  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.2562  Validation loss = 5.4212  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.2556  Validation loss = 5.4195  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.2548  Validation loss = 5.4161  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.2536  Validation loss = 5.4141  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.2532  Validation loss = 5.4134  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.2524  Validation loss = 5.4112  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.2515  Validation loss = 5.4037  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.2508  Validation loss = 5.4023  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.2502  Validation loss = 5.4002  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.2490  Validation loss = 5.3973  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.2482  Validation loss = 5.3964  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.2472  Validation loss = 5.3937  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.2463  Validation loss = 5.3920  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.2453  Validation loss = 5.3903  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.2442  Validation loss = 5.3869  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.2432  Validation loss = 5.3844  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.2450  Validation loss = 5.3843  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.2415  Validation loss = 5.3817  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.2406  Validation loss = 5.3788  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.2397  Validation loss = 5.3747  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.2392  Validation loss = 5.3737  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.2385  Validation loss = 5.3700  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.2378  Validation loss = 5.3677  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 2.2370  Validation loss = 5.3667  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.2355  Validation loss = 5.3614  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 2.2349  Validation loss = 5.3590  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 2.2342  Validation loss = 5.3563  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 2.2336  Validation loss = 5.3510  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 2.2324  Validation loss = 5.3453  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.2320  Validation loss = 5.3425  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 2.2322  Validation loss = 5.3400  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 2.2307  Validation loss = 5.3400  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 2.2301  Validation loss = 5.3381  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 2.2297  Validation loss = 5.3354  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 2.2289  Validation loss = 5.3351  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 2.2286  Validation loss = 5.3337  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 2.2275  Validation loss = 5.3306  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 2.2270  Validation loss = 5.3233  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 2.2258  Validation loss = 5.3219  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 2.2250  Validation loss = 5.3192  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 2.2243  Validation loss = 5.3143  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 2.2234  Validation loss = 5.3115  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 2.2227  Validation loss = 5.3099  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 2.2219  Validation loss = 5.3072  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 2.2217  Validation loss = 5.3047  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 2.2207  Validation loss = 5.3015  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 2.2202  Validation loss = 5.2987  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 2.2181  Validation loss = 5.2985  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 2.2174  Validation loss = 5.2949  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 2.2165  Validation loss = 5.2902  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 2.2158  Validation loss = 5.2897  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 2.2147  Validation loss = 5.2864  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 2.2139  Validation loss = 5.2838  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 2.2124  Validation loss = 5.2791  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 2.2121  Validation loss = 5.2779  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 2.2115  Validation loss = 5.2753  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 2.2109  Validation loss = 5.2770  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 2.2101  Validation loss = 5.2741  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 2.2103  Validation loss = 5.2749  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 2.2094  Validation loss = 5.2739  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 2.2088  Validation loss = 5.2730  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 2.2075  Validation loss = 5.2702  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 2.2058  Validation loss = 5.2640  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 2.2048  Validation loss = 5.2611  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 2.2044  Validation loss = 5.2601  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 2.2041  Validation loss = 5.2594  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 2.2030  Validation loss = 5.2563  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 2.2025  Validation loss = 5.2549  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 2.2010  Validation loss = 5.2511  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 2.2003  Validation loss = 5.2488  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 2.1992  Validation loss = 5.2448  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 2.1983  Validation loss = 5.2423  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 2.1975  Validation loss = 5.2400  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 2.1970  Validation loss = 5.2391  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 2.1960  Validation loss = 5.2342  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 2.1954  Validation loss = 5.2321  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 2.1948  Validation loss = 5.2283  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 2.1939  Validation loss = 5.2265  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 2.1932  Validation loss = 5.2212  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 2.1923  Validation loss = 5.2188  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 2.1914  Validation loss = 5.2157  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 2.1902  Validation loss = 5.2106  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 2.1895  Validation loss = 5.2073  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 2.1890  Validation loss = 5.2029  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 2.1889  Validation loss = 5.2012  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 2.1875  Validation loss = 5.2001  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 2.1869  Validation loss = 5.1997  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 2.1858  Validation loss = 5.1964  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 2.1856  Validation loss = 5.1956  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 2.1848  Validation loss = 5.1922  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 2.1838  Validation loss = 5.1903  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 2.1831  Validation loss = 5.1891  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 2.1823  Validation loss = 5.1861  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 2.1816  Validation loss = 5.1831  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 2.1810  Validation loss = 5.1816  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 2.1806  Validation loss = 5.1802  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 2.1797  Validation loss = 5.1761  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 2.1789  Validation loss = 5.1721  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 2.1779  Validation loss = 5.1693  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 2.1773  Validation loss = 5.1669  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 2.1768  Validation loss = 5.1651  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 2.1758  Validation loss = 5.1628  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 2.1752  Validation loss = 5.1605  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 2.1748  Validation loss = 5.1604  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 2.1740  Validation loss = 5.1577  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 2.1737  Validation loss = 5.1544  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 2.1728  Validation loss = 5.1470  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 2.1725  Validation loss = 5.1431  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 2.1715  Validation loss = 5.1433  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 2.1701  Validation loss = 5.1380  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 2.1698  Validation loss = 5.1347  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 2.1685  Validation loss = 5.1347  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 2.1678  Validation loss = 5.1306  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 2.1668  Validation loss = 5.1300  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 2.1663  Validation loss = 5.1257  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 2.1657  Validation loss = 5.1221  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 2.1650  Validation loss = 5.1230  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 2.1642  Validation loss = 5.1216  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 2.1637  Validation loss = 5.1167  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 2.1633  Validation loss = 5.1158  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 2.1629  Validation loss = 5.1173  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 2.1623  Validation loss = 5.1169  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 2.1620  Validation loss = 5.1154  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 2.1609  Validation loss = 5.1113  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 2.1606  Validation loss = 5.1089  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 2.1600  Validation loss = 5.1070  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 2.1596  Validation loss = 5.1048  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 2.1589  Validation loss = 5.1034  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 2.1582  Validation loss = 5.1017  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 2.1579  Validation loss = 5.0979  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 2.1567  Validation loss = 5.0930  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 2.1564  Validation loss = 5.0897  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 2.1556  Validation loss = 5.0899  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 2.1548  Validation loss = 5.0844  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 2.1543  Validation loss = 5.0844  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 2.1538  Validation loss = 5.0791  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 2.1530  Validation loss = 5.0761  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 2.1526  Validation loss = 5.0768  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 2.1521  Validation loss = 5.0739  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 2.1510  Validation loss = 5.0707  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 2.1501  Validation loss = 5.0685  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 2.1495  Validation loss = 5.0668  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 2.1490  Validation loss = 5.0658  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 2.1485  Validation loss = 5.0637  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 2.1480  Validation loss = 5.0612  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 2.1480  Validation loss = 5.0587  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 2.1469  Validation loss = 5.0558  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 2.1462  Validation loss = 5.0540  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 2.1452  Validation loss = 5.0501  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 2.1438  Validation loss = 5.0462  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 2.1431  Validation loss = 5.0449  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 2.1423  Validation loss = 5.0421  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 2.1412  Validation loss = 5.0390  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 2.1408  Validation loss = 5.0389  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 2.1405  Validation loss = 5.0383  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 2.1403  Validation loss = 5.0380  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 2.1395  Validation loss = 5.0350  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 2.1392  Validation loss = 5.0344  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 2.1385  Validation loss = 5.0319  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 2.1386  Validation loss = 5.0311  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 2.1378  Validation loss = 5.0301  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 2.1369  Validation loss = 5.0261  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 2.1364  Validation loss = 5.0243  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 2.1356  Validation loss = 5.0215  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 2.1349  Validation loss = 5.0187  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 2.1343  Validation loss = 5.0155  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 2.1334  Validation loss = 5.0109  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 2.1332  Validation loss = 5.0097  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 2.1327  Validation loss = 5.0059  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 2.1328  Validation loss = 4.9967  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 2.1334  Validation loss = 4.9922  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 2.1332  Validation loss = 4.9908  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 2.1324  Validation loss = 4.9877  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 2.1332  Validation loss = 4.9821  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 2.1317  Validation loss = 4.9801  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 2.1308  Validation loss = 4.9781  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 2.1313  Validation loss = 4.9765  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 2.1320  Validation loss = 4.9732  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 2.1315  Validation loss = 4.9710  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 2.1308  Validation loss = 4.9674  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 2.1294  Validation loss = 4.9633  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 2.1273  Validation loss = 4.9636  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 2.1255  Validation loss = 4.9630  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 2.1250  Validation loss = 4.9621  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 2.1244  Validation loss = 4.9582  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 2.1251  Validation loss = 4.9547  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 2.1238  Validation loss = 4.9532  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 2.1227  Validation loss = 4.9492  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 2.1214  Validation loss = 4.9457  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 2.1201  Validation loss = 4.9437  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 2.1195  Validation loss = 4.9432  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 2.1187  Validation loss = 4.9400  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 2.1184  Validation loss = 4.9393  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 2.1174  Validation loss = 4.9380  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 2.1166  Validation loss = 4.9392  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 2.1159  Validation loss = 4.9383  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 2.1156  Validation loss = 4.9367  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 2.1150  Validation loss = 4.9341  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 2.1144  Validation loss = 4.9329  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 2.1141  Validation loss = 4.9323  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 2.1137  Validation loss = 4.9301  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 2.1133  Validation loss = 4.9304  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 2.1128  Validation loss = 4.9289  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 2.1123  Validation loss = 4.9265  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 2.1118  Validation loss = 4.9261  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 2.1114  Validation loss = 4.9243  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 2.1109  Validation loss = 4.9218  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 2.1110  Validation loss = 4.9235  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 2.1099  Validation loss = 4.9187  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 2.1101  Validation loss = 4.9201  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 2.1098  Validation loss = 4.9190  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 2.1095  Validation loss = 4.9181  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 2.1090  Validation loss = 4.9160  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 2.1084  Validation loss = 4.9125  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 2.1081  Validation loss = 4.9116  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 2.1068  Validation loss = 4.9054  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 2.1065  Validation loss = 4.9049  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 2.1059  Validation loss = 4.9020  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 2.1053  Validation loss = 4.8995  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 2.1042  Validation loss = 4.8940  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 2.1040  Validation loss = 4.8934  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 2.1042  Validation loss = 4.8940  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 2.1033  Validation loss = 4.8917  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 2.1034  Validation loss = 4.8921  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 2.1028  Validation loss = 4.8903  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 2.1018  Validation loss = 4.8860  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 2.1010  Validation loss = 4.8816  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 2.1004  Validation loss = 4.8783  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 2.1003  Validation loss = 4.8784  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 2.0996  Validation loss = 4.8752  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 2.0989  Validation loss = 4.8712  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 2.0984  Validation loss = 4.8691  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 2.0976  Validation loss = 4.8641  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 2.0972  Validation loss = 4.8620  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 2.0964  Validation loss = 4.8589  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 2.0959  Validation loss = 4.8565  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 2.0953  Validation loss = 4.8536  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 2.0949  Validation loss = 4.8522  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 2.0946  Validation loss = 4.8515  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 2.0937  Validation loss = 4.8466  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 2.0931  Validation loss = 4.8428  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 2.0926  Validation loss = 4.8413  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 2.0922  Validation loss = 4.8390  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 2.0920  Validation loss = 4.8360  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 2.0915  Validation loss = 4.8335  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 2.0909  Validation loss = 4.8294  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 2.0911  Validation loss = 4.8270  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 2.0907  Validation loss = 4.8250  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 2.0903  Validation loss = 4.8232  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 2.0896  Validation loss = 4.8221  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 2.0890  Validation loss = 4.8208  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 2.0879  Validation loss = 4.8168  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 2.0875  Validation loss = 4.8163  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 2.0867  Validation loss = 4.8145  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 2.0861  Validation loss = 4.8135  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 2.0856  Validation loss = 4.8104  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 2.0853  Validation loss = 4.8085  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 2.0858  Validation loss = 4.8134  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 2.0857  Validation loss = 4.8122  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 2.0848  Validation loss = 4.8100  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 2.0844  Validation loss = 4.8087  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 2.0843  Validation loss = 4.8083  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 2.0839  Validation loss = 4.8064  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 2.0834  Validation loss = 4.8033  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 2.0831  Validation loss = 4.8021  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 2.0825  Validation loss = 4.7990  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 2.0822  Validation loss = 4.7971  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 2.0819  Validation loss = 4.7954  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 2.0817  Validation loss = 4.7943  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 2.0820  Validation loss = 4.7954  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 2.0821  Validation loss = 4.7945  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 2.0812  Validation loss = 4.7912  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 2.0811  Validation loss = 4.7907  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 2.0808  Validation loss = 4.7899  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 2.0802  Validation loss = 4.7861  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 2.0798  Validation loss = 4.7847  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 2.0802  Validation loss = 4.7859  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 2.0798  Validation loss = 4.7842  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 2.0794  Validation loss = 4.7830  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 2.0797  Validation loss = 4.7837  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 2.0793  Validation loss = 4.7820  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 2.0791  Validation loss = 4.7802  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 2.0774  Validation loss = 4.7742  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 2.0775  Validation loss = 4.7735  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 2.0758  Validation loss = 4.7679  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 2.0748  Validation loss = 4.7633  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 2.0739  Validation loss = 4.7593  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 2.0733  Validation loss = 4.7562  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 2.0726  Validation loss = 4.7526  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 2.0725  Validation loss = 4.7537  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 2.0719  Validation loss = 4.7517  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 2.0713  Validation loss = 4.7481  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 2.0713  Validation loss = 4.7469  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 2.0711  Validation loss = 4.7456  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 2.0708  Validation loss = 4.7451  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 2.0706  Validation loss = 4.7427  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 2.0705  Validation loss = 4.7403  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 2.0703  Validation loss = 4.7390  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 2.0702  Validation loss = 4.7400  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 2.0693  Validation loss = 4.7372  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 2.0689  Validation loss = 4.7364  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 2.0681  Validation loss = 4.7353  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 2.0676  Validation loss = 4.7320  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 2.0675  Validation loss = 4.7307  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 2.0666  Validation loss = 4.7295  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 2.0662  Validation loss = 4.7259  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 2.0660  Validation loss = 4.7271  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 2.0658  Validation loss = 4.7254  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 2.0653  Validation loss = 4.7260  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 2.0650  Validation loss = 4.7254  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 2.0649  Validation loss = 4.7218  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 2.0643  Validation loss = 4.7195  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 2.0640  Validation loss = 4.7214  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 2.0638  Validation loss = 4.7163  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 2.0635  Validation loss = 4.7174  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 2.0634  Validation loss = 4.7180  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 2.0634  Validation loss = 4.7186  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 2.0630  Validation loss = 4.7178  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 2.0627  Validation loss = 4.7173  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 2.0621  Validation loss = 4.7143  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 2.0615  Validation loss = 4.7106  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 2.0611  Validation loss = 4.7088  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 2.0606  Validation loss = 4.7072  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 2.0602  Validation loss = 4.7034  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 2.0597  Validation loss = 4.7003  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 2.0597  Validation loss = 4.6975  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 2.0592  Validation loss = 4.6976  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 2.0588  Validation loss = 4.6964  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 2.0584  Validation loss = 4.6944  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 2.0581  Validation loss = 4.6951  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 2.0571  Validation loss = 4.6910  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 2.0538  Validation loss = 4.6859  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 2.0535  Validation loss = 4.6862  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 2.0528  Validation loss = 4.6820  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 2.0523  Validation loss = 4.6805  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 2.0514  Validation loss = 4.6747  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 2.0511  Validation loss = 4.6732  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 2.0506  Validation loss = 4.6724  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 2.0500  Validation loss = 4.6695  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 2.0498  Validation loss = 4.6684  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 2.0496  Validation loss = 4.6685  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 2.0496  Validation loss = 4.6684  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 2.0489  Validation loss = 4.6635  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 2.0486  Validation loss = 4.6629  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 2.0482  Validation loss = 4.6611  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 2.0480  Validation loss = 4.6605  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 2.0474  Validation loss = 4.6586  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 2.0468  Validation loss = 4.6559  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 2.0460  Validation loss = 4.6526  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 2.0453  Validation loss = 4.6484  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 2.0450  Validation loss = 4.6473  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 2.0448  Validation loss = 4.6475  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 2.0442  Validation loss = 4.6448  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 2.0436  Validation loss = 4.6422  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 2.0434  Validation loss = 4.6426  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 2.0427  Validation loss = 4.6390  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 2.0422  Validation loss = 4.6371  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 2.0418  Validation loss = 4.6359  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 2.0410  Validation loss = 4.6293  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 2.0408  Validation loss = 4.6288  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 2.0404  Validation loss = 4.6256  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 2.0399  Validation loss = 4.6245  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 2.0394  Validation loss = 4.6251  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 2.0389  Validation loss = 4.6220  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 2.0385  Validation loss = 4.6195  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 2.0382  Validation loss = 4.6159  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 2.0382  Validation loss = 4.6177  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 2.0384  Validation loss = 4.6143  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 2.0384  Validation loss = 4.6122  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 2.0381  Validation loss = 4.6098  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 2.0375  Validation loss = 4.6074  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 2.0374  Validation loss = 4.6070  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 2.0364  Validation loss = 4.6094  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 2.0355  Validation loss = 4.6069  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 2.0350  Validation loss = 4.6041  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 2.0345  Validation loss = 4.6011  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 2.0341  Validation loss = 4.5988  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 2.0339  Validation loss = 4.5981  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 2.0332  Validation loss = 4.5935  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 2.0327  Validation loss = 4.5921  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 2.0325  Validation loss = 4.5876  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 2.0317  Validation loss = 4.5858  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 2.0310  Validation loss = 4.5864  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 2.0311  Validation loss = 4.5824  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 2.0307  Validation loss = 4.5841  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 2.0304  Validation loss = 4.5807  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 2.0306  Validation loss = 4.5805  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 2.0301  Validation loss = 4.5784  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 2.0293  Validation loss = 4.5780  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 2.0289  Validation loss = 4.5772  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 2.0281  Validation loss = 4.5749  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 2.0278  Validation loss = 4.5734  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 2.0279  Validation loss = 4.5701  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 2.0274  Validation loss = 4.5694  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 2.0271  Validation loss = 4.5689  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 2.0269  Validation loss = 4.5677  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 2.0268  Validation loss = 4.5664  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 2.0265  Validation loss = 4.5651  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 2.0261  Validation loss = 4.5658  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 2.0257  Validation loss = 4.5644  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 2.0256  Validation loss = 4.5638  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 2.0253  Validation loss = 4.5612  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 2.0252  Validation loss = 4.5575  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 2.0243  Validation loss = 4.5578  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 2.0240  Validation loss = 4.5589  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 2.0235  Validation loss = 4.5564  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 2.0231  Validation loss = 4.5550  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 2.0226  Validation loss = 4.5528  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 2.0222  Validation loss = 4.5528  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 2.0217  Validation loss = 4.5508  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 2.0213  Validation loss = 4.5495  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 2.0212  Validation loss = 4.5499  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 2.0203  Validation loss = 4.5454  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 2.0195  Validation loss = 4.5401  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 2.0192  Validation loss = 4.5368  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 2.0187  Validation loss = 4.5352  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 2.0183  Validation loss = 4.5327  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 2.0184  Validation loss = 4.5299  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 2.0181  Validation loss = 4.5266  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 2.0176  Validation loss = 4.5243  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 2.0171  Validation loss = 4.5244  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 2.0167  Validation loss = 4.5247  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 2.0167  Validation loss = 4.5274  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 2.0160  Validation loss = 4.5264  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 2.0162  Validation loss = 4.5271  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 2.0157  Validation loss = 4.5263  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 2.0156  Validation loss = 4.5257  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 2.0154  Validation loss = 4.5257  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 2.0154  Validation loss = 4.5261  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 2.0149  Validation loss = 4.5234  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 2.0146  Validation loss = 4.5228  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 2.0141  Validation loss = 4.5181  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 2.0135  Validation loss = 4.5154  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 2.0132  Validation loss = 4.5144  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 2.0131  Validation loss = 4.5114  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 2.0129  Validation loss = 4.5085  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 2.0123  Validation loss = 4.5067  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 2.0122  Validation loss = 4.5064  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 2.0119  Validation loss = 4.5060  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 2.0115  Validation loss = 4.5036  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 2.0111  Validation loss = 4.5034  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 2.0106  Validation loss = 4.5031  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 2.0105  Validation loss = 4.5014  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 2.0103  Validation loss = 4.5024  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 2.0099  Validation loss = 4.5014  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 2.0100  Validation loss = 4.5021  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 2.0096  Validation loss = 4.5004  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 2.0096  Validation loss = 4.5009  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 2.0089  Validation loss = 4.4980  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 2.0086  Validation loss = 4.4982  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 2.0083  Validation loss = 4.4971  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 2.0078  Validation loss = 4.4945  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 2.0075  Validation loss = 4.4928  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 2.0073  Validation loss = 4.4912  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 2.0071  Validation loss = 4.4927  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 2.0069  Validation loss = 4.4919  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 2.0065  Validation loss = 4.4904  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 2.0062  Validation loss = 4.4880  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 2.0066  Validation loss = 4.4910  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 2.0064  Validation loss = 4.4895  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 2.0062  Validation loss = 4.4885  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 2.0059  Validation loss = 4.4876  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 2.0055  Validation loss = 4.4854  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 2.0062  Validation loss = 4.4880  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 2.0057  Validation loss = 4.4870  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 2.0055  Validation loss = 4.4864  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 2.0047  Validation loss = 4.4841  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 2.0041  Validation loss = 4.4812  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 2.0036  Validation loss = 4.4787  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 2.0034  Validation loss = 4.4774  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 2.0028  Validation loss = 4.4751  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 2.0030  Validation loss = 4.4751  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 2.0027  Validation loss = 4.4735  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 2.0013  Validation loss = 4.4699  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 2.0008  Validation loss = 4.4671  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 2.0008  Validation loss = 4.4666  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 2.0003  Validation loss = 4.4637  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 2.0004  Validation loss = 4.4649  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 2.0001  Validation loss = 4.4640  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 1.9999  Validation loss = 4.4625  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 1.9997  Validation loss = 4.4610  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 1.9995  Validation loss = 4.4604  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 1.9992  Validation loss = 4.4582  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 1.9990  Validation loss = 4.4589  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 1.9990  Validation loss = 4.4594  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 1.9985  Validation loss = 4.4565  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 1.9985  Validation loss = 4.4567  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 1.9984  Validation loss = 4.4559  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 1.9978  Validation loss = 4.4525  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 1.9976  Validation loss = 4.4503  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 1.9972  Validation loss = 4.4495  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 1.9968  Validation loss = 4.4488  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 1.9966  Validation loss = 4.4469  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 1.9963  Validation loss = 4.4457  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 1.9961  Validation loss = 4.4462  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 1.9956  Validation loss = 4.4462  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 1.9949  Validation loss = 4.4417  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 1.9945  Validation loss = 4.4403  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.2619  Validation loss = 3.9488  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.2614  Validation loss = 3.9491  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.2606  Validation loss = 3.9481  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.2599  Validation loss = 3.9557  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.2598  Validation loss = 3.9667  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.2595  Validation loss = 3.9686  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.2590  Validation loss = 3.9661  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.2577  Validation loss = 3.9595  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.2566  Validation loss = 3.9518  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.2556  Validation loss = 3.9479  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.2540  Validation loss = 3.9461  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.2534  Validation loss = 3.9498  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.2525  Validation loss = 3.9380  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.2508  Validation loss = 3.9376  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.2499  Validation loss = 3.9350  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.2490  Validation loss = 3.9317  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.2483  Validation loss = 3.9296  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 2.2477  Validation loss = 3.9302  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.2470  Validation loss = 3.9226  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.2463  Validation loss = 3.9364  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 2.2448  Validation loss = 3.9247  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 2.2444  Validation loss = 3.9275  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 2.2435  Validation loss = 3.9240  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 2.2426  Validation loss = 3.9280  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 2.2416  Validation loss = 3.9239  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 2.2411  Validation loss = 3.9220  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 2.2405  Validation loss = 3.9235  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 2.2397  Validation loss = 3.9162  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 2.2387  Validation loss = 3.9088  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 2.2378  Validation loss = 3.9085  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 2.2368  Validation loss = 3.9130  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 2.2366  Validation loss = 3.9210  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 2.2356  Validation loss = 3.9174  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 2.2354  Validation loss = 3.9219  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 2.2346  Validation loss = 3.9235  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 30  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.4330  Validation loss = 3.3333  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.4305  Validation loss = 3.3348  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.4279  Validation loss = 3.3351  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.4263  Validation loss = 3.3361  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.4250  Validation loss = 3.3361  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.4232  Validation loss = 3.3376  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.4203  Validation loss = 3.3400  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.4200  Validation loss = 3.3402  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.4189  Validation loss = 3.3412  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.4175  Validation loss = 3.3397  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.4161  Validation loss = 3.3396  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.4151  Validation loss = 3.3394  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.4143  Validation loss = 3.3412  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.5467  Validation loss = 1.7113  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.5452  Validation loss = 1.7087  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.5436  Validation loss = 1.7049  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.5427  Validation loss = 1.7046  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.5409  Validation loss = 1.7032  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.5397  Validation loss = 1.6999  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.5385  Validation loss = 1.6963  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.5372  Validation loss = 1.6925  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.5367  Validation loss = 1.6894  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.5354  Validation loss = 1.6870  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.5347  Validation loss = 1.6884  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 2.5334  Validation loss = 1.6877  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 2.5323  Validation loss = 1.6847  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 2.5310  Validation loss = 1.6846  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 2.5297  Validation loss = 1.6853  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 2.5291  Validation loss = 1.6863  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 2.5282  Validation loss = 1.6833  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 2.5269  Validation loss = 1.6845  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 2.5264  Validation loss = 1.6831  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 2.5251  Validation loss = 1.6819  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 2.5236  Validation loss = 1.6795  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 2.5223  Validation loss = 1.6766  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 2.5216  Validation loss = 1.6775  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 2.5213  Validation loss = 1.6748  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 2.5208  Validation loss = 1.6731  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 2.5194  Validation loss = 1.6714  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 2.5184  Validation loss = 1.6712  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 2.5175  Validation loss = 1.6705  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 2.5168  Validation loss = 1.6686  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 2.5151  Validation loss = 1.6668  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 2.5145  Validation loss = 1.6619  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 2.5124  Validation loss = 1.6629  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 2.5118  Validation loss = 1.6603  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 2.5116  Validation loss = 1.6588  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 2.5104  Validation loss = 1.6587  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 2.5096  Validation loss = 1.6557  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 2.5085  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 2.5077  Validation loss = 1.6531  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 2.5064  Validation loss = 1.6546  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 2.5048  Validation loss = 1.6550  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 2.5035  Validation loss = 1.6536  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 2.5028  Validation loss = 1.6522  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 2.5015  Validation loss = 1.6501  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 2.5010  Validation loss = 1.6472  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 2.5001  Validation loss = 1.6467  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 2.4995  Validation loss = 1.6452  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 2.4976  Validation loss = 1.6461  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 2.4974  Validation loss = 1.6423  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 2.4949  Validation loss = 1.6431  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 2.4935  Validation loss = 1.6420  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 2.4921  Validation loss = 1.6439  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 2.4919  Validation loss = 1.6424  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 2.4905  Validation loss = 1.6436  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 2.4899  Validation loss = 1.6413  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 2.4886  Validation loss = 1.6406  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 2.4884  Validation loss = 1.6403  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 2.4880  Validation loss = 1.6394  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 2.4867  Validation loss = 1.6379  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 2.4855  Validation loss = 1.6379  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 2.4842  Validation loss = 1.6373  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 2.4834  Validation loss = 1.6377  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 2.4832  Validation loss = 1.6380  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 2.4825  Validation loss = 1.6350  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 2.4821  Validation loss = 1.6348  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 2.4805  Validation loss = 1.6368  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 2.4802  Validation loss = 1.6358  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 2.4794  Validation loss = 1.6317  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 2.4780  Validation loss = 1.6326  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 2.4771  Validation loss = 1.6319  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 2.4762  Validation loss = 1.6315  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 2.4751  Validation loss = 1.6325  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 2.4745  Validation loss = 1.6323  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 2.4733  Validation loss = 1.6291  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 2.4731  Validation loss = 1.6301  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 2.4721  Validation loss = 1.6278  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 2.4713  Validation loss = 1.6290  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 2.4706  Validation loss = 1.6268  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 2.4697  Validation loss = 1.6273  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 2.4691  Validation loss = 1.6278  \n",
      "\n",
      "Fold: 18  Epoch: 80  Training loss = 2.4685  Validation loss = 1.6310  \n",
      "\n",
      "Fold: 18  Epoch: 81  Training loss = 2.4683  Validation loss = 1.6313  \n",
      "\n",
      "Fold: 18  Epoch: 82  Training loss = 2.4668  Validation loss = 1.6283  \n",
      "\n",
      "Fold: 18  Epoch: 83  Training loss = 2.4661  Validation loss = 1.6282  \n",
      "\n",
      "Fold: 18  Epoch: 84  Training loss = 2.4649  Validation loss = 1.6253  \n",
      "\n",
      "Fold: 18  Epoch: 85  Training loss = 2.4643  Validation loss = 1.6252  \n",
      "\n",
      "Fold: 18  Epoch: 86  Training loss = 2.4637  Validation loss = 1.6244  \n",
      "\n",
      "Fold: 18  Epoch: 87  Training loss = 2.4633  Validation loss = 1.6257  \n",
      "\n",
      "Fold: 18  Epoch: 88  Training loss = 2.4632  Validation loss = 1.6287  \n",
      "\n",
      "Fold: 18  Epoch: 89  Training loss = 2.4618  Validation loss = 1.6231  \n",
      "\n",
      "Fold: 18  Epoch: 90  Training loss = 2.4611  Validation loss = 1.6228  \n",
      "\n",
      "Fold: 18  Epoch: 91  Training loss = 2.4602  Validation loss = 1.6233  \n",
      "\n",
      "Fold: 18  Epoch: 92  Training loss = 2.4595  Validation loss = 1.6210  \n",
      "\n",
      "Fold: 18  Epoch: 93  Training loss = 2.4591  Validation loss = 1.6220  \n",
      "\n",
      "Fold: 18  Epoch: 94  Training loss = 2.4584  Validation loss = 1.6218  \n",
      "\n",
      "Fold: 18  Epoch: 95  Training loss = 2.4571  Validation loss = 1.6199  \n",
      "\n",
      "Fold: 18  Epoch: 96  Training loss = 2.4558  Validation loss = 1.6174  \n",
      "\n",
      "Fold: 18  Epoch: 97  Training loss = 2.4558  Validation loss = 1.6190  \n",
      "\n",
      "Fold: 18  Epoch: 98  Training loss = 2.4547  Validation loss = 1.6170  \n",
      "\n",
      "Fold: 18  Epoch: 99  Training loss = 2.4539  Validation loss = 1.6164  \n",
      "\n",
      "Fold: 18  Epoch: 100  Training loss = 2.4528  Validation loss = 1.6150  \n",
      "\n",
      "Fold: 18  Epoch: 101  Training loss = 2.4519  Validation loss = 1.6135  \n",
      "\n",
      "Fold: 18  Epoch: 102  Training loss = 2.4514  Validation loss = 1.6144  \n",
      "\n",
      "Fold: 18  Epoch: 103  Training loss = 2.4507  Validation loss = 1.6138  \n",
      "\n",
      "Fold: 18  Epoch: 104  Training loss = 2.4497  Validation loss = 1.6140  \n",
      "\n",
      "Fold: 18  Epoch: 105  Training loss = 2.4490  Validation loss = 1.6136  \n",
      "\n",
      "Fold: 18  Epoch: 106  Training loss = 2.4483  Validation loss = 1.6105  \n",
      "\n",
      "Fold: 18  Epoch: 107  Training loss = 2.4473  Validation loss = 1.6079  \n",
      "\n",
      "Fold: 18  Epoch: 108  Training loss = 2.4459  Validation loss = 1.6070  \n",
      "\n",
      "Fold: 18  Epoch: 109  Training loss = 2.4448  Validation loss = 1.6054  \n",
      "\n",
      "Fold: 18  Epoch: 110  Training loss = 2.4441  Validation loss = 1.6051  \n",
      "\n",
      "Fold: 18  Epoch: 111  Training loss = 2.4438  Validation loss = 1.6053  \n",
      "\n",
      "Fold: 18  Epoch: 112  Training loss = 2.4428  Validation loss = 1.6034  \n",
      "\n",
      "Fold: 18  Epoch: 113  Training loss = 2.4422  Validation loss = 1.6043  \n",
      "\n",
      "Fold: 18  Epoch: 114  Training loss = 2.4415  Validation loss = 1.6037  \n",
      "\n",
      "Fold: 18  Epoch: 115  Training loss = 2.4405  Validation loss = 1.6022  \n",
      "\n",
      "Fold: 18  Epoch: 116  Training loss = 2.4398  Validation loss = 1.5986  \n",
      "\n",
      "Fold: 18  Epoch: 117  Training loss = 2.4390  Validation loss = 1.5956  \n",
      "\n",
      "Fold: 18  Epoch: 118  Training loss = 2.4382  Validation loss = 1.5952  \n",
      "\n",
      "Fold: 18  Epoch: 119  Training loss = 2.4376  Validation loss = 1.5947  \n",
      "\n",
      "Fold: 18  Epoch: 120  Training loss = 2.4369  Validation loss = 1.5939  \n",
      "\n",
      "Fold: 18  Epoch: 121  Training loss = 2.4358  Validation loss = 1.5926  \n",
      "\n",
      "Fold: 18  Epoch: 122  Training loss = 2.4353  Validation loss = 1.5921  \n",
      "\n",
      "Fold: 18  Epoch: 123  Training loss = 2.4350  Validation loss = 1.5919  \n",
      "\n",
      "Fold: 18  Epoch: 124  Training loss = 2.4347  Validation loss = 1.5930  \n",
      "\n",
      "Fold: 18  Epoch: 125  Training loss = 2.4332  Validation loss = 1.5938  \n",
      "\n",
      "Fold: 18  Epoch: 126  Training loss = 2.4325  Validation loss = 1.5922  \n",
      "\n",
      "Fold: 18  Epoch: 127  Training loss = 2.4321  Validation loss = 1.5921  \n",
      "\n",
      "Fold: 18  Epoch: 128  Training loss = 2.4317  Validation loss = 1.5922  \n",
      "\n",
      "Fold: 18  Epoch: 129  Training loss = 2.4314  Validation loss = 1.5913  \n",
      "\n",
      "Fold: 18  Epoch: 130  Training loss = 2.4308  Validation loss = 1.5895  \n",
      "\n",
      "Fold: 18  Epoch: 131  Training loss = 2.4302  Validation loss = 1.5883  \n",
      "\n",
      "Fold: 18  Epoch: 132  Training loss = 2.4293  Validation loss = 1.5871  \n",
      "\n",
      "Fold: 18  Epoch: 133  Training loss = 2.4282  Validation loss = 1.5854  \n",
      "\n",
      "Fold: 18  Epoch: 134  Training loss = 2.4276  Validation loss = 1.5870  \n",
      "\n",
      "Fold: 18  Epoch: 135  Training loss = 2.4272  Validation loss = 1.5884  \n",
      "\n",
      "Fold: 18  Epoch: 136  Training loss = 2.4263  Validation loss = 1.5880  \n",
      "\n",
      "Fold: 18  Epoch: 137  Training loss = 2.4258  Validation loss = 1.5871  \n",
      "\n",
      "Fold: 18  Epoch: 138  Training loss = 2.4253  Validation loss = 1.5855  \n",
      "\n",
      "Fold: 18  Epoch: 139  Training loss = 2.4236  Validation loss = 1.5813  \n",
      "\n",
      "Fold: 18  Epoch: 140  Training loss = 2.4225  Validation loss = 1.5788  \n",
      "\n",
      "Fold: 18  Epoch: 141  Training loss = 2.4215  Validation loss = 1.5756  \n",
      "\n",
      "Fold: 18  Epoch: 142  Training loss = 2.4202  Validation loss = 1.5763  \n",
      "\n",
      "Fold: 18  Epoch: 143  Training loss = 2.4196  Validation loss = 1.5768  \n",
      "\n",
      "Fold: 18  Epoch: 144  Training loss = 2.4191  Validation loss = 1.5758  \n",
      "\n",
      "Fold: 18  Epoch: 145  Training loss = 2.4187  Validation loss = 1.5760  \n",
      "\n",
      "Fold: 18  Epoch: 146  Training loss = 2.4184  Validation loss = 1.5776  \n",
      "\n",
      "Fold: 18  Epoch: 147  Training loss = 2.4176  Validation loss = 1.5775  \n",
      "\n",
      "Fold: 18  Epoch: 148  Training loss = 2.4177  Validation loss = 1.5788  \n",
      "\n",
      "Fold: 18  Epoch: 149  Training loss = 2.4170  Validation loss = 1.5771  \n",
      "\n",
      "Fold: 18  Epoch: 150  Training loss = 2.4166  Validation loss = 1.5776  \n",
      "\n",
      "Fold: 18  Epoch: 151  Training loss = 2.4159  Validation loss = 1.5769  \n",
      "\n",
      "Fold: 18  Epoch: 152  Training loss = 2.4150  Validation loss = 1.5767  \n",
      "\n",
      "Fold: 18  Epoch: 153  Training loss = 2.4148  Validation loss = 1.5755  \n",
      "\n",
      "Fold: 18  Epoch: 154  Training loss = 2.4142  Validation loss = 1.5765  \n",
      "\n",
      "Fold: 18  Epoch: 155  Training loss = 2.4144  Validation loss = 1.5764  \n",
      "\n",
      "Fold: 18  Epoch: 156  Training loss = 2.4128  Validation loss = 1.5744  \n",
      "\n",
      "Fold: 18  Epoch: 157  Training loss = 2.4129  Validation loss = 1.5748  \n",
      "\n",
      "Fold: 18  Epoch: 158  Training loss = 2.4113  Validation loss = 1.5707  \n",
      "\n",
      "Fold: 18  Epoch: 159  Training loss = 2.4105  Validation loss = 1.5715  \n",
      "\n",
      "Fold: 18  Epoch: 160  Training loss = 2.4101  Validation loss = 1.5706  \n",
      "\n",
      "Fold: 18  Epoch: 161  Training loss = 2.4093  Validation loss = 1.5682  \n",
      "\n",
      "Fold: 18  Epoch: 162  Training loss = 2.4087  Validation loss = 1.5665  \n",
      "\n",
      "Fold: 18  Epoch: 163  Training loss = 2.4080  Validation loss = 1.5662  \n",
      "\n",
      "Fold: 18  Epoch: 164  Training loss = 2.4074  Validation loss = 1.5641  \n",
      "\n",
      "Fold: 18  Epoch: 165  Training loss = 2.4070  Validation loss = 1.5613  \n",
      "\n",
      "Fold: 18  Epoch: 166  Training loss = 2.4064  Validation loss = 1.5588  \n",
      "\n",
      "Fold: 18  Epoch: 167  Training loss = 2.4068  Validation loss = 1.5581  \n",
      "\n",
      "Fold: 18  Epoch: 168  Training loss = 2.4065  Validation loss = 1.5580  \n",
      "\n",
      "Fold: 18  Epoch: 169  Training loss = 2.4055  Validation loss = 1.5596  \n",
      "\n",
      "Fold: 18  Epoch: 170  Training loss = 2.4045  Validation loss = 1.5602  \n",
      "\n",
      "Fold: 18  Epoch: 171  Training loss = 2.4034  Validation loss = 1.5595  \n",
      "\n",
      "Fold: 18  Epoch: 172  Training loss = 2.4033  Validation loss = 1.5602  \n",
      "\n",
      "Fold: 18  Epoch: 173  Training loss = 2.4022  Validation loss = 1.5617  \n",
      "\n",
      "Fold: 18  Epoch: 174  Training loss = 2.4015  Validation loss = 1.5612  \n",
      "\n",
      "Fold: 18  Epoch: 175  Training loss = 2.4010  Validation loss = 1.5620  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 168  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.3687  Validation loss = 2.3607  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.3689  Validation loss = 2.3606  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.3689  Validation loss = 2.3600  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.3691  Validation loss = 2.3587  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.3677  Validation loss = 2.3584  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.3672  Validation loss = 2.3575  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.3655  Validation loss = 2.3545  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.3649  Validation loss = 2.3533  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.3647  Validation loss = 2.3538  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.3645  Validation loss = 2.3521  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.3612  Validation loss = 2.3497  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.3615  Validation loss = 2.3488  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.3602  Validation loss = 2.3477  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.3592  Validation loss = 2.3482  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.3581  Validation loss = 2.3470  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.3580  Validation loss = 2.3465  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 2.3571  Validation loss = 2.3460  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 2.3571  Validation loss = 2.3445  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 2.3558  Validation loss = 2.3437  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 2.3547  Validation loss = 2.3419  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 2.3536  Validation loss = 2.3411  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 2.3532  Validation loss = 2.3395  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 2.3526  Validation loss = 2.3385  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 2.3520  Validation loss = 2.3377  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 2.3515  Validation loss = 2.3361  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 2.3510  Validation loss = 2.3350  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 2.3508  Validation loss = 2.3347  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 2.3500  Validation loss = 2.3335  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 2.3493  Validation loss = 2.3306  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 2.3493  Validation loss = 2.3295  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 2.3488  Validation loss = 2.3294  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 2.3482  Validation loss = 2.3278  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 2.3475  Validation loss = 2.3287  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 2.3463  Validation loss = 2.3284  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 2.3454  Validation loss = 2.3270  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 2.3450  Validation loss = 2.3263  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 2.3445  Validation loss = 2.3247  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 2.3438  Validation loss = 2.3230  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 2.3435  Validation loss = 2.3243  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 2.3426  Validation loss = 2.3225  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 2.3418  Validation loss = 2.3199  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 2.3410  Validation loss = 2.3187  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 2.3400  Validation loss = 2.3173  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 2.3395  Validation loss = 2.3142  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 2.3385  Validation loss = 2.3133  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 2.3378  Validation loss = 2.3142  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 2.3374  Validation loss = 2.3121  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 2.3372  Validation loss = 2.3112  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 2.3374  Validation loss = 2.3100  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 2.3362  Validation loss = 2.3068  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 2.3350  Validation loss = 2.3048  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 2.3340  Validation loss = 2.3055  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 2.3331  Validation loss = 2.3073  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 2.3324  Validation loss = 2.3058  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 2.3321  Validation loss = 2.3062  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 2.3313  Validation loss = 2.3052  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 2.3320  Validation loss = 2.3063  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 2.3317  Validation loss = 2.3069  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 2.3310  Validation loss = 2.3069  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 2.3305  Validation loss = 2.3055  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 2.3290  Validation loss = 2.3046  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 2.3284  Validation loss = 2.3034  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 2.3287  Validation loss = 2.3016  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 2.3268  Validation loss = 2.3021  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 2.3259  Validation loss = 2.3017  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 2.3252  Validation loss = 2.3004  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 2.3249  Validation loss = 2.2997  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 2.3245  Validation loss = 2.2985  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 2.3237  Validation loss = 2.2977  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 2.3231  Validation loss = 2.2968  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 2.3225  Validation loss = 2.2980  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 2.3213  Validation loss = 2.2949  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 2.3193  Validation loss = 2.2932  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 2.3192  Validation loss = 2.2924  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 2.3190  Validation loss = 2.2929  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 2.3193  Validation loss = 2.2917  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 2.3184  Validation loss = 2.2917  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 2.3178  Validation loss = 2.2888  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 2.3170  Validation loss = 2.2868  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 2.3169  Validation loss = 2.2870  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 2.3166  Validation loss = 2.2863  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 2.3155  Validation loss = 2.2859  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 2.3150  Validation loss = 2.2862  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 2.3145  Validation loss = 2.2873  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 2.3140  Validation loss = 2.2866  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 2.3141  Validation loss = 2.2869  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 2.3126  Validation loss = 2.2851  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 2.3122  Validation loss = 2.2832  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 2.3125  Validation loss = 2.2829  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 2.3118  Validation loss = 2.2813  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 2.3113  Validation loss = 2.2815  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 2.3101  Validation loss = 2.2791  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 2.3093  Validation loss = 2.2767  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 2.3086  Validation loss = 2.2768  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 2.3093  Validation loss = 2.2767  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 2.3082  Validation loss = 2.2765  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 2.3069  Validation loss = 2.2752  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 2.3061  Validation loss = 2.2752  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 2.3049  Validation loss = 2.2733  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 2.3042  Validation loss = 2.2711  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 2.3034  Validation loss = 2.2701  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 2.3029  Validation loss = 2.2699  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 2.3027  Validation loss = 2.2700  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 2.3022  Validation loss = 2.2685  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 2.3027  Validation loss = 2.2674  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 2.3015  Validation loss = 2.2679  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 2.3017  Validation loss = 2.2681  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 2.3007  Validation loss = 2.2675  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 2.3010  Validation loss = 2.2687  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 2.3004  Validation loss = 2.2688  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 2.2993  Validation loss = 2.2669  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 2.3002  Validation loss = 2.2662  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 2.2980  Validation loss = 2.2656  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 2.2960  Validation loss = 2.2632  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 2.2949  Validation loss = 2.2628  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 2.2936  Validation loss = 2.2601  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 2.2929  Validation loss = 2.2591  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 2.2927  Validation loss = 2.2599  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 2.2915  Validation loss = 2.2585  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 2.2912  Validation loss = 2.2592  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 2.2903  Validation loss = 2.2588  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 2.2901  Validation loss = 2.2589  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 2.2892  Validation loss = 2.2579  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 2.2888  Validation loss = 2.2566  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 2.2883  Validation loss = 2.2559  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 2.2877  Validation loss = 2.2539  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 2.2874  Validation loss = 2.2528  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 2.2862  Validation loss = 2.2526  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 2.2859  Validation loss = 2.2538  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 2.2850  Validation loss = 2.2539  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 2.2842  Validation loss = 2.2537  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 2.2834  Validation loss = 2.2533  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 2.2834  Validation loss = 2.2533  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 2.2824  Validation loss = 2.2520  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 2.2824  Validation loss = 2.2523  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 2.2827  Validation loss = 2.2526  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 2.2822  Validation loss = 2.2516  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 2.2827  Validation loss = 2.2508  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 2.2822  Validation loss = 2.2504  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 2.2806  Validation loss = 2.2487  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 2.2802  Validation loss = 2.2498  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 2.2787  Validation loss = 2.2495  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 2.2771  Validation loss = 2.2497  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 2.2771  Validation loss = 2.2496  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 2.2768  Validation loss = 2.2501  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 2.2762  Validation loss = 2.2486  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 2.2751  Validation loss = 2.2486  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 2.2738  Validation loss = 2.2451  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 2.2741  Validation loss = 2.2452  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 2.2738  Validation loss = 2.2441  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 2.2726  Validation loss = 2.2445  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 2.2734  Validation loss = 2.2453  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 2.2736  Validation loss = 2.2449  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 2.2718  Validation loss = 2.2449  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 2.2715  Validation loss = 2.2457  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 2.2719  Validation loss = 2.2456  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 2.2712  Validation loss = 2.2461  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 150  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.3311  Validation loss = 1.3930  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.3312  Validation loss = 1.3916  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.3296  Validation loss = 1.3857  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.3299  Validation loss = 1.3869  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.3299  Validation loss = 1.3883  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.3290  Validation loss = 1.3845  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.3283  Validation loss = 1.3821  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.3272  Validation loss = 1.3776  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.3266  Validation loss = 1.3775  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.3263  Validation loss = 1.3764  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.3262  Validation loss = 1.3756  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.3256  Validation loss = 1.3741  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 2.3249  Validation loss = 1.3709  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.3239  Validation loss = 1.3683  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.3224  Validation loss = 1.3628  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.3213  Validation loss = 1.3578  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.3207  Validation loss = 1.3518  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.3200  Validation loss = 1.3484  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 2.3192  Validation loss = 1.3399  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 2.3188  Validation loss = 1.3332  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 2.3179  Validation loss = 1.3264  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 2.3176  Validation loss = 1.3200  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 2.3165  Validation loss = 1.3212  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 2.3151  Validation loss = 1.3179  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 2.3144  Validation loss = 1.3164  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 2.3137  Validation loss = 1.3148  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 2.3133  Validation loss = 1.3151  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 2.3128  Validation loss = 1.3144  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 2.3130  Validation loss = 1.3059  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 2.3142  Validation loss = 1.2973  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 2.3129  Validation loss = 1.2998  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 2.3117  Validation loss = 1.2992  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 2.3112  Validation loss = 1.2971  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 2.3102  Validation loss = 1.2948  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 2.3101  Validation loss = 1.2914  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 2.3092  Validation loss = 1.2886  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 2.3080  Validation loss = 1.2877  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 2.3074  Validation loss = 1.2851  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 2.3065  Validation loss = 1.2821  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 2.3066  Validation loss = 1.2780  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 2.3061  Validation loss = 1.2765  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 2.3051  Validation loss = 1.2779  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 2.3048  Validation loss = 1.2760  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 2.3045  Validation loss = 1.2703  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 2.3040  Validation loss = 1.2674  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 2.3037  Validation loss = 1.2619  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 2.3033  Validation loss = 1.2563  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 2.3030  Validation loss = 1.2532  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 2.3033  Validation loss = 1.2478  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 2.3024  Validation loss = 1.2466  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 2.3000  Validation loss = 1.2464  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 2.2989  Validation loss = 1.2497  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 2.2994  Validation loss = 1.2425  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 2.2984  Validation loss = 1.2403  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 2.2974  Validation loss = 1.2399  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 2.2966  Validation loss = 1.2413  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 2.2969  Validation loss = 1.2426  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 2.2962  Validation loss = 1.2434  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 2.2954  Validation loss = 1.2409  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 2.2952  Validation loss = 1.2324  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 2.2943  Validation loss = 1.2279  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 2.2948  Validation loss = 1.2232  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 2.2950  Validation loss = 1.2195  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 2.2937  Validation loss = 1.2169  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 2.2926  Validation loss = 1.2163  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 2.2925  Validation loss = 1.2104  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 2.2925  Validation loss = 1.2055  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 2.2921  Validation loss = 1.2034  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 2.2926  Validation loss = 1.2031  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 2.2900  Validation loss = 1.2042  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 2.2881  Validation loss = 1.2067  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 2.2870  Validation loss = 1.2084  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 2.2865  Validation loss = 1.2087  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 2.2862  Validation loss = 1.2017  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 2.2861  Validation loss = 1.1966  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 2.2854  Validation loss = 1.1924  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 2.2839  Validation loss = 1.1943  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 2.2836  Validation loss = 1.1923  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 2.2833  Validation loss = 1.1893  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 2.2826  Validation loss = 1.1905  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 2.2821  Validation loss = 1.1936  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 2.2818  Validation loss = 1.1953  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 2.2815  Validation loss = 1.1938  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 2.2811  Validation loss = 1.1850  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 2.2803  Validation loss = 1.1825  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 2.2795  Validation loss = 1.1809  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 2.2790  Validation loss = 1.1778  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 2.2792  Validation loss = 1.1770  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 2.2780  Validation loss = 1.1782  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 2.2783  Validation loss = 1.1765  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 2.2770  Validation loss = 1.1790  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 2.2771  Validation loss = 1.1746  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 2.2765  Validation loss = 1.1743  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 2.2759  Validation loss = 1.1740  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 2.2756  Validation loss = 1.1738  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 2.2750  Validation loss = 1.1710  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 2.2747  Validation loss = 1.1745  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 2.2750  Validation loss = 1.1749  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 2.2746  Validation loss = 1.1749  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 2.2746  Validation loss = 1.1761  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 2.2732  Validation loss = 1.1711  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 2.2725  Validation loss = 1.1681  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 2.2715  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 2.2712  Validation loss = 1.1600  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 2.2707  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 2.2703  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 2.2697  Validation loss = 1.1543  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 2.2693  Validation loss = 1.1505  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 2.2687  Validation loss = 1.1485  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 2.2685  Validation loss = 1.1468  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 2.2677  Validation loss = 1.1484  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 2.2674  Validation loss = 1.1453  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 2.2666  Validation loss = 1.1443  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 2.2667  Validation loss = 1.1451  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 2.2669  Validation loss = 1.1464  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 2.2668  Validation loss = 1.1435  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 2.2651  Validation loss = 1.1382  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 2.2645  Validation loss = 1.1374  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 2.2651  Validation loss = 1.1364  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 2.2646  Validation loss = 1.1368  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 2.2648  Validation loss = 1.1376  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 2.2631  Validation loss = 1.1337  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 2.2623  Validation loss = 1.1301  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 2.2610  Validation loss = 1.1247  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 2.2602  Validation loss = 1.1188  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 2.2598  Validation loss = 1.1131  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 2.2596  Validation loss = 1.1097  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 2.2588  Validation loss = 1.1046  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 2.2586  Validation loss = 1.0991  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 2.2584  Validation loss = 1.0929  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 2.2577  Validation loss = 1.0863  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 2.2574  Validation loss = 1.0857  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 2.2568  Validation loss = 1.0837  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 2.2567  Validation loss = 1.0843  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 2.2555  Validation loss = 1.0834  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 2.2549  Validation loss = 1.0818  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 2.2543  Validation loss = 1.0777  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 2.2537  Validation loss = 1.0761  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 2.2535  Validation loss = 1.0738  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 2.2530  Validation loss = 1.0710  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 2.2525  Validation loss = 1.0694  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 2.2518  Validation loss = 1.0678  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 2.2516  Validation loss = 1.0653  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 2.2512  Validation loss = 1.0652  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 2.2505  Validation loss = 1.0659  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 2.2503  Validation loss = 1.0619  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 2.2496  Validation loss = 1.0585  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 2.2492  Validation loss = 1.0568  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 2.2487  Validation loss = 1.0574  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 2.2487  Validation loss = 1.0571  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 2.2480  Validation loss = 1.0568  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 2.2476  Validation loss = 1.0542  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 2.2467  Validation loss = 1.0552  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 2.2464  Validation loss = 1.0522  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 2.2458  Validation loss = 1.0547  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 2.2451  Validation loss = 1.0486  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 2.2448  Validation loss = 1.0471  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 2.2443  Validation loss = 1.0460  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 2.2439  Validation loss = 1.0485  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 2.2437  Validation loss = 1.0425  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 2.2430  Validation loss = 1.0386  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 2.2427  Validation loss = 1.0366  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 2.2429  Validation loss = 1.0315  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 2.2426  Validation loss = 1.0310  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 2.2414  Validation loss = 1.0304  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 2.2413  Validation loss = 1.0253  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 2.2403  Validation loss = 1.0263  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 2.2400  Validation loss = 1.0229  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 2.2388  Validation loss = 1.0218  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 2.2381  Validation loss = 1.0206  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 2.2377  Validation loss = 1.0204  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 2.2376  Validation loss = 1.0185  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 2.2371  Validation loss = 1.0251  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 2.2363  Validation loss = 1.0209  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 2.2356  Validation loss = 1.0165  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 2.2353  Validation loss = 1.0171  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 2.2349  Validation loss = 1.0170  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 2.2343  Validation loss = 1.0166  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 2.2339  Validation loss = 1.0157  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 2.2334  Validation loss = 1.0135  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 2.2333  Validation loss = 1.0135  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 2.2332  Validation loss = 1.0149  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 2.2328  Validation loss = 1.0128  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 2.2324  Validation loss = 1.0095  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 2.2325  Validation loss = 1.0078  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 2.2319  Validation loss = 1.0048  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 2.2312  Validation loss = 1.0050  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 2.2309  Validation loss = 1.0077  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 2.2304  Validation loss = 1.0036  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 2.2299  Validation loss = 0.9983  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 2.2292  Validation loss = 0.9945  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 2.2293  Validation loss = 0.9895  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 2.2287  Validation loss = 0.9884  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 2.2283  Validation loss = 0.9882  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 2.2273  Validation loss = 0.9870  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 2.2269  Validation loss = 0.9859  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 2.2266  Validation loss = 0.9777  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 2.2256  Validation loss = 0.9757  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 2.2251  Validation loss = 0.9715  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 2.2248  Validation loss = 0.9712  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 2.2248  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 2.2240  Validation loss = 0.9652  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 2.2239  Validation loss = 0.9652  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 2.2234  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 2.2237  Validation loss = 0.9636  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 2.2223  Validation loss = 0.9608  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 2.2217  Validation loss = 0.9524  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 2.2212  Validation loss = 0.9499  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 2.2215  Validation loss = 0.9471  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 2.2217  Validation loss = 0.9437  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 2.2205  Validation loss = 0.9447  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 2.2202  Validation loss = 0.9395  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 2.2204  Validation loss = 0.9360  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 2.2197  Validation loss = 0.9371  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 2.2193  Validation loss = 0.9321  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 2.2186  Validation loss = 0.9343  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 2.2176  Validation loss = 0.9330  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 2.2170  Validation loss = 0.9311  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 2.2163  Validation loss = 0.9314  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 2.2162  Validation loss = 0.9308  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 2.2159  Validation loss = 0.9317  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 2.2158  Validation loss = 0.9308  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 2.2173  Validation loss = 0.9364  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 2.2169  Validation loss = 0.9331  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 2.2157  Validation loss = 0.9314  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 2.2159  Validation loss = 0.9288  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 2.2150  Validation loss = 0.9285  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 2.2143  Validation loss = 0.9254  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 2.2139  Validation loss = 0.9301  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 2.2132  Validation loss = 0.9286  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 2.2128  Validation loss = 0.9235  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 2.2124  Validation loss = 0.9265  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 2.2122  Validation loss = 0.9249  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 2.2117  Validation loss = 0.9252  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 2.2121  Validation loss = 0.9310  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 231  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.1964  Validation loss = 3.4664  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.1959  Validation loss = 3.4667  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.1942  Validation loss = 3.4738  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.1932  Validation loss = 3.4801  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.1929  Validation loss = 3.4808  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.1917  Validation loss = 3.4869  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.1909  Validation loss = 3.4890  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.1905  Validation loss = 3.4902  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.1907  Validation loss = 3.4827  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.1912  Validation loss = 3.4757  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.1906  Validation loss = 3.4758  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.1918  Validation loss = 3.4695  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 2.1916  Validation loss = 3.4669  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 2.1894  Validation loss = 3.4776  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 2.1879  Validation loss = 3.4882  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 2.1874  Validation loss = 3.4878  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 2.1870  Validation loss = 3.4859  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 2.1862  Validation loss = 3.4912  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.2626  Validation loss = 2.5840  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.2593  Validation loss = 2.6729  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.2585  Validation loss = 2.6669  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.2588  Validation loss = 2.6234  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.2573  Validation loss = 2.6476  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.2557  Validation loss = 2.6662  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 2.2547  Validation loss = 2.6627  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.2547  Validation loss = 2.6349  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.2541  Validation loss = 2.6159  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.2541  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.2544  Validation loss = 2.5472  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.2522  Validation loss = 2.5438  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.2505  Validation loss = 2.5757  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 2.2498  Validation loss = 2.5910  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 2.2488  Validation loss = 2.6329  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 2.2483  Validation loss = 2.5862  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 2.2476  Validation loss = 2.5814  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 2.2468  Validation loss = 2.6144  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 2.2458  Validation loss = 2.6761  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 12  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.2857  Validation loss = 2.2445  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.2869  Validation loss = 2.1275  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.2798  Validation loss = 2.1665  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.2772  Validation loss = 2.1124  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.2866  Validation loss = 1.9737  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.2819  Validation loss = 2.0124  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.2785  Validation loss = 2.0255  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.2795  Validation loss = 1.9679  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.2685  Validation loss = 2.0396  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.2645  Validation loss = 2.0344  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.2663  Validation loss = 2.0685  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.2649  Validation loss = 2.0471  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.2629  Validation loss = 1.9864  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 2.2608  Validation loss = 2.0190  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 2.2591  Validation loss = 2.0169  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 2.2585  Validation loss = 1.9486  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 2.2575  Validation loss = 1.9518  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 2.2576  Validation loss = 1.9826  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 2.2555  Validation loss = 1.9922  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 2.2555  Validation loss = 2.0259  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 2.2543  Validation loss = 2.0211  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 2.2526  Validation loss = 1.9708  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 2.2513  Validation loss = 1.9681  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 2.2500  Validation loss = 1.9613  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 2.2494  Validation loss = 1.9376  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 2.2494  Validation loss = 1.9816  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 2.2480  Validation loss = 1.9775  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 2.2471  Validation loss = 1.9542  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 2.2469  Validation loss = 1.9642  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 2.2469  Validation loss = 1.9761  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 2.2460  Validation loss = 1.9937  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 25  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.2589  Validation loss = 1.6126  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.2550  Validation loss = 1.5893  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.2555  Validation loss = 1.6012  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.2530  Validation loss = 1.5889  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.2576  Validation loss = 1.5785  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.2493  Validation loss = 1.5805  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.2477  Validation loss = 1.5779  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.2554  Validation loss = 1.5658  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.2524  Validation loss = 1.5845  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.2459  Validation loss = 1.5810  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.2434  Validation loss = 1.5752  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.2420  Validation loss = 1.5690  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.2432  Validation loss = 1.5768  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.2411  Validation loss = 1.5722  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.2403  Validation loss = 1.5701  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.2420  Validation loss = 1.5726  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.2480  Validation loss = 1.5749  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.2443  Validation loss = 1.5704  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.2400  Validation loss = 1.5598  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.2379  Validation loss = 1.5547  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.2375  Validation loss = 1.5513  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.2412  Validation loss = 1.5628  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 2.2388  Validation loss = 1.5573  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 2.2426  Validation loss = 1.5631  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 2.2369  Validation loss = 1.5575  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 2.2347  Validation loss = 1.5532  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 2.2340  Validation loss = 1.5537  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 2.2326  Validation loss = 1.5523  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 2.2325  Validation loss = 1.5413  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 2.2310  Validation loss = 1.5376  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 2.2295  Validation loss = 1.5378  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 2.2296  Validation loss = 1.5396  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 2.2279  Validation loss = 1.5421  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 2.2424  Validation loss = 1.5531  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 2.2518  Validation loss = 1.5507  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 2.2470  Validation loss = 1.5485  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 2.2435  Validation loss = 1.5409  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 2.2405  Validation loss = 1.5351  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 2.2418  Validation loss = 1.5304  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 2.2372  Validation loss = 1.5362  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 2.2351  Validation loss = 1.5309  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 2.2335  Validation loss = 1.5261  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 2.2321  Validation loss = 1.5243  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 2.2404  Validation loss = 1.5207  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 2.2290  Validation loss = 1.5196  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 2.2221  Validation loss = 1.5075  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 2.2301  Validation loss = 1.5139  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 2.2212  Validation loss = 1.5148  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 2.2200  Validation loss = 1.5155  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 2.2155  Validation loss = 1.5101  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 2.2158  Validation loss = 1.5119  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 2.2277  Validation loss = 1.5068  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 2.2127  Validation loss = 1.5201  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 2.2108  Validation loss = 1.5096  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 2.2107  Validation loss = 1.5109  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 2.2088  Validation loss = 1.5043  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 2.2088  Validation loss = 1.5049  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 2.2073  Validation loss = 1.5067  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 2.2076  Validation loss = 1.5074  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 2.2077  Validation loss = 1.5075  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 2.2063  Validation loss = 1.5087  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 2.2071  Validation loss = 1.5040  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 2.2080  Validation loss = 1.5087  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 2.2066  Validation loss = 1.5084  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 2.2037  Validation loss = 1.4979  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 2.2052  Validation loss = 1.5035  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 2.2066  Validation loss = 1.5104  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 65  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.1499  Validation loss = 2.3009  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.1569  Validation loss = 2.2868  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.1565  Validation loss = 2.2783  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.1545  Validation loss = 2.2702  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.1533  Validation loss = 2.2815  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.1515  Validation loss = 2.2740  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.1500  Validation loss = 2.2904  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.1410  Validation loss = 2.2986  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.1456  Validation loss = 2.2695  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.1406  Validation loss = 2.2753  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.1400  Validation loss = 2.2873  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.1626  Validation loss = 2.2582  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.1581  Validation loss = 2.2492  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.1481  Validation loss = 2.2422  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.1397  Validation loss = 2.2704  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.1376  Validation loss = 2.2379  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 2.1352  Validation loss = 2.2606  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 2.1361  Validation loss = 2.3060  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 16  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.1628  Validation loss = 2.8821  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.1639  Validation loss = 2.5972  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.1833  Validation loss = 3.3344  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.1707  Validation loss = 2.9371  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.1674  Validation loss = 2.8154  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.1631  Validation loss = 2.6058  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.1641  Validation loss = 2.8778  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.1601  Validation loss = 2.6571  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.1578  Validation loss = 2.6592  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.1595  Validation loss = 2.3127  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.1592  Validation loss = 2.2958  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.1560  Validation loss = 2.5360  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.1549  Validation loss = 2.4581  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.1558  Validation loss = 2.2645  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.1534  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 2.1521  Validation loss = 2.5797  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 2.1514  Validation loss = 2.5452  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 2.1550  Validation loss = 2.9077  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 14  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.0833  Validation loss = 0.5564  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.0729  Validation loss = 0.5449  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.0901  Validation loss = 0.5370  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.0782  Validation loss = 0.5538  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.0689  Validation loss = 0.5441  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.0751  Validation loss = 0.5432  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.0746  Validation loss = 0.5423  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.0722  Validation loss = 0.5410  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.0595  Validation loss = 0.5242  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.0636  Validation loss = 0.5186  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.0596  Validation loss = 0.5163  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.0529  Validation loss = 0.5255  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.0594  Validation loss = 0.5207  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.0554  Validation loss = 0.5095  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.0487  Validation loss = 0.5078  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.0515  Validation loss = 0.5159  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.0683  Validation loss = 0.5004  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.0539  Validation loss = 0.5045  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.0522  Validation loss = 0.5131  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.0444  Validation loss = 0.5123  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 2.0414  Validation loss = 0.5013  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 2.0428  Validation loss = 0.5097  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 2.0499  Validation loss = 0.4889  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 2.0767  Validation loss = 0.4815  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 2.1580  Validation loss = 0.4658  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 2.0377  Validation loss = 0.4828  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 2.0419  Validation loss = 0.4927  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 2.0474  Validation loss = 0.4756  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 2.0436  Validation loss = 0.4689  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 2.0531  Validation loss = 0.4747  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 2.0501  Validation loss = 0.4714  \n",
      "\n",
      "Fold: 27  Epoch: 32  Training loss = 2.0450  Validation loss = 0.4713  \n",
      "\n",
      "Fold: 27  Epoch: 33  Training loss = 2.0376  Validation loss = 0.4802  \n",
      "\n",
      "Fold: 27  Epoch: 34  Training loss = 2.0379  Validation loss = 0.4911  \n",
      "\n",
      "Fold: 27  Epoch: 35  Training loss = 2.0387  Validation loss = 0.4906  \n",
      "\n",
      "Fold: 27  Epoch: 36  Training loss = 2.0302  Validation loss = 0.4780  \n",
      "\n",
      "Fold: 27  Epoch: 37  Training loss = 2.0269  Validation loss = 0.4716  \n",
      "\n",
      "Fold: 27  Epoch: 38  Training loss = 2.0314  Validation loss = 0.4666  \n",
      "\n",
      "Fold: 27  Epoch: 39  Training loss = 2.0244  Validation loss = 0.4685  \n",
      "\n",
      "Fold: 27  Epoch: 40  Training loss = 2.0242  Validation loss = 0.4698  \n",
      "\n",
      "Fold: 27  Epoch: 41  Training loss = 2.0240  Validation loss = 0.4702  \n",
      "\n",
      "Fold: 27  Epoch: 42  Training loss = 2.0355  Validation loss = 0.4829  \n",
      "\n",
      "Fold: 27  Epoch: 43  Training loss = 2.0274  Validation loss = 0.4743  \n",
      "\n",
      "Fold: 27  Epoch: 44  Training loss = 2.0267  Validation loss = 0.4726  \n",
      "\n",
      "Fold: 27  Epoch: 45  Training loss = 2.0200  Validation loss = 0.4607  \n",
      "\n",
      "Fold: 27  Epoch: 46  Training loss = 2.0219  Validation loss = 0.4504  \n",
      "\n",
      "Fold: 27  Epoch: 47  Training loss = 2.0184  Validation loss = 0.4541  \n",
      "\n",
      "Fold: 27  Epoch: 48  Training loss = 2.0176  Validation loss = 0.4553  \n",
      "\n",
      "Fold: 27  Epoch: 49  Training loss = 2.0206  Validation loss = 0.4564  \n",
      "\n",
      "Fold: 27  Epoch: 50  Training loss = 2.0280  Validation loss = 0.4429  \n",
      "\n",
      "Fold: 27  Epoch: 51  Training loss = 2.0205  Validation loss = 0.4463  \n",
      "\n",
      "Fold: 27  Epoch: 52  Training loss = 2.0179  Validation loss = 0.4442  \n",
      "\n",
      "Fold: 27  Epoch: 53  Training loss = 2.0259  Validation loss = 0.4589  \n",
      "\n",
      "Fold: 27  Epoch: 54  Training loss = 2.0181  Validation loss = 0.4556  \n",
      "\n",
      "Fold: 27  Epoch: 55  Training loss = 2.0138  Validation loss = 0.4474  \n",
      "\n",
      "Fold: 27  Epoch: 56  Training loss = 2.0144  Validation loss = 0.4635  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 50  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 1.9938  Validation loss = 0.8171  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 1.9923  Validation loss = 0.8150  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 1.9997  Validation loss = 0.8082  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 1.9911  Validation loss = 0.8081  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 1.9908  Validation loss = 0.8076  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 1.9882  Validation loss = 0.8101  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.0261  Validation loss = 0.7941  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.0105  Validation loss = 0.7958  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 1.9916  Validation loss = 0.7975  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 1.9857  Validation loss = 0.8027  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.0140  Validation loss = 0.8182  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 7  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 1.9705  Validation loss = 0.8956  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 1.9609  Validation loss = 0.8901  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 1.9609  Validation loss = 0.8876  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 1.9679  Validation loss = 0.8932  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 1.9693  Validation loss = 0.8837  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 1.9592  Validation loss = 0.8892  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 1.9569  Validation loss = 0.8903  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 1.9556  Validation loss = 0.8881  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 1.9627  Validation loss = 0.8913  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.9908  Validation loss = 0.8901  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 1.9539  Validation loss = 0.8958  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 5  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.9287  Validation loss = 1.3422  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 1.9302  Validation loss = 1.3336  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 1.9374  Validation loss = 1.3232  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 1.9288  Validation loss = 1.3286  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 1.9252  Validation loss = 1.3334  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.9343  Validation loss = 1.3684  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 1.9232  Validation loss = 1.3362  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.9215  Validation loss = 1.3394  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.9231  Validation loss = 1.3294  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.9309  Validation loss = 1.3104  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.9320  Validation loss = 1.3037  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 1.9183  Validation loss = 1.3138  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 1.9183  Validation loss = 1.3348  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 1.9181  Validation loss = 1.3440  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 1.9125  Validation loss = 1.3227  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 1.9129  Validation loss = 1.3299  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 1.9141  Validation loss = 1.3095  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 1.9093  Validation loss = 1.3172  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 1.9107  Validation loss = 1.3286  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 1.9117  Validation loss = 1.3253  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 1.9146  Validation loss = 1.3427  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 1.9094  Validation loss = 1.3170  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 1.9056  Validation loss = 1.3122  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 1.9091  Validation loss = 1.3042  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 1.9011  Validation loss = 1.3190  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 1.9003  Validation loss = 1.3244  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 1.8986  Validation loss = 1.3175  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 1.9038  Validation loss = 1.2985  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 1.9062  Validation loss = 1.3060  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 1.8947  Validation loss = 1.3168  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 1.9008  Validation loss = 1.3467  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 28  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 1.8668  Validation loss = 0.8082  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.8597  Validation loss = 0.7856  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.8607  Validation loss = 0.7956  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.8575  Validation loss = 0.7790  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 1.8544  Validation loss = 0.7514  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 1.8543  Validation loss = 0.7646  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.8517  Validation loss = 0.7757  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.8559  Validation loss = 0.8019  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.8576  Validation loss = 0.8038  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 1.8576  Validation loss = 0.7910  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.8530  Validation loss = 0.7525  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.8460  Validation loss = 0.7524  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.8553  Validation loss = 0.7201  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 1.8457  Validation loss = 0.7609  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 1.8446  Validation loss = 0.7649  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 1.8559  Validation loss = 0.7914  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 1.8484  Validation loss = 0.7742  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 1.8439  Validation loss = 0.7423  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 1.8443  Validation loss = 0.7240  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 1.8434  Validation loss = 0.7548  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 1.8827  Validation loss = 0.6833  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 1.8411  Validation loss = 0.7366  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 1.8395  Validation loss = 0.7256  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 1.8432  Validation loss = 0.7102  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 1.8362  Validation loss = 0.7461  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 1.8408  Validation loss = 0.7338  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 1.8376  Validation loss = 0.7485  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 1.8349  Validation loss = 0.7253  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 1.8321  Validation loss = 0.7319  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 1.8404  Validation loss = 0.7621  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 21  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.6309  Validation loss = 2.0538  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.6444  Validation loss = 2.1455  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.6252  Validation loss = 1.9823  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.6225  Validation loss = 1.9854  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.6227  Validation loss = 2.0180  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.6191  Validation loss = 1.9760  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.6191  Validation loss = 1.8713  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.6152  Validation loss = 1.8958  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.6143  Validation loss = 1.9691  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.6141  Validation loss = 1.8400  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.6094  Validation loss = 1.9231  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.6089  Validation loss = 1.8872  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.6075  Validation loss = 1.8873  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.6059  Validation loss = 1.8527  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.6035  Validation loss = 1.8396  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.6041  Validation loss = 1.7951  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.6060  Validation loss = 1.7480  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.6036  Validation loss = 1.7588  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.6026  Validation loss = 1.7586  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.5991  Validation loss = 1.7869  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.5973  Validation loss = 1.8034  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 1.5957  Validation loss = 1.7924  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 1.5929  Validation loss = 1.8615  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 17  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 182\n",
      "Average validation error: 2.42419\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.5443  Test loss = 2.4532  \n",
      "\n",
      "Epoch: 2  Training loss = 1.5436  Test loss = 2.4504  \n",
      "\n",
      "Epoch: 3  Training loss = 1.5430  Test loss = 2.4478  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5423  Test loss = 2.4453  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5417  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 6  Training loss = 1.5411  Test loss = 2.4405  \n",
      "\n",
      "Epoch: 7  Training loss = 1.5405  Test loss = 2.4382  \n",
      "\n",
      "Epoch: 8  Training loss = 1.5399  Test loss = 2.4360  \n",
      "\n",
      "Epoch: 9  Training loss = 1.5394  Test loss = 2.4339  \n",
      "\n",
      "Epoch: 10  Training loss = 1.5389  Test loss = 2.4319  \n",
      "\n",
      "Epoch: 11  Training loss = 1.5383  Test loss = 2.4300  \n",
      "\n",
      "Epoch: 12  Training loss = 1.5378  Test loss = 2.4281  \n",
      "\n",
      "Epoch: 13  Training loss = 1.5374  Test loss = 2.4263  \n",
      "\n",
      "Epoch: 14  Training loss = 1.5369  Test loss = 2.4246  \n",
      "\n",
      "Epoch: 15  Training loss = 1.5364  Test loss = 2.4229  \n",
      "\n",
      "Epoch: 16  Training loss = 1.5360  Test loss = 2.4213  \n",
      "\n",
      "Epoch: 17  Training loss = 1.5355  Test loss = 2.4198  \n",
      "\n",
      "Epoch: 18  Training loss = 1.5351  Test loss = 2.4183  \n",
      "\n",
      "Epoch: 19  Training loss = 1.5347  Test loss = 2.4169  \n",
      "\n",
      "Epoch: 20  Training loss = 1.5343  Test loss = 2.4156  \n",
      "\n",
      "Epoch: 21  Training loss = 1.5339  Test loss = 2.4143  \n",
      "\n",
      "Epoch: 22  Training loss = 1.5335  Test loss = 2.4130  \n",
      "\n",
      "Epoch: 23  Training loss = 1.5331  Test loss = 2.4118  \n",
      "\n",
      "Epoch: 24  Training loss = 1.5327  Test loss = 2.4106  \n",
      "\n",
      "Epoch: 25  Training loss = 1.5324  Test loss = 2.4095  \n",
      "\n",
      "Epoch: 26  Training loss = 1.5320  Test loss = 2.4085  \n",
      "\n",
      "Epoch: 27  Training loss = 1.5316  Test loss = 2.4075  \n",
      "\n",
      "Epoch: 28  Training loss = 1.5313  Test loss = 2.4065  \n",
      "\n",
      "Epoch: 29  Training loss = 1.5309  Test loss = 2.4055  \n",
      "\n",
      "Epoch: 30  Training loss = 1.5306  Test loss = 2.4046  \n",
      "\n",
      "Epoch: 31  Training loss = 1.5303  Test loss = 2.4038  \n",
      "\n",
      "Epoch: 32  Training loss = 1.5299  Test loss = 2.4029  \n",
      "\n",
      "Epoch: 33  Training loss = 1.5296  Test loss = 2.4021  \n",
      "\n",
      "Epoch: 34  Training loss = 1.5293  Test loss = 2.4014  \n",
      "\n",
      "Epoch: 35  Training loss = 1.5289  Test loss = 2.4007  \n",
      "\n",
      "Epoch: 36  Training loss = 1.5286  Test loss = 2.4000  \n",
      "\n",
      "Epoch: 37  Training loss = 1.5283  Test loss = 2.3993  \n",
      "\n",
      "Epoch: 38  Training loss = 1.5280  Test loss = 2.3987  \n",
      "\n",
      "Epoch: 39  Training loss = 1.5277  Test loss = 2.3980  \n",
      "\n",
      "Epoch: 40  Training loss = 1.5274  Test loss = 2.3975  \n",
      "\n",
      "Epoch: 41  Training loss = 1.5271  Test loss = 2.3969  \n",
      "\n",
      "Epoch: 42  Training loss = 1.5268  Test loss = 2.3964  \n",
      "\n",
      "Epoch: 43  Training loss = 1.5265  Test loss = 2.3959  \n",
      "\n",
      "Epoch: 44  Training loss = 1.5262  Test loss = 2.3954  \n",
      "\n",
      "Epoch: 45  Training loss = 1.5259  Test loss = 2.3949  \n",
      "\n",
      "Epoch: 46  Training loss = 1.5256  Test loss = 2.3945  \n",
      "\n",
      "Epoch: 47  Training loss = 1.5253  Test loss = 2.3940  \n",
      "\n",
      "Epoch: 48  Training loss = 1.5250  Test loss = 2.3936  \n",
      "\n",
      "Epoch: 49  Training loss = 1.5247  Test loss = 2.3933  \n",
      "\n",
      "Epoch: 50  Training loss = 1.5244  Test loss = 2.3929  \n",
      "\n",
      "Epoch: 51  Training loss = 1.5241  Test loss = 2.3925  \n",
      "\n",
      "Epoch: 52  Training loss = 1.5239  Test loss = 2.3922  \n",
      "\n",
      "Epoch: 53  Training loss = 1.5236  Test loss = 2.3919  \n",
      "\n",
      "Epoch: 54  Training loss = 1.5233  Test loss = 2.3916  \n",
      "\n",
      "Epoch: 55  Training loss = 1.5230  Test loss = 2.3913  \n",
      "\n",
      "Epoch: 56  Training loss = 1.5227  Test loss = 2.3910  \n",
      "\n",
      "Epoch: 57  Training loss = 1.5225  Test loss = 2.3908  \n",
      "\n",
      "Epoch: 58  Training loss = 1.5222  Test loss = 2.3906  \n",
      "\n",
      "Epoch: 59  Training loss = 1.5219  Test loss = 2.3903  \n",
      "\n",
      "Epoch: 60  Training loss = 1.5216  Test loss = 2.3901  \n",
      "\n",
      "Epoch: 61  Training loss = 1.5214  Test loss = 2.3899  \n",
      "\n",
      "Epoch: 62  Training loss = 1.5211  Test loss = 2.3897  \n",
      "\n",
      "Epoch: 63  Training loss = 1.5208  Test loss = 2.3895  \n",
      "\n",
      "Epoch: 64  Training loss = 1.5205  Test loss = 2.3894  \n",
      "\n",
      "Epoch: 65  Training loss = 1.5203  Test loss = 2.3892  \n",
      "\n",
      "Epoch: 66  Training loss = 1.5200  Test loss = 2.3891  \n",
      "\n",
      "Epoch: 67  Training loss = 1.5197  Test loss = 2.3889  \n",
      "\n",
      "Epoch: 68  Training loss = 1.5195  Test loss = 2.3888  \n",
      "\n",
      "Epoch: 69  Training loss = 1.5192  Test loss = 2.3887  \n",
      "\n",
      "Epoch: 70  Training loss = 1.5189  Test loss = 2.3886  \n",
      "\n",
      "Epoch: 71  Training loss = 1.5187  Test loss = 2.3884  \n",
      "\n",
      "Epoch: 72  Training loss = 1.5184  Test loss = 2.3884  \n",
      "\n",
      "Epoch: 73  Training loss = 1.5181  Test loss = 2.3883  \n",
      "\n",
      "Epoch: 74  Training loss = 1.5179  Test loss = 2.3882  \n",
      "\n",
      "Epoch: 75  Training loss = 1.5176  Test loss = 2.3881  \n",
      "\n",
      "Epoch: 76  Training loss = 1.5174  Test loss = 2.3880  \n",
      "\n",
      "Epoch: 77  Training loss = 1.5171  Test loss = 2.3880  \n",
      "\n",
      "Epoch: 78  Training loss = 1.5168  Test loss = 2.3879  \n",
      "\n",
      "Epoch: 79  Training loss = 1.5166  Test loss = 2.3879  \n",
      "\n",
      "Epoch: 80  Training loss = 1.5163  Test loss = 2.3878  \n",
      "\n",
      "Epoch: 81  Training loss = 1.5161  Test loss = 2.3878  \n",
      "\n",
      "Epoch: 82  Training loss = 1.5158  Test loss = 2.3878  \n",
      "\n",
      "Epoch: 83  Training loss = 1.5155  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 84  Training loss = 1.5153  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 85  Training loss = 1.5150  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 86  Training loss = 1.5148  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 87  Training loss = 1.5145  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 88  Training loss = 1.5143  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 89  Training loss = 1.5140  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 90  Training loss = 1.5137  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 91  Training loss = 1.5135  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 92  Training loss = 1.5132  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 93  Training loss = 1.5130  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 94  Training loss = 1.5127  Test loss = 2.3877  \n",
      "\n",
      "Epoch: 95  Training loss = 1.5125  Test loss = 2.3878  \n",
      "\n",
      "Epoch: 96  Training loss = 1.5122  Test loss = 2.3878  \n",
      "\n",
      "Epoch: 97  Training loss = 1.5119  Test loss = 2.3878  \n",
      "\n",
      "Epoch: 98  Training loss = 1.5117  Test loss = 2.3878  \n",
      "\n",
      "Epoch: 99  Training loss = 1.5114  Test loss = 2.3879  \n",
      "\n",
      "Epoch: 100  Training loss = 1.5112  Test loss = 2.3879  \n",
      "\n",
      "Epoch: 101  Training loss = 1.5109  Test loss = 2.3880  \n",
      "\n",
      "Epoch: 102  Training loss = 1.5107  Test loss = 2.3880  \n",
      "\n",
      "Epoch: 103  Training loss = 1.5104  Test loss = 2.3881  \n",
      "\n",
      "Epoch: 104  Training loss = 1.5102  Test loss = 2.3881  \n",
      "\n",
      "Epoch: 105  Training loss = 1.5099  Test loss = 2.3882  \n",
      "\n",
      "Epoch: 106  Training loss = 1.5096  Test loss = 2.3882  \n",
      "\n",
      "Epoch: 107  Training loss = 1.5094  Test loss = 2.3883  \n",
      "\n",
      "Epoch: 108  Training loss = 1.5091  Test loss = 2.3884  \n",
      "\n",
      "Epoch: 109  Training loss = 1.5089  Test loss = 2.3884  \n",
      "\n",
      "Epoch: 110  Training loss = 1.5086  Test loss = 2.3885  \n",
      "\n",
      "Epoch: 111  Training loss = 1.5083  Test loss = 2.3886  \n",
      "\n",
      "Epoch: 112  Training loss = 1.5081  Test loss = 2.3887  \n",
      "\n",
      "Epoch: 113  Training loss = 1.5078  Test loss = 2.3888  \n",
      "\n",
      "Epoch: 114  Training loss = 1.5075  Test loss = 2.3889  \n",
      "\n",
      "Epoch: 115  Training loss = 1.5073  Test loss = 2.3890  \n",
      "\n",
      "Epoch: 116  Training loss = 1.5070  Test loss = 2.3891  \n",
      "\n",
      "Epoch: 117  Training loss = 1.5067  Test loss = 2.3892  \n",
      "\n",
      "Epoch: 118  Training loss = 1.5065  Test loss = 2.3893  \n",
      "\n",
      "Epoch: 119  Training loss = 1.5062  Test loss = 2.3894  \n",
      "\n",
      "Epoch: 120  Training loss = 1.5059  Test loss = 2.3895  \n",
      "\n",
      "Epoch: 121  Training loss = 1.5056  Test loss = 2.3896  \n",
      "\n",
      "Epoch: 122  Training loss = 1.5054  Test loss = 2.3898  \n",
      "\n",
      "Epoch: 123  Training loss = 1.5051  Test loss = 2.3899  \n",
      "\n",
      "Epoch: 124  Training loss = 1.5048  Test loss = 2.3900  \n",
      "\n",
      "Epoch: 125  Training loss = 1.5045  Test loss = 2.3902  \n",
      "\n",
      "Epoch: 126  Training loss = 1.5042  Test loss = 2.3904  \n",
      "\n",
      "Epoch: 127  Training loss = 1.5039  Test loss = 2.3905  \n",
      "\n",
      "Epoch: 128  Training loss = 1.5037  Test loss = 2.3907  \n",
      "\n",
      "Epoch: 129  Training loss = 1.5034  Test loss = 2.3909  \n",
      "\n",
      "Epoch: 130  Training loss = 1.5031  Test loss = 2.3911  \n",
      "\n",
      "Epoch: 131  Training loss = 1.5028  Test loss = 2.3912  \n",
      "\n",
      "Epoch: 132  Training loss = 1.5025  Test loss = 2.3914  \n",
      "\n",
      "Epoch: 133  Training loss = 1.5021  Test loss = 2.3916  \n",
      "\n",
      "Epoch: 134  Training loss = 1.5018  Test loss = 2.3919  \n",
      "\n",
      "Epoch: 135  Training loss = 1.5015  Test loss = 2.3921  \n",
      "\n",
      "Epoch: 136  Training loss = 1.5012  Test loss = 2.3923  \n",
      "\n",
      "Epoch: 137  Training loss = 1.5009  Test loss = 2.3926  \n",
      "\n",
      "Epoch: 138  Training loss = 1.5006  Test loss = 2.3928  \n",
      "\n",
      "Epoch: 139  Training loss = 1.5002  Test loss = 2.3931  \n",
      "\n",
      "Epoch: 140  Training loss = 1.4999  Test loss = 2.3933  \n",
      "\n",
      "Epoch: 141  Training loss = 1.4996  Test loss = 2.3936  \n",
      "\n",
      "Epoch: 142  Training loss = 1.4992  Test loss = 2.3939  \n",
      "\n",
      "Epoch: 143  Training loss = 1.4989  Test loss = 2.3941  \n",
      "\n",
      "Epoch: 144  Training loss = 1.4986  Test loss = 2.3944  \n",
      "\n",
      "Epoch: 145  Training loss = 1.4982  Test loss = 2.3947  \n",
      "\n",
      "Epoch: 146  Training loss = 1.4979  Test loss = 2.3950  \n",
      "\n",
      "Epoch: 147  Training loss = 1.4975  Test loss = 2.3953  \n",
      "\n",
      "Epoch: 148  Training loss = 1.4972  Test loss = 2.3956  \n",
      "\n",
      "Epoch: 149  Training loss = 1.4968  Test loss = 2.3960  \n",
      "\n",
      "Epoch: 150  Training loss = 1.4965  Test loss = 2.3963  \n",
      "\n",
      "Epoch: 151  Training loss = 1.4961  Test loss = 2.3966  \n",
      "\n",
      "Epoch: 152  Training loss = 1.4957  Test loss = 2.3969  \n",
      "\n",
      "Epoch: 153  Training loss = 1.4954  Test loss = 2.3972  \n",
      "\n",
      "Epoch: 154  Training loss = 1.4950  Test loss = 2.3976  \n",
      "\n",
      "Epoch: 155  Training loss = 1.4947  Test loss = 2.3979  \n",
      "\n",
      "Epoch: 156  Training loss = 1.4943  Test loss = 2.3982  \n",
      "\n",
      "Epoch: 157  Training loss = 1.4939  Test loss = 2.3986  \n",
      "\n",
      "Epoch: 158  Training loss = 1.4936  Test loss = 2.3989  \n",
      "\n",
      "Epoch: 159  Training loss = 1.4932  Test loss = 2.3992  \n",
      "\n",
      "Epoch: 160  Training loss = 1.4929  Test loss = 2.3995  \n",
      "\n",
      "Epoch: 161  Training loss = 1.4925  Test loss = 2.3999  \n",
      "\n",
      "Epoch: 162  Training loss = 1.4921  Test loss = 2.4002  \n",
      "\n",
      "Epoch: 163  Training loss = 1.4918  Test loss = 2.4005  \n",
      "\n",
      "Epoch: 164  Training loss = 1.4914  Test loss = 2.4008  \n",
      "\n",
      "Epoch: 165  Training loss = 1.4911  Test loss = 2.4011  \n",
      "\n",
      "Epoch: 166  Training loss = 1.4907  Test loss = 2.4014  \n",
      "\n",
      "Epoch: 167  Training loss = 1.4904  Test loss = 2.4017  \n",
      "\n",
      "Epoch: 168  Training loss = 1.4900  Test loss = 2.4020  \n",
      "\n",
      "Epoch: 169  Training loss = 1.4897  Test loss = 2.4022  \n",
      "\n",
      "Epoch: 170  Training loss = 1.4893  Test loss = 2.4025  \n",
      "\n",
      "Epoch: 171  Training loss = 1.4890  Test loss = 2.4028  \n",
      "\n",
      "Epoch: 172  Training loss = 1.4886  Test loss = 2.4030  \n",
      "\n",
      "Epoch: 173  Training loss = 1.4883  Test loss = 2.4033  \n",
      "\n",
      "Epoch: 174  Training loss = 1.4880  Test loss = 2.4035  \n",
      "\n",
      "Epoch: 175  Training loss = 1.4876  Test loss = 2.4037  \n",
      "\n",
      "Epoch: 176  Training loss = 1.4873  Test loss = 2.4039  \n",
      "\n",
      "Epoch: 177  Training loss = 1.4870  Test loss = 2.4041  \n",
      "\n",
      "Epoch: 178  Training loss = 1.4867  Test loss = 2.4043  \n",
      "\n",
      "Epoch: 179  Training loss = 1.4864  Test loss = 2.4045  \n",
      "\n",
      "Epoch: 180  Training loss = 1.4861  Test loss = 2.4047  \n",
      "\n",
      "Epoch: 181  Training loss = 1.4857  Test loss = 2.4048  \n",
      "\n",
      "Epoch: 182  Training loss = 1.4854  Test loss = 2.4050  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4VFX6xz8nnSSQTu8KhN4CaFhsa0FdFRVRViwLKq69\nwK7oqmtZ13VVLOgPlbWAYi+4axdFbKgQahKqEDChJKEkENLf3x9n7mQmU0MmCZk5n+fJE3LvmXPP\nDZPvvPc9b1EigsFgMBiCh7CWXoDBYDAYAosRdoPBYAgyjLAbDAZDkGGE3WAwGIIMI+wGg8EQZBhh\nNxgMhiDDCLvBYDAEGUbYDQaDIcgwwm4wGAxBRkRLXDQ1NVV69uzZEpc2GAyGVsuKFSuKRCTN17gW\nEfaePXuyfPnylri0wWAwtFqUUnn+jDOuGIPBYAgyjLAbDAZDkGGE3WAwGIIMI+wGg8EQZBhhNxgM\nhiAjIMKulLpVKZWtlFqnlHpdKRUTiHkNBoPB0HAaLexKqS7ATUCGiAwCwoFLGjuvwWAwGI6MQLli\nIoA2SqkIIBYoCNC8znz8MTz8cJNMbTAYDMFCo4VdRPKBR4HtwE7ggIh83th53bJ4Mdx3H9TUNMn0\nBoPBEAwEwhWTBJwH9AI6A3FKqSluxl2jlFqulFpeWFh4ZBcbNAjKy+HXXxuzZIPBYAhqAuGKORXY\nKiKFIlIFvAdk1h8kIs+LSIaIZKSl+Sx14J5Bg/T3deuOeLEGg8EQ7ARC2LcDxymlYpVSCvg9kBuA\neV0ZMEB/N8JuMBgMHgmEj/0n4B0gC1hrm/P5xs7rlrg46N0b1q5tkukNBoMhGAhIdUcRuRe4NxBz\n+WTQIGOxGwwGgxdaX+bpoEGwcSNUVLT0SgwGg+GopPUJ++DBOtxxw4aWXonBYDAclbQ+YTeRMQaD\nweCV1ifsfftCRIQRdoPBYPBA6xP2qCjo188Iu8FgMHig9Qk7mMgYg8Fg8ELrFfatW6G0tKVXYjAY\nDEcdrVfYAXJyWnYdBoPBcBTSOoV98GD93bhjDAaDwYXWKey9ekGbNkbYDQaDwQ2tU9jDwmDgQCPs\nBoPB4IbWKezQoMiYvXv3ctddd1FVVdXEizIYDIaWp3UL+65dUFTkc+ibb77JQw89xJo1a5phYYZg\nYteuXWzwUb6irKyMM888k/vvv5+SkpJmWpnB4JnWLewA2dk+h2ZlZQFw6NChplyRIQj561//yvnn\nn+91zKZNm/j000+599576dWrF//617/Me83QorR+YfejNrsl7GVlZU25IkMQsmPHDvLz872OKbI9\nNc6ePZsxY8Zwxx130Lt3b55/vmnaEhgMvmi9wt65MyQm+vSzV1ZWstYm/kbYDQ2lqKiIkpISKisr\nvY4BOP300/n444/5/vvvOeaYY5g+fTo7duxorqUaDHZar7ArpePZfQh7dna2fdPUPB4bGorVeL24\nuNjjGEvYU1NTAcjMzOQvf/mL0zmDoTlpvcIOdZExIh6HWG4YMBa7oWGIiF2YLYF3hzUmOTnZfiwh\nIQGA/fv3N+EKDQb3tH5hP3AAvPhAs7KyiIqKAozFbmgY+/fvp7q6GvBueRcVFZGUlERERF2nycTE\nRPscBkNz0/qFHby6Y7KyssjIyACMxW5oGI5Wui9ht9wwFpawHzhwoGkWZzB4oVUJ+48//sirr75a\nd2DgQP3dg7BXV1ezevVqxowZQ2RkpBF2Q4PwV9iLi4tdhN24YgwtSasS9oULF3LzzTfXHUhJgU6d\nPIY8btiwgcOHDzNixAhiY2ONKyaEWbBgAStXrmzQaxpjsbdr1w4wFruhZWhVwp6amsq+ffvsfk9A\nW+0eyvdaG6cjRowgLi7OWOwhiogwffp05syZ06DXNUbYIyIiiI+PNxa7oUVodcIuIuzdu7fu4MCB\nkJsLtbUu47OysmjTpg39+vUzFnsIU1RUxOHDh53fN35gCXvXrl0bLOyg/ezGYje0BK1O2KGe9TRg\nABw6BNu3u4xfsWIFw4YNIzw83FjsIUxeXh4A+/bta9DrioqKiI+Pp2vXrh7DHcvKyjh8+DApKSku\n5xISEozFbmgRgkPYwcUdU1tby8qVKxkxYgQAsbGxRthDFEvYj8RiT0tLIzU11aPFXj85yRFjsRta\niqAV9s2bN3Pw4EFGjhwJYFwxIcx229NcSwi7sdgNLUHrF/bkZOjY0UXYHTdOAeOKCWEaa7GnpaVR\nVFSEuMlw9ibsxhVjaClalbBbfkwX62nAAJfyvVbG6QCbRW8s9tDFEvbDhw9TXl7u9+scLfby8nK3\nhoFxxRiORlqVsMfExBAfH+9e2HNynGrGZGVlMWTIECIjIwFjsYcy2x021v3dQBURCgsLSU1Ndf+k\naMMfi92dpW8wNCWtStgB9/7OgQPh4EH47TdA/1FmZWXZ3TBgLPZQJi8vz16gy193zKFDhygvL7db\n7OBZ2MPCwuwlBBxJTEykpqbGGBSGZicgwq6USlRKvaOUWq+UylVKHR+Ied3hVtjrbaDm5eWxb98+\nF2E3f2Chx6FDhyguLmbYsGGA/8JuhTc6Cru7kMeioiKSk5MJDw93OWfKChhaikBZ7E8Cn4pIOjAU\nyA3QvC54FXabn73+xiloV0xlZaVz1qoh6LHcMJaw++uKcSfsnix2d24YMIXADC1Ho4VdKZUAnAD8\nB0BEKkWkyUwUt8KemgppaXaLPSsri/DwcAYPHmwfEhsbC5gKj6GGtXE6fPhwwH+L3XqPBULYjcVu\naG4CYbH3AgqBl5RSK5VS85RScQGY1y1W6JkLDjVjsrKyGDhwIDExMfbTcXF6SUbYQ4v6FvuRuGIS\nExMJDw9vsLAbV4yhpQiEsEcAI4D/E5HhwCHgjvqDlFLXKKWWK6WWe+tG44vU1FRKS0upqKhwPmGL\njJHaWlasWGFPTLKwLHazgRpa5OXlER4eTr9+/QgPDz8iYQ8LCyMlJcW4YgythkAI+2/AbyLyk+3n\nd9BC74SIPC8iGSKSkZaWdsQXs/6IXHpQDhgABw6wNzubPXv2MGTIEKfTxhUTmuTl5dG1a1ciIyNJ\nSkpqkI89Ojqa+Ph4wL0L0GqdZyx2w9FGo4VdRHYBO5RS/WyHfg+4r6MbADz6O20bqPu++w6A7t27\nO51ubldMTU0NNTU1zXItg2e2b99Ojx49AEhKSmqQxZ6WloZSCnAv7KWlpVRVVRmL3XDUEaiomBuB\n15RSa4BhwEMBmtcFj6Fntm5KFbZmCl26dHE63dyumAsvvJBp06Y1y7UMnsnLy7N/yCcnJzdI2B0F\nOzU11eU95y05CXRCXWRkpLHYDc1OhO8hvhGRVUBGIObyhUeLPS0NUlIIW78ecBX25rbYf/zxR49/\n8Ibmobq6mvz8fLvFnpyc7LH8bn0si93CncXuS9iVUqasgKFFaJWZp+BG2JWCAQOI3bYNpRQdOnRw\nOt2cFntpaSl79uwhLy/PpJO3IAUFBdTU1DgJe0N87PWFvbi4mFqHhi6+hB1MITBDy9DqhN1KDfcU\n8pi6ezcd2re314ixaE6LfcuWLYD+EGloRUFD4LBi2C1XzJH42C1SU1Opqalxsr69Cnt5OXz3nSnd\na2gRWp2wR0REkJSU5F7YBwwgrrKSIfWsdWjeqBhL2KFOXAzNj/W7d7TY9+/f73NTu6KigtLSUidh\nt/7t+L7zKuwLFsC4cZxVWWlcMYZmp9UJO3jIPgV7ZMyoONf8qOZ0xRhhPzqwkpMcN09FxKfQOmad\nWrhzARYVFREREUG7du1cJ1m1CoAbNm+mwjy1GZqZoBT2QW4KMrVp0wZoHot98+bN9qzXbdu2Nfn1\nDO7Jy8sjNTXV/qFuufF8+dkdk5MsPAl7amqqPSTSibVroUMH0srKuDI/v1H3YTA0lKAS9oqkJPYC\nfepnpQJhYWG0adOm2Sz2YcOGERcXZyz2FiQvL8/uhgHtYwffZQV8CvuECfDEE56Tk0Rg3TqYMIGf\nBw7k2oMHXTp8GQxNSVAJe8HOneQAnT08ajdXs40tW7ZwzDHH0KNHDyPsLYhjchLgd012b8J+aOtW\nWLQI3nnHs7Dv3An79sGgQXz7hz9QCtRed51TIxiDoSlp1cJeP5SwoKCAHCBl9263r2uOZhsVFRVs\n376dY4891gh7CyIiTslJ0HBhdxTtuLg4oqOjabdmjT6wciV76yUx2Vm7Vn8fPJjIzp2ZBYR98w0s\nXHjkN2QwNIBWK+zuelDm5+eTA0QdOABuElGao9nGtm3bEBFjsbcwxcXFlJWVuXXF+ONjDw8Pt48H\nnWyUmppKx02b9IGyMhJ373Yv7OvW6e8DB5KYmMg8oHzIELj9djChj4ZmoNUKO7jGsufn52NvaV2v\nuTU0jyvGioixhH3v3r2UlpY26TUNrlgRMUfqY09JSSEszPnPIzU1lV75+dCxIwC99+/3LOwdO0Jq\nKomJidQCW2fO1MbG3Xc34q4MBv8IKmEvKChgc3S0/uGee2DDBqfzzeGK2bx5M4DdFQMm5LElqJ+c\nBBAVFUV8fLxfwu6uAmm3pCR6HTgAV16JtGnDcBHPrhhbkxerwmNBp04waRK89daR3pLB4DdBJez5\n+fmEd+0K8+bBmjX6j+vOO8Em5s1lscfHx5OWlkbPnj0BI+wtQf3kJAt/CoF5EvbjsRVXOvlkyvv1\nYwRukpNqanQEzKBBQL0Kj+npsGcPVFYeyS0ZDH4TdMLeuXNnmDYNNm6EP/4R/vlPHd++aFGzWOxW\nRIxSyljsLcj27dtp06YNKSkpTsf9qcleVFTkVtiHHzpEDcDxx3Ogd2+GAykOfngAtm6Fw4ftwu5U\nk71zZz1m164juSWDwW9atbDXr9RXUFBQV9WxfXt4+WVYuhQSEmDCBI6trGxyi33z5s0cc8wxAHTs\n2JGoqCgj7C2AFcNeP3moMRZ7emEhq4CqmBh2delCO6BL/feTtXFqc8U4WezWe7OgoMH3YzA0hFYp\n7ImJiYSFhTlZ7CJCfn6+S7lexo2DDz4AYPCBA00q7DU1NWzdupVjjz0W0ElR3bp1M8IeIPbs2cOf\n//xn+8aoN+onJ1n4Evaamhr27t3rKuyVlXTLz+db9ObrNtuTQMf6Im2FOtqyoNu2bQvUs9hNJqqh\niQlIPfbmxl0Pyv3793P48GHtiqlPr16QnMyx+/Y1qSsmPz+fyspKu8UO2scbrGUFFi5cSEFBATNm\nzGjya1VVVXHRRRexdOlSKisr+c9//uN1/Pbt2xkxwqVDo09hLy4uRtxtimZlEVFVxbfAaUVFbImO\nphxIsG2W21m3Dnr3Blu9ovDwcNq1a+cs7MZiNzQxrdJiB9fs0wLbH4uLxQ66VntGBj0KCykrK2uy\nGulWRIyjsPfs2TNoLfY5c+Ywc+ZMXn311Sa/1m233cbSpUsZNmwYr776Kjt37vQ4tqysjMLCQrcW\nu+Vj9/QecJd1CsC33wLwHdoHv2ffPtYqRaRloVusW2d3w1jYm22kpkJkpBF2Q5MTNMKeb3u8dSvs\nAKNG0aGwkKjaWirc1JIJBFYMu+WKAW2x79q1i/Ly8ia5ZkuyY8cOAK655hrWWBmZTcBLL73EnDlz\nuP3223n77bepqqriqaee8jjeXQy7RXJyMhUVFRw+fNjta70Je3mPHuxBC3tRURG5sbGorCywmm9U\nVOgQW9vGqYW92UZYGHTqZFwxhian1Qp7WlqaW4vdrSsGICODsNpahtF0FR63bNlCZGQkXbt2tR+z\nxMUSwWChurqagoICrrnmGpKSkrjggguapKHETz/9xLXXXsvvf/97Hn74YY499lguuOAC5s6d6zHx\nq365Xkd8lRVwK+y1tfDdd9QcfzxQJ+zbkpKgpAR+/VWP27BBhzt6sthBu2OMxW5oYlqtsHuy2D0K\n+6hRgG7M2hBhf+655/jtt9/8GrtlyxZ69epFuEPZ4GANeSwoKKC2tpaMjAzefvtt8vLyuPzyy51a\nxzWWXbt2ccEFF9C5c2fefPNNIiL0ltDMmTPZv3+/Rz+7pxh2OEJhz8mBffuIOuUUoE7YCzp10uez\nsvR3KyLGk8UORtgNzUKrF3bLV5qfn09KSoq9DroLXbpQlpjIKPxvtrF//36uvfZa/vGPf/g1fvPm\nzU5uGKgTl2DbQLWeQLp160ZmZiazZ8/mv//9Lw899FDArjFlyhT27dvHBx984BSPPmbMGMaNG8fs\n2bOpqqpyeV1eXh5hYWFu3XK+6sVYwu4U/27zr0eecgpt27alsLCQoqIiSnv00D7zFSv0uLVr9c99\n+zrN6WSxd+liXDGGJqdVC7tjD8qCggLP1rqNA336MAr/LXZr7vfff99nOzURsScnOdK1a1fCwsKC\nzmKv7+64/vrrmTJlCvfccw+ffvppo+c/dOgQixcv5rbbbmPo0KEu52fOnMn27dt5++23nY6Xlpby\n9ddf06VLF7uF74gvi72oqIikpCTnnrnffad947172w2KoqIikjp00G4XS9jXrdPZpfX67bpY7CUl\ncPCgv78Kg6HBtGphh7rsU7cx7PU41L8//YDyPXv8ukZJSQkAu3fvZtmyZV7HFhUVUVpa6iLskZGR\ndOnSJeiE3dFiB1398LnnnmPw4MFMnjzZHiF0pGyw1flxJ+oAZ599Nunp6fz73/+2P7WtWbOGjIwM\nli1bxh133OH2df64YtxGxIwbB7YKj7t27WLfvn36PThypHbFWM016rlhoM5iF5G6kEcvUT0GQ2MJ\nKWGvHDqUMCDCzwgOS9gB3nvvPa9jHYt/1ScYy/fu2LGDhIQEewIO6CJrH3zwAeHh4Zx33nmNqmq5\nfv16APr37+/2fFhYGDNmzGDVqlUsXryYefPmMWbMGEpKSvjyyy+57rrr3L6uwcKelwc7dsDvfgfo\n992mTZvqYt1HjtRNNdauhW3b3Ap7QkICtbW1HDx40GSfGpqFoBD26upqdu/e7dMVUzN8OABtrE0u\nH1jC3r59e9577z2v8e+O5XrrE4zCvn37drdRJ7169eKtt95iw4YNXHbZZUe8mZqbm0tYWBh9+vTx\nOGbKlCl07NiRiy66iKuvvpqxY8eyatUqTj75ZNfBt98O775LXFwcERERXn3sTslJNv8648YB+n1n\nuaFSU1PBSoKaP19/rxcRA3VlBUz2qaG5CAph3717N7W1tT4t9uguXdgKtLVZg76whH3KlCls27aN\nVbbO8+7YsmULSil69erlcq5Hjx789ttvVFdX+3Xd1sCOHTvsbpj6nHLKKTz22GMsWrSI+++//4jm\nX79+Pb179ybaKsPshujoaGbMmMGBAwe47777+Oyzz+jQoYPrwPJyeOIJuP9+lFKes08XL+aL7Gxe\n/fRTSEqCxERdUK5dO7tgu7TLGzwYIiLgtdf0QQ+uGLDt2ZjsU0MzEBTC7jPU0UZcXBy/AElW3LEP\nHIU9LCzMqztm8+bNdOvWza0Q9ejRg5qaGvs6gwFPFrvFTTfdxBVXXMF9993H+++/3+D5c3NzPbph\nHLntttvYvXs399xzj1OYqRMbNuhY9DVrYP16j8IuTz9NWG0tawcOhMsugyuvhOuu02WgbXM7WvOp\nqakQEwMDB+qKjXFx4CbE0qnCY7t2epwRdkMT0mqFPT4+nqioKB1P7K2cgAOxsbEsB9oVFYGbZtj1\nsXzExxxzDCeccIJXYXcXEWMRbHXZy8rKKC4u9mixg95MnTt3LqNHj+ayyy5r0GZqdXU1Gzdu9EvY\nlVJuKzE64dhN6+23SUpKchX24mL4+GNeAZZNmQJPPaWt/Nmz4aKL7MNchB20nx20tR7m+iflZLEr\npa32IPqQNxx9tFpht3pQFhYW+i4nYMOy2AFYvtznNSyLPT4+ngsuuICcnBz7pl59vAl7sCUpWQlb\n3oQdICYmhnfffZeamhoeeeQRv+ffunUrVVVVpKenN2qddrKztcU9ejS89RbJycmuPva330ZVVfEq\nbsoJOOAo7PZYd0dhd4OTxQ4mScnQ5LRaYYe6JKWCggIiIiJ8Wm6RkZGssiwqP4U9Pj6esLAwJkyY\nAODWrVBaWsqePXvcRsRAXax3sAi7t5T9+nTt2pUrr7yS+fPns3v3br/mz83NBTxHxDSY7Gzo00e7\nV9atY1BYmKvF/uqrHOrVi9X4J+xxcXG0adNGH7Q2UD0Iu5PFDkbYDU1OUAh7fn4+nTp1cmk+XB+l\nFDVxcexOSoJffvE6FrSwt2vXDtDW6ejRo926Y7xFxAC0adOG9mlpdP7iCx0S10wcPHiQtfWrDwaA\n+jHsvrjtttuorKxkzpw5fo23nooCZrHn5Gg/+IUXglKctGePs7D/+it8/z15tpBGf4TdKXJm9Gj4\n179gyhS3r3Gx2K3s0yaqMmowBEzYlVLhSqmVSqn/BWpOXzgKuy83jEVcXBxbU1IaLOwAF1xwAcuX\nL3dp9OBL2AEmpKQwdelSOP98cJMG3xTMnj2b0aNHB7yypCXs/v7O+/Tpw4QJE3j22Wf9KueQm5tL\nx44d7ZZuoygvhy1btLB36gQnnsjILVsoKSmpi1JauBCAFf36ATq81RNuhT0sDP7yF12W1w0xMTFE\nR0c7u2IqKnT8u8HQBATSYr8ZyA3gfD5xdMX4ioixiI2NZWNCgs788/E4XFpa6iTs559/PgAf2Doy\ngbbCPvzwQ8C7sF9z4ACHlYJVq+Dhh/1aa2NZu3Yt5eXlfhcx85ft27fTsWNHr6GI9ZkxYwZ79+7l\npZde8jnW34gYv1i/XkfE2DoaMWkSaUVFDMRmQYvAggVw4ol8vn497du39/qBlZycbN/faQguFR7B\nuGMMTUZAhF0p1RU4G5gXiPn8JTU1lb1797Jjx44GWey5tu42vqz2+hZ73759GThwIO+99x4rVqxg\n2rRpdO7cmfnz5zNx4kSnsU7k5DBy507+HRaGXHwxPPBAXQu1JmTTpk0Azk8YNTX6qxF4i2H3RGZm\nJpmZmTz++ONe4/lFhC25uYzr3BmWLAFLDI8UKyJm4ED9/YILqFWKi7Flny5fDhs3IpdeyjfffMNJ\nJ53k0ifVkfDwcJKTk12aZPvCqV6M9V41kTGGJiJQFvsTwF8Aj2mGSqlrlFLLlVLL6zehPlIsq6m0\ntNRvYY+NjSU7MlJHSTRQ2EG7Y7755hsyMjJ44403mDJlCllZWS7FqJx49FGqoqJ4sqaGPXffrRNf\n/vQnaMKEJRFh48aNgIOwV1XBySfrEsaNqJ1+JMIO2mrfunWr6wZ0WRk8+CCMG0dtly7sLinhvtde\n02udOLFxvujsbJ1AZFVc7NCBvUOGMAnYW1wMr74KUVHkjRrFjh07OPHEE31OOXv2bG666aYGLcNY\n7IbmpNHCrpT6A7BHRFZ4Gyciz4tIhohk+Iw79hPHx+GGuGL2VVToCAYfkTElJSVOtVAApk2bxlln\nncXTTz9NQUEBzz//PMNtpQrckp8Pr77Kb6edxl5g28GD8MwzuiLgo4+6H//llzquuhEUFBTYq1ja\nhf0f/9Ap8qtXwwUXQGVlg+cVEZ/JSZ4499xz6dOnT13hLhF44w1dEfHuu6G2lj2DB3M/kD1jBsya\npX8Xr7/e4GvZycnRETFRUfZDJePH0w+o+flnPfc55/D1ypUAnHTSST6nvOyyyxgzZkyDluFksVt1\n3I2wG5qIQFjsY4FzlVLbgDeAU5RSTd8EE2dhb4grpqysTFuty5bpzTUPuLPYe/TowUcffcQNN9xg\nj3bwylNPQU0N5baiVHl5eTrh5cIL4d57tfCIwFdfaeu0Rw847TS9Ede3L1x+OTz7LDTQT265YcAm\n7D/9pK3iKVPg5Zfh669h6tQGW8P79+/n0KFDR2Sxh4eHc9ttt/HLL7+wct48XX9l8mR9r0uXwvff\n8/5553EfkHjLLdplNXo03HoreGlA7ZXs7Dr/ug2ZMIFqoN9TT0FhIUyZwpIlS0hLSwucb78eThZ7\nmzaQnGyEPRCIwEMP1TU5MWhEJGBfwEnA/3yNGzlypASCrKwsAQSQ9evX+/WaSZMmSb9+/UQWL9Y2\n47x5bsfV1tZKWFiY3HXXXUe+wAMHRNq1E7n4Yjlw4IAAcu211+pzu3aJpKSI9O8v0q+fXktKisjM\nmSKffCLy8MMiEyaIdOigz40b16BLP/fccwJIhw4d5JyTTxY59liR7t1F9u/XAx58UM87a1aD5l29\nerUA8tZbbzXodRZlhw7JQ7GxUgMi7dvr3391tf38DTfcIG3btpXa2lp9YOVKkfBwkauuOoKLlYko\nJXLPPU6HCwsL5TMtCSJJSSLl5dK9e3eZOHHiEd2TP1x11VXSsWPHugODBomcd16TXS9kWL5c/z8e\nf7yI9Z4JYoDl4ocWt/o4dgt/XTF2i/3kk2HIEJ0y7sZqPXz4MLW1tZ43RP3h+ed1U4WZM2nXrh3X\nXXcdc+fO5c0334QOHbRLJjdXF5yaP19b5Y88AuPHw1//Cu+/Dzt3IjffjPz0k9eni/ps2rSJ6Oho\nxo4dy6VZWTrkb/58sJ4y7rwTrrkG/vlPeO45v+dtSHKSC7W1tJk1i1llZSwEtn72mS6y5VDjZf36\n9aSnp9dtYA4bpi32efPqKi36y/r1+v/W2ji1kZiYyFvWD5MmsW3nTrZv3+6XG+ZISUxMdO4JG8JJ\nSrW1tdx2222sXr268ZPZQlX58Uf45JPGz+cP+/frjf2jOQ/BH/UP9FegLPZDhw4JIG3btvX7Nddf\nf70kJyfrH156SX/af/65y7idO3cKIP/3f/93ZIurqBDp0kXklFMcDlVIZmamxMbGyurVq/XBvXu9\nTrNnzx6Z2aePCMgfu3eXP/zhD3LrrbfKs88+K3u9vPbcc8+VgQMHyrzzzhMBqZ0503VQVZXI2WeL\nhIW5/R2449lnnxVA8vPz/Rpvp7JS5LLLREBKpk2TcKXk7rvvdhnWpUsXufzyy50PHjyonzb699e/\nV3959VX9/7tuncuprm3bytpevUSys+Wll14SQNauXduwe2oADz74oABSXl6uD/zpT/r9EYJs2bJF\nALntttsaN1F1tUjnziJnninSu7fI8OEiNTWBWaQnampEfv97/b664gqRQ4ea9nr1IBQs9tjYWGJj\nY/32r1tK+zu/AAAgAElEQVSvsbfGmzxZW86zZ7uMs+rEHLHF/vrreiN05kz7oaioKN555x0SEhI4\n//zzdbidrQenO3bu3MlJJ53E6zYreXzbtuTl5TF37lyuu+46r/VXNm7cyKgePZi8eDGrgOKbb3Yd\nFBEBb74JvXrpzUs/2LFjBxEREe7L43ri8GG9p7BgATzwAG1feIHTzjiDl19+2anlYElJCfn5+a4Z\np3Fxep8hNxf+/W//r2tFxLip6R6RksIjv/sdDBjAkiVLSE1NZUA9X3wgsfZjnCJjdu1qdOhpa8Qq\nGZHtWJztSPj2W/3Uc8UVer9q5Ur9lNuUPP00LF4MZ5+tn4CPPx4c9rOOFlq1sIN2x/jrhgHtiikv\nL9eCEh0N11+vH+FynXOrLGGvHxXjN08+qWt1n3GG0+FOnTrx7rvvsmPHDv74xz967KW6fft2Tjjh\nBPLy8ljw6afQty+X9e7NmjVrOHToECNHjuTnn392+9qamhq2bNnC9du3E11ezqXAdk91WuLi4Oab\n9eaqh/nqr6tr166eS+TWp7wczjoL/vc/7Xr6299AKaZOncqOHTtYvHixfajVDs/tBubZZ+tN5wce\ngK1b/bu2VSPGISLGwrF07zfffMOJJ57osyRFY3BbL6amBvxs0xhM5OTkALCusRueCxfq9+8558Cl\nl9ZFV7n5m1qxYgU33nij/dpHRE6OdpGecw7897/w8cfafZqRAT46rDU3rV7Yr7zySiZPnuz3+NjY\nWED70AG49lot8E884TTOo8W+fTtcdZX3OPCcHG09XHWVLtNaj+OPP545c+bw2Wefcdddd7l0Gdqy\nZQvjxo2jsLCQL7/8Uvt+x46FH36A2lqUUowaNYoVK1a47VCUl5dHn6oqRmRnU3jJJeSASxkEJ664\nAtq21daIDxocw/7SS9of+dJLura5jXPPPZfk5GRefPFF+zHLkvNYI+axx3Qqvr/hj9nZLv51C0vY\n8/Ly2LZtm1/x643Bbb0YaHY/+65du/jb3/4W8DITDcES1/z8fOd9h4ZQUQHvvKNLdMTG6n2a++/X\nBpqb98fzzz/PnDlzGDRoEJMnT7a/1/ymslJHlLVrBy+8oP+ux4/Xf+fp6fqJ9KGHjuxemgJ//DWB\n/gqUj/1IeOaZZwSQ3bt31x286iqRmBiRwkL7offff18AycrKqhtXW1vnX3vsMc8X+dvftN96506v\na7nmmmsEkOjoaOnbt6+cfvrpMn36dOnUqZOkpKTIihUr6gbPm6evm5Nj+3GeALJx40aXeT/55BN5\nD6QqLk4K168XQJ588knvv5ibbhKJjPS55l69eskf//hH73NZ1NSI9OkjMmqU24iFG2+8UaKjo6W4\nuFhERGbNmiURERFSWVnpec7hw/2LEDp0SEfE3Huv29MXXXSRpKenyyuvvCKArFmzxp87OmKWLl0q\ngHzxxRf6wM8/6//PRYua9Lr1ufLKKwWQl19+uVmv68jo0aMlKipKAPnuu++ObJJFi/Tv76OP6o7V\n1IgMHSpyzDF6T8eBsWPHyogRI2TWrFkSFxcnSimZPHmybN261etl1q9fL8nJybL76qv19T74wHVQ\nebnIRReJRESIbNp0ZPfjJ4SCj/1IsCx2p2JUt9yiXQYO0SFWkw0ni/2ll7R/LT5ef2q72xUX0Y+I\nv/89dOzodS1PP/00L774IjfddBNDhgyhuLiYt99+m5iYGL755htGWOVgwd5Mme+/ByAjIwOA5W6S\nrEo//5zzgcM33EBK377ExMR4t9gBbrhBZ6Z6iZCpra3lt99+8z8i5qOPtP/xttvcPrlMnTqViooK\nXrdZWLm5ufTp04fIyEjPc555pn5y8WXpbdjgNiLGwrLYlyxZQkpKCgM9jAsUbmuyQ7Na7OvXr2e+\nrTfrCy+80GzXdUREyMnJ4Qybi/KI3TELF0JKis75sAgL07kaW7boXA2ADRuQBx5g7o8/8u26dTy0\ndSsFTz7J3bfeyqJFi7jyyisdF6fzGqyneeDLL78kfe9eUufN0xFc553nupboaJ2vEh2tXY1HA/6o\nf6C/WtJif+uttwSQdfUjJc44Q6RTJ3vUxZw5cwSQPXv26PMFBSKJidpatKznb791vcCyZfrcSy8d\n8Rpr3cXj1taKpKaKXHmliIhUVlZKTEyMa2RBba1s7NxZdikltaWlIiLSt29fueiii3xf+KyzdNy8\nh8iTgoICAeSZZ57x70ZOOkmkWzcX68mRYcOGyYgRI0REpF+/fnL++ed7n3PpUv37fecd7+MWLNDj\nsrPdnraeDnr16uX7mgEgLy9PAHnhhRf0gaoq/VTnJjKoqZg0aZLEx8fLzJkzBZBsD7+bpmT79u32\n91B8fLzceOONDZ+ktFSkTRuRP//Z9VxtrciYMfp9PGSI2PKb5VuQnOOOE0lL08eio2Vt797yTHi4\n1Jx1lsjAgSKxsfbxkpYmkpEhv/ToIXkgO2NjRUpKvK/r7rv1a5cvb/g9+QnGYnePW4sddKz0zp12\n/5yLj/2GG/Qn+bx5cMkl2tf2/POuF1i4UH9y2ypBHglui1ApBZmZdos9MjKSYcOGuVrsn35Kn4IC\nXuraFRUfD+iYc58WO8BNN8Hu3eCh7k2D6rBnZWnf+k03gRcLfOrUqWRlZbF8+XK2bNniO/Pz+ON1\nLL6vmGUrIsZD85OkpCSqq6vZunVrk8avW7hsnkZE6IgsPwqBLV68mHPOOce165M3du7UNeJPPBHm\nzGHVypW89dZb3HLLLcyYMYPIyEjmzWtczb4dO3YwceLEunvyA8u/PmjQIAYMGHBkFvuiRfpv8Y9/\ndD2nlL7vvXv1vtETT7BkwQLGAXseflj/Xr75Bq69ll4lJVxWU0PFpk36fTJ9ut5re/BBmDABkpNJ\n2bWLaODq6GjE9vfkkRkzdBb1HXc0/J4CjT/qH+ivlrTYv/rqKwHk66+/dj5RW6v9c5GRIvfcI3+b\nMUMiIyP1uXfe0Z/EDz9cN/7aa7Vf3jGWvKpKZ1NeeGHTLP5f/9Lr2LVLRHSWZnx8vFRbmZs2H+O2\niAi51MFCnzp1qnTq1Mn3/DU1In37aovHDW+//bYAsmrVKt9zTZkiEh8vsm+f12FFRUUSFRUlp59+\nugCyYMEC33NPnKhjwL1lGp5zjsiAAR5PW3sUQF1OQRNSU1MjSin529/+Vndw5EiR8ePrD9Tx9//6\nl8js2fLbrFlyQ3S0nAry5BNPeL9IZaXI++/rew8P1++Vnj1FQH5u316ObddO9tn+PyZOnCgpKSl1\ncfVHgJXT8N///tfv1zz++OMCSGFhoUydOlXat2/v92tra2vlxhtvlE39+uknQW8x6w7ZzI8++qj9\nmo5s2rTJ+SmqHmVlZRIeHi4dO3YUQLZs2eJ7kU88IZ5yYwIBxmJ3T5ytZK89lt1CKfj8c5g0Ce6/\nnxvmzeOsNm30J//11+v2Z7ffXjf+mmu0X/611+qOffWVDl9zZ0kEAsvP/sMPAIwaNYqDBw/awwR5\n4w1YvZo7a2o4xsHy7d69Ozt37qSiosL7/GFhcOONOvTxp59cTvttsefn67VcdZWuZOmFlJQUzjvv\nPD7//HPAz65J48fra3iz9qyuSR5ITk62fx/koaVdIAkLCyMhIcHZunWXfbpwoY6++Otf4dZb6fLP\nf/J0RQVfAJtnz0bc7euADvEbN04/KS5frvMnNmyAX39l6+23M3jPHlbW1pK4bBkAV199NcXFxU69\nBRqKFVnSkAzSnJwc0tLSSE1NZdCgQezZs4c9foZ8vvLKK7z+9NP03LBB56B4C091CMddt24dHTt2\ndKmhf8wxx5CYmMgvHqq8rlmzhpqaGq699loAfrD93Xnl2muhZ09ttbuJWGsuQk7YPbpiANq312Vc\nP/8cqqv5oKREF6EqKoL//Ec/PlsMH66bGD//fN0m6sKF2k1w1llNs/iRI7Wbx90GamUl3H035f36\n8boIfRyScqzNznx/6n97CX3csWMHsbGxJHlJqgJgzhz9pvaztO3UqVPt//Zb2AE+/dT9+bIy3e7O\nD2E/4YQTmjR+3RGnCo+gQx4dhf3gQS3oo0ZRmp/PuIED6R0bS84nn7A/LY1peXlkeapI+tpr+sP4\niSd0SO4//6mLyCnFVStXckZyMrHdu+vN51tu4dQxY+jRo0ejNlEtYV+zZo3fr8nJybG726wNa38S\nlbZs2cKNN97IxWFhRABlth7E/pCdne12c1wpRUZGhkdht9ycV1xxBW3btuXHH3/0fbHoaJ1rkZUF\nb73le3wTEXLC7tFid+S007jxpJOY17495OXpuirDhrmOu/pq3TDj55+1z++993Q8a0xM0yw+Olon\nQ9iEvV+/fsTFxek34BNPwK+/snLSJATdFMTCEna//Oxt2+qqj2+9pa1eB6xyvd4aUXDwIMydq8sC\n9+rl122ddtppdOnShW7duhHvy48JWhAHD/bsZ/dQI8YRq1FGU8evO+JU4RG0xV5UpGOyQYtxQQHV\njz3GpGnT+HH9ep59910GjB9P5IMPMhRYddddrhOXl+vEnIwM/cTlYIB89dVXfPXVV5x/992ELV+u\nzz/5JGH9+jFn6FCWLF5sb+3YUBoq7CJCbm6uPcPXelLKzs7WZaz794c//1nXfXF4MqmurubOiRN5\nsLKSR2NiyAFWe3pyqUdtbS3Z2dken8pGjRpl7zRWnxUrVpCamkqPHj0YM2aMfxY76Cf2IUN0hMwR\nlMYOCP74awL91ZI+9l27dvkV2XHyySfLuHHj9E64J1/ugQMicXEi06aJvP229q19+WUTrNqBv/xF\n7wOUlYmIyLhx4+T84cN1lMCECfLII48I4FRHZuPGjQLIK6+84t81tm7VlSbbtBF55hn7/Y8ePVpO\nO+0076+dM0f/Hn74oUG39eGHH/rnX7ewfg/uIhXmz/caESOi/bXPPvuslPiKdAggJ5xwgpxwwgl1\nB6zoqq1bRbZsEYmOFpkyRaZPny6APPfcc3Vjq6tlR0KCbAwLk7L6a37sMRGQO0aPlm7dusno0aNl\nwoQJct1118nAgQOla9eucvjw4brxy5aJjB0rArIW5KVJkxpcGdGqVtq2bVsJCwuTMtv70RtW/aWn\nnnpKRPT/QWJioky/5hpdnbFtW/2eA12N9P77RebPl1979RIBqQkLk0Pjx8tgkGeffdavdVp1aTz5\n0d977z0B5Mcff3Q5N2TIEDnjjDNEROSee+6RsLAw/98vH3+s72PuXP/G+wl++thDTthLSkoEkH//\n+99ex40cOVLOPvts3xNOm6bF/dRTRTp2dNq0aRKsxIxvvhERkVtvuUU+DguT2vh4ke3b5eqrr5bU\n1FSnl5SVlQkgDzzwgP/Xyc/XIaCgv+fnS6dOnWTq1KmeX1NRoZNDjjvuSO6sYXz1lXhMGLnjDi36\n3hKdWoBzzz1XhgwZUnfgk0/0PXz/vcgFF4jExcnqjz8WQGbMmOHy+rX33y8C8sPVV9cd3LdPJDlZ\ntqWnCyDnnHOOnHbaaTJo0CBJTk4WpZT7D/TaWpF33pF8W4hfzdln62JrfvLTTz8JIFOmTBFAlvsR\n4rd48WIB5EsH4+d3v/ud/C09Xf8eXnhBG0svvqhDZW2hh1tA3hw6VKSgQGprayU5OVmuueYav9b5\n4YcfCiA/eDA0duzYIYA8/fTTTsetjdM777xTREQ+/fRTl7V7pbZWh1tmZvo33k/8FfaQc8VYPnav\nrhjcN9lwy9VXw6FDutPPJZc4bdo0CZmZ+rvNHXN+bS1n1tay889/hm7d2Lhxo5MbBqBNmza0b9/e\nP1eMRefO2tXx7LOwdCkyeDCZO3d6T0566imdHOJnQbFGMXasThSr72f/7TddnGnoUK9hli1BSkoK\n+fn5dfWBrCSlBQu0G+/OO3nlyy+JjIzkzjvvdHn9gDvvZE10NL0WLKhz3zzyCOzdyyXbtjF+/HgW\nLVrE559/ztq1aykuLqaqqorLL7/cdTFKwYUXsmL+fGYC6pNP9N7QwYN+3YsVtnjxxRcD/rljrNc4\nFlsbmp7O1I0bkcGDdbvIdu3096+/5uC6dVzUpQundOvG6UuWQKdOKKUYNmwYq1at8mudVjilpwS0\nLl260LFjRxc/u7Vxau1jjRkzBqWU/+4YpXQgxg8/NLhJTiAIOWEPDw8nOjra/eapA+7a4rll9Gjt\n74Wmi4ZxJDVV16b4/ns4cIDjX3+dLOAz22apO2GHBsSyO6KU9nmuXEll1668BYyxZeS6sHMn3Hcf\n/OEPTbd57EhUlM7u/eSTOn/sgQP62qWlerP7KOPss8+muLjYHgFkF/a5c6FXL2pvuYU333yT8ePH\nu92gDgsPJ/uSS+hYXk7Rww9Dfj7yxBN81bkza8PDmTt3rsv+h69ibWeedx4LO3fmrm7dqP32W/Zk\nZLDkf/9j3bp1VFVVeXxdbm4ukZGRnHbaacTGxvot7ImJiXR0yMi+pLiYXrW17J01y8Uoeui113i3\noID5r75qzwMAGDZsGGvWrPHaFN0iOzubbt26eTTSPG2grlihO32OHDkS0PsjAwcO9G8D1WLiRP39\n3Xf9f02g8MesD/RXS7piRESSk5Plhhtu8DqmTZs2bh+H3bJokc4Iba4OLtOm6SzY66+XWqXkpLg4\n+fOf/yylpaUCyD/+8Q+Xl1xwwQXSv3//I77kt599JutAypOT7XH0Tlx2mUhUVJPXynBi7lyx18+p\nrNTusIiIJoshbiwVFRWSmppa16mptlb/zkDkvfdkyZIlAsjChQs9zrFj+3b5BqQkPl5kyhSpDg+X\nniBP+Ipx98Ls2bMlKipKJoFUgSwFiQfXuvgOnHPOOTLAlicwevRoOcWh74AnTjzxRMl0dE0UF0tl\nfLx8AvLZZ585ja2srJQOHTrIeW66TM2fP18AybHVTfLG0KFD5cwzz/Q65r777hOllJP//E9/+pOk\npqY6ZYFfffXVkpiYKDUNqfk+eLDezwgQGFeMZ2JjY71a7NXV1Rw+fNj/WuznnqvryHiLFgkkY8fq\nWinPPIO64QbU6NEsX77c3ufUm8UulnXbQLbt2cMlQOShQzok0jFG9/vvtTthxgyPmZ5NghX2+Mkn\nOq/gyy91DR/H+iFHEVFRUUyZMoVFixZRVFSk3y99+8Kpp8KECbz++uvExsZy7rnnepyja7du/HfM\nGNoePAivvsq8yEjajx7NDTfccMTruuWWWygvL2fu3r3sfvxxfhcWxrKEBJZ9/rnH90tubq49bHHI\nkCGsXr3a53srJyfHueb9Aw8QUVbGDFxDHj/++GN2797tFAprMcwWoebLHVNdXU1ubq7PPIVRo0Yh\nInYrHbTFPnLkSKcnoMzMTPbv38/69eu9zufERRfpvw9/Qo0DSMgKuzcfu9sCYEcTVqJS587w4INk\nZGSwevVquz+xj5vGEt27d+fQoUMNS0t34IsvviA3PJzqRx6Bzz6Dxx/XJ2pqdLmFrl11WGhz0qOH\nDpH7+9910ae//x0cizodhfzpT3+iqqqKhVZLt8WL4YMPqKqu5p133uHcc8+1h+R64riZM/kEOBgW\nxt+rqpg3b57/9fE9oJQiKSmJLrfeinrzTfqXlrJ41y72//WvUFzsNLa8vJxff/3VSdiLi4vZtWuX\nx/kLCwspLCysKxmxebM2TKZNY09amktpgRdffJGOHTtylhu3Xnp6OlFRUT6FfcuWLVRWVvos8DZq\n1CgAuzvm8OHDZGdn290wFpm2/S2//eyghR2a3R0TksIeFxfn1WJvdPekpubYY7WFOn8+tGtHRkYG\nlZWVvG/rHnOsG6u5QbHs9fjkk0+YP38+M2fOJOrGG3Ws/qxZOn7/hRdg1Sp49FHd9KC5GT9e+9Sv\nvBLuuaf5r99AhgwZwsiRI+vq0LdvD3FxfPHFFxQXF/NHP/ZpzjnnHG5ITmZobS1XzZrFYGuPJ1BM\nnMiW554jF0j697+hWzf9frNZ1Zs2baK2ttZufQ8ZMgTwvoFqxbzbLfa//lXnZdx/P4MGDXIS9p07\nd/LRRx9xxRVXEOGYFGgjMjKSQYMG+RR2a05fFntqaio9e/a0JyTV3zi16NOnDykpKQ3zs6enw6BB\nHusvNRn++GsC/dXSPvaxY8d69QmuWbNGAHnHVwXBo4Rff/1VAImKipKuXbu6HfPzzz8LIIsaWP97\n79690rlzZxk4cGBdXZG9e3UP0l69RJKTdWhaS3WI37lTx3E3pBdqC2P1BHCs9T9lyhRJSkqSCj/v\n48EHH5QxY8Y4x6cHkKqqKomPj5d/TJ4scvXVui4SiIwZI1mXXy6dQVauXCkiIsXFxQLII4884nG+\nuXPnCiB5eXkiv/2m57JVtrRqHlm+64cfflgAWb9+vcf5pk6dKmlpae4rodr4+9//LkopOeRHX9KJ\nEydKr169RKTu/ycvL89l3DnnnCPp6ek+53Pivvt0b4CG9gl2A8bH7pm4uDivrphGt8VrZnr27Ely\ncjKVlZVu3TBw5Bb7Lbfcwu7du3n55ZeJjo7WB5OSdBXM7dt1JMpTTzXf/kJ9OnbU9d7dtL87Wpk8\neTLR0dF2q72srIz333+fCy+8kCg/7+Ouu+5i2bJlxDRRlnNERARjxozh3Q0bdNmMHTt0aGVlJcPn\nz2cHMPimm+CFF0hOSKBr165eLfacnBzi4+N1naGvv9YHbRVQBw0axMGDB+17QC+++CK/+93v6Nev\nn8f5hg0bRmFhoVf3T3Z2Nr1797aHOHtj1KhRbN26laKiInvGqbuaSMcffzzr16+nuJ57yisXXaQj\nt5rRHROSwu5r8/Sod8XUwwrZAvcbpwBpaWlER0c3SNg//PBD5s+fz6xZs1weS8nM1PVJXnihLtzT\n4BdJSUmcf/75vPbaa5SXl/O///2PQ4cONajFY3OQmZnJ6tWrOXjwoA6znTkTsrK49cwzeTIxkfDC\nQu2imTyZEQMH+hT2/v37683Ir77SxsHQoYBzaYHvv/+ejRs3Mm3aNK9r82cDdd26dX4XeLP87MuX\nL2f58uUuG6cWlp99ma2Yml/076/LWzSjOyZkhb1Vb566wZewh4WF0a1bN7+Fvbi4mOnTpzNkyBDu\n9pRwdPHFOpnE0GCmTp3Kvn37+PDDD3n99dfp1KlTs9at8YfMzExqampcYry/ys/ny8xMXUvoscfg\n7bd5dMMGtufkUOmhNopTRMzXX8NJJ9mrM1qbm+vWreM///kP8fHxXGRtOnrA8ut7EvaKigo2btzo\nt7BbQv7tt9+63Ti1GDVqFOHh4Q3zs4O22r/7Tud7NAMhKeytfvPUDb6EHRqWpHTTTTdRVFTEyy+/\n7Ld7wOA/p5xyCt27d+fJJ5/k448/ZtKkSY2ObAk0xx13HOAcBVJTU8OGDRt0dItS2g32n/9wTF4e\nH1dXs/nnn13m2b9/PwUFBVrYt23TXyefbD+fmJhIly5dWLZsGW+99RaXXHKJz8ighIQEevfu7VHY\nN27cSE1Njd8tD9u1a0e/fv14+eWX3W6cWsTGxjJ8+PCGRcZAs7tjQlLYfVnsrVHY//CHPzB37lx7\nL0l3+Cvsa9euZeHChdx5550MHz48kMs02AgPD+eKK67ghx9+oLKy8qhzw0BdtqWjiG3bto2Kigrn\nTldTp/Lb448zAug8ebKLVeoUEWP51x2EHbTV/sEHH1BWVubTDWPhrbSAvxExjmRkZFBgK6PsyWIH\n7Wf/6aef6kpD+MOAAfqrmdwxISns/m6e+lVC9ighMjKS6dOne20E3b17dwoKCrymigP2N7e3DwlD\n47EaKffu3ZvRo0e37GI8kJmZyQ8//ECtLSHNEun6LQw7XX8950VE0Gb3bl3qwUH0rBox/fv318Ke\nluZSUtkS4AEDBjBmzBi/1jZs2DA2bdqk9wDqsW7dOiIiIrxuwNbH8rN72jh1vG5ZWRl5eXl+zw1o\nq/3bb5vFHROSwh4bG0t1dbVHf2BJSQnx8fHN1oChuejevTsi4rPhRmt8YmmN9O7dm1mzZnH//fd7\nr3HfgtTPtvQk7JGRkeweNIjZ/ftDbq7OAraRk5NDTEwMPXv0qPOv17tfy2UydepUv38Xw4YNQ0RY\nu3aty7ns7Gz69OnTIDeiJeyeNk4trGYwDcpABS3s0dGwcmXDXncEBJdy+YmvCo9+V3ZsZfgb8miE\nvfl46KGHuPTSS1t6GR6pn22Zk5NDhw4d3BYpGzJkCHP37IGUFKcibKtXryY9PZ3wbdt0pcN6bhjQ\nrsRp06a5LSHgCW+RMQ2JiHGcLz4+nt9Zmd0esJ4CGizsAwfqxirNUCQvJIXd2pjxtIFaWloalKLW\nUGFvLXH8hqbDyra0hN2xRkx9hgwZQt6uXZRNnAgffACFhcyZM4fFixfr0gBffaUHnnKKy2vbt2/P\nvHnzfLdddKBr164kJye7CHtZWRm//vprg4W9TZs2ZGdnM3PmTK/jUlJSSEtLa7iwQ7NlZ4eksIeq\nxW75DX0JuxXuaYTdoJSy+9lFnFvb1ccKQVw7ahRUVbF65kxuuukmzj33XO677z7thunUSRc+C9Da\n3G2gfvDBB4iI3xExjnTv3r0uEc8L6enpDRb2mpoaFixY4Fe54cbSaGFXSnVTSn2tlMpRSmUrpW4O\nxMKaEl99T4NV2GNjY0lNTfXLYo+NjXVbp8MQemRmZrJhwwbWrVtHSUmJV4sd4MfSUkr69ydy/nyO\nP+44Xn/9dSLCw7Wwn3xyQLOUhw4daq/NfujQIa677jouvfRSBg0axKmnnhqw69SnocK+YcMGTjjh\nBC6//HLebYaQx0BY7NXA7SIyADgOuF4p5f4j/SjBstg9uWKCVdhBWyS+dvOD+f4NDcfys1slEDwJ\ne4cOHWjfvj3vvvsuf9u2jQEifHzvvfrvbf162L3brX+9MQwbNozy8nJee+01RowYwdy5c7n99tv5\n5ZdfSEhICOi1HOnXrx+FhYU+SwvU1NTw6KOPMmzYMHJycnjllVeYNGlSk63LotHCLiI7RSTL9u9S\nIHURb+MAAA7FSURBVBfo0th5mxJ/LPZgdUN06NCBwsJCr2OMsBscycjIICIiggULFgCehR201f7d\nd9/xWWIitbGxJLzzjj7hIX69sVgbqFdeeSWHDx9m8eLFPProo01WQ8fCiozZsGGDxzG5ubmMHTuW\nmTNncsYZZ5CTk8Pll1/eLBFQAfWxK6V6AsOBnwI5b6AJZYs9ISGBAwcOeB0TzPdvaDhWtmVxcTHt\n2rWjU6dOHsdmZmaSlJTEu59/TtjFF8Mbb+g+ql9/rcv/9u4d0LX179+fIUOGcPnll7NmzRpODvAH\nhyd8hTxWVVVxwgknsHnzZhYuXMj777/v9fcWaAIm7EqpeOBd4BYRKXFz/hql1HKl1HJfFmNT423z\nVESCNioGjLAbjgzLHWMv5OWBe++9l+3bt+uIlGnTtKi/8QYsWaKjYQJsrUZGRrJ69WpeeeUVp76o\nTU3Pnj2JioryaLGvXbuWoqIinn76aSZPntzseQoBEXalVCRa1F8TkffcjRGR50UkQ0Qy0tLSAnHZ\nI8ZbuOPhw4epqakJWmFLTEzkwIEDXtuYGWE31MdR2L0RFhZWl7GdmakbTdx7r47fbiZrujkIDw+n\nb9++Hi12q/rj8ccf35zLshOIqBgF/AfIFZHHG7+kpsebxR7syTkJCQlUVlZSXl7ucYwRdkN9xo4d\nS1hYGENtpXb9QilttdtKVASTsIP3yJhly5bRoUMHevTo0cyr0gTCYh8LXAacopRaZftq+tSqRuBt\n8zQUhB3w6o4xwm6oT5cuXfj555+ZPn16w154+eUQEaF967YEuWAhPT3d3le1PsuWLeO4445rsVIR\njQ5UFpHvgKOz0IUHoqOjUUq5dcUEe9alo7B37NjR5byIGGE3uMVbxUOPtG8P992nG3UEGenp6dTU\n1LBlyxYnF1VxcTGbNm1qUHmEQBOSGShKKY+le4PdYrc2mDxZ7MG+x2BoAe68s6VX0CQ4RsY4CvtP\nP+mgwJbyr0OIlhQAz802WmP3pIZgWez79+93ez7YP9gMhkDhqRjYjz/+SFhYmMdmHc1ByAp7qFrs\nvnzswX7/BkOgiI+Pp2vXri7CvmzZMoYMGeKzC1RTErLC7qnZRrALmxF2gyFw1I+Mqamp4aeffrK3\nFWwpQlbYY2NjvW6eBquw+fKxB/v9GwyBxBJ2Ky9k/fr1lJaWGmFvKby5YiIjI/0q3dkaiY+PRyll\nfOwGQwBIT0+npKSEXbt2AXWJSUbYWwhPm6fBHuoXFhZGu3btPFrswb55bDAEkvo1Y5YtW0ZSUhJ9\n+vRpyWWFrrB7stiDuU6Mhbd6McZiNxj8p35kjJWY1NL9kkNW2L1tnga7qFn1YtwR7AlaBkMg6dKl\nC3Fxcaxfv54DBw6QnZ3d4m4YCGFh97Z5GuzCnpCQ4NXHHsx7DAZDIFFKkZ6ezoYNG/jll18QESPs\nLUm3bt0oKiqiqKjI6XioCLs3i71du3YtVuPCYGhtWJEx1sbp6NGjW3hFISzsJ554IgBLly51Om6E\nPfjv32AIJOnp6eTl5fHVV1/Rv3//Zq0L74mQFfaMjAxiY2NZsmSJ0/Fgbotn4cvHboTdYPAfKzJm\nyZIlR4UbBkJY2KOiohg7dizffPON0/FQiopx12zDCLvB0DAsYT9a/OsQwsIO2h2zZs0ae6fx6upq\nysrKgl7YEhISqKmpCdnNY4MhkBx77LH28MaWrOjoSEgL+0knnQTU+dlDJTnHW70YI+wGQ8OIiYmh\nV69exMfHM2DAgJZeDhDiwj5q1CjatGlj97OHSnKOt3oxRtgNhoZz+umnc/755xMeHt7SSwFCtNGG\nheVnDzVhNxa7wRBYnn322ZZeghMhbbGD9rOvXbuWvXv3hkzWpadmG1aTayPsBkPrJqQtdtB+dhFh\n6dKlxMTEAKFrsYfKHoPBEOyEvMXu6GcPFVeMJx97qNy/wRDshLywR0dHk5mZGVLC7sliD5X7NxiC\nnZAXdqiLZ9+2bRsQ/MIWGxtLeHi4i4/dCLvBEBwYYafOz/7RRx8BustQMKOUclsvxvjYDYbgwAg7\nuhpbTEwMq1atIj4+vsWL5DcH7oTdWOwGQ3AQ/ArmB5afHUJH1NwVAjPCbjAEB0bYbVhlfENF1Nw1\n2zDCbjAEB0bYbVh1Y0JF1Dy5YpRSxMXFtdCqDAZDIDDCbsPys4e6sLdt29Z0TzIYWjkhn3lqERMT\nw/Tp0+nSpUtLL6VZ8ORjD5UPNoMhmDHC7sATTzzR0ktoNhISEigpKaG2ttYeBWSE3WAIDgLiilFK\njVdKbVBKbVZK3RGIOQ1NS0JCAiJij10HI+wGQ7DQaGFXSoUDzwBnAgOAyUqpo6PavMEj7soKGGE3\nGIKDQFjso4HNIvKriFQCbwDnBWBeQxPirhCYEXaDITgIhLB3AXY4/Pyb7ZjhKMZY7AZD8NJs4Y5K\nqWuUUsuVUssLCwub67IGD7hrtmGE3WAIDgIh7PlAN4efu9qOOSEiz4tIhohkpKWlBeCyhsZQ32Kv\nra2ltLTUCLvBEAQEQth/AfoopXoppaKAS4APAzCvoQmp72M/ePAgEDqZtwZDMNPoOHYRqVZK3QB8\nBoQDL4pIdqNXZmhS6lvspk6MwRA8BCRBSUQ+Bj4OxFyG5iEmJoaoqCi7j93UYjcYggdTKyaEcawX\nYyx2gyF4MMIewjjWizHCbjAED0bYQxhjsRsMwYkR9hDGsdmGEXaDIXgwwh7CGIvdYAhOjLCHMO58\n7G3btm3JJRkMhgBghD2EqW+xt2nThogIU6LfYGjtGGEPYRISEjh48CDV1dWmTozBEEQYYQ9hrOzT\nkpISI+wGQxBhhD2EcawXY4TdYAgejLCHMI71YoywGwzBgxH2EMYIu8EQnBhhD2Ecm20YYTcYggcj\n7CGMsdgNhuDECHsIYzZPDYbgxAh7CGNZ7Lt27aK6utoIu8EQJBhhD2EiIyNp06YNO3bsAEydGIMh\nWDDCHuIkJCQYYTcYggwj7CFOYmKiEXaDIcgwwh7iJCQk8NtvvwFG2A2GYMEIe4iTkJBARUUFYITd\nYAgWjLCHOFZkDBhhNxiCBSPsIY4Vyw5G2A2GYMEIe4hjLHaDIfgwwh7iWMIeGRlJdHR0C6/GYDAE\nAiPsIY4l7G3btkUp1cKrMRgMgcAIe4hj+diNG8ZgCB6MsIc4lsVuhN1gCB6MsIc4RtgNhuDDCHuI\nY4TdYAg+jLCHOMbHbjAEH40SdqXUv5VS65VSa5RS7yulEn2/ynA0YSx2gyH4aKzF/gUwSESGABuB\nWY1fkqE5sQS9bdu2LbwSg8EQKCIa82IR+dzhx2XAxMYtx9DchIeH89hjj3Hqqae29FIMBkOAUCIS\nmImU+i/wpoi86uH8NcA1AN27dx+Zl5cXkOsaDAZDqKCUWiEiGb7G+bTYlVJfAh3dnLpLRBbZxtwF\nVAOveZpHRJ4HngfIyMgIzKeJwWAwGFzwKewi4vUZXSl1JfAH4PcSKPPfYDAYDEdMo3zsSqnxwF+A\nE0WkLDBLMhgMBkNjaGxUzBygLfCFUmqVUmpuANZkMBgMhkbQ2KiYYwO1EIPBYDAEBpN5ajAYDEGG\nEXaDwWAIMoywGwwGQ5ARsASlBl1UqULgSDOUUoGiAC6nuWnN62/Na4fWvf7WvHYw6w8UPUQkzdeg\nFhH2xqCUWu5P5tXRSmtef2teO7Tu9bfmtYNZf3NjXDEGg8EQZBhhNxgMhiCjNQr78y29gEbSmtff\nmtcOrXv9rXntYNbfrLQ6H7vBYDAYvNMaLXaDwWAweKFVCbtSarxSaoNSarNS6o6WXo8vlFIvKqX2\nKKXWORxLVkp9oZTaZPue1JJr9IRSqptS6mulVI5SKlspdbPt+FG/fqVUjFLqZ6XUatva77Md76WU\n+sn2/nlTKRXV0mv1hlIqXCm1Uin1P9vPrWL9SqltSqm1tvpRy23Hjvr3jYVSKlEp9Y6t7WeuUur4\n1rR+aEXCrpQKB54BzgQGAJOVUgNadlU+eRkYX+/YHcBiEekDLLb9fDRSDdwuIgOA44Drbb/v1rD+\nCuAUERkKDAPGK6WOA/4FzLbVONoHTGvBNfrDzUCuw8+taf0ni8gwhxDB1vC+sXgS+FRE0oGh6P+D\n1rR+EJFW8QUcD3zm8PMs+P/27t3VjioKwPhvgQ80ivFFuBjhKohWkqTQwiCiaBHEykKwSGFpYxsE\n/wTRykaxCgq+QyrxUUeNRrka4gMDuSHx2gTBysey2PvKIRg4ppnZh/XBZvbeM8U3sM46c9bMnO3Q\n1F5LeK9jY2F8Cmu9v4ZTUzsueR4f4NHR/HEtvsT92gsmV/xXPM2tYbeWQB7GUcQo/jiNWy6aGyJu\ncAN+1u8/jua/3Ya5YsdtOLMw3uxzo7ErM8/1/nnsmlJmGSJiHXtxzCD+vYxxAlvaous/4UJm/tkP\nmXv8vKStdfB3H99sHP/EhxFxvC+JySBxgzvwK17vZbBXI2KHcfwxUClmFcn29T/rx5Ii4jq8g+cy\n87fFfXP2z8y/MnOPduV7H+6ZWGlpIuJxbGXm8aldLpP9mblPK5s+GxEPLu6cc9xof2W+D69k5l78\n7qKyy8z9MVZiP4vbF8a7+9xo/BIRa9C3WxP7XJKIuFJL6ocz890+PYw/ZOYFfKqVLnZGxPYaBHOO\nnwfwREScxptaOeZlg/hn5tm+3cJ72hfrKHGzic3MPNbHb2uJfhR/jJXYP8dd/cmAq/AUjkzsdDkc\nwcHeP6jVrmdHRARew8nMfHFh1+z9I+LWiNjZ+9do9wZOagn+yX7YLN0hMw9l5u7MXNfi/JPMfNoA\n/hGxIyKu3+7jMWwYIG4gM8/jTETc3acewXcG8f+XqYv8//PGxgF8r9VLn5/aZwnfN3AOf2hXAs9o\ntdKP8QM+wk1Te17Cfb/2c/MbnOjtwAj+uBdfdfcNvNDn78Rn+BFv4eqpXZc4l4dwdBT/7vh1b99u\nf05HiJuFc9iDL3r8vI8bR/LPzHrztCiKYtUYqRRTFEVRLEEl9qIoihWjEntRFMWKUYm9KIpixajE\nXhRFsWJUYi+KolgxKrEXRVGsGJXYi6IoVox/APo88L4T2+mxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc062630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc16ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.40499565038 \n",
      "Fixed scheme MAE:  1.47310581414\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.4854  Test loss = 1.4484  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.4866  Test loss = 0.9775  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.4432  Test loss = 0.1795  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.4406  Test loss = 0.2146  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.3254  Test loss = 0.1818  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.2819  Test loss = 0.9100  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.2347  Test loss = 0.0646  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.2085  Test loss = 0.0929  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.1453  Test loss = 0.1436  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.1368  Test loss = 1.5280  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.1288  Test loss = 1.5447  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.1432  Test loss = 2.3354  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.1123  Test loss = 0.8074  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.1157  Test loss = 1.3039  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.1274  Test loss = 2.3826  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.1613  Test loss = 2.9395  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.1751  Test loss = 0.4782  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.1725  Test loss = 0.5811  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.1692  Test loss = 0.8649  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.0407  Test loss = 0.4977  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.0145  Test loss = 2.0731  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.0458  Test loss = 4.2477  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.1533  Test loss = 0.5560  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.1442  Test loss = 1.5487  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.0894  Test loss = 0.9942  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.0933  Test loss = 0.2019  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.0931  Test loss = 0.3381  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.0882  Test loss = 1.6743  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.0857  Test loss = 0.5812  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.0825  Test loss = 0.2005  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.0777  Test loss = 3.7063  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.1572  Test loss = 0.1127  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.1109  Test loss = 1.4156  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.1247  Test loss = 0.1958  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.0739  Test loss = 0.0108  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.0649  Test loss = 4.9662  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.1770  Test loss = 1.0558  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.1715  Test loss = 1.9643  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.1835  Test loss = 1.1714  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.1921  Test loss = 2.2679  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.1657  Test loss = 1.3000  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.1761  Test loss = 1.7446  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.1959  Test loss = 2.8808  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.2470  Test loss = 12.4373  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0121  Test loss = 6.4125  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1607  Test loss = 0.7380  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1623  Test loss = 0.2279  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1613  Test loss = 0.7627  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.9422  Test loss = 1.7975  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.9513  Test loss = 2.3773  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.9733  Test loss = 1.6919  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.9836  Test loss = 1.2096  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.9174  Test loss = 2.5920  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.9430  Test loss = 2.8029  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.9720  Test loss = 0.1754  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.9667  Test loss = 0.8288  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.9084  Test loss = 0.6174  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.9100  Test loss = 1.8595  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.9224  Test loss = 0.5839  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.9219  Test loss = 0.1824  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.8811  Test loss = 0.3983  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.8811  Test loss = 2.6054  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.9064  Test loss = 0.3642  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.8975  Test loss = 0.3223  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.8614  Test loss = 0.3554  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.8609  Test loss = 0.1284  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.8550  Test loss = 1.0786  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.8565  Test loss = 2.7101  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.8563  Test loss = 4.9920  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.9562  Test loss = 0.3796  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.9567  Test loss = 1.3707  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.9593  Test loss = 2.8897  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.9464  Test loss = 2.6497  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.9733  Test loss = 1.0562  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.9764  Test loss = 1.0642  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.9782  Test loss = 0.4363  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.9166  Test loss = 1.5042  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXlclPX2xz/fgQERREDcDUFANFAxUUwtc0lNTW1fNEtL\ns25WtmdZ1252+7VevTdLbbPUXLspWlaay1XcEDdcQQV3wY19nTm/P77zDDPMCswwzHDerxcv5Xme\n+T6HZ2Y+z3nOOd/zFUQEhmEYxnNQudoAhmEYxrGwsDMMw3gYLOwMwzAeBgs7wzCMh8HCzjAM42Gw\nsDMMw3gYLOwMwzAeBgs7wzCMh8HCzjAM42F4u+KkoaGhFB4e7opTMwzDuC179+69QkTNbR3nEmEP\nDw9HSkqKK07NMAzjtgghsuw5jkMxDMMwHgYLO8MwjIfBws4wDONhsLAzDMN4GCzsDMMwHgYLO8Mw\njIfBws4wDONhsLAzjIPIzc3FwoULXW0Gw7CwM4yjmD17Np544gmcO3fO1aYwDRyHCLsQIkgIsVII\ncUwIcVQIcasjxmUaFgcPHsSUKVOg0WhcbUqNWLt2LQCguLjYxZYwDR1HeeyzAawnok4AugE46qBx\nmQbE6tWrMW/ePGRl2TVrul5x8eJF7NmzBwBQXl7uYmuYhk6thV0I0RTA7QC+AQAiKiOiG7Udl2l4\nXL58GQCQmZnpWkNqwLp16/T/Z2FnXI0jPPYIADkAvhNC7BNCfC2E8HfAuEwDIzs7GwBw+vRpF1tS\nfZQwDMDCzrgeRwi7N4BbAHxJRN0BFAJ4o+pBQojJQogUIURKTk6OA07LeBru6rGXlJTgzz//RGRk\nJAAWdsb1OELYzwE4R0S7dL+vhBR6I4hoPhElEFFC8+Y22wkzDRBF2N3NY9+0aROKiopw7733AmBh\nZ1xPrYWdiC4BOCuEiNFtGgTgSG3HZRoe7uqxJyUlwd/fH0OGDAEAlJWVudgipqHjqIU2pgJYLITw\nAXAKwAQHjcs0EMrKynDjhsy5u5PHTkRYu3Yt7rzzTgQEBABgj51xPQ4pdySi/bowS1ciGkNE1x0x\nLtNwUBKn7dq1w4ULF1BSUuJii+zj4MGDOHv2LO6++26o1WoALOyM6+GZp0y9QAnDJCYmAgDOnDnj\nSnPsRqmGGT58OAs7U29gYWfqBYrHrgi7u4RjkpKS0KtXL7Rq1Qo+Pj4AWNgZ18PCztQLqnrs7pBA\nvXz5Mnbv3o2RI0cCgN5j5+Qp42oclTxlAODCBWD9eqBVK6BdO6BtWyAkBBDC1ZbVexRhj4+Ph1qt\ndguPPSkpCURkIuzssTOuhoXdURABjz0G/PWX8fYuXYDkZEBXMcGYJzs7G40bN0ZgYCDat2/vFh77\nkiVLEBUVhfj4eAAs7Ez9gUMxjmLdOinqs2YB27cDy5cD770HHDoEfPihq62r91y+fBktW7YEAISH\nh9d7j/3cuXPYvHkzxo0bB6F7ImNhZ+oL7LE7gvJy4NVXgY4d5b+6LzgA4Phx4JNPgIkTgQ4dXGdj\nPcdQ2CMiIvDLL7+42CLr/PTTTyAijB07Vr+Nk6dMfYE9dkewYAFw7Bjw0UfGog5Ib93LC3jlFdfY\n5iZkZ2ejRYsWAKSw5+TkoLCw0KU2nT59Gq+++ipKS0tN9i1evBiJiYmIiorSb+PkKVNfYGGvLbm5\nwLvvAv37A6NGme5v1w6YPh3473+BjRvr3j43oWooBnB9ZczKlSvxySef4LPPPjPanpaWhgMHDhh5\n6wCHYpj6Awt7bfnnP4ErV4BPP7Vc/fLyy0BEBPDCC0BFRd3a5wZoNBrk5OQYhWIA1wu7Eud///33\njZa7W7x4Mby8vPDQQw8ZHe/l5QWAhZ1xPSzstSEzE/jXv2Q1TI8elo9r1EgK/+HDwFdf1Zl57sLV\nq1eh1Wr1oRjFY3d1AjUzMxPt2rWDVqvFK7pQmlarxZIlSzBkyBC9vQpCCKjVahZ2xuWwsNeGN9+U\nXvqsWbaPHTMGGDQIeOcd4No159vmRiizThWPvWXLlmjUqJHThf3SpUv44osvQERm958+fRq9evXC\nG2+8gWXLlmHz5s3Ytm0bzpw5YxKGUXAnYb9+/Tq++eYbaLVaV5vCOBgW9pqSnAwsXSqrYG66yfbx\nQgCffy5j8u+/73z73AhlcpIi7EIIhIeHOz0U8/bbb+O5555DRkaGyT4iQmZmJsLDw/Haa68hPDwc\nU6dOxcKFC+Hv748xY8aYHdPHx8cthD0/Px9Dhw7FU089pV+rlfEcWNhrglYLTJsGtGkDvPaa/a/r\n0gWYMAH4z38AM2LSUFGE3TC0ERER4VSPPScnB4sWLQIApKenm7WppKQEERER8PPzw2effYa0tDR8\n++23GDNmDPz9za/+qFar631VTHFxMe6++269oB87dszFFjGOhoW9JixZAuzeLROn1Z1R+o9/AD4+\nwBsmqwc2WKqGYgA43WOfN2+evozxxIkTJvuVcyvx/jFjxuDOO+8EAIwbN87iuPU9FFNWVoYHHngA\nW7duxcKFC+Ht7Y3jx4+72izGwbCwV5fCQinKCQmAlS+4RVq3ll7+qlVyhqoHs3XrVowaNQoVNiqB\nLl++DG9vbwQHB+u3RURE4Pr168jNzXW4XWVlZfjiiy8wZMgQNG3a1KzHrjwtKBU6Qgh8/fXXeO+9\n9/QCb476LOwajQbjx4/HunXr8OWXX2L8+PGIjIxkYfdAWNiryyefAOfPy3i5qoaX7+WXZRjn5Zdl\njxkPZeXKlUhKSrLZW/3y5cto0aKFfmo+4Nxa9uXLl+PSpUuYNm0aOnbsaFbYlfO2b99evy0sLAwz\nZszQlzWaoz4L+7Jly7Bs2TJ8+OGHePrppwEAMTExHIrxQBwm7EIILyHEPiHEWkeNWe84dw74v/8D\nHnwQ6Nev5uP4+8sE6q5dwLJljrPPBteuXcOmTZvq7HxpaWkAgFOnTlk9Ljs72ygMA1R6yo6OsxMR\nPv/8c3Tq1AlDhgxBdHS0xVBMaGiofrk7e6nPydPVq1ejVatWePXVV/XbYmJikJGRAY1G40LLGEfj\nSI/9BQBHHThe/eNf/wI0GinutWX8eKBbN1kyWUfJtk8//RRDhgwxO0XeGSjCbkucDWedKjhL2Ldv\n347U1FS88MILUKlU6NixI86cOWOyFN/p06f1NlSH+po8LS8vx/r16zFixAioDJ40O3XqhLKyMpdP\nBmMci0OEXQjRDsAIAF87Yrz6SsWGDSiIjwd0YYJa4eUlk6+ZmcDChbUfzw4OHDiAiooK/aLRziQ7\nOxs5OTkAbHvs5oQ9JCQEAQEBDhec2bNnIzg4GI899hgAIDo6GkRkYqNS6lhd6msoZtu2bcjLy9P3\njleIiYkBAI6zexiO8tj/BeA1AJ470yEvD6qDBzF7715cv+6gtbqHDQN69gQ++EB2iHQyigddF8Ku\nnAuwLuxEZNQATEEI4fCSx6ysLPz888+YPHmyvlwxOjoagHFljFarRVZWVo099voo7GvXroWPjw8G\nDx5stJ2F3TOptbALIUYCyCaivTaOmyyESBFCpCienDtB27dDRYS/NBqsWLGiRmMcP34c33//feUG\nIWQDscxM4McfHWKnJfLz85GVlQWgboW9W7duVoU9Ly8PpaWlJh474PiSx3Xr1kGr1eKpp57Sb1OE\n3TCBevHiRZSVlXmUx7527VoMGDDAJGcQGhqKkJAQTqB6GI7w2PsCGCWEyASwFMBAIcSiqgcR0Xwi\nSiCihObNmzvgtHXL5RUrUA5gtxD4sYYi/M4772DChAk4f/585cbhw2WfmVmznNog7MiRI/r/15Ww\nh4aGonfv3la97qqzTg1RPHZLU/4NuXHjBuY++ih+a9sWZRaeqJS/+yaDmcJBQUFo3ry5kbBXLXWs\nDvUxeXrixAmcOHHCJAyjEBMTwx67h1FrYSeiN4moHRGFA3gYwF9EVIMC7/pN2caNSAEw6cUXsW3b\nNrNiVVRUZHZ6OgCUlpbit99+AwD8+uuvlTuEkP1jTp0CFi92hukAjEMjDgsl2ThfbGwsIiMjcfXq\nVYv16OZmnSpERESgoKBAP4HJHOXl5ZgzZw6Gh4fj0Z9+wl0XLqDkzTfNHpuXlwcfHx/4+voabddX\nxpSWAjt2mExOqg71MXm6bt06AMCIESPM7u/UqRMLu4fBdez2UFyM1mfP4mSbNnjxxRcBQD8d3ZAn\nnngC3bp1M+sRb9myBfn5+VCpVPovmp677wbi453qtRsKu7M9diJCWloa4uLi0EG3apQlr93crFOF\nvmo1kgBcnDfPbL1/RkYGYmNjMeuFF7CqtBReAQFYBaDJ118D+/aZHJ+Xl4fAwECT7fpa9jlzgD59\nkL97NwDjGnZ7MQnFlJfLeQ9798rlE3U397pk7dq1iI2NtfgEEhMTg0uXLjllMhjjGhwq7ES0mYjM\nP++5Mdd++w1qIqgHDUJYWBjuuOMO/PDDD0Yhgi1btmDFihUoKirC8uXLTcZYvXo1GjdujPHjx2PD\nhg3GJYeK156e7rS6dsWDBgyEfdMm4OGHZQmnAzl79izy8/MRFxenFxNLcXZroZi4HTswEkD8u+/K\nJPPatUYC/+233+LSqVM41rEjWqlUOPzPf+IpAOVNmwKTJpncJHNzc80Ke3R0NC5cuADNf/8LAGi+\nYwdatWoFPz8/639oUZEU6/x8/Sa9sJ84AYwdC/j5ycVWEhKAkSNl6G3rVuvjOpDc3Fxs3brVYhgG\n4ASqJ8Ieux1k/vADtABiJ08GADz22GPIyMjArl27AMip2i+88ALCwsIQExODhVXKF4kIa9aswdCh\nQ3H//fejsLAQW7ZsMT7J6NGySdj77ztlNmpaWhp69uwJX1/fylDMjz/KG4kZ77a25wJgl8d++fJl\nCCEQGhpqss8vORl/+vri6z59ZKvju++Wtf+TJwNz5kD755/4OSAAwenpEEuWAAkJuAHg8OTJ0kOe\nM8dovLy8PDRt2tTkPNHR0QgBoNK9nzHp6bbj60RyHduRI4GWLeUNMikJNxUXY+a5c0DnzsAvvwDP\nPit78P/yC7BtG9C0KfDll2aHLCsrw86dO+3KKdjL77//joqKChb2hgYR1flPjx49yJ3Y37w5HVKr\nSavVEhFRbm4uNWrUiJ599lkiIpo/fz4BoKVLl9JHH31EAOj48eP61+/du5cA0HfffUeFhYXUqFEj\nev75501P9P33RABRcrJD7b9y5QoBoE8++YRatmxJkydPljvi4uT5PvjArnHS09Pp7bffptzcXKvH\nKdfg2rVrREQUHBysv1ZVmTJlCoWGhpruOHWKCKC5nTtTt27diMrKiBYsILr9dqJmzaTdys/nnxMR\n0eHDh+X78NNPRCNHEjVuTHT6tH7I22+/nfr3729yqv3799NYZawRI0gD0OR77rF+MebPl8dPnUr0\nzDNGNpUARNOmEV26ZPq6558nUqvN7vv6668JAH388cfWz10NHnvsMQoJCaHy8nKLx5SWlpKXlxe9\n9dZbDjsv4xwApJAdGsvCboPivDwqAOivLl2Mtj/00EMUEhJC2dnZ1Lx5c+rXrx9ptVq6cOECqVQq\noy/JO++8QyqVinJycoiIaPjw4RQZGam/UejJzSVq1Ijouecc+jds2bKFAND69espJiaGHnzwQaKC\nAiKVSn4E7rjDrnFeeeUVAkCdO3emEydOWDxu/Pjx1LZtW/3vPXr0oGHDhpk99p577qHY2FjTHQsW\nEAH06ZNPklqtptLS0sp9Wi2dS0mhgQD9d+pUIt11PHfuHAGgefPmEZ05QxQQQDRsmH5/fHw83X33\n3SanKigooKUA5QcEUPnOnUQArRg50vKFOHRIvk933kmk0chtZWVEa9fSyoQE6tGqleXXHj1q8Wb6\n2GOPEQACQD/99JPlMeykoqKCmjVrRmPHjrV5bHR0NN1///21PifjXOwVdg7F2GD/t9/CH0DTu+82\n2j5+/Hhcu3YNw4YNw5UrVzB79mwIIdC6dWsMHToUP/zwg35lmtWrV6Nv3776cMOIESNw8uRJ0x4l\ngYHy0X75cocmUZXQSGxsLIKDg2WMPTVV9pW/+WbZZbKw0OY4R44cQatWrZCdnY1evXrh999/t3i+\nuLg4/e8RERFWY+zmKmLw119Aq1ZoNWAAysvLjcMEQmDP2bP4C0DLRx7RrzWrxM/z8vLk4icffACs\nXw98951+u7kYu7+PD+4SAntbt8b5li1xDkAPw5JUQ4qKgIcekiGVH3+sbASnVgMjRmBDQgLOWMtZ\ndOoEDBggwzNVjtv9v/9hat++uP322/H4449j8+bNlsexg927d+Pq1atWwzAK3AzMAg4Oi9ZVuIuF\n3QaXdInQzpMmGW1X1rxMTU3FxIkTccstt+j3Pf744zh79iw2bdqErKwsHDhwAKNGjdLvV8rOTKpj\nAODRR4HsbClsNrh8+TL++OMPm8elpaWhadOmaNu2LYKCgmSMPSVF7nzzTVm5UTXmb4ajR4/ijjvu\nwJ49exAWFobhw4fjs88+MzpGo9HgyJEjRsLeoUMHZGZmml2CzVwDMBDJv3/gQHSLjwcg2yEYkpqa\nCpVKhW7duum3BQQEQAghhR0A/vY34I475CLip09bFHb8738IJMKvXl7IzMrCWgA3HTsmyx+r8vzz\nwNGjwKJFMrZeBbsmKD37LHDmjFGFzMXz5/FBZibmbN+OpLffRlRUFMaMGWNUzVRd9u6VcwZvv/12\nm8fGxMQgPT2dm4EZsnIl0KqVXd9FWxQVFeGll15C586dsWbNGgcYZx0WdisQEZrs24dz/v7wq1LT\n7O3tjSeeeAJBQUGYVWXN09GjR6Np06b4/vvv9W/i6NGj9fvbt2+P2NhY88J+113SG1yyxKZ9n332\nGYYOHYoLFy5YPU7xoIUQCAoKkh77nj3Sq73vPrnY9p9/WroIAOQHMzMzE507d0ZERASSk5MxZswY\nvPzyy/okMiCrX0pKSkyEvayszKyd5vrE4PBh4PJlYNAgxMTEwMfHx6ywd+7cGY0bN9ZvE0IgMDCw\nsmxPpQK+/1569E88gXwLVTFYuxblXl5YduUKTp8+jTUAvIuLgaoe87JlwDffANOnA1Wm5ivYJeyj\nR8u+/AZJ1Ly//Q33AiAhELh2LX777Tf4+/vjrrvuQqEdT1PmSE9PR0BAAFq3bm3z2JiYGJSWltps\nsdxgWL++0sl68kmgoKDGQ23ZsgVdu3bF559/jilTpmDAgAEONNQ8DVrYz5w5g7lz52LJkiX4/fff\nkfXaayiPiEDRN9+AtFocOXQIPYqLkd+9u9nXv//++zh58qSJMDVq1AgPP/wwVq1ahcWLF6Nz5876\nqesKI0aMwNatWyu9y8oXA/feC/z8M1BcbNV+xZtbu1bXKfn4ceDTT4GrV/XHkEFNOQBjYe/ZU5bj\n3XYb8McfKCwsxKFDhypP8O9/S4/l2jUcP34cRISbb74ZAODv74/vv/8eoaGhePfdd01sqirsgGnJ\nY3FxMfLz801DMYqHNGgQvL29ERsbi4MHDxodsnfvXqOnJIXAwEDja9q+vayO2boVz5aXmwo7EZCU\nhLNRUci6cgX79+/HJgDUuDFg6FlduAA88wyQmAj8/e8m51WwS9jValmO+dtvwOnTwDffIGb1aszz\n8gKNGgUsX46wtm0xZ84cnDt3zvg9qQbp6emIiooy6nNviU6dOgHgyhgAsnrp3nuB2FhZzpqVVaMV\nzzQaDaZOnYo77rgDRIS//voLc+fORZMmTZxgdBXsCcQ7+qe+JE+ffPJJfbIKAKUBVKGrbNgK0CRf\nXyKArs6eXe2xd+zYoR/39ddfN9mvJDRXrlxp+uI//5QJNnP7DAgPDycANGLECKLCQqKYGPm6gACi\n6dOJrlyh8+fPEwD697//TUREb775JoV6eRkn8D7+mAigL996i9RqNV2/fp0oL6+y0uPvf6fFixfL\na5SWVmnAX3/R6eho+higYzNnEp06Re/NnElCCCooKNAflp6erq8KMiQzM5MA0Ndff238h40aRdSh\ng/7XJ554glq2bKn//cKFCwSA/vWvf5lck7i4OLqnakWLVkslw4ZRMUCLp0833nfsGBFA+ydPJgB0\n8803U7t27YhGjya66SaZeNVqie66i8jPj8ig2skcM2bMICGEaWK8KmfPEnl5EQ0ZQuTtTcmBgTTw\n9tuJli+X13zDBkpLSyMAtGTJEutjWSAqKkomyu3g8uXLFq9pg2LvXqLAQPldunxZbnvxRfmebNpU\nraHWrl1LAGjKlClG34faAK6KsU18fDwNGDCAjh07RqlLlhABtPORR+j3Bx6gAj8/0pfTZWVVe2yt\nVksdO3YkAJRspnyxvLycgoKCaMKECaYvrqggatmS6N57LY5fWFhIQgjy9fWlRo0aUdlTT0lb588n\neughIiGIAgLoxIQJBIA26T6U//d//0eDlL/rzz/lYPv3EwH04+DBBIA2bNhA9M9/ymPi4oiCg2nm\nK6+Ql5dXZXVKaSlRVBRpAwOp2KD08HLjxjS2dWsjW0tLS0mlUtGMGTOMtu/atYsAUFJSkuGFkV+s\nSZP0mz7//HMCQJd0JYJJSUkEgLZu3WpyXfr06UODBg0y2X561y66DNDVsDDjUkPdTe34n3/qb8T9\n+vUj+uYb+Tft20c0b578v+7maI333nuPAFgtL9QzZgwRQJpOnShYpaLp06cTFRXJG/OTT1JBQQEB\noFmzZtkei0hW6Bw4QEREZWVl1Sph1Gq1FBQURFOmTLHvXJ7I+fNEzZsThYXJqiqFwkKiyEjpbNgS\n6PPn9VVYr7zyCvn6+lJxcbHDTLRX2BtsKKakpARpaWno3bs3YmJi0F03gSbx448xZPly+J8/D7z4\nIvDYY0BYWLXHF0Lg1VdfRZ8+fdCrVy+T/d7e3hg2bBh+/fVXeYc1xMtLVl6sWwdYmOathEYmTJiA\ngSUlUH/9tVxqb9IkYOlSIC0N6N8f0d99h66AftZpUFAQeiqD9Ogh/+3SBWjZEhG6Kp2D27cDH38s\nZ0l+/TVw/Trar1+PqKgo+Pj4yNfMnQtkZEAsXYp5H32EWwCcmDYNBRUV+OHiRRmH1oUkfHx8cNNN\nN5lMUjLbJyY1FcjLAwYN0m/q2rUrgMoEampqKoQQiNclVg1p2rSpaXgLwDVvb0wA0PTiRSAuDlA6\ndK5dC3TtirB+/fQhi4iICGDECBmbnzMHeOklGVN/9lmz74UharUaAOxrBDZjBjB4MHbNmIHrWi36\n9u0rQ2P33AOsWgV/b2+0aNHC/tbF//mPnMC1cydOnz4NjUZjEgK0hBDCdjOwHTukzT/9JMMTDq4Y\ncTmLFwM5OfJ7Z9AoDo0bA99+K/s5vfWW5dfv3Qu0bQtMmACUlWHz5s1ITExEo0aNnG97VexRf0f/\n1AePfc+ePQSAVqxYITfccgtR7951asMXX3xBAOjs2bOmO3X11FQlfKGwaNEiAkCHNm6ky0LQmeBg\nopIS44OuXqUyLy/62s9Pv2nZsmW0CqCSsDDjY8eOpWtqNQmAFsfGynPv3i33DRpE2V5e9IBSA37l\nClFQENHQoUREVFRURK1bt6Zbb72VAr28aE+3bvL1vXvLiUZENGDAAOrTp4/RKZUJOZmZmZUbP/hA\nvlZ5DKbKCVbKxJ1Ro0ZRTEyM2evy0EMPUceOHU22b9q0iQDQjm++IerZU57j3ntlOETn1SqhLf2T\nRWKiPK5pU2MPzgqffPIJAbA5icuQf/zjH0YTuujXX+V5V6+mxMREGjx4sO1BysqkpwkQTZyoDwNs\n377dbjvGjx9Pbdq0Md5YUSFDgrfeWvkEq/y0aUP06KNEuvkZbk+vXkQJCZb3P/ecfBI+dMj8/n/9\nS39tym+/nYKFoHfeecehJoI9dusopWA9evSQ/dBTU2XCpA6p6oka0asX0KGDxeqYo0ePwkulws2f\nfoogITAWgMbb2/igkBBsCArCQ+Xlsv4aQHBwMHoCyO3Y0fjYIUMQXF6OfgDuOnpUeqw9pW9f8frr\naK7RYKzStXDmTOlVf/IJAMDPzw/Tp0/Hjh07kKfRIOONN+RTw5EjQEwM0KcPXrlyBRFHjgAGDcg2\nbNiAwMBA46qNjRvlE4SBF9+sWTO0bdvWyGPvoTxtVMEkeapD2abu1g1ITpYN15KSZC25rs5b8W71\n7QSUSqY5c4w9OCtUy2PXsX37dv0cAwDy6aBZM2DJEvsXG1m+XJZQduoELFuG07pkc8eq77MVOnXq\nhAsXLiBf6X2zdi3QsSNw//2ySunf/5bvX2oq8MUXsh7/55/lk51BvxwFrVaLHTt22H1+W5SXl2PZ\nsmXOKcnMygJ275ZVYpZ4/XUp25bmF+zbJ4sNFi6EKjkZ/yPCUF1Sus6xR/0d/VMfPPbJkydTcHCw\nTHJ9+qm802Zk1KkNN27cIAD0gaUp/W+9JWeHXrxosuuee+6hV1u1IgIoRTdjsWosX6PR0NBGjeTf\ntnAhERGl6rzBtCefNB7wwgUigE7pPI6r69frdx05fJiSAcoPDZXeipcXUZVYbHFxMbVr104+RSge\nzenTRK+/TtSnD1XoErZalYqoTx+6/tJL1EuloldeeslwEDmj88UXTf7e4cOHU5cuXfRJvk8++cTs\nJXvllVfIz+AJReHHH38kAMYzZg8eJJo7Vx8TffbZZwkA/fXXX3J/QYH0nm0lQg348ssvCQBdNPOe\nmaOiooICAwPp6aefNt4xZQqRnx+989JLpFarqaKiQm43Z4tWS9StG1HnzrIdBUA/9u9PQUFBtpO4\nBii5iw0rVxI9/rj83HTpQrRqlfTczbFmjfw8DB5s8sT43XffGV/PWqK8hzVNJlvls8/k32tlRjVp\ntUStWhGNH29+f9euMslORF89+CBdB0jbsqXdT3v2AE6eWqdHjx6VSbY+feQXwwWEh4fTww8/bH7n\n4cPyLZozx2RXp06d6FhwMFFcHF27coW8vLzozTffNDrm1KlTBICut2xJ1K8fERGd1yUC17/9ttGx\nGo2GDupEfQ1A69at0+9btWoVjVAev1u1kslNg1CJwpIlSyg+Pt54+r+OZd99R/0Byp4yhahnT9Lo\nxtM0aUIDf5YJAAAgAElEQVTUvbsMizz6qDzHmjUmr3/jjTfI29ubVq9ebVUslORlWVmZ0XYl7HXJ\nXP8WHf/+978JAGXVIFmuoISX7B3jwIEDBIB++OEH4x1bthABtEFXuXXuf/8jevhhGRbavNn42D/+\nkNftm2+k+MTG0uGmTalnz57Vsr2kpITuCwigK35+UqxnzJBJclt89508/0MPGd0AbrvtNgJAzzzz\nTLXssMTYsWMJAA3VhQCrjVZLtGeP+ZujvRowciTRzTebbi8ultdMV3XVs2dPevyWW2To5t13a2av\nGVjYrVBaWko+Pj706quv6j1Veu89l9gyatQo6ty5s+UDunY1if2XlpZSZ6VkURd3HjBggEnPlTVr\n1sgY9t/+Jo89coQKX3mFKgCaW6XR1JUrV+hjndgmAPT3v/9dv0+JAVcoTcP+7/+q/Xfu3LlTXwGT\nn59PHZo0oX8lJhI9+6z0cjp3luWEzZrJnjlV+OmnnwgAPfjgg/Jmdf262fPMnj2bANCVK1eMtv/z\nn/8kAFRUVGTRxsLCQlpv8KRSExYuXEgAKMPOp7+5c+cSADp58qTxDo2GqF07uhIfT58DpPH2lten\nXTsp7oZx3sGDiVq3rvSYdd7nq8OHV8/4NWuIADosBF1XKqbs5aOP5Gdj/HiiWbMob9QoSgXoNEC3\nNG9OGqWnTg3RaDQUGhpKarWaVCoVnTt3rvqDKE/m//mP8fZz5+T2f/zD9hgzZ0qxzs833r5njxxj\nxQrKzc2trAIbOJAoKqpaT33WYGG3QmpqKgGyGyN98YW8DIcPu8SWt99+m1QqleWSqA8/lPYZfPEP\nHz5MMwHSCCHLq6iyJFARlEuXLtHAgQNJCEG56emyo+BLL5Fm2DA6CNB7VW5kR48epRCA/nrzTerc\nubOsjdfx6KOPUvv27Yk2bCC6/37pnVST7OxsAkCzZ8/We8YmZaBarSx3NMORI0cIAPn4+FBkZKTF\n8yiP/6d0SVuFN998k7y9vasVmqgJS5YsIQB09OhRu44fO3YstWrVyrxdr7xCBDm34vjtt8v3OjNT\ninjbtvIRPzVVfj4+/FD/suKzZ6kUoOTqFANoNETdulFx+/bkC9AcM0+JNtHZSwBdDwykDbr/T6lm\nEtccSrHDzJkzCQB9aPD32sXZs7KMVAii4GCinBwqLy+nb7/9lsqVMIw979m6dfLYLVuIiOjq1aty\nu9LtMyODfv31VwJAGzdurCyb3bWrmn+xeewVdvdKni5cCDz4IDBwoEywtWolfwYPBqZNkyVJugWb\nrZGamgoAcubizz/LBF/nzs623ixdu3aFVqs1WpPUiIcflv8uXarfdPTwYTwGID8xEWjTBgBwt65J\nWVJSEn755RfExcUhOTkZX375JQKjomQicOFCqPbswT5vb5NVlLKzs3ENgGbgQPTs2RMpKSnyzg+Z\nqO3cubMsQVyxQs6OrSahoaHw9/dHRkYGZs+ejcTERNx6663GBwkBVE0A64iOjoavry/KysosJk6B\nKo3ADFD6xNgzC7M2VDd5um3bNvTt29e8XdOmQfP88+gKYPEdd8j3un17Od09Px8YNkwuht6kCfD0\n0/qXnczNxS8Auqelme93Y46kJODAATT6xz8Q16MHvvnmG/37bzcffQScPAnt9evoFhSET4YOhbZd\nO9wpBFatWlW9saqwfv16xAJ4ffdu3NOzJ77//vvq2Tdtmmysl5QkE/9vvYWtW7di4sSJyPnqKznL\n1J5EZ0KC/DclBQcPHkRoaChWrlwpE6dNmwIdOmDz5s1Qq9Xo3bu3TMb6+jp12Utz1FrYhRA3CSE2\nCSGOCCEOCyFecIRhZsnIAA4ckPXR0dFSrEaMkG/UvHmyp0O3brK/gxX27t2LwMBARAYFyQz3fffp\nOwTWNUoTq6pT5vW0bw/07WtUHVP4+++IAOBr0JgsMjISsbGxePfdd3HPPffgpptuwt69e/G08oWf\nNEm2Grh6FUf9/U2EPScnB4CsKe/ZsycuX76Mc+fOQavV4tixY1LYa4EQAh06dMCiRYuQkZGBl156\nqVqv9/b21rcpMNdKQEFZSKPqMm8WG4A5GKXO3x5hP3/+PLKystCvXz/zB7RpA6/Zs5FfdQ5A165y\n4Y6MDClUkycDQUH63enp6fgaQKOCAuO2CJYgAt57D4iMBB55BBMnTsSBAwf0DpDCtWvX8MUXX1iu\nShEC6NABm/buxZkzZ/DEhAlQ3XknBnt747+rVlX/RmHA5nXrkNSoEXzXrcMHjRrh2LFj2LNnj/m/\npSrr18uGXm+/LfVi6lRgwQJU7N6NlgBanjghK3/soUULOa9lzx7s27cPRISXXnoJmr175fKWQujr\n1xs3bizFfsQI6Zg5cbF6E+xx6639AGgN4Bbd/5sAOAHgZmuvcUoopqKCaNs2WUVibhELAxITE+WC\nC8pjUkqK4+2xk4qKCvLz86MXzVSC6PnPf6SdBw8SEdHGyEgqEMJkFtzMmTNJpZvBaJLA1GiI2rcn\nAuihDh1Mpt0r1RwXLlzQt0NYtWqVPgG7YMGCWv+to0ePJgAUFhZm38zMKkycOJEA0J9W4r+7d+/W\nx/Krnrtr167VPmd1UR7Dd+7cafPYVatWEQDaZeMx/bbbbqPbbrvNdMeKFUQ9esgYsQEfffQRCYA0\n7drJlgW2SEqSn69vvyUiouvXr1OjRo2Mkp5FRUXUp08fAkB//PGH1eHGjRtHTZs2leHFRYuIAOoO\nUGpqqvGBBw/KHNKOHURElJGRQQkJCSb5iWvXrtG3gEy49+9PWi8vivX1NU3K/vGHzD8891xlbX1R\nkZwxGhNTmYO4cYOoRQu6GBlJU3ThotNVPi9WufdeoqgoevvttwkAqQAq9fYmevFFysvLIy8vL3rb\nsDhh1Sp5fWuZvyGqw1AMEV0kolTd//MBHAXQtrbjVhsvLyw4cgRrmjeHdu5cOUvMDBUVFThw4IB8\nnP/pJyAiArDiATobLy8vxMXFWfbYAeCBB+Rs1CVLgOJi9Dx9Gslt2gD+/kaHTZ8+HWfPnsWsWbMq\nZ4gqqFSyfW2LFshu1cpsKAaQIZP4+Hh4e3tjz549OHr0KADU2mMHKpuBTZ06Fd4WQi7WuO222+Dv\n7281FONqj10JxZQpNf9WuHTpEgAgvErn0KpYrGW//37Zfrmt8dftxIkTCG3eHKqnnpJdO3futDy4\n4q1HRADjxgGQs5Pvu+8+LFmyBMXFxdBoNBg3bhx27NgBIQS2bdtmcbi8vDysWrUKjzzyiJxxOXAg\nAGCIuXDM3LnAwYPAmDHAmTPYtm0bUlJSMGPGDKPD0t99FxMAnH/8cWDpUggfH3zVujV++uknlJSU\nyINyc+VShWq1HDcyUoaG3ntPasHcuTIkAkgv+sMP0erkScwCcAzA/O3bLV+jqiQkABkZuHT0KMLD\nw/HyyJHwqahAdtu22L59OzQaDe64447K44cPt7tjq8OwR/3t/QEQDuAMgEBrxznDYy8rK6M2bdpQ\nG4AKAdrcti2lp6ebHHfw4EECQD/Pnu3wUqSa8uSTT1KzZs2sJ/aGDiVq3540ixcTATS3JqvdaLVE\npaU0cuRI6t69u9Gu5557joKDg/W/d+/enQYPHkwff/wxAahMEtWC//73vxQdHW2xosUWGo2mcnam\nBS5evEgAaO7cuUbbb7nlFhpe3SqRGrB58+bKxJkNZs2aRQCopOqM4Sq8++67JISweZxC//795Szf\nK1ektxoaSmTmu0BERL/9Jr3JKk9kGzduJAC0aNEieuGFFwgAffbZZ9S9e3caOHCgxXMvWLDA9Inl\n5ptpd0iIcfVXaSlRSIgsww0MJOrWjf751lsEgIQQdFD3dErHj1Oxtzdt9/KiciVp/9prpBWCOgO0\nfPlyuW3iRPm0vmuXLIQYMUKfyKVHHzU1VKOhM61bEwG0NDKS2rZtWzlXwBa6Jn3PduxIgwcPpqtz\n5hAB9PyAAfT666+TWq2mwsJC49c8+aRM3lbdXk1Q11UxAAIA7AVwr4X9kwGkAEgJqzqd3QEoj7XL\nli2j7f37EwHU09ub3n33XSPBVKomLk+bRkoW29XMmTNHHwaxyMKFRACVtWtHZwBaMG9ejc83btw4\nCg8PN9r24IMPGk3Fnzx5sr5JmWFnxfpOYWGh2aqJqKgoeuSRR5x+/u3btxMAu8omX331VbOTqary\n/fffEwCryxEa0qZNG3r88cflLydOyBLSyEii7GzjA7VaWUobFmZSr67RaCgiIoKaNWtGAOiFF14g\nIqKpU6eSv7+/yTwBhb59+1Lnzp2NnZSpU6lMrSYfgI4cOSK36UorKSlJ3lxUKkpt356CmzalwMBA\nGj16NFFGBmnj4+mqSkWTDW/KV66QtkkTSvLzkzdrpQXDG28YG7NhA9FTT5mdc0FE9MH999MplYrW\n60pk7S51vXaNCKC/+/nJpmkvv0xl3t7kBVCzZs2ob9++pq/56y9p49Kl9p3DAvYKu0OqYoQQagCr\nACwmop8tPBnMJ6IEIkpo3ry5I05rxNy5cxEWFob77rsPfX75BdrgYCwIDcXMmTPxww8/6I9LTU2F\nf+PGaP7rr0C/fvKRzcVYbS2gMGYM0KgR1OfOYRGAmw36nVcX/fJ4BuTk5Bg140pISMCNGzfw22+/\nOSQMU1f4+fnB29vb5aEYe5KnN27cQJBB0tMSSosDe1oLFBQU4MKFC5WtBKKjZWuA8+dl64SiItlG\n4fffZaO5nTvlKlpVQncqlQoTJkzA1atXce+99+LTTz8FAPTr1w+FhYVmP6vp6enYvn07nnjiCeMq\nn8GDoS4vR28AP/+sk4fFi2XbhKFDZXXP55+je1YW5vv6Ym337vjH6tVAVBRw6BDGa7XoZdjuo1kz\niGnTMLK4GKXr10MzcaKsaqnaJ3/QIGDBAqP2FIYc9PbG0MhI3PH00wgJCcF3uiUUbRIcDE1EBOKK\nixEVFQXs2wev+Hh0iI7G1atXjcMwCv37y5BZHVXHOKIqRgD4BsBRIvrM1vHO4Pjx49i4cSOefvpp\neHl5AUFBUL39NrpduoSXunXD3/72N/36onv37sWj0dEQx48Djz/uCnNN6NKlCwArlTFA5XqoAH5E\n7WLeQUFByM3NNVqqLjs7G4Y33J66PjGXLl1yK2FXVlGyVO7obKpTFeMMYc/IyAAA466OvXvLqoyU\nFCkwYWFSTDdulJ0rJ040O9a0adPw1VdfYdGiRfJ7BcgOlIDZOPuyZcsAAGPHjjXe0b8/oFLh8bZt\npbDn58tqnYcekjFxAJg6FUubNsX92dno97//IVetxtyOHbHgtdewDsDQoUOrGgdN06ZYq9VCZGfL\nlbKUGLqdKNff19cXY8eOxS+//CKXjbTntdHRSAAQ2aEDsG8fVLfcgjlz5kClUuGuu+4yfYFKBTzy\niFxcxWAhHGfhCI+9L4DHAAwUQuzX/Qx3wLh289VXX0GtVuPJJ5+s3Pjss0BYGP6p0aCJry8efvhh\nFBUVYf/+/XhMq5W12A88UJdmWiQkJATt2rWzLuwA8P77+OHWW3GtZcvKhlE1ICgoCERU2ewJ0mM3\nFPbY2Fh9u1Fl1SR3oWnTpkYee1lZGUpKSupd8tReYW/Tpg3UarVdwp6eng4Apu16R4+WbX0PHJDF\nAitXylWhPv3UxFtXCAgIwNNPPw0/Pz/9trZt2yIiIsKssK9cuRJ9+vRB2yrJXDRtCvTsiaHe3khN\nTcWVBQvk6mAGNwACMKm0FPPvuQfi8mXs/vBD/O3ECcxcuBBxcXFo166d8ZhBQfB6/XU0AvCfgABo\nLKxyZg3D6//EE0+gtLQUSw3mi1jjTPPmaA+gS2kpcP060L07hg0bhmvXrulvfiY8+qhcQL46idoa\n4oiqmG1EJIioKxHF635+dYRx9lBYWIjvvvsO9913n/ESdY0aAZ9/Dp+0NCT37o19+/bhgQceQEVR\nEXqdOiV7XusqKOoD3bp1sy3sMTGYq9XWWmiVm4LinWi1Wly5csUoFKNWq/X9zt3JYwdMOzwqNzB3\nDcV4eXkhLCwMmZmZNo9VhD0qKsp05zPPyFBMUlLlxJka0K9fP2zbts2oLj0jIwMHDhzA/ZbqwQcN\nQptz59AEgPbHH2UVjsEEtatXr6KgpAQld9wBhIbimWeeQZs2bXDhwgUMGzbM/Jgvv4wdr72GV/Ly\nzK8fbAPD69+9e3d07drV7nDMId21a//779ANAKCyKsss8fHyZmqwsL2zcK+Zp2ZYunQpcnNz8ay5\nRRDuvRd4+WVE/PorFg0ejF9//RUjAfgWFgLjx9e5rdbo2rUrjh49ilIrMwWJqHIWaC1QPsxKnP3a\ntWvQarWomvtQwjHuLuzK/91V2AErJY9VOHHiBNq0aYOAgADzB9SgzLQq/fr1w+XLl3Hy5En9NqWU\n8T5LbW8HDYLQaPAggNADB6T3ahCHVxbRDtMtauPn54d33nkHgFwf2Cw+Pug5axaat2mDLw0WBrcX\nw+svhMCECROwZ88ey7PADUguKYEWgPeKFTLMogunWkUIoOrC7U7CrYWdiDB37lzExcVZnr334YfA\nwIF49H//wyMdO+JJLy9Q69bAnXfWrbE26Nq1KyoqKnDs2DGLx1y8eBF5eXm19tirCrvhrFNDnnvu\nOXz00Ud2rXJfn6gaimlIwp6enm73qkk1RfmuGYZjVq5ciZ49e+qF2YQ+fYBGjfB/QkBFZBSGAYAs\nXSsQw9dPnjwZKSkp5pOROry9vTFp0iT8/vvvJoul2+L69etGIU3lpvS74oVbIS0rC2caNwYKC2U7\nksaNq3VuZ+PWwr5nzx6kpqbimWeesdwDxNsbWLYMomVL/FhQgGEAxLhxcsJPPUKpjLEWjlE8CUd5\n7EooRpmcVNVj79ixI1599VWn91dxNK702O1NnhJRtYU9JycHBQUFVo+rC2Hv1KkTQkJC9MKelZWF\nlJQUy2EYQIZG+/VDMyKcaNLEpDdTVY8dkF60tcloCpMmTYJKpcK8efPs/htKSkpQWlpqdP1vuukm\nREdH46+//rL5+pMnT+KC4vDUIL7vbNxa2GfNmoWAgACM082Ys0hoKPDzz/C6ehUqjabehWEAKaK+\nvr5Whd1Rs0AVL8WWx+6u1AeP3VbytLi4GOXl5dZjsgYolTHW4uw3btxATk6O04VdpVKhb9++emG3\nGYZR0K1ju8yMU3XmzBn4+fmhWbNm1banbdu2GDVqFL799tvKmag2UD77VW+sAwcOxJYtW1Bhpa9L\nQUEBLl26hALle8jC7jhWr16NNWvWYMaMGfZ9YXv0kJ0JZ8yQixnXM7y9vREbG2u1lv3gwYMICQlB\nq1atanUuS6EYZ8wvcAXuEGO3JCyWsKfkUUmcVmc5vJrSr18/HD9+HDk5OVi5ciXi4+MRaWtOyCOP\n4HjHjphz44aJAJ85cwbt27ev8dPhM888gytXrshOi3ZgTdjz8/P1S2eaQ8ktaPv3lxVFVkJFrsIt\nhb2goABTp05FXFwcpk2bZv8L775b9o6op3Tt2tWqsKempuKWW26pdWhEaV+rfLiVUExNvKX6SGBg\nIMrKyvSJaMV7t9c7rg3OEnaln4w1YVee6OpC2JWSvhUrVmDHjh3WwzAK7dtj77vv4gpgEg/Pysqy\nHJ+3g0GDBiEqKsruJKql66/E862FYxRhbzFwoKzJd2GvKUu4pbDPnDkTZ8+exbx58/RfJE+ge/fu\nyM7Oxrlz50z2lZWVIS0tzWrLWntRqVQIDAzUx9hzcnIQEhLiMdeyaiMwT/DYW7RogcaNG1sV9p07\nd6JJkyaIiYmx09qak5CQAF9fX/xdN9vTLmFHZX298nShcObMmVoJu0qlwpQpU5CcnKy/wVlD+exX\nnQ/SokULdOnSxaqwK5PAIiMjLc4BcDVuJ+wHDhzA559/jkmTJqFPnz6uNsehJCYmAgB27dplsu/I\nkSMoKytziLADxm0Fqs46dXeqLraRl5cHlUol+2M7GSEEvL29HS7sQgiEh4dbjbEnJyejd+/e+lmi\nzsTX1xc9e/ZETk4OYmNj7b6ZKPX1hsJeUlKCy5cv10rYAWD4cDkvMiUlxeax1q7/wIEDsW3bNoul\nxxkZGQgNDa2TJ8Ca4lbCrtVqMWXKFISEhODDDz90tTkOJz4+Hj4+Pti9e7fJPmXRg+4OStQEBQUZ\nxdg9JXEKmPfY62L1JAW1Wm0zeVpdYQeslzzm5eXh0KFDdersKGWP9nrrgHQomjVrZiTsyhNq+/bt\na2VPVFQUfHx8kJaWZvNYW8JeUlKCnRbaHZ88edL8BLB6hFsJ+4IFC7Bz5058+umnCAkJcbU5DsfX\n1xfx8fFmPfZ9+/YhICDAYR+ooKAgo3JHT/fY6yIMo6BWqx3usQOVwm4441Nh9+7d0Gq1dSrsI0eO\nhJ+fHx555JFqvS46OlofzgDM17DXBLVajU6dOtVa2G+//XaoVCqL4ZiMjAwWdkdSWlqKESNG2C5v\ndGMSExORkpJisvxYamoqunfvDpXKMW+ZYSimap8Yd0cR8aoee11RHWGvzuN8REQE8vLyzDaqSk5O\nhhBCH86rC/r27Yv8/Pxqx/Sjo6ONPHZzNew1JTY2FocPH7Z53PXr19GoUSN9PyRDgoKC0KNHD7PC\nXlpairNnz9quAHIxbiXszz//PJKSktxuwkx16NWrFwoLC40+nBqNBvv373dYGAaoDMVoNBpcvXrV\nI0Mx9d1jtyQsllC6gJprwJWcnIy4uLg6j/vWJJ4fFRWFs2fPori4GIAUdiGEafOwGhAXF4esrCyj\nBnfmsDU5bODAgdi5cycKCwuNtitPTOyxOxhPFnXAfAL1xIkTKCoqcljiFKgUdkt9YtwZV4difHx8\n7BL26oRhAFmKFxwcjBUrVhht12q12LFjh9sUEyiVMUrJ45kzZ9CqVSv41rApmSHKgue2+r3YI+wV\nFRUmN1ElhMTCzlSLqKgohISEGCVQ9+3bBwAOF3ZlUQbAc2adAu4TiqmusKvVatxzzz1Ys2aNUcXG\nkSNHkJeX53bCroRjlMlJjiA2NhYAbMbZbV3/vn37Qq1Wm4RjWNiZGiGEQK9evYw89tTUVPj6+qJT\np04OO49Sv6t8uTzJY/f19YWvr69LQzH2VMVUV9gB4IEHHkBeXh7++OMP/bbk5GQAcBthr1ryWNvJ\nSYZERETAz8+v1sLu7++P3r17mwj7yZMnERgYWO8n87Gw10MSExNx+PBhfcOn1NRUdO3a1aETiJQP\ntScKOyC9dsVjz83NrdPYs7M8dkDOsKwajklOTkbz5s3rfUJPISgoCKGhoUhPTwcR1XpykiEqlcqu\nBGrVzo7mGDhwIFJTU42S1UpFTH0PCbOw10MSExOh1WqRkpICIsK+ffscGoYBKoVdWTLQk0IxgEyg\n5uXloaKiAkVFRR4RilHGHjNmDFavXq0PxyQnJ6Nv3771XmwMUUoec3JyUFpa6jBhB2Q4prYeOyAn\nPGm1WgwbNkyfD3CHUkfAQcIuhBgmhDguhMgQQrzhiDEbMsoCF7t27UJmZiZu3Ljh0IoYwFTY6/uj\nZXVRGoHV5epJCs4UdsA4HJOTk4P09HS3CcMoKCWPSqmjo2LsgEygXrx4EdeuXTO7396Wyb169cLK\nlStx4sQJdO/eHYsXL0ZmZqZbPBk5YjFrLwBfALgLwM0AHhFCuNcimfWM0NBQREZGYvfu3foZp472\n2A1j7M2aNYO3A1bWqU8orXvrsk+Mgq2qmOr2Yq+KYThmx44dANwnvq4QFRWFc+fO6ReWcbTHDsBi\nOKaoqAgVFRV2Xf/77rsP+/fvR2xsLMaNG4eKiooG47H3ApBBRKeIqAzAUgCjHTBugyYxMRG7du3C\nvn374OXlpa9hdhTKh9rTJicpKB67K4TdVvJU6cVeU2H38fHRh2M2bdoEtVpt14IU9QmlMmbTpk0A\nHCvsSsmjpXBMdWf9tm/fHlu2bMH06dPRuHHjOp0EVlMcIextAZw1+P2cbhtTCxITE3H+/HkkJSUh\nNja2WhNZ7MHwQ+2pwu4qj91WKKYm7QSqooRj5s+fjx49ejj88+FsFGHfuHEj/P39bSYyq0O7du0Q\nGBho0WO31NnRGmq1GrNmzUJBQYH+iaA+U2fJUyHEZCFEihAiRVnYgbGM4hUcPHjQ4fF1QJZzKeEX\nT0ucApXJU08V9kGDBiEoKAhFRUVuF4YBKkses7KyarXAhjmEEFYTqLW5/u6SoHaEsJ8HcJPB7+10\n24wgovlElEBECZ7oIToapdMj4Pj4OiA/oMoH2xPfDyUUo5Q81idhV2yqjbAr4RjA/eLrgLzxKp87\nR4ZhFOLi4pCWlma2YZojbqz1HUcI+x4A0UKICCGED4CHAaxxwLgNGqXTI+AcYQcqP9ie6rFrNBpc\nunQJQP1KnjpKWKZMmYIuXbroV/1xN5RwjLOE/erVq/rVwQxhYbcDIqoA8ByA3wEcBbCciGy3V2Ns\n0rt3b6hUKnTr1s0p43u6xw5U9vquT8nTmnR2NEdiYiIOHjzotqWqzhR2a60FahJjdzccEmMnol+J\nqCMRRRLRLEeMyQDTp0/H+vXr0aRJE6eMr3ywPVnYz549CyEEAgIC6uzcdRFj9wSc7bED5kseHXVj\nrc/wzNN6TMuWLXHnnXc6bXxPD8UAUtibNGnisD729sDCbh+KsCsLdTuSFi1aIDQ01KzHfuPGDfj7\n+3vMGr/mYGFvwDSUUExdhmEA+4Td19fX7UoUHc3o0aMxb948pyR/rVXG1GZymLvAwt6AUUIxnuyx\nX7hwoc6F3Z7kqacLiz34+vpi8uTJTlt8Oy4uDocPHzapjGkI15+FvQHTrVs3REVFuW3yzRqKmGs0\nmnrpsXu6sNQHYmNjkZeXp0+gK9jT2dHdYWFvwDz66KNIT093msfkSgzF3BXCbqsqhoXd+VhqLdAQ\nrj8LO+ORuFrYtVottFqt2f0NQVjqAyzsDONheHt7o3HjxgBcI+wALIZjGoKw1AeCg4PRtm1bFnaG\n8VigTUkAAA2KSURBVCSUBKorkqcAC3t9QGktoKDVapGbm+vx15+FnfFYFEGvTx57bXuxM9UjLi4O\nR44cgUajAQDk5+dDq9Vy8pRh3BVXC7u5BGpJSQnKyspY2OuIuLg4lJSU4OTJkwAazuQwFnbGY1FC\nMXU9ddyax95QhKW+UDWB2lCuPws747G42mNnYXc9N998M4QQLOwM4ym4KnnKwl5/aNy4MSIjI1nY\nGcZTcJXHbq0qpqEIS33CsDKmIbTsBVjYGQ/G1aEYc8lTFva6Jy4uDidOnEBpaWmDuf4s7IzHwqEY\nBpDCrtFocOzYMf31r+vPRF3Dws54LEOGDMHYsWPRpk2bOj0vC3v9wrAy5saNGwgMDPTI/kiG1ErY\nhRAfCyGOCSEOCiH+K4TgTytTb+jSpQsWLVoEb2/vOj2vLWHnXux1S8eOHaFWq5GWltYgOjsCtffY\n/wQQR0RdAZwA8GbtTWIY98ZW8pS99bpFrVajU6dOeo+9IVz/Wgk7Ef2hW8waAHYCaFd7kxjGvbHl\nsTcEYalvxMXF4dChQw3m+jsyxj4RwG8OHI9h3BJbVTGevIhyfSUuLg5ZWVk4c+YMCzsACCE2CCHS\nzPyMNjjmLQAVABZbGWeyECJFCJGSk5PjGOsZph7CHnv9Q0mgZmZmNojrbzOrRESDre0XQjwBYCSA\nQVR1cUHjceYDmA8ACQkJFo9jGHfHlrCHh4fXsUWMIuyA509OAmpfFTMMwGsARhFRkWNMYhj3hpOn\n9Y/w8HD4+/sDaBilprWNsf8HQBMAfwoh9gshvnKATQzj1ljy2LkXu+tQqVSIjY0F0DCEvVYFvkQU\n5ShDGMZTsJQ85V7sriUuLg67d+9uENefZ54yjIOx5LHzrFPXosTZG8L1Z2FnGAfDwl4/SUxMBAC0\nb9/exZY4n7qda80wDQBLydPc3FwALOyuok+fPjh16hQiIiJcbYrTYY+dYRwMe+z1l4Yg6gALO8M4\nHJVKBZVKZZI8ZWFn6goWdoZxAmq12mIoxtN7gTOuh4WdYZyAOWHPz88HADRp0sQVJjENCBZ2hnEC\n1oQ9ICDAFSYxDQgWdoZxAj4+PmaF3d/fHyoVf+0Y58KfMIZxAmq12iR5mp+fz2EYpk5gYWcYJ2Ap\nFMPCztQFLOwM4wRY2BlXwsLOME6AhZ1xJSzsDOMELCVPWdiZuoCFnWGcAHvsjCthYWcYJ8BVMYwr\nYWFnGCfAHjvjShwi7EKIl4UQJIQIdcR4DOPuVBX2iooKFBcXs7AzdUKthV0IcROAIQDO1N4chvEM\nqiZPCwoKAHCfGKZucITH/jmA1wCQA8ZiGI+gqsfODcCYuqRWwi6EGA3gPBEdcJA9DOMRVE2esrAz\ndYnNpfGEEBsAtDKz6y0A0yHDMDYRQkwGMBkAwsLCqmEiw7gf7LEzrsSmsBPRYHPbhRBdAEQAOCCE\nAIB2AFKFEL2I6JKZceYDmA8ACQkJHLZhPBoWdsaV1HgxayI6BKCF8rsQIhNAAhFdcYBdDOPWsLAz\nroTr2BnGCVStimFhZ+qSGnvsVSGicEeNxTDuDidPGVfCHjvDOAEOxTCuhIWdYZyAOWFXqVTw8/Nz\noVVMQ4GFnWGcgFqtRkVFBYhkAZjSJ0ZXQcYwToWFnWGcgI+PDwDZIwbgBmBM3cLCzjBOQK1WA4A+\nHMPCztQlLOwM4wQUYVcqY1jYmbqEhZ1hnAB77IwrYWFnGCfAws64EhZ2hnECSvKUhZ1xBSzsDOME\n2GNnXAkLO8M4AU6eMq6EhZ1hnIChx15aWory8nIWdqbOYGFnGCdgKOzcJ4apa1jYGcYJGCZPWdiZ\nuoaFnWGcAHvsjCthYWcYJ2CYPGVhZ+oahy20wTBMJYYeu9IIjIWdqStq7bELIaYKIY4JIQ4LIT5y\nhFEM4+5wKIZxJbXy2IUQAwCMBtCNiEqFEC1svYZhGgIs7Iwrqa3H/gyAD4moFACIKLv2JjGM+8NV\nMYwrqa2wdwRwmxBilxBiixCipyOMYhh3hz12xpXYDMUIITYAaGVm11u614cA6A2gJ4DlQogOpKwH\nZjzOZACTASAsLKw2NjNMvadqVYyPj4/ei2cYZ2NT2IlosKV9QohnAPysE/LdQggtgFAAOWbGmQ9g\nPgAkJCSYCD/DeBJVPXb21pm6pLahmF8ADAAAIURHAD4ArtTWKIZxd1jYGVdS2zr2bwF8K4RIA1AG\n4HFzYRiGaWhUTZ6ysDN1Sa2EnYjKAIxzkC0M4zGwx864Em4pwDBOoGrylIWdqUtY2BnGCXh5eQFg\nj51xDSzsDOMEhBBQq9Us7IxLYGFnGCfh4+PDws64BBZ2hnESarUaZWVlKCgoYGFn6hQWdoZxEmq1\nGrm5udBqtSzsTJ3Cws4wTkKtVuPatWsAuE8MU7ewsDOMk1Cr1bh+/ToAFnambmFhZxgn4ePjwx47\n4xJY2BnGSXAohnEVLOwM4yTUajWuXr0KgIWdqVtY2BnGSajVal7ImnEJLOwM4ySUfjEACztTt7Cw\nM4yTYGFnXAULO8M4CcOl8AICAlxoCdPQYGFnGCeheOyNGzfWd3tkmLqAhZ1hnIQi7ByGYeqaWgm7\nECJeCLFTCLFfCJEihOjlKMMYxt1hYWdcRW099o8AzCSieADv6H5nGAYs7IzrqK2wE4BA3f+bArhQ\ny/EYxmNQkqcs7ExdU6vFrAG8COB3IcQnkDeJPrU3iWE8A/bYGVdhU9iFEBsAtDKz6y0AgwBMI6JV\nQogHAXwDYLCFcSYDmAwAYWFhNTaYYdwFFnbGVdgUdiIyK9QAIIT4AcALul9XAPjayjjzAcwHgISE\nBKqemQzjfrCwM66itjH2CwD66/4/EEB6LcdjGI+BhZ1xFbWNsU8CMFsI4Q2gBLpQC8MwnDxlXEet\nhJ2ItgHo4SBbGMajYI+dcRU885RhnAQLO+MqWNgZxkmwsDOugoWdYZwECzvjKljYGcZJsLAzroKF\nnWGcBFfFMK6ChZ1hnAQLO+MqWNgZxkncddddeOuttxAZGelqU5gGhiCq+9n9CQkJlJKSUufnZRiG\ncWeEEHuJKMHWceyxMwzDeBgs7AzDMB4GCzvDMIyHwcLOMAzjYbCwMwzDeBgs7AzDMB4GCzvDMIyH\nwcLOMAzjYbhkgpIQIgdAVg1fHgrgigPNcTRsX+1g+2oH21d76rON7Ymoua2DXCLstUEIkWLPzCtX\nwfbVDravdrB9tccdbLQFh2IYhmE8DBZ2hmEYD8MdhX2+qw2wAdtXO9i+2sH21R53sNEqbhdjZxiG\nYazjjh47wzAMYwW3EnYhxDAhxHEhRIYQ4o16YM+3QohsIUSawbYQIcSfQoh03b/BLrTvJiHEJiHE\nESHEYSHEC/XJRiFEIyHEbiHEAZ19M3XbI4QQu3Tv8zIhhI8r7DOw00sIsU8Isba+2SeEyBRCHBJC\n7BdCpOi21Yv3V2dLkBBipRDimBDiqBDi1vpinxAiRnfdlJ88IcSL9cW+2uA2wi6E8AL+v327CbWq\nigI4/lvwKspC+0KkF1gkiYN8GpiRRBmFSjhqkDRwIDRxUBBEEjRvUjmIJkVNwqBvcdDXq1EDK83C\netgHCSrqi0iCgshaDc5+dHhI9Gxw9r3sP2zu3mvfwZ+z7l33nHXO9Sw2YxW2RcSqYa28hE3zYo9h\nOjNXYLqsh+IsHsnMVViPneWY1eL4OzZm5mpMYVNErMeTeDozb8DP2DGQ3xwPYaa3rs3vzsyc6j2i\nV0t+YTfeycyVWK07jlX4ZeaRctymcDN+w5u1+P0vMnMkBm7Fu731LuyqwGs5DvfWR7CszJfhyNCO\nPbe3cXeNjrgEB3GL7s8hE+fK+wBek7ov90bsQ1TmdxRXzYtVkV8sxg/Kvbza/OY53YOPa/Vb6BiZ\nM3Zcg2O99fESq42lmXmyzE9h6ZAyc0TEcqzBfhU5ljbHIczifXyPM5l5trxl6Dw/g0fxV1lfqS6/\nxHsRcSAiHiyxWvJ7HX7Ei6WV9XxELKrIr8/92FPmNfotiFEq7CNHdj/5gz92FBGX4nU8nJm/9PeG\ndszMP7O7FJ7EOqwcymU+EXEvZjPzwNAu/8KGzFyra1HujIjb+5sD53cCa/FcZq7Br+a1NYb+/EG5\nR7IVr87fq8HvfBilwn4C1/bWkyVWG6cjYhmU19khZSLiAl1Rfzkz3yjhqhwhM8/gI11rY0lETJSt\nIfN8G7ZGxFG8omvH7FaPn8w8UV5ndf3hderJ73Ecz8z9Zf2artDX4jfHZhzMzNNlXZvfghmlwv4p\nVpQnEi7UXTrtHdjpXOzF9jLfrutrD0JEBF7ATGY+1duqwjEiro6IJWV+sa7/P6Mr8PcN7ZeZuzJz\nMjOX6z5vH2bmA7X4RcSiiLhsbq7rEx9WSX4z8xSORcSNJXQXvlaJX49t/mnDUJ/fwhm6yb/AGxxb\n8I2uD/t4BT57cBJ/6M5Oduh6sNP4Fh/gigH9NuguI7/EoTK21OKIm/B58TuMJ0r8enyC73SXxxdV\nkOs7sK8mv+LxRRlfzX0naslvcZnCZyXHb+HyyvwW4Scs7sWq8Tvf0f552mg0GmPGKLViGo1Go/Ef\naIW90Wg0xoxW2BuNRmPMaIW90Wg0xoxW2BuNRmPMaIW90Wg0xoxW2BuNRmPMaIW90Wg0xoy/AY3m\n4m8YwuOtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcf77860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.33363179476 \n",
      "Updating scheme MAE:  1.51021730344\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
