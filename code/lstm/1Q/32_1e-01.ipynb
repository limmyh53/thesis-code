{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/32_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-1\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 32 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 32 \n",
      "Learning rate = 0.1 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.1\n",
      "Fold: 1  Epoch: 1  Training loss = 2.6903  Validation loss = 1.7600  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.6883  Validation loss = 1.8307  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.3326  Validation loss = 0.9957  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.6392  Validation loss = 1.6486  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.4975  Validation loss = 1.0368  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.3372  Validation loss = 2.0194  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.0126  Validation loss = 2.0827  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.2486  Validation loss = 1.2427  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.5497  Validation loss = 1.9932  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 1.8271  Validation loss = 1.0503  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 1.6879  Validation loss = 0.8559  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 1.9050  Validation loss = 2.2314  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 11  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 1.7103  Validation loss = 1.8772  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 1.5965  Validation loss = 1.7989  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 1.4696  Validation loss = 1.8523  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 1.5104  Validation loss = 1.7403  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 1.9708  Validation loss = 1.9906  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 1.6040  Validation loss = 1.5074  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 1.4956  Validation loss = 1.4864  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 1.4833  Validation loss = 1.7853  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 1.4039  Validation loss = 2.0305  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 1.4974  Validation loss = 1.8457  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 1.3723  Validation loss = 1.9885  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 1.4841  Validation loss = 1.9665  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 1.2687  Validation loss = 2.1819  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 7  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.3056  Validation loss = 2.0505  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.3978  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.2261  Validation loss = 1.8991  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.2187  Validation loss = 1.1707  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.3462  Validation loss = 0.8462  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.1997  Validation loss = 1.6426  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.2225  Validation loss = 1.8034  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.6685  Validation loss = 2.6069  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.1555  Validation loss = 1.4694  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.1678  Validation loss = 1.1693  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.1903  Validation loss = 1.1891  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.1760  Validation loss = 1.1523  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.0775  Validation loss = 1.4107  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.1236  Validation loss = 0.6097  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.2721  Validation loss = 1.7780  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.0990  Validation loss = 0.7808  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.2592  Validation loss = 0.6682  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.1308  Validation loss = 0.8807  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.2652  Validation loss = 0.9280  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.0548  Validation loss = 0.7813  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.0186  Validation loss = 1.1099  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.1857  Validation loss = 1.2403  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 0.9461  Validation loss = 0.5038  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.0373  Validation loss = 0.5112  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 0.9538  Validation loss = 0.6282  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.3183  Validation loss = 0.4541  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.3768  Validation loss = 0.4543  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 0.9938  Validation loss = 1.0695  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 0.9609  Validation loss = 1.2184  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 0.9782  Validation loss = 0.6952  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.0018  Validation loss = 0.8299  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 0.9445  Validation loss = 0.8160  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.2542  Validation loss = 0.3020  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 0.8854  Validation loss = 0.8094  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 0.9654  Validation loss = 0.4639  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 0.9210  Validation loss = 0.7722  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 0.8852  Validation loss = 0.9335  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 0.9026  Validation loss = 0.5962  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 0.9251  Validation loss = 0.6158  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 0.8773  Validation loss = 0.8662  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 0.9219  Validation loss = 0.8417  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 0.9810  Validation loss = 0.6698  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 0.8706  Validation loss = 0.6372  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 0.8460  Validation loss = 0.8972  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 0.8442  Validation loss = 0.7693  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 0.9889  Validation loss = 1.3750  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 33  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 0.9627  Validation loss = 3.3889  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 0.8524  Validation loss = 3.4388  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 0.8912  Validation loss = 3.7790  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.3136  Validation loss = 4.0265  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 0.8667  Validation loss = 3.1573  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.0298  Validation loss = 3.4632  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 0.8404  Validation loss = 3.1369  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 0.8250  Validation loss = 2.7568  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 0.8062  Validation loss = 3.1675  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 0.8914  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 0.8822  Validation loss = 3.3052  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 0.9007  Validation loss = 3.8038  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 0.8101  Validation loss = 2.8585  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 0.8260  Validation loss = 2.7069  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 0.8086  Validation loss = 3.5470  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 0.8991  Validation loss = 3.0943  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 0.8250  Validation loss = 2.7781  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 0.8608  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 0.7756  Validation loss = 2.8532  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 0.9080  Validation loss = 3.1631  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 0.8514  Validation loss = 3.3779  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 0.8336  Validation loss = 3.3481  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 0.8161  Validation loss = 2.9907  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 0.7782  Validation loss = 3.4261  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 0.8098  Validation loss = 3.5075  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 14  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 0.9438  Validation loss = 0.9259  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 0.9393  Validation loss = 0.8234  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 0.8534  Validation loss = 1.0026  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.2120  Validation loss = 1.2161  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 0.8023  Validation loss = 0.9470  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 0.7713  Validation loss = 1.1648  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 0.8343  Validation loss = 0.9436  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 0.7397  Validation loss = 1.0730  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 0.8928  Validation loss = 1.3753  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.9002  Validation loss = 0.7392  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.7423  Validation loss = 1.1791  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 0.7283  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 0.8894  Validation loss = 1.1849  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 0.7395  Validation loss = 1.3251  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.7718  Validation loss = 1.1983  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 0.7021  Validation loss = 1.3043  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 0.8046  Validation loss = 1.3894  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 10  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.9890  Validation loss = 2.0792  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 0.8300  Validation loss = 2.6212  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.7631  Validation loss = 2.5450  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.7443  Validation loss = 2.7357  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.7464  Validation loss = 2.6793  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.7015  Validation loss = 2.8925  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.8171  Validation loss = 2.9890  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.7383  Validation loss = 3.0021  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.7134  Validation loss = 2.5360  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.6815  Validation loss = 2.6879  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.6951  Validation loss = 2.6164  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.7044  Validation loss = 2.7881  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.6943  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.7453  Validation loss = 2.9755  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.6648  Validation loss = 2.8797  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.6810  Validation loss = 3.0776  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 1  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.0178  Validation loss = 2.4569  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.8984  Validation loss = 1.3150  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.8497  Validation loss = 2.0746  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.7698  Validation loss = 1.8138  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.0718  Validation loss = 2.8465  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.8240  Validation loss = 2.0006  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.8734  Validation loss = 2.4341  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.8082  Validation loss = 1.7397  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.9942  Validation loss = 2.5587  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.8718  Validation loss = 2.1070  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.7713  Validation loss = 2.0122  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.0858  Validation loss = 2.3665  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.7667  Validation loss = 1.8314  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.7865  Validation loss = 1.7387  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.7851  Validation loss = 1.9717  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 0.8278  Validation loss = 2.2541  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.0081  Validation loss = 2.7921  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 2  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.8017  Validation loss = 5.3859  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.8981  Validation loss = 5.7236  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.8537  Validation loss = 5.3865  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.7147  Validation loss = 4.9212  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.8259  Validation loss = 5.5959  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.7419  Validation loss = 5.2955  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.7846  Validation loss = 5.6868  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.7458  Validation loss = 4.5776  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.7025  Validation loss = 5.2372  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.6627  Validation loss = 4.9251  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.6582  Validation loss = 5.0338  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.6464  Validation loss = 4.7105  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 0.6524  Validation loss = 4.8659  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 0.6392  Validation loss = 4.8649  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 0.8464  Validation loss = 4.4780  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 0.6503  Validation loss = 4.8446  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 0.6811  Validation loss = 4.6726  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 0.7853  Validation loss = 5.4165  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 15  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.4442  Validation loss = 6.2620  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.7324  Validation loss = 4.9768  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.0515  Validation loss = 5.6275  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.0228  Validation loss = 5.8897  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.3087  Validation loss = 6.6689  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.3692  Validation loss = 6.4973  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.4715  Validation loss = 5.9115  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.3814  Validation loss = 6.6307  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.1592  Validation loss = 5.9001  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.1773  Validation loss = 5.9095  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.5700  Validation loss = 6.4123  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.6295  Validation loss = 5.5810  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.2490  Validation loss = 6.7151  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 2  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.7130  Validation loss = 1.6616  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.8486  Validation loss = 1.8164  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.4807  Validation loss = 1.5343  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.3800  Validation loss = 2.1347  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.5935  Validation loss = 1.7904  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.9506  Validation loss = 2.3805  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.2657  Validation loss = 2.9975  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.3777  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.5289  Validation loss = 2.4168  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.7813  Validation loss = 1.5550  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.1298  Validation loss = 2.3633  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.1203  Validation loss = 2.2013  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 1.4252  Validation loss = 2.9087  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.2564  Validation loss = 2.0025  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.1514  Validation loss = 2.5210  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 1.1608  Validation loss = 2.2872  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 1.1719  Validation loss = 2.1479  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 1.5204  Validation loss = 3.3735  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 3  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.5980  Validation loss = 2.7083  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.6254  Validation loss = 2.5199  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.3520  Validation loss = 2.5736  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.3081  Validation loss = 2.3219  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.1795  Validation loss = 1.9560  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 2.0092  Validation loss = 1.7786  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.2070  Validation loss = 1.5810  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.5170  Validation loss = 3.0631  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.3546  Validation loss = 1.9147  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.9036  Validation loss = 2.0565  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.3291  Validation loss = 2.0023  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.5425  Validation loss = 2.2362  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.2935  Validation loss = 1.6073  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.1855  Validation loss = 1.7446  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 1.1503  Validation loss = 1.3957  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 1.1243  Validation loss = 1.6895  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 1.2106  Validation loss = 1.7071  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 1.1534  Validation loss = 1.8185  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 1.1845  Validation loss = 1.7874  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 1.1681  Validation loss = 1.6129  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 1.1030  Validation loss = 1.9644  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 1.1006  Validation loss = 1.7881  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 1.1082  Validation loss = 2.0793  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 15  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.1185  Validation loss = 1.4969  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.1571  Validation loss = 1.7715  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.5057  Validation loss = 1.4367  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.1304  Validation loss = 1.2228  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.2263  Validation loss = 1.3482  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.3977  Validation loss = 1.7620  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.0779  Validation loss = 1.4944  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.2877  Validation loss = 1.6829  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.1415  Validation loss = 1.8296  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.1147  Validation loss = 1.6175  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.0879  Validation loss = 1.5088  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.2501  Validation loss = 1.2712  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.0619  Validation loss = 1.5778  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 0.9993  Validation loss = 1.3676  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.1166  Validation loss = 1.5843  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.1054  Validation loss = 1.9499  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 4  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.2483  Validation loss = 3.0225  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.2704  Validation loss = 0.4804  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.1959  Validation loss = 3.4409  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.3039  Validation loss = 3.2658  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.3667  Validation loss = 2.1418  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.2582  Validation loss = 3.4293  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.1899  Validation loss = 2.7276  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.5043  Validation loss = 4.2466  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.2129  Validation loss = 3.5383  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.2323  Validation loss = 2.2825  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.2666  Validation loss = 2.9986  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.1409  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 1.0563  Validation loss = 2.8752  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 1.1622  Validation loss = 3.3387  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 1.1544  Validation loss = 2.9475  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 1.4466  Validation loss = 1.7851  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 1.3642  Validation loss = 2.2118  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 1.1558  Validation loss = 2.5893  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 1.6311  Validation loss = 4.7347  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 2  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.2380  Validation loss = 3.4738  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.4362  Validation loss = 5.5841  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.3245  Validation loss = 4.8632  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.1884  Validation loss = 3.9919  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.3247  Validation loss = 5.3569  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.2104  Validation loss = 3.8715  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.2676  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.4034  Validation loss = 5.9929  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.2514  Validation loss = 5.7614  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.2202  Validation loss = 4.5030  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.3194  Validation loss = 4.0910  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.1401  Validation loss = 4.3912  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.1266  Validation loss = 4.2848  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.1558  Validation loss = 5.1227  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.2021  Validation loss = 5.3652  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.1354  Validation loss = 4.7392  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.2597  Validation loss = 5.8345  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.1456  Validation loss = 5.5257  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.1272  Validation loss = 5.7490  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 1.2884  Validation loss = 5.5947  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 1.1075  Validation loss = 4.7485  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 1.5013  Validation loss = 3.7090  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 1.5080  Validation loss = 3.9104  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 1.0940  Validation loss = 4.7620  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 1.1300  Validation loss = 5.6968  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 1.0164  Validation loss = 5.3175  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 1.1515  Validation loss = 4.4486  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 1.1009  Validation loss = 5.3232  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 1.6747  Validation loss = 5.3716  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.0152  Validation loss = 3.7799  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 1.0568  Validation loss = 5.4723  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 1.1924  Validation loss = 5.6661  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 1.0121  Validation loss = 4.4436  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 0.9845  Validation loss = 4.6259  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 1.2058  Validation loss = 3.8881  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 1.1777  Validation loss = 4.1986  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 1.1225  Validation loss = 3.8573  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 1.0188  Validation loss = 4.8219  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 1.1690  Validation loss = 3.5867  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 1.1047  Validation loss = 5.6373  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 1.1878  Validation loss = 4.9625  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 1.0658  Validation loss = 4.2423  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 0.9806  Validation loss = 5.2689  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 1.0459  Validation loss = 5.2193  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 1.1253  Validation loss = 3.9075  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 0.9694  Validation loss = 4.3692  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 0.9504  Validation loss = 4.8519  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 1.1332  Validation loss = 4.6809  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 1.0665  Validation loss = 4.6527  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 1.0384  Validation loss = 4.6912  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 1.1514  Validation loss = 6.0124  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 7  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.1223  Validation loss = 4.0345  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.5430  Validation loss = 3.9120  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 1.4322  Validation loss = 3.5574  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.5903  Validation loss = 3.5830  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.5845  Validation loss = 4.9552  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.5033  Validation loss = 4.6966  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.4443  Validation loss = 5.1961  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.4502  Validation loss = 5.2725  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.9923  Validation loss = 5.5413  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.0659  Validation loss = 6.4957  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 1.4838  Validation loss = 6.3446  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.1184  Validation loss = 4.8582  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 1.4396  Validation loss = 4.7779  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 1.2720  Validation loss = 5.1978  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 1.8334  Validation loss = 5.1945  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 1.4890  Validation loss = 4.7579  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 1.6315  Validation loss = 4.6718  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 1.6290  Validation loss = 4.9100  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.4596  Validation loss = 5.3920  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 1.3954  Validation loss = 5.5105  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 1.3236  Validation loss = 6.3956  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 3  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 1.8980  Validation loss = 3.3382  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.1775  Validation loss = 3.4085  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 1.9491  Validation loss = 3.0399  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.1319  Validation loss = 2.6667  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.0021  Validation loss = 3.1703  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.0685  Validation loss = 3.0016  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.0328  Validation loss = 2.6347  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 1.8394  Validation loss = 3.7214  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.4869  Validation loss = 4.0560  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 1.8642  Validation loss = 3.6000  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.0242  Validation loss = 2.9915  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 1.8313  Validation loss = 3.9756  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.1238  Validation loss = 3.2353  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.0262  Validation loss = 3.6846  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 1.9142  Validation loss = 2.6900  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 1.9196  Validation loss = 3.1307  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.0275  Validation loss = 3.0632  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 1.7062  Validation loss = 3.1307  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.0632  Validation loss = 3.9389  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 1.8649  Validation loss = 3.5433  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 2.1008  Validation loss = 3.8105  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 1.7765  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 1.5830  Validation loss = 2.4992  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 1.6589  Validation loss = 2.6150  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 2.0425  Validation loss = 2.5345  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 3.0407  Validation loss = 4.2180  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 23  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 1.6482  Validation loss = 4.1182  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.2607  Validation loss = 2.1424  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 1.7050  Validation loss = 3.3196  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.3369  Validation loss = 3.6310  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.4360  Validation loss = 4.3078  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.3135  Validation loss = 4.9951  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.0156  Validation loss = 4.5722  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.2033  Validation loss = 5.9971  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.1207  Validation loss = 5.4509  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.2354  Validation loss = 5.3230  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.6834  Validation loss = 4.2178  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.5306  Validation loss = 5.3022  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.6170  Validation loss = 3.6644  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 3.2814  Validation loss = 4.5194  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.3836  Validation loss = 4.1872  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 2.2457  Validation loss = 2.4392  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 2.3068  Validation loss = 3.9870  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 1.8462  Validation loss = 3.4940  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 1.8301  Validation loss = 3.5769  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 2.1766  Validation loss = 4.7635  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 2.3032  Validation loss = 4.1497  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 2.1073  Validation loss = 2.4707  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 1.8975  Validation loss = 3.5950  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 2.8255  Validation loss = 2.1409  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 1.9464  Validation loss = 3.9836  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 1.8639  Validation loss = 3.7560  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 2.5182  Validation loss = 3.5901  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 1.9703  Validation loss = 4.6639  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 1.8825  Validation loss = 3.7864  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 2.3089  Validation loss = 3.7979  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 2.5407  Validation loss = 3.3264  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 2.6918  Validation loss = 4.2380  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 1.8021  Validation loss = 2.5778  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 1.8063  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 1.6924  Validation loss = 2.2555  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 2.1319  Validation loss = 4.0422  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 2.1106  Validation loss = 2.8568  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 1.6723  Validation loss = 3.4964  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 1.8159  Validation loss = 3.7644  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 1.5618  Validation loss = 2.8092  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 2.5052  Validation loss = 2.9561  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 2.0453  Validation loss = 2.2462  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 2.1029  Validation loss = 3.9627  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 2.2429  Validation loss = 3.0908  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 2.0800  Validation loss = 2.8778  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 1.9969  Validation loss = 4.1502  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 24  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.5326  Validation loss = 4.4149  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.4155  Validation loss = 4.2807  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.2870  Validation loss = 5.1003  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.2317  Validation loss = 4.5593  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.5010  Validation loss = 4.7401  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.1343  Validation loss = 3.7250  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.6349  Validation loss = 4.8294  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.3047  Validation loss = 4.4432  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.6744  Validation loss = 5.0819  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.2722  Validation loss = 4.1132  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.0111  Validation loss = 5.2264  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 6  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.3118  Validation loss = 2.7021  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 1.9841  Validation loss = 2.4109  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.0910  Validation loss = 2.5496  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.1756  Validation loss = 1.5146  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.7726  Validation loss = 1.7348  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.1294  Validation loss = 2.1526  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 1.9750  Validation loss = 2.4368  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 1.8972  Validation loss = 2.7427  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.0188  Validation loss = 2.7692  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.1973  Validation loss = 2.4673  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 1.8010  Validation loss = 2.6600  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.1755  Validation loss = 2.6265  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.5154  Validation loss = 2.2875  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.3941  Validation loss = 2.4075  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.4161  Validation loss = 2.5346  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.5769  Validation loss = 3.2121  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 4  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 3.4109  Validation loss = 2.2880  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.1371  Validation loss = 1.7388  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.4763  Validation loss = 2.6540  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.8287  Validation loss = 1.0921  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.1170  Validation loss = 2.0761  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.5111  Validation loss = 3.0598  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.2173  Validation loss = 1.5049  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 3.6263  Validation loss = 3.0541  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.5427  Validation loss = 1.5573  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.3780  Validation loss = 1.5397  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.4937  Validation loss = 1.6096  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 3.1780  Validation loss = 1.5435  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 3.2359  Validation loss = 2.0730  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.4382  Validation loss = 2.3014  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.3993  Validation loss = 1.6958  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.5601  Validation loss = 1.7526  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.4996  Validation loss = 2.5093  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.4676  Validation loss = 3.3255  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 4  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.7690  Validation loss = 4.3019  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.6774  Validation loss = 6.3707  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.7581  Validation loss = 6.3808  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.5898  Validation loss = 4.9511  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.4589  Validation loss = 5.2053  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.2813  Validation loss = 4.5898  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.5335  Validation loss = 4.1194  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.3975  Validation loss = 4.0120  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 3.0745  Validation loss = 5.9009  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.4955  Validation loss = 5.2531  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.6713  Validation loss = 5.3639  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.2937  Validation loss = 4.5421  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 2.1304  Validation loss = 4.4645  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 2.2210  Validation loss = 3.9603  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 2.1540  Validation loss = 4.2884  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 2.0847  Validation loss = 4.6164  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 2.0650  Validation loss = 4.4613  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 2.1951  Validation loss = 4.2717  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 2.0930  Validation loss = 3.7115  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 2.3287  Validation loss = 3.8878  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 2.1956  Validation loss = 4.3805  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 1.9476  Validation loss = 3.0775  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 2.1379  Validation loss = 3.3590  \n",
      "\n",
      "Fold: 21  Epoch: 24  Training loss = 2.1746  Validation loss = 4.1854  \n",
      "\n",
      "Fold: 21  Epoch: 25  Training loss = 2.3880  Validation loss = 4.4422  \n",
      "\n",
      "Fold: 21  Epoch: 26  Training loss = 2.2154  Validation loss = 3.9707  \n",
      "\n",
      "Fold: 21  Epoch: 27  Training loss = 3.5428  Validation loss = 6.4486  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 22  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.8410  Validation loss = 5.3906  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.6119  Validation loss = 5.0799  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.5059  Validation loss = 3.2687  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 3.0245  Validation loss = 2.5887  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.6615  Validation loss = 4.5011  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.5218  Validation loss = 4.0372  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 3.6802  Validation loss = 3.8122  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.8408  Validation loss = 3.8444  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.5704  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.4958  Validation loss = 4.0567  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.4577  Validation loss = 3.9635  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.3480  Validation loss = 4.6013  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 4  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.5656  Validation loss = 4.4788  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 3.2171  Validation loss = 4.1443  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 3.0642  Validation loss = 5.9332  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.6620  Validation loss = 5.2903  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.6303  Validation loss = 3.5043  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.8088  Validation loss = 6.3582  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.8885  Validation loss = 6.3964  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 3.0702  Validation loss = 3.1812  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.5871  Validation loss = 4.1826  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.5868  Validation loss = 5.1475  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.4942  Validation loss = 3.7931  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.7849  Validation loss = 4.6681  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.6717  Validation loss = 4.0822  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 3.1506  Validation loss = 2.5359  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 2.9189  Validation loss = 4.1403  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 2.8067  Validation loss = 4.9837  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 2.5249  Validation loss = 4.7913  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 2.5251  Validation loss = 4.0278  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 3.6031  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 2.9651  Validation loss = 5.1641  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 19  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 3.7032  Validation loss = 2.8847  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 3.1381  Validation loss = 0.7547  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 3.5095  Validation loss = 1.9724  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.8710  Validation loss = 1.0724  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 3.1089  Validation loss = 3.0147  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 3.4563  Validation loss = 1.6191  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.8056  Validation loss = 1.0326  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 3.3190  Validation loss = 1.7584  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 3.0412  Validation loss = 1.5024  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 3.3299  Validation loss = 1.6672  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.8544  Validation loss = 0.6491  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 3.2872  Validation loss = 2.0264  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.8380  Validation loss = 1.2762  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 3.1940  Validation loss = 1.6578  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.7286  Validation loss = 1.3344  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 3.1264  Validation loss = 1.2261  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.9579  Validation loss = 1.2628  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 3.2115  Validation loss = 1.2410  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 3.0607  Validation loss = 2.5409  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 11  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 3.0764  Validation loss = 2.1408  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 3.1823  Validation loss = 1.8595  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.9992  Validation loss = 1.4928  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 3.2397  Validation loss = 2.5861  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.8157  Validation loss = 2.1005  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 3.1865  Validation loss = 2.0187  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 3.0787  Validation loss = 1.7905  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 3.3201  Validation loss = 1.7104  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.9077  Validation loss = 1.6858  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.9687  Validation loss = 1.4058  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 3.0779  Validation loss = 1.5646  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 3.1670  Validation loss = 3.2463  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 10  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.9341  Validation loss = 4.2710  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.0080  Validation loss = 4.3458  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.2329  Validation loss = 4.9156  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.9933  Validation loss = 2.1144  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.2490  Validation loss = 2.0036  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 4.3518  Validation loss = 1.8909  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 4.0080  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.1776  Validation loss = 1.6511  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.7806  Validation loss = 2.1811  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.9688  Validation loss = 4.2717  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.8242  Validation loss = 2.4814  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.8056  Validation loss = 3.3468  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 3.1354  Validation loss = 3.3316  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 3.1728  Validation loss = 1.5380  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 3.6386  Validation loss = 5.3924  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 7  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.3496  Validation loss = 3.2036  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.6270  Validation loss = 2.2369  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.9304  Validation loss = 3.7375  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.4949  Validation loss = 2.0148  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.5435  Validation loss = 2.0356  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.6067  Validation loss = 1.8543  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.8580  Validation loss = 2.3184  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.9602  Validation loss = 1.9997  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.8893  Validation loss = 2.5616  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.7904  Validation loss = 2.1448  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.0278  Validation loss = 2.0170  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.6909  Validation loss = 1.6485  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.7275  Validation loss = 1.8847  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.9783  Validation loss = 2.2176  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.5621  Validation loss = 1.7599  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 3.3729  Validation loss = 2.0677  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.5783  Validation loss = 1.8734  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.8541  Validation loss = 1.1697  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.5468  Validation loss = 1.3356  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.6016  Validation loss = 1.5181  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 2.5084  Validation loss = 1.6717  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 2.6484  Validation loss = 2.2495  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 18  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.5447  Validation loss = 3.4542  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.4632  Validation loss = 2.9119  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.0325  Validation loss = 1.5755  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.6503  Validation loss = 2.1594  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.0719  Validation loss = 1.2600  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.6444  Validation loss = 3.8441  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.1265  Validation loss = 4.6856  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.5464  Validation loss = 2.1613  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.5668  Validation loss = 2.0912  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.0236  Validation loss = 4.7445  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.4383  Validation loss = 2.9083  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.1020  Validation loss = 4.8557  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 5  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.7367  Validation loss = 1.8670  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.6043  Validation loss = 2.8973  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.9427  Validation loss = 1.6563  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.7954  Validation loss = 1.6739  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.5409  Validation loss = 1.9219  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.5236  Validation loss = 1.8463  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.8186  Validation loss = 2.4197  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.5276  Validation loss = 1.8390  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.5406  Validation loss = 1.5679  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 4.5339  Validation loss = 2.3677  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.4726  Validation loss = 1.3744  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.5376  Validation loss = 1.3536  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.1735  Validation loss = 2.3346  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.4981  Validation loss = 2.0745  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.3649  Validation loss = 1.8431  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.6819  Validation loss = 1.8336  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 2.4255  Validation loss = 2.3076  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 2.3581  Validation loss = 2.1449  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 3.5082  Validation loss = 1.5647  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.4351  Validation loss = 1.3354  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 2.6755  Validation loss = 1.5520  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 2.3655  Validation loss = 1.5316  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 2.5861  Validation loss = 2.7936  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 20  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.3441  Validation loss = 2.1588  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.5175  Validation loss = 2.0571  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.5208  Validation loss = 2.5947  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.5069  Validation loss = 2.1421  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.5509  Validation loss = 2.3176  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.3823  Validation loss = 2.4462  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.6656  Validation loss = 2.8315  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.4360  Validation loss = 2.5309  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.3721  Validation loss = 2.8258  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.4980  Validation loss = 3.2263  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.6224  Validation loss = 0.7939  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.3332  Validation loss = 3.0236  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 2.4894  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.5866  Validation loss = 3.4305  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 11  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.3153  Validation loss = 2.7656  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.4662  Validation loss = 4.2741  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.3756  Validation loss = 2.4991  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.3268  Validation loss = 3.7945  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.5807  Validation loss = 2.2829  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.3122  Validation loss = 3.4765  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.5852  Validation loss = 4.4391  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.3043  Validation loss = 2.5694  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.7174  Validation loss = 4.7462  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.5073  Validation loss = 2.0438  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.4163  Validation loss = 2.9374  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.3619  Validation loss = 2.4900  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 3.2289  Validation loss = 5.4803  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 10  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.9938  Validation loss = 2.0303  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.4334  Validation loss = 2.5984  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.3032  Validation loss = 5.2840  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.9083  Validation loss = 6.4466  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.1546  Validation loss = 4.6055  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.1356  Validation loss = 3.6849  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.1661  Validation loss = 4.6954  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.1161  Validation loss = 4.5136  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.8406  Validation loss = 6.9961  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.1377  Validation loss = 3.3965  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.3116  Validation loss = 2.5008  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.3601  Validation loss = 5.1618  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.4810  Validation loss = 4.7552  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.2879  Validation loss = 5.2400  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.2511  Validation loss = 2.5164  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.4744  Validation loss = 1.8749  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.1125  Validation loss = 3.0499  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.1126  Validation loss = 3.1108  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.0626  Validation loss = 4.1381  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.5112  Validation loss = 5.6727  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 16  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 10\n",
      "Average validation error: 3.91375\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.6346  Test loss = 3.2802  \n",
      "\n",
      "Epoch: 2  Training loss = 1.5602  Test loss = 3.0634  \n",
      "\n",
      "Epoch: 3  Training loss = 1.5467  Test loss = 3.0105  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5409  Test loss = 2.9910  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5368  Test loss = 2.9808  \n",
      "\n",
      "Epoch: 6  Training loss = 1.5333  Test loss = 2.9740  \n",
      "\n",
      "Epoch: 7  Training loss = 1.5299  Test loss = 2.9690  \n",
      "\n",
      "Epoch: 8  Training loss = 1.5265  Test loss = 2.9648  \n",
      "\n",
      "Epoch: 9  Training loss = 1.5232  Test loss = 2.9612  \n",
      "\n",
      "Epoch: 10  Training loss = 1.5202  Test loss = 2.9578  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x48066a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwm5mVjMu7GZmNfMvrRPvGn33UwsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc8a1fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.95777825838 \n",
      "Fixed scheme MAE:  2.18160661172\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.5202  Test loss = 2.0652  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.5368  Test loss = 1.5255  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.5453  Test loss = 1.0634  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.5370  Test loss = 1.2436  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.4257  Test loss = 1.3654  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.4351  Test loss = 0.3205  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.3753  Test loss = 0.3135  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.3540  Test loss = 0.0519  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.2927  Test loss = 0.9413  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.2980  Test loss = 0.1023  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.2708  Test loss = 0.6224  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.2721  Test loss = 0.7632  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.2534  Test loss = 2.9040  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.2923  Test loss = 0.5235  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.2939  Test loss = 2.8410  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.3410  Test loss = 4.1477  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.3769  Test loss = 0.8002  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.3777  Test loss = 0.1055  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.3774  Test loss = 1.0893  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.3230  Test loss = 0.6728  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.2364  Test loss = 0.6911  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.2389  Test loss = 3.7795  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.3111  Test loss = 0.5888  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.3041  Test loss = 4.0999  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.3316  Test loss = 0.1379  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.3277  Test loss = 0.4046  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.3248  Test loss = 0.3701  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.3219  Test loss = 1.4184  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.2241  Test loss = 0.8877  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.2241  Test loss = 0.1926  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.2194  Test loss = 3.2746  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.2173  Test loss = 0.8604  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.1879  Test loss = 1.6346  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.2049  Test loss = 0.0073  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.1287  Test loss = 0.7181  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.1266  Test loss = 5.1325  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.1936  Test loss = 0.5910  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.1103  Test loss = 2.0809  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.1398  Test loss = 1.8396  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.1592  Test loss = 2.4255  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.1242  Test loss = 2.1496  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.1529  Test loss = 2.2601  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.1862  Test loss = 3.2845  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.2531  Test loss = 12.0625  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9121  Test loss = 5.9328  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.0488  Test loss = 0.3218  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.0491  Test loss = 1.3016  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.0551  Test loss = 1.2883  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.9212  Test loss = 2.4257  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.9427  Test loss = 3.3953  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.9862  Test loss = 2.6479  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.0116  Test loss = 0.4215  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.9768  Test loss = 2.0728  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.9934  Test loss = 1.1987  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.9989  Test loss = 0.5371  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.9909  Test loss = 0.1437  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.9506  Test loss = 0.6388  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.9520  Test loss = 1.3818  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.9428  Test loss = 0.5435  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.9381  Test loss = 1.3500  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.9357  Test loss = 0.0726  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.9341  Test loss = 2.8820  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.9662  Test loss = 0.0674  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.9659  Test loss = 0.7595  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.9540  Test loss = 1.1187  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.9589  Test loss = 1.5072  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.9677  Test loss = 1.2153  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.9735  Test loss = 2.6741  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.9544  Test loss = 3.9494  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.0148  Test loss = 1.2838  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.0211  Test loss = 0.4307  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.0213  Test loss = 2.3268  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.0233  Test loss = 2.7204  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.0511  Test loss = 2.0347  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.0636  Test loss = 1.3346  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.0702  Test loss = 0.0003  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.0108  Test loss = 0.8104  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLOxJkiR9xj/udxe40jZmywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcba9400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.38260680327 \n",
      "Updating scheme MAE:  1.62523674131\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
