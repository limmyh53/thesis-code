{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/32_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-6\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 32 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 32 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.5489  Validation loss = 3.9867  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.5487  Validation loss = 3.9863  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.5484  Validation loss = 3.9859  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.5481  Validation loss = 3.9854  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.5478  Validation loss = 3.9850  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.5476  Validation loss = 3.9846  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.5473  Validation loss = 3.9841  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.5471  Validation loss = 3.9837  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.5469  Validation loss = 3.9833  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.5466  Validation loss = 3.9829  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.5464  Validation loss = 3.9825  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.5461  Validation loss = 3.9821  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.5459  Validation loss = 3.9816  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.5457  Validation loss = 3.9813  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.5455  Validation loss = 3.9810  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.5452  Validation loss = 3.9805  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.5450  Validation loss = 3.9801  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.5447  Validation loss = 3.9797  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.5445  Validation loss = 3.9794  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.5442  Validation loss = 3.9789  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.5440  Validation loss = 3.9786  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.5437  Validation loss = 3.9781  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.5435  Validation loss = 3.9777  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.5433  Validation loss = 3.9773  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.5430  Validation loss = 3.9769  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.5428  Validation loss = 3.9765  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.5426  Validation loss = 3.9761  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.5423  Validation loss = 3.9757  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.5421  Validation loss = 3.9753  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.5417  Validation loss = 3.9747  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.5415  Validation loss = 3.9743  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.5412  Validation loss = 3.9739  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.5410  Validation loss = 3.9735  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.5407  Validation loss = 3.9730  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.5405  Validation loss = 3.9726  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.5403  Validation loss = 3.9723  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.5400  Validation loss = 3.9719  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.5398  Validation loss = 3.9715  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.5396  Validation loss = 3.9712  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.5394  Validation loss = 3.9708  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.5390  Validation loss = 3.9703  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.5388  Validation loss = 3.9699  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.5385  Validation loss = 3.9693  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.5382  Validation loss = 3.9689  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.5380  Validation loss = 3.9685  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.5377  Validation loss = 3.9681  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.5375  Validation loss = 3.9676  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.5372  Validation loss = 3.9672  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.5370  Validation loss = 3.9668  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.5367  Validation loss = 3.9664  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.5365  Validation loss = 3.9660  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.5363  Validation loss = 3.9657  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.5361  Validation loss = 3.9653  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.5358  Validation loss = 3.9649  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.5356  Validation loss = 3.9645  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.5354  Validation loss = 3.9641  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.5352  Validation loss = 3.9638  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.5349  Validation loss = 3.9633  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.5347  Validation loss = 3.9629  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.5344  Validation loss = 3.9624  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.5341  Validation loss = 3.9620  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.5339  Validation loss = 3.9616  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.5336  Validation loss = 3.9611  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.5333  Validation loss = 3.9607  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.5331  Validation loss = 3.9603  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.5329  Validation loss = 3.9599  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.5326  Validation loss = 3.9595  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.5325  Validation loss = 3.9592  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.5322  Validation loss = 3.9588  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.5320  Validation loss = 3.9585  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.5318  Validation loss = 3.9581  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.5316  Validation loss = 3.9577  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.5313  Validation loss = 3.9573  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.5311  Validation loss = 3.9568  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.5308  Validation loss = 3.9564  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.5306  Validation loss = 3.9560  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.5304  Validation loss = 3.9557  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.5301  Validation loss = 3.9553  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.5298  Validation loss = 3.9548  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.5296  Validation loss = 3.9543  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.5294  Validation loss = 3.9540  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.5292  Validation loss = 3.9537  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.5289  Validation loss = 3.9533  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.5286  Validation loss = 3.9528  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.5284  Validation loss = 3.9523  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.5281  Validation loss = 3.9519  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.5279  Validation loss = 3.9516  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.5277  Validation loss = 3.9512  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.5274  Validation loss = 3.9508  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.5272  Validation loss = 3.9504  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.5269  Validation loss = 3.9499  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.5267  Validation loss = 3.9495  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.5264  Validation loss = 3.9490  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.5261  Validation loss = 3.9485  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.5259  Validation loss = 3.9482  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.5257  Validation loss = 3.9478  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.5254  Validation loss = 3.9474  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.5253  Validation loss = 3.9471  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.5250  Validation loss = 3.9466  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.5246  Validation loss = 3.9461  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.5244  Validation loss = 3.9456  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.5242  Validation loss = 3.9452  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.5239  Validation loss = 3.9448  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.5237  Validation loss = 3.9444  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.5234  Validation loss = 3.9439  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.5231  Validation loss = 3.9434  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.5228  Validation loss = 3.9430  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.5226  Validation loss = 3.9425  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.5223  Validation loss = 3.9421  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.5221  Validation loss = 3.9417  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.5218  Validation loss = 3.9412  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.5215  Validation loss = 3.9407  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.5213  Validation loss = 3.9403  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.5210  Validation loss = 3.9399  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.5208  Validation loss = 3.9395  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.5206  Validation loss = 3.9391  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.5203  Validation loss = 3.9387  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.5201  Validation loss = 3.9384  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.5199  Validation loss = 3.9380  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.5196  Validation loss = 3.9375  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.5194  Validation loss = 3.9371  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.5191  Validation loss = 3.9365  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.5188  Validation loss = 3.9361  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.5186  Validation loss = 3.9357  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.5183  Validation loss = 3.9352  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.5180  Validation loss = 3.9348  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.5178  Validation loss = 3.9344  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.5175  Validation loss = 3.9340  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.5173  Validation loss = 3.9336  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.5171  Validation loss = 3.9333  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.5168  Validation loss = 3.9328  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.5165  Validation loss = 3.9321  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.5162  Validation loss = 3.9317  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.5159  Validation loss = 3.9311  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.5156  Validation loss = 3.9307  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.5153  Validation loss = 3.9301  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.5150  Validation loss = 3.9297  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.5147  Validation loss = 3.9292  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.5145  Validation loss = 3.9288  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.5142  Validation loss = 3.9282  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.5139  Validation loss = 3.9278  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.5137  Validation loss = 3.9274  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.5135  Validation loss = 3.9271  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.5132  Validation loss = 3.9266  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.5130  Validation loss = 3.9263  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.5127  Validation loss = 3.9258  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.5125  Validation loss = 3.9254  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.5123  Validation loss = 3.9250  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.5120  Validation loss = 3.9246  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.5119  Validation loss = 3.9242  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.5116  Validation loss = 3.9239  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.5114  Validation loss = 3.9235  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.5111  Validation loss = 3.9230  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.5109  Validation loss = 3.9225  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.5106  Validation loss = 3.9221  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.5103  Validation loss = 3.9217  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.5101  Validation loss = 3.9212  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.5099  Validation loss = 3.9209  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.5097  Validation loss = 3.9205  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.5094  Validation loss = 3.9201  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.5092  Validation loss = 3.9197  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.5089  Validation loss = 3.9192  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.5086  Validation loss = 3.9188  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.5084  Validation loss = 3.9184  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.5082  Validation loss = 3.9180  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.5079  Validation loss = 3.9175  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.5077  Validation loss = 3.9171  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.5074  Validation loss = 3.9166  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.5071  Validation loss = 3.9162  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.5069  Validation loss = 3.9157  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.5067  Validation loss = 3.9154  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.5065  Validation loss = 3.9150  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.5062  Validation loss = 3.9146  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.5060  Validation loss = 3.9142  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.5056  Validation loss = 3.9136  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.5054  Validation loss = 3.9132  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.5051  Validation loss = 3.9127  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.5049  Validation loss = 3.9123  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.5047  Validation loss = 3.9120  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.5045  Validation loss = 3.9117  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.5043  Validation loss = 3.9113  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.5041  Validation loss = 3.9109  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.5038  Validation loss = 3.9104  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.5035  Validation loss = 3.9099  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.5032  Validation loss = 3.9095  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.5030  Validation loss = 3.9090  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.5027  Validation loss = 3.9085  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.5024  Validation loss = 3.9080  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.5022  Validation loss = 3.9076  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.5019  Validation loss = 3.9072  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.5017  Validation loss = 3.9068  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.5014  Validation loss = 3.9063  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.5012  Validation loss = 3.9059  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.5009  Validation loss = 3.9055  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.5007  Validation loss = 3.9051  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.5005  Validation loss = 3.9047  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.5002  Validation loss = 3.9042  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.4999  Validation loss = 3.9038  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.4997  Validation loss = 3.9035  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.4995  Validation loss = 3.9030  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.4993  Validation loss = 3.9026  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.4990  Validation loss = 3.9022  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.4988  Validation loss = 3.9018  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.4986  Validation loss = 3.9015  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.4984  Validation loss = 3.9011  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.4981  Validation loss = 3.9006  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.4979  Validation loss = 3.9002  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.4977  Validation loss = 3.8999  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.4974  Validation loss = 3.8993  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.4971  Validation loss = 3.8990  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.4969  Validation loss = 3.8985  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.4966  Validation loss = 3.8981  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.4963  Validation loss = 3.8976  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.4960  Validation loss = 3.8970  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.4958  Validation loss = 3.8966  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.4955  Validation loss = 3.8961  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.4953  Validation loss = 3.8957  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.4950  Validation loss = 3.8953  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.4948  Validation loss = 3.8949  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.4945  Validation loss = 3.8943  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.4942  Validation loss = 3.8938  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.4939  Validation loss = 3.8933  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.4937  Validation loss = 3.8930  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.4935  Validation loss = 3.8926  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.4932  Validation loss = 3.8922  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.4930  Validation loss = 3.8919  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.4927  Validation loss = 3.8913  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.4925  Validation loss = 3.8909  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.4922  Validation loss = 3.8905  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.4919  Validation loss = 3.8899  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.4917  Validation loss = 3.8896  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.4915  Validation loss = 3.8891  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.4913  Validation loss = 3.8888  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.4910  Validation loss = 3.8884  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.4907  Validation loss = 3.8878  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.4905  Validation loss = 3.8874  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.4902  Validation loss = 3.8869  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.4900  Validation loss = 3.8866  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.4898  Validation loss = 3.8862  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.4895  Validation loss = 3.8857  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.4892  Validation loss = 3.8852  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.4890  Validation loss = 3.8849  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.4888  Validation loss = 3.8846  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.4886  Validation loss = 3.8841  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.4884  Validation loss = 3.8838  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.4881  Validation loss = 3.8834  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.4879  Validation loss = 3.8829  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.4876  Validation loss = 3.8824  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.4874  Validation loss = 3.8820  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.4870  Validation loss = 3.8814  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.4868  Validation loss = 3.8811  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.4866  Validation loss = 3.8806  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.4864  Validation loss = 3.8803  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.4861  Validation loss = 3.8798  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.4858  Validation loss = 3.8793  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.4856  Validation loss = 3.8790  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.4854  Validation loss = 3.8786  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.4851  Validation loss = 3.8780  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.4849  Validation loss = 3.8777  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.4846  Validation loss = 3.8771  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.4843  Validation loss = 3.8767  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.4841  Validation loss = 3.8763  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.4839  Validation loss = 3.8760  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.4837  Validation loss = 3.8755  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.4834  Validation loss = 3.8751  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.4832  Validation loss = 3.8747  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.4829  Validation loss = 3.8743  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.4827  Validation loss = 3.8739  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.4825  Validation loss = 3.8736  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.4823  Validation loss = 3.8732  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.4821  Validation loss = 3.8728  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.4819  Validation loss = 3.8724  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.4816  Validation loss = 3.8720  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.4814  Validation loss = 3.8716  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.4811  Validation loss = 3.8711  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.4809  Validation loss = 3.8708  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.4807  Validation loss = 3.8704  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.4805  Validation loss = 3.8700  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.4802  Validation loss = 3.8696  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.4799  Validation loss = 3.8689  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.4796  Validation loss = 3.8684  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.4793  Validation loss = 3.8680  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.4791  Validation loss = 3.8676  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.4788  Validation loss = 3.8671  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.4786  Validation loss = 3.8667  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.4784  Validation loss = 3.8663  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.4782  Validation loss = 3.8660  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.4779  Validation loss = 3.8655  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.4777  Validation loss = 3.8651  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.4774  Validation loss = 3.8646  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.4772  Validation loss = 3.8642  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.4769  Validation loss = 3.8638  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.4767  Validation loss = 3.8634  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.4765  Validation loss = 3.8631  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.4762  Validation loss = 3.8626  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.4760  Validation loss = 3.8621  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.4757  Validation loss = 3.8617  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.4755  Validation loss = 3.8612  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.4752  Validation loss = 3.8608  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.4750  Validation loss = 3.8604  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.4748  Validation loss = 3.8600  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.4746  Validation loss = 3.8597  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.4743  Validation loss = 3.8592  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.4741  Validation loss = 3.8589  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.4738  Validation loss = 3.8583  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.4736  Validation loss = 3.8580  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.4734  Validation loss = 3.8576  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.4731  Validation loss = 3.8571  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.4729  Validation loss = 3.8568  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.4727  Validation loss = 3.8564  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.4725  Validation loss = 3.8561  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.4723  Validation loss = 3.8557  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.4720  Validation loss = 3.8551  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.4717  Validation loss = 3.8545  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.4715  Validation loss = 3.8542  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.4711  Validation loss = 3.8536  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.4709  Validation loss = 3.8532  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.4706  Validation loss = 3.8527  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.4704  Validation loss = 3.8522  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.4701  Validation loss = 3.8517  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.4699  Validation loss = 3.8514  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.4697  Validation loss = 3.8510  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.4694  Validation loss = 3.8505  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.4692  Validation loss = 3.8502  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.4690  Validation loss = 3.8498  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.4688  Validation loss = 3.8494  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.4685  Validation loss = 3.8490  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.4683  Validation loss = 3.8485  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.4680  Validation loss = 3.8481  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.4678  Validation loss = 3.8477  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.4676  Validation loss = 3.8473  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.4673  Validation loss = 3.8468  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.4671  Validation loss = 3.8464  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.4669  Validation loss = 3.8461  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.4666  Validation loss = 3.8457  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.4664  Validation loss = 3.8452  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.4661  Validation loss = 3.8448  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.4658  Validation loss = 3.8442  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.4656  Validation loss = 3.8438  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.4654  Validation loss = 3.8434  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.4652  Validation loss = 3.8431  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.4649  Validation loss = 3.8426  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.4646  Validation loss = 3.8421  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.4644  Validation loss = 3.8417  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.4641  Validation loss = 3.8412  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.4639  Validation loss = 3.8408  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.4636  Validation loss = 3.8403  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.4634  Validation loss = 3.8399  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.4632  Validation loss = 3.8396  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.4629  Validation loss = 3.8391  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.4627  Validation loss = 3.8386  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.4624  Validation loss = 3.8382  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.4622  Validation loss = 3.8378  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.4620  Validation loss = 3.8375  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.4618  Validation loss = 3.8370  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.4615  Validation loss = 3.8366  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.4613  Validation loss = 3.8362  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.4611  Validation loss = 3.8357  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.4609  Validation loss = 3.8355  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.4607  Validation loss = 3.8351  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.4604  Validation loss = 3.8346  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.4602  Validation loss = 3.8342  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.4599  Validation loss = 3.8337  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.4597  Validation loss = 3.8333  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.4594  Validation loss = 3.8329  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.4592  Validation loss = 3.8324  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.4589  Validation loss = 3.8319  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.4586  Validation loss = 3.8314  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.4584  Validation loss = 3.8310  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.4582  Validation loss = 3.8306  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.4579  Validation loss = 3.8302  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.4577  Validation loss = 3.8297  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.4575  Validation loss = 3.8294  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.4572  Validation loss = 3.8289  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.4570  Validation loss = 3.8285  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.4568  Validation loss = 3.8281  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.4565  Validation loss = 3.8276  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.4562  Validation loss = 3.8271  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.4559  Validation loss = 3.8266  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.4557  Validation loss = 3.8263  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.4555  Validation loss = 3.8258  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.4552  Validation loss = 3.8253  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.4550  Validation loss = 3.8249  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.4548  Validation loss = 3.8245  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.4545  Validation loss = 3.8241  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.4543  Validation loss = 3.8237  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.4541  Validation loss = 3.8233  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.4539  Validation loss = 3.8230  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.4537  Validation loss = 3.8226  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.4534  Validation loss = 3.8222  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.4532  Validation loss = 3.8218  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.4530  Validation loss = 3.8214  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.4528  Validation loss = 3.8210  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.4525  Validation loss = 3.8205  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.4522  Validation loss = 3.8200  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.4520  Validation loss = 3.8197  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.4518  Validation loss = 3.8192  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.4516  Validation loss = 3.8189  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.4513  Validation loss = 3.8184  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.4512  Validation loss = 3.8182  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.4510  Validation loss = 3.8178  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.4507  Validation loss = 3.8173  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.4505  Validation loss = 3.8169  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.4503  Validation loss = 3.8166  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.4501  Validation loss = 3.8162  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.4498  Validation loss = 3.8157  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.4496  Validation loss = 3.8153  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.4494  Validation loss = 3.8150  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.4491  Validation loss = 3.8145  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.4489  Validation loss = 3.8141  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.4487  Validation loss = 3.8138  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.4484  Validation loss = 3.8132  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.4482  Validation loss = 3.8128  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.4480  Validation loss = 3.8124  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.4477  Validation loss = 3.8119  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.4474  Validation loss = 3.8114  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.4472  Validation loss = 3.8110  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.4469  Validation loss = 3.8105  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.4467  Validation loss = 3.8100  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.4464  Validation loss = 3.8096  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.4462  Validation loss = 3.8093  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.4459  Validation loss = 3.8086  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.4457  Validation loss = 3.8083  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.4455  Validation loss = 3.8080  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.4453  Validation loss = 3.8076  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.4451  Validation loss = 3.8072  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.4449  Validation loss = 3.8068  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.4446  Validation loss = 3.8064  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.4443  Validation loss = 3.8059  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.4441  Validation loss = 3.8054  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.4439  Validation loss = 3.8050  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.4436  Validation loss = 3.8046  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.4434  Validation loss = 3.8041  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.4432  Validation loss = 3.8038  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.4429  Validation loss = 3.8033  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.4427  Validation loss = 3.8029  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.4425  Validation loss = 3.8025  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.4423  Validation loss = 3.8021  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.4420  Validation loss = 3.8016  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.4417  Validation loss = 3.8011  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.4414  Validation loss = 3.8006  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.4411  Validation loss = 3.8001  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.4409  Validation loss = 3.7996  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.4407  Validation loss = 3.7993  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.4405  Validation loss = 3.7989  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.4402  Validation loss = 3.7984  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.4400  Validation loss = 3.7980  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.4397  Validation loss = 3.7975  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.4395  Validation loss = 3.7971  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.4393  Validation loss = 3.7968  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.4391  Validation loss = 3.7965  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.4390  Validation loss = 3.7961  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.4387  Validation loss = 3.7956  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.4384  Validation loss = 3.7951  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.4382  Validation loss = 3.7947  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.4379  Validation loss = 3.7943  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.4377  Validation loss = 3.7939  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.4375  Validation loss = 3.7936  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.4373  Validation loss = 3.7932  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.4371  Validation loss = 3.7928  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.4369  Validation loss = 3.7924  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.4367  Validation loss = 3.7920  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.4364  Validation loss = 3.7915  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.4362  Validation loss = 3.7911  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.4359  Validation loss = 3.7905  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.4356  Validation loss = 3.7900  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.4353  Validation loss = 3.7896  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.4351  Validation loss = 3.7892  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.4349  Validation loss = 3.7888  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.4346  Validation loss = 3.7882  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.4343  Validation loss = 3.7877  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.4341  Validation loss = 3.7874  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.4339  Validation loss = 3.7870  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.4336  Validation loss = 3.7865  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.4334  Validation loss = 3.7860  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.4331  Validation loss = 3.7855  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.4329  Validation loss = 3.7851  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.4327  Validation loss = 3.7848  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.4325  Validation loss = 3.7844  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.4322  Validation loss = 3.7839  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.4320  Validation loss = 3.7835  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.4317  Validation loss = 3.7830  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.4314  Validation loss = 3.7825  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.4312  Validation loss = 3.7821  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.4310  Validation loss = 3.7817  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.4307  Validation loss = 3.7812  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.4304  Validation loss = 3.7807  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.4302  Validation loss = 3.7803  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.4300  Validation loss = 3.7798  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.4297  Validation loss = 3.7794  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.4296  Validation loss = 3.7791  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.4293  Validation loss = 3.7787  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.4291  Validation loss = 3.7783  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.4289  Validation loss = 3.7779  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.4287  Validation loss = 3.7775  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.4283  Validation loss = 3.7769  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.4281  Validation loss = 3.7765  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.4279  Validation loss = 3.7761  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.4276  Validation loss = 3.7756  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.4274  Validation loss = 3.7753  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 3.3919  Validation loss = 3.6764  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 3.3917  Validation loss = 3.6761  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 3.3915  Validation loss = 3.6758  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 3.3912  Validation loss = 3.6754  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 3.3909  Validation loss = 3.6751  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 3.3907  Validation loss = 3.6748  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 3.3904  Validation loss = 3.6745  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 3.3901  Validation loss = 3.6742  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 3.3899  Validation loss = 3.6739  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 3.3896  Validation loss = 3.6736  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 3.3894  Validation loss = 3.6733  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 3.3890  Validation loss = 3.6729  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 3.3888  Validation loss = 3.6725  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 3.3885  Validation loss = 3.6722  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 3.3883  Validation loss = 3.6719  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 3.3880  Validation loss = 3.6716  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 3.3877  Validation loss = 3.6712  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 3.3874  Validation loss = 3.6709  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 3.3871  Validation loss = 3.6705  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 3.3868  Validation loss = 3.6702  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 3.3866  Validation loss = 3.6699  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 3.3863  Validation loss = 3.6696  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 3.3861  Validation loss = 3.6693  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 3.3858  Validation loss = 3.6690  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 3.3855  Validation loss = 3.6687  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 3.3853  Validation loss = 3.6683  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 3.3850  Validation loss = 3.6680  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 3.3847  Validation loss = 3.6677  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 3.3845  Validation loss = 3.6674  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 3.3842  Validation loss = 3.6671  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 3.3839  Validation loss = 3.6667  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 3.3836  Validation loss = 3.6663  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 3.3833  Validation loss = 3.6660  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 3.3831  Validation loss = 3.6657  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 3.3828  Validation loss = 3.6654  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 3.3826  Validation loss = 3.6651  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 3.3823  Validation loss = 3.6648  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 3.3820  Validation loss = 3.6644  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 3.3818  Validation loss = 3.6641  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 3.3815  Validation loss = 3.6638  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 3.3812  Validation loss = 3.6635  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 3.3809  Validation loss = 3.6631  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 3.3806  Validation loss = 3.6627  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 3.3804  Validation loss = 3.6624  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 3.3801  Validation loss = 3.6621  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 3.3798  Validation loss = 3.6617  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 3.3795  Validation loss = 3.6614  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 3.3791  Validation loss = 3.6609  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 3.3788  Validation loss = 3.6606  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 3.3786  Validation loss = 3.6603  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 3.3782  Validation loss = 3.6599  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 3.3780  Validation loss = 3.6596  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 3.3777  Validation loss = 3.6592  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 3.3774  Validation loss = 3.6589  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 3.3771  Validation loss = 3.6585  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 3.3769  Validation loss = 3.6583  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 3.3766  Validation loss = 3.6579  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 3.3763  Validation loss = 3.6576  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 3.3761  Validation loss = 3.6573  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 3.3759  Validation loss = 3.6571  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 3.3756  Validation loss = 3.6567  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 3.3752  Validation loss = 3.6563  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 3.3749  Validation loss = 3.6559  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 3.3746  Validation loss = 3.6555  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 3.3744  Validation loss = 3.6552  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 3.3741  Validation loss = 3.6548  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 3.3738  Validation loss = 3.6545  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 3.3736  Validation loss = 3.6543  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 3.3732  Validation loss = 3.6539  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 3.3729  Validation loss = 3.6535  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 3.3727  Validation loss = 3.6532  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 3.3724  Validation loss = 3.6528  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 3.3722  Validation loss = 3.6525  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 3.3719  Validation loss = 3.6522  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 3.3716  Validation loss = 3.6518  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 3.3713  Validation loss = 3.6515  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 3.3711  Validation loss = 3.6512  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 3.3707  Validation loss = 3.6507  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 3.3704  Validation loss = 3.6504  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 3.3702  Validation loss = 3.6501  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 3.3698  Validation loss = 3.6497  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 3.3695  Validation loss = 3.6493  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 3.3693  Validation loss = 3.6490  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 3.3689  Validation loss = 3.6486  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 3.3688  Validation loss = 3.6484  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 3.3685  Validation loss = 3.6481  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 3.3682  Validation loss = 3.6477  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 3.3679  Validation loss = 3.6474  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 3.3677  Validation loss = 3.6471  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 3.3675  Validation loss = 3.6468  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 3.3672  Validation loss = 3.6465  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 3.3670  Validation loss = 3.6462  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 3.3667  Validation loss = 3.6459  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 3.3665  Validation loss = 3.6457  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 3.3662  Validation loss = 3.6453  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 3.3660  Validation loss = 3.6451  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 3.3658  Validation loss = 3.6448  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 3.3655  Validation loss = 3.6444  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 3.3652  Validation loss = 3.6441  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 3.3649  Validation loss = 3.6437  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 3.3646  Validation loss = 3.6434  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 3.3644  Validation loss = 3.6431  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 3.3641  Validation loss = 3.6428  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 3.3639  Validation loss = 3.6425  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 3.3636  Validation loss = 3.6422  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 3.3634  Validation loss = 3.6419  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 3.3631  Validation loss = 3.6415  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 3.3628  Validation loss = 3.6412  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 3.3626  Validation loss = 3.6409  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 3.3623  Validation loss = 3.6406  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 3.3621  Validation loss = 3.6403  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 3.3617  Validation loss = 3.6399  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 3.3614  Validation loss = 3.6394  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 3.3610  Validation loss = 3.6390  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 3.3608  Validation loss = 3.6387  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 3.3605  Validation loss = 3.6384  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 3.3602  Validation loss = 3.6380  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 3.3599  Validation loss = 3.6377  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 3.3597  Validation loss = 3.6374  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 3.3594  Validation loss = 3.6371  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 3.3592  Validation loss = 3.6368  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 3.3589  Validation loss = 3.6365  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 3.3586  Validation loss = 3.6361  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 3.3584  Validation loss = 3.6358  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 3.3580  Validation loss = 3.6354  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 3.3578  Validation loss = 3.6351  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 3.3576  Validation loss = 3.6349  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 3.3574  Validation loss = 3.6346  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 3.3571  Validation loss = 3.6342  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 3.3568  Validation loss = 3.6339  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 3.3565  Validation loss = 3.6335  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 3.3563  Validation loss = 3.6333  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 3.3560  Validation loss = 3.6330  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 3.3557  Validation loss = 3.6325  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 3.3555  Validation loss = 3.6323  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 3.3552  Validation loss = 3.6319  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 3.3549  Validation loss = 3.6316  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 3.3546  Validation loss = 3.6312  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 3.3544  Validation loss = 3.6309  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 3.3541  Validation loss = 3.6305  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 3.3538  Validation loss = 3.6302  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 3.3535  Validation loss = 3.6298  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 3.3532  Validation loss = 3.6295  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 3.3529  Validation loss = 3.6291  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 3.3527  Validation loss = 3.6288  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 3.3524  Validation loss = 3.6285  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 3.3521  Validation loss = 3.6282  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 3.3519  Validation loss = 3.6278  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 3.3516  Validation loss = 3.6276  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 3.3513  Validation loss = 3.6272  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 3.3511  Validation loss = 3.6269  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 3.3509  Validation loss = 3.6266  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 3.3506  Validation loss = 3.6262  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 3.3503  Validation loss = 3.6259  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 3.3501  Validation loss = 3.6257  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 3.3499  Validation loss = 3.6254  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 3.3496  Validation loss = 3.6251  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 3.3494  Validation loss = 3.6248  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 3.3491  Validation loss = 3.6245  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 3.3488  Validation loss = 3.6241  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 3.3485  Validation loss = 3.6237  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 3.3483  Validation loss = 3.6235  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 3.3480  Validation loss = 3.6231  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 3.3478  Validation loss = 3.6228  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 3.3475  Validation loss = 3.6225  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 3.3473  Validation loss = 3.6222  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 3.3469  Validation loss = 3.6218  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 3.3467  Validation loss = 3.6215  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 3.3465  Validation loss = 3.6212  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 3.3462  Validation loss = 3.6209  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 3.3459  Validation loss = 3.6205  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 3.3456  Validation loss = 3.6202  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 3.3454  Validation loss = 3.6199  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 3.3452  Validation loss = 3.6197  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 3.3449  Validation loss = 3.6193  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 3.3447  Validation loss = 3.6190  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 3.3443  Validation loss = 3.6185  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 3.3441  Validation loss = 3.6182  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 3.3438  Validation loss = 3.6178  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 3.3435  Validation loss = 3.6176  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 3.3433  Validation loss = 3.6172  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 3.3430  Validation loss = 3.6169  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 3.3428  Validation loss = 3.6167  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 3.3425  Validation loss = 3.6163  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 3.3422  Validation loss = 3.6160  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 3.3420  Validation loss = 3.6156  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 3.3417  Validation loss = 3.6153  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 3.3413  Validation loss = 3.6149  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 3.3411  Validation loss = 3.6146  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 3.3409  Validation loss = 3.6144  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 3.3406  Validation loss = 3.6140  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 3.3404  Validation loss = 3.6137  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 3.3402  Validation loss = 3.6134  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 3.3400  Validation loss = 3.6132  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 3.3397  Validation loss = 3.6128  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 3.3394  Validation loss = 3.6125  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 3.3391  Validation loss = 3.6122  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 3.3389  Validation loss = 3.6118  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 3.3386  Validation loss = 3.6115  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 3.3383  Validation loss = 3.6111  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 3.3381  Validation loss = 3.6108  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 3.3378  Validation loss = 3.6105  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 3.3375  Validation loss = 3.6101  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 3.3372  Validation loss = 3.6097  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 3.3369  Validation loss = 3.6093  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 3.3366  Validation loss = 3.6090  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 3.3364  Validation loss = 3.6087  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 3.3361  Validation loss = 3.6085  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 3.3359  Validation loss = 3.6081  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 3.3356  Validation loss = 3.6078  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 3.3354  Validation loss = 3.6075  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 3.3350  Validation loss = 3.6071  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 3.3348  Validation loss = 3.6068  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 3.3346  Validation loss = 3.6065  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 3.3344  Validation loss = 3.6063  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 3.3341  Validation loss = 3.6059  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 3.3338  Validation loss = 3.6055  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 3.3335  Validation loss = 3.6052  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 3.3332  Validation loss = 3.6049  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 3.3330  Validation loss = 3.6046  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 3.3327  Validation loss = 3.6042  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 3.3325  Validation loss = 3.6040  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 3.3323  Validation loss = 3.6036  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 3.3319  Validation loss = 3.6032  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 3.3317  Validation loss = 3.6029  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 3.3314  Validation loss = 3.6026  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 3.3312  Validation loss = 3.6023  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 3.3309  Validation loss = 3.6020  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 3.3306  Validation loss = 3.6017  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 3.3304  Validation loss = 3.6013  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 3.3300  Validation loss = 3.6009  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 3.3298  Validation loss = 3.6006  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 3.3295  Validation loss = 3.6003  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 3.3293  Validation loss = 3.6000  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 3.3290  Validation loss = 3.5996  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 3.3287  Validation loss = 3.5992  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 3.3285  Validation loss = 3.5989  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 3.3282  Validation loss = 3.5986  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 3.3279  Validation loss = 3.5983  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 3.3277  Validation loss = 3.5980  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 3.3275  Validation loss = 3.5978  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 3.3272  Validation loss = 3.5973  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 3.3269  Validation loss = 3.5970  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 3.3267  Validation loss = 3.5967  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 3.3264  Validation loss = 3.5963  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 3.3261  Validation loss = 3.5960  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 3.3259  Validation loss = 3.5957  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 3.3256  Validation loss = 3.5954  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 3.3253  Validation loss = 3.5950  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 3.3250  Validation loss = 3.5946  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 3.3248  Validation loss = 3.5943  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 3.3244  Validation loss = 3.5939  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 3.3242  Validation loss = 3.5936  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 3.3239  Validation loss = 3.5933  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 3.3237  Validation loss = 3.5930  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 3.3234  Validation loss = 3.5926  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 3.3231  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 3.3229  Validation loss = 3.5920  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 3.3227  Validation loss = 3.5917  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 3.3224  Validation loss = 3.5914  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 3.3221  Validation loss = 3.5910  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 3.3219  Validation loss = 3.5907  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 3.3217  Validation loss = 3.5905  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 3.3214  Validation loss = 3.5902  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 3.3212  Validation loss = 3.5899  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 3.3210  Validation loss = 3.5896  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 3.3208  Validation loss = 3.5894  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 3.3204  Validation loss = 3.5890  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 3.3202  Validation loss = 3.5887  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 3.3200  Validation loss = 3.5884  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 3.3197  Validation loss = 3.5880  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 3.3193  Validation loss = 3.5876  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 3.3191  Validation loss = 3.5873  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 3.3188  Validation loss = 3.5869  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 3.3186  Validation loss = 3.5866  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 3.3183  Validation loss = 3.5863  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 3.3180  Validation loss = 3.5860  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 3.3177  Validation loss = 3.5856  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 3.3175  Validation loss = 3.5853  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 3.3172  Validation loss = 3.5849  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 3.3169  Validation loss = 3.5845  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 3.3166  Validation loss = 3.5842  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 3.3164  Validation loss = 3.5839  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 3.3162  Validation loss = 3.5837  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 3.3160  Validation loss = 3.5834  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 3.3157  Validation loss = 3.5831  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 3.3155  Validation loss = 3.5828  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 3.3152  Validation loss = 3.5825  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 3.3150  Validation loss = 3.5822  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 3.3148  Validation loss = 3.5819  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 3.3146  Validation loss = 3.5816  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 3.3143  Validation loss = 3.5813  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 3.3141  Validation loss = 3.5810  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 3.3138  Validation loss = 3.5807  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 3.3135  Validation loss = 3.5803  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 3.3132  Validation loss = 3.5800  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 3.3129  Validation loss = 3.5796  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 3.3126  Validation loss = 3.5792  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 3.3123  Validation loss = 3.5788  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 3.3119  Validation loss = 3.5784  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 3.3117  Validation loss = 3.5780  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 3.3114  Validation loss = 3.5777  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 3.3112  Validation loss = 3.5774  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 3.3109  Validation loss = 3.5771  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 3.3106  Validation loss = 3.5767  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 3.3104  Validation loss = 3.5765  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 3.3103  Validation loss = 3.5763  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 3.3099  Validation loss = 3.5759  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 3.3097  Validation loss = 3.5756  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 3.3095  Validation loss = 3.5753  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 3.3093  Validation loss = 3.5751  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 3.3091  Validation loss = 3.5748  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 3.3088  Validation loss = 3.5744  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 3.3084  Validation loss = 3.5740  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 3.3082  Validation loss = 3.5736  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 3.3079  Validation loss = 3.5733  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 3.3076  Validation loss = 3.5729  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 3.3074  Validation loss = 3.5726  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 3.3071  Validation loss = 3.5722  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 3.3068  Validation loss = 3.5719  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 3.3066  Validation loss = 3.5716  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 3.3063  Validation loss = 3.5713  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 3.3061  Validation loss = 3.5709  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 3.3058  Validation loss = 3.5706  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 3.3055  Validation loss = 3.5703  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 3.3054  Validation loss = 3.5701  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 3.3050  Validation loss = 3.5695  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 3.3047  Validation loss = 3.5693  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 3.3045  Validation loss = 3.5689  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 3.3042  Validation loss = 3.5686  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 3.3039  Validation loss = 3.5682  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 3.3037  Validation loss = 3.5679  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 3.3034  Validation loss = 3.5676  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 3.3033  Validation loss = 3.5674  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 3.3030  Validation loss = 3.5670  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 3.3027  Validation loss = 3.5667  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 3.3024  Validation loss = 3.5664  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 3.3022  Validation loss = 3.5661  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 3.3020  Validation loss = 3.5658  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 3.3018  Validation loss = 3.5655  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 3.3015  Validation loss = 3.5653  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 3.3013  Validation loss = 3.5649  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 3.3010  Validation loss = 3.5646  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 3.3008  Validation loss = 3.5643  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 3.3003  Validation loss = 3.5637  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 3.3001  Validation loss = 3.5635  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 3.2999  Validation loss = 3.5631  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 3.2996  Validation loss = 3.5628  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 3.2994  Validation loss = 3.5626  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 3.2992  Validation loss = 3.5623  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 3.2989  Validation loss = 3.5619  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 3.2986  Validation loss = 3.5616  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 3.2984  Validation loss = 3.5613  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 3.2982  Validation loss = 3.5610  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 3.2980  Validation loss = 3.5607  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 3.2978  Validation loss = 3.5605  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 3.2975  Validation loss = 3.5601  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 3.2972  Validation loss = 3.5598  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 3.2970  Validation loss = 3.5595  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 3.2967  Validation loss = 3.5591  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 3.2964  Validation loss = 3.5588  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 3.2962  Validation loss = 3.5585  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 3.2959  Validation loss = 3.5581  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 3.2957  Validation loss = 3.5578  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 3.2954  Validation loss = 3.5575  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 3.2952  Validation loss = 3.5572  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 3.2950  Validation loss = 3.5570  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 3.2947  Validation loss = 3.5566  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 3.2945  Validation loss = 3.5563  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 3.2941  Validation loss = 3.5558  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 3.2938  Validation loss = 3.5555  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 3.2936  Validation loss = 3.5552  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 3.2933  Validation loss = 3.5548  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 3.2930  Validation loss = 3.5545  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 3.2926  Validation loss = 3.5540  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 3.2924  Validation loss = 3.5536  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 3.2921  Validation loss = 3.5533  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 3.2918  Validation loss = 3.5529  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 3.2915  Validation loss = 3.5526  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 3.2913  Validation loss = 3.5523  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 3.2910  Validation loss = 3.5520  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 3.2908  Validation loss = 3.5517  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 3.2905  Validation loss = 3.5513  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 3.2903  Validation loss = 3.5510  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 3.2900  Validation loss = 3.5507  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 3.2898  Validation loss = 3.5504  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 3.2895  Validation loss = 3.5501  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 3.2893  Validation loss = 3.5497  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 3.2890  Validation loss = 3.5494  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 3.2888  Validation loss = 3.5491  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 3.2886  Validation loss = 3.5489  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 3.2883  Validation loss = 3.5486  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 3.2881  Validation loss = 3.5482  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 3.2878  Validation loss = 3.5479  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 3.2876  Validation loss = 3.5476  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 3.2873  Validation loss = 3.5473  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 3.2871  Validation loss = 3.5470  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 3.2868  Validation loss = 3.5466  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 3.2865  Validation loss = 3.5462  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 3.2863  Validation loss = 3.5459  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 3.2861  Validation loss = 3.5456  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 3.2858  Validation loss = 3.5453  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 3.2855  Validation loss = 3.5450  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 3.2852  Validation loss = 3.5446  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 3.2850  Validation loss = 3.5443  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 3.2847  Validation loss = 3.5439  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 3.2845  Validation loss = 3.5436  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 3.2843  Validation loss = 3.5434  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 3.2840  Validation loss = 3.5430  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 3.2838  Validation loss = 3.5427  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 3.2835  Validation loss = 3.5424  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 3.2833  Validation loss = 3.5421  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 3.2830  Validation loss = 3.5417  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 3.2827  Validation loss = 3.5414  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 3.2824  Validation loss = 3.5410  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 3.2822  Validation loss = 3.5407  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 3.2819  Validation loss = 3.5403  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 3.2817  Validation loss = 3.5401  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 3.2815  Validation loss = 3.5398  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 3.2813  Validation loss = 3.5395  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 3.2810  Validation loss = 3.5392  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 3.2807  Validation loss = 3.5388  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 3.2805  Validation loss = 3.5385  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 3.2802  Validation loss = 3.5381  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 3.2799  Validation loss = 3.5377  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 3.2796  Validation loss = 3.5375  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 3.2794  Validation loss = 3.5372  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 3.2791  Validation loss = 3.5368  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 3.2788  Validation loss = 3.5364  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 3.2786  Validation loss = 3.5361  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 3.2783  Validation loss = 3.5358  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 3.2781  Validation loss = 3.5355  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 3.2778  Validation loss = 3.5352  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 3.2774  Validation loss = 3.5347  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 3.2772  Validation loss = 3.5343  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 3.2769  Validation loss = 3.5340  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 3.2767  Validation loss = 3.5337  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 3.2765  Validation loss = 3.5334  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 3.2762  Validation loss = 3.5330  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 3.2759  Validation loss = 3.5327  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 3.2757  Validation loss = 3.5325  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 3.2755  Validation loss = 3.5322  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 3.2752  Validation loss = 3.5319  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 3.2751  Validation loss = 3.5316  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 3.2748  Validation loss = 3.5313  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 3.2744  Validation loss = 3.5308  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 3.2742  Validation loss = 3.5305  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 3.2739  Validation loss = 3.5302  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 3.2737  Validation loss = 3.5299  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 3.2735  Validation loss = 3.5296  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 3.2733  Validation loss = 3.5293  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 3.2730  Validation loss = 3.5290  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 3.2727  Validation loss = 3.5286  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 3.2724  Validation loss = 3.5283  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 3.2722  Validation loss = 3.5280  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 3.2720  Validation loss = 3.5277  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 3.2718  Validation loss = 3.5274  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 3.2715  Validation loss = 3.5271  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 3.2712  Validation loss = 3.5267  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 3.2710  Validation loss = 3.5265  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 3.2708  Validation loss = 3.5262  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 3.2705  Validation loss = 3.5258  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 3.2702  Validation loss = 3.5255  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 3.2700  Validation loss = 3.5252  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 3.2697  Validation loss = 3.5248  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 3.2695  Validation loss = 3.5246  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 3.2693  Validation loss = 3.5243  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 3.2690  Validation loss = 3.5240  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 3.2688  Validation loss = 3.5237  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 3.2686  Validation loss = 3.5234  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 3.2682  Validation loss = 3.5230  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 3.2680  Validation loss = 3.5226  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 3.2677  Validation loss = 3.5222  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 3.2675  Validation loss = 3.5220  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 3.2672  Validation loss = 3.5217  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 3.2670  Validation loss = 3.5213  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 3.2667  Validation loss = 3.5210  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 3.2665  Validation loss = 3.5207  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 3.2663  Validation loss = 3.5204  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 3.2660  Validation loss = 3.5201  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 3.2658  Validation loss = 3.5199  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 3.2655  Validation loss = 3.5195  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 3.2653  Validation loss = 3.5192  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 3.2651  Validation loss = 3.5189  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 3.2649  Validation loss = 3.5186  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 3.2646  Validation loss = 3.5183  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 3.2643  Validation loss = 3.5179  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 3.2640  Validation loss = 3.5175  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 3.2637  Validation loss = 3.5172  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 3.2635  Validation loss = 3.5168  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 3.2632  Validation loss = 3.5165  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 3.2629  Validation loss = 3.5161  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 3.2626  Validation loss = 3.5158  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 3.2625  Validation loss = 3.5155  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 3.2621  Validation loss = 3.5151  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 3.2619  Validation loss = 3.5148  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 3.2617  Validation loss = 3.5145  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 3.2615  Validation loss = 3.5142  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 3.2612  Validation loss = 3.5139  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 3.2610  Validation loss = 3.5136  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 2.3417  Validation loss = 4.9255  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 2.3415  Validation loss = 4.9253  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 2.3413  Validation loss = 4.9250  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 2.3411  Validation loss = 4.9247  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 2.3408  Validation loss = 4.9244  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 2.3406  Validation loss = 4.9241  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 2.3403  Validation loss = 4.9238  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 2.3401  Validation loss = 4.9234  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 2.3399  Validation loss = 4.9231  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 2.3396  Validation loss = 4.9228  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 2.3394  Validation loss = 4.9226  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 2.3392  Validation loss = 4.9222  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 2.3389  Validation loss = 4.9219  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 2.3387  Validation loss = 4.9216  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 2.3384  Validation loss = 4.9212  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 2.3381  Validation loss = 4.9209  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 2.3379  Validation loss = 4.9206  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 2.3376  Validation loss = 4.9202  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 2.3374  Validation loss = 4.9199  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 2.3372  Validation loss = 4.9196  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 2.3369  Validation loss = 4.9192  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 2.3366  Validation loss = 4.9189  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 2.3364  Validation loss = 4.9186  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 2.3361  Validation loss = 4.9182  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 2.3359  Validation loss = 4.9179  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 2.3357  Validation loss = 4.9177  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 2.3355  Validation loss = 4.9174  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 2.3353  Validation loss = 4.9171  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 2.3350  Validation loss = 4.9168  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 2.3347  Validation loss = 4.9164  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 2.3345  Validation loss = 4.9161  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 2.3342  Validation loss = 4.9157  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 2.3340  Validation loss = 4.9154  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 2.3337  Validation loss = 4.9150  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 2.3335  Validation loss = 4.9147  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 2.3332  Validation loss = 4.9144  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 2.3330  Validation loss = 4.9141  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 2.3328  Validation loss = 4.9139  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 2.3326  Validation loss = 4.9136  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 2.3323  Validation loss = 4.9132  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 2.3321  Validation loss = 4.9129  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 2.3319  Validation loss = 4.9126  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 2.3317  Validation loss = 4.9123  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 2.3314  Validation loss = 4.9120  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 2.3312  Validation loss = 4.9116  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 2.3310  Validation loss = 4.9114  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 2.3307  Validation loss = 4.9111  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 2.3305  Validation loss = 4.9108  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 2.3302  Validation loss = 4.9104  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 2.3300  Validation loss = 4.9101  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 2.3298  Validation loss = 4.9098  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 2.3295  Validation loss = 4.9095  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 2.3293  Validation loss = 4.9091  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 2.3290  Validation loss = 4.9088  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 2.3288  Validation loss = 4.9085  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 2.3286  Validation loss = 4.9082  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 2.3283  Validation loss = 4.9079  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 2.3281  Validation loss = 4.9075  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 2.3278  Validation loss = 4.9072  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 2.3276  Validation loss = 4.9069  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 2.3273  Validation loss = 4.9065  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 2.3271  Validation loss = 4.9062  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 2.3268  Validation loss = 4.9059  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 2.3266  Validation loss = 4.9056  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 2.3264  Validation loss = 4.9053  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 2.3261  Validation loss = 4.9050  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 2.3259  Validation loss = 4.9046  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 2.3257  Validation loss = 4.9044  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 2.3254  Validation loss = 4.9041  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 2.3252  Validation loss = 4.9038  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 2.3249  Validation loss = 4.9033  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 2.3247  Validation loss = 4.9030  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 2.3244  Validation loss = 4.9027  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 2.3242  Validation loss = 4.9024  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 2.3239  Validation loss = 4.9021  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 2.3237  Validation loss = 4.9017  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 2.3234  Validation loss = 4.9013  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 2.3231  Validation loss = 4.9010  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 2.3229  Validation loss = 4.9007  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 2.3227  Validation loss = 4.9004  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 2.3224  Validation loss = 4.9000  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 2.3222  Validation loss = 4.8997  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 2.3219  Validation loss = 4.8994  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 2.3217  Validation loss = 4.8990  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 2.3214  Validation loss = 4.8987  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 2.3212  Validation loss = 4.8984  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 2.3209  Validation loss = 4.8980  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 2.3207  Validation loss = 4.8977  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 2.3204  Validation loss = 4.8973  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 2.3201  Validation loss = 4.8970  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 2.3199  Validation loss = 4.8967  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 2.3197  Validation loss = 4.8964  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 2.3194  Validation loss = 4.8960  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 2.3192  Validation loss = 4.8958  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 2.3189  Validation loss = 4.8954  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 2.3187  Validation loss = 4.8951  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 2.3184  Validation loss = 4.8947  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 2.3181  Validation loss = 4.8943  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 2.3179  Validation loss = 4.8940  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 2.3177  Validation loss = 4.8937  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 2.3174  Validation loss = 4.8934  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 2.3172  Validation loss = 4.8931  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 2.3170  Validation loss = 4.8928  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 2.3168  Validation loss = 4.8925  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 2.3165  Validation loss = 4.8922  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 2.3163  Validation loss = 4.8918  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 2.3160  Validation loss = 4.8915  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 2.3158  Validation loss = 4.8912  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 2.3155  Validation loss = 4.8908  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 2.3153  Validation loss = 4.8905  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 2.3151  Validation loss = 4.8903  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 2.3149  Validation loss = 4.8900  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 2.3146  Validation loss = 4.8896  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 2.3144  Validation loss = 4.8893  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 2.3141  Validation loss = 4.8890  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 2.3139  Validation loss = 4.8886  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 2.3137  Validation loss = 4.8883  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 2.3134  Validation loss = 4.8879  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 2.3131  Validation loss = 4.8875  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 2.3129  Validation loss = 4.8872  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 2.3126  Validation loss = 4.8869  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 2.3124  Validation loss = 4.8866  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 2.3122  Validation loss = 4.8863  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 2.3120  Validation loss = 4.8860  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 2.3117  Validation loss = 4.8857  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 2.3115  Validation loss = 4.8854  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 2.3112  Validation loss = 4.8851  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 2.3110  Validation loss = 4.8847  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 2.3107  Validation loss = 4.8844  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 2.3105  Validation loss = 4.8841  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 2.3103  Validation loss = 4.8838  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 2.3100  Validation loss = 4.8835  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 2.3098  Validation loss = 4.8832  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 2.3095  Validation loss = 4.8828  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 2.3093  Validation loss = 4.8825  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 2.3090  Validation loss = 4.8821  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 2.3088  Validation loss = 4.8818  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 2.3085  Validation loss = 4.8815  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 2.3083  Validation loss = 4.8812  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 2.3081  Validation loss = 4.8809  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 2.3078  Validation loss = 4.8805  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 2.3076  Validation loss = 4.8802  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 2.3073  Validation loss = 4.8798  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 2.3071  Validation loss = 4.8795  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 2.3068  Validation loss = 4.8792  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 2.3066  Validation loss = 4.8789  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 2.3064  Validation loss = 4.8786  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 2.3062  Validation loss = 4.8784  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 2.3059  Validation loss = 4.8780  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 2.3057  Validation loss = 4.8777  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 2.3054  Validation loss = 4.8774  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 2.3052  Validation loss = 4.8771  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 2.3050  Validation loss = 4.8768  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 2.3047  Validation loss = 4.8765  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 2.3045  Validation loss = 4.8762  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 2.3043  Validation loss = 4.8759  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 2.3041  Validation loss = 4.8756  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 2.3039  Validation loss = 4.8753  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 2.3036  Validation loss = 4.8750  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 2.3034  Validation loss = 4.8747  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 2.3031  Validation loss = 4.8744  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 2.3029  Validation loss = 4.8740  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 2.3026  Validation loss = 4.8737  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 2.3024  Validation loss = 4.8735  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 2.3022  Validation loss = 4.8731  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 2.3019  Validation loss = 4.8728  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 2.3017  Validation loss = 4.8724  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 2.3014  Validation loss = 4.8721  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 2.3012  Validation loss = 4.8718  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 2.3010  Validation loss = 4.8715  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 2.3008  Validation loss = 4.8713  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 2.3005  Validation loss = 4.8710  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 2.3003  Validation loss = 4.8706  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 2.3001  Validation loss = 4.8703  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 2.2998  Validation loss = 4.8700  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 2.2996  Validation loss = 4.8697  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 2.2993  Validation loss = 4.8693  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 2.2991  Validation loss = 4.8690  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 2.2988  Validation loss = 4.8687  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 2.2986  Validation loss = 4.8684  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 2.2984  Validation loss = 4.8681  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 2.2981  Validation loss = 4.8678  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 2.2979  Validation loss = 4.8675  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 2.2976  Validation loss = 4.8671  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 2.2974  Validation loss = 4.8668  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 2.2972  Validation loss = 4.8665  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 2.2970  Validation loss = 4.8662  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 2.2967  Validation loss = 4.8659  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 2.2965  Validation loss = 4.8657  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 2.2963  Validation loss = 4.8653  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 2.2960  Validation loss = 4.8650  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 2.2957  Validation loss = 4.8646  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 2.2955  Validation loss = 4.8643  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 2.2953  Validation loss = 4.8640  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 2.2950  Validation loss = 4.8637  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 2.2948  Validation loss = 4.8634  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 2.2945  Validation loss = 4.8630  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 2.2943  Validation loss = 4.8627  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 2.2940  Validation loss = 4.8623  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 2.2938  Validation loss = 4.8620  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 2.2936  Validation loss = 4.8617  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 2.2933  Validation loss = 4.8615  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 2.2931  Validation loss = 4.8612  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 2.2929  Validation loss = 4.8608  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 2.2926  Validation loss = 4.8605  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 2.2924  Validation loss = 4.8602  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 2.2922  Validation loss = 4.8600  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 2.2920  Validation loss = 4.8597  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 2.2918  Validation loss = 4.8594  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 2.2915  Validation loss = 4.8590  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 2.2913  Validation loss = 4.8588  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 2.2911  Validation loss = 4.8584  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 2.2908  Validation loss = 4.8582  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 2.2906  Validation loss = 4.8578  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 2.2903  Validation loss = 4.8575  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 2.2901  Validation loss = 4.8571  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 2.2899  Validation loss = 4.8568  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 2.2897  Validation loss = 4.8566  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 2.2895  Validation loss = 4.8563  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 2.2892  Validation loss = 4.8559  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 2.2890  Validation loss = 4.8556  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 2.2887  Validation loss = 4.8553  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 2.2885  Validation loss = 4.8550  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 2.2883  Validation loss = 4.8547  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 2.2881  Validation loss = 4.8544  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 2.2878  Validation loss = 4.8541  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 2.2876  Validation loss = 4.8538  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 2.2874  Validation loss = 4.8535  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 2.2871  Validation loss = 4.8531  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 2.2869  Validation loss = 4.8528  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 2.2866  Validation loss = 4.8525  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 2.2864  Validation loss = 4.8522  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 2.2861  Validation loss = 4.8518  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 2.2859  Validation loss = 4.8515  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 2.2857  Validation loss = 4.8512  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 2.2855  Validation loss = 4.8509  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 2.2852  Validation loss = 4.8506  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 2.2850  Validation loss = 4.8503  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 2.2848  Validation loss = 4.8500  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 2.2846  Validation loss = 4.8497  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 2.2843  Validation loss = 4.8494  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 2.2841  Validation loss = 4.8491  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 2.2838  Validation loss = 4.8488  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 2.2836  Validation loss = 4.8485  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 2.2834  Validation loss = 4.8482  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 2.2832  Validation loss = 4.8479  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 2.2830  Validation loss = 4.8477  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 2.2827  Validation loss = 4.8473  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 2.2825  Validation loss = 4.8470  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 2.2823  Validation loss = 4.8467  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 2.2821  Validation loss = 4.8465  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 2.2819  Validation loss = 4.8462  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 2.2816  Validation loss = 4.8458  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 2.2814  Validation loss = 4.8455  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 2.2811  Validation loss = 4.8452  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 2.2809  Validation loss = 4.8449  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 2.2807  Validation loss = 4.8446  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 2.2804  Validation loss = 4.8442  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 2.2802  Validation loss = 4.8439  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 2.2799  Validation loss = 4.8436  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 2.2797  Validation loss = 4.8433  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 2.2795  Validation loss = 4.8430  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 2.2792  Validation loss = 4.8426  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 2.2790  Validation loss = 4.8424  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 2.2787  Validation loss = 4.8420  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 2.2785  Validation loss = 4.8416  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 2.2782  Validation loss = 4.8413  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 2.2780  Validation loss = 4.8410  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 2.2778  Validation loss = 4.8408  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 2.2775  Validation loss = 4.8404  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 2.2773  Validation loss = 4.8401  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 2.2771  Validation loss = 4.8398  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 2.2769  Validation loss = 4.8395  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 2.2766  Validation loss = 4.8392  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 2.2764  Validation loss = 4.8389  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 2.2762  Validation loss = 4.8386  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 2.2759  Validation loss = 4.8382  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 2.2757  Validation loss = 4.8379  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 2.2755  Validation loss = 4.8377  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 2.2752  Validation loss = 4.8374  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 2.2750  Validation loss = 4.8371  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 2.2748  Validation loss = 4.8367  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 2.2746  Validation loss = 4.8365  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 2.2743  Validation loss = 4.8362  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 2.2741  Validation loss = 4.8359  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 2.2739  Validation loss = 4.8356  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 2.2736  Validation loss = 4.8353  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 2.2734  Validation loss = 4.8350  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 2.2732  Validation loss = 4.8347  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 2.2730  Validation loss = 4.8344  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 2.2727  Validation loss = 4.8341  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 2.2725  Validation loss = 4.8338  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 2.2723  Validation loss = 4.8335  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 2.2720  Validation loss = 4.8331  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 2.2718  Validation loss = 4.8329  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 2.2715  Validation loss = 4.8325  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 2.2714  Validation loss = 4.8323  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 2.2712  Validation loss = 4.8320  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 2.2710  Validation loss = 4.8318  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 2.2707  Validation loss = 4.8314  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 2.2705  Validation loss = 4.8311  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 2.2703  Validation loss = 4.8308  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 2.2700  Validation loss = 4.8305  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 2.2698  Validation loss = 4.8301  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 2.2695  Validation loss = 4.8298  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 2.2693  Validation loss = 4.8295  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 2.2691  Validation loss = 4.8293  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 2.2689  Validation loss = 4.8291  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 2.2687  Validation loss = 4.8288  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 2.2685  Validation loss = 4.8284  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 2.2682  Validation loss = 4.8281  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 2.2680  Validation loss = 4.8278  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 2.2677  Validation loss = 4.8275  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 2.2675  Validation loss = 4.8272  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 2.2673  Validation loss = 4.8269  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 2.2670  Validation loss = 4.8265  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 2.2668  Validation loss = 4.8262  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 2.2666  Validation loss = 4.8259  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 2.2664  Validation loss = 4.8257  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 2.2661  Validation loss = 4.8254  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 2.2659  Validation loss = 4.8250  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 2.2657  Validation loss = 4.8247  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 2.2654  Validation loss = 4.8244  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 2.2652  Validation loss = 4.8241  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 2.2650  Validation loss = 4.8238  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 2.2648  Validation loss = 4.8236  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 2.2645  Validation loss = 4.8233  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 2.2643  Validation loss = 4.8229  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 2.2641  Validation loss = 4.8226  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 2.2638  Validation loss = 4.8223  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 2.2636  Validation loss = 4.8221  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 2.2634  Validation loss = 4.8217  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 2.2631  Validation loss = 4.8214  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 2.2629  Validation loss = 4.8211  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 2.2627  Validation loss = 4.8208  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 2.2624  Validation loss = 4.8205  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 2.2622  Validation loss = 4.8202  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 2.2620  Validation loss = 4.8199  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 2.2617  Validation loss = 4.8195  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 2.2614  Validation loss = 4.8192  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 2.2612  Validation loss = 4.8189  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 2.2610  Validation loss = 4.8186  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 2.2608  Validation loss = 4.8183  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 2.2605  Validation loss = 4.8180  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 2.2603  Validation loss = 4.8177  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 2.2601  Validation loss = 4.8174  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 2.2598  Validation loss = 4.8170  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 2.2596  Validation loss = 4.8167  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 2.2594  Validation loss = 4.8165  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 2.2592  Validation loss = 4.8161  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 2.2589  Validation loss = 4.8158  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 2.2587  Validation loss = 4.8155  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 2.2585  Validation loss = 4.8153  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 2.2583  Validation loss = 4.8150  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 2.2581  Validation loss = 4.8147  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 2.2579  Validation loss = 4.8145  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 2.2577  Validation loss = 4.8142  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 2.2574  Validation loss = 4.8138  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 2.2572  Validation loss = 4.8135  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 2.2570  Validation loss = 4.8132  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 2.2568  Validation loss = 4.8130  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 2.2565  Validation loss = 4.8127  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 2.2563  Validation loss = 4.8123  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 2.2561  Validation loss = 4.8121  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 2.2559  Validation loss = 4.8117  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 2.2556  Validation loss = 4.8114  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 2.2554  Validation loss = 4.8111  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 2.2551  Validation loss = 4.8108  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 2.2549  Validation loss = 4.8105  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 2.2547  Validation loss = 4.8102  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 2.2545  Validation loss = 4.8099  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 2.2543  Validation loss = 4.8097  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 2.2541  Validation loss = 4.8094  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 2.2539  Validation loss = 4.8091  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 2.2536  Validation loss = 4.8088  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 2.2534  Validation loss = 4.8085  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 2.2531  Validation loss = 4.8082  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 2.2529  Validation loss = 4.8079  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 2.2527  Validation loss = 4.8076  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 2.2525  Validation loss = 4.8073  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 2.2522  Validation loss = 4.8070  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 2.2520  Validation loss = 4.8067  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 2.2518  Validation loss = 4.8065  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 2.2516  Validation loss = 4.8062  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 2.2513  Validation loss = 4.8058  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 2.2511  Validation loss = 4.8055  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 2.2509  Validation loss = 4.8052  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 2.2507  Validation loss = 4.8049  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 2.2504  Validation loss = 4.8047  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 2.2502  Validation loss = 4.8044  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 2.2500  Validation loss = 4.8041  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 2.2498  Validation loss = 4.8038  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 2.2496  Validation loss = 4.8035  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 2.2493  Validation loss = 4.8032  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 2.2491  Validation loss = 4.8029  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 2.2489  Validation loss = 4.8026  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 2.2487  Validation loss = 4.8023  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 2.2484  Validation loss = 4.8020  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 2.2482  Validation loss = 4.8018  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 2.2480  Validation loss = 4.8014  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 2.2477  Validation loss = 4.8011  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 2.2475  Validation loss = 4.8008  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 2.2473  Validation loss = 4.8005  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 2.2471  Validation loss = 4.8002  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 2.2468  Validation loss = 4.7999  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 2.2466  Validation loss = 4.7996  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 2.2464  Validation loss = 4.7994  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 2.2462  Validation loss = 4.7991  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 2.2460  Validation loss = 4.7988  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 2.2458  Validation loss = 4.7985  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 2.2456  Validation loss = 4.7982  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 2.2454  Validation loss = 4.7979  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 2.2451  Validation loss = 4.7976  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 2.2449  Validation loss = 4.7973  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 2.2447  Validation loss = 4.7970  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 2.2444  Validation loss = 4.7967  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 2.2442  Validation loss = 4.7963  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 2.2440  Validation loss = 4.7961  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 2.2438  Validation loss = 4.7959  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 2.2436  Validation loss = 4.7956  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 2.2434  Validation loss = 4.7953  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 2.2432  Validation loss = 4.7951  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 2.2430  Validation loss = 4.7948  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 2.2428  Validation loss = 4.7945  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 2.2426  Validation loss = 4.7942  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 2.2423  Validation loss = 4.7939  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 2.2421  Validation loss = 4.7936  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 2.2419  Validation loss = 4.7933  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 2.2417  Validation loss = 4.7930  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 2.2415  Validation loss = 4.7927  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 2.2412  Validation loss = 4.7924  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 2.2410  Validation loss = 4.7920  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 2.2407  Validation loss = 4.7917  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 2.2405  Validation loss = 4.7915  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 2.2403  Validation loss = 4.7911  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 2.2401  Validation loss = 4.7908  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 2.2399  Validation loss = 4.7906  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 2.2396  Validation loss = 4.7903  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 2.2394  Validation loss = 4.7900  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 2.2393  Validation loss = 4.7898  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 2.2390  Validation loss = 4.7895  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 2.2388  Validation loss = 4.7892  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 2.2385  Validation loss = 4.7888  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 2.2383  Validation loss = 4.7885  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 2.2381  Validation loss = 4.7882  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 2.2378  Validation loss = 4.7879  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 2.2376  Validation loss = 4.7876  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 2.2374  Validation loss = 4.7873  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 2.2372  Validation loss = 4.7870  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 2.2370  Validation loss = 4.7867  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 2.2368  Validation loss = 4.7865  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 2.2365  Validation loss = 4.7862  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 2.2363  Validation loss = 4.7859  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 2.2361  Validation loss = 4.7855  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 2.2359  Validation loss = 4.7853  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 2.2357  Validation loss = 4.7851  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 2.2355  Validation loss = 4.7848  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 2.2353  Validation loss = 4.7846  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 2.2351  Validation loss = 4.7842  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 2.2349  Validation loss = 4.7839  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 2.2346  Validation loss = 4.7836  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 2.2343  Validation loss = 4.7832  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 2.2341  Validation loss = 4.7829  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 2.2340  Validation loss = 4.7827  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 2.2338  Validation loss = 4.7825  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 2.2335  Validation loss = 4.7821  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 2.2333  Validation loss = 4.7819  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 2.2331  Validation loss = 4.7815  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 2.2329  Validation loss = 4.7813  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 2.2327  Validation loss = 4.7810  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 2.2325  Validation loss = 4.7808  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 2.2323  Validation loss = 4.7805  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 2.2321  Validation loss = 4.7802  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 2.2319  Validation loss = 4.7799  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 2.2316  Validation loss = 4.7796  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 2.2314  Validation loss = 4.7793  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 2.2312  Validation loss = 4.7791  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 2.2310  Validation loss = 4.7788  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 2.2308  Validation loss = 4.7785  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 2.2306  Validation loss = 4.7783  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 2.2304  Validation loss = 4.7780  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 2.2303  Validation loss = 4.7778  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 2.2301  Validation loss = 4.7776  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 2.2299  Validation loss = 4.7773  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 2.2297  Validation loss = 4.7770  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 2.2294  Validation loss = 4.7767  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 2.2293  Validation loss = 4.7765  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 2.2291  Validation loss = 4.7763  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 2.2289  Validation loss = 4.7760  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 2.2287  Validation loss = 4.7757  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 2.2284  Validation loss = 4.7754  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 2.2282  Validation loss = 4.7751  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 2.2280  Validation loss = 4.7747  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 2.2278  Validation loss = 4.7745  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 2.2276  Validation loss = 4.7742  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 2.2274  Validation loss = 4.7739  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 2.2272  Validation loss = 4.7737  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 2.2270  Validation loss = 4.7734  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 2.2267  Validation loss = 4.7731  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 2.2265  Validation loss = 4.7728  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 2.3716  Validation loss = 5.8974  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 2.3713  Validation loss = 5.8971  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 2.3710  Validation loss = 5.8967  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 2.3708  Validation loss = 5.8964  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 2.3705  Validation loss = 5.8961  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 2.3703  Validation loss = 5.8958  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 2.3700  Validation loss = 5.8955  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 2.3698  Validation loss = 5.8952  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 2.3696  Validation loss = 5.8949  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 2.3694  Validation loss = 5.8946  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 2.3691  Validation loss = 5.8942  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 2.3688  Validation loss = 5.8939  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 2.3686  Validation loss = 5.8936  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 2.3684  Validation loss = 5.8933  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 2.3681  Validation loss = 5.8930  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 2.3679  Validation loss = 5.8927  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 2.3677  Validation loss = 5.8924  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 2.3674  Validation loss = 5.8921  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 2.3672  Validation loss = 5.8918  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 2.3670  Validation loss = 5.8916  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 2.3668  Validation loss = 5.8912  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 2.3665  Validation loss = 5.8909  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 2.3662  Validation loss = 5.8906  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 2.3660  Validation loss = 5.8903  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 2.3657  Validation loss = 5.8899  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 2.3655  Validation loss = 5.8896  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 2.3652  Validation loss = 5.8893  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 2.3650  Validation loss = 5.8890  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 2.3647  Validation loss = 5.8886  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 2.3645  Validation loss = 5.8884  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 2.3643  Validation loss = 5.8881  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 2.3640  Validation loss = 5.8878  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 2.3638  Validation loss = 5.8875  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 2.3636  Validation loss = 5.8872  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 2.3633  Validation loss = 5.8869  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 2.3631  Validation loss = 5.8866  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 2.3629  Validation loss = 5.8863  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 2.3627  Validation loss = 5.8860  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 2.3624  Validation loss = 5.8856  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 2.3621  Validation loss = 5.8852  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 2.3619  Validation loss = 5.8850  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 2.3616  Validation loss = 5.8846  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 2.3614  Validation loss = 5.8844  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 2.3612  Validation loss = 5.8841  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 2.3610  Validation loss = 5.8838  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 2.3607  Validation loss = 5.8835  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 2.3604  Validation loss = 5.8831  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 2.3602  Validation loss = 5.8829  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 2.3600  Validation loss = 5.8826  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 2.3597  Validation loss = 5.8823  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 2.3595  Validation loss = 5.8819  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 2.3592  Validation loss = 5.8816  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 2.3590  Validation loss = 5.8813  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 2.3588  Validation loss = 5.8810  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 2.3585  Validation loss = 5.8807  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 2.3583  Validation loss = 5.8804  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 2.3581  Validation loss = 5.8801  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 2.3578  Validation loss = 5.8798  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 2.3576  Validation loss = 5.8796  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 2.3574  Validation loss = 5.8792  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 2.3571  Validation loss = 5.8789  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 2.3568  Validation loss = 5.8785  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 2.3565  Validation loss = 5.8781  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 2.3563  Validation loss = 5.8778  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 2.3561  Validation loss = 5.8775  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 2.3558  Validation loss = 5.8772  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 2.3556  Validation loss = 5.8769  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 2.3554  Validation loss = 5.8767  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 2.3552  Validation loss = 5.8764  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 2.3550  Validation loss = 5.8761  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 2.3547  Validation loss = 5.8758  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 2.3545  Validation loss = 5.8755  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 2.3542  Validation loss = 5.8752  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 2.3540  Validation loss = 5.8748  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 2.3538  Validation loss = 5.8745  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 2.3535  Validation loss = 5.8742  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 2.3533  Validation loss = 5.8740  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 2.3531  Validation loss = 5.8737  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 2.3529  Validation loss = 5.8734  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 2.3526  Validation loss = 5.8731  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 2.3524  Validation loss = 5.8728  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 2.3522  Validation loss = 5.8725  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 2.3519  Validation loss = 5.8722  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 2.3517  Validation loss = 5.8719  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 2.3515  Validation loss = 5.8716  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 2.3512  Validation loss = 5.8713  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 2.3510  Validation loss = 5.8710  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 2.3508  Validation loss = 5.8707  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 2.3505  Validation loss = 5.8705  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 2.3503  Validation loss = 5.8702  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 2.3501  Validation loss = 5.8699  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 2.3499  Validation loss = 5.8696  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 2.3497  Validation loss = 5.8694  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 2.3495  Validation loss = 5.8691  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 2.3493  Validation loss = 5.8689  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 2.3491  Validation loss = 5.8686  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 2.3488  Validation loss = 5.8682  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 2.3486  Validation loss = 5.8679  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 2.3484  Validation loss = 5.8676  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 2.3481  Validation loss = 5.8673  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 2.3479  Validation loss = 5.8671  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 2.3476  Validation loss = 5.8667  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 2.3474  Validation loss = 5.8664  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 2.3471  Validation loss = 5.8661  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 2.3469  Validation loss = 5.8658  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 2.3467  Validation loss = 5.8656  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 2.3465  Validation loss = 5.8653  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 2.3463  Validation loss = 5.8650  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 2.3460  Validation loss = 5.8647  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 2.3458  Validation loss = 5.8644  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 2.3455  Validation loss = 5.8640  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 2.3453  Validation loss = 5.8638  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 2.3451  Validation loss = 5.8634  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 2.3448  Validation loss = 5.8631  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 2.3446  Validation loss = 5.8628  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 2.3443  Validation loss = 5.8625  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 2.3442  Validation loss = 5.8622  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 2.3439  Validation loss = 5.8620  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 2.3437  Validation loss = 5.8617  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 2.3435  Validation loss = 5.8614  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 2.3433  Validation loss = 5.8611  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 2.3431  Validation loss = 5.8608  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 2.3428  Validation loss = 5.8605  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 2.3426  Validation loss = 5.8602  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 2.3424  Validation loss = 5.8600  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 2.3422  Validation loss = 5.8597  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 2.3419  Validation loss = 5.8594  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 2.3417  Validation loss = 5.8590  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 2.3414  Validation loss = 5.8587  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 2.3412  Validation loss = 5.8584  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 2.3410  Validation loss = 5.8582  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 2.3408  Validation loss = 5.8579  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 2.3405  Validation loss = 5.8575  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 2.3402  Validation loss = 5.8572  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 2.3400  Validation loss = 5.8569  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 2.3398  Validation loss = 5.8566  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 2.3396  Validation loss = 5.8563  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 2.3394  Validation loss = 5.8561  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 2.3391  Validation loss = 5.8558  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 2.3389  Validation loss = 5.8555  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 2.3386  Validation loss = 5.8551  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 2.3384  Validation loss = 5.8548  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 2.3381  Validation loss = 5.8545  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 2.3379  Validation loss = 5.8542  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 2.3377  Validation loss = 5.8539  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 2.3375  Validation loss = 5.8536  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 2.3373  Validation loss = 5.8533  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 2.3371  Validation loss = 5.8530  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 2.3368  Validation loss = 5.8527  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 2.3365  Validation loss = 5.8523  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 2.3363  Validation loss = 5.8520  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 2.3360  Validation loss = 5.8517  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 2.3358  Validation loss = 5.8514  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 2.3356  Validation loss = 5.8511  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 2.3354  Validation loss = 5.8508  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 2.3351  Validation loss = 5.8505  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 2.3349  Validation loss = 5.8502  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 2.3346  Validation loss = 5.8499  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 2.3344  Validation loss = 5.8496  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 2.3342  Validation loss = 5.8493  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 2.3340  Validation loss = 5.8490  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 2.3338  Validation loss = 5.8488  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 2.3336  Validation loss = 5.8485  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 2.3334  Validation loss = 5.8483  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 2.3331  Validation loss = 5.8479  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 2.3329  Validation loss = 5.8477  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 2.3327  Validation loss = 5.8474  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 2.3325  Validation loss = 5.8471  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 2.3322  Validation loss = 5.8467  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 2.3320  Validation loss = 5.8465  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 2.3318  Validation loss = 5.8462  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 2.3315  Validation loss = 5.8458  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 2.3313  Validation loss = 5.8456  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 2.3311  Validation loss = 5.8452  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 2.3308  Validation loss = 5.8449  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 2.3306  Validation loss = 5.8446  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 2.3304  Validation loss = 5.8443  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 2.3301  Validation loss = 5.8440  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 2.3299  Validation loss = 5.8437  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 2.3296  Validation loss = 5.8434  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 2.3294  Validation loss = 5.8431  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 2.3292  Validation loss = 5.8428  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 2.3290  Validation loss = 5.8425  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 2.3287  Validation loss = 5.8422  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 2.3285  Validation loss = 5.8419  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 2.3283  Validation loss = 5.8417  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 2.3281  Validation loss = 5.8413  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 2.3278  Validation loss = 5.8410  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 2.3277  Validation loss = 5.8408  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 2.3275  Validation loss = 5.8405  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 2.3272  Validation loss = 5.8402  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 2.3270  Validation loss = 5.8399  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 2.3268  Validation loss = 5.8396  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 2.3266  Validation loss = 5.8393  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 2.3263  Validation loss = 5.8390  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 2.3261  Validation loss = 5.8387  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 2.3259  Validation loss = 5.8384  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 2.3257  Validation loss = 5.8382  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 2.3254  Validation loss = 5.8379  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 2.3252  Validation loss = 5.8376  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 2.3250  Validation loss = 5.8373  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 2.3247  Validation loss = 5.8370  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 2.3245  Validation loss = 5.8366  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 2.3242  Validation loss = 5.8363  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 2.3240  Validation loss = 5.8360  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 2.3238  Validation loss = 5.8357  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 2.3236  Validation loss = 5.8355  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 2.3233  Validation loss = 5.8352  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 2.3232  Validation loss = 5.8349  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 2.3229  Validation loss = 5.8346  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 2.3227  Validation loss = 5.8344  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 2.3225  Validation loss = 5.8341  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 2.3223  Validation loss = 5.8338  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 2.3221  Validation loss = 5.8335  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 2.3219  Validation loss = 5.8332  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 2.3216  Validation loss = 5.8330  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 2.3214  Validation loss = 5.8327  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 2.3213  Validation loss = 5.8325  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 2.3211  Validation loss = 5.8322  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 2.3208  Validation loss = 5.8320  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 2.3207  Validation loss = 5.8318  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 2.3205  Validation loss = 5.8315  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 2.3203  Validation loss = 5.8312  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 2.3201  Validation loss = 5.8309  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 2.3198  Validation loss = 5.8307  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 2.3196  Validation loss = 5.8304  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 2.3194  Validation loss = 5.8301  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 2.3192  Validation loss = 5.8299  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 2.3190  Validation loss = 5.8296  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 2.3189  Validation loss = 5.8294  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 2.3186  Validation loss = 5.8291  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 2.3184  Validation loss = 5.8288  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 2.3182  Validation loss = 5.8286  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 2.3180  Validation loss = 5.8283  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 2.3178  Validation loss = 5.8280  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 2.3176  Validation loss = 5.8278  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 2.3173  Validation loss = 5.8274  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 2.3171  Validation loss = 5.8272  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 2.3169  Validation loss = 5.8269  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 2.3167  Validation loss = 5.8266  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 2.3165  Validation loss = 5.8263  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 2.3163  Validation loss = 5.8260  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 2.3161  Validation loss = 5.8257  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 2.3159  Validation loss = 5.8255  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 2.3157  Validation loss = 5.8252  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 2.3154  Validation loss = 5.8249  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 2.3152  Validation loss = 5.8246  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 2.3150  Validation loss = 5.8243  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 2.3148  Validation loss = 5.8241  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 2.3146  Validation loss = 5.8238  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 2.3144  Validation loss = 5.8236  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 2.3142  Validation loss = 5.8233  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 2.3140  Validation loss = 5.8231  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 2.3138  Validation loss = 5.8228  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 2.3136  Validation loss = 5.8225  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 2.3133  Validation loss = 5.8222  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 2.3131  Validation loss = 5.8219  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 2.3129  Validation loss = 5.8217  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 2.3128  Validation loss = 5.8215  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 2.3125  Validation loss = 5.8211  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 2.3123  Validation loss = 5.8209  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 2.3121  Validation loss = 5.8206  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 2.3119  Validation loss = 5.8203  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 2.3117  Validation loss = 5.8200  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 2.3114  Validation loss = 5.8197  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 2.3112  Validation loss = 5.8194  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 2.3111  Validation loss = 5.8192  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 2.3109  Validation loss = 5.8189  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 2.3106  Validation loss = 5.8186  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 2.3104  Validation loss = 5.8184  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 2.3102  Validation loss = 5.8181  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 2.3099  Validation loss = 5.8177  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 2.3097  Validation loss = 5.8174  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 2.3095  Validation loss = 5.8172  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 2.3093  Validation loss = 5.8169  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 2.3091  Validation loss = 5.8167  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 2.3089  Validation loss = 5.8164  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 2.3087  Validation loss = 5.8161  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 2.3085  Validation loss = 5.8158  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 2.3082  Validation loss = 5.8155  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 2.3080  Validation loss = 5.8152  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 2.3078  Validation loss = 5.8149  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 2.3076  Validation loss = 5.8146  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 2.3073  Validation loss = 5.8143  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 2.3071  Validation loss = 5.8140  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 2.3069  Validation loss = 5.8137  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 2.3067  Validation loss = 5.8135  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 2.3065  Validation loss = 5.8132  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 2.3063  Validation loss = 5.8130  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 2.3061  Validation loss = 5.8127  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 2.3058  Validation loss = 5.8124  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 2.3056  Validation loss = 5.8121  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 2.3054  Validation loss = 5.8119  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 2.3052  Validation loss = 5.8116  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 2.3050  Validation loss = 5.8113  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 2.3048  Validation loss = 5.8110  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 2.3045  Validation loss = 5.8107  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 2.3043  Validation loss = 5.8104  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 2.3042  Validation loss = 5.8102  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 2.3039  Validation loss = 5.8099  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 2.3037  Validation loss = 5.8096  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 2.3035  Validation loss = 5.8094  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 2.3033  Validation loss = 5.8091  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 2.3031  Validation loss = 5.8088  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 2.3029  Validation loss = 5.8085  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 2.3027  Validation loss = 5.8083  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 2.3025  Validation loss = 5.8081  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 2.3023  Validation loss = 5.8078  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 2.3021  Validation loss = 5.8076  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 2.3019  Validation loss = 5.8073  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 2.3017  Validation loss = 5.8070  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 2.3015  Validation loss = 5.8067  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 2.3013  Validation loss = 5.8065  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 2.3011  Validation loss = 5.8062  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 2.3009  Validation loss = 5.8060  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 2.3007  Validation loss = 5.8057  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 2.3005  Validation loss = 5.8055  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 2.3003  Validation loss = 5.8052  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 2.3000  Validation loss = 5.8048  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 2.2998  Validation loss = 5.8045  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 2.2995  Validation loss = 5.8042  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 2.2993  Validation loss = 5.8040  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 2.2991  Validation loss = 5.8037  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 2.2989  Validation loss = 5.8034  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 2.2987  Validation loss = 5.8032  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 2.2986  Validation loss = 5.8030  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 2.2984  Validation loss = 5.8027  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 2.2982  Validation loss = 5.8025  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 2.2980  Validation loss = 5.8022  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 2.2978  Validation loss = 5.8020  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 2.2976  Validation loss = 5.8017  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 2.2973  Validation loss = 5.8014  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 2.2971  Validation loss = 5.8011  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 2.2969  Validation loss = 5.8009  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 2.2967  Validation loss = 5.8006  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 2.2965  Validation loss = 5.8004  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 2.2963  Validation loss = 5.8001  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 2.2961  Validation loss = 5.7998  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 2.2959  Validation loss = 5.7995  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 2.2957  Validation loss = 5.7993  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 2.2955  Validation loss = 5.7990  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 2.2953  Validation loss = 5.7987  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 2.2951  Validation loss = 5.7985  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 2.2949  Validation loss = 5.7983  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 2.2947  Validation loss = 5.7980  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 2.2945  Validation loss = 5.7977  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 2.2943  Validation loss = 5.7974  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 2.2941  Validation loss = 5.7972  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 2.2939  Validation loss = 5.7969  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 2.2937  Validation loss = 5.7966  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 2.2935  Validation loss = 5.7964  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 2.2933  Validation loss = 5.7962  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 2.2931  Validation loss = 5.7959  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 2.2930  Validation loss = 5.7957  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 2.2928  Validation loss = 5.7955  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 2.2926  Validation loss = 5.7952  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 2.2924  Validation loss = 5.7949  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 2.2922  Validation loss = 5.7946  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 2.2920  Validation loss = 5.7944  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 2.2917  Validation loss = 5.7941  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 2.2916  Validation loss = 5.7938  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 2.2913  Validation loss = 5.7936  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 2.2911  Validation loss = 5.7933  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 2.2909  Validation loss = 5.7930  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 2.2907  Validation loss = 5.7927  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 2.2905  Validation loss = 5.7924  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 2.2903  Validation loss = 5.7921  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 2.2901  Validation loss = 5.7919  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 2.2898  Validation loss = 5.7916  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 2.2896  Validation loss = 5.7913  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 2.2894  Validation loss = 5.7910  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 2.2892  Validation loss = 5.7908  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 2.2890  Validation loss = 5.7905  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 2.2888  Validation loss = 5.7902  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 2.2886  Validation loss = 5.7900  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 2.2884  Validation loss = 5.7897  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 2.2882  Validation loss = 5.7895  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 2.2880  Validation loss = 5.7892  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 2.2878  Validation loss = 5.7889  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 2.2876  Validation loss = 5.7887  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 2.2874  Validation loss = 5.7883  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 2.2872  Validation loss = 5.7881  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 2.2870  Validation loss = 5.7878  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 2.2868  Validation loss = 5.7876  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 2.2866  Validation loss = 5.7873  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 2.2863  Validation loss = 5.7870  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 2.2861  Validation loss = 5.7868  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 2.2859  Validation loss = 5.7865  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 2.2857  Validation loss = 5.7861  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 2.2855  Validation loss = 5.7859  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 2.2853  Validation loss = 5.7856  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 2.2850  Validation loss = 5.7853  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 2.2848  Validation loss = 5.7850  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 2.2846  Validation loss = 5.7847  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 2.2844  Validation loss = 5.7844  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 2.2842  Validation loss = 5.7842  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 2.2840  Validation loss = 5.7839  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 2.2837  Validation loss = 5.7835  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 2.2835  Validation loss = 5.7832  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 2.2833  Validation loss = 5.7829  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 2.2831  Validation loss = 5.7827  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 2.2829  Validation loss = 5.7824  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 2.2827  Validation loss = 5.7822  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 2.2826  Validation loss = 5.7820  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 2.2823  Validation loss = 5.7817  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 2.2821  Validation loss = 5.7814  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 2.2819  Validation loss = 5.7812  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 2.2817  Validation loss = 5.7809  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 2.2816  Validation loss = 5.7807  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 2.2814  Validation loss = 5.7804  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 2.2812  Validation loss = 5.7802  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 2.2811  Validation loss = 5.7800  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 2.2809  Validation loss = 5.7797  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 2.2807  Validation loss = 5.7795  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 2.2805  Validation loss = 5.7792  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 2.2803  Validation loss = 5.7790  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 2.2801  Validation loss = 5.7787  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 2.2799  Validation loss = 5.7785  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 2.2797  Validation loss = 5.7783  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 2.2795  Validation loss = 5.7780  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 2.2793  Validation loss = 5.7777  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 2.2791  Validation loss = 5.7774  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 2.2789  Validation loss = 5.7772  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 2.2787  Validation loss = 5.7770  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 2.2785  Validation loss = 5.7767  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 2.2783  Validation loss = 5.7763  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 2.2781  Validation loss = 5.7761  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 2.2778  Validation loss = 5.7757  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 2.2777  Validation loss = 5.7755  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 2.2775  Validation loss = 5.7753  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 2.2773  Validation loss = 5.7750  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 2.2771  Validation loss = 5.7748  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 2.2769  Validation loss = 5.7746  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 2.2767  Validation loss = 5.7742  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 2.2765  Validation loss = 5.7740  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 2.2763  Validation loss = 5.7737  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 2.2761  Validation loss = 5.7735  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 2.2759  Validation loss = 5.7732  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 2.2757  Validation loss = 5.7729  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 2.2755  Validation loss = 5.7726  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 2.2753  Validation loss = 5.7724  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 2.2750  Validation loss = 5.7721  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 2.2749  Validation loss = 5.7719  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 2.2747  Validation loss = 5.7716  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 2.2745  Validation loss = 5.7713  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 2.2743  Validation loss = 5.7710  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 2.2740  Validation loss = 5.7707  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 2.2738  Validation loss = 5.7705  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 2.2737  Validation loss = 5.7703  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 2.2735  Validation loss = 5.7700  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 2.2733  Validation loss = 5.7698  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 2.2731  Validation loss = 5.7695  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 2.2729  Validation loss = 5.7693  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 2.2727  Validation loss = 5.7690  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 2.2726  Validation loss = 5.7688  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 2.2723  Validation loss = 5.7685  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 2.2722  Validation loss = 5.7683  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 2.2720  Validation loss = 5.7681  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 2.2718  Validation loss = 5.7678  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 2.2716  Validation loss = 5.7676  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 2.2714  Validation loss = 5.7673  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 2.2712  Validation loss = 5.7670  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 2.2709  Validation loss = 5.7667  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 2.2708  Validation loss = 5.7665  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 2.2706  Validation loss = 5.7663  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 2.2704  Validation loss = 5.7660  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 2.2702  Validation loss = 5.7657  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 2.2700  Validation loss = 5.7654  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 2.2698  Validation loss = 5.7652  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 2.2696  Validation loss = 5.7650  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 2.2693  Validation loss = 5.7646  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 2.2692  Validation loss = 5.7644  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 2.2690  Validation loss = 5.7642  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 2.2688  Validation loss = 5.7639  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 2.2686  Validation loss = 5.7636  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 2.2683  Validation loss = 5.7633  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 2.2681  Validation loss = 5.7631  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 2.2680  Validation loss = 5.7629  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 2.2677  Validation loss = 5.7626  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 2.2675  Validation loss = 5.7623  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 2.2673  Validation loss = 5.7620  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 2.2671  Validation loss = 5.7617  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 2.2669  Validation loss = 5.7614  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 2.2667  Validation loss = 5.7612  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 2.2665  Validation loss = 5.7609  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 2.2663  Validation loss = 5.7607  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 2.2661  Validation loss = 5.7604  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 2.2660  Validation loss = 5.7602  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 2.2658  Validation loss = 5.7599  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 2.2656  Validation loss = 5.7597  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 2.2654  Validation loss = 5.7594  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 2.2652  Validation loss = 5.7592  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 2.2650  Validation loss = 5.7589  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 2.2648  Validation loss = 5.7587  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 2.2646  Validation loss = 5.7584  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 2.2644  Validation loss = 5.7582  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 2.2642  Validation loss = 5.7579  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 2.2641  Validation loss = 5.7577  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 2.2638  Validation loss = 5.7574  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 2.2636  Validation loss = 5.7571  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.6479  Validation loss = 5.5832  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.6476  Validation loss = 5.5827  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.6474  Validation loss = 5.5825  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.6472  Validation loss = 5.5822  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.6470  Validation loss = 5.5819  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.6467  Validation loss = 5.5816  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.6465  Validation loss = 5.5813  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.6462  Validation loss = 5.5809  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.6460  Validation loss = 5.5806  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.6458  Validation loss = 5.5803  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.6456  Validation loss = 5.5800  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.6454  Validation loss = 5.5798  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.6451  Validation loss = 5.5795  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.6449  Validation loss = 5.5792  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.6447  Validation loss = 5.5789  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.6445  Validation loss = 5.5786  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.6442  Validation loss = 5.5783  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.6440  Validation loss = 5.5780  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.6438  Validation loss = 5.5777  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.6436  Validation loss = 5.5774  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.6434  Validation loss = 5.5771  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.6431  Validation loss = 5.5768  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.6429  Validation loss = 5.5765  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.6426  Validation loss = 5.5761  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.6424  Validation loss = 5.5758  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.6421  Validation loss = 5.5755  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.6419  Validation loss = 5.5752  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.6416  Validation loss = 5.5748  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.6414  Validation loss = 5.5746  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.6412  Validation loss = 5.5743  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.6410  Validation loss = 5.5740  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.6407  Validation loss = 5.5737  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.6405  Validation loss = 5.5734  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.6403  Validation loss = 5.5731  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.6401  Validation loss = 5.5728  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.6399  Validation loss = 5.5725  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.6397  Validation loss = 5.5723  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.6395  Validation loss = 5.5720  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.6392  Validation loss = 5.5717  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.6390  Validation loss = 5.5714  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.6388  Validation loss = 5.5711  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.6386  Validation loss = 5.5709  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.6383  Validation loss = 5.5705  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.6381  Validation loss = 5.5703  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.6379  Validation loss = 5.5700  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.6377  Validation loss = 5.5697  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.6375  Validation loss = 5.5694  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.6373  Validation loss = 5.5691  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.6370  Validation loss = 5.5688  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.6367  Validation loss = 5.5684  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.6365  Validation loss = 5.5682  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.6363  Validation loss = 5.5679  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.6361  Validation loss = 5.5675  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.6358  Validation loss = 5.5672  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.6356  Validation loss = 5.5669  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.6353  Validation loss = 5.5666  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.6351  Validation loss = 5.5663  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.6349  Validation loss = 5.5659  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.6346  Validation loss = 5.5656  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.6344  Validation loss = 5.5653  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.6342  Validation loss = 5.5650  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.6340  Validation loss = 5.5647  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.6338  Validation loss = 5.5645  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.6335  Validation loss = 5.5641  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.6334  Validation loss = 5.5639  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.6332  Validation loss = 5.5637  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.6330  Validation loss = 5.5634  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.6328  Validation loss = 5.5632  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.6325  Validation loss = 5.5628  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.6323  Validation loss = 5.5626  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.6321  Validation loss = 5.5623  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.6318  Validation loss = 5.5619  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.6316  Validation loss = 5.5616  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.6314  Validation loss = 5.5613  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.6311  Validation loss = 5.5610  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.6309  Validation loss = 5.5607  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.6307  Validation loss = 5.5604  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.6304  Validation loss = 5.5601  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.6302  Validation loss = 5.5597  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.6300  Validation loss = 5.5595  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.6298  Validation loss = 5.5592  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.6296  Validation loss = 5.5589  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.6293  Validation loss = 5.5586  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.6291  Validation loss = 5.5583  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.6288  Validation loss = 5.5579  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.6286  Validation loss = 5.5576  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.6283  Validation loss = 5.5573  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.6281  Validation loss = 5.5570  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.6279  Validation loss = 5.5567  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.6277  Validation loss = 5.5565  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.6275  Validation loss = 5.5562  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.6273  Validation loss = 5.5560  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.6271  Validation loss = 5.5557  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.6269  Validation loss = 5.5554  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.6266  Validation loss = 5.5550  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.6264  Validation loss = 5.5548  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.6262  Validation loss = 5.5545  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.6259  Validation loss = 5.5541  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.6257  Validation loss = 5.5539  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.6255  Validation loss = 5.5536  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.6254  Validation loss = 5.5534  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.6251  Validation loss = 5.5531  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.6249  Validation loss = 5.5528  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.6246  Validation loss = 5.5524  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.6244  Validation loss = 5.5522  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.6242  Validation loss = 5.5519  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.6240  Validation loss = 5.5516  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.6238  Validation loss = 5.5514  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.6236  Validation loss = 5.5511  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.6234  Validation loss = 5.5509  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.6232  Validation loss = 5.5506  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.6230  Validation loss = 5.5503  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.6227  Validation loss = 5.5500  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.6225  Validation loss = 5.5497  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.6223  Validation loss = 5.5494  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.6220  Validation loss = 5.5491  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.6218  Validation loss = 5.5487  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.6215  Validation loss = 5.5484  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.6213  Validation loss = 5.5481  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.6211  Validation loss = 5.5478  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.6209  Validation loss = 5.5475  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.6207  Validation loss = 5.5473  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.6204  Validation loss = 5.5469  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.6202  Validation loss = 5.5466  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.6199  Validation loss = 5.5463  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.6197  Validation loss = 5.5460  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.6195  Validation loss = 5.5457  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.6193  Validation loss = 5.5454  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.6191  Validation loss = 5.5452  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.6189  Validation loss = 5.5449  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.6186  Validation loss = 5.5446  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.6184  Validation loss = 5.5443  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.6182  Validation loss = 5.5441  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.6180  Validation loss = 5.5438  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.6178  Validation loss = 5.5435  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.6175  Validation loss = 5.5431  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.6173  Validation loss = 5.5428  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.6171  Validation loss = 5.5426  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.6168  Validation loss = 5.5422  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.6166  Validation loss = 5.5419  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.6164  Validation loss = 5.5416  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.6161  Validation loss = 5.5413  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.6159  Validation loss = 5.5410  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.6157  Validation loss = 5.5407  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.6155  Validation loss = 5.5405  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.6153  Validation loss = 5.5402  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.6151  Validation loss = 5.5398  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.6149  Validation loss = 5.5396  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.6147  Validation loss = 5.5393  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.6145  Validation loss = 5.5390  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.6142  Validation loss = 5.5387  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.6141  Validation loss = 5.5385  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.6139  Validation loss = 5.5383  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.6137  Validation loss = 5.5380  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.6135  Validation loss = 5.5377  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.6132  Validation loss = 5.5374  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.6130  Validation loss = 5.5371  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.6129  Validation loss = 5.5369  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.6127  Validation loss = 5.5367  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.6124  Validation loss = 5.5364  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.6122  Validation loss = 5.5360  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.6120  Validation loss = 5.5358  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.6118  Validation loss = 5.5355  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.6116  Validation loss = 5.5352  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.6113  Validation loss = 5.5349  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.6111  Validation loss = 5.5346  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.6109  Validation loss = 5.5345  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.6108  Validation loss = 5.5342  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.6105  Validation loss = 5.5339  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.6103  Validation loss = 5.5336  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.6101  Validation loss = 5.5333  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.6099  Validation loss = 5.5331  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.6097  Validation loss = 5.5328  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.6095  Validation loss = 5.5325  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.6093  Validation loss = 5.5323  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.6090  Validation loss = 5.5319  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.6088  Validation loss = 5.5317  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.6086  Validation loss = 5.5314  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.6084  Validation loss = 5.5311  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.6082  Validation loss = 5.5308  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.6079  Validation loss = 5.5305  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.6077  Validation loss = 5.5302  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.6075  Validation loss = 5.5299  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.6073  Validation loss = 5.5296  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.6070  Validation loss = 5.5293  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.6068  Validation loss = 5.5290  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.6066  Validation loss = 5.5287  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.6063  Validation loss = 5.5284  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.6061  Validation loss = 5.5281  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.6059  Validation loss = 5.5278  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.6057  Validation loss = 5.5275  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.6055  Validation loss = 5.5272  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.6053  Validation loss = 5.5270  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.6050  Validation loss = 5.5267  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.6048  Validation loss = 5.5264  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.6046  Validation loss = 5.5261  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.6043  Validation loss = 5.5257  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.6041  Validation loss = 5.5255  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.6039  Validation loss = 5.5252  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.6037  Validation loss = 5.5249  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.6035  Validation loss = 5.5246  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.6032  Validation loss = 5.5243  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.6031  Validation loss = 5.5241  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.6028  Validation loss = 5.5238  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.6026  Validation loss = 5.5235  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.6024  Validation loss = 5.5232  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.6022  Validation loss = 5.5230  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.6020  Validation loss = 5.5227  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.6017  Validation loss = 5.5223  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.6016  Validation loss = 5.5221  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.6014  Validation loss = 5.5218  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.6011  Validation loss = 5.5215  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.6009  Validation loss = 5.5212  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.6007  Validation loss = 5.5209  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.6005  Validation loss = 5.5207  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.6003  Validation loss = 5.5204  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.6001  Validation loss = 5.5202  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.5999  Validation loss = 5.5199  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.5997  Validation loss = 5.5196  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.5995  Validation loss = 5.5194  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.5993  Validation loss = 5.5191  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.5991  Validation loss = 5.5188  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.5988  Validation loss = 5.5185  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.5987  Validation loss = 5.5183  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.5985  Validation loss = 5.5181  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.5983  Validation loss = 5.5178  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.5981  Validation loss = 5.5175  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.5979  Validation loss = 5.5172  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.5976  Validation loss = 5.5169  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.5974  Validation loss = 5.5167  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.5973  Validation loss = 5.5164  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.5970  Validation loss = 5.5162  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.5969  Validation loss = 5.5159  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.5967  Validation loss = 5.5157  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.5965  Validation loss = 5.5154  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.5963  Validation loss = 5.5152  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.5961  Validation loss = 5.5149  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.5959  Validation loss = 5.5147  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.5957  Validation loss = 5.5144  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.5955  Validation loss = 5.5141  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.5952  Validation loss = 5.5138  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.5950  Validation loss = 5.5135  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.5948  Validation loss = 5.5132  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.5946  Validation loss = 5.5130  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.5944  Validation loss = 5.5127  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.5942  Validation loss = 5.5124  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.5940  Validation loss = 5.5122  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.5937  Validation loss = 5.5119  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.5935  Validation loss = 5.5116  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.5933  Validation loss = 5.5113  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.5931  Validation loss = 5.5110  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.5929  Validation loss = 5.5108  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.5927  Validation loss = 5.5105  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.5926  Validation loss = 5.5103  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.5923  Validation loss = 5.5099  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.5921  Validation loss = 5.5097  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.5919  Validation loss = 5.5094  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.5917  Validation loss = 5.5092  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.5915  Validation loss = 5.5089  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.5913  Validation loss = 5.5087  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.5911  Validation loss = 5.5084  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.5909  Validation loss = 5.5082  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.5907  Validation loss = 5.5078  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.5905  Validation loss = 5.5076  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.5903  Validation loss = 5.5073  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.5901  Validation loss = 5.5070  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.5899  Validation loss = 5.5067  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.5896  Validation loss = 5.5064  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.5894  Validation loss = 5.5061  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.5892  Validation loss = 5.5059  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.5890  Validation loss = 5.5056  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.5888  Validation loss = 5.5054  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.5886  Validation loss = 5.5051  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.5884  Validation loss = 5.5048  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.5882  Validation loss = 5.5046  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.5880  Validation loss = 5.5043  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.5878  Validation loss = 5.5040  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.5875  Validation loss = 5.5036  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.5873  Validation loss = 5.5034  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.5871  Validation loss = 5.5031  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.5869  Validation loss = 5.5028  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.5866  Validation loss = 5.5025  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.5864  Validation loss = 5.5021  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.5861  Validation loss = 5.5018  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.5859  Validation loss = 5.5015  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.5858  Validation loss = 5.5013  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.5856  Validation loss = 5.5011  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.5854  Validation loss = 5.5007  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.5851  Validation loss = 5.5005  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.5849  Validation loss = 5.5002  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.5847  Validation loss = 5.4999  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.5845  Validation loss = 5.4996  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.5843  Validation loss = 5.4994  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.5841  Validation loss = 5.4992  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.5839  Validation loss = 5.4989  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.5838  Validation loss = 5.4987  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.5835  Validation loss = 5.4984  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.5833  Validation loss = 5.4981  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.5831  Validation loss = 5.4978  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.5829  Validation loss = 5.4975  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.5827  Validation loss = 5.4972  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.5824  Validation loss = 5.4968  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.5822  Validation loss = 5.4966  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.5820  Validation loss = 5.4963  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.5818  Validation loss = 5.4960  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.5816  Validation loss = 5.4957  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.5814  Validation loss = 5.4955  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.5811  Validation loss = 5.4951  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.5809  Validation loss = 5.4949  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.5807  Validation loss = 5.4946  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.5805  Validation loss = 5.4942  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.5803  Validation loss = 5.4940  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.5801  Validation loss = 5.4937  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.5798  Validation loss = 5.4934  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.5796  Validation loss = 5.4930  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.5794  Validation loss = 5.4928  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.5792  Validation loss = 5.4926  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.5790  Validation loss = 5.4923  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.5788  Validation loss = 5.4920  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.5786  Validation loss = 5.4918  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.5784  Validation loss = 5.4915  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.5782  Validation loss = 5.4913  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.5781  Validation loss = 5.4910  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.5779  Validation loss = 5.4908  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.5777  Validation loss = 5.4905  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.5775  Validation loss = 5.4903  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.5773  Validation loss = 5.4900  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.5771  Validation loss = 5.4898  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.5769  Validation loss = 5.4895  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.5767  Validation loss = 5.4893  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.5765  Validation loss = 5.4891  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.5764  Validation loss = 5.4888  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.5762  Validation loss = 5.4885  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.5760  Validation loss = 5.4883  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.5758  Validation loss = 5.4880  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.5756  Validation loss = 5.4878  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.5753  Validation loss = 5.4875  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.5751  Validation loss = 5.4872  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.5750  Validation loss = 5.4870  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.5748  Validation loss = 5.4867  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.5745  Validation loss = 5.4864  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.5743  Validation loss = 5.4861  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.5741  Validation loss = 5.4858  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.5739  Validation loss = 5.4855  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.5737  Validation loss = 5.4852  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.5735  Validation loss = 5.4850  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.5733  Validation loss = 5.4848  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.5731  Validation loss = 5.4845  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.5729  Validation loss = 5.4842  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.5728  Validation loss = 5.4840  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.5726  Validation loss = 5.4838  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.5724  Validation loss = 5.4835  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.5722  Validation loss = 5.4832  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.5720  Validation loss = 5.4829  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.5718  Validation loss = 5.4827  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.5716  Validation loss = 5.4824  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.5714  Validation loss = 5.4821  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.5711  Validation loss = 5.4818  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.5710  Validation loss = 5.4816  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.5708  Validation loss = 5.4813  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.5706  Validation loss = 5.4811  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.5704  Validation loss = 5.4808  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.5702  Validation loss = 5.4805  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.5700  Validation loss = 5.4803  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.5697  Validation loss = 5.4799  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.5695  Validation loss = 5.4797  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.5694  Validation loss = 5.4795  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.5692  Validation loss = 5.4792  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.5690  Validation loss = 5.4790  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.5688  Validation loss = 5.4786  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.5686  Validation loss = 5.4784  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.5684  Validation loss = 5.4781  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.5682  Validation loss = 5.4779  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.5680  Validation loss = 5.4776  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.5678  Validation loss = 5.4774  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.5676  Validation loss = 5.4771  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.5674  Validation loss = 5.4769  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.5671  Validation loss = 5.4765  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.5670  Validation loss = 5.4763  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.5667  Validation loss = 5.4760  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.5665  Validation loss = 5.4757  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.5663  Validation loss = 5.4755  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.5661  Validation loss = 5.4752  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.5659  Validation loss = 5.4748  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.5657  Validation loss = 5.4746  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.5655  Validation loss = 5.4744  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.5653  Validation loss = 5.4741  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.5651  Validation loss = 5.4739  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.5649  Validation loss = 5.4736  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.5647  Validation loss = 5.4733  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.5645  Validation loss = 5.4730  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.5643  Validation loss = 5.4728  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.5641  Validation loss = 5.4726  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.5640  Validation loss = 5.4724  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.5638  Validation loss = 5.4721  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.5636  Validation loss = 5.4719  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.5634  Validation loss = 5.4716  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.5632  Validation loss = 5.4713  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.5630  Validation loss = 5.4711  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.5628  Validation loss = 5.4708  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.5626  Validation loss = 5.4705  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.5624  Validation loss = 5.4703  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.5622  Validation loss = 5.4701  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.5620  Validation loss = 5.4698  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.5618  Validation loss = 5.4695  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.5616  Validation loss = 5.4692  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.5614  Validation loss = 5.4690  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.5613  Validation loss = 5.4688  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.5611  Validation loss = 5.4686  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.5609  Validation loss = 5.4683  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.5607  Validation loss = 5.4681  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.5605  Validation loss = 5.4678  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.5603  Validation loss = 5.4676  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.5601  Validation loss = 5.4673  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.5599  Validation loss = 5.4671  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.5597  Validation loss = 5.4668  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.5596  Validation loss = 5.4666  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.5594  Validation loss = 5.4664  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.5592  Validation loss = 5.4662  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.5590  Validation loss = 5.4659  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.5588  Validation loss = 5.4656  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.5586  Validation loss = 5.4654  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.5584  Validation loss = 5.4651  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.5583  Validation loss = 5.4649  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.5581  Validation loss = 5.4647  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.5579  Validation loss = 5.4644  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.5577  Validation loss = 5.4642  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.5575  Validation loss = 5.4640  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.5573  Validation loss = 5.4637  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.5572  Validation loss = 5.4635  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.5569  Validation loss = 5.4632  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.5568  Validation loss = 5.4630  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.5566  Validation loss = 5.4627  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.5564  Validation loss = 5.4625  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.5563  Validation loss = 5.4623  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.5560  Validation loss = 5.4620  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.5559  Validation loss = 5.4618  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.5557  Validation loss = 5.4616  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.5555  Validation loss = 5.4614  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.5553  Validation loss = 5.4611  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.5552  Validation loss = 5.4609  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.5550  Validation loss = 5.4607  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.5548  Validation loss = 5.4604  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.5546  Validation loss = 5.4602  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.5545  Validation loss = 5.4600  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.5543  Validation loss = 5.4598  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.5542  Validation loss = 5.4596  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.5540  Validation loss = 5.4594  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.5538  Validation loss = 5.4592  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.5536  Validation loss = 5.4589  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.5534  Validation loss = 5.4587  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.5532  Validation loss = 5.4584  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.5531  Validation loss = 5.4581  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.5529  Validation loss = 5.4579  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.5526  Validation loss = 5.4576  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.5525  Validation loss = 5.4574  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.5523  Validation loss = 5.4571  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.5521  Validation loss = 5.4568  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.5519  Validation loss = 5.4566  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.5518  Validation loss = 5.4564  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.5516  Validation loss = 5.4562  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.5514  Validation loss = 5.4559  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.5512  Validation loss = 5.4557  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.5511  Validation loss = 5.4555  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.5508  Validation loss = 5.4552  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.5507  Validation loss = 5.4549  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.5505  Validation loss = 5.4547  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.5503  Validation loss = 5.4544  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.5501  Validation loss = 5.4542  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.5499  Validation loss = 5.4539  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.5497  Validation loss = 5.4537  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.5495  Validation loss = 5.4535  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.5493  Validation loss = 5.4532  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.5492  Validation loss = 5.4530  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.5490  Validation loss = 5.4527  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.5488  Validation loss = 5.4524  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.5486  Validation loss = 5.4522  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.5484  Validation loss = 5.4520  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.5483  Validation loss = 5.4518  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.5481  Validation loss = 5.4515  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.5479  Validation loss = 5.4514  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.5478  Validation loss = 5.4512  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.5476  Validation loss = 5.4509  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.5474  Validation loss = 5.4507  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.5472  Validation loss = 5.4504  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.5471  Validation loss = 5.4503  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.5469  Validation loss = 5.4500  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.5467  Validation loss = 5.4498  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.5465  Validation loss = 5.4495  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.5463  Validation loss = 5.4492  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.5461  Validation loss = 5.4490  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.5459  Validation loss = 5.4487  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.5458  Validation loss = 5.4485  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.5456  Validation loss = 5.4483  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.5454  Validation loss = 5.4481  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.5453  Validation loss = 5.4479  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.5451  Validation loss = 5.4476  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.5450  Validation loss = 5.4474  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.5448  Validation loss = 5.4472  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.5446  Validation loss = 5.4470  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.8779  Validation loss = 3.2838  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.8776  Validation loss = 3.2834  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.8774  Validation loss = 3.2831  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.8772  Validation loss = 3.2827  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.8769  Validation loss = 3.2824  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.8767  Validation loss = 3.2820  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.8765  Validation loss = 3.2817  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.8763  Validation loss = 3.2814  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.8761  Validation loss = 3.2810  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.8758  Validation loss = 3.2806  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.8756  Validation loss = 3.2803  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.8753  Validation loss = 3.2799  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.8751  Validation loss = 3.2796  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.8748  Validation loss = 3.2792  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.8746  Validation loss = 3.2788  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.8744  Validation loss = 3.2784  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.8742  Validation loss = 3.2781  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.8739  Validation loss = 3.2778  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.8736  Validation loss = 3.2773  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.8734  Validation loss = 3.2770  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.8732  Validation loss = 3.2766  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.8730  Validation loss = 3.2763  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.8728  Validation loss = 3.2760  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.8726  Validation loss = 3.2757  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.8724  Validation loss = 3.2754  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.8721  Validation loss = 3.2750  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.8719  Validation loss = 3.2746  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.8716  Validation loss = 3.2742  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.8714  Validation loss = 3.2738  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.8711  Validation loss = 3.2735  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.8709  Validation loss = 3.2731  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.8707  Validation loss = 3.2728  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.8705  Validation loss = 3.2724  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.8702  Validation loss = 3.2721  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.8700  Validation loss = 3.2718  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.8698  Validation loss = 3.2714  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.8696  Validation loss = 3.2711  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.8693  Validation loss = 3.2707  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.8691  Validation loss = 3.2704  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.8689  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.8687  Validation loss = 3.2697  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.8684  Validation loss = 3.2693  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.8682  Validation loss = 3.2690  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.8680  Validation loss = 3.2687  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.8678  Validation loss = 3.2683  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.8676  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.8674  Validation loss = 3.2677  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.8671  Validation loss = 3.2673  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.8669  Validation loss = 3.2669  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.8666  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.8664  Validation loss = 3.2662  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.8662  Validation loss = 3.2660  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.8661  Validation loss = 3.2657  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.8659  Validation loss = 3.2654  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.8656  Validation loss = 3.2650  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.8654  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.8652  Validation loss = 3.2644  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.8650  Validation loss = 3.2640  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.8647  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.8645  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.8643  Validation loss = 3.2630  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.8641  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.8638  Validation loss = 3.2623  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.8636  Validation loss = 3.2619  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.8634  Validation loss = 3.2616  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.8632  Validation loss = 3.2613  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.8630  Validation loss = 3.2610  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.8628  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.8626  Validation loss = 3.2605  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.8624  Validation loss = 3.2601  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.8622  Validation loss = 3.2598  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.8619  Validation loss = 3.2594  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.8617  Validation loss = 3.2591  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.8615  Validation loss = 3.2587  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.8613  Validation loss = 3.2584  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.8611  Validation loss = 3.2580  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.8608  Validation loss = 3.2577  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.8606  Validation loss = 3.2573  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.8604  Validation loss = 3.2570  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.8602  Validation loss = 3.2567  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.8600  Validation loss = 3.2564  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.8597  Validation loss = 3.2560  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.8595  Validation loss = 3.2557  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.8593  Validation loss = 3.2553  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.8590  Validation loss = 3.2549  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.8588  Validation loss = 3.2545  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.8586  Validation loss = 3.2542  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.8583  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.8581  Validation loss = 3.2535  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.8579  Validation loss = 3.2531  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.8576  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.8574  Validation loss = 3.2525  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.8572  Validation loss = 3.2521  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.8570  Validation loss = 3.2518  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.8567  Validation loss = 3.2514  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.8565  Validation loss = 3.2510  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.8563  Validation loss = 3.2506  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.8561  Validation loss = 3.2503  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.8558  Validation loss = 3.2500  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.8556  Validation loss = 3.2497  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.8554  Validation loss = 3.2493  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.8551  Validation loss = 3.2489  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.8549  Validation loss = 3.2486  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.8547  Validation loss = 3.2483  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.8545  Validation loss = 3.2479  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.8542  Validation loss = 3.2476  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.8540  Validation loss = 3.2472  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.8538  Validation loss = 3.2469  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.8536  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.8534  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.8531  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.8529  Validation loss = 3.2455  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.8527  Validation loss = 3.2452  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.8525  Validation loss = 3.2448  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.8522  Validation loss = 3.2444  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.8520  Validation loss = 3.2441  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.8518  Validation loss = 3.2438  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.8516  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.8514  Validation loss = 3.2431  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.8512  Validation loss = 3.2428  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.8509  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.8507  Validation loss = 3.2421  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.8505  Validation loss = 3.2418  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.8503  Validation loss = 3.2415  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.8501  Validation loss = 3.2411  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.8499  Validation loss = 3.2408  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.8497  Validation loss = 3.2405  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.8495  Validation loss = 3.2402  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.8493  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.8490  Validation loss = 3.2395  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.8488  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.8485  Validation loss = 3.2388  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.8483  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.8481  Validation loss = 3.2382  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.8479  Validation loss = 3.2378  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.8476  Validation loss = 3.2374  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.8474  Validation loss = 3.2371  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.8472  Validation loss = 3.2367  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.8470  Validation loss = 3.2364  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.8468  Validation loss = 3.2361  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.8466  Validation loss = 3.2357  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.8463  Validation loss = 3.2353  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.8461  Validation loss = 3.2349  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.8459  Validation loss = 3.2346  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.8456  Validation loss = 3.2343  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.8454  Validation loss = 3.2340  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.8452  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.8450  Validation loss = 3.2332  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.8447  Validation loss = 3.2329  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.8445  Validation loss = 3.2325  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.8443  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.8441  Validation loss = 3.2319  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.8439  Validation loss = 3.2316  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.8437  Validation loss = 3.2313  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.8435  Validation loss = 3.2310  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.8433  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.8430  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.8428  Validation loss = 3.2300  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.8426  Validation loss = 3.2296  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.8424  Validation loss = 3.2292  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.8422  Validation loss = 3.2289  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.8419  Validation loss = 3.2286  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.8418  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.8415  Validation loss = 3.2279  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.8413  Validation loss = 3.2276  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.8411  Validation loss = 3.2272  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.8409  Validation loss = 3.2269  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.8407  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.8404  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.8402  Validation loss = 3.2259  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.8400  Validation loss = 3.2256  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.8399  Validation loss = 3.2253  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.8396  Validation loss = 3.2250  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.8395  Validation loss = 3.2247  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.8393  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.8390  Validation loss = 3.2241  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.8388  Validation loss = 3.2238  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.8386  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.8384  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.8381  Validation loss = 3.2226  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.8380  Validation loss = 3.2224  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.8377  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.8376  Validation loss = 3.2218  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.8373  Validation loss = 3.2214  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.8371  Validation loss = 3.2211  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.8369  Validation loss = 3.2208  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.8368  Validation loss = 3.2206  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.8366  Validation loss = 3.2202  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.8364  Validation loss = 3.2200  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.8362  Validation loss = 3.2196  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.8360  Validation loss = 3.2193  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.8357  Validation loss = 3.2190  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.8356  Validation loss = 3.2187  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.8353  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.8351  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.8349  Validation loss = 3.2177  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.8347  Validation loss = 3.2173  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.8345  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.8343  Validation loss = 3.2168  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.8341  Validation loss = 3.2164  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.8339  Validation loss = 3.2161  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.8336  Validation loss = 3.2158  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.8335  Validation loss = 3.2155  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.8332  Validation loss = 3.2151  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.8330  Validation loss = 3.2147  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.8328  Validation loss = 3.2144  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.8325  Validation loss = 3.2140  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.8323  Validation loss = 3.2138  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.8321  Validation loss = 3.2134  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.8319  Validation loss = 3.2131  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.8317  Validation loss = 3.2128  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.8315  Validation loss = 3.2125  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.8313  Validation loss = 3.2121  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.8310  Validation loss = 3.2117  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.8309  Validation loss = 3.2114  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.8307  Validation loss = 3.2111  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.8304  Validation loss = 3.2107  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.8302  Validation loss = 3.2104  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.8300  Validation loss = 3.2100  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.8297  Validation loss = 3.2097  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.8295  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.8293  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.8290  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.8288  Validation loss = 3.2082  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.8286  Validation loss = 3.2079  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.8283  Validation loss = 3.2075  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.8281  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.8279  Validation loss = 3.2068  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.8277  Validation loss = 3.2065  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.8275  Validation loss = 3.2062  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.8273  Validation loss = 3.2058  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.8271  Validation loss = 3.2055  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.8268  Validation loss = 3.2051  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.8266  Validation loss = 3.2048  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.8264  Validation loss = 3.2045  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.8261  Validation loss = 3.2041  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.8259  Validation loss = 3.2037  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.8258  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.8255  Validation loss = 3.2031  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.8253  Validation loss = 3.2028  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.8251  Validation loss = 3.2025  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.8249  Validation loss = 3.2022  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.8247  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.8245  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.8243  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.8241  Validation loss = 3.2009  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.8239  Validation loss = 3.2006  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.8237  Validation loss = 3.2002  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.8235  Validation loss = 3.1999  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.8233  Validation loss = 3.1996  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.8231  Validation loss = 3.1994  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.8229  Validation loss = 3.1990  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.8227  Validation loss = 3.1987  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.8225  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.8223  Validation loss = 3.1981  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.8221  Validation loss = 3.1978  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.8219  Validation loss = 3.1974  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.8216  Validation loss = 3.1970  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.8214  Validation loss = 3.1967  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.8212  Validation loss = 3.1964  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.8209  Validation loss = 3.1959  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.8207  Validation loss = 3.1956  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.8205  Validation loss = 3.1953  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.8203  Validation loss = 3.1949  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.8201  Validation loss = 3.1946  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.8198  Validation loss = 3.1942  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.8197  Validation loss = 3.1940  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.8195  Validation loss = 3.1937  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.8193  Validation loss = 3.1934  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.8191  Validation loss = 3.1931  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.8189  Validation loss = 3.1928  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.8187  Validation loss = 3.1924  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.8185  Validation loss = 3.1921  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.8183  Validation loss = 3.1919  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.8181  Validation loss = 3.1915  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.8179  Validation loss = 3.1912  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.8177  Validation loss = 3.1909  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.8174  Validation loss = 3.1905  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.8172  Validation loss = 3.1902  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.8170  Validation loss = 3.1898  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.8168  Validation loss = 3.1895  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.8166  Validation loss = 3.1892  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.8164  Validation loss = 3.1889  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.8162  Validation loss = 3.1885  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.8160  Validation loss = 3.1882  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.8158  Validation loss = 3.1879  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.8156  Validation loss = 3.1876  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.8154  Validation loss = 3.1874  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.8152  Validation loss = 3.1870  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.8150  Validation loss = 3.1867  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.8148  Validation loss = 3.1863  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.8146  Validation loss = 3.1860  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.8144  Validation loss = 3.1858  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.8142  Validation loss = 3.1855  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.8140  Validation loss = 3.1851  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.8138  Validation loss = 3.1848  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.8136  Validation loss = 3.1844  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.8134  Validation loss = 3.1841  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.8132  Validation loss = 3.1839  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.8130  Validation loss = 3.1835  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.8128  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.8125  Validation loss = 3.1828  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.8123  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.8121  Validation loss = 3.1822  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.8119  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.8116  Validation loss = 3.1814  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.8114  Validation loss = 3.1811  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.8112  Validation loss = 3.1808  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.8111  Validation loss = 3.1805  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.8109  Validation loss = 3.1802  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.8107  Validation loss = 3.1800  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.8104  Validation loss = 3.1795  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.8102  Validation loss = 3.1791  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.8100  Validation loss = 3.1788  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.8098  Validation loss = 3.1786  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.8096  Validation loss = 3.1782  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.8094  Validation loss = 3.1779  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.8092  Validation loss = 3.1775  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.8090  Validation loss = 3.1773  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.8088  Validation loss = 3.1769  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.8086  Validation loss = 3.1766  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.8083  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.8081  Validation loss = 3.1758  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.8079  Validation loss = 3.1755  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.8077  Validation loss = 3.1752  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.8075  Validation loss = 3.1749  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.8073  Validation loss = 3.1746  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.8071  Validation loss = 3.1742  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.8068  Validation loss = 3.1738  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.8066  Validation loss = 3.1735  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.8064  Validation loss = 3.1732  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.8062  Validation loss = 3.1729  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.8060  Validation loss = 3.1726  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.8058  Validation loss = 3.1723  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.8056  Validation loss = 3.1719  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.8054  Validation loss = 3.1716  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.8052  Validation loss = 3.1713  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.8050  Validation loss = 3.1710  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.8048  Validation loss = 3.1707  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.8046  Validation loss = 3.1704  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.8044  Validation loss = 3.1700  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.8041  Validation loss = 3.1696  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.8039  Validation loss = 3.1693  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.8037  Validation loss = 3.1690  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.8035  Validation loss = 3.1687  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.8033  Validation loss = 3.1684  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.8031  Validation loss = 3.1680  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.8030  Validation loss = 3.1678  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.8028  Validation loss = 3.1675  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.8026  Validation loss = 3.1671  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.8023  Validation loss = 3.1668  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.8022  Validation loss = 3.1665  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.8020  Validation loss = 3.1663  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.8017  Validation loss = 3.1658  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.8015  Validation loss = 3.1655  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.8013  Validation loss = 3.1651  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.8011  Validation loss = 3.1648  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.8009  Validation loss = 3.1645  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.8007  Validation loss = 3.1642  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.8004  Validation loss = 3.1638  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.8003  Validation loss = 3.1635  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.8001  Validation loss = 3.1632  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.7999  Validation loss = 3.1629  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.7997  Validation loss = 3.1626  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.7995  Validation loss = 3.1622  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.7993  Validation loss = 3.1619  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.7991  Validation loss = 3.1616  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.7989  Validation loss = 3.1613  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.7987  Validation loss = 3.1610  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.7985  Validation loss = 3.1607  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.7982  Validation loss = 3.1603  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.7981  Validation loss = 3.1600  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.7979  Validation loss = 3.1598  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.7977  Validation loss = 3.1594  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.7975  Validation loss = 3.1591  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.7973  Validation loss = 3.1588  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.7971  Validation loss = 3.1585  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.7969  Validation loss = 3.1582  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.7967  Validation loss = 3.1579  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.7965  Validation loss = 3.1575  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.7963  Validation loss = 3.1572  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.7961  Validation loss = 3.1569  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.7958  Validation loss = 3.1565  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.7957  Validation loss = 3.1562  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.7955  Validation loss = 3.1560  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.7953  Validation loss = 3.1557  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.7951  Validation loss = 3.1554  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.7949  Validation loss = 3.1550  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.7947  Validation loss = 3.1547  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.7945  Validation loss = 3.1544  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.7943  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.7941  Validation loss = 3.1538  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.7939  Validation loss = 3.1535  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.7937  Validation loss = 3.1531  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.7935  Validation loss = 3.1529  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.7934  Validation loss = 3.1526  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.7932  Validation loss = 3.1523  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.7929  Validation loss = 3.1519  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.7927  Validation loss = 3.1516  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.7925  Validation loss = 3.1512  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.7923  Validation loss = 3.1509  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.7921  Validation loss = 3.1506  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.7920  Validation loss = 3.1504  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.7918  Validation loss = 3.1501  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.7915  Validation loss = 3.1497  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.7914  Validation loss = 3.1495  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.7912  Validation loss = 3.1492  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.7910  Validation loss = 3.1488  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.7908  Validation loss = 3.1485  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.7906  Validation loss = 3.1483  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.7904  Validation loss = 3.1480  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.7902  Validation loss = 3.1476  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.7900  Validation loss = 3.1473  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.7898  Validation loss = 3.1470  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.7896  Validation loss = 3.1467  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.7894  Validation loss = 3.1464  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.7892  Validation loss = 3.1460  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.7890  Validation loss = 3.1457  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.7888  Validation loss = 3.1454  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.7886  Validation loss = 3.1450  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.7884  Validation loss = 3.1447  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.7882  Validation loss = 3.1444  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.7880  Validation loss = 3.1441  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.7877  Validation loss = 3.1437  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.7876  Validation loss = 3.1434  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.7874  Validation loss = 3.1431  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.7871  Validation loss = 3.1428  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.7869  Validation loss = 3.1424  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.7867  Validation loss = 3.1421  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.7865  Validation loss = 3.1418  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.7863  Validation loss = 3.1415  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.7861  Validation loss = 3.1411  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.7859  Validation loss = 3.1408  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.7857  Validation loss = 3.1404  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.7854  Validation loss = 3.1401  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.7852  Validation loss = 3.1397  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.7850  Validation loss = 3.1394  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.7848  Validation loss = 3.1391  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.7846  Validation loss = 3.1387  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.7844  Validation loss = 3.1384  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.7842  Validation loss = 3.1381  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.7840  Validation loss = 3.1378  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.7838  Validation loss = 3.1374  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.7836  Validation loss = 3.1371  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.7834  Validation loss = 3.1369  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.7832  Validation loss = 3.1366  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.7831  Validation loss = 3.1363  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.7829  Validation loss = 3.1360  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.7826  Validation loss = 3.1356  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.7825  Validation loss = 3.1354  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.7823  Validation loss = 3.1351  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.7821  Validation loss = 3.1348  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.7819  Validation loss = 3.1345  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.7817  Validation loss = 3.1341  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.7815  Validation loss = 3.1338  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.7813  Validation loss = 3.1334  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.7811  Validation loss = 3.1332  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.7809  Validation loss = 3.1328  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.7807  Validation loss = 3.1325  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.7805  Validation loss = 3.1322  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.7803  Validation loss = 3.1318  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.7801  Validation loss = 3.1316  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.7799  Validation loss = 3.1313  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.7797  Validation loss = 3.1309  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.7796  Validation loss = 3.1307  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.7794  Validation loss = 3.1304  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.7792  Validation loss = 3.1301  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.7790  Validation loss = 3.1298  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.7788  Validation loss = 3.1295  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.7786  Validation loss = 3.1292  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.7785  Validation loss = 3.1290  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.7783  Validation loss = 3.1287  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.7781  Validation loss = 3.1284  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.7779  Validation loss = 3.1281  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.7777  Validation loss = 3.1278  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.7775  Validation loss = 3.1275  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.7773  Validation loss = 3.1272  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.7772  Validation loss = 3.1269  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.7770  Validation loss = 3.1266  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.7768  Validation loss = 3.1263  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.7765  Validation loss = 3.1259  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.7763  Validation loss = 3.1255  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.7762  Validation loss = 3.1253  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.7760  Validation loss = 3.1250  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.7758  Validation loss = 3.1248  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.7756  Validation loss = 3.1244  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.7754  Validation loss = 3.1241  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.7752  Validation loss = 3.1238  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.7750  Validation loss = 3.1234  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.7748  Validation loss = 3.1231  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.7747  Validation loss = 3.1229  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.7744  Validation loss = 3.1225  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.7742  Validation loss = 3.1222  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.7740  Validation loss = 3.1219  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.7739  Validation loss = 3.1216  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.7737  Validation loss = 3.1213  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.7735  Validation loss = 3.1210  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.7733  Validation loss = 3.1207  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.7731  Validation loss = 3.1204  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.7729  Validation loss = 3.1200  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.8657  Validation loss = 2.8355  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.8654  Validation loss = 2.8352  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.8652  Validation loss = 2.8349  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.8649  Validation loss = 2.8345  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.8646  Validation loss = 2.8341  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.8644  Validation loss = 2.8337  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.8641  Validation loss = 2.8334  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.8639  Validation loss = 2.8330  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.8637  Validation loss = 2.8328  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.8635  Validation loss = 2.8325  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.8633  Validation loss = 2.8322  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.8631  Validation loss = 2.8319  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.8628  Validation loss = 2.8316  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.8626  Validation loss = 2.8312  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.8623  Validation loss = 2.8308  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.8620  Validation loss = 2.8304  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.8618  Validation loss = 2.8301  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.8615  Validation loss = 2.8297  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.8613  Validation loss = 2.8294  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.8610  Validation loss = 2.8290  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.8608  Validation loss = 2.8287  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.8606  Validation loss = 2.8284  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.8603  Validation loss = 2.8281  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.8601  Validation loss = 2.8277  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.8599  Validation loss = 2.8274  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.8596  Validation loss = 2.8271  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.8594  Validation loss = 2.8268  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.8592  Validation loss = 2.8264  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.8589  Validation loss = 2.8261  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.8587  Validation loss = 2.8257  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.8585  Validation loss = 2.8254  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.8582  Validation loss = 2.8251  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.8580  Validation loss = 2.8248  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.8578  Validation loss = 2.8245  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.8576  Validation loss = 2.8242  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.8574  Validation loss = 2.8239  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.8571  Validation loss = 2.8235  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.8569  Validation loss = 2.8232  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.8566  Validation loss = 2.8228  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.8564  Validation loss = 2.8225  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.8561  Validation loss = 2.8221  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.8559  Validation loss = 2.8218  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.8557  Validation loss = 2.8215  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.8554  Validation loss = 2.8211  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.8551  Validation loss = 2.8207  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.8549  Validation loss = 2.8204  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.8546  Validation loss = 2.8200  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.8544  Validation loss = 2.8197  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.8542  Validation loss = 2.8194  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.8539  Validation loss = 2.8190  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.8537  Validation loss = 2.8187  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.8535  Validation loss = 2.8184  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.8532  Validation loss = 2.8181  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.8530  Validation loss = 2.8177  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.8527  Validation loss = 2.8173  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.8525  Validation loss = 2.8170  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.8522  Validation loss = 2.8167  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.8520  Validation loss = 2.8163  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.8517  Validation loss = 2.8160  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.8515  Validation loss = 2.8157  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.8512  Validation loss = 2.8153  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.8510  Validation loss = 2.8149  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.8507  Validation loss = 2.8146  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.8505  Validation loss = 2.8143  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.8503  Validation loss = 2.8139  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.8500  Validation loss = 2.8135  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.8498  Validation loss = 2.8132  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.8495  Validation loss = 2.8129  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.8493  Validation loss = 2.8125  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.8490  Validation loss = 2.8122  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.8487  Validation loss = 2.8118  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.8485  Validation loss = 2.8115  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.8482  Validation loss = 2.8111  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.8480  Validation loss = 2.8107  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.8478  Validation loss = 2.8104  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.8475  Validation loss = 2.8101  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.8472  Validation loss = 2.8097  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.8470  Validation loss = 2.8094  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.8468  Validation loss = 2.8090  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.8466  Validation loss = 2.8088  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.8464  Validation loss = 2.8084  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.8461  Validation loss = 2.8081  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.8459  Validation loss = 2.8078  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.8457  Validation loss = 2.8075  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.8454  Validation loss = 2.8071  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.8452  Validation loss = 2.8068  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.8450  Validation loss = 2.8065  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.8447  Validation loss = 2.8062  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.8445  Validation loss = 2.8058  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.8443  Validation loss = 2.8055  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.8440  Validation loss = 2.8052  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.8438  Validation loss = 2.8049  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.8436  Validation loss = 2.8046  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.8435  Validation loss = 2.8044  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.8432  Validation loss = 2.8041  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.8430  Validation loss = 2.8038  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.8428  Validation loss = 2.8034  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.8426  Validation loss = 2.8031  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.8424  Validation loss = 2.8029  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.8421  Validation loss = 2.8025  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.8419  Validation loss = 2.8022  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.8417  Validation loss = 2.8019  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.8415  Validation loss = 2.8016  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.8413  Validation loss = 2.8013  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.8410  Validation loss = 2.8009  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.8408  Validation loss = 2.8006  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.8405  Validation loss = 2.8003  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.8402  Validation loss = 2.7999  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.8400  Validation loss = 2.7995  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.8397  Validation loss = 2.7991  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.8394  Validation loss = 2.7988  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.8392  Validation loss = 2.7984  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.8390  Validation loss = 2.7981  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.8387  Validation loss = 2.7977  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.8385  Validation loss = 2.7974  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.8383  Validation loss = 2.7971  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.8380  Validation loss = 2.7967  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.8378  Validation loss = 2.7964  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.8375  Validation loss = 2.7960  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.8372  Validation loss = 2.7956  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.8370  Validation loss = 2.7954  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.8368  Validation loss = 2.7950  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.8366  Validation loss = 2.7947  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.8364  Validation loss = 2.7944  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.8361  Validation loss = 2.7941  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.8359  Validation loss = 2.7937  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.8356  Validation loss = 2.7933  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.8353  Validation loss = 2.7929  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.8351  Validation loss = 2.7927  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.8349  Validation loss = 2.7923  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.8346  Validation loss = 2.7920  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.8344  Validation loss = 2.7917  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.8342  Validation loss = 2.7914  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.8340  Validation loss = 2.7911  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.8337  Validation loss = 2.7907  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.8335  Validation loss = 2.7904  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.8332  Validation loss = 2.7901  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.8330  Validation loss = 2.7898  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.8328  Validation loss = 2.7895  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.8326  Validation loss = 2.7891  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.8323  Validation loss = 2.7888  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.8321  Validation loss = 2.7884  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.8318  Validation loss = 2.7880  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.8316  Validation loss = 2.7877  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.8313  Validation loss = 2.7873  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.8311  Validation loss = 2.7871  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.8309  Validation loss = 2.7867  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.8307  Validation loss = 2.7864  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.8304  Validation loss = 2.7861  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.8302  Validation loss = 2.7857  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.8299  Validation loss = 2.7854  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.8297  Validation loss = 2.7851  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.8295  Validation loss = 2.7848  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.8293  Validation loss = 2.7844  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.8290  Validation loss = 2.7841  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.8288  Validation loss = 2.7838  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.8286  Validation loss = 2.7835  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.8284  Validation loss = 2.7832  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.8282  Validation loss = 2.7829  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.8280  Validation loss = 2.7827  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.8277  Validation loss = 2.7823  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.8275  Validation loss = 2.7820  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.8273  Validation loss = 2.7816  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.8271  Validation loss = 2.7813  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.8268  Validation loss = 2.7810  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.8266  Validation loss = 2.7807  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.8264  Validation loss = 2.7804  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.8262  Validation loss = 2.7801  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.8259  Validation loss = 2.7797  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.8256  Validation loss = 2.7793  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.8254  Validation loss = 2.7790  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.8251  Validation loss = 2.7786  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.8249  Validation loss = 2.7783  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.8247  Validation loss = 2.7780  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.8245  Validation loss = 2.7777  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.8243  Validation loss = 2.7774  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.8240  Validation loss = 2.7770  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.8238  Validation loss = 2.7767  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.8235  Validation loss = 2.7764  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.8233  Validation loss = 2.7761  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.8231  Validation loss = 2.7757  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.8229  Validation loss = 2.7754  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.8227  Validation loss = 2.7751  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.8224  Validation loss = 2.7748  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.8222  Validation loss = 2.7744  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.8219  Validation loss = 2.7741  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.8217  Validation loss = 2.7738  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.8214  Validation loss = 2.7734  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.8212  Validation loss = 2.7730  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.8210  Validation loss = 2.7727  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.8208  Validation loss = 2.7725  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.8205  Validation loss = 2.7721  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.8202  Validation loss = 2.7716  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.8199  Validation loss = 2.7713  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.8197  Validation loss = 2.7709  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.8195  Validation loss = 2.7706  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.8192  Validation loss = 2.7702  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.8189  Validation loss = 2.7698  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.8187  Validation loss = 2.7695  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.8185  Validation loss = 2.7693  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.8183  Validation loss = 2.7689  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.8181  Validation loss = 2.7687  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.8179  Validation loss = 2.7683  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.8176  Validation loss = 2.7680  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.8174  Validation loss = 2.7677  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.8172  Validation loss = 2.7674  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.8170  Validation loss = 2.7671  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.8167  Validation loss = 2.7667  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.8165  Validation loss = 2.7664  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.8163  Validation loss = 2.7661  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.8160  Validation loss = 2.7657  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.8158  Validation loss = 2.7654  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.8156  Validation loss = 2.7651  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.8154  Validation loss = 2.7648  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.8152  Validation loss = 2.7646  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.8150  Validation loss = 2.7642  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.8147  Validation loss = 2.7639  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.8145  Validation loss = 2.7635  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.8143  Validation loss = 2.7633  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.8141  Validation loss = 2.7630  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.8138  Validation loss = 2.7626  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.8136  Validation loss = 2.7623  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.8133  Validation loss = 2.7619  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.8131  Validation loss = 2.7616  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.8129  Validation loss = 2.7613  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.8127  Validation loss = 2.7610  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.8125  Validation loss = 2.7607  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.8122  Validation loss = 2.7604  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.8121  Validation loss = 2.7602  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.8119  Validation loss = 2.7599  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.8116  Validation loss = 2.7595  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.8114  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.8111  Validation loss = 2.7589  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.8109  Validation loss = 2.7585  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.8106  Validation loss = 2.7581  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.8104  Validation loss = 2.7578  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.8101  Validation loss = 2.7574  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.8099  Validation loss = 2.7571  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.8097  Validation loss = 2.7568  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.8094  Validation loss = 2.7564  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.8092  Validation loss = 2.7560  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.8089  Validation loss = 2.7557  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.8087  Validation loss = 2.7554  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.8085  Validation loss = 2.7551  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.8082  Validation loss = 2.7547  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.8080  Validation loss = 2.7544  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.8078  Validation loss = 2.7541  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.8076  Validation loss = 2.7538  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.8074  Validation loss = 2.7535  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.8071  Validation loss = 2.7532  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.8069  Validation loss = 2.7528  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.8066  Validation loss = 2.7525  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.8064  Validation loss = 2.7521  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.8062  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.8059  Validation loss = 2.7514  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.8057  Validation loss = 2.7511  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.8054  Validation loss = 2.7507  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.8052  Validation loss = 2.7504  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.8049  Validation loss = 2.7501  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.8047  Validation loss = 2.7498  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.8045  Validation loss = 2.7495  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.8043  Validation loss = 2.7491  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.8041  Validation loss = 2.7489  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.8038  Validation loss = 2.7485  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.8036  Validation loss = 2.7481  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.8033  Validation loss = 2.7478  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.8031  Validation loss = 2.7474  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.8028  Validation loss = 2.7471  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.8026  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.8024  Validation loss = 2.7464  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.8021  Validation loss = 2.7461  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.8019  Validation loss = 2.7458  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.8017  Validation loss = 2.7455  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.8015  Validation loss = 2.7451  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.8012  Validation loss = 2.7448  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.8010  Validation loss = 2.7445  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.8007  Validation loss = 2.7442  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.8005  Validation loss = 2.7438  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.8003  Validation loss = 2.7435  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.8000  Validation loss = 2.7431  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.7998  Validation loss = 2.7428  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.7995  Validation loss = 2.7424  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.7993  Validation loss = 2.7421  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.7990  Validation loss = 2.7417  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.7988  Validation loss = 2.7414  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.7985  Validation loss = 2.7410  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.7983  Validation loss = 2.7407  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.7981  Validation loss = 2.7404  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.7979  Validation loss = 2.7401  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.7977  Validation loss = 2.7398  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.7974  Validation loss = 2.7395  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.7972  Validation loss = 2.7391  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.7970  Validation loss = 2.7388  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.7967  Validation loss = 2.7385  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.7965  Validation loss = 2.7382  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.7963  Validation loss = 2.7379  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.7961  Validation loss = 2.7376  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.7959  Validation loss = 2.7373  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.7956  Validation loss = 2.7370  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.7954  Validation loss = 2.7367  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.7952  Validation loss = 2.7363  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.7950  Validation loss = 2.7360  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.7948  Validation loss = 2.7357  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.7945  Validation loss = 2.7353  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.7943  Validation loss = 2.7350  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.7940  Validation loss = 2.7347  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.7938  Validation loss = 2.7344  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.7936  Validation loss = 2.7340  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.7934  Validation loss = 2.7337  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.7931  Validation loss = 2.7334  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.7929  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.7927  Validation loss = 2.7328  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.7925  Validation loss = 2.7325  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.7923  Validation loss = 2.7322  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.7920  Validation loss = 2.7318  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.7918  Validation loss = 2.7315  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.7916  Validation loss = 2.7312  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.7914  Validation loss = 2.7310  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.7912  Validation loss = 2.7306  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.7910  Validation loss = 2.7303  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.7908  Validation loss = 2.7300  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.7905  Validation loss = 2.7297  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.7903  Validation loss = 2.7294  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.7901  Validation loss = 2.7292  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.7899  Validation loss = 2.7289  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.7897  Validation loss = 2.7286  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.7895  Validation loss = 2.7283  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.7892  Validation loss = 2.7279  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.7890  Validation loss = 2.7276  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.7888  Validation loss = 2.7273  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.7885  Validation loss = 2.7269  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.7883  Validation loss = 2.7265  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.7881  Validation loss = 2.7263  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.7879  Validation loss = 2.7260  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.7877  Validation loss = 2.7257  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.7875  Validation loss = 2.7254  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.7873  Validation loss = 2.7252  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.7871  Validation loss = 2.7249  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.7869  Validation loss = 2.7245  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.7866  Validation loss = 2.7242  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.7864  Validation loss = 2.7239  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.7862  Validation loss = 2.7235  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.7859  Validation loss = 2.7232  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.7857  Validation loss = 2.7229  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.7855  Validation loss = 2.7225  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.7853  Validation loss = 2.7223  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.7850  Validation loss = 2.7219  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.7848  Validation loss = 2.7216  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.7846  Validation loss = 2.7213  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.7844  Validation loss = 2.7210  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.7842  Validation loss = 2.7207  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.7840  Validation loss = 2.7205  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.7838  Validation loss = 2.7202  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.7836  Validation loss = 2.7198  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.7833  Validation loss = 2.7195  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.7831  Validation loss = 2.7191  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.7828  Validation loss = 2.7188  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.7826  Validation loss = 2.7185  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.7823  Validation loss = 2.7181  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.7821  Validation loss = 2.7177  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.7818  Validation loss = 2.7174  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.7816  Validation loss = 2.7171  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.7815  Validation loss = 2.7169  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.7812  Validation loss = 2.7165  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.7810  Validation loss = 2.7162  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.7807  Validation loss = 2.7158  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.7805  Validation loss = 2.7156  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.7803  Validation loss = 2.7152  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.7800  Validation loss = 2.7149  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.7799  Validation loss = 2.7146  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.7796  Validation loss = 2.7143  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.7794  Validation loss = 2.7141  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.7793  Validation loss = 2.7138  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.7791  Validation loss = 2.7135  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.7789  Validation loss = 2.7132  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.7787  Validation loss = 2.7129  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.7785  Validation loss = 2.7127  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.7782  Validation loss = 2.7123  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.7780  Validation loss = 2.7120  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.7778  Validation loss = 2.7117  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.7776  Validation loss = 2.7114  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.7773  Validation loss = 2.7111  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.7771  Validation loss = 2.7107  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.7769  Validation loss = 2.7104  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.7767  Validation loss = 2.7101  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.7765  Validation loss = 2.7098  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.7762  Validation loss = 2.7095  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.7760  Validation loss = 2.7091  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.7757  Validation loss = 2.7088  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.7755  Validation loss = 2.7085  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.7753  Validation loss = 2.7081  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.7751  Validation loss = 2.7078  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.7749  Validation loss = 2.7075  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.7746  Validation loss = 2.7072  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.7744  Validation loss = 2.7069  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.7742  Validation loss = 2.7066  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.7740  Validation loss = 2.7063  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.7737  Validation loss = 2.7059  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.7735  Validation loss = 2.7057  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.7733  Validation loss = 2.7053  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.7730  Validation loss = 2.7050  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.7728  Validation loss = 2.7046  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.7725  Validation loss = 2.7043  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.7723  Validation loss = 2.7040  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.7721  Validation loss = 2.7037  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.7720  Validation loss = 2.7034  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.7717  Validation loss = 2.7031  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.7715  Validation loss = 2.7028  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.7713  Validation loss = 2.7025  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.7711  Validation loss = 2.7022  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.7709  Validation loss = 2.7019  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.7706  Validation loss = 2.7016  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.7704  Validation loss = 2.7013  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.7702  Validation loss = 2.7009  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.7700  Validation loss = 2.7007  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.7698  Validation loss = 2.7003  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.7695  Validation loss = 2.7000  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.7693  Validation loss = 2.6997  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.7690  Validation loss = 2.6993  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.7688  Validation loss = 2.6989  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.7686  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.7684  Validation loss = 2.6983  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.7681  Validation loss = 2.6980  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.7680  Validation loss = 2.6977  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.7677  Validation loss = 2.6974  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.7675  Validation loss = 2.6970  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.7673  Validation loss = 2.6967  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.7671  Validation loss = 2.6964  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.7668  Validation loss = 2.6961  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.7666  Validation loss = 2.6958  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.7664  Validation loss = 2.6955  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.7662  Validation loss = 2.6952  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.7660  Validation loss = 2.6949  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.7657  Validation loss = 2.6946  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.7656  Validation loss = 2.6943  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.7653  Validation loss = 2.6939  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.7651  Validation loss = 2.6937  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.7649  Validation loss = 2.6933  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.7647  Validation loss = 2.6930  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.7645  Validation loss = 2.6928  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.7643  Validation loss = 2.6925  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.7641  Validation loss = 2.6923  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.7639  Validation loss = 2.6919  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.7636  Validation loss = 2.6916  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.7634  Validation loss = 2.6912  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.7632  Validation loss = 2.6910  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.7630  Validation loss = 2.6907  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.7628  Validation loss = 2.6904  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.7626  Validation loss = 2.6900  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.7623  Validation loss = 2.6897  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.7621  Validation loss = 2.6894  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.7619  Validation loss = 2.6891  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.7617  Validation loss = 2.6888  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.7615  Validation loss = 2.6884  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.7612  Validation loss = 2.6881  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.7609  Validation loss = 2.6877  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.7607  Validation loss = 2.6874  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.7605  Validation loss = 2.6871  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.7603  Validation loss = 2.6868  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.7600  Validation loss = 2.6864  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.7598  Validation loss = 2.6861  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.7596  Validation loss = 2.6858  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.7594  Validation loss = 2.6855  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.7591  Validation loss = 2.6851  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.7589  Validation loss = 2.6848  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.7587  Validation loss = 2.6845  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.7585  Validation loss = 2.6842  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.7582  Validation loss = 2.6839  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.7580  Validation loss = 2.6835  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.7578  Validation loss = 2.6833  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.7576  Validation loss = 2.6830  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.7573  Validation loss = 2.6826  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.7571  Validation loss = 2.6822  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.7568  Validation loss = 2.6819  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.7566  Validation loss = 2.6815  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.7564  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.7561  Validation loss = 2.6809  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.7559  Validation loss = 2.6806  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.7557  Validation loss = 2.6803  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.7555  Validation loss = 2.6800  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.7553  Validation loss = 2.6797  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.7551  Validation loss = 2.6794  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.7549  Validation loss = 2.6791  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.7547  Validation loss = 2.6788  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.7544  Validation loss = 2.6784  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.7542  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.7540  Validation loss = 2.6778  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.7538  Validation loss = 2.6776  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.7536  Validation loss = 2.6772  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.7533  Validation loss = 2.6768  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.7531  Validation loss = 2.6765  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.7529  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.7527  Validation loss = 2.6760  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.7525  Validation loss = 2.6757  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.7523  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.7521  Validation loss = 2.6751  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.7519  Validation loss = 2.6748  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.7516  Validation loss = 2.6744  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.7514  Validation loss = 2.6742  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.7512  Validation loss = 2.6738  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.7770  Validation loss = 7.8063  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.7768  Validation loss = 7.8061  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.7766  Validation loss = 7.8057  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.7763  Validation loss = 7.8054  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.7761  Validation loss = 7.8050  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.7759  Validation loss = 7.8047  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.7756  Validation loss = 7.8044  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.7754  Validation loss = 7.8041  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.7752  Validation loss = 7.8038  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.7750  Validation loss = 7.8035  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.7748  Validation loss = 7.8032  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.7745  Validation loss = 7.8028  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.7742  Validation loss = 7.8025  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.7740  Validation loss = 7.8021  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.7738  Validation loss = 7.8018  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.7735  Validation loss = 7.8015  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.7733  Validation loss = 7.8012  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.7731  Validation loss = 7.8009  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.7729  Validation loss = 7.8007  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.7727  Validation loss = 7.8004  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.7724  Validation loss = 7.8000  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.7722  Validation loss = 7.7997  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.7720  Validation loss = 7.7994  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.7717  Validation loss = 7.7991  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.7715  Validation loss = 7.7987  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.7712  Validation loss = 7.7984  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.7710  Validation loss = 7.7981  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.7707  Validation loss = 7.7977  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.7705  Validation loss = 7.7974  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.7702  Validation loss = 7.7970  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.7700  Validation loss = 7.7967  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.7697  Validation loss = 7.7963  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.7695  Validation loss = 7.7960  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.7692  Validation loss = 7.7957  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.7690  Validation loss = 7.7953  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.7687  Validation loss = 7.7950  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.7684  Validation loss = 7.7946  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.7682  Validation loss = 7.7943  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.7680  Validation loss = 7.7939  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.7677  Validation loss = 7.7936  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.7675  Validation loss = 7.7933  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.7672  Validation loss = 7.7929  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.7670  Validation loss = 7.7926  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.7668  Validation loss = 7.7923  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.7666  Validation loss = 7.7921  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.7664  Validation loss = 7.7918  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.7661  Validation loss = 7.7914  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.7659  Validation loss = 7.7911  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.7656  Validation loss = 7.7907  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.7654  Validation loss = 7.7905  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.7651  Validation loss = 7.7901  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.7649  Validation loss = 7.7897  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.7646  Validation loss = 7.7894  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.7644  Validation loss = 7.7891  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.7641  Validation loss = 7.7887  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.7639  Validation loss = 7.7884  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.7637  Validation loss = 7.7881  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.7635  Validation loss = 7.7878  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.7633  Validation loss = 7.7875  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.7630  Validation loss = 7.7872  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.7628  Validation loss = 7.7870  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.7626  Validation loss = 7.7866  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.7623  Validation loss = 7.7863  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.7622  Validation loss = 7.7860  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.7619  Validation loss = 7.7857  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.7617  Validation loss = 7.7854  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.7615  Validation loss = 7.7851  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.7612  Validation loss = 7.7848  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.7610  Validation loss = 7.7844  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.7607  Validation loss = 7.7841  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.7604  Validation loss = 7.7837  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.7602  Validation loss = 7.7834  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.7600  Validation loss = 7.7832  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.7598  Validation loss = 7.7828  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.7595  Validation loss = 7.7824  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.7592  Validation loss = 7.7821  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.7590  Validation loss = 7.7817  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.7588  Validation loss = 7.7814  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.7586  Validation loss = 7.7811  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.7583  Validation loss = 7.7808  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.7581  Validation loss = 7.7805  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.7578  Validation loss = 7.7801  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.7576  Validation loss = 7.7798  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.7573  Validation loss = 7.7795  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.7572  Validation loss = 7.7792  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.7569  Validation loss = 7.7789  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.7567  Validation loss = 7.7785  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.7564  Validation loss = 7.7782  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.7561  Validation loss = 7.7778  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.7559  Validation loss = 7.7775  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.7557  Validation loss = 7.7772  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.7555  Validation loss = 7.7769  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.7552  Validation loss = 7.7766  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.7550  Validation loss = 7.7763  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.7548  Validation loss = 7.7760  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.7545  Validation loss = 7.7756  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.7543  Validation loss = 7.7753  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.7541  Validation loss = 7.7750  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.7538  Validation loss = 7.7746  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.7536  Validation loss = 7.7743  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.7534  Validation loss = 7.7741  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.7532  Validation loss = 7.7738  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.7529  Validation loss = 7.7734  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.7527  Validation loss = 7.7731  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.7525  Validation loss = 7.7728  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.7523  Validation loss = 7.7725  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.7520  Validation loss = 7.7721  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.7518  Validation loss = 7.7718  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.7515  Validation loss = 7.7715  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.7513  Validation loss = 7.7711  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.7510  Validation loss = 7.7708  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.7508  Validation loss = 7.7705  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.7506  Validation loss = 7.7702  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.7504  Validation loss = 7.7699  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.7501  Validation loss = 7.7695  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.7499  Validation loss = 7.7692  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.7497  Validation loss = 7.7689  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.7494  Validation loss = 7.7685  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.7492  Validation loss = 7.7682  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.7489  Validation loss = 7.7679  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.7486  Validation loss = 7.7675  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.7484  Validation loss = 7.7672  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.7482  Validation loss = 7.7669  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.7480  Validation loss = 7.7666  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.7478  Validation loss = 7.7663  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.7475  Validation loss = 7.7660  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.7473  Validation loss = 7.7657  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.7471  Validation loss = 7.7654  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.7469  Validation loss = 7.7651  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.7466  Validation loss = 7.7647  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.7464  Validation loss = 7.7644  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.7462  Validation loss = 7.7641  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.7459  Validation loss = 7.7637  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.7457  Validation loss = 7.7634  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.7455  Validation loss = 7.7631  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.7453  Validation loss = 7.7628  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.7450  Validation loss = 7.7625  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.7448  Validation loss = 7.7622  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.7446  Validation loss = 7.7618  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.7443  Validation loss = 7.7615  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.7441  Validation loss = 7.7612  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.7438  Validation loss = 7.7608  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.7436  Validation loss = 7.7605  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.7434  Validation loss = 7.7602  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.7432  Validation loss = 7.7599  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.7430  Validation loss = 7.7596  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.7427  Validation loss = 7.7593  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.7424  Validation loss = 7.7589  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.7423  Validation loss = 7.7587  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.7420  Validation loss = 7.7583  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.7418  Validation loss = 7.7580  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.7415  Validation loss = 7.7577  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.7413  Validation loss = 7.7574  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.7410  Validation loss = 7.7570  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.7408  Validation loss = 7.7567  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.7406  Validation loss = 7.7564  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.7404  Validation loss = 7.7561  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.7401  Validation loss = 7.7558  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.7399  Validation loss = 7.7555  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.7397  Validation loss = 7.7552  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.7395  Validation loss = 7.7549  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.7392  Validation loss = 7.7546  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.7390  Validation loss = 7.7542  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.7387  Validation loss = 7.7539  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.7385  Validation loss = 7.7536  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.7383  Validation loss = 7.7534  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.7381  Validation loss = 7.7530  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.7379  Validation loss = 7.7527  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.7376  Validation loss = 7.7524  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.7374  Validation loss = 7.7520  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.7372  Validation loss = 7.7517  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.7369  Validation loss = 7.7513  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.7367  Validation loss = 7.7511  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.7364  Validation loss = 7.7507  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.7362  Validation loss = 7.7504  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.7360  Validation loss = 7.7501  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.7357  Validation loss = 7.7497  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.7355  Validation loss = 7.7494  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.7353  Validation loss = 7.7491  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.7350  Validation loss = 7.7488  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.7348  Validation loss = 7.7485  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.7346  Validation loss = 7.7483  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.7344  Validation loss = 7.7479  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.7341  Validation loss = 7.7475  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.7338  Validation loss = 7.7472  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.7336  Validation loss = 7.7469  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.7334  Validation loss = 7.7467  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.7332  Validation loss = 7.7463  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.7329  Validation loss = 7.7460  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.7327  Validation loss = 7.7456  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.7325  Validation loss = 7.7453  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.7322  Validation loss = 7.7450  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.7320  Validation loss = 7.7446  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.7317  Validation loss = 7.7443  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.7315  Validation loss = 7.7440  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.7313  Validation loss = 7.7437  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.7311  Validation loss = 7.7435  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.7308  Validation loss = 7.7431  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.7306  Validation loss = 7.7427  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.7303  Validation loss = 7.7424  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.7301  Validation loss = 7.7422  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.7299  Validation loss = 7.7418  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.7297  Validation loss = 7.7415  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.7295  Validation loss = 7.7413  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.7292  Validation loss = 7.7409  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.7290  Validation loss = 7.7406  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.7287  Validation loss = 7.7403  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.7285  Validation loss = 7.7399  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.7282  Validation loss = 7.7396  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.7280  Validation loss = 7.7393  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.7278  Validation loss = 7.7390  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.7275  Validation loss = 7.7386  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.7272  Validation loss = 7.7383  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.7271  Validation loss = 7.7380  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.7268  Validation loss = 7.7376  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.7266  Validation loss = 7.7374  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.7263  Validation loss = 7.7370  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.7261  Validation loss = 7.7368  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.7259  Validation loss = 7.7365  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.7257  Validation loss = 7.7362  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.7254  Validation loss = 7.7358  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.7252  Validation loss = 7.7355  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.7250  Validation loss = 7.7352  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.7247  Validation loss = 7.7349  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.7245  Validation loss = 7.7346  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.7243  Validation loss = 7.7343  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.7241  Validation loss = 7.7340  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.7239  Validation loss = 7.7337  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.7236  Validation loss = 7.7334  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.7234  Validation loss = 7.7330  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.7232  Validation loss = 7.7327  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.7229  Validation loss = 7.7324  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.7226  Validation loss = 7.7320  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.7224  Validation loss = 7.7316  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.7222  Validation loss = 7.7313  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.7220  Validation loss = 7.7311  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.7217  Validation loss = 7.7307  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.7215  Validation loss = 7.7304  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.7213  Validation loss = 7.7301  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.7211  Validation loss = 7.7298  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.7208  Validation loss = 7.7295  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.7206  Validation loss = 7.7292  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.7203  Validation loss = 7.7288  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.7201  Validation loss = 7.7285  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.7199  Validation loss = 7.7283  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.7197  Validation loss = 7.7280  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.7195  Validation loss = 7.7276  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.7193  Validation loss = 7.7273  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.7190  Validation loss = 7.7270  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.7188  Validation loss = 7.7267  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.7186  Validation loss = 7.7264  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.7184  Validation loss = 7.7261  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.7181  Validation loss = 7.7258  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.7179  Validation loss = 7.7255  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.7177  Validation loss = 7.7252  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.7175  Validation loss = 7.7249  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.7172  Validation loss = 7.7246  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.7170  Validation loss = 7.7242  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.7168  Validation loss = 7.7239  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.7165  Validation loss = 7.7236  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.7163  Validation loss = 7.7232  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.7160  Validation loss = 7.7229  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.7158  Validation loss = 7.7226  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.7156  Validation loss = 7.7223  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.7153  Validation loss = 7.7219  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.7151  Validation loss = 7.7217  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.7149  Validation loss = 7.7213  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.7147  Validation loss = 7.7210  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.7145  Validation loss = 7.7207  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.7142  Validation loss = 7.7204  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.7140  Validation loss = 7.7201  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.7138  Validation loss = 7.7198  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.7136  Validation loss = 7.7195  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.7134  Validation loss = 7.7192  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.7131  Validation loss = 7.7189  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.7129  Validation loss = 7.7186  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.7127  Validation loss = 7.7182  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.7124  Validation loss = 7.7179  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.7122  Validation loss = 7.7176  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.7119  Validation loss = 7.7172  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.7117  Validation loss = 7.7169  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.7115  Validation loss = 7.7166  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.7112  Validation loss = 7.7163  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.7110  Validation loss = 7.7160  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.7108  Validation loss = 7.7156  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.7105  Validation loss = 7.7153  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.7103  Validation loss = 7.7150  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.7101  Validation loss = 7.7146  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.7099  Validation loss = 7.7143  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.7096  Validation loss = 7.7140  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.7094  Validation loss = 7.7136  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.7091  Validation loss = 7.7133  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.7089  Validation loss = 7.7130  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.7087  Validation loss = 7.7127  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.7084  Validation loss = 7.7123  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.7082  Validation loss = 7.7120  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.7080  Validation loss = 7.7117  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.7077  Validation loss = 7.7113  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.7075  Validation loss = 7.7110  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.7072  Validation loss = 7.7107  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.7070  Validation loss = 7.7103  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.7068  Validation loss = 7.7100  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.7065  Validation loss = 7.7097  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.7063  Validation loss = 7.7093  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.7061  Validation loss = 7.7091  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.7059  Validation loss = 7.7087  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.7056  Validation loss = 7.7084  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.7053  Validation loss = 7.7081  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.7051  Validation loss = 7.7078  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.7049  Validation loss = 7.7074  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.7047  Validation loss = 7.7071  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.7045  Validation loss = 7.7069  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.7042  Validation loss = 7.7065  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.7040  Validation loss = 7.7062  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.7037  Validation loss = 7.7059  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.7035  Validation loss = 7.7055  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.7032  Validation loss = 7.7052  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.7030  Validation loss = 7.7048  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.7027  Validation loss = 7.7044  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.7025  Validation loss = 7.7041  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.7022  Validation loss = 7.7038  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.7020  Validation loss = 7.7035  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.7018  Validation loss = 7.7032  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.7016  Validation loss = 7.7029  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.7014  Validation loss = 7.7026  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.7011  Validation loss = 7.7023  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.7009  Validation loss = 7.7020  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.7007  Validation loss = 7.7017  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.7005  Validation loss = 7.7014  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.7003  Validation loss = 7.7011  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.7000  Validation loss = 7.7008  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.6998  Validation loss = 7.7005  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.6995  Validation loss = 7.7001  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.6993  Validation loss = 7.6998  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.6991  Validation loss = 7.6995  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.6989  Validation loss = 7.6992  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.6987  Validation loss = 7.6989  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.6984  Validation loss = 7.6986  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.6982  Validation loss = 7.6983  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.6980  Validation loss = 7.6980  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.6978  Validation loss = 7.6977  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.6976  Validation loss = 7.6974  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.6974  Validation loss = 7.6971  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.6972  Validation loss = 7.6969  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.6969  Validation loss = 7.6965  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.6967  Validation loss = 7.6963  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.6965  Validation loss = 7.6959  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.6963  Validation loss = 7.6956  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.6961  Validation loss = 7.6954  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.6959  Validation loss = 7.6951  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.6956  Validation loss = 7.6947  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.6953  Validation loss = 7.6943  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.6951  Validation loss = 7.6940  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.6948  Validation loss = 7.6936  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.6946  Validation loss = 7.6933  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.6944  Validation loss = 7.6930  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.6942  Validation loss = 7.6927  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.6940  Validation loss = 7.6924  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.6938  Validation loss = 7.6922  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.6935  Validation loss = 7.6918  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.6933  Validation loss = 7.6916  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.6932  Validation loss = 7.6913  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.6930  Validation loss = 7.6911  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.6928  Validation loss = 7.6908  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.6925  Validation loss = 7.6904  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.6923  Validation loss = 7.6902  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.6921  Validation loss = 7.6899  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.6919  Validation loss = 7.6895  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.6917  Validation loss = 7.6892  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.6914  Validation loss = 7.6889  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.6912  Validation loss = 7.6886  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.6910  Validation loss = 7.6884  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.6908  Validation loss = 7.6881  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.6906  Validation loss = 7.6878  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.6904  Validation loss = 7.6876  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.6902  Validation loss = 7.6872  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.6900  Validation loss = 7.6869  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.6898  Validation loss = 7.6866  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.6896  Validation loss = 7.6864  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.6894  Validation loss = 7.6861  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.6891  Validation loss = 7.6858  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.6889  Validation loss = 7.6854  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.6886  Validation loss = 7.6851  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.6884  Validation loss = 7.6848  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.6881  Validation loss = 7.6844  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.6879  Validation loss = 7.6841  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.6878  Validation loss = 7.6839  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.6876  Validation loss = 7.6836  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 2.6873  Validation loss = 7.6833  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 2.6871  Validation loss = 7.6829  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 2.6868  Validation loss = 7.6825  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 2.6866  Validation loss = 7.6823  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 2.6864  Validation loss = 7.6820  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 2.6862  Validation loss = 7.6818  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 2.6860  Validation loss = 7.6815  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 2.6858  Validation loss = 7.6812  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 2.6855  Validation loss = 7.6809  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 2.6853  Validation loss = 7.6805  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 2.6851  Validation loss = 7.6802  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 2.6848  Validation loss = 7.6799  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 2.6846  Validation loss = 7.6796  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 2.6844  Validation loss = 7.6793  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 2.6842  Validation loss = 7.6790  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 2.6840  Validation loss = 7.6787  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 2.6838  Validation loss = 7.6784  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 2.6835  Validation loss = 7.6781  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 2.6833  Validation loss = 7.6777  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 2.6831  Validation loss = 7.6774  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 2.6828  Validation loss = 7.6771  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 2.6825  Validation loss = 7.6767  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 2.6823  Validation loss = 7.6764  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 2.6820  Validation loss = 7.6761  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 2.6818  Validation loss = 7.6758  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 2.6816  Validation loss = 7.6755  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 2.6814  Validation loss = 7.6752  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 2.6812  Validation loss = 7.6749  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 2.6810  Validation loss = 7.6746  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 2.6807  Validation loss = 7.6743  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 2.6805  Validation loss = 7.6740  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 2.6803  Validation loss = 7.6737  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 2.6801  Validation loss = 7.6734  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 2.6799  Validation loss = 7.6731  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 2.6797  Validation loss = 7.6728  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 2.6795  Validation loss = 7.6725  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 2.6792  Validation loss = 7.6722  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 2.6790  Validation loss = 7.6719  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 2.6788  Validation loss = 7.6716  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 2.6786  Validation loss = 7.6713  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 2.6784  Validation loss = 7.6710  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 2.6782  Validation loss = 7.6707  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 2.6779  Validation loss = 7.6704  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 2.6777  Validation loss = 7.6700  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 2.6774  Validation loss = 7.6698  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 2.6772  Validation loss = 7.6694  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 2.6769  Validation loss = 7.6691  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 2.6767  Validation loss = 7.6688  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 2.6765  Validation loss = 7.6685  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 2.6763  Validation loss = 7.6682  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 2.6760  Validation loss = 7.6679  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 2.6758  Validation loss = 7.6675  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 2.6756  Validation loss = 7.6672  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 2.6753  Validation loss = 7.6669  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 2.6751  Validation loss = 7.6666  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 2.6749  Validation loss = 7.6663  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 2.6747  Validation loss = 7.6660  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 2.6745  Validation loss = 7.6657  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 2.6743  Validation loss = 7.6654  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 2.6741  Validation loss = 7.6651  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 2.6738  Validation loss = 7.6648  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 2.6736  Validation loss = 7.6645  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 2.6734  Validation loss = 7.6642  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 2.6732  Validation loss = 7.6639  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 2.6730  Validation loss = 7.6637  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 2.6728  Validation loss = 7.6634  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 2.6726  Validation loss = 7.6631  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 2.6723  Validation loss = 7.6628  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 2.6721  Validation loss = 7.6625  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 2.6719  Validation loss = 7.6621  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 2.6717  Validation loss = 7.6619  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 2.6716  Validation loss = 7.6616  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 2.6714  Validation loss = 7.6614  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 2.6711  Validation loss = 7.6611  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 2.6709  Validation loss = 7.6608  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 2.6707  Validation loss = 7.6605  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 2.6705  Validation loss = 7.6602  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 2.6703  Validation loss = 7.6599  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 2.6701  Validation loss = 7.6596  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 2.6698  Validation loss = 7.6593  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 2.6696  Validation loss = 7.6590  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 2.6694  Validation loss = 7.6587  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 2.6692  Validation loss = 7.6584  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 2.6690  Validation loss = 7.6581  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 2.6688  Validation loss = 7.6578  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 2.6686  Validation loss = 7.6576  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 2.6683  Validation loss = 7.6572  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 2.6681  Validation loss = 7.6569  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 2.6679  Validation loss = 7.6566  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 2.6677  Validation loss = 7.6563  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 2.6675  Validation loss = 7.6560  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 2.6672  Validation loss = 7.6557  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 2.6670  Validation loss = 7.6554  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 2.6669  Validation loss = 7.6552  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 2.6666  Validation loss = 7.6548  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 2.6664  Validation loss = 7.6546  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 2.6662  Validation loss = 7.6543  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 2.6659  Validation loss = 7.6539  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 2.6657  Validation loss = 7.6536  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 2.6655  Validation loss = 7.6533  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 2.6653  Validation loss = 7.6530  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 2.6651  Validation loss = 7.6528  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 2.6649  Validation loss = 7.6525  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 2.6647  Validation loss = 7.6521  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 2.6644  Validation loss = 7.6518  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 2.6642  Validation loss = 7.6515  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 2.6640  Validation loss = 7.6512  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 2.6637  Validation loss = 7.6509  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 2.6635  Validation loss = 7.6506  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 2.6633  Validation loss = 7.6503  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 2.6631  Validation loss = 7.6500  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 2.6629  Validation loss = 7.6498  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 500  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 3.2012  Validation loss = 11.5690  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 3.2009  Validation loss = 11.5687  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 3.2006  Validation loss = 11.5684  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 3.2004  Validation loss = 11.5681  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 3.2002  Validation loss = 11.5678  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 3.2000  Validation loss = 11.5676  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 3.1998  Validation loss = 11.5673  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 3.1995  Validation loss = 11.5670  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 3.1993  Validation loss = 11.5668  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 3.1991  Validation loss = 11.5665  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 3.1988  Validation loss = 11.5662  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 3.1986  Validation loss = 11.5659  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 3.1984  Validation loss = 11.5657  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 3.1982  Validation loss = 11.5654  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 3.1979  Validation loss = 11.5651  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 3.1977  Validation loss = 11.5649  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 3.1974  Validation loss = 11.5646  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 3.1972  Validation loss = 11.5643  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 3.1970  Validation loss = 11.5640  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 3.1967  Validation loss = 11.5635  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 3.1964  Validation loss = 11.5632  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 3.1962  Validation loss = 11.5630  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 3.1960  Validation loss = 11.5627  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 3.1958  Validation loss = 11.5623  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 3.1955  Validation loss = 11.5621  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 3.1953  Validation loss = 11.5618  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 3.1951  Validation loss = 11.5616  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 3.1949  Validation loss = 11.5613  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 3.1946  Validation loss = 11.5611  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 3.1944  Validation loss = 11.5608  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 3.1941  Validation loss = 11.5605  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 3.1939  Validation loss = 11.5602  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 3.1936  Validation loss = 11.5598  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 3.1934  Validation loss = 11.5596  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 3.1931  Validation loss = 11.5593  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 3.1929  Validation loss = 11.5591  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 3.1927  Validation loss = 11.5588  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 3.1924  Validation loss = 11.5584  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 3.1922  Validation loss = 11.5582  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 3.1919  Validation loss = 11.5579  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 3.1917  Validation loss = 11.5576  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 3.1915  Validation loss = 11.5574  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 3.1914  Validation loss = 11.5573  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 3.1911  Validation loss = 11.5569  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 3.1909  Validation loss = 11.5566  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 3.1907  Validation loss = 11.5564  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 3.1904  Validation loss = 11.5561  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 3.1902  Validation loss = 11.5557  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 3.1899  Validation loss = 11.5554  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 3.1897  Validation loss = 11.5551  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 3.1894  Validation loss = 11.5548  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 3.1891  Validation loss = 11.5545  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 3.1889  Validation loss = 11.5542  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 3.1887  Validation loss = 11.5540  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 3.1885  Validation loss = 11.5537  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 3.1882  Validation loss = 11.5533  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 3.1879  Validation loss = 11.5530  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 3.1876  Validation loss = 11.5527  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 3.1874  Validation loss = 11.5525  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 3.1872  Validation loss = 11.5521  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 3.1869  Validation loss = 11.5519  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 3.1867  Validation loss = 11.5517  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 3.1865  Validation loss = 11.5515  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 3.1863  Validation loss = 11.5512  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 3.1860  Validation loss = 11.5508  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 3.1857  Validation loss = 11.5505  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 3.1855  Validation loss = 11.5502  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 3.1852  Validation loss = 11.5498  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 3.1849  Validation loss = 11.5494  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 3.1847  Validation loss = 11.5492  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 3.1845  Validation loss = 11.5489  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 3.1843  Validation loss = 11.5487  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 3.1840  Validation loss = 11.5484  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 3.1838  Validation loss = 11.5481  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 3.1835  Validation loss = 11.5478  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 3.1834  Validation loss = 11.5476  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 3.1831  Validation loss = 11.5473  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 3.1829  Validation loss = 11.5470  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 3.1826  Validation loss = 11.5467  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 3.1824  Validation loss = 11.5464  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 3.1822  Validation loss = 11.5461  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 3.1819  Validation loss = 11.5458  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 3.1817  Validation loss = 11.5455  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 3.1814  Validation loss = 11.5452  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 3.1811  Validation loss = 11.5448  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 3.1809  Validation loss = 11.5445  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 3.1806  Validation loss = 11.5442  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 3.1804  Validation loss = 11.5439  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 3.1802  Validation loss = 11.5436  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 3.1799  Validation loss = 11.5433  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 3.1797  Validation loss = 11.5430  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 3.1794  Validation loss = 11.5427  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 3.1792  Validation loss = 11.5424  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 3.1789  Validation loss = 11.5421  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 3.1787  Validation loss = 11.5418  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 3.1784  Validation loss = 11.5415  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 3.1782  Validation loss = 11.5412  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 3.1780  Validation loss = 11.5410  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 3.1778  Validation loss = 11.5407  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 3.1775  Validation loss = 11.5405  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 3.1773  Validation loss = 11.5401  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 3.1770  Validation loss = 11.5397  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 3.1767  Validation loss = 11.5393  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 3.1765  Validation loss = 11.5390  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 3.1762  Validation loss = 11.5387  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 3.1760  Validation loss = 11.5384  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 3.1757  Validation loss = 11.5381  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 3.1754  Validation loss = 11.5377  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 3.1752  Validation loss = 11.5375  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 3.1749  Validation loss = 11.5372  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 3.1747  Validation loss = 11.5369  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 3.1744  Validation loss = 11.5366  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 3.1742  Validation loss = 11.5363  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 3.1740  Validation loss = 11.5360  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 3.1737  Validation loss = 11.5356  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 3.1735  Validation loss = 11.5354  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 3.1733  Validation loss = 11.5351  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 3.1731  Validation loss = 11.5348  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 3.1729  Validation loss = 11.5347  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 3.1726  Validation loss = 11.5343  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 3.1724  Validation loss = 11.5340  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 3.1722  Validation loss = 11.5337  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 3.1719  Validation loss = 11.5335  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 3.1717  Validation loss = 11.5331  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 3.1715  Validation loss = 11.5329  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 3.1713  Validation loss = 11.5326  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 3.1710  Validation loss = 11.5323  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 3.1708  Validation loss = 11.5320  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 3.1706  Validation loss = 11.5318  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 3.1703  Validation loss = 11.5314  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 3.1700  Validation loss = 11.5311  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 3.1698  Validation loss = 11.5308  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 3.1695  Validation loss = 11.5305  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 3.1694  Validation loss = 11.5303  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 3.1691  Validation loss = 11.5300  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 3.1689  Validation loss = 11.5296  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 3.1687  Validation loss = 11.5294  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 3.1684  Validation loss = 11.5291  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 3.1681  Validation loss = 11.5288  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 3.1679  Validation loss = 11.5284  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 3.1676  Validation loss = 11.5282  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 3.1674  Validation loss = 11.5279  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 3.1672  Validation loss = 11.5276  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 3.1669  Validation loss = 11.5273  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 3.1667  Validation loss = 11.5271  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 3.1665  Validation loss = 11.5268  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 3.1663  Validation loss = 11.5266  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 3.1660  Validation loss = 11.5263  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 3.1658  Validation loss = 11.5260  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 3.1655  Validation loss = 11.5257  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 3.1653  Validation loss = 11.5255  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 3.1651  Validation loss = 11.5251  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 3.1648  Validation loss = 11.5247  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 3.1646  Validation loss = 11.5245  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 3.1643  Validation loss = 11.5242  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 3.1640  Validation loss = 11.5239  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 3.1638  Validation loss = 11.5235  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 3.1636  Validation loss = 11.5233  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 3.1633  Validation loss = 11.5229  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 3.1631  Validation loss = 11.5227  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 3.1628  Validation loss = 11.5224  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 3.1625  Validation loss = 11.5220  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 3.1623  Validation loss = 11.5217  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 3.1621  Validation loss = 11.5215  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 3.1618  Validation loss = 11.5212  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 3.1616  Validation loss = 11.5209  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 3.1614  Validation loss = 11.5207  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 3.1611  Validation loss = 11.5203  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 3.1609  Validation loss = 11.5201  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 3.1607  Validation loss = 11.5198  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 3.1605  Validation loss = 11.5196  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 3.1603  Validation loss = 11.5193  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 3.1600  Validation loss = 11.5190  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 3.1598  Validation loss = 11.5187  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 3.1595  Validation loss = 11.5184  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 3.1593  Validation loss = 11.5180  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 3.1590  Validation loss = 11.5177  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 3.1588  Validation loss = 11.5174  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 3.1586  Validation loss = 11.5172  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 3.1584  Validation loss = 11.5169  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 3.1581  Validation loss = 11.5166  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 3.1578  Validation loss = 11.5163  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 3.1576  Validation loss = 11.5161  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 3.1573  Validation loss = 11.5157  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 3.1571  Validation loss = 11.5154  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 3.1568  Validation loss = 11.5151  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 3.1566  Validation loss = 11.5147  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 3.1564  Validation loss = 11.5145  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 3.1561  Validation loss = 11.5142  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 3.1559  Validation loss = 11.5139  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 3.1557  Validation loss = 11.5136  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 3.1554  Validation loss = 11.5132  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 3.1551  Validation loss = 11.5129  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 3.1548  Validation loss = 11.5125  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 3.1546  Validation loss = 11.5122  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 3.1543  Validation loss = 11.5119  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 3.1541  Validation loss = 11.5116  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 3.1538  Validation loss = 11.5113  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 3.1536  Validation loss = 11.5110  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 3.1533  Validation loss = 11.5107  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 3.1531  Validation loss = 11.5104  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 3.1528  Validation loss = 11.5101  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 3.1526  Validation loss = 11.5098  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 3.1523  Validation loss = 11.5095  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 3.1521  Validation loss = 11.5092  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 3.1519  Validation loss = 11.5089  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 3.1517  Validation loss = 11.5087  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 3.1514  Validation loss = 11.5083  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 3.1512  Validation loss = 11.5080  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 3.1509  Validation loss = 11.5077  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 3.1507  Validation loss = 11.5075  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 3.1505  Validation loss = 11.5072  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 3.1502  Validation loss = 11.5070  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 3.1500  Validation loss = 11.5067  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 3.1498  Validation loss = 11.5064  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 3.1496  Validation loss = 11.5061  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 3.1493  Validation loss = 11.5057  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 3.1491  Validation loss = 11.5055  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 3.1489  Validation loss = 11.5052  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 3.1486  Validation loss = 11.5049  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 3.1484  Validation loss = 11.5047  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 3.1481  Validation loss = 11.5043  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 3.1479  Validation loss = 11.5040  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 3.1476  Validation loss = 11.5036  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 3.1475  Validation loss = 11.5034  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 3.1472  Validation loss = 11.5030  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 3.1470  Validation loss = 11.5028  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 3.1468  Validation loss = 11.5025  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 3.1465  Validation loss = 11.5021  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 3.1463  Validation loss = 11.5019  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 3.1460  Validation loss = 11.5015  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 3.1458  Validation loss = 11.5013  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 3.1456  Validation loss = 11.5010  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 3.1453  Validation loss = 11.5007  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 3.1451  Validation loss = 11.5005  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 3.1449  Validation loss = 11.5002  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 3.1446  Validation loss = 11.4999  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 3.1444  Validation loss = 11.4997  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 3.1442  Validation loss = 11.4993  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 3.1440  Validation loss = 11.4991  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 3.1438  Validation loss = 11.4988  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 3.1435  Validation loss = 11.4985  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 3.1433  Validation loss = 11.4983  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 3.1431  Validation loss = 11.4980  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 3.1429  Validation loss = 11.4977  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 3.1426  Validation loss = 11.4973  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 3.1424  Validation loss = 11.4970  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 3.1422  Validation loss = 11.4967  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 3.1419  Validation loss = 11.4964  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 3.1417  Validation loss = 11.4961  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 3.1414  Validation loss = 11.4958  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 3.1411  Validation loss = 11.4954  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 3.1409  Validation loss = 11.4951  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 3.1407  Validation loss = 11.4949  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 3.1405  Validation loss = 11.4946  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 3.1402  Validation loss = 11.4943  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 3.1399  Validation loss = 11.4940  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 3.1397  Validation loss = 11.4935  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 3.1394  Validation loss = 11.4932  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 3.1391  Validation loss = 11.4929  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 3.1389  Validation loss = 11.4925  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 3.1386  Validation loss = 11.4922  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 3.1384  Validation loss = 11.4920  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 3.1381  Validation loss = 11.4917  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 3.1379  Validation loss = 11.4914  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 3.1376  Validation loss = 11.4910  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 3.1374  Validation loss = 11.4907  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 3.1371  Validation loss = 11.4904  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 3.1368  Validation loss = 11.4900  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 3.1366  Validation loss = 11.4898  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 3.1364  Validation loss = 11.4895  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 3.1361  Validation loss = 11.4891  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 3.1359  Validation loss = 11.4889  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 3.1356  Validation loss = 11.4886  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 3.1353  Validation loss = 11.4882  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 3.1351  Validation loss = 11.4880  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 3.1349  Validation loss = 11.4876  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 3.1346  Validation loss = 11.4873  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 3.1343  Validation loss = 11.4869  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 3.1341  Validation loss = 11.4866  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 3.1338  Validation loss = 11.4863  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 3.1336  Validation loss = 11.4860  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 3.1334  Validation loss = 11.4856  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 3.1331  Validation loss = 11.4853  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 3.1329  Validation loss = 11.4850  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 3.1327  Validation loss = 11.4847  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 3.1324  Validation loss = 11.4843  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 3.1322  Validation loss = 11.4841  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 3.1320  Validation loss = 11.4838  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 3.1318  Validation loss = 11.4835  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 3.1316  Validation loss = 11.4833  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 3.1313  Validation loss = 11.4829  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 3.1310  Validation loss = 11.4826  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 3.1308  Validation loss = 11.4823  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 3.1306  Validation loss = 11.4821  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 3.1303  Validation loss = 11.4817  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 3.1300  Validation loss = 11.4813  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 3.1298  Validation loss = 11.4810  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 3.1296  Validation loss = 11.4807  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 3.1294  Validation loss = 11.4804  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 3.1292  Validation loss = 11.4801  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 3.1289  Validation loss = 11.4798  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 3.1287  Validation loss = 11.4795  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 3.1285  Validation loss = 11.4792  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 3.1282  Validation loss = 11.4789  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 3.1280  Validation loss = 11.4786  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 3.1278  Validation loss = 11.4783  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 3.1276  Validation loss = 11.4780  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 3.1273  Validation loss = 11.4777  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 3.1271  Validation loss = 11.4773  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 3.1269  Validation loss = 11.4771  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 3.1266  Validation loss = 11.4768  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 3.1264  Validation loss = 11.4764  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 3.1262  Validation loss = 11.4762  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 3.1259  Validation loss = 11.4758  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 3.1257  Validation loss = 11.4755  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 3.1253  Validation loss = 11.4750  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 3.1251  Validation loss = 11.4747  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 3.1248  Validation loss = 11.4743  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 3.1246  Validation loss = 11.4739  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 3.1243  Validation loss = 11.4736  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 3.1241  Validation loss = 11.4733  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 3.1238  Validation loss = 11.4729  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 3.1236  Validation loss = 11.4726  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 3.1233  Validation loss = 11.4723  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 3.1231  Validation loss = 11.4720  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 3.1229  Validation loss = 11.4717  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 3.1226  Validation loss = 11.4714  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 3.1224  Validation loss = 11.4711  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 3.1222  Validation loss = 11.4708  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 3.1219  Validation loss = 11.4703  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 3.1216  Validation loss = 11.4698  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 3.1214  Validation loss = 11.4695  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 3.1212  Validation loss = 11.4693  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 3.1210  Validation loss = 11.4690  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 3.1207  Validation loss = 11.4686  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 3.1205  Validation loss = 11.4683  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 3.1203  Validation loss = 11.4681  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 3.1200  Validation loss = 11.4676  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 3.1198  Validation loss = 11.4673  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 3.1195  Validation loss = 11.4669  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 3.1193  Validation loss = 11.4665  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 3.1190  Validation loss = 11.4661  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 3.1188  Validation loss = 11.4658  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 3.1185  Validation loss = 11.4654  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 3.1182  Validation loss = 11.4651  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 3.1180  Validation loss = 11.4647  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 3.1178  Validation loss = 11.4643  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 3.1175  Validation loss = 11.4640  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 3.1173  Validation loss = 11.4636  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 3.1171  Validation loss = 11.4633  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 3.1169  Validation loss = 11.4631  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 3.1167  Validation loss = 11.4628  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 3.1164  Validation loss = 11.4625  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 3.1163  Validation loss = 11.4623  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 3.1160  Validation loss = 11.4619  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 3.1157  Validation loss = 11.4616  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 3.1155  Validation loss = 11.4612  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 3.1153  Validation loss = 11.4608  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 3.1150  Validation loss = 11.4605  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 3.1149  Validation loss = 11.4603  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 3.1146  Validation loss = 11.4599  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 3.1144  Validation loss = 11.4597  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 3.1142  Validation loss = 11.4593  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 3.1140  Validation loss = 11.4589  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 3.1138  Validation loss = 11.4586  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 3.1135  Validation loss = 11.4582  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 3.1133  Validation loss = 11.4578  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 3.1131  Validation loss = 11.4574  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 3.1128  Validation loss = 11.4568  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 3.1126  Validation loss = 11.4565  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 3.1124  Validation loss = 11.4563  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 3.1122  Validation loss = 11.4560  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 3.1120  Validation loss = 11.4556  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 3.1117  Validation loss = 11.4553  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 3.1116  Validation loss = 11.4551  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 3.1113  Validation loss = 11.4548  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 3.1111  Validation loss = 11.4544  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 3.1108  Validation loss = 11.4541  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 3.1107  Validation loss = 11.4539  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 3.1104  Validation loss = 11.4535  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 3.1102  Validation loss = 11.4530  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 3.1099  Validation loss = 11.4526  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 3.1097  Validation loss = 11.4523  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 3.1095  Validation loss = 11.4521  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 3.1094  Validation loss = 11.4518  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 3.1091  Validation loss = 11.4512  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 3.1089  Validation loss = 11.4509  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 3.1087  Validation loss = 11.4506  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 3.1084  Validation loss = 11.4500  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 3.1082  Validation loss = 11.4496  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 3.1079  Validation loss = 11.4492  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 3.1077  Validation loss = 11.4488  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 3.1075  Validation loss = 11.4483  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 3.1073  Validation loss = 11.4480  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 3.1071  Validation loss = 11.4477  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 3.1068  Validation loss = 11.4475  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 3.1066  Validation loss = 11.4470  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 3.1064  Validation loss = 11.4467  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 3.1062  Validation loss = 11.4464  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 3.1059  Validation loss = 11.4459  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 3.1057  Validation loss = 11.4455  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 3.1055  Validation loss = 11.4452  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 3.1052  Validation loss = 11.4447  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 3.1050  Validation loss = 11.4444  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 3.1048  Validation loss = 11.4440  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 3.1045  Validation loss = 11.4437  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 3.1043  Validation loss = 11.4434  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 3.1041  Validation loss = 11.4429  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 3.1039  Validation loss = 11.4426  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 3.1036  Validation loss = 11.4421  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 3.1033  Validation loss = 11.4417  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 3.1031  Validation loss = 11.4412  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 3.1028  Validation loss = 11.4407  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 3.1026  Validation loss = 11.4404  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 3.1024  Validation loss = 11.4402  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 3.1021  Validation loss = 11.4396  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 3.1019  Validation loss = 11.4393  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 3.1017  Validation loss = 11.4389  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 3.1015  Validation loss = 11.4386  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 3.1013  Validation loss = 11.4382  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 3.1010  Validation loss = 11.4378  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 3.1008  Validation loss = 11.4373  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 3.1006  Validation loss = 11.4369  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 3.1003  Validation loss = 11.4365  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 3.1001  Validation loss = 11.4360  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 3.0998  Validation loss = 11.4356  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 3.0996  Validation loss = 11.4351  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 3.0993  Validation loss = 11.4347  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 3.0991  Validation loss = 11.4344  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 3.0989  Validation loss = 11.4339  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 3.0987  Validation loss = 11.4336  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 3.0985  Validation loss = 11.4332  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 3.0983  Validation loss = 11.4327  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 3.0981  Validation loss = 11.4324  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 3.0979  Validation loss = 11.4321  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 3.0977  Validation loss = 11.4318  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 3.0975  Validation loss = 11.4314  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 3.0972  Validation loss = 11.4311  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 3.0970  Validation loss = 11.4305  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 3.0967  Validation loss = 11.4301  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 3.0965  Validation loss = 11.4296  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 3.0962  Validation loss = 11.4292  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 3.0960  Validation loss = 11.4288  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 3.0958  Validation loss = 11.4282  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 3.0955  Validation loss = 11.4278  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 3.0951  Validation loss = 11.4270  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 3.0949  Validation loss = 11.4267  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 3.0947  Validation loss = 11.4262  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 3.0945  Validation loss = 11.4260  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 3.0943  Validation loss = 11.4256  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 3.0941  Validation loss = 11.4251  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 3.0938  Validation loss = 11.4246  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 3.0936  Validation loss = 11.4241  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 3.0934  Validation loss = 11.4236  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 3.0932  Validation loss = 11.4230  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 3.0930  Validation loss = 11.4226  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 3.0928  Validation loss = 11.4221  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 3.0925  Validation loss = 11.4218  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 3.0924  Validation loss = 11.4215  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 3.0921  Validation loss = 11.4210  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 3.0918  Validation loss = 11.4206  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 3.0916  Validation loss = 11.4202  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 3.0913  Validation loss = 11.4197  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 3.0911  Validation loss = 11.4193  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 3.0909  Validation loss = 11.4189  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 3.0906  Validation loss = 11.4184  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 3.0904  Validation loss = 11.4180  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 3.0902  Validation loss = 11.4175  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 3.0900  Validation loss = 11.4172  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 3.0898  Validation loss = 11.4167  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 3.0896  Validation loss = 11.4162  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 3.0893  Validation loss = 11.4155  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 3.0891  Validation loss = 11.4153  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 3.0889  Validation loss = 11.4148  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 3.0886  Validation loss = 11.4141  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 3.0884  Validation loss = 11.4137  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 3.0882  Validation loss = 11.4132  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 3.0879  Validation loss = 11.4126  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 3.0877  Validation loss = 11.4123  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 3.0875  Validation loss = 11.4117  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 3.0872  Validation loss = 11.4111  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 3.0870  Validation loss = 11.4106  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 3.0868  Validation loss = 11.4098  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 3.0866  Validation loss = 11.4096  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 3.0864  Validation loss = 11.4090  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 3.0861  Validation loss = 11.4086  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 3.0859  Validation loss = 11.4080  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 3.0856  Validation loss = 11.4073  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 3.0855  Validation loss = 11.4070  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 3.0852  Validation loss = 11.4065  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 3.0850  Validation loss = 11.4060  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 3.0848  Validation loss = 11.4055  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 3.0846  Validation loss = 11.4049  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 3.0844  Validation loss = 11.4045  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 3.0841  Validation loss = 11.4040  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 3.0839  Validation loss = 11.4035  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 3.0837  Validation loss = 11.4030  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 3.0835  Validation loss = 11.4026  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 3.0833  Validation loss = 11.4023  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 4.1381  Validation loss = 6.7407  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 4.1378  Validation loss = 6.7402  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 4.1374  Validation loss = 6.7391  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 4.1367  Validation loss = 6.7367  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 4.1364  Validation loss = 6.7362  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 4.1359  Validation loss = 6.7349  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 4.1357  Validation loss = 6.7346  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 4.1354  Validation loss = 6.7339  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 4.1350  Validation loss = 6.7332  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 4.1346  Validation loss = 6.7325  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 4.1343  Validation loss = 6.7320  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 4.1340  Validation loss = 6.7314  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 4.1337  Validation loss = 6.7310  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 4.1334  Validation loss = 6.7304  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 4.1331  Validation loss = 6.7299  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 4.1328  Validation loss = 6.7293  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 4.1325  Validation loss = 6.7288  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 4.1321  Validation loss = 6.7282  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 4.1318  Validation loss = 6.7277  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 4.1315  Validation loss = 6.7271  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 4.1312  Validation loss = 6.7265  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 4.1309  Validation loss = 6.7261  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 4.1306  Validation loss = 6.7256  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 4.1304  Validation loss = 6.7253  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 4.1302  Validation loss = 6.7249  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 4.1298  Validation loss = 6.7243  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 4.1295  Validation loss = 6.7238  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 4.1292  Validation loss = 6.7233  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 4.1289  Validation loss = 6.7229  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 4.1286  Validation loss = 6.7224  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 4.1283  Validation loss = 6.7219  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 4.1281  Validation loss = 6.7215  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 4.1277  Validation loss = 6.7210  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 4.1275  Validation loss = 6.7205  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 4.1273  Validation loss = 6.7202  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 4.1270  Validation loss = 6.7198  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 4.1267  Validation loss = 6.7193  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 4.1265  Validation loss = 6.7190  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 4.1263  Validation loss = 6.7187  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 4.1260  Validation loss = 6.7182  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 4.1256  Validation loss = 6.7176  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 4.1253  Validation loss = 6.7171  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 4.1251  Validation loss = 6.7166  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 4.1247  Validation loss = 6.7162  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 4.1245  Validation loss = 6.7157  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 4.1241  Validation loss = 6.7152  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 4.1238  Validation loss = 6.7146  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 4.1235  Validation loss = 6.7142  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 4.1232  Validation loss = 6.7137  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 4.1228  Validation loss = 6.7130  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 4.1225  Validation loss = 6.7125  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 4.1222  Validation loss = 6.7120  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 4.1219  Validation loss = 6.7115  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 4.1217  Validation loss = 6.7111  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 4.1214  Validation loss = 6.7106  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 4.1211  Validation loss = 6.7101  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 4.1206  Validation loss = 6.7093  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 4.1203  Validation loss = 6.7088  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 4.1199  Validation loss = 6.7082  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 4.1196  Validation loss = 6.7077  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 4.1193  Validation loss = 6.7072  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 4.1190  Validation loss = 6.7067  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 4.1188  Validation loss = 6.7063  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 4.1185  Validation loss = 6.7058  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 4.1182  Validation loss = 6.7054  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 4.1178  Validation loss = 6.7048  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 4.1176  Validation loss = 6.7044  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 4.1173  Validation loss = 6.7040  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 4.1170  Validation loss = 6.7034  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 4.1167  Validation loss = 6.7030  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 4.1164  Validation loss = 6.7025  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 4.1161  Validation loss = 6.7020  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 4.1159  Validation loss = 6.7017  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 4.1156  Validation loss = 6.7012  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 4.1154  Validation loss = 6.7009  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 4.1150  Validation loss = 6.7003  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 4.1148  Validation loss = 6.6998  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 4.1145  Validation loss = 6.6994  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 4.1143  Validation loss = 6.6991  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 4.1140  Validation loss = 6.6987  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 4.1138  Validation loss = 6.6982  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 4.1135  Validation loss = 6.6978  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 4.1132  Validation loss = 6.6973  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 4.1128  Validation loss = 6.6967  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 4.1126  Validation loss = 6.6964  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 4.1122  Validation loss = 6.6958  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 4.1120  Validation loss = 6.6955  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 4.1117  Validation loss = 6.6950  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 4.1114  Validation loss = 6.6945  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 4.1112  Validation loss = 6.6942  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 4.1109  Validation loss = 6.6937  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 4.1106  Validation loss = 6.6932  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 4.1103  Validation loss = 6.6928  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 4.1100  Validation loss = 6.6923  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 4.1098  Validation loss = 6.6920  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 4.1095  Validation loss = 6.6916  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 4.1092  Validation loss = 6.6910  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 4.1089  Validation loss = 6.6906  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 4.1086  Validation loss = 6.6901  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 4.1083  Validation loss = 6.6895  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 4.1081  Validation loss = 6.6891  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 4.1078  Validation loss = 6.6887  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 4.1075  Validation loss = 6.6883  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 4.1073  Validation loss = 6.6878  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 4.1070  Validation loss = 6.6874  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 4.1068  Validation loss = 6.6872  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 4.1066  Validation loss = 6.6869  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 4.1063  Validation loss = 6.6864  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 4.1061  Validation loss = 6.6861  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 4.1058  Validation loss = 6.6855  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 4.1054  Validation loss = 6.6850  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 4.1052  Validation loss = 6.6845  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 4.1049  Validation loss = 6.6842  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 4.1046  Validation loss = 6.6836  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 4.1044  Validation loss = 6.6832  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 4.1041  Validation loss = 6.6829  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 4.1039  Validation loss = 6.6825  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 4.1037  Validation loss = 6.6822  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 4.1035  Validation loss = 6.6819  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 4.1033  Validation loss = 6.6815  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 4.1030  Validation loss = 6.6811  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 4.1026  Validation loss = 6.6805  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 4.1024  Validation loss = 6.6801  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 4.1021  Validation loss = 6.6797  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 4.1019  Validation loss = 6.6793  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 4.1017  Validation loss = 6.6790  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 4.1014  Validation loss = 6.6786  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 4.1011  Validation loss = 6.6781  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 4.1009  Validation loss = 6.6777  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 4.1006  Validation loss = 6.6773  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 4.1004  Validation loss = 6.6770  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 4.1001  Validation loss = 6.6766  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 4.0998  Validation loss = 6.6761  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 4.0996  Validation loss = 6.6758  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 4.0993  Validation loss = 6.6754  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 4.0990  Validation loss = 6.6748  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 4.0987  Validation loss = 6.6744  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 4.0984  Validation loss = 6.6739  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 4.0982  Validation loss = 6.6735  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 4.0979  Validation loss = 6.6732  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 4.0976  Validation loss = 6.6727  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 4.0973  Validation loss = 6.6722  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 4.0970  Validation loss = 6.6716  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 4.0967  Validation loss = 6.6712  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 4.0965  Validation loss = 6.6708  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 4.0962  Validation loss = 6.6704  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 4.0960  Validation loss = 6.6700  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 4.0957  Validation loss = 6.6696  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 4.0955  Validation loss = 6.6692  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 4.0952  Validation loss = 6.6688  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 4.0950  Validation loss = 6.6684  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 4.0947  Validation loss = 6.6681  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 4.0945  Validation loss = 6.6677  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 4.0941  Validation loss = 6.6671  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 4.0939  Validation loss = 6.6666  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 4.0936  Validation loss = 6.6662  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 4.0933  Validation loss = 6.6657  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 4.0930  Validation loss = 6.6654  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 4.0928  Validation loss = 6.6649  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 4.0924  Validation loss = 6.6644  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 4.0921  Validation loss = 6.6639  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 4.0918  Validation loss = 6.6634  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 4.0915  Validation loss = 6.6630  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 4.0912  Validation loss = 6.6624  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 4.0910  Validation loss = 6.6620  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 4.0906  Validation loss = 6.6615  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 4.0903  Validation loss = 6.6610  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 4.0901  Validation loss = 6.6607  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 4.0898  Validation loss = 6.6603  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 4.0896  Validation loss = 6.6599  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 4.0893  Validation loss = 6.6594  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 4.0890  Validation loss = 6.6590  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 4.0887  Validation loss = 6.6585  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 4.0884  Validation loss = 6.6580  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 4.0882  Validation loss = 6.6577  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 4.0879  Validation loss = 6.6571  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 4.0876  Validation loss = 6.6566  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 4.0873  Validation loss = 6.6562  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 4.0871  Validation loss = 6.6558  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 4.0868  Validation loss = 6.6554  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 4.0865  Validation loss = 6.6549  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 4.0860  Validation loss = 6.6542  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 4.0858  Validation loss = 6.6537  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 4.0854  Validation loss = 6.6532  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 4.0852  Validation loss = 6.6528  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 4.0849  Validation loss = 6.6524  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 4.0847  Validation loss = 6.6521  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 4.0845  Validation loss = 6.6518  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 4.0843  Validation loss = 6.6514  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 4.0840  Validation loss = 6.6510  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 4.0837  Validation loss = 6.6506  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 4.0835  Validation loss = 6.6502  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 4.0832  Validation loss = 6.6498  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 4.0829  Validation loss = 6.6492  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 4.0826  Validation loss = 6.6488  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 4.0823  Validation loss = 6.6483  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 4.0821  Validation loss = 6.6479  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 4.0817  Validation loss = 6.6473  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 4.0815  Validation loss = 6.6469  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 4.0812  Validation loss = 6.6465  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 4.0809  Validation loss = 6.6461  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 4.0806  Validation loss = 6.6456  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 4.0804  Validation loss = 6.6453  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 4.0801  Validation loss = 6.6448  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 4.0799  Validation loss = 6.6444  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 4.0797  Validation loss = 6.6441  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 4.0794  Validation loss = 6.6437  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 4.0792  Validation loss = 6.6434  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 4.0789  Validation loss = 6.6430  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 4.0787  Validation loss = 6.6426  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 4.0784  Validation loss = 6.6422  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 4.0781  Validation loss = 6.6417  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 4.0778  Validation loss = 6.6412  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 4.0776  Validation loss = 6.6409  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 4.0773  Validation loss = 6.6403  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 4.0770  Validation loss = 6.6399  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 4.0766  Validation loss = 6.6393  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 4.0764  Validation loss = 6.6389  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 4.0761  Validation loss = 6.6384  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 4.0758  Validation loss = 6.6380  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 4.0755  Validation loss = 6.6375  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 4.0752  Validation loss = 6.6370  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 4.0749  Validation loss = 6.6366  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 4.0747  Validation loss = 6.6362  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 4.0744  Validation loss = 6.6357  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 4.0740  Validation loss = 6.6351  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 4.0738  Validation loss = 6.6347  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 4.0735  Validation loss = 6.6343  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 4.0731  Validation loss = 6.6337  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 4.0728  Validation loss = 6.6332  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 4.0726  Validation loss = 6.6327  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 4.0723  Validation loss = 6.6323  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 4.0720  Validation loss = 6.6318  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 4.0717  Validation loss = 6.6315  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 4.0714  Validation loss = 6.6310  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 4.0712  Validation loss = 6.6306  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 4.0709  Validation loss = 6.6302  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 4.0706  Validation loss = 6.6296  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 4.0702  Validation loss = 6.6291  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 4.0699  Validation loss = 6.6286  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 4.0691  Validation loss = 6.6280  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 4.0685  Validation loss = 6.6275  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 4.0677  Validation loss = 6.6270  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 4.0673  Validation loss = 6.6265  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 4.0671  Validation loss = 6.6261  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 4.0668  Validation loss = 6.6256  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 4.0665  Validation loss = 6.6252  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 4.0663  Validation loss = 6.6248  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 4.0659  Validation loss = 6.6242  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 4.0656  Validation loss = 6.6237  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 4.0654  Validation loss = 6.6234  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 4.0652  Validation loss = 6.6230  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 4.0650  Validation loss = 6.6228  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 4.0648  Validation loss = 6.6224  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 4.0645  Validation loss = 6.6220  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 4.0642  Validation loss = 6.6215  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 4.0640  Validation loss = 6.6211  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 4.0638  Validation loss = 6.6207  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 4.0635  Validation loss = 6.6202  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 4.0632  Validation loss = 6.6197  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 4.0629  Validation loss = 6.6191  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 4.0625  Validation loss = 6.6185  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 4.0623  Validation loss = 6.6179  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 4.0620  Validation loss = 6.6175  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 4.0617  Validation loss = 6.6168  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 4.0613  Validation loss = 6.6159  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 4.0611  Validation loss = 6.6156  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 4.0608  Validation loss = 6.6152  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 4.0605  Validation loss = 6.6148  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 4.0603  Validation loss = 6.6140  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 4.0599  Validation loss = 6.6132  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 4.0597  Validation loss = 6.6124  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 4.0594  Validation loss = 6.6117  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 4.0593  Validation loss = 6.6116  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 4.0590  Validation loss = 6.6110  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 4.0586  Validation loss = 6.6103  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 4.0583  Validation loss = 6.6094  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 4.0580  Validation loss = 6.6086  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 4.0578  Validation loss = 6.6084  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 4.0575  Validation loss = 6.6075  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 4.0573  Validation loss = 6.6069  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 4.0570  Validation loss = 6.6064  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 4.0567  Validation loss = 6.6058  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 4.0566  Validation loss = 6.6055  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 4.0562  Validation loss = 6.6043  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 4.0559  Validation loss = 6.6038  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 4.0556  Validation loss = 6.6034  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 4.0553  Validation loss = 6.6026  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 4.0549  Validation loss = 6.6017  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 4.0547  Validation loss = 6.6014  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 4.0545  Validation loss = 6.6010  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 4.0542  Validation loss = 6.6006  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 4.0539  Validation loss = 6.6002  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 4.0536  Validation loss = 6.5996  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 4.0534  Validation loss = 6.5993  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 4.0532  Validation loss = 6.5989  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 4.0529  Validation loss = 6.5985  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 4.0526  Validation loss = 6.5980  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 4.0523  Validation loss = 6.5975  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 4.0520  Validation loss = 6.5970  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 4.0517  Validation loss = 6.5963  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 4.0515  Validation loss = 6.5960  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 4.0513  Validation loss = 6.5955  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 4.0510  Validation loss = 6.5951  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 4.0508  Validation loss = 6.5948  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 4.0505  Validation loss = 6.5943  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 4.0502  Validation loss = 6.5937  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 4.0499  Validation loss = 6.5931  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 4.0496  Validation loss = 6.5927  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 4.0493  Validation loss = 6.5922  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 4.0490  Validation loss = 6.5916  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 4.0488  Validation loss = 6.5913  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 4.0486  Validation loss = 6.5909  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 4.0482  Validation loss = 6.5904  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 4.0480  Validation loss = 6.5900  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 4.0477  Validation loss = 6.5895  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 4.0474  Validation loss = 6.5890  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 4.0472  Validation loss = 6.5887  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 4.0470  Validation loss = 6.5883  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 4.0467  Validation loss = 6.5878  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 4.0464  Validation loss = 6.5874  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 4.0462  Validation loss = 6.5870  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 4.0459  Validation loss = 6.5865  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 4.0457  Validation loss = 6.5861  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 4.0454  Validation loss = 6.5856  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 4.0451  Validation loss = 6.5853  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 4.0448  Validation loss = 6.5846  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 4.0445  Validation loss = 6.5842  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 4.0443  Validation loss = 6.5839  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 4.0440  Validation loss = 6.5833  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 4.0437  Validation loss = 6.5829  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 4.0434  Validation loss = 6.5824  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 4.0431  Validation loss = 6.5819  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 4.0429  Validation loss = 6.5815  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 4.0426  Validation loss = 6.5812  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 4.0424  Validation loss = 6.5807  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 4.0421  Validation loss = 6.5804  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 4.0419  Validation loss = 6.5800  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 4.0415  Validation loss = 6.5793  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 4.0412  Validation loss = 6.5788  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 4.0409  Validation loss = 6.5783  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 4.0406  Validation loss = 6.5779  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 4.0404  Validation loss = 6.5776  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 4.0402  Validation loss = 6.5772  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 4.0399  Validation loss = 6.5767  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 4.0396  Validation loss = 6.5762  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 4.0393  Validation loss = 6.5758  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 4.0391  Validation loss = 6.5754  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 4.0388  Validation loss = 6.5750  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 4.0385  Validation loss = 6.5744  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 4.0383  Validation loss = 6.5741  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 4.0380  Validation loss = 6.5737  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 4.0377  Validation loss = 6.5732  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 4.0374  Validation loss = 6.5727  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 4.0371  Validation loss = 6.5722  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 4.0369  Validation loss = 6.5719  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 4.0366  Validation loss = 6.5715  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 4.0363  Validation loss = 6.5710  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 4.0361  Validation loss = 6.5706  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 4.0358  Validation loss = 6.5702  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 4.0354  Validation loss = 6.5696  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 4.0351  Validation loss = 6.5691  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 4.0349  Validation loss = 6.5687  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 4.0346  Validation loss = 6.5682  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 4.0343  Validation loss = 6.5677  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 4.0340  Validation loss = 6.5672  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 4.0337  Validation loss = 6.5668  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 4.0334  Validation loss = 6.5664  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 4.0331  Validation loss = 6.5658  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 4.0328  Validation loss = 6.5654  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 4.0325  Validation loss = 6.5648  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 4.0322  Validation loss = 6.5643  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 4.0319  Validation loss = 6.5639  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 4.0317  Validation loss = 6.5635  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 4.0315  Validation loss = 6.5632  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 4.0312  Validation loss = 6.5628  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 4.0310  Validation loss = 6.5624  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 4.0307  Validation loss = 6.5619  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 4.0305  Validation loss = 6.5615  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 4.0302  Validation loss = 6.5612  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 4.0300  Validation loss = 6.5607  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 4.0297  Validation loss = 6.5603  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 4.0294  Validation loss = 6.5597  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 4.0291  Validation loss = 6.5592  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 4.0288  Validation loss = 6.5588  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 4.0285  Validation loss = 6.5583  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 4.0282  Validation loss = 6.5578  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 4.0279  Validation loss = 6.5574  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 4.0277  Validation loss = 6.5571  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 4.0275  Validation loss = 6.5567  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 4.0272  Validation loss = 6.5563  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 4.0270  Validation loss = 6.5559  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 4.0266  Validation loss = 6.5552  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 4.0264  Validation loss = 6.5548  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 4.0261  Validation loss = 6.5544  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 4.0257  Validation loss = 6.5538  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 4.0255  Validation loss = 6.5534  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 4.0252  Validation loss = 6.5530  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 4.0250  Validation loss = 6.5526  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 4.0247  Validation loss = 6.5521  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 4.0245  Validation loss = 6.5519  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 4.0243  Validation loss = 6.5515  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 4.0240  Validation loss = 6.5511  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 4.0237  Validation loss = 6.5506  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 4.0235  Validation loss = 6.5502  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 4.0232  Validation loss = 6.5497  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 4.0228  Validation loss = 6.5490  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 4.0225  Validation loss = 6.5485  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 4.0223  Validation loss = 6.5482  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 4.0220  Validation loss = 6.5477  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 4.0218  Validation loss = 6.5474  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 4.0215  Validation loss = 6.5468  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 4.0212  Validation loss = 6.5465  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 4.0209  Validation loss = 6.5460  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 4.0207  Validation loss = 6.5457  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 4.0205  Validation loss = 6.5453  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 4.0202  Validation loss = 6.5449  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 4.0200  Validation loss = 6.5445  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 4.0197  Validation loss = 6.5440  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 4.0195  Validation loss = 6.5436  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 4.0192  Validation loss = 6.5433  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 4.0190  Validation loss = 6.5430  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 4.0188  Validation loss = 6.5426  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 4.0184  Validation loss = 6.5420  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 4.0182  Validation loss = 6.5416  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 4.0179  Validation loss = 6.5412  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 4.0177  Validation loss = 6.5407  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 4.0174  Validation loss = 6.5402  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 4.0170  Validation loss = 6.5397  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 4.0168  Validation loss = 6.5393  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 4.0165  Validation loss = 6.5389  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 4.0162  Validation loss = 6.5384  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 4.0160  Validation loss = 6.5380  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 4.0158  Validation loss = 6.5377  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 4.0155  Validation loss = 6.5372  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 4.0152  Validation loss = 6.5368  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 4.0150  Validation loss = 6.5364  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 4.0147  Validation loss = 6.5360  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 4.0144  Validation loss = 6.5355  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 4.0142  Validation loss = 6.5351  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 4.0139  Validation loss = 6.5346  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 4.0137  Validation loss = 6.5342  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 4.0134  Validation loss = 6.5339  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 4.0131  Validation loss = 6.5334  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 4.0128  Validation loss = 6.5329  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 4.0126  Validation loss = 6.5325  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 4.0124  Validation loss = 6.5321  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 4.0121  Validation loss = 6.5317  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 4.0118  Validation loss = 6.5311  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 4.0115  Validation loss = 6.5307  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 4.0113  Validation loss = 6.5303  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 4.0110  Validation loss = 6.5299  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 4.0107  Validation loss = 6.5295  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 4.0105  Validation loss = 6.5291  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 4.0102  Validation loss = 6.5287  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 4.0099  Validation loss = 6.5281  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 4.0096  Validation loss = 6.5276  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 4.0092  Validation loss = 6.5270  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 4.0089  Validation loss = 6.5265  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 4.0087  Validation loss = 6.5261  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 4.0085  Validation loss = 6.5258  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 4.0081  Validation loss = 6.5253  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 4.0078  Validation loss = 6.5247  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 4.0076  Validation loss = 6.5244  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 4.0073  Validation loss = 6.5239  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 4.0070  Validation loss = 6.5233  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 4.0067  Validation loss = 6.5229  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 4.0063  Validation loss = 6.5223  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 4.0061  Validation loss = 6.5219  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 4.0058  Validation loss = 6.5214  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 4.0055  Validation loss = 6.5210  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 4.0053  Validation loss = 6.5206  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 4.0050  Validation loss = 6.5202  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 4.0048  Validation loss = 6.5198  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 4.0044  Validation loss = 6.5192  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 4.0042  Validation loss = 6.5188  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 4.0038  Validation loss = 6.5182  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 4.0036  Validation loss = 6.5178  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 4.0033  Validation loss = 6.5174  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 4.0030  Validation loss = 6.5168  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 4.0026  Validation loss = 6.5161  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 4.0024  Validation loss = 6.5158  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 4.0021  Validation loss = 6.5152  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 4.0019  Validation loss = 6.5149  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 4.0016  Validation loss = 6.5144  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 4.0012  Validation loss = 6.5138  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 4.0010  Validation loss = 6.5134  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 4.0006  Validation loss = 6.5128  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 4.0004  Validation loss = 6.5124  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 4.0001  Validation loss = 6.5119  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 3.9999  Validation loss = 6.5115  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 3.9996  Validation loss = 6.5110  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 3.9993  Validation loss = 6.5103  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 3.9990  Validation loss = 6.5099  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 3.9988  Validation loss = 6.5095  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 3.9985  Validation loss = 6.5090  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 3.9982  Validation loss = 6.5085  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 3.9979  Validation loss = 6.5079  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 3.9976  Validation loss = 6.5073  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 3.9974  Validation loss = 6.5069  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 4.3035  Validation loss = 3.9352  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 4.3031  Validation loss = 3.9345  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 4.3027  Validation loss = 3.9339  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 4.3024  Validation loss = 3.9335  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 4.3020  Validation loss = 3.9328  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 4.3016  Validation loss = 3.9323  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 4.3011  Validation loss = 3.9316  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 4.3006  Validation loss = 3.9310  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 4.2999  Validation loss = 3.9303  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 4.2976  Validation loss = 3.9297  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 4.2938  Validation loss = 3.9292  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 4.2910  Validation loss = 3.9287  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 4.2905  Validation loss = 3.9280  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 4.2901  Validation loss = 3.9275  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 4.2898  Validation loss = 3.9270  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 4.2893  Validation loss = 3.9263  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 4.2890  Validation loss = 3.9257  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 4.2886  Validation loss = 3.9253  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 4.2882  Validation loss = 3.9245  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 4.2879  Validation loss = 3.9241  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 4.2875  Validation loss = 3.9235  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 4.2872  Validation loss = 3.9230  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 4.2868  Validation loss = 3.9223  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 4.2865  Validation loss = 3.9218  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 4.2862  Validation loss = 3.9214  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 4.2859  Validation loss = 3.9209  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 4.2855  Validation loss = 3.9203  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 4.2851  Validation loss = 3.9197  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 4.2848  Validation loss = 3.9192  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 4.2845  Validation loss = 3.9188  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 4.2843  Validation loss = 3.9183  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 4.2839  Validation loss = 3.9177  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 4.2835  Validation loss = 3.9171  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 4.2832  Validation loss = 3.9166  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 4.2830  Validation loss = 3.9162  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 4.2827  Validation loss = 3.9157  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 4.2823  Validation loss = 3.9151  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 4.2820  Validation loss = 3.9145  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 4.2816  Validation loss = 3.9140  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 4.2812  Validation loss = 3.9133  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 4.2809  Validation loss = 3.9128  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 4.2806  Validation loss = 3.9123  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 4.2803  Validation loss = 3.9118  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 4.2799  Validation loss = 3.9111  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 4.2796  Validation loss = 3.9106  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 4.2794  Validation loss = 3.9102  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 4.2790  Validation loss = 3.9095  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 4.2787  Validation loss = 3.9090  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 4.2784  Validation loss = 3.9086  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 4.2781  Validation loss = 3.9080  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 4.2778  Validation loss = 3.9075  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 4.2774  Validation loss = 3.9069  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 4.2771  Validation loss = 3.9066  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 4.2768  Validation loss = 3.9060  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 4.2765  Validation loss = 3.9055  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 4.2762  Validation loss = 3.9050  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 4.2757  Validation loss = 3.9043  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 4.2754  Validation loss = 3.9038  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 4.2750  Validation loss = 3.9032  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 4.2747  Validation loss = 3.9026  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 4.2744  Validation loss = 3.9022  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 4.2741  Validation loss = 3.9017  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 4.2738  Validation loss = 3.9012  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 4.2735  Validation loss = 3.9006  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 4.2731  Validation loss = 3.9001  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 4.2728  Validation loss = 3.8996  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 4.2724  Validation loss = 3.8991  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 4.2721  Validation loss = 3.8985  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 4.2717  Validation loss = 3.8979  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 4.2714  Validation loss = 3.8974  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 4.2712  Validation loss = 3.8970  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 4.2709  Validation loss = 3.8966  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 4.2705  Validation loss = 3.8961  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 4.2703  Validation loss = 3.8956  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 4.2699  Validation loss = 3.8950  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 4.2695  Validation loss = 3.8944  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 4.2691  Validation loss = 3.8938  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 4.2688  Validation loss = 3.8933  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 4.2685  Validation loss = 3.8928  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 4.2681  Validation loss = 3.8922  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 4.2678  Validation loss = 3.8917  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 4.2674  Validation loss = 3.8911  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 4.2671  Validation loss = 3.8907  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 4.2667  Validation loss = 3.8900  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 4.2664  Validation loss = 3.8895  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 4.2660  Validation loss = 3.8890  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 4.2657  Validation loss = 3.8885  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 4.2654  Validation loss = 3.8881  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 4.2651  Validation loss = 3.8876  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 4.2647  Validation loss = 3.8871  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 4.2644  Validation loss = 3.8865  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 4.2640  Validation loss = 3.8859  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 4.2635  Validation loss = 3.8852  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 4.2632  Validation loss = 3.8847  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 4.2629  Validation loss = 3.8842  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 4.2626  Validation loss = 3.8838  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 4.2623  Validation loss = 3.8833  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 4.2618  Validation loss = 3.8827  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 4.2615  Validation loss = 3.8821  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 4.2610  Validation loss = 3.8814  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 4.2605  Validation loss = 3.8807  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 4.2602  Validation loss = 3.8802  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 4.2599  Validation loss = 3.8798  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 4.2595  Validation loss = 3.8791  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 4.2591  Validation loss = 3.8785  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 4.2587  Validation loss = 3.8779  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 4.2584  Validation loss = 3.8775  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 4.2581  Validation loss = 3.8771  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 4.2577  Validation loss = 3.8766  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 4.2574  Validation loss = 3.8761  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 4.2571  Validation loss = 3.8756  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 4.2567  Validation loss = 3.8751  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 4.2564  Validation loss = 3.8746  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 4.2561  Validation loss = 3.8741  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 4.2557  Validation loss = 3.8736  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 4.2554  Validation loss = 3.8731  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 4.2551  Validation loss = 3.8727  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 4.2548  Validation loss = 3.8722  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 4.2545  Validation loss = 3.8717  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 4.2542  Validation loss = 3.8712  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 4.2538  Validation loss = 3.8708  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 4.2534  Validation loss = 3.8702  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 4.2531  Validation loss = 3.8697  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 4.2528  Validation loss = 3.8692  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 4.2524  Validation loss = 3.8687  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 4.2520  Validation loss = 3.8681  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 4.2517  Validation loss = 3.8677  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 4.2513  Validation loss = 3.8671  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 4.2508  Validation loss = 3.8664  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 4.2505  Validation loss = 3.8660  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 4.2502  Validation loss = 3.8654  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 4.2497  Validation loss = 3.8648  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 4.2494  Validation loss = 3.8644  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 4.2491  Validation loss = 3.8639  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 4.2486  Validation loss = 3.8634  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 4.2483  Validation loss = 3.8628  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 4.2479  Validation loss = 3.8623  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 4.2474  Validation loss = 3.8617  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 4.2471  Validation loss = 3.8612  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 4.2467  Validation loss = 3.8606  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 4.2463  Validation loss = 3.8601  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 4.2458  Validation loss = 3.8596  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 4.2455  Validation loss = 3.8591  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 4.2451  Validation loss = 3.8587  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 4.2446  Validation loss = 3.8582  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 4.2441  Validation loss = 3.8577  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 4.2436  Validation loss = 3.8573  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 4.2418  Validation loss = 3.8566  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 4.2400  Validation loss = 3.8560  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 4.2396  Validation loss = 3.8555  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 4.2391  Validation loss = 3.8549  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 4.2386  Validation loss = 3.8544  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 4.2383  Validation loss = 3.8540  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 4.2378  Validation loss = 3.8535  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 4.2374  Validation loss = 3.8529  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 4.2369  Validation loss = 3.8524  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 4.2364  Validation loss = 3.8517  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 4.2360  Validation loss = 3.8511  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 4.2356  Validation loss = 3.8506  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 4.2352  Validation loss = 3.8501  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 4.2349  Validation loss = 3.8496  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 4.2346  Validation loss = 3.8491  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 4.2343  Validation loss = 3.8487  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 4.2339  Validation loss = 3.8482  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 4.2335  Validation loss = 3.8477  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 4.2333  Validation loss = 3.8473  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 4.2329  Validation loss = 3.8468  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 4.2325  Validation loss = 3.8463  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 4.2322  Validation loss = 3.8458  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 4.2317  Validation loss = 3.8453  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 4.2314  Validation loss = 3.8448  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 4.2311  Validation loss = 3.8444  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 4.2309  Validation loss = 3.8440  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 4.2304  Validation loss = 3.8434  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 4.2301  Validation loss = 3.8429  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 4.2296  Validation loss = 3.8424  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 4.2293  Validation loss = 3.8420  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 4.2290  Validation loss = 3.8415  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 4.2287  Validation loss = 3.8411  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 4.2284  Validation loss = 3.8406  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 4.2279  Validation loss = 3.8400  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 4.2275  Validation loss = 3.8395  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 4.2272  Validation loss = 3.8391  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 4.2268  Validation loss = 3.8386  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 4.2265  Validation loss = 3.8381  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 4.2260  Validation loss = 3.8376  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 4.2257  Validation loss = 3.8371  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 4.2254  Validation loss = 3.8367  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 4.2250  Validation loss = 3.8361  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 4.2245  Validation loss = 3.8355  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 4.2242  Validation loss = 3.8351  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 4.2239  Validation loss = 3.8347  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 4.2236  Validation loss = 3.8343  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 4.2233  Validation loss = 3.8338  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 4.2230  Validation loss = 3.8334  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 4.2226  Validation loss = 3.8329  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 4.2222  Validation loss = 3.8324  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 4.2219  Validation loss = 3.8320  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 4.2216  Validation loss = 3.8315  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 4.2212  Validation loss = 3.8311  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 4.2207  Validation loss = 3.8305  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 4.2204  Validation loss = 3.8301  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 4.2202  Validation loss = 3.8298  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 4.2198  Validation loss = 3.8294  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 4.2195  Validation loss = 3.8289  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 4.2190  Validation loss = 3.8283  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 4.2188  Validation loss = 3.8279  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 4.2184  Validation loss = 3.8274  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 4.2180  Validation loss = 3.8270  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 4.2176  Validation loss = 3.8264  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 4.2172  Validation loss = 3.8259  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 4.2169  Validation loss = 3.8255  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 4.2166  Validation loss = 3.8252  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 4.2162  Validation loss = 3.8247  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 4.2158  Validation loss = 3.8242  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 4.2155  Validation loss = 3.8238  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 4.2152  Validation loss = 3.8234  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 4.2148  Validation loss = 3.8229  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 4.2144  Validation loss = 3.8224  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 4.2140  Validation loss = 3.8220  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 4.2137  Validation loss = 3.8216  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 4.2133  Validation loss = 3.8211  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 4.2131  Validation loss = 3.8208  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 4.2126  Validation loss = 3.8202  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 4.2123  Validation loss = 3.8198  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 4.2120  Validation loss = 3.8194  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 4.2117  Validation loss = 3.8190  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 4.2114  Validation loss = 3.8186  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 4.2111  Validation loss = 3.8182  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 4.2107  Validation loss = 3.8177  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 4.2103  Validation loss = 3.8172  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 4.2100  Validation loss = 3.8168  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 4.2097  Validation loss = 3.8165  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 4.2094  Validation loss = 3.8160  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 4.2091  Validation loss = 3.8157  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 4.2088  Validation loss = 3.8152  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 4.2084  Validation loss = 3.8147  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 4.2080  Validation loss = 3.8142  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 4.2077  Validation loss = 3.8138  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 4.2073  Validation loss = 3.8133  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 4.2070  Validation loss = 3.8129  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 4.2067  Validation loss = 3.8125  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 4.2064  Validation loss = 3.8120  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 4.2061  Validation loss = 3.8116  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 4.2057  Validation loss = 3.8111  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 4.2053  Validation loss = 3.8107  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 4.2050  Validation loss = 3.8103  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 4.2045  Validation loss = 3.8097  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 4.2042  Validation loss = 3.8093  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 4.2038  Validation loss = 3.8088  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 4.2034  Validation loss = 3.8084  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 4.2031  Validation loss = 3.8079  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 4.2027  Validation loss = 3.8074  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 4.2023  Validation loss = 3.8069  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 4.2018  Validation loss = 3.8064  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 4.2013  Validation loss = 3.8059  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 4.2011  Validation loss = 3.8055  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 4.2006  Validation loss = 3.8050  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 4.2002  Validation loss = 3.8045  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 4.1999  Validation loss = 3.8041  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 4.1995  Validation loss = 3.8036  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 4.1992  Validation loss = 3.8033  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 4.1988  Validation loss = 3.8028  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 4.1985  Validation loss = 3.8024  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 4.1981  Validation loss = 3.8019  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 4.1977  Validation loss = 3.8013  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 4.1973  Validation loss = 3.8009  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 4.1969  Validation loss = 3.8005  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 4.1964  Validation loss = 3.7999  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 4.1960  Validation loss = 3.7995  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 4.1957  Validation loss = 3.7991  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 4.1953  Validation loss = 3.7986  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 4.1950  Validation loss = 3.7983  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 4.1947  Validation loss = 3.7979  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 4.1944  Validation loss = 3.7975  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 4.1940  Validation loss = 3.7971  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 4.1936  Validation loss = 3.7966  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 4.1933  Validation loss = 3.7962  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 4.1929  Validation loss = 3.7958  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 4.1925  Validation loss = 3.7953  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 4.1920  Validation loss = 3.7948  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 4.1917  Validation loss = 3.7944  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 4.1915  Validation loss = 3.7942  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 4.1911  Validation loss = 3.7937  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 4.1907  Validation loss = 3.7932  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 4.1902  Validation loss = 3.7927  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 4.1898  Validation loss = 3.7922  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 4.1893  Validation loss = 3.7916  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 4.1888  Validation loss = 3.7911  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 4.1885  Validation loss = 3.7907  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 4.1880  Validation loss = 3.7902  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 4.1876  Validation loss = 3.7897  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 4.1872  Validation loss = 3.7891  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 4.1869  Validation loss = 3.7887  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 4.1866  Validation loss = 3.7884  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 4.1862  Validation loss = 3.7879  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 4.1859  Validation loss = 3.7875  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 4.1855  Validation loss = 3.7871  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 4.1851  Validation loss = 3.7866  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 4.1848  Validation loss = 3.7863  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 4.1845  Validation loss = 3.7859  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 4.1842  Validation loss = 3.7855  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 4.1837  Validation loss = 3.7850  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 4.1834  Validation loss = 3.7847  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 4.1831  Validation loss = 3.7843  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 4.1826  Validation loss = 3.7838  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 4.1823  Validation loss = 3.7834  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 4.1819  Validation loss = 3.7829  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 4.1817  Validation loss = 3.7827  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 4.1814  Validation loss = 3.7822  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 4.1810  Validation loss = 3.7818  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 4.1807  Validation loss = 3.7814  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 4.1804  Validation loss = 3.7810  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 4.1799  Validation loss = 3.7805  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 4.1794  Validation loss = 3.7800  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 4.1789  Validation loss = 3.7794  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 4.1784  Validation loss = 3.7789  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 4.1780  Validation loss = 3.7784  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 4.1776  Validation loss = 3.7779  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 4.1770  Validation loss = 3.7774  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 4.1766  Validation loss = 3.7768  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 4.1762  Validation loss = 3.7764  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 4.1757  Validation loss = 3.7759  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 4.1753  Validation loss = 3.7754  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 4.1750  Validation loss = 3.7751  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 4.1746  Validation loss = 3.7746  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 4.1744  Validation loss = 3.7743  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 4.1740  Validation loss = 3.7739  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 4.1735  Validation loss = 3.7734  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 4.1732  Validation loss = 3.7730  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 4.1729  Validation loss = 3.7726  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 4.1724  Validation loss = 3.7721  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 4.1719  Validation loss = 3.7717  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 4.1716  Validation loss = 3.7713  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 4.1712  Validation loss = 3.7709  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 4.1709  Validation loss = 3.7705  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 4.1705  Validation loss = 3.7700  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 4.1700  Validation loss = 3.7695  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 4.1696  Validation loss = 3.7691  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 4.1692  Validation loss = 3.7685  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 4.1687  Validation loss = 3.7679  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 4.1684  Validation loss = 3.7676  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 4.1681  Validation loss = 3.7672  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 4.1677  Validation loss = 3.7667  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 4.1673  Validation loss = 3.7664  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 4.1669  Validation loss = 3.7659  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 4.1664  Validation loss = 3.7654  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 4.1660  Validation loss = 3.7649  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 4.1654  Validation loss = 3.7643  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 4.1649  Validation loss = 3.7639  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 4.1644  Validation loss = 3.7634  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 4.1639  Validation loss = 3.7629  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 4.1635  Validation loss = 3.7625  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 4.1630  Validation loss = 3.7620  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 4.1626  Validation loss = 3.7616  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 4.1622  Validation loss = 3.7611  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 4.1618  Validation loss = 3.7607  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 4.1612  Validation loss = 3.7602  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 4.1606  Validation loss = 3.7597  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 4.1601  Validation loss = 3.7594  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 4.1595  Validation loss = 3.7589  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 4.1591  Validation loss = 3.7584  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 4.1586  Validation loss = 3.7579  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 4.1581  Validation loss = 3.7575  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 4.1573  Validation loss = 3.7570  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 4.1568  Validation loss = 3.7567  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 4.1564  Validation loss = 3.7562  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 4.1558  Validation loss = 3.7557  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 4.1554  Validation loss = 3.7554  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 4.1550  Validation loss = 3.7551  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 4.1544  Validation loss = 3.7546  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 4.1540  Validation loss = 3.7541  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 4.1534  Validation loss = 3.7536  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 4.1528  Validation loss = 3.7531  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 4.1526  Validation loss = 3.7528  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 4.1521  Validation loss = 3.7523  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 4.1515  Validation loss = 3.7517  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 4.1510  Validation loss = 3.7513  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 4.1506  Validation loss = 3.7509  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 4.1502  Validation loss = 3.7505  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 4.1499  Validation loss = 3.7501  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 4.1493  Validation loss = 3.7496  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 4.1487  Validation loss = 3.7490  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 4.1479  Validation loss = 3.7485  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 4.1472  Validation loss = 3.7479  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 4.1469  Validation loss = 3.7475  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 4.1464  Validation loss = 3.7470  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 4.1458  Validation loss = 3.7464  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 4.1453  Validation loss = 3.7460  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 4.1449  Validation loss = 3.7456  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 4.1444  Validation loss = 3.7451  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 4.1438  Validation loss = 3.7446  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 4.1432  Validation loss = 3.7442  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 4.1429  Validation loss = 3.7438  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 4.1425  Validation loss = 3.7434  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 4.1420  Validation loss = 3.7430  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 4.1416  Validation loss = 3.7426  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 4.1410  Validation loss = 3.7421  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 4.1404  Validation loss = 3.7416  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 4.1401  Validation loss = 3.7411  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 4.1397  Validation loss = 3.7406  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 4.1392  Validation loss = 3.7402  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 4.1386  Validation loss = 3.7397  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 4.1382  Validation loss = 3.7394  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 4.1376  Validation loss = 3.7389  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 4.1372  Validation loss = 3.7385  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 4.1368  Validation loss = 3.7381  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 4.1362  Validation loss = 3.7376  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 4.1356  Validation loss = 3.7371  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 4.1350  Validation loss = 3.7367  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 4.1346  Validation loss = 3.7363  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 4.1343  Validation loss = 3.7360  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 4.1335  Validation loss = 3.7354  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 4.1329  Validation loss = 3.7350  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 4.1326  Validation loss = 3.7347  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 4.1321  Validation loss = 3.7343  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 4.1316  Validation loss = 3.7339  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 4.1310  Validation loss = 3.7334  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 4.1303  Validation loss = 3.7329  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 4.1298  Validation loss = 3.7325  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 4.1293  Validation loss = 3.7320  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 4.1289  Validation loss = 3.7316  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 4.1283  Validation loss = 3.7311  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 4.1276  Validation loss = 3.7307  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 4.1271  Validation loss = 3.7302  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 4.1266  Validation loss = 3.7298  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 4.1261  Validation loss = 3.7293  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 4.1257  Validation loss = 3.7289  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 4.1251  Validation loss = 3.7285  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 4.1245  Validation loss = 3.7280  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 4.1240  Validation loss = 3.7275  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 4.1232  Validation loss = 3.7271  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 4.1227  Validation loss = 3.7267  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 4.1221  Validation loss = 3.7261  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 4.1215  Validation loss = 3.7256  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 4.1211  Validation loss = 3.7252  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 4.1205  Validation loss = 3.7247  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 4.1199  Validation loss = 3.7242  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 4.1195  Validation loss = 3.7237  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 4.1189  Validation loss = 3.7233  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 4.1183  Validation loss = 3.7229  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 4.1176  Validation loss = 3.7223  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 4.1166  Validation loss = 3.7217  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 4.1160  Validation loss = 3.7212  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 4.1153  Validation loss = 3.7207  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 4.1148  Validation loss = 3.7202  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 4.1139  Validation loss = 3.7197  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 4.1134  Validation loss = 3.7192  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 4.1128  Validation loss = 3.7187  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 4.1124  Validation loss = 3.7183  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 4.1120  Validation loss = 3.7178  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 4.1117  Validation loss = 3.7175  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 4.1113  Validation loss = 3.7170  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 4.1110  Validation loss = 3.7166  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 4.1105  Validation loss = 3.7161  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 4.1100  Validation loss = 3.7156  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 4.1096  Validation loss = 3.7153  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 4.1092  Validation loss = 3.7148  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 4.1088  Validation loss = 3.7144  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 4.1082  Validation loss = 3.7139  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 4.1079  Validation loss = 3.7135  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 4.1074  Validation loss = 3.7130  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 4.1068  Validation loss = 3.7125  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 4.1063  Validation loss = 3.7121  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 4.1059  Validation loss = 3.7117  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 4.1056  Validation loss = 3.7113  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 4.1051  Validation loss = 3.7109  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 4.1044  Validation loss = 3.7104  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 4.1041  Validation loss = 3.7100  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 4.1036  Validation loss = 3.7095  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 4.1029  Validation loss = 3.7089  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 4.1024  Validation loss = 3.7084  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 4.1019  Validation loss = 3.7078  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 4.1013  Validation loss = 3.7073  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 4.1010  Validation loss = 3.7069  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 4.1006  Validation loss = 3.7064  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 4.1002  Validation loss = 3.7060  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 4.0999  Validation loss = 3.7057  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 4.0996  Validation loss = 3.7052  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 4.0991  Validation loss = 3.7048  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 4.0988  Validation loss = 3.7043  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 4.0984  Validation loss = 3.7039  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 4.0981  Validation loss = 3.7035  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 4.0976  Validation loss = 3.7030  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 4.0973  Validation loss = 3.7026  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 4.0969  Validation loss = 3.7021  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 4.0964  Validation loss = 3.7017  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 4.0959  Validation loss = 3.7012  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 4.0955  Validation loss = 3.7007  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 4.0951  Validation loss = 3.7002  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 4.0948  Validation loss = 3.6998  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 4.0944  Validation loss = 3.6994  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 4.0941  Validation loss = 3.6990  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 4.0935  Validation loss = 3.6984  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 4.0932  Validation loss = 3.6980  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 4.0929  Validation loss = 3.6975  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 4.0926  Validation loss = 3.6972  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 4.0922  Validation loss = 3.6967  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 4.0919  Validation loss = 3.6963  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 4.0915  Validation loss = 3.6958  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 500  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 4.1842  Validation loss = 5.3675  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 4.1838  Validation loss = 5.3671  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 4.1834  Validation loss = 5.3666  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 4.1829  Validation loss = 5.3660  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 4.1826  Validation loss = 5.3656  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 4.1823  Validation loss = 5.3651  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 4.1818  Validation loss = 5.3645  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 4.1814  Validation loss = 5.3640  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 4.1811  Validation loss = 5.3635  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 4.1806  Validation loss = 5.3629  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 4.1803  Validation loss = 5.3625  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 4.1799  Validation loss = 5.3620  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 4.1795  Validation loss = 5.3615  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 4.1792  Validation loss = 5.3611  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 4.1789  Validation loss = 5.3608  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 4.1785  Validation loss = 5.3603  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 4.1781  Validation loss = 5.3597  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 4.1777  Validation loss = 5.3591  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 4.1773  Validation loss = 5.3586  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 4.1769  Validation loss = 5.3581  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 4.1765  Validation loss = 5.3575  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 4.1761  Validation loss = 5.3571  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 4.1757  Validation loss = 5.3565  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 4.1753  Validation loss = 5.3559  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 4.1748  Validation loss = 5.3553  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 4.1745  Validation loss = 5.3548  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 4.1741  Validation loss = 5.3544  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 4.1737  Validation loss = 5.3538  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 4.1734  Validation loss = 5.3533  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 4.1729  Validation loss = 5.3528  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 4.1726  Validation loss = 5.3523  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 4.1722  Validation loss = 5.3519  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 4.1717  Validation loss = 5.3513  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 4.1713  Validation loss = 5.3507  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 4.1709  Validation loss = 5.3502  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 4.1705  Validation loss = 5.3497  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 4.1703  Validation loss = 5.3493  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 4.1700  Validation loss = 5.3490  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 4.1696  Validation loss = 5.3485  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 4.1693  Validation loss = 5.3480  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 4.1688  Validation loss = 5.3475  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 4.1684  Validation loss = 5.3469  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 4.1680  Validation loss = 5.3464  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 4.1676  Validation loss = 5.3459  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 4.1669  Validation loss = 5.3453  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 4.1601  Validation loss = 5.3447  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 4.1590  Validation loss = 5.3442  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 4.1587  Validation loss = 5.3438  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 4.1583  Validation loss = 5.3432  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 4.1580  Validation loss = 5.3427  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 4.1576  Validation loss = 5.3421  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 4.1573  Validation loss = 5.3417  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 4.1570  Validation loss = 5.3413  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 4.1567  Validation loss = 5.3410  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 4.1564  Validation loss = 5.3405  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 4.1562  Validation loss = 5.3402  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 4.1558  Validation loss = 5.3396  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 4.1554  Validation loss = 5.3391  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 4.1551  Validation loss = 5.3387  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 4.1548  Validation loss = 5.3382  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 4.1544  Validation loss = 5.3376  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 4.1541  Validation loss = 5.3371  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 4.1537  Validation loss = 5.3365  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 4.1534  Validation loss = 5.3360  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 4.1531  Validation loss = 5.3355  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 4.1527  Validation loss = 5.3350  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 4.1524  Validation loss = 5.3345  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 4.1520  Validation loss = 5.3338  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 4.1517  Validation loss = 5.3334  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 4.1514  Validation loss = 5.3329  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 4.1510  Validation loss = 5.3322  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 4.1506  Validation loss = 5.3317  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 4.1503  Validation loss = 5.3311  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 4.1499  Validation loss = 5.3305  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 4.1496  Validation loss = 5.3300  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 4.1493  Validation loss = 5.3296  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 4.1490  Validation loss = 5.3292  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 4.1487  Validation loss = 5.3286  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 4.1483  Validation loss = 5.3281  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 4.1480  Validation loss = 5.3277  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 4.1477  Validation loss = 5.3272  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 4.1474  Validation loss = 5.3267  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 4.1470  Validation loss = 5.3260  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 4.1467  Validation loss = 5.3255  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 4.1464  Validation loss = 5.3252  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 4.1461  Validation loss = 5.3248  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 4.1458  Validation loss = 5.3242  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 4.1455  Validation loss = 5.3237  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 4.1451  Validation loss = 5.3230  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 4.1447  Validation loss = 5.3226  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 4.1444  Validation loss = 5.3221  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 4.1441  Validation loss = 5.3215  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 4.1437  Validation loss = 5.3210  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 4.1434  Validation loss = 5.3207  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 4.1431  Validation loss = 5.3202  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 4.1428  Validation loss = 5.3198  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 4.1425  Validation loss = 5.3193  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 4.1422  Validation loss = 5.3187  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 4.1418  Validation loss = 5.3181  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 4.1415  Validation loss = 5.3176  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 4.1412  Validation loss = 5.3171  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 4.1408  Validation loss = 5.3165  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 4.1405  Validation loss = 5.3161  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 4.1401  Validation loss = 5.3154  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 4.1398  Validation loss = 5.3150  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 4.1395  Validation loss = 5.3144  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 4.1391  Validation loss = 5.3139  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 4.1387  Validation loss = 5.3131  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 4.1384  Validation loss = 5.3126  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 4.1380  Validation loss = 5.3120  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 4.1377  Validation loss = 5.3116  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 4.1373  Validation loss = 5.3110  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 4.1370  Validation loss = 5.3104  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 4.1366  Validation loss = 5.3098  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 4.1363  Validation loss = 5.3093  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 4.1360  Validation loss = 5.3087  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 4.1356  Validation loss = 5.3079  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 4.1352  Validation loss = 5.3075  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 4.1349  Validation loss = 5.3071  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 4.1346  Validation loss = 5.3066  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 4.1343  Validation loss = 5.3062  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 4.1340  Validation loss = 5.3057  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 4.1336  Validation loss = 5.3051  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 4.1333  Validation loss = 5.3046  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 4.1330  Validation loss = 5.3042  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 4.1325  Validation loss = 5.3035  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 4.1322  Validation loss = 5.3030  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 4.1319  Validation loss = 5.3025  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 4.1316  Validation loss = 5.3020  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 4.1312  Validation loss = 5.3014  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 4.1309  Validation loss = 5.3009  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 4.1305  Validation loss = 5.3004  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 4.1302  Validation loss = 5.2999  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 4.1298  Validation loss = 5.2993  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 4.1294  Validation loss = 5.2986  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 4.1291  Validation loss = 5.2981  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 4.1288  Validation loss = 5.2976  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 4.1285  Validation loss = 5.2973  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 4.1281  Validation loss = 5.2967  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 4.1278  Validation loss = 5.2961  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 4.1274  Validation loss = 5.2956  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 4.1271  Validation loss = 5.2951  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 4.1269  Validation loss = 5.2947  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 4.1265  Validation loss = 5.2941  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 4.1262  Validation loss = 5.2937  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 4.1260  Validation loss = 5.2933  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 4.1256  Validation loss = 5.2928  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 4.1253  Validation loss = 5.2923  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 4.1250  Validation loss = 5.2918  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 4.1247  Validation loss = 5.2913  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 4.1243  Validation loss = 5.2908  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 4.1240  Validation loss = 5.2904  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 4.1236  Validation loss = 5.2898  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 4.1232  Validation loss = 5.2890  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 4.1228  Validation loss = 5.2884  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 4.1225  Validation loss = 5.2880  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 4.1222  Validation loss = 5.2874  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 4.1218  Validation loss = 5.2868  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 4.1215  Validation loss = 5.2864  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 4.1212  Validation loss = 5.2860  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 4.1209  Validation loss = 5.2855  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 4.1206  Validation loss = 5.2851  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 4.1203  Validation loss = 5.2846  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 4.1200  Validation loss = 5.2841  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 4.1196  Validation loss = 5.2835  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 4.1193  Validation loss = 5.2831  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 4.1190  Validation loss = 5.2827  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 4.1187  Validation loss = 5.2821  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 4.1184  Validation loss = 5.2818  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 4.1181  Validation loss = 5.2811  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 4.1177  Validation loss = 5.2806  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 4.1174  Validation loss = 5.2801  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 4.1171  Validation loss = 5.2796  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 4.1169  Validation loss = 5.2792  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 4.1165  Validation loss = 5.2787  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 4.1162  Validation loss = 5.2781  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 4.1158  Validation loss = 5.2774  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 4.1154  Validation loss = 5.2768  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 4.1151  Validation loss = 5.2764  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 4.1148  Validation loss = 5.2759  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 4.1145  Validation loss = 5.2754  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 4.1142  Validation loss = 5.2749  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 4.1139  Validation loss = 5.2746  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 4.1136  Validation loss = 5.2740  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 4.1133  Validation loss = 5.2734  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 4.1129  Validation loss = 5.2729  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 4.1126  Validation loss = 5.2725  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 4.1123  Validation loss = 5.2718  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 4.1119  Validation loss = 5.2711  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 4.1116  Validation loss = 5.2706  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 4.1112  Validation loss = 5.2698  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 4.1109  Validation loss = 5.2693  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 4.1106  Validation loss = 5.2689  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 4.1103  Validation loss = 5.2684  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 4.1099  Validation loss = 5.2678  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 4.1095  Validation loss = 5.2672  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 4.1092  Validation loss = 5.2668  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 4.1090  Validation loss = 5.2664  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 4.1086  Validation loss = 5.2659  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 4.1083  Validation loss = 5.2655  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 4.1081  Validation loss = 5.2652  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 4.1078  Validation loss = 5.2647  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 4.1076  Validation loss = 5.2643  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 4.1072  Validation loss = 5.2637  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 4.1068  Validation loss = 5.2632  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 4.1065  Validation loss = 5.2627  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 4.1062  Validation loss = 5.2624  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 4.1060  Validation loss = 5.2620  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 4.1056  Validation loss = 5.2614  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 4.1053  Validation loss = 5.2608  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 4.1050  Validation loss = 5.2603  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 4.1046  Validation loss = 5.2598  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 4.1042  Validation loss = 5.2592  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 4.1040  Validation loss = 5.2587  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 4.1036  Validation loss = 5.2580  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 4.1033  Validation loss = 5.2575  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 4.1029  Validation loss = 5.2569  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 4.1027  Validation loss = 5.2565  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 4.1023  Validation loss = 5.2559  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 4.1020  Validation loss = 5.2555  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 4.1016  Validation loss = 5.2548  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 4.1013  Validation loss = 5.2542  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 4.1009  Validation loss = 5.2537  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 4.1006  Validation loss = 5.2531  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 4.1003  Validation loss = 5.2526  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 4.0999  Validation loss = 5.2521  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 4.0997  Validation loss = 5.2517  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 4.0993  Validation loss = 5.2512  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 4.0990  Validation loss = 5.2506  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 4.0986  Validation loss = 5.2501  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 4.0983  Validation loss = 5.2494  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 4.0980  Validation loss = 5.2489  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 4.0977  Validation loss = 5.2485  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 4.0975  Validation loss = 5.2483  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 4.0972  Validation loss = 5.2479  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 4.0968  Validation loss = 5.2472  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 4.0965  Validation loss = 5.2467  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 4.0961  Validation loss = 5.2462  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 4.0958  Validation loss = 5.2456  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 4.0955  Validation loss = 5.2453  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 4.0953  Validation loss = 5.2449  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 4.0949  Validation loss = 5.2444  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 4.0947  Validation loss = 5.2440  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 4.0943  Validation loss = 5.2434  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 4.0940  Validation loss = 5.2431  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 4.0937  Validation loss = 5.2426  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 4.0934  Validation loss = 5.2422  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 4.0931  Validation loss = 5.2417  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 4.0928  Validation loss = 5.2412  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 4.0925  Validation loss = 5.2406  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 4.0921  Validation loss = 5.2399  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 4.0917  Validation loss = 5.2394  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 4.0914  Validation loss = 5.2389  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 4.0911  Validation loss = 5.2384  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 4.0909  Validation loss = 5.2381  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 4.0905  Validation loss = 5.2376  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 4.0902  Validation loss = 5.2373  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 4.0900  Validation loss = 5.2368  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 4.0897  Validation loss = 5.2365  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 4.0894  Validation loss = 5.2360  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 4.0891  Validation loss = 5.2356  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 4.0888  Validation loss = 5.2352  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 4.0885  Validation loss = 5.2348  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 4.0881  Validation loss = 5.2343  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 4.0878  Validation loss = 5.2338  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 4.0874  Validation loss = 5.2330  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 4.0870  Validation loss = 5.2325  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 4.0867  Validation loss = 5.2320  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 4.0864  Validation loss = 5.2316  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 4.0861  Validation loss = 5.2312  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 4.0858  Validation loss = 5.2307  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 4.0855  Validation loss = 5.2303  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 4.0852  Validation loss = 5.2298  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 4.0849  Validation loss = 5.2292  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 4.0845  Validation loss = 5.2287  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 4.0843  Validation loss = 5.2282  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 4.0839  Validation loss = 5.2278  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 4.0837  Validation loss = 5.2273  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 4.0833  Validation loss = 5.2267  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 4.0829  Validation loss = 5.2262  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 4.0825  Validation loss = 5.2254  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 4.0821  Validation loss = 5.2247  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 4.0818  Validation loss = 5.2242  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 4.0815  Validation loss = 5.2237  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 4.0811  Validation loss = 5.2231  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 4.0809  Validation loss = 5.2228  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 4.0805  Validation loss = 5.2222  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 4.0803  Validation loss = 5.2219  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 4.0799  Validation loss = 5.2212  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 4.0796  Validation loss = 5.2208  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 4.0793  Validation loss = 5.2203  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 4.0790  Validation loss = 5.2197  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 4.0787  Validation loss = 5.2193  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 4.0783  Validation loss = 5.2186  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 4.0779  Validation loss = 5.2180  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 4.0777  Validation loss = 5.2176  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 4.0775  Validation loss = 5.2173  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 4.0771  Validation loss = 5.2167  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 4.0767  Validation loss = 5.2161  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 4.0764  Validation loss = 5.2157  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 4.0761  Validation loss = 5.2152  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 4.0758  Validation loss = 5.2148  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 4.0755  Validation loss = 5.2143  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 4.0751  Validation loss = 5.2138  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 4.0748  Validation loss = 5.2132  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 4.0744  Validation loss = 5.2127  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 4.0740  Validation loss = 5.2119  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 4.0737  Validation loss = 5.2115  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 4.0733  Validation loss = 5.2111  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 4.0731  Validation loss = 5.2106  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 4.0727  Validation loss = 5.2102  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 4.0725  Validation loss = 5.2098  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 4.0721  Validation loss = 5.2093  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 4.0718  Validation loss = 5.2088  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 4.0716  Validation loss = 5.2085  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 4.0713  Validation loss = 5.2081  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 4.0709  Validation loss = 5.2075  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 4.0707  Validation loss = 5.2071  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 4.0703  Validation loss = 5.2066  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 4.0700  Validation loss = 5.2062  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 4.0697  Validation loss = 5.2057  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 4.0694  Validation loss = 5.2052  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 4.0690  Validation loss = 5.2047  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 4.0687  Validation loss = 5.2041  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 4.0683  Validation loss = 5.2035  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 4.0680  Validation loss = 5.2029  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 4.0677  Validation loss = 5.2025  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 4.0674  Validation loss = 5.2020  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 4.0671  Validation loss = 5.2016  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 4.0668  Validation loss = 5.2012  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 4.0664  Validation loss = 5.2005  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 4.0661  Validation loss = 5.2000  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 4.0658  Validation loss = 5.1996  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 4.0655  Validation loss = 5.1991  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 4.0651  Validation loss = 5.1985  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 4.0647  Validation loss = 5.1979  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 4.0644  Validation loss = 5.1974  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 4.0641  Validation loss = 5.1970  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 4.0637  Validation loss = 5.1964  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 4.0634  Validation loss = 5.1960  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 4.0630  Validation loss = 5.1952  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 4.0627  Validation loss = 5.1948  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 4.0624  Validation loss = 5.1944  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 4.0621  Validation loss = 5.1940  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 4.0618  Validation loss = 5.1936  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 4.0614  Validation loss = 5.1929  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 4.0612  Validation loss = 5.1926  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 4.0609  Validation loss = 5.1922  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 4.0606  Validation loss = 5.1919  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 4.0603  Validation loss = 5.1914  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 4.0600  Validation loss = 5.1909  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 4.0597  Validation loss = 5.1903  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 4.0594  Validation loss = 5.1899  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 4.0591  Validation loss = 5.1894  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 4.0588  Validation loss = 5.1889  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 4.0585  Validation loss = 5.1884  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 4.0580  Validation loss = 5.1876  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 4.0576  Validation loss = 5.1870  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 4.0574  Validation loss = 5.1865  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 4.0570  Validation loss = 5.1860  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 4.0567  Validation loss = 5.1856  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 4.0564  Validation loss = 5.1849  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 4.0560  Validation loss = 5.1844  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 4.0556  Validation loss = 5.1838  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 4.0552  Validation loss = 5.1832  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 4.0549  Validation loss = 5.1826  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 4.0546  Validation loss = 5.1822  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 4.0542  Validation loss = 5.1816  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 4.0539  Validation loss = 5.1811  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 4.0536  Validation loss = 5.1805  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 4.0532  Validation loss = 5.1799  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 4.0529  Validation loss = 5.1794  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 4.0526  Validation loss = 5.1788  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 4.0522  Validation loss = 5.1782  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 4.0519  Validation loss = 5.1777  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 4.0516  Validation loss = 5.1772  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 4.0513  Validation loss = 5.1768  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 4.0510  Validation loss = 5.1763  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 4.0507  Validation loss = 5.1758  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 4.0503  Validation loss = 5.1753  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 4.0500  Validation loss = 5.1747  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 4.0497  Validation loss = 5.1742  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 4.0494  Validation loss = 5.1737  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 4.0491  Validation loss = 5.1733  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 4.0487  Validation loss = 5.1728  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 4.0484  Validation loss = 5.1723  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 4.0482  Validation loss = 5.1719  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 4.0479  Validation loss = 5.1715  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 4.0476  Validation loss = 5.1711  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 4.0473  Validation loss = 5.1706  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 4.0469  Validation loss = 5.1700  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 4.0466  Validation loss = 5.1695  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 4.0463  Validation loss = 5.1690  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 4.0461  Validation loss = 5.1687  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 4.0458  Validation loss = 5.1682  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 4.0454  Validation loss = 5.1678  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 4.0451  Validation loss = 5.1673  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 4.0448  Validation loss = 5.1667  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 4.0445  Validation loss = 5.1663  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 4.0442  Validation loss = 5.1658  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 4.0438  Validation loss = 5.1653  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 4.0435  Validation loss = 5.1648  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 4.0432  Validation loss = 5.1645  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 4.0429  Validation loss = 5.1641  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 4.0426  Validation loss = 5.1636  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 4.0422  Validation loss = 5.1631  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 4.0419  Validation loss = 5.1626  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 4.0415  Validation loss = 5.1621  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 4.0412  Validation loss = 5.1616  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 4.0409  Validation loss = 5.1611  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 4.0405  Validation loss = 5.1605  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 4.0402  Validation loss = 5.1599  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 4.0400  Validation loss = 5.1595  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 4.0397  Validation loss = 5.1591  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 4.0394  Validation loss = 5.1586  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 4.0391  Validation loss = 5.1581  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 4.0388  Validation loss = 5.1577  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 4.0385  Validation loss = 5.1572  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 4.0382  Validation loss = 5.1567  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 4.0379  Validation loss = 5.1563  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 4.0375  Validation loss = 5.1557  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 4.0372  Validation loss = 5.1554  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 4.0369  Validation loss = 5.1548  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 4.0365  Validation loss = 5.1542  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 4.0362  Validation loss = 5.1537  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 4.0359  Validation loss = 5.1533  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 4.0355  Validation loss = 5.1527  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 4.0351  Validation loss = 5.1520  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 4.0347  Validation loss = 5.1513  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 4.0343  Validation loss = 5.1506  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 4.0340  Validation loss = 5.1503  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 4.0337  Validation loss = 5.1498  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 4.0333  Validation loss = 5.1493  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 4.0330  Validation loss = 5.1488  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 4.0326  Validation loss = 5.1482  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 4.0322  Validation loss = 5.1476  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 4.0319  Validation loss = 5.1471  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 4.0315  Validation loss = 5.1465  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 4.0309  Validation loss = 5.1458  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 4.0297  Validation loss = 5.1449  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 4.0283  Validation loss = 5.1442  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 4.0272  Validation loss = 5.1434  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 4.0260  Validation loss = 5.1426  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 4.0254  Validation loss = 5.1420  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 4.0252  Validation loss = 5.1417  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 4.0247  Validation loss = 5.1410  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 4.0243  Validation loss = 5.1404  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 4.0240  Validation loss = 5.1401  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 4.0236  Validation loss = 5.1395  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 4.0232  Validation loss = 5.1388  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 4.0229  Validation loss = 5.1382  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 4.0226  Validation loss = 5.1377  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 4.0222  Validation loss = 5.1372  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 4.0218  Validation loss = 5.1364  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 4.0214  Validation loss = 5.1359  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 4.0211  Validation loss = 5.1352  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 4.0208  Validation loss = 5.1348  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 4.0205  Validation loss = 5.1343  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 4.0200  Validation loss = 5.1336  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 4.0197  Validation loss = 5.1330  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 4.0194  Validation loss = 5.1326  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 4.0190  Validation loss = 5.1320  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 4.0187  Validation loss = 5.1315  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 4.0184  Validation loss = 5.1310  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 4.0181  Validation loss = 5.1304  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 4.0178  Validation loss = 5.1299  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 4.0174  Validation loss = 5.1293  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 4.0171  Validation loss = 5.1288  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 4.0168  Validation loss = 5.1282  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 4.0164  Validation loss = 5.1275  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 4.0162  Validation loss = 5.1272  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 4.0159  Validation loss = 5.1267  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 4.0156  Validation loss = 5.1263  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 4.0154  Validation loss = 5.1259  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 4.0150  Validation loss = 5.1255  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 4.0147  Validation loss = 5.1251  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 4.0144  Validation loss = 5.1246  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 4.0142  Validation loss = 5.1242  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 4.0139  Validation loss = 5.1237  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 4.0136  Validation loss = 5.1231  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 4.0133  Validation loss = 5.1227  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 4.0129  Validation loss = 5.1221  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 4.0126  Validation loss = 5.1216  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 4.0123  Validation loss = 5.1210  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 4.0119  Validation loss = 5.1205  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 4.0116  Validation loss = 5.1199  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 4.0113  Validation loss = 5.1196  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 4.0110  Validation loss = 5.1191  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 4.0107  Validation loss = 5.1187  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 4.0104  Validation loss = 5.1181  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 4.0100  Validation loss = 5.1177  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 4.0097  Validation loss = 5.1172  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 4.0094  Validation loss = 5.1168  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 4.0091  Validation loss = 5.1162  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 4.0088  Validation loss = 5.1157  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 4.0085  Validation loss = 5.1153  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 4.0082  Validation loss = 5.1149  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 4.0079  Validation loss = 5.1144  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 4.0076  Validation loss = 5.1140  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 4.0073  Validation loss = 5.1134  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 500  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 4.1914  Validation loss = 7.2226  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 4.1911  Validation loss = 7.2221  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 4.1906  Validation loss = 7.2214  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 4.1903  Validation loss = 7.2209  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 4.1899  Validation loss = 7.2203  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 4.1895  Validation loss = 7.2197  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 4.1892  Validation loss = 7.2192  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 4.1888  Validation loss = 7.2186  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 4.1884  Validation loss = 7.2180  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 4.1880  Validation loss = 7.2174  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 4.1876  Validation loss = 7.2168  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 4.1872  Validation loss = 7.2161  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 4.1868  Validation loss = 7.2155  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 4.1864  Validation loss = 7.2149  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 4.1860  Validation loss = 7.2142  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 4.1855  Validation loss = 7.2136  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 4.1851  Validation loss = 7.2130  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 4.1847  Validation loss = 7.2123  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 4.1844  Validation loss = 7.2118  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 4.1840  Validation loss = 7.2113  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 4.1837  Validation loss = 7.2108  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 4.1833  Validation loss = 7.2102  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 4.1829  Validation loss = 7.2096  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 4.1825  Validation loss = 7.2090  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 4.1822  Validation loss = 7.2085  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 4.1818  Validation loss = 7.2079  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 4.1814  Validation loss = 7.2073  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 4.1811  Validation loss = 7.2068  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 4.1807  Validation loss = 7.2062  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 4.1803  Validation loss = 7.2056  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 4.1800  Validation loss = 7.2051  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 4.1796  Validation loss = 7.2045  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 4.1792  Validation loss = 7.2038  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 4.1788  Validation loss = 7.2032  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 4.1784  Validation loss = 7.2027  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 4.1781  Validation loss = 7.2021  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 4.1777  Validation loss = 7.2015  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 4.1773  Validation loss = 7.2010  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 4.1770  Validation loss = 7.2004  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 4.1765  Validation loss = 7.1997  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 4.1762  Validation loss = 7.1992  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 4.1759  Validation loss = 7.1987  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 4.1755  Validation loss = 7.1981  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 4.1751  Validation loss = 7.1976  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 4.1747  Validation loss = 7.1969  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 4.1742  Validation loss = 7.1962  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 4.1739  Validation loss = 7.1957  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 4.1734  Validation loss = 7.1949  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 4.1730  Validation loss = 7.1943  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 4.1726  Validation loss = 7.1937  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 4.1723  Validation loss = 7.1932  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 4.1719  Validation loss = 7.1927  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 4.1716  Validation loss = 7.1922  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 4.1712  Validation loss = 7.1915  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 4.1709  Validation loss = 7.1910  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 4.1705  Validation loss = 7.1904  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 4.1701  Validation loss = 7.1899  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 4.1698  Validation loss = 7.1894  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 4.1694  Validation loss = 7.1887  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 4.1690  Validation loss = 7.1882  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 4.1686  Validation loss = 7.1875  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 4.1683  Validation loss = 7.1870  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 4.1679  Validation loss = 7.1864  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 4.1675  Validation loss = 7.1858  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 4.1672  Validation loss = 7.1853  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 4.1668  Validation loss = 7.1848  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 4.1665  Validation loss = 7.1842  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 4.1661  Validation loss = 7.1836  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 4.1658  Validation loss = 7.1832  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 4.1655  Validation loss = 7.1826  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 4.1650  Validation loss = 7.1820  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 4.1647  Validation loss = 7.1815  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 4.1644  Validation loss = 7.1809  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 4.1639  Validation loss = 7.1803  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 4.1636  Validation loss = 7.1798  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 4.1632  Validation loss = 7.1792  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 4.1628  Validation loss = 7.1786  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 4.1625  Validation loss = 7.1780  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 4.1622  Validation loss = 7.1775  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 4.1617  Validation loss = 7.1768  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 4.1612  Validation loss = 7.1761  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 4.1608  Validation loss = 7.1754  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 4.1604  Validation loss = 7.1748  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 4.1601  Validation loss = 7.1743  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 4.1597  Validation loss = 7.1737  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 4.1593  Validation loss = 7.1731  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 4.1589  Validation loss = 7.1725  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 4.1584  Validation loss = 7.1718  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 4.1582  Validation loss = 7.1714  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 4.1577  Validation loss = 7.1707  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 4.1574  Validation loss = 7.1702  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 4.1571  Validation loss = 7.1696  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 4.1567  Validation loss = 7.1690  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 4.1563  Validation loss = 7.1685  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 4.1559  Validation loss = 7.1679  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 4.1556  Validation loss = 7.1673  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 4.1552  Validation loss = 7.1667  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 4.1548  Validation loss = 7.1661  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 4.1545  Validation loss = 7.1656  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 4.1539  Validation loss = 7.1648  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 4.1535  Validation loss = 7.1640  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 4.1531  Validation loss = 7.1634  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 4.1528  Validation loss = 7.1629  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 4.1523  Validation loss = 7.1623  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 4.1520  Validation loss = 7.1617  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 4.1516  Validation loss = 7.1612  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 4.1513  Validation loss = 7.1607  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 4.1510  Validation loss = 7.1602  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 4.1506  Validation loss = 7.1596  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 4.1503  Validation loss = 7.1591  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 4.1499  Validation loss = 7.1586  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 4.1496  Validation loss = 7.1580  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 4.1491  Validation loss = 7.1573  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 4.1488  Validation loss = 7.1567  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 4.1485  Validation loss = 7.1563  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 4.1481  Validation loss = 7.1557  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 4.1477  Validation loss = 7.1551  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 4.1473  Validation loss = 7.1544  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 4.1469  Validation loss = 7.1538  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 4.1465  Validation loss = 7.1532  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 4.1462  Validation loss = 7.1527  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 4.1458  Validation loss = 7.1522  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 4.1454  Validation loss = 7.1516  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 4.1451  Validation loss = 7.1511  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 4.1447  Validation loss = 7.1504  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 4.1443  Validation loss = 7.1499  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 4.1439  Validation loss = 7.1492  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 4.1434  Validation loss = 7.1485  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 4.1430  Validation loss = 7.1478  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 4.1425  Validation loss = 7.1471  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 4.1422  Validation loss = 7.1465  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 4.1418  Validation loss = 7.1459  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 4.1415  Validation loss = 7.1454  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 4.1411  Validation loss = 7.1449  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 4.1407  Validation loss = 7.1442  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 4.1404  Validation loss = 7.1437  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 4.1400  Validation loss = 7.1432  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 4.1396  Validation loss = 7.1425  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 4.1392  Validation loss = 7.1419  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 4.1388  Validation loss = 7.1413  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 4.1385  Validation loss = 7.1408  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 4.1381  Validation loss = 7.1402  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 4.1377  Validation loss = 7.1395  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 4.1372  Validation loss = 7.1388  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 4.1369  Validation loss = 7.1383  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 4.1366  Validation loss = 7.1378  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 4.1362  Validation loss = 7.1372  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 4.1358  Validation loss = 7.1366  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 4.1354  Validation loss = 7.1361  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 4.1350  Validation loss = 7.1354  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 4.1346  Validation loss = 7.1347  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 4.1342  Validation loss = 7.1342  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 4.1338  Validation loss = 7.1335  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 4.1335  Validation loss = 7.1331  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 4.1331  Validation loss = 7.1324  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 4.1327  Validation loss = 7.1318  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 4.1323  Validation loss = 7.1312  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 4.1319  Validation loss = 7.1306  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 4.1315  Validation loss = 7.1299  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 4.1312  Validation loss = 7.1294  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 4.1308  Validation loss = 7.1288  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 4.1305  Validation loss = 7.1283  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 4.1302  Validation loss = 7.1278  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 4.1298  Validation loss = 7.1273  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 4.1294  Validation loss = 7.1267  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 4.1289  Validation loss = 7.1260  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 4.1286  Validation loss = 7.1253  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 4.1281  Validation loss = 7.1247  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 4.1277  Validation loss = 7.1240  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 4.1273  Validation loss = 7.1234  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 4.1269  Validation loss = 7.1227  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 4.1265  Validation loss = 7.1221  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 4.1262  Validation loss = 7.1216  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 4.1258  Validation loss = 7.1211  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 4.1255  Validation loss = 7.1206  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 4.1252  Validation loss = 7.1201  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 4.1248  Validation loss = 7.1195  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 4.1244  Validation loss = 7.1188  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 4.1241  Validation loss = 7.1183  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 4.1236  Validation loss = 7.1176  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 4.1233  Validation loss = 7.1170  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 4.1229  Validation loss = 7.1165  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 4.1225  Validation loss = 7.1158  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 4.1221  Validation loss = 7.1152  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 4.1217  Validation loss = 7.1146  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 4.1214  Validation loss = 7.1140  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 4.1211  Validation loss = 7.1135  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 4.1207  Validation loss = 7.1130  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 4.1203  Validation loss = 7.1124  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 4.1200  Validation loss = 7.1118  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 4.1196  Validation loss = 7.1112  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 4.1192  Validation loss = 7.1107  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 4.1188  Validation loss = 7.1101  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 4.1185  Validation loss = 7.1096  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 4.1182  Validation loss = 7.1091  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 4.1179  Validation loss = 7.1086  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 4.1174  Validation loss = 7.1079  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 4.1171  Validation loss = 7.1074  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 4.1168  Validation loss = 7.1069  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 4.1164  Validation loss = 7.1063  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 4.1159  Validation loss = 7.1055  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 4.1155  Validation loss = 7.1049  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 4.1151  Validation loss = 7.1042  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 4.1147  Validation loss = 7.1036  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 4.1143  Validation loss = 7.1030  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 4.1139  Validation loss = 7.1024  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 4.1135  Validation loss = 7.1017  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 4.1131  Validation loss = 7.1012  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 4.1127  Validation loss = 7.1005  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 4.1122  Validation loss = 7.0998  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 4.1119  Validation loss = 7.0992  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 4.1116  Validation loss = 7.0987  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 4.1111  Validation loss = 7.0980  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 4.1107  Validation loss = 7.0974  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 4.1103  Validation loss = 7.0968  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 4.1100  Validation loss = 7.0963  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 4.1096  Validation loss = 7.0956  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 4.1092  Validation loss = 7.0951  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 4.1089  Validation loss = 7.0946  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 4.1085  Validation loss = 7.0940  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 4.1082  Validation loss = 7.0934  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 4.1078  Validation loss = 7.0928  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 4.1074  Validation loss = 7.0922  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 4.1070  Validation loss = 7.0916  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 4.1067  Validation loss = 7.0911  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 4.1063  Validation loss = 7.0905  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 4.1059  Validation loss = 7.0899  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 4.1056  Validation loss = 7.0894  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 4.1052  Validation loss = 7.0888  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 4.1048  Validation loss = 7.0882  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 4.1045  Validation loss = 7.0877  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 4.1040  Validation loss = 7.0870  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 4.1037  Validation loss = 7.0864  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 4.1033  Validation loss = 7.0858  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 4.1030  Validation loss = 7.0853  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 4.1026  Validation loss = 7.0847  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 4.1022  Validation loss = 7.0841  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 4.1018  Validation loss = 7.0835  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 4.1015  Validation loss = 7.0830  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 4.1010  Validation loss = 7.0823  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 4.1006  Validation loss = 7.0817  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 4.1003  Validation loss = 7.0812  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 4.0999  Validation loss = 7.0805  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 4.0995  Validation loss = 7.0800  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 4.0991  Validation loss = 7.0793  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 4.0988  Validation loss = 7.0788  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 4.0984  Validation loss = 7.0782  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 4.0981  Validation loss = 7.0777  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 4.0977  Validation loss = 7.0771  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 4.0973  Validation loss = 7.0765  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 4.0970  Validation loss = 7.0760  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 4.0967  Validation loss = 7.0755  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 4.0963  Validation loss = 7.0748  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 4.0959  Validation loss = 7.0743  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 4.0955  Validation loss = 7.0736  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 4.0952  Validation loss = 7.0731  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 4.0948  Validation loss = 7.0725  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 4.0944  Validation loss = 7.0719  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 4.0941  Validation loss = 7.0714  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 4.0938  Validation loss = 7.0709  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 4.0934  Validation loss = 7.0704  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 4.0930  Validation loss = 7.0697  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 4.0926  Validation loss = 7.0691  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 4.0923  Validation loss = 7.0686  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 4.0919  Validation loss = 7.0680  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 4.0915  Validation loss = 7.0674  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 4.0912  Validation loss = 7.0668  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 4.0908  Validation loss = 7.0662  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 4.0904  Validation loss = 7.0655  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 4.0900  Validation loss = 7.0650  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 4.0897  Validation loss = 7.0645  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 4.0894  Validation loss = 7.0640  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 4.0889  Validation loss = 7.0633  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 4.0885  Validation loss = 7.0627  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 4.0882  Validation loss = 7.0621  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 4.0878  Validation loss = 7.0615  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 4.0874  Validation loss = 7.0609  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 4.0870  Validation loss = 7.0603  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 4.0867  Validation loss = 7.0598  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 4.0864  Validation loss = 7.0593  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 4.0860  Validation loss = 7.0587  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 4.0856  Validation loss = 7.0581  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 4.0853  Validation loss = 7.0576  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 4.0849  Validation loss = 7.0570  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 4.0845  Validation loss = 7.0564  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 4.0843  Validation loss = 7.0560  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 4.0839  Validation loss = 7.0554  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 4.0835  Validation loss = 7.0548  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 4.0832  Validation loss = 7.0544  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 4.0828  Validation loss = 7.0537  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 4.0824  Validation loss = 7.0531  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 4.0820  Validation loss = 7.0524  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 4.0815  Validation loss = 7.0517  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 4.0811  Validation loss = 7.0511  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 4.0808  Validation loss = 7.0505  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 4.0804  Validation loss = 7.0499  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 4.0799  Validation loss = 7.0492  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 4.0796  Validation loss = 7.0487  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 4.0792  Validation loss = 7.0480  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 4.0788  Validation loss = 7.0475  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 4.0784  Validation loss = 7.0468  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 4.0781  Validation loss = 7.0463  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 4.0777  Validation loss = 7.0457  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 4.0773  Validation loss = 7.0451  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 4.0769  Validation loss = 7.0445  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 4.0766  Validation loss = 7.0440  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 4.0763  Validation loss = 7.0434  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 4.0759  Validation loss = 7.0428  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 4.0755  Validation loss = 7.0423  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 4.0752  Validation loss = 7.0417  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 4.0748  Validation loss = 7.0411  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 4.0744  Validation loss = 7.0406  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 4.0740  Validation loss = 7.0399  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 4.0736  Validation loss = 7.0392  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 4.0732  Validation loss = 7.0386  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 4.0728  Validation loss = 7.0380  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 4.0725  Validation loss = 7.0375  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 4.0721  Validation loss = 7.0368  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 4.0717  Validation loss = 7.0362  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 4.0714  Validation loss = 7.0358  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 4.0710  Validation loss = 7.0352  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 4.0707  Validation loss = 7.0347  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 4.0703  Validation loss = 7.0342  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 4.0700  Validation loss = 7.0336  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 4.0696  Validation loss = 7.0330  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 4.0692  Validation loss = 7.0325  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 4.0689  Validation loss = 7.0320  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 4.0686  Validation loss = 7.0314  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 4.0683  Validation loss = 7.0310  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 4.0679  Validation loss = 7.0304  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 4.0676  Validation loss = 7.0298  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 4.0672  Validation loss = 7.0292  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 4.0667  Validation loss = 7.0285  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 4.0664  Validation loss = 7.0280  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 4.0661  Validation loss = 7.0275  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 4.0658  Validation loss = 7.0270  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 4.0654  Validation loss = 7.0264  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 4.0651  Validation loss = 7.0259  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 4.0647  Validation loss = 7.0252  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 4.0643  Validation loss = 7.0246  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 4.0639  Validation loss = 7.0240  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 4.0636  Validation loss = 7.0235  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 4.0633  Validation loss = 7.0230  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 4.0629  Validation loss = 7.0224  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 4.0626  Validation loss = 7.0219  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 4.0623  Validation loss = 7.0215  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 4.0619  Validation loss = 7.0210  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 4.0615  Validation loss = 7.0204  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 4.0612  Validation loss = 7.0198  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 4.0608  Validation loss = 7.0192  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 4.0604  Validation loss = 7.0186  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 4.0601  Validation loss = 7.0180  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 4.0597  Validation loss = 7.0175  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 4.0594  Validation loss = 7.0170  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 4.0590  Validation loss = 7.0164  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 4.0586  Validation loss = 7.0157  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 4.0583  Validation loss = 7.0152  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 4.0579  Validation loss = 7.0146  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 4.0575  Validation loss = 7.0140  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 4.0572  Validation loss = 7.0136  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 4.0569  Validation loss = 7.0131  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 4.0565  Validation loss = 7.0125  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 4.0561  Validation loss = 7.0119  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 4.0557  Validation loss = 7.0113  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 4.0554  Validation loss = 7.0107  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 4.0550  Validation loss = 7.0102  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 4.0546  Validation loss = 7.0096  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 4.0543  Validation loss = 7.0090  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 4.0538  Validation loss = 7.0082  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 4.0535  Validation loss = 7.0077  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 4.0531  Validation loss = 7.0071  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 4.0527  Validation loss = 7.0066  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 4.0524  Validation loss = 7.0060  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 4.0519  Validation loss = 7.0053  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 4.0515  Validation loss = 7.0046  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 4.0512  Validation loss = 7.0041  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 4.0508  Validation loss = 7.0036  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 4.0505  Validation loss = 7.0031  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 4.0502  Validation loss = 7.0026  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 4.0499  Validation loss = 7.0021  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 4.0495  Validation loss = 7.0015  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 4.0492  Validation loss = 7.0010  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 4.0488  Validation loss = 7.0004  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 4.0484  Validation loss = 6.9997  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 4.0480  Validation loss = 6.9991  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 4.0476  Validation loss = 6.9985  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 4.0472  Validation loss = 6.9979  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 4.0469  Validation loss = 6.9973  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 4.0465  Validation loss = 6.9968  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 4.0462  Validation loss = 6.9962  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 4.0458  Validation loss = 6.9956  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 4.0453  Validation loss = 6.9949  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 4.0450  Validation loss = 6.9943  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 4.0447  Validation loss = 6.9939  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 4.0444  Validation loss = 6.9934  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 4.0440  Validation loss = 6.9928  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 4.0437  Validation loss = 6.9923  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 4.0433  Validation loss = 6.9916  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 4.0429  Validation loss = 6.9910  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 4.0425  Validation loss = 6.9904  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 4.0421  Validation loss = 6.9899  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 4.0418  Validation loss = 6.9893  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 4.0414  Validation loss = 6.9887  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 4.0410  Validation loss = 6.9881  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 4.0406  Validation loss = 6.9875  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 4.0403  Validation loss = 6.9870  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 4.0400  Validation loss = 6.9865  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 4.0396  Validation loss = 6.9858  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 4.0392  Validation loss = 6.9853  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 4.0388  Validation loss = 6.9846  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 4.0384  Validation loss = 6.9840  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 4.0381  Validation loss = 6.9835  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 4.0378  Validation loss = 6.9829  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 4.0373  Validation loss = 6.9823  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 4.0369  Validation loss = 6.9817  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 4.0366  Validation loss = 6.9811  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 4.0362  Validation loss = 6.9805  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 4.0358  Validation loss = 6.9799  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 4.0355  Validation loss = 6.9794  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 4.0351  Validation loss = 6.9788  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 4.0347  Validation loss = 6.9781  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 4.0344  Validation loss = 6.9777  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 4.0341  Validation loss = 6.9772  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 4.0337  Validation loss = 6.9765  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 4.0334  Validation loss = 6.9760  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 4.0330  Validation loss = 6.9754  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 4.0326  Validation loss = 6.9748  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 4.0323  Validation loss = 6.9743  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 4.0320  Validation loss = 6.9739  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 4.0317  Validation loss = 6.9733  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 4.0312  Validation loss = 6.9727  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 4.0308  Validation loss = 6.9720  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 4.0305  Validation loss = 6.9714  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 4.0300  Validation loss = 6.9708  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 4.0296  Validation loss = 6.9701  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 4.0292  Validation loss = 6.9695  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 4.0289  Validation loss = 6.9689  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 4.0285  Validation loss = 6.9684  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 4.0281  Validation loss = 6.9678  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 4.0278  Validation loss = 6.9672  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 4.0275  Validation loss = 6.9667  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 4.0271  Validation loss = 6.9661  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 4.0267  Validation loss = 6.9654  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 4.0263  Validation loss = 6.9649  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 4.0259  Validation loss = 6.9643  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 4.0255  Validation loss = 6.9636  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 4.0251  Validation loss = 6.9630  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 4.0247  Validation loss = 6.9624  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 4.0244  Validation loss = 6.9618  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 4.0240  Validation loss = 6.9613  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 4.0236  Validation loss = 6.9607  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 4.0233  Validation loss = 6.9601  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 4.0230  Validation loss = 6.9597  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 4.0226  Validation loss = 6.9591  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 4.0223  Validation loss = 6.9585  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 4.0219  Validation loss = 6.9580  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 4.0214  Validation loss = 6.9572  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 4.0211  Validation loss = 6.9566  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 4.0207  Validation loss = 6.9560  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 4.0203  Validation loss = 6.9555  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 4.0200  Validation loss = 6.9549  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 4.0196  Validation loss = 6.9543  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 4.0192  Validation loss = 6.9536  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 4.0189  Validation loss = 6.9532  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 4.0185  Validation loss = 6.9526  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 4.0181  Validation loss = 6.9520  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 4.0177  Validation loss = 6.9514  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 4.0175  Validation loss = 6.9509  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 4.0171  Validation loss = 6.9503  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 4.0168  Validation loss = 6.9498  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 4.0165  Validation loss = 6.9494  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 4.0162  Validation loss = 6.9489  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 4.0159  Validation loss = 6.9485  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 4.0155  Validation loss = 6.9479  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 4.0151  Validation loss = 6.9472  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 4.0148  Validation loss = 6.9466  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 4.0145  Validation loss = 6.9462  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 4.0141  Validation loss = 6.9456  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 4.0138  Validation loss = 6.9451  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 4.0134  Validation loss = 6.9445  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 4.0130  Validation loss = 6.9438  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 4.0125  Validation loss = 6.9431  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 4.0121  Validation loss = 6.9425  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 4.0118  Validation loss = 6.9420  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 4.0114  Validation loss = 6.9413  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 4.0111  Validation loss = 6.9408  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 4.0108  Validation loss = 6.9404  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 4.0103  Validation loss = 6.9396  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 4.0098  Validation loss = 6.9389  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 4.0095  Validation loss = 6.9384  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 4.0092  Validation loss = 6.9379  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 4.0089  Validation loss = 6.9374  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 4.0086  Validation loss = 6.9369  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 4.0082  Validation loss = 6.9362  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 4.0079  Validation loss = 6.9357  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 4.0075  Validation loss = 6.9352  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 4.0072  Validation loss = 6.9347  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 4.0068  Validation loss = 6.9341  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 4.0064  Validation loss = 6.9334  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 4.0059  Validation loss = 6.9327  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 500  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 4.3559  Validation loss = 10.5455  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 4.3555  Validation loss = 10.5449  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 4.3551  Validation loss = 10.5443  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 4.3546  Validation loss = 10.5436  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 4.3542  Validation loss = 10.5430  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 4.3537  Validation loss = 10.5423  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 4.3533  Validation loss = 10.5417  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 4.3528  Validation loss = 10.5411  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 4.3524  Validation loss = 10.5404  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 4.3520  Validation loss = 10.5398  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 4.3515  Validation loss = 10.5392  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 4.3510  Validation loss = 10.5384  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 4.3506  Validation loss = 10.5378  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 4.3500  Validation loss = 10.5371  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 4.3495  Validation loss = 10.5364  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 4.3490  Validation loss = 10.5356  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 4.3486  Validation loss = 10.5350  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 4.3480  Validation loss = 10.5342  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 4.3476  Validation loss = 10.5335  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 4.3471  Validation loss = 10.5328  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 4.3466  Validation loss = 10.5322  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 4.3461  Validation loss = 10.5314  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 4.3456  Validation loss = 10.5307  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 4.3451  Validation loss = 10.5300  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 4.3447  Validation loss = 10.5294  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 4.3442  Validation loss = 10.5287  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 4.3437  Validation loss = 10.5279  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 4.3433  Validation loss = 10.5273  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 4.3426  Validation loss = 10.5264  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 4.3421  Validation loss = 10.5257  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 4.3417  Validation loss = 10.5251  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 4.3413  Validation loss = 10.5245  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 4.3408  Validation loss = 10.5238  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 4.3403  Validation loss = 10.5231  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 4.3399  Validation loss = 10.5224  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 4.3394  Validation loss = 10.5217  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 4.3389  Validation loss = 10.5210  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 4.3385  Validation loss = 10.5204  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 4.3379  Validation loss = 10.5196  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 4.3374  Validation loss = 10.5189  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 4.3369  Validation loss = 10.5182  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 4.3366  Validation loss = 10.5177  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 4.3362  Validation loss = 10.5170  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 4.3358  Validation loss = 10.5165  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 4.3352  Validation loss = 10.5156  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 4.3347  Validation loss = 10.5149  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 4.3343  Validation loss = 10.5143  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 4.3340  Validation loss = 10.5139  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 4.3335  Validation loss = 10.5132  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 4.3330  Validation loss = 10.5125  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 4.3326  Validation loss = 10.5118  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 4.3321  Validation loss = 10.5112  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 4.3317  Validation loss = 10.5106  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 4.3313  Validation loss = 10.5099  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 4.3308  Validation loss = 10.5093  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 4.3304  Validation loss = 10.5087  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 4.3300  Validation loss = 10.5082  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 4.3295  Validation loss = 10.5074  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 4.3292  Validation loss = 10.5069  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 4.3287  Validation loss = 10.5064  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 4.3283  Validation loss = 10.5057  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 4.3279  Validation loss = 10.5052  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 4.3275  Validation loss = 10.5046  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 4.3271  Validation loss = 10.5040  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 4.3267  Validation loss = 10.5034  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 4.3263  Validation loss = 10.5028  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 4.3259  Validation loss = 10.5022  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 4.3255  Validation loss = 10.5016  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 4.3250  Validation loss = 10.5009  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 4.3246  Validation loss = 10.5003  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 4.3242  Validation loss = 10.4997  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 4.3237  Validation loss = 10.4989  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 4.3232  Validation loss = 10.4982  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 4.3227  Validation loss = 10.4975  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 4.3223  Validation loss = 10.4969  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 4.3218  Validation loss = 10.4962  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 4.3214  Validation loss = 10.4956  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 4.3209  Validation loss = 10.4949  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 4.3205  Validation loss = 10.4943  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 4.3200  Validation loss = 10.4936  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 4.3196  Validation loss = 10.4929  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 4.3192  Validation loss = 10.4923  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 4.3188  Validation loss = 10.4917  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 4.3183  Validation loss = 10.4911  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 4.3179  Validation loss = 10.4905  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 4.3175  Validation loss = 10.4900  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 4.3171  Validation loss = 10.4894  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 4.3167  Validation loss = 10.4887  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 4.3162  Validation loss = 10.4881  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 4.3157  Validation loss = 10.4874  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 4.3152  Validation loss = 10.4867  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 4.3148  Validation loss = 10.4861  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 4.3144  Validation loss = 10.4855  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 4.3139  Validation loss = 10.4848  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 4.3134  Validation loss = 10.4841  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 4.3128  Validation loss = 10.4832  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 4.3123  Validation loss = 10.4825  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 4.3118  Validation loss = 10.4818  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 4.3114  Validation loss = 10.4812  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 4.3110  Validation loss = 10.4805  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 4.3105  Validation loss = 10.4798  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 4.3100  Validation loss = 10.4791  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 4.3096  Validation loss = 10.4784  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 4.3092  Validation loss = 10.4779  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 4.3087  Validation loss = 10.4772  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 4.3083  Validation loss = 10.4766  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 4.3080  Validation loss = 10.4761  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 4.3075  Validation loss = 10.4754  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 4.3071  Validation loss = 10.4748  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 4.3066  Validation loss = 10.4741  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 4.3061  Validation loss = 10.4734  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 4.3056  Validation loss = 10.4727  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 4.3052  Validation loss = 10.4721  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 4.3047  Validation loss = 10.4714  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 4.3042  Validation loss = 10.4707  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 4.3038  Validation loss = 10.4701  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 4.3033  Validation loss = 10.4694  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 4.3029  Validation loss = 10.4688  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 4.3025  Validation loss = 10.4682  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 4.3020  Validation loss = 10.4675  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 4.3016  Validation loss = 10.4669  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 4.3011  Validation loss = 10.4662  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 4.3007  Validation loss = 10.4656  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 4.3003  Validation loss = 10.4649  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 4.2998  Validation loss = 10.4642  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 4.2993  Validation loss = 10.4636  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 4.2989  Validation loss = 10.4630  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 4.2985  Validation loss = 10.4623  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 4.2980  Validation loss = 10.4617  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 4.2975  Validation loss = 10.4610  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 4.2971  Validation loss = 10.4603  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 4.2967  Validation loss = 10.4597  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 4.2962  Validation loss = 10.4590  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 4.2958  Validation loss = 10.4584  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 4.2953  Validation loss = 10.4578  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 4.2949  Validation loss = 10.4571  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 4.2944  Validation loss = 10.4564  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 4.2940  Validation loss = 10.4558  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 4.2936  Validation loss = 10.4552  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 4.2933  Validation loss = 10.4547  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 4.2928  Validation loss = 10.4541  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 4.2924  Validation loss = 10.4534  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 4.2918  Validation loss = 10.4527  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 4.2914  Validation loss = 10.4520  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 4.2910  Validation loss = 10.4514  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 4.2905  Validation loss = 10.4507  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 4.2900  Validation loss = 10.4500  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 4.2896  Validation loss = 10.4494  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 4.2893  Validation loss = 10.4489  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 4.2888  Validation loss = 10.4482  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 4.2883  Validation loss = 10.4475  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 4.2878  Validation loss = 10.4467  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 4.2874  Validation loss = 10.4461  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 4.2869  Validation loss = 10.4453  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 4.2864  Validation loss = 10.4446  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 4.2860  Validation loss = 10.4439  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 4.2855  Validation loss = 10.4433  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 4.2850  Validation loss = 10.4426  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 4.2845  Validation loss = 10.4419  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 4.2840  Validation loss = 10.4412  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 4.2836  Validation loss = 10.4405  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 4.2831  Validation loss = 10.4398  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 4.2827  Validation loss = 10.4392  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 4.2823  Validation loss = 10.4386  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 4.2818  Validation loss = 10.4379  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 4.2814  Validation loss = 10.4373  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 4.2809  Validation loss = 10.4366  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 4.2806  Validation loss = 10.4361  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 4.2801  Validation loss = 10.4354  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 4.2796  Validation loss = 10.4347  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 4.2791  Validation loss = 10.4340  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 4.2788  Validation loss = 10.4335  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 4.2784  Validation loss = 10.4329  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 4.2779  Validation loss = 10.4323  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 4.2774  Validation loss = 10.4315  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 4.2770  Validation loss = 10.4309  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 4.2766  Validation loss = 10.4304  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 4.2761  Validation loss = 10.4296  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 4.2756  Validation loss = 10.4290  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 4.2752  Validation loss = 10.4282  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 4.2747  Validation loss = 10.4276  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 4.2742  Validation loss = 10.4267  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 4.2736  Validation loss = 10.4259  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 4.2732  Validation loss = 10.4252  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 4.2727  Validation loss = 10.4245  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 4.2723  Validation loss = 10.4239  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 4.2718  Validation loss = 10.4233  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 4.2714  Validation loss = 10.4226  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 4.2709  Validation loss = 10.4220  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 4.2704  Validation loss = 10.4214  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 4.2699  Validation loss = 10.4206  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 4.2694  Validation loss = 10.4199  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 4.2691  Validation loss = 10.4194  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 4.2686  Validation loss = 10.4186  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 4.2681  Validation loss = 10.4180  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 4.2677  Validation loss = 10.4173  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 4.2672  Validation loss = 10.4166  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 4.2667  Validation loss = 10.4160  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 4.2663  Validation loss = 10.4154  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 4.2658  Validation loss = 10.4147  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 4.2653  Validation loss = 10.4140  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 4.2649  Validation loss = 10.4134  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 4.2644  Validation loss = 10.4126  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 4.2639  Validation loss = 10.4119  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 4.2635  Validation loss = 10.4113  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 4.2630  Validation loss = 10.4106  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 4.2627  Validation loss = 10.4101  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 4.2622  Validation loss = 10.4094  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 4.2618  Validation loss = 10.4088  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 4.2614  Validation loss = 10.4083  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 4.2609  Validation loss = 10.4076  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 4.2605  Validation loss = 10.4069  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 4.2600  Validation loss = 10.4063  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 4.2595  Validation loss = 10.4055  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 4.2591  Validation loss = 10.4049  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 4.2587  Validation loss = 10.4044  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 4.2583  Validation loss = 10.4037  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 4.2578  Validation loss = 10.4031  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 4.2575  Validation loss = 10.4025  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 4.2569  Validation loss = 10.4017  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 4.2565  Validation loss = 10.4011  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 4.2561  Validation loss = 10.4005  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 4.2556  Validation loss = 10.3999  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 4.2553  Validation loss = 10.3993  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 4.2548  Validation loss = 10.3987  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 4.2544  Validation loss = 10.3981  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 4.2539  Validation loss = 10.3973  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 4.2534  Validation loss = 10.3966  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 4.2529  Validation loss = 10.3960  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 4.2525  Validation loss = 10.3953  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 4.2519  Validation loss = 10.3945  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 4.2514  Validation loss = 10.3937  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 4.2509  Validation loss = 10.3930  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 4.2505  Validation loss = 10.3925  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 4.2500  Validation loss = 10.3918  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 4.2495  Validation loss = 10.3910  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 4.2491  Validation loss = 10.3904  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 4.2487  Validation loss = 10.3897  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 4.2482  Validation loss = 10.3890  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 4.2477  Validation loss = 10.3883  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 4.2473  Validation loss = 10.3877  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 4.2469  Validation loss = 10.3871  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 4.2465  Validation loss = 10.3865  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 4.2462  Validation loss = 10.3860  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 4.2456  Validation loss = 10.3852  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 4.2452  Validation loss = 10.3845  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 4.2447  Validation loss = 10.3840  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 4.2443  Validation loss = 10.3833  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 4.2439  Validation loss = 10.3827  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 4.2434  Validation loss = 10.3821  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 4.2431  Validation loss = 10.3815  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 4.2426  Validation loss = 10.3808  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 4.2422  Validation loss = 10.3803  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 4.2419  Validation loss = 10.3797  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 4.2413  Validation loss = 10.3789  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 4.2408  Validation loss = 10.3782  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 4.2404  Validation loss = 10.3776  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 4.2399  Validation loss = 10.3768  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 4.2394  Validation loss = 10.3761  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 4.2390  Validation loss = 10.3755  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 4.2386  Validation loss = 10.3749  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 4.2381  Validation loss = 10.3742  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 4.2376  Validation loss = 10.3735  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 4.2371  Validation loss = 10.3726  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 4.2366  Validation loss = 10.3719  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 4.2361  Validation loss = 10.3712  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 4.2356  Validation loss = 10.3705  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 4.2351  Validation loss = 10.3698  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 4.2347  Validation loss = 10.3691  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 4.2343  Validation loss = 10.3685  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 4.2339  Validation loss = 10.3678  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 4.2333  Validation loss = 10.3671  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 4.2330  Validation loss = 10.3666  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 4.2325  Validation loss = 10.3659  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 4.2320  Validation loss = 10.3652  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 4.2316  Validation loss = 10.3647  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 4.2311  Validation loss = 10.3639  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 4.2307  Validation loss = 10.3633  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 4.2302  Validation loss = 10.3626  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 4.2297  Validation loss = 10.3619  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 4.2293  Validation loss = 10.3613  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 4.2288  Validation loss = 10.3606  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 4.2284  Validation loss = 10.3600  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 4.2279  Validation loss = 10.3592  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 4.2275  Validation loss = 10.3586  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 4.2270  Validation loss = 10.3579  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 4.2266  Validation loss = 10.3573  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 4.2262  Validation loss = 10.3567  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 4.2258  Validation loss = 10.3561  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 4.2253  Validation loss = 10.3554  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 4.2249  Validation loss = 10.3549  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 4.2245  Validation loss = 10.3543  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 4.2240  Validation loss = 10.3535  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 4.2236  Validation loss = 10.3529  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 4.2230  Validation loss = 10.3521  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 4.2226  Validation loss = 10.3514  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 4.2222  Validation loss = 10.3508  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 4.2217  Validation loss = 10.3501  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 4.2212  Validation loss = 10.3494  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 4.2208  Validation loss = 10.3488  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 4.2204  Validation loss = 10.3481  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 4.2200  Validation loss = 10.3475  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 4.2195  Validation loss = 10.3469  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 4.2190  Validation loss = 10.3462  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 4.2186  Validation loss = 10.3456  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 4.2182  Validation loss = 10.3450  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 4.2179  Validation loss = 10.3444  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 4.2174  Validation loss = 10.3438  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 4.2171  Validation loss = 10.3433  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 4.2167  Validation loss = 10.3427  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 4.2162  Validation loss = 10.3420  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 4.2157  Validation loss = 10.3413  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 4.2153  Validation loss = 10.3408  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 4.2149  Validation loss = 10.3402  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 4.2144  Validation loss = 10.3395  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 4.2139  Validation loss = 10.3388  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 4.2135  Validation loss = 10.3382  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 4.2132  Validation loss = 10.3377  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 4.2127  Validation loss = 10.3369  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 4.2123  Validation loss = 10.3363  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 4.2117  Validation loss = 10.3355  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 4.2112  Validation loss = 10.3348  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 4.2107  Validation loss = 10.3342  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 4.2104  Validation loss = 10.3336  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 4.2099  Validation loss = 10.3329  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 4.2095  Validation loss = 10.3323  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 4.2090  Validation loss = 10.3317  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 4.2085  Validation loss = 10.3310  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 4.2081  Validation loss = 10.3304  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 4.2076  Validation loss = 10.3296  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 4.2072  Validation loss = 10.3290  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 4.2068  Validation loss = 10.3284  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 4.2065  Validation loss = 10.3279  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 4.2060  Validation loss = 10.3273  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 4.2057  Validation loss = 10.3267  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 4.2052  Validation loss = 10.3260  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 4.2048  Validation loss = 10.3254  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 4.2043  Validation loss = 10.3248  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 4.2039  Validation loss = 10.3242  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 4.2034  Validation loss = 10.3235  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 4.2029  Validation loss = 10.3228  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 4.2025  Validation loss = 10.3222  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 4.2020  Validation loss = 10.3215  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 4.2016  Validation loss = 10.3209  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 4.2011  Validation loss = 10.3202  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 4.2006  Validation loss = 10.3195  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 4.2002  Validation loss = 10.3189  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 4.1997  Validation loss = 10.3182  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 4.1992  Validation loss = 10.3175  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 4.1987  Validation loss = 10.3168  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 4.1982  Validation loss = 10.3161  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 4.1978  Validation loss = 10.3156  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 4.1974  Validation loss = 10.3149  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 4.1969  Validation loss = 10.3142  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 4.1964  Validation loss = 10.3136  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 4.1960  Validation loss = 10.3129  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 4.1955  Validation loss = 10.3122  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 4.1950  Validation loss = 10.3115  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 4.1945  Validation loss = 10.3108  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 4.1941  Validation loss = 10.3102  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 4.1936  Validation loss = 10.3095  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 4.1933  Validation loss = 10.3090  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 4.1928  Validation loss = 10.3083  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 4.1924  Validation loss = 10.3077  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 4.1919  Validation loss = 10.3071  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 4.1915  Validation loss = 10.3064  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 4.1911  Validation loss = 10.3059  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 4.1906  Validation loss = 10.3053  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 4.1901  Validation loss = 10.3046  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 4.1896  Validation loss = 10.3038  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 4.1891  Validation loss = 10.3031  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 4.1888  Validation loss = 10.3027  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 4.1884  Validation loss = 10.3021  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 4.1879  Validation loss = 10.3014  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 4.1874  Validation loss = 10.3006  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 4.1869  Validation loss = 10.2998  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 4.1864  Validation loss = 10.2992  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 4.1859  Validation loss = 10.2984  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 4.1856  Validation loss = 10.2979  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 4.1851  Validation loss = 10.2972  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 4.1846  Validation loss = 10.2965  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 4.1842  Validation loss = 10.2959  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 4.1837  Validation loss = 10.2952  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 4.1833  Validation loss = 10.2946  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 4.1828  Validation loss = 10.2939  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 4.1824  Validation loss = 10.2933  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 4.1819  Validation loss = 10.2926  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 4.1814  Validation loss = 10.2919  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 4.1809  Validation loss = 10.2913  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 4.1805  Validation loss = 10.2906  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 4.1800  Validation loss = 10.2899  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 4.1795  Validation loss = 10.2892  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 4.1790  Validation loss = 10.2885  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 4.1786  Validation loss = 10.2880  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 4.1781  Validation loss = 10.2872  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 4.1777  Validation loss = 10.2866  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 4.1773  Validation loss = 10.2861  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 4.1768  Validation loss = 10.2854  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 4.1764  Validation loss = 10.2848  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 4.1760  Validation loss = 10.2842  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 4.1754  Validation loss = 10.2834  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 4.1750  Validation loss = 10.2828  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 4.1745  Validation loss = 10.2821  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 4.1741  Validation loss = 10.2815  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 4.1735  Validation loss = 10.2808  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 4.1731  Validation loss = 10.2800  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 4.1727  Validation loss = 10.2795  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 4.1722  Validation loss = 10.2788  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 4.1718  Validation loss = 10.2783  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 4.1713  Validation loss = 10.2775  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 4.1708  Validation loss = 10.2768  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 4.1703  Validation loss = 10.2761  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 4.1699  Validation loss = 10.2755  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 4.1695  Validation loss = 10.2748  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 4.1690  Validation loss = 10.2742  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 4.1686  Validation loss = 10.2735  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 4.1681  Validation loss = 10.2728  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 4.1677  Validation loss = 10.2723  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 4.1673  Validation loss = 10.2717  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 4.1668  Validation loss = 10.2711  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 4.1664  Validation loss = 10.2705  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 4.1660  Validation loss = 10.2699  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 4.1655  Validation loss = 10.2692  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 4.1651  Validation loss = 10.2686  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 4.1647  Validation loss = 10.2681  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 4.1642  Validation loss = 10.2673  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 4.1638  Validation loss = 10.2668  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 4.1634  Validation loss = 10.2661  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 4.1629  Validation loss = 10.2655  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 4.1626  Validation loss = 10.2650  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 4.1620  Validation loss = 10.2643  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 4.1616  Validation loss = 10.2637  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 4.1611  Validation loss = 10.2630  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 4.1607  Validation loss = 10.2623  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 4.1601  Validation loss = 10.2616  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 4.1596  Validation loss = 10.2609  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 4.1591  Validation loss = 10.2602  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 4.1586  Validation loss = 10.2595  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 4.1581  Validation loss = 10.2589  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 4.1577  Validation loss = 10.2583  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 4.1572  Validation loss = 10.2576  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 4.1567  Validation loss = 10.2568  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 4.1563  Validation loss = 10.2563  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 4.1558  Validation loss = 10.2556  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 4.1553  Validation loss = 10.2550  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 4.1549  Validation loss = 10.2543  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 4.1544  Validation loss = 10.2537  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 4.1541  Validation loss = 10.2532  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 4.1537  Validation loss = 10.2526  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 4.1533  Validation loss = 10.2521  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 4.1529  Validation loss = 10.2515  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 4.1524  Validation loss = 10.2509  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 4.1520  Validation loss = 10.2503  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 4.1516  Validation loss = 10.2497  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 4.1512  Validation loss = 10.2491  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 4.1507  Validation loss = 10.2484  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 4.1502  Validation loss = 10.2477  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 4.1496  Validation loss = 10.2470  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 4.1492  Validation loss = 10.2465  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 4.1488  Validation loss = 10.2459  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 4.1483  Validation loss = 10.2452  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 4.1477  Validation loss = 10.2443  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 4.1473  Validation loss = 10.2438  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 4.1470  Validation loss = 10.2433  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 4.1466  Validation loss = 10.2428  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 4.1461  Validation loss = 10.2422  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 4.1457  Validation loss = 10.2415  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 4.1453  Validation loss = 10.2409  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 4.1449  Validation loss = 10.2403  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 4.1444  Validation loss = 10.2396  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 4.1438  Validation loss = 10.2389  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 4.1433  Validation loss = 10.2381  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 4.1429  Validation loss = 10.2376  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 4.1424  Validation loss = 10.2369  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 4.1420  Validation loss = 10.2363  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 4.1415  Validation loss = 10.2357  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 4.1411  Validation loss = 10.2351  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 4.1407  Validation loss = 10.2344  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 4.1401  Validation loss = 10.2338  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 4.1397  Validation loss = 10.2331  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 4.1393  Validation loss = 10.2325  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 4.1388  Validation loss = 10.2318  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 4.1385  Validation loss = 10.2314  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 4.1380  Validation loss = 10.2307  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 4.1374  Validation loss = 10.2300  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 4.1369  Validation loss = 10.2292  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 4.1364  Validation loss = 10.2286  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 4.1359  Validation loss = 10.2279  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 4.1356  Validation loss = 10.2273  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 4.1351  Validation loss = 10.2267  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 4.1348  Validation loss = 10.2262  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 4.1344  Validation loss = 10.2256  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 4.1338  Validation loss = 10.2248  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 4.1334  Validation loss = 10.2243  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 4.1329  Validation loss = 10.2236  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 4.1324  Validation loss = 10.2228  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 4.1320  Validation loss = 10.2222  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 4.1316  Validation loss = 10.2217  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 4.1312  Validation loss = 10.2211  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 4.1307  Validation loss = 10.2205  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 4.8405  Validation loss = 10.8060  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 4.8399  Validation loss = 10.8053  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 4.8392  Validation loss = 10.8045  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 4.8386  Validation loss = 10.8037  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 4.8380  Validation loss = 10.8029  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 4.8375  Validation loss = 10.8023  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 4.8369  Validation loss = 10.8016  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 4.8363  Validation loss = 10.8010  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 4.8357  Validation loss = 10.8002  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 4.8352  Validation loss = 10.7996  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 4.8345  Validation loss = 10.7988  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 4.8339  Validation loss = 10.7982  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 4.8332  Validation loss = 10.7973  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 4.8326  Validation loss = 10.7966  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 4.8320  Validation loss = 10.7960  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 4.8313  Validation loss = 10.7951  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 4.8308  Validation loss = 10.7945  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 4.8301  Validation loss = 10.7936  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 4.8295  Validation loss = 10.7927  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 4.8290  Validation loss = 10.7921  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 4.8285  Validation loss = 10.7915  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 4.8278  Validation loss = 10.7907  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 4.8272  Validation loss = 10.7899  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 4.8265  Validation loss = 10.7892  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 4.8258  Validation loss = 10.7884  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 4.8253  Validation loss = 10.7877  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 4.8248  Validation loss = 10.7871  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 4.8242  Validation loss = 10.7863  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 4.8235  Validation loss = 10.7855  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 4.8228  Validation loss = 10.7847  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 4.8222  Validation loss = 10.7840  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 4.8217  Validation loss = 10.7832  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 4.8210  Validation loss = 10.7823  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 4.8204  Validation loss = 10.7817  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 4.8197  Validation loss = 10.7809  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 4.8192  Validation loss = 10.7801  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 4.8186  Validation loss = 10.7794  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 4.8179  Validation loss = 10.7786  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 4.8173  Validation loss = 10.7779  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 4.8167  Validation loss = 10.7771  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 4.8159  Validation loss = 10.7762  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 4.8153  Validation loss = 10.7756  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 4.8145  Validation loss = 10.7747  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 4.8139  Validation loss = 10.7740  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 4.8132  Validation loss = 10.7731  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 4.8125  Validation loss = 10.7724  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 4.8119  Validation loss = 10.7716  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 4.8113  Validation loss = 10.7709  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 4.8107  Validation loss = 10.7701  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 4.8102  Validation loss = 10.7695  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 4.8096  Validation loss = 10.7688  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 4.8091  Validation loss = 10.7681  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 4.8085  Validation loss = 10.7673  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 4.8079  Validation loss = 10.7666  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 4.8073  Validation loss = 10.7659  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 4.8067  Validation loss = 10.7652  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 4.8062  Validation loss = 10.7647  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 4.8056  Validation loss = 10.7641  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 4.8051  Validation loss = 10.7634  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 4.8044  Validation loss = 10.7628  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 4.8038  Validation loss = 10.7621  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 4.8031  Validation loss = 10.7613  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 4.8027  Validation loss = 10.7606  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 4.8019  Validation loss = 10.7598  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 4.8013  Validation loss = 10.7590  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 4.8005  Validation loss = 10.7582  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 4.8000  Validation loss = 10.7575  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 4.7993  Validation loss = 10.7568  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 4.7987  Validation loss = 10.7561  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 4.7980  Validation loss = 10.7553  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 4.7975  Validation loss = 10.7545  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 4.7969  Validation loss = 10.7539  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 4.7964  Validation loss = 10.7533  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 4.7957  Validation loss = 10.7524  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 4.7950  Validation loss = 10.7515  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 4.7945  Validation loss = 10.7509  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 4.7939  Validation loss = 10.7501  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 4.7934  Validation loss = 10.7494  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 4.7927  Validation loss = 10.7484  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 4.7919  Validation loss = 10.7476  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 4.7914  Validation loss = 10.7468  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 4.7910  Validation loss = 10.7461  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 4.7904  Validation loss = 10.7454  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 4.7899  Validation loss = 10.7447  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 4.7893  Validation loss = 10.7440  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 4.7887  Validation loss = 10.7433  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 4.7881  Validation loss = 10.7425  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 4.7874  Validation loss = 10.7416  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 4.7869  Validation loss = 10.7411  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 4.7863  Validation loss = 10.7404  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 4.7857  Validation loss = 10.7396  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 4.7852  Validation loss = 10.7390  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 4.7844  Validation loss = 10.7383  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 4.7839  Validation loss = 10.7376  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 4.7833  Validation loss = 10.7369  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 4.7827  Validation loss = 10.7364  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 4.7821  Validation loss = 10.7358  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 4.7815  Validation loss = 10.7350  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 4.7809  Validation loss = 10.7343  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 4.7803  Validation loss = 10.7336  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 4.7797  Validation loss = 10.7329  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 4.7790  Validation loss = 10.7322  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 4.7784  Validation loss = 10.7314  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 4.7778  Validation loss = 10.7308  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 4.7773  Validation loss = 10.7302  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 4.7767  Validation loss = 10.7294  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 4.7761  Validation loss = 10.7287  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 4.7755  Validation loss = 10.7280  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 4.7749  Validation loss = 10.7272  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 4.7743  Validation loss = 10.7264  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 4.7737  Validation loss = 10.7258  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 4.7732  Validation loss = 10.7251  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 4.7727  Validation loss = 10.7244  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 4.7723  Validation loss = 10.7237  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 4.7717  Validation loss = 10.7230  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 4.7711  Validation loss = 10.7223  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 4.7704  Validation loss = 10.7215  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 4.7700  Validation loss = 10.7209  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 4.7694  Validation loss = 10.7202  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 4.7687  Validation loss = 10.7193  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 4.7681  Validation loss = 10.7185  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 4.7675  Validation loss = 10.7178  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 4.7669  Validation loss = 10.7170  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 4.7662  Validation loss = 10.7161  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 4.7656  Validation loss = 10.7155  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 4.7648  Validation loss = 10.7145  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 4.7643  Validation loss = 10.7139  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 4.7637  Validation loss = 10.7132  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 4.7631  Validation loss = 10.7125  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 4.7625  Validation loss = 10.7117  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 4.7618  Validation loss = 10.7108  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 4.7611  Validation loss = 10.7101  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 4.7607  Validation loss = 10.7094  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 4.7600  Validation loss = 10.7086  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 4.7596  Validation loss = 10.7081  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 4.7588  Validation loss = 10.7071  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 4.7582  Validation loss = 10.7064  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 4.7577  Validation loss = 10.7056  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 4.7570  Validation loss = 10.7048  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 4.7564  Validation loss = 10.7041  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 4.7557  Validation loss = 10.7033  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 4.7551  Validation loss = 10.7026  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 4.7545  Validation loss = 10.7018  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 4.7537  Validation loss = 10.7010  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 4.7532  Validation loss = 10.7003  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 4.7525  Validation loss = 10.6995  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 4.7520  Validation loss = 10.6987  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 4.7514  Validation loss = 10.6978  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 4.7507  Validation loss = 10.6970  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 4.7501  Validation loss = 10.6962  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 4.7496  Validation loss = 10.6957  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 4.7489  Validation loss = 10.6948  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 4.7483  Validation loss = 10.6940  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 4.7478  Validation loss = 10.6934  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 4.7471  Validation loss = 10.6926  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 4.7465  Validation loss = 10.6920  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 4.7460  Validation loss = 10.6913  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 4.7453  Validation loss = 10.6906  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 4.7446  Validation loss = 10.6897  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 4.7439  Validation loss = 10.6888  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 4.7433  Validation loss = 10.6881  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 4.7428  Validation loss = 10.6876  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 4.7422  Validation loss = 10.6870  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 4.7416  Validation loss = 10.6862  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 4.7410  Validation loss = 10.6855  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 4.7405  Validation loss = 10.6849  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 4.7400  Validation loss = 10.6843  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 4.7394  Validation loss = 10.6835  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 4.7387  Validation loss = 10.6827  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 4.7382  Validation loss = 10.6820  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 4.7376  Validation loss = 10.6813  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 4.7370  Validation loss = 10.6804  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 4.7365  Validation loss = 10.6799  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 4.7359  Validation loss = 10.6792  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 4.7354  Validation loss = 10.6784  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 4.7348  Validation loss = 10.6777  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 4.7342  Validation loss = 10.6770  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 4.7336  Validation loss = 10.6763  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 4.7330  Validation loss = 10.6754  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 4.7324  Validation loss = 10.6747  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 4.7318  Validation loss = 10.6740  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 4.7311  Validation loss = 10.6731  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 4.7306  Validation loss = 10.6725  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 4.7299  Validation loss = 10.6716  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 4.7293  Validation loss = 10.6708  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 4.7287  Validation loss = 10.6700  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 4.7281  Validation loss = 10.6694  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 4.7275  Validation loss = 10.6686  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 4.7269  Validation loss = 10.6678  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 4.7262  Validation loss = 10.6670  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 4.7256  Validation loss = 10.6662  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 4.7252  Validation loss = 10.6655  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 4.7248  Validation loss = 10.6651  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 4.7243  Validation loss = 10.6646  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 4.7237  Validation loss = 10.6637  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 4.7229  Validation loss = 10.6629  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 4.7223  Validation loss = 10.6622  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 4.7218  Validation loss = 10.6617  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 4.7213  Validation loss = 10.6611  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 4.7208  Validation loss = 10.6603  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 4.7202  Validation loss = 10.6596  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 4.7197  Validation loss = 10.6590  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 4.7190  Validation loss = 10.6581  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 4.7185  Validation loss = 10.6574  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 4.7180  Validation loss = 10.6568  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 4.7175  Validation loss = 10.6563  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 4.7169  Validation loss = 10.6555  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 4.7164  Validation loss = 10.6549  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 4.7158  Validation loss = 10.6541  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 4.7153  Validation loss = 10.6533  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 4.7147  Validation loss = 10.6525  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 4.7142  Validation loss = 10.6518  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 4.7136  Validation loss = 10.6512  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 4.7130  Validation loss = 10.6506  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 4.7126  Validation loss = 10.6500  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 4.7120  Validation loss = 10.6493  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 4.7113  Validation loss = 10.6485  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 4.7108  Validation loss = 10.6478  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 4.7101  Validation loss = 10.6470  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 4.7096  Validation loss = 10.6462  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 4.7091  Validation loss = 10.6457  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 4.7086  Validation loss = 10.6451  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 4.7081  Validation loss = 10.6443  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 4.7076  Validation loss = 10.6437  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 4.7070  Validation loss = 10.6430  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 4.7066  Validation loss = 10.6425  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 4.7060  Validation loss = 10.6418  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 4.7055  Validation loss = 10.6412  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 4.7049  Validation loss = 10.6404  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 4.7044  Validation loss = 10.6397  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 4.7038  Validation loss = 10.6389  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 4.7032  Validation loss = 10.6380  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 4.7027  Validation loss = 10.6373  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 4.7020  Validation loss = 10.6366  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 4.7017  Validation loss = 10.6362  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 4.7011  Validation loss = 10.6356  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 4.7007  Validation loss = 10.6351  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 4.7002  Validation loss = 10.6344  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 4.6997  Validation loss = 10.6338  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 4.6992  Validation loss = 10.6332  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 4.6986  Validation loss = 10.6325  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 4.6981  Validation loss = 10.6319  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 4.6976  Validation loss = 10.6312  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 4.6969  Validation loss = 10.6304  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 4.6964  Validation loss = 10.6297  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 4.6959  Validation loss = 10.6291  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 4.6953  Validation loss = 10.6283  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 4.6947  Validation loss = 10.6275  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 4.6942  Validation loss = 10.6270  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 4.6937  Validation loss = 10.6264  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 4.6931  Validation loss = 10.6256  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 4.6926  Validation loss = 10.6248  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 4.6921  Validation loss = 10.6242  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 4.6916  Validation loss = 10.6235  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 4.6910  Validation loss = 10.6227  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 4.6906  Validation loss = 10.6221  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 4.6901  Validation loss = 10.6216  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 4.6895  Validation loss = 10.6208  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 4.6889  Validation loss = 10.6200  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 4.6883  Validation loss = 10.6193  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 4.6876  Validation loss = 10.6184  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 4.6870  Validation loss = 10.6176  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 4.6864  Validation loss = 10.6168  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 4.6859  Validation loss = 10.6162  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 4.6852  Validation loss = 10.6155  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 4.6846  Validation loss = 10.6148  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 4.6842  Validation loss = 10.6142  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 4.6836  Validation loss = 10.6137  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 4.6831  Validation loss = 10.6130  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 4.6825  Validation loss = 10.6123  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 4.6819  Validation loss = 10.6116  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 4.6813  Validation loss = 10.6109  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 4.6807  Validation loss = 10.6102  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 4.6801  Validation loss = 10.6094  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 4.6796  Validation loss = 10.6088  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 4.6791  Validation loss = 10.6081  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 4.6784  Validation loss = 10.6071  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 4.6779  Validation loss = 10.6064  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 4.6773  Validation loss = 10.6055  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 4.6768  Validation loss = 10.6048  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 4.6762  Validation loss = 10.6039  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 4.6757  Validation loss = 10.6031  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 4.6750  Validation loss = 10.6024  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 4.6745  Validation loss = 10.6017  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 4.6740  Validation loss = 10.6010  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 4.6734  Validation loss = 10.6002  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 4.6728  Validation loss = 10.5994  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 4.6723  Validation loss = 10.5988  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 4.6716  Validation loss = 10.5980  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 4.6711  Validation loss = 10.5972  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 4.6706  Validation loss = 10.5966  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 4.6701  Validation loss = 10.5959  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 4.6694  Validation loss = 10.5950  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 4.6688  Validation loss = 10.5942  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 4.6682  Validation loss = 10.5934  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 4.6675  Validation loss = 10.5925  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 4.6669  Validation loss = 10.5917  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 4.6663  Validation loss = 10.5909  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 4.6657  Validation loss = 10.5902  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 4.6652  Validation loss = 10.5894  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 4.6645  Validation loss = 10.5887  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 4.6640  Validation loss = 10.5881  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 4.6636  Validation loss = 10.5875  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 4.6632  Validation loss = 10.5871  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 4.6628  Validation loss = 10.5865  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 4.6623  Validation loss = 10.5858  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 4.6616  Validation loss = 10.5849  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 4.6611  Validation loss = 10.5841  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 4.6605  Validation loss = 10.5835  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 4.6599  Validation loss = 10.5828  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 4.6594  Validation loss = 10.5821  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 4.6588  Validation loss = 10.5814  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 4.6582  Validation loss = 10.5805  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 4.6576  Validation loss = 10.5798  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 4.6571  Validation loss = 10.5789  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 4.6565  Validation loss = 10.5781  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 4.6559  Validation loss = 10.5774  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 4.6556  Validation loss = 10.5769  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 4.6550  Validation loss = 10.5761  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 4.6545  Validation loss = 10.5755  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 4.6540  Validation loss = 10.5748  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 4.6533  Validation loss = 10.5741  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 4.6528  Validation loss = 10.5735  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 4.6521  Validation loss = 10.5728  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 4.6516  Validation loss = 10.5722  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 4.6510  Validation loss = 10.5713  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 4.6503  Validation loss = 10.5704  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 4.6498  Validation loss = 10.5697  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 4.6493  Validation loss = 10.5689  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 4.6486  Validation loss = 10.5680  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 4.6481  Validation loss = 10.5674  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 4.6475  Validation loss = 10.5668  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 4.6469  Validation loss = 10.5660  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 4.6464  Validation loss = 10.5654  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 4.6457  Validation loss = 10.5645  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 4.6452  Validation loss = 10.5637  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 4.6448  Validation loss = 10.5633  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 4.6441  Validation loss = 10.5626  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 4.6436  Validation loss = 10.5619  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 4.6431  Validation loss = 10.5614  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 4.6426  Validation loss = 10.5608  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 4.6421  Validation loss = 10.5601  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 4.6416  Validation loss = 10.5594  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 4.6409  Validation loss = 10.5586  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 4.6405  Validation loss = 10.5581  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 4.6399  Validation loss = 10.5574  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 4.6394  Validation loss = 10.5567  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 4.6389  Validation loss = 10.5559  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 4.6385  Validation loss = 10.5555  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 4.6380  Validation loss = 10.5547  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 4.6374  Validation loss = 10.5540  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 4.6367  Validation loss = 10.5531  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 4.6361  Validation loss = 10.5524  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 4.6354  Validation loss = 10.5515  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 4.6348  Validation loss = 10.5505  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 4.6344  Validation loss = 10.5499  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 4.6340  Validation loss = 10.5495  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 4.6334  Validation loss = 10.5487  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 4.6329  Validation loss = 10.5480  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 4.6324  Validation loss = 10.5473  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 4.6318  Validation loss = 10.5465  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 4.6313  Validation loss = 10.5459  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 4.6308  Validation loss = 10.5452  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 4.6302  Validation loss = 10.5446  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 4.6295  Validation loss = 10.5437  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 4.6291  Validation loss = 10.5431  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 4.6286  Validation loss = 10.5426  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 4.6282  Validation loss = 10.5420  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 4.6276  Validation loss = 10.5412  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 4.6270  Validation loss = 10.5404  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 4.6264  Validation loss = 10.5397  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 4.6258  Validation loss = 10.5388  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 4.6254  Validation loss = 10.5382  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 4.6248  Validation loss = 10.5376  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 4.6242  Validation loss = 10.5367  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 4.6236  Validation loss = 10.5359  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 4.6230  Validation loss = 10.5351  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 4.6224  Validation loss = 10.5345  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 4.6220  Validation loss = 10.5338  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 4.6214  Validation loss = 10.5331  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 4.6208  Validation loss = 10.5324  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 4.6203  Validation loss = 10.5319  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 4.6197  Validation loss = 10.5311  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 4.6192  Validation loss = 10.5305  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 4.6187  Validation loss = 10.5299  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 4.6183  Validation loss = 10.5293  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 4.6178  Validation loss = 10.5286  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 4.6173  Validation loss = 10.5279  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 4.6169  Validation loss = 10.5274  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 4.6163  Validation loss = 10.5266  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 4.6158  Validation loss = 10.5259  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 4.6152  Validation loss = 10.5252  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 4.6148  Validation loss = 10.5247  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 4.6142  Validation loss = 10.5240  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 4.6136  Validation loss = 10.5232  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 4.6131  Validation loss = 10.5226  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 4.6125  Validation loss = 10.5217  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 4.6119  Validation loss = 10.5211  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 4.6113  Validation loss = 10.5204  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 4.6108  Validation loss = 10.5197  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 4.6102  Validation loss = 10.5190  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 4.6098  Validation loss = 10.5185  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 4.6092  Validation loss = 10.5177  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 4.6086  Validation loss = 10.5170  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 4.6080  Validation loss = 10.5162  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 4.6074  Validation loss = 10.5153  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 4.6069  Validation loss = 10.5147  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 4.6064  Validation loss = 10.5139  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 4.6058  Validation loss = 10.5131  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 4.6053  Validation loss = 10.5125  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 4.6045  Validation loss = 10.5113  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 4.6040  Validation loss = 10.5106  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 4.6034  Validation loss = 10.5099  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 4.6029  Validation loss = 10.5091  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 4.6023  Validation loss = 10.5083  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 4.6018  Validation loss = 10.5077  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 4.6012  Validation loss = 10.5068  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 4.6007  Validation loss = 10.5061  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 4.6002  Validation loss = 10.5054  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 4.5997  Validation loss = 10.5048  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 4.5991  Validation loss = 10.5040  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 4.5985  Validation loss = 10.5033  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 4.5979  Validation loss = 10.5024  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 4.5974  Validation loss = 10.5018  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 4.5969  Validation loss = 10.5011  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 4.5965  Validation loss = 10.5005  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 4.5958  Validation loss = 10.4996  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 4.5953  Validation loss = 10.4989  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 4.5946  Validation loss = 10.4980  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 4.5940  Validation loss = 10.4971  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 4.5935  Validation loss = 10.4965  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 4.5929  Validation loss = 10.4958  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 4.5923  Validation loss = 10.4951  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 4.5917  Validation loss = 10.4941  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 4.5911  Validation loss = 10.4931  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 4.5905  Validation loss = 10.4920  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 4.5900  Validation loss = 10.4913  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 4.5894  Validation loss = 10.4905  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 4.5888  Validation loss = 10.4898  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 4.5883  Validation loss = 10.4891  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 4.5878  Validation loss = 10.4882  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 4.5872  Validation loss = 10.4874  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 4.5867  Validation loss = 10.4865  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 4.5862  Validation loss = 10.4856  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 4.5856  Validation loss = 10.4848  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 4.5850  Validation loss = 10.4838  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 4.5845  Validation loss = 10.4829  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 4.5840  Validation loss = 10.4820  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 4.5834  Validation loss = 10.4808  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 4.5827  Validation loss = 10.4792  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 4.5818  Validation loss = 10.4775  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 4.5808  Validation loss = 10.4757  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 4.5799  Validation loss = 10.4745  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 4.5772  Validation loss = 10.4713  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 4.5756  Validation loss = 10.4692  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 4.5743  Validation loss = 10.4665  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 4.5736  Validation loss = 10.4653  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 4.5730  Validation loss = 10.4643  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 4.5724  Validation loss = 10.4631  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 4.5717  Validation loss = 10.4621  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 4.5712  Validation loss = 10.4612  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 4.5706  Validation loss = 10.4604  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 4.5701  Validation loss = 10.4596  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 4.5695  Validation loss = 10.4588  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 4.5689  Validation loss = 10.4580  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 4.5683  Validation loss = 10.4571  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 4.5679  Validation loss = 10.4564  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 4.5673  Validation loss = 10.4557  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 4.5667  Validation loss = 10.4549  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 4.5661  Validation loss = 10.4542  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 4.5656  Validation loss = 10.4535  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 4.5649  Validation loss = 10.4526  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 4.5643  Validation loss = 10.4517  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 4.5638  Validation loss = 10.4510  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 4.5632  Validation loss = 10.4503  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 4.5627  Validation loss = 10.4498  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 4.5622  Validation loss = 10.4490  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 4.5616  Validation loss = 10.4483  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 4.5612  Validation loss = 10.4477  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 4.5606  Validation loss = 10.4469  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 4.5600  Validation loss = 10.4461  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 4.5596  Validation loss = 10.4455  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 4.5590  Validation loss = 10.4447  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 4.5585  Validation loss = 10.4441  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 4.5581  Validation loss = 10.4436  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 4.5576  Validation loss = 10.4430  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 4.5570  Validation loss = 10.4422  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 4.5565  Validation loss = 10.4416  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 4.5560  Validation loss = 10.4408  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 4.5556  Validation loss = 10.4403  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 4.5551  Validation loss = 10.4397  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 4.5547  Validation loss = 10.4392  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 4.5541  Validation loss = 10.4385  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 4.5536  Validation loss = 10.4379  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 4.5530  Validation loss = 10.4371  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 4.5525  Validation loss = 10.4365  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 4.5520  Validation loss = 10.4360  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 4.5515  Validation loss = 10.4352  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 4.5509  Validation loss = 10.4345  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 4.5503  Validation loss = 10.4338  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 5.2244  Validation loss = 7.2463  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 5.2238  Validation loss = 7.2456  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 5.2230  Validation loss = 7.2447  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 5.2223  Validation loss = 7.2440  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 5.2216  Validation loss = 7.2431  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 5.2209  Validation loss = 7.2423  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 5.2203  Validation loss = 7.2417  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 5.2197  Validation loss = 7.2409  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 5.2190  Validation loss = 7.2401  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 5.2182  Validation loss = 7.2393  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 5.2175  Validation loss = 7.2385  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 5.2170  Validation loss = 7.2378  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 5.2163  Validation loss = 7.2370  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 5.2157  Validation loss = 7.2363  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 5.2150  Validation loss = 7.2356  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 5.2143  Validation loss = 7.2348  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 5.2136  Validation loss = 7.2339  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 5.2129  Validation loss = 7.2331  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 5.2121  Validation loss = 7.2322  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 5.2115  Validation loss = 7.2315  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 5.2107  Validation loss = 7.2306  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 5.2099  Validation loss = 7.2297  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 5.2093  Validation loss = 7.2290  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 5.2086  Validation loss = 7.2282  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 5.2080  Validation loss = 7.2275  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 5.2072  Validation loss = 7.2266  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 5.2065  Validation loss = 7.2258  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 5.2057  Validation loss = 7.2248  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 5.2050  Validation loss = 7.2240  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 5.2043  Validation loss = 7.2232  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 5.2036  Validation loss = 7.2225  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 5.2029  Validation loss = 7.2216  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 5.2022  Validation loss = 7.2208  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 5.2015  Validation loss = 7.2200  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 5.2009  Validation loss = 7.2193  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 5.2003  Validation loss = 7.2185  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 5.1996  Validation loss = 7.2177  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 5.1989  Validation loss = 7.2169  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 5.1982  Validation loss = 7.2161  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 5.1974  Validation loss = 7.2152  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 5.1966  Validation loss = 7.2144  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 5.1958  Validation loss = 7.2135  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 5.1952  Validation loss = 7.2127  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 5.1945  Validation loss = 7.2119  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 5.1938  Validation loss = 7.2112  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 5.1932  Validation loss = 7.2105  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 5.1926  Validation loss = 7.2098  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 5.1920  Validation loss = 7.2091  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 5.1915  Validation loss = 7.2085  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 5.1909  Validation loss = 7.2078  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 5.1902  Validation loss = 7.2070  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 5.1896  Validation loss = 7.2064  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 5.1890  Validation loss = 7.2056  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 5.1883  Validation loss = 7.2048  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 5.1876  Validation loss = 7.2040  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 5.1868  Validation loss = 7.2032  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 5.1862  Validation loss = 7.2024  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 5.1854  Validation loss = 7.2015  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 5.1847  Validation loss = 7.2008  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 5.1840  Validation loss = 7.1999  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 5.1832  Validation loss = 7.1990  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 5.1826  Validation loss = 7.1983  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 5.1819  Validation loss = 7.1974  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 5.1813  Validation loss = 7.1969  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 5.1806  Validation loss = 7.1961  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 5.1799  Validation loss = 7.1952  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 5.1792  Validation loss = 7.1944  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 5.1785  Validation loss = 7.1936  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 5.1778  Validation loss = 7.1929  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 5.1771  Validation loss = 7.1919  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 5.1764  Validation loss = 7.1912  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 5.1757  Validation loss = 7.1903  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 5.1749  Validation loss = 7.1894  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 5.1743  Validation loss = 7.1887  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 5.1735  Validation loss = 7.1879  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 5.1728  Validation loss = 7.1871  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 5.1721  Validation loss = 7.1863  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 5.1712  Validation loss = 7.1852  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 5.1706  Validation loss = 7.1844  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 5.1699  Validation loss = 7.1837  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 5.1693  Validation loss = 7.1829  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 5.1685  Validation loss = 7.1820  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 5.1677  Validation loss = 7.1812  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 5.1671  Validation loss = 7.1805  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 5.1665  Validation loss = 7.1797  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 5.1657  Validation loss = 7.1789  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 5.1651  Validation loss = 7.1782  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 5.1646  Validation loss = 7.1776  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 5.1638  Validation loss = 7.1767  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 5.1631  Validation loss = 7.1758  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 5.1626  Validation loss = 7.1753  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 5.1619  Validation loss = 7.1745  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 5.1614  Validation loss = 7.1738  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 5.1607  Validation loss = 7.1730  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 5.1599  Validation loss = 7.1721  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 5.1592  Validation loss = 7.1714  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 5.1585  Validation loss = 7.1705  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 5.1580  Validation loss = 7.1700  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 5.1574  Validation loss = 7.1693  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 5.1567  Validation loss = 7.1685  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 5.1560  Validation loss = 7.1677  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 5.1554  Validation loss = 7.1670  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 5.1546  Validation loss = 7.1661  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 5.1540  Validation loss = 7.1653  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 5.1534  Validation loss = 7.1645  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 5.1525  Validation loss = 7.1636  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 5.1517  Validation loss = 7.1626  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 5.1511  Validation loss = 7.1619  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 5.1503  Validation loss = 7.1610  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 5.1496  Validation loss = 7.1602  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 5.1490  Validation loss = 7.1595  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 5.1484  Validation loss = 7.1587  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 5.1477  Validation loss = 7.1580  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 5.1472  Validation loss = 7.1573  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 5.1466  Validation loss = 7.1566  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 5.1459  Validation loss = 7.1559  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 5.1452  Validation loss = 7.1550  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 5.1445  Validation loss = 7.1543  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 5.1438  Validation loss = 7.1534  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 5.1432  Validation loss = 7.1527  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 5.1425  Validation loss = 7.1519  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 5.1418  Validation loss = 7.1511  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 5.1411  Validation loss = 7.1504  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 5.1404  Validation loss = 7.1496  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 5.1398  Validation loss = 7.1488  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 5.1390  Validation loss = 7.1478  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 5.1382  Validation loss = 7.1469  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 5.1376  Validation loss = 7.1462  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 5.1369  Validation loss = 7.1454  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 5.1362  Validation loss = 7.1445  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 5.1356  Validation loss = 7.1438  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 5.1350  Validation loss = 7.1431  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 5.1345  Validation loss = 7.1424  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 5.1338  Validation loss = 7.1417  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 5.1331  Validation loss = 7.1409  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 5.1325  Validation loss = 7.1402  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 5.1318  Validation loss = 7.1394  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 5.1310  Validation loss = 7.1385  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 5.1303  Validation loss = 7.1377  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 5.1297  Validation loss = 7.1368  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 5.1290  Validation loss = 7.1361  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 5.1284  Validation loss = 7.1354  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 5.1279  Validation loss = 7.1347  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 5.1271  Validation loss = 7.1338  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 5.1265  Validation loss = 7.1331  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 5.1259  Validation loss = 7.1324  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 5.1253  Validation loss = 7.1317  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 5.1247  Validation loss = 7.1311  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 5.1242  Validation loss = 7.1304  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 5.1235  Validation loss = 7.1296  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 5.1229  Validation loss = 7.1289  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 5.1222  Validation loss = 7.1281  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 5.1215  Validation loss = 7.1273  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 5.1209  Validation loss = 7.1266  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 5.1202  Validation loss = 7.1256  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 5.1194  Validation loss = 7.1248  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 5.1187  Validation loss = 7.1240  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 5.1181  Validation loss = 7.1232  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 5.1174  Validation loss = 7.1225  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 5.1168  Validation loss = 7.1217  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 5.1162  Validation loss = 7.1211  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 5.1157  Validation loss = 7.1204  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 5.1151  Validation loss = 7.1197  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 5.1143  Validation loss = 7.1188  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 5.1137  Validation loss = 7.1181  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 5.1131  Validation loss = 7.1174  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 5.1124  Validation loss = 7.1165  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 5.1117  Validation loss = 7.1157  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 5.1111  Validation loss = 7.1150  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 5.1105  Validation loss = 7.1144  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 5.1100  Validation loss = 7.1137  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 5.1094  Validation loss = 7.1130  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 5.1089  Validation loss = 7.1124  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 5.1083  Validation loss = 7.1117  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 5.1077  Validation loss = 7.1110  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 5.1071  Validation loss = 7.1103  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 5.1064  Validation loss = 7.1095  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 5.1057  Validation loss = 7.1087  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 5.1051  Validation loss = 7.1079  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 5.1043  Validation loss = 7.1071  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 5.1037  Validation loss = 7.1064  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 5.1031  Validation loss = 7.1056  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 5.1025  Validation loss = 7.1049  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 5.1019  Validation loss = 7.1042  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 5.1014  Validation loss = 7.1035  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 5.1007  Validation loss = 7.1028  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 5.1001  Validation loss = 7.1020  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 5.0995  Validation loss = 7.1014  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 5.0990  Validation loss = 7.1007  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 5.0982  Validation loss = 7.0998  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 5.0975  Validation loss = 7.0990  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 5.0970  Validation loss = 7.0983  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 5.0963  Validation loss = 7.0975  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 5.0956  Validation loss = 7.0967  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 5.0948  Validation loss = 7.0957  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 5.0941  Validation loss = 7.0949  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 5.0935  Validation loss = 7.0943  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 5.0929  Validation loss = 7.0936  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 5.0923  Validation loss = 7.0928  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 5.0917  Validation loss = 7.0922  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 5.0910  Validation loss = 7.0914  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 5.0904  Validation loss = 7.0905  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 5.0897  Validation loss = 7.0898  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 5.0890  Validation loss = 7.0889  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 5.0883  Validation loss = 7.0881  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 5.0877  Validation loss = 7.0874  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 5.0871  Validation loss = 7.0866  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 5.0865  Validation loss = 7.0859  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 5.0858  Validation loss = 7.0852  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 5.0852  Validation loss = 7.0844  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 5.0846  Validation loss = 7.0837  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 5.0839  Validation loss = 7.0829  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 5.0831  Validation loss = 7.0820  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 5.0825  Validation loss = 7.0813  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 5.0819  Validation loss = 7.0805  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 5.0813  Validation loss = 7.0798  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 5.0807  Validation loss = 7.0790  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 5.0800  Validation loss = 7.0782  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 5.0793  Validation loss = 7.0774  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 5.0786  Validation loss = 7.0765  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 5.0780  Validation loss = 7.0758  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 5.0772  Validation loss = 7.0748  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 5.0764  Validation loss = 7.0739  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 5.0758  Validation loss = 7.0732  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 5.0751  Validation loss = 7.0724  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 5.0745  Validation loss = 7.0716  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 5.0739  Validation loss = 7.0709  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 5.0732  Validation loss = 7.0700  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 5.0725  Validation loss = 7.0692  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 5.0719  Validation loss = 7.0685  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 5.0713  Validation loss = 7.0677  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 5.0707  Validation loss = 7.0670  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 5.0701  Validation loss = 7.0664  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 5.0695  Validation loss = 7.0655  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 5.0689  Validation loss = 7.0648  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 5.0682  Validation loss = 7.0641  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 5.0676  Validation loss = 7.0634  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 5.0670  Validation loss = 7.0626  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 5.0665  Validation loss = 7.0620  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 5.0658  Validation loss = 7.0612  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 5.0652  Validation loss = 7.0605  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 5.0646  Validation loss = 7.0597  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 5.0640  Validation loss = 7.0591  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 5.0635  Validation loss = 7.0584  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 5.0628  Validation loss = 7.0576  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 5.0621  Validation loss = 7.0567  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 5.0613  Validation loss = 7.0558  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 5.0608  Validation loss = 7.0551  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 5.0601  Validation loss = 7.0544  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 5.0595  Validation loss = 7.0536  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 5.0589  Validation loss = 7.0528  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 5.0582  Validation loss = 7.0521  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 5.0575  Validation loss = 7.0512  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 5.0566  Validation loss = 7.0502  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 5.0560  Validation loss = 7.0495  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 5.0553  Validation loss = 7.0486  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 5.0546  Validation loss = 7.0478  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 5.0539  Validation loss = 7.0470  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 5.0532  Validation loss = 7.0461  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 5.0525  Validation loss = 7.0453  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 5.0519  Validation loss = 7.0446  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 5.0512  Validation loss = 7.0437  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 5.0506  Validation loss = 7.0430  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 5.0499  Validation loss = 7.0421  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 5.0494  Validation loss = 7.0415  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 5.0487  Validation loss = 7.0407  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 5.0480  Validation loss = 7.0399  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 5.0473  Validation loss = 7.0391  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 5.0469  Validation loss = 7.0386  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 5.0462  Validation loss = 7.0377  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 5.0455  Validation loss = 7.0370  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 5.0449  Validation loss = 7.0362  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 5.0441  Validation loss = 7.0352  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 5.0435  Validation loss = 7.0345  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 5.0427  Validation loss = 7.0336  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 5.0421  Validation loss = 7.0328  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 5.0414  Validation loss = 7.0320  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 5.0407  Validation loss = 7.0311  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 5.0402  Validation loss = 7.0305  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 5.0397  Validation loss = 7.0298  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 5.0390  Validation loss = 7.0290  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 5.0383  Validation loss = 7.0281  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 5.0375  Validation loss = 7.0272  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 5.0369  Validation loss = 7.0265  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 5.0362  Validation loss = 7.0256  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 5.0355  Validation loss = 7.0248  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 5.0347  Validation loss = 7.0239  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 5.0342  Validation loss = 7.0233  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 5.0337  Validation loss = 7.0227  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 5.0332  Validation loss = 7.0220  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 5.0325  Validation loss = 7.0211  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 5.0317  Validation loss = 7.0203  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 5.0311  Validation loss = 7.0194  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 5.0305  Validation loss = 7.0187  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 5.0300  Validation loss = 7.0181  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 5.0292  Validation loss = 7.0172  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 5.0286  Validation loss = 7.0164  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 5.0279  Validation loss = 7.0156  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 5.0274  Validation loss = 7.0149  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 5.0268  Validation loss = 7.0143  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 5.0262  Validation loss = 7.0135  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 5.0256  Validation loss = 7.0127  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 5.0250  Validation loss = 7.0121  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 5.0244  Validation loss = 7.0113  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 5.0237  Validation loss = 7.0104  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 5.0230  Validation loss = 7.0097  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 5.0224  Validation loss = 7.0088  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 5.0217  Validation loss = 7.0081  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 5.0211  Validation loss = 7.0073  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 5.0203  Validation loss = 7.0064  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 5.0197  Validation loss = 7.0056  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 5.0191  Validation loss = 7.0049  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 5.0184  Validation loss = 7.0040  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 5.0177  Validation loss = 7.0032  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 5.0172  Validation loss = 7.0026  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 5.0165  Validation loss = 7.0018  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 5.0160  Validation loss = 7.0012  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 5.0157  Validation loss = 7.0007  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 5.0152  Validation loss = 7.0001  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 5.0145  Validation loss = 6.9994  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 5.0139  Validation loss = 6.9985  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 5.0132  Validation loss = 6.9977  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 5.0124  Validation loss = 6.9967  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 5.0118  Validation loss = 6.9960  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 5.0111  Validation loss = 6.9951  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 5.0104  Validation loss = 6.9943  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 5.0097  Validation loss = 6.9935  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 5.0092  Validation loss = 6.9928  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 5.0085  Validation loss = 6.9921  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 5.0081  Validation loss = 6.9915  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 5.0074  Validation loss = 6.9907  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 5.0067  Validation loss = 6.9898  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 5.0060  Validation loss = 6.9889  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 5.0053  Validation loss = 6.9881  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 5.0047  Validation loss = 6.9873  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 5.0041  Validation loss = 6.9867  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 5.0035  Validation loss = 6.9859  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 5.0028  Validation loss = 6.9850  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 5.0020  Validation loss = 6.9841  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 5.0015  Validation loss = 6.9834  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 5.0007  Validation loss = 6.9825  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 5.0000  Validation loss = 6.9816  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 4.9994  Validation loss = 6.9809  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 4.9988  Validation loss = 6.9802  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 4.9980  Validation loss = 6.9791  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 4.9973  Validation loss = 6.9784  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 4.9967  Validation loss = 6.9775  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 4.9960  Validation loss = 6.9767  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 4.9953  Validation loss = 6.9759  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 4.9947  Validation loss = 6.9751  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 4.9941  Validation loss = 6.9745  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 4.9935  Validation loss = 6.9737  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 4.9928  Validation loss = 6.9728  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 4.9921  Validation loss = 6.9719  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 4.9914  Validation loss = 6.9711  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 4.9908  Validation loss = 6.9704  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 4.9903  Validation loss = 6.9697  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 4.9896  Validation loss = 6.9690  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 4.9890  Validation loss = 6.9681  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 4.9883  Validation loss = 6.9673  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 4.9876  Validation loss = 6.9664  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 4.9871  Validation loss = 6.9657  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 4.9864  Validation loss = 6.9649  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 4.9858  Validation loss = 6.9642  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 4.9852  Validation loss = 6.9634  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 4.9846  Validation loss = 6.9627  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 4.9841  Validation loss = 6.9620  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 4.9834  Validation loss = 6.9612  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 4.9828  Validation loss = 6.9603  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 4.9822  Validation loss = 6.9596  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 4.9813  Validation loss = 6.9585  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 4.9806  Validation loss = 6.9576  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 4.9800  Validation loss = 6.9568  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 4.9793  Validation loss = 6.9560  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 4.9786  Validation loss = 6.9551  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 4.9780  Validation loss = 6.9543  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 4.9772  Validation loss = 6.9533  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 4.9766  Validation loss = 6.9525  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 4.9761  Validation loss = 6.9518  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 4.9754  Validation loss = 6.9511  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 4.9749  Validation loss = 6.9504  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 4.9744  Validation loss = 6.9498  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 4.9738  Validation loss = 6.9490  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 4.9731  Validation loss = 6.9482  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 4.9726  Validation loss = 6.9476  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 4.9721  Validation loss = 6.9469  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 4.9714  Validation loss = 6.9461  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 4.9709  Validation loss = 6.9454  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 4.9702  Validation loss = 6.9445  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 4.9697  Validation loss = 6.9439  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 4.9692  Validation loss = 6.9433  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 4.9684  Validation loss = 6.9423  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 4.9677  Validation loss = 6.9414  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 4.9672  Validation loss = 6.9408  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 4.9666  Validation loss = 6.9400  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 4.9659  Validation loss = 6.9392  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 4.9652  Validation loss = 6.9384  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 4.9646  Validation loss = 6.9376  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 4.9640  Validation loss = 6.9368  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 4.9633  Validation loss = 6.9359  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 4.9626  Validation loss = 6.9350  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 4.9618  Validation loss = 6.9340  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 4.9610  Validation loss = 6.9330  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 4.9602  Validation loss = 6.9321  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 4.9595  Validation loss = 6.9312  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 4.9588  Validation loss = 6.9302  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 4.9580  Validation loss = 6.9293  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 4.9574  Validation loss = 6.9285  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 4.9566  Validation loss = 6.9276  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 4.9560  Validation loss = 6.9268  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 4.9555  Validation loss = 6.9261  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 4.9547  Validation loss = 6.9251  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 4.9542  Validation loss = 6.9245  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 4.9536  Validation loss = 6.9237  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 4.9530  Validation loss = 6.9230  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 4.9523  Validation loss = 6.9221  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 4.9517  Validation loss = 6.9213  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 4.9510  Validation loss = 6.9204  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 4.9504  Validation loss = 6.9197  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 4.9498  Validation loss = 6.9190  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 4.9491  Validation loss = 6.9181  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 4.9484  Validation loss = 6.9172  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 4.9476  Validation loss = 6.9162  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 4.9469  Validation loss = 6.9154  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 4.9463  Validation loss = 6.9146  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 4.9456  Validation loss = 6.9137  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 4.9451  Validation loss = 6.9130  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 4.9443  Validation loss = 6.9121  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 4.9437  Validation loss = 6.9113  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 4.9430  Validation loss = 6.9105  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 4.9422  Validation loss = 6.9097  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 4.9413  Validation loss = 6.9087  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 4.9405  Validation loss = 6.9079  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 4.9398  Validation loss = 6.9070  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 4.9391  Validation loss = 6.9062  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 4.9383  Validation loss = 6.9053  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 4.9378  Validation loss = 6.9045  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 4.9372  Validation loss = 6.9038  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 4.9366  Validation loss = 6.9030  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 4.9359  Validation loss = 6.9022  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 4.9352  Validation loss = 6.9014  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 4.9345  Validation loss = 6.9006  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 4.9339  Validation loss = 6.8998  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 4.9332  Validation loss = 6.8989  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 4.9325  Validation loss = 6.8980  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 4.9319  Validation loss = 6.8972  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 4.9311  Validation loss = 6.8962  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 4.9304  Validation loss = 6.8953  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 4.9298  Validation loss = 6.8945  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 4.9291  Validation loss = 6.8936  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 4.9285  Validation loss = 6.8928  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 4.9280  Validation loss = 6.8922  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 4.9273  Validation loss = 6.8913  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 4.9267  Validation loss = 6.8905  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 4.9260  Validation loss = 6.8896  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 4.9255  Validation loss = 6.8889  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 4.9248  Validation loss = 6.8880  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 4.9243  Validation loss = 6.8874  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 4.9237  Validation loss = 6.8867  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 4.9230  Validation loss = 6.8858  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 4.9223  Validation loss = 6.8849  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 4.9217  Validation loss = 6.8841  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 4.9210  Validation loss = 6.8832  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 4.9204  Validation loss = 6.8825  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 4.9197  Validation loss = 6.8816  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 4.9191  Validation loss = 6.8808  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 4.9185  Validation loss = 6.8800  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 4.9179  Validation loss = 6.8793  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 4.9174  Validation loss = 6.8786  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 4.9167  Validation loss = 6.8776  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 4.9161  Validation loss = 6.8769  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 4.9156  Validation loss = 6.8762  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 4.9150  Validation loss = 6.8754  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 4.9143  Validation loss = 6.8746  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 4.9139  Validation loss = 6.8741  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 4.9133  Validation loss = 6.8733  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 4.9126  Validation loss = 6.8723  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 4.9118  Validation loss = 6.8713  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 4.9113  Validation loss = 6.8706  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 4.9107  Validation loss = 6.8698  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 4.9101  Validation loss = 6.8691  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 4.9094  Validation loss = 6.8681  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 4.9088  Validation loss = 6.8674  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 4.9082  Validation loss = 6.8666  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 4.9076  Validation loss = 6.8659  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 4.9070  Validation loss = 6.8651  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 4.9065  Validation loss = 6.8644  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 4.9059  Validation loss = 6.8637  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 4.9053  Validation loss = 6.8629  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 4.9048  Validation loss = 6.8623  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 4.9042  Validation loss = 6.8615  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 4.9036  Validation loss = 6.8607  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 4.9028  Validation loss = 6.8596  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 4.9022  Validation loss = 6.8589  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 4.9017  Validation loss = 6.8582  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 4.9010  Validation loss = 6.8573  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 4.9003  Validation loss = 6.8563  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 4.8997  Validation loss = 6.8554  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 4.8991  Validation loss = 6.8546  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 4.8983  Validation loss = 6.8537  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 500  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 5.1788  Validation loss = 2.7186  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 5.1780  Validation loss = 2.7181  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 5.1772  Validation loss = 2.7176  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 5.1764  Validation loss = 2.7173  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 5.1757  Validation loss = 2.7168  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 5.1750  Validation loss = 2.7163  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 5.1743  Validation loss = 2.7159  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 5.1735  Validation loss = 2.7155  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 5.1727  Validation loss = 2.7149  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 5.1720  Validation loss = 2.7144  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 5.1713  Validation loss = 2.7140  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 5.1705  Validation loss = 2.7136  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 5.1697  Validation loss = 2.7132  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 5.1690  Validation loss = 2.7126  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 5.1682  Validation loss = 2.7120  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 5.1674  Validation loss = 2.7115  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 5.1665  Validation loss = 2.7110  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 5.1658  Validation loss = 2.7104  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 5.1651  Validation loss = 2.7099  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 5.1642  Validation loss = 2.7092  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 5.1635  Validation loss = 2.7088  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 5.1627  Validation loss = 2.7082  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 5.1618  Validation loss = 2.7077  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 5.1611  Validation loss = 2.7071  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 5.1604  Validation loss = 2.7064  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 5.1595  Validation loss = 2.7058  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 5.1586  Validation loss = 2.7053  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 5.1578  Validation loss = 2.7049  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 5.1569  Validation loss = 2.7044  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 5.1560  Validation loss = 2.7039  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 5.1551  Validation loss = 2.7033  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 5.1543  Validation loss = 2.7026  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 5.1536  Validation loss = 2.7022  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 5.1527  Validation loss = 2.7016  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 5.1519  Validation loss = 2.7012  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 5.1511  Validation loss = 2.7007  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 5.1504  Validation loss = 2.7002  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 5.1496  Validation loss = 2.6997  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 5.1486  Validation loss = 2.6992  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 5.1477  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 5.1467  Validation loss = 2.6981  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 5.1459  Validation loss = 2.6976  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 5.1449  Validation loss = 2.6970  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 5.1441  Validation loss = 2.6966  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 5.1433  Validation loss = 2.6962  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 5.1426  Validation loss = 2.6958  \n",
      "\n",
      "Fold: 17  Epoch: 47  Training loss = 5.1418  Validation loss = 2.6953  \n",
      "\n",
      "Fold: 17  Epoch: 48  Training loss = 5.1412  Validation loss = 2.6949  \n",
      "\n",
      "Fold: 17  Epoch: 49  Training loss = 5.1404  Validation loss = 2.6944  \n",
      "\n",
      "Fold: 17  Epoch: 50  Training loss = 5.1397  Validation loss = 2.6939  \n",
      "\n",
      "Fold: 17  Epoch: 51  Training loss = 5.1388  Validation loss = 2.6934  \n",
      "\n",
      "Fold: 17  Epoch: 52  Training loss = 5.1380  Validation loss = 2.6930  \n",
      "\n",
      "Fold: 17  Epoch: 53  Training loss = 5.1372  Validation loss = 2.6924  \n",
      "\n",
      "Fold: 17  Epoch: 54  Training loss = 5.1365  Validation loss = 2.6919  \n",
      "\n",
      "Fold: 17  Epoch: 55  Training loss = 5.1357  Validation loss = 2.6915  \n",
      "\n",
      "Fold: 17  Epoch: 56  Training loss = 5.1350  Validation loss = 2.6912  \n",
      "\n",
      "Fold: 17  Epoch: 57  Training loss = 5.1343  Validation loss = 2.6907  \n",
      "\n",
      "Fold: 17  Epoch: 58  Training loss = 5.1336  Validation loss = 2.6904  \n",
      "\n",
      "Fold: 17  Epoch: 59  Training loss = 5.1330  Validation loss = 2.6900  \n",
      "\n",
      "Fold: 17  Epoch: 60  Training loss = 5.1321  Validation loss = 2.6894  \n",
      "\n",
      "Fold: 17  Epoch: 61  Training loss = 5.1313  Validation loss = 2.6889  \n",
      "\n",
      "Fold: 17  Epoch: 62  Training loss = 5.1304  Validation loss = 2.6884  \n",
      "\n",
      "Fold: 17  Epoch: 63  Training loss = 5.1297  Validation loss = 2.6880  \n",
      "\n",
      "Fold: 17  Epoch: 64  Training loss = 5.1289  Validation loss = 2.6874  \n",
      "\n",
      "Fold: 17  Epoch: 65  Training loss = 5.1283  Validation loss = 2.6871  \n",
      "\n",
      "Fold: 17  Epoch: 66  Training loss = 5.1274  Validation loss = 2.6868  \n",
      "\n",
      "Fold: 17  Epoch: 67  Training loss = 5.1265  Validation loss = 2.6862  \n",
      "\n",
      "Fold: 17  Epoch: 68  Training loss = 5.1258  Validation loss = 2.6857  \n",
      "\n",
      "Fold: 17  Epoch: 69  Training loss = 5.1250  Validation loss = 2.6850  \n",
      "\n",
      "Fold: 17  Epoch: 70  Training loss = 5.1240  Validation loss = 2.6846  \n",
      "\n",
      "Fold: 17  Epoch: 71  Training loss = 5.1232  Validation loss = 2.6840  \n",
      "\n",
      "Fold: 17  Epoch: 72  Training loss = 5.1224  Validation loss = 2.6833  \n",
      "\n",
      "Fold: 17  Epoch: 73  Training loss = 5.1215  Validation loss = 2.6826  \n",
      "\n",
      "Fold: 17  Epoch: 74  Training loss = 5.1208  Validation loss = 2.6822  \n",
      "\n",
      "Fold: 17  Epoch: 75  Training loss = 5.1201  Validation loss = 2.6818  \n",
      "\n",
      "Fold: 17  Epoch: 76  Training loss = 5.1194  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 17  Epoch: 77  Training loss = 5.1185  Validation loss = 2.6807  \n",
      "\n",
      "Fold: 17  Epoch: 78  Training loss = 5.1177  Validation loss = 2.6803  \n",
      "\n",
      "Fold: 17  Epoch: 79  Training loss = 5.1169  Validation loss = 2.6798  \n",
      "\n",
      "Fold: 17  Epoch: 80  Training loss = 5.1162  Validation loss = 2.6794  \n",
      "\n",
      "Fold: 17  Epoch: 81  Training loss = 5.1154  Validation loss = 2.6790  \n",
      "\n",
      "Fold: 17  Epoch: 82  Training loss = 5.1147  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 17  Epoch: 83  Training loss = 5.1139  Validation loss = 2.6782  \n",
      "\n",
      "Fold: 17  Epoch: 84  Training loss = 5.1132  Validation loss = 2.6777  \n",
      "\n",
      "Fold: 17  Epoch: 85  Training loss = 5.1124  Validation loss = 2.6772  \n",
      "\n",
      "Fold: 17  Epoch: 86  Training loss = 5.1116  Validation loss = 2.6769  \n",
      "\n",
      "Fold: 17  Epoch: 87  Training loss = 5.1107  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 17  Epoch: 88  Training loss = 5.1100  Validation loss = 2.6758  \n",
      "\n",
      "Fold: 17  Epoch: 89  Training loss = 5.1092  Validation loss = 2.6753  \n",
      "\n",
      "Fold: 17  Epoch: 90  Training loss = 5.1084  Validation loss = 2.6749  \n",
      "\n",
      "Fold: 17  Epoch: 91  Training loss = 5.1077  Validation loss = 2.6745  \n",
      "\n",
      "Fold: 17  Epoch: 92  Training loss = 5.1069  Validation loss = 2.6741  \n",
      "\n",
      "Fold: 17  Epoch: 93  Training loss = 5.1060  Validation loss = 2.6736  \n",
      "\n",
      "Fold: 17  Epoch: 94  Training loss = 5.1052  Validation loss = 2.6732  \n",
      "\n",
      "Fold: 17  Epoch: 95  Training loss = 5.1044  Validation loss = 2.6727  \n",
      "\n",
      "Fold: 17  Epoch: 96  Training loss = 5.1036  Validation loss = 2.6723  \n",
      "\n",
      "Fold: 17  Epoch: 97  Training loss = 5.1029  Validation loss = 2.6718  \n",
      "\n",
      "Fold: 17  Epoch: 98  Training loss = 5.1021  Validation loss = 2.6713  \n",
      "\n",
      "Fold: 17  Epoch: 99  Training loss = 5.1012  Validation loss = 2.6709  \n",
      "\n",
      "Fold: 17  Epoch: 100  Training loss = 5.1004  Validation loss = 2.6703  \n",
      "\n",
      "Fold: 17  Epoch: 101  Training loss = 5.0996  Validation loss = 2.6700  \n",
      "\n",
      "Fold: 17  Epoch: 102  Training loss = 5.0989  Validation loss = 2.6694  \n",
      "\n",
      "Fold: 17  Epoch: 103  Training loss = 5.0982  Validation loss = 2.6690  \n",
      "\n",
      "Fold: 17  Epoch: 104  Training loss = 5.0975  Validation loss = 2.6686  \n",
      "\n",
      "Fold: 17  Epoch: 105  Training loss = 5.0966  Validation loss = 2.6680  \n",
      "\n",
      "Fold: 17  Epoch: 106  Training loss = 5.0960  Validation loss = 2.6676  \n",
      "\n",
      "Fold: 17  Epoch: 107  Training loss = 5.0953  Validation loss = 2.6672  \n",
      "\n",
      "Fold: 17  Epoch: 108  Training loss = 5.0946  Validation loss = 2.6669  \n",
      "\n",
      "Fold: 17  Epoch: 109  Training loss = 5.0937  Validation loss = 2.6665  \n",
      "\n",
      "Fold: 17  Epoch: 110  Training loss = 5.0929  Validation loss = 2.6659  \n",
      "\n",
      "Fold: 17  Epoch: 111  Training loss = 5.0919  Validation loss = 2.6653  \n",
      "\n",
      "Fold: 17  Epoch: 112  Training loss = 5.0911  Validation loss = 2.6649  \n",
      "\n",
      "Fold: 17  Epoch: 113  Training loss = 5.0903  Validation loss = 2.6645  \n",
      "\n",
      "Fold: 17  Epoch: 114  Training loss = 5.0893  Validation loss = 2.6640  \n",
      "\n",
      "Fold: 17  Epoch: 115  Training loss = 5.0881  Validation loss = 2.6635  \n",
      "\n",
      "Fold: 17  Epoch: 116  Training loss = 5.0874  Validation loss = 2.6630  \n",
      "\n",
      "Fold: 17  Epoch: 117  Training loss = 5.0865  Validation loss = 2.6627  \n",
      "\n",
      "Fold: 17  Epoch: 118  Training loss = 5.0857  Validation loss = 2.6623  \n",
      "\n",
      "Fold: 17  Epoch: 119  Training loss = 5.0849  Validation loss = 2.6620  \n",
      "\n",
      "Fold: 17  Epoch: 120  Training loss = 5.0839  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 17  Epoch: 121  Training loss = 5.0830  Validation loss = 2.6606  \n",
      "\n",
      "Fold: 17  Epoch: 122  Training loss = 5.0820  Validation loss = 2.6601  \n",
      "\n",
      "Fold: 17  Epoch: 123  Training loss = 5.0812  Validation loss = 2.6595  \n",
      "\n",
      "Fold: 17  Epoch: 124  Training loss = 5.0805  Validation loss = 2.6591  \n",
      "\n",
      "Fold: 17  Epoch: 125  Training loss = 5.0795  Validation loss = 2.6586  \n",
      "\n",
      "Fold: 17  Epoch: 126  Training loss = 5.0785  Validation loss = 2.6581  \n",
      "\n",
      "Fold: 17  Epoch: 127  Training loss = 5.0777  Validation loss = 2.6577  \n",
      "\n",
      "Fold: 17  Epoch: 128  Training loss = 5.0768  Validation loss = 2.6573  \n",
      "\n",
      "Fold: 17  Epoch: 129  Training loss = 5.0760  Validation loss = 2.6569  \n",
      "\n",
      "Fold: 17  Epoch: 130  Training loss = 5.0752  Validation loss = 2.6565  \n",
      "\n",
      "Fold: 17  Epoch: 131  Training loss = 5.0742  Validation loss = 2.6560  \n",
      "\n",
      "Fold: 17  Epoch: 132  Training loss = 5.0732  Validation loss = 2.6554  \n",
      "\n",
      "Fold: 17  Epoch: 133  Training loss = 5.0726  Validation loss = 2.6550  \n",
      "\n",
      "Fold: 17  Epoch: 134  Training loss = 5.0719  Validation loss = 2.6547  \n",
      "\n",
      "Fold: 17  Epoch: 135  Training loss = 5.0711  Validation loss = 2.6543  \n",
      "\n",
      "Fold: 17  Epoch: 136  Training loss = 5.0703  Validation loss = 2.6539  \n",
      "\n",
      "Fold: 17  Epoch: 137  Training loss = 5.0694  Validation loss = 2.6534  \n",
      "\n",
      "Fold: 17  Epoch: 138  Training loss = 5.0686  Validation loss = 2.6529  \n",
      "\n",
      "Fold: 17  Epoch: 139  Training loss = 5.0678  Validation loss = 2.6525  \n",
      "\n",
      "Fold: 17  Epoch: 140  Training loss = 5.0669  Validation loss = 2.6521  \n",
      "\n",
      "Fold: 17  Epoch: 141  Training loss = 5.0661  Validation loss = 2.6516  \n",
      "\n",
      "Fold: 17  Epoch: 142  Training loss = 5.0652  Validation loss = 2.6510  \n",
      "\n",
      "Fold: 17  Epoch: 143  Training loss = 5.0645  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 17  Epoch: 144  Training loss = 5.0636  Validation loss = 2.6500  \n",
      "\n",
      "Fold: 17  Epoch: 145  Training loss = 5.0628  Validation loss = 2.6496  \n",
      "\n",
      "Fold: 17  Epoch: 146  Training loss = 5.0620  Validation loss = 2.6491  \n",
      "\n",
      "Fold: 17  Epoch: 147  Training loss = 5.0614  Validation loss = 2.6486  \n",
      "\n",
      "Fold: 17  Epoch: 148  Training loss = 5.0606  Validation loss = 2.6482  \n",
      "\n",
      "Fold: 17  Epoch: 149  Training loss = 5.0599  Validation loss = 2.6478  \n",
      "\n",
      "Fold: 17  Epoch: 150  Training loss = 5.0591  Validation loss = 2.6474  \n",
      "\n",
      "Fold: 17  Epoch: 151  Training loss = 5.0583  Validation loss = 2.6471  \n",
      "\n",
      "Fold: 17  Epoch: 152  Training loss = 5.0575  Validation loss = 2.6467  \n",
      "\n",
      "Fold: 17  Epoch: 153  Training loss = 5.0566  Validation loss = 2.6461  \n",
      "\n",
      "Fold: 17  Epoch: 154  Training loss = 5.0557  Validation loss = 2.6457  \n",
      "\n",
      "Fold: 17  Epoch: 155  Training loss = 5.0549  Validation loss = 2.6453  \n",
      "\n",
      "Fold: 17  Epoch: 156  Training loss = 5.0540  Validation loss = 2.6449  \n",
      "\n",
      "Fold: 17  Epoch: 157  Training loss = 5.0531  Validation loss = 2.6444  \n",
      "\n",
      "Fold: 17  Epoch: 158  Training loss = 5.0522  Validation loss = 2.6440  \n",
      "\n",
      "Fold: 17  Epoch: 159  Training loss = 5.0514  Validation loss = 2.6436  \n",
      "\n",
      "Fold: 17  Epoch: 160  Training loss = 5.0504  Validation loss = 2.6432  \n",
      "\n",
      "Fold: 17  Epoch: 161  Training loss = 5.0497  Validation loss = 2.6429  \n",
      "\n",
      "Fold: 17  Epoch: 162  Training loss = 5.0489  Validation loss = 2.6424  \n",
      "\n",
      "Fold: 17  Epoch: 163  Training loss = 5.0483  Validation loss = 2.6421  \n",
      "\n",
      "Fold: 17  Epoch: 164  Training loss = 5.0473  Validation loss = 2.6417  \n",
      "\n",
      "Fold: 17  Epoch: 165  Training loss = 5.0464  Validation loss = 2.6413  \n",
      "\n",
      "Fold: 17  Epoch: 166  Training loss = 5.0455  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 17  Epoch: 167  Training loss = 5.0446  Validation loss = 2.6404  \n",
      "\n",
      "Fold: 17  Epoch: 168  Training loss = 5.0439  Validation loss = 2.6400  \n",
      "\n",
      "Fold: 17  Epoch: 169  Training loss = 5.0430  Validation loss = 2.6395  \n",
      "\n",
      "Fold: 17  Epoch: 170  Training loss = 5.0422  Validation loss = 2.6391  \n",
      "\n",
      "Fold: 17  Epoch: 171  Training loss = 5.0412  Validation loss = 2.6388  \n",
      "\n",
      "Fold: 17  Epoch: 172  Training loss = 5.0405  Validation loss = 2.6384  \n",
      "\n",
      "Fold: 17  Epoch: 173  Training loss = 5.0396  Validation loss = 2.6378  \n",
      "\n",
      "Fold: 17  Epoch: 174  Training loss = 5.0387  Validation loss = 2.6374  \n",
      "\n",
      "Fold: 17  Epoch: 175  Training loss = 5.0381  Validation loss = 2.6371  \n",
      "\n",
      "Fold: 17  Epoch: 176  Training loss = 5.0375  Validation loss = 2.6366  \n",
      "\n",
      "Fold: 17  Epoch: 177  Training loss = 5.0365  Validation loss = 2.6361  \n",
      "\n",
      "Fold: 17  Epoch: 178  Training loss = 5.0358  Validation loss = 2.6357  \n",
      "\n",
      "Fold: 17  Epoch: 179  Training loss = 5.0349  Validation loss = 2.6354  \n",
      "\n",
      "Fold: 17  Epoch: 180  Training loss = 5.0341  Validation loss = 2.6349  \n",
      "\n",
      "Fold: 17  Epoch: 181  Training loss = 5.0333  Validation loss = 2.6345  \n",
      "\n",
      "Fold: 17  Epoch: 182  Training loss = 5.0325  Validation loss = 2.6342  \n",
      "\n",
      "Fold: 17  Epoch: 183  Training loss = 5.0318  Validation loss = 2.6338  \n",
      "\n",
      "Fold: 17  Epoch: 184  Training loss = 5.0310  Validation loss = 2.6334  \n",
      "\n",
      "Fold: 17  Epoch: 185  Training loss = 5.0301  Validation loss = 2.6330  \n",
      "\n",
      "Fold: 17  Epoch: 186  Training loss = 5.0294  Validation loss = 2.6328  \n",
      "\n",
      "Fold: 17  Epoch: 187  Training loss = 5.0286  Validation loss = 2.6323  \n",
      "\n",
      "Fold: 17  Epoch: 188  Training loss = 5.0279  Validation loss = 2.6319  \n",
      "\n",
      "Fold: 17  Epoch: 189  Training loss = 5.0268  Validation loss = 2.6316  \n",
      "\n",
      "Fold: 17  Epoch: 190  Training loss = 5.0259  Validation loss = 2.6311  \n",
      "\n",
      "Fold: 17  Epoch: 191  Training loss = 5.0251  Validation loss = 2.6305  \n",
      "\n",
      "Fold: 17  Epoch: 192  Training loss = 5.0242  Validation loss = 2.6299  \n",
      "\n",
      "Fold: 17  Epoch: 193  Training loss = 5.0232  Validation loss = 2.6295  \n",
      "\n",
      "Fold: 17  Epoch: 194  Training loss = 5.0224  Validation loss = 2.6290  \n",
      "\n",
      "Fold: 17  Epoch: 195  Training loss = 5.0215  Validation loss = 2.6285  \n",
      "\n",
      "Fold: 17  Epoch: 196  Training loss = 5.0207  Validation loss = 2.6282  \n",
      "\n",
      "Fold: 17  Epoch: 197  Training loss = 5.0200  Validation loss = 2.6278  \n",
      "\n",
      "Fold: 17  Epoch: 198  Training loss = 5.0191  Validation loss = 2.6275  \n",
      "\n",
      "Fold: 17  Epoch: 199  Training loss = 5.0182  Validation loss = 2.6271  \n",
      "\n",
      "Fold: 17  Epoch: 200  Training loss = 5.0174  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 17  Epoch: 201  Training loss = 5.0166  Validation loss = 2.6263  \n",
      "\n",
      "Fold: 17  Epoch: 202  Training loss = 5.0158  Validation loss = 2.6259  \n",
      "\n",
      "Fold: 17  Epoch: 203  Training loss = 5.0151  Validation loss = 2.6255  \n",
      "\n",
      "Fold: 17  Epoch: 204  Training loss = 5.0143  Validation loss = 2.6251  \n",
      "\n",
      "Fold: 17  Epoch: 205  Training loss = 5.0135  Validation loss = 2.6247  \n",
      "\n",
      "Fold: 17  Epoch: 206  Training loss = 5.0127  Validation loss = 2.6243  \n",
      "\n",
      "Fold: 17  Epoch: 207  Training loss = 5.0119  Validation loss = 2.6239  \n",
      "\n",
      "Fold: 17  Epoch: 208  Training loss = 5.0112  Validation loss = 2.6236  \n",
      "\n",
      "Fold: 17  Epoch: 209  Training loss = 5.0104  Validation loss = 2.6232  \n",
      "\n",
      "Fold: 17  Epoch: 210  Training loss = 5.0097  Validation loss = 2.6228  \n",
      "\n",
      "Fold: 17  Epoch: 211  Training loss = 5.0086  Validation loss = 2.6225  \n",
      "\n",
      "Fold: 17  Epoch: 212  Training loss = 5.0079  Validation loss = 2.6220  \n",
      "\n",
      "Fold: 17  Epoch: 213  Training loss = 5.0070  Validation loss = 2.6216  \n",
      "\n",
      "Fold: 17  Epoch: 214  Training loss = 5.0061  Validation loss = 2.6212  \n",
      "\n",
      "Fold: 17  Epoch: 215  Training loss = 5.0054  Validation loss = 2.6208  \n",
      "\n",
      "Fold: 17  Epoch: 216  Training loss = 5.0045  Validation loss = 2.6203  \n",
      "\n",
      "Fold: 17  Epoch: 217  Training loss = 5.0037  Validation loss = 2.6199  \n",
      "\n",
      "Fold: 17  Epoch: 218  Training loss = 5.0028  Validation loss = 2.6195  \n",
      "\n",
      "Fold: 17  Epoch: 219  Training loss = 5.0019  Validation loss = 2.6192  \n",
      "\n",
      "Fold: 17  Epoch: 220  Training loss = 5.0010  Validation loss = 2.6187  \n",
      "\n",
      "Fold: 17  Epoch: 221  Training loss = 5.0002  Validation loss = 2.6183  \n",
      "\n",
      "Fold: 17  Epoch: 222  Training loss = 4.9995  Validation loss = 2.6180  \n",
      "\n",
      "Fold: 17  Epoch: 223  Training loss = 4.9986  Validation loss = 2.6175  \n",
      "\n",
      "Fold: 17  Epoch: 224  Training loss = 4.9976  Validation loss = 2.6169  \n",
      "\n",
      "Fold: 17  Epoch: 225  Training loss = 4.9969  Validation loss = 2.6166  \n",
      "\n",
      "Fold: 17  Epoch: 226  Training loss = 4.9960  Validation loss = 2.6162  \n",
      "\n",
      "Fold: 17  Epoch: 227  Training loss = 4.9952  Validation loss = 2.6159  \n",
      "\n",
      "Fold: 17  Epoch: 228  Training loss = 4.9944  Validation loss = 2.6154  \n",
      "\n",
      "Fold: 17  Epoch: 229  Training loss = 4.9936  Validation loss = 2.6150  \n",
      "\n",
      "Fold: 17  Epoch: 230  Training loss = 4.9928  Validation loss = 2.6145  \n",
      "\n",
      "Fold: 17  Epoch: 231  Training loss = 4.9919  Validation loss = 2.6142  \n",
      "\n",
      "Fold: 17  Epoch: 232  Training loss = 4.9912  Validation loss = 2.6137  \n",
      "\n",
      "Fold: 17  Epoch: 233  Training loss = 4.9900  Validation loss = 2.6133  \n",
      "\n",
      "Fold: 17  Epoch: 234  Training loss = 4.9892  Validation loss = 2.6130  \n",
      "\n",
      "Fold: 17  Epoch: 235  Training loss = 4.9885  Validation loss = 2.6126  \n",
      "\n",
      "Fold: 17  Epoch: 236  Training loss = 4.9876  Validation loss = 2.6123  \n",
      "\n",
      "Fold: 17  Epoch: 237  Training loss = 4.9866  Validation loss = 2.6117  \n",
      "\n",
      "Fold: 17  Epoch: 238  Training loss = 4.9858  Validation loss = 2.6113  \n",
      "\n",
      "Fold: 17  Epoch: 239  Training loss = 4.9849  Validation loss = 2.6110  \n",
      "\n",
      "Fold: 17  Epoch: 240  Training loss = 4.9841  Validation loss = 2.6106  \n",
      "\n",
      "Fold: 17  Epoch: 241  Training loss = 4.9834  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 17  Epoch: 242  Training loss = 4.9824  Validation loss = 2.6098  \n",
      "\n",
      "Fold: 17  Epoch: 243  Training loss = 4.9813  Validation loss = 2.6093  \n",
      "\n",
      "Fold: 17  Epoch: 244  Training loss = 4.9805  Validation loss = 2.6090  \n",
      "\n",
      "Fold: 17  Epoch: 245  Training loss = 4.9797  Validation loss = 2.6085  \n",
      "\n",
      "Fold: 17  Epoch: 246  Training loss = 4.9789  Validation loss = 2.6081  \n",
      "\n",
      "Fold: 17  Epoch: 247  Training loss = 4.9779  Validation loss = 2.6075  \n",
      "\n",
      "Fold: 17  Epoch: 248  Training loss = 4.9770  Validation loss = 2.6070  \n",
      "\n",
      "Fold: 17  Epoch: 249  Training loss = 4.9761  Validation loss = 2.6067  \n",
      "\n",
      "Fold: 17  Epoch: 250  Training loss = 4.9752  Validation loss = 2.6063  \n",
      "\n",
      "Fold: 17  Epoch: 251  Training loss = 4.9745  Validation loss = 2.6058  \n",
      "\n",
      "Fold: 17  Epoch: 252  Training loss = 4.9737  Validation loss = 2.6055  \n",
      "\n",
      "Fold: 17  Epoch: 253  Training loss = 4.9729  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 17  Epoch: 254  Training loss = 4.9722  Validation loss = 2.6047  \n",
      "\n",
      "Fold: 17  Epoch: 255  Training loss = 4.9713  Validation loss = 2.6042  \n",
      "\n",
      "Fold: 17  Epoch: 256  Training loss = 4.9705  Validation loss = 2.6038  \n",
      "\n",
      "Fold: 17  Epoch: 257  Training loss = 4.9695  Validation loss = 2.6033  \n",
      "\n",
      "Fold: 17  Epoch: 258  Training loss = 4.9687  Validation loss = 2.6027  \n",
      "\n",
      "Fold: 17  Epoch: 259  Training loss = 4.9678  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 17  Epoch: 260  Training loss = 4.9670  Validation loss = 2.6017  \n",
      "\n",
      "Fold: 17  Epoch: 261  Training loss = 4.9662  Validation loss = 2.6014  \n",
      "\n",
      "Fold: 17  Epoch: 262  Training loss = 4.9653  Validation loss = 2.6010  \n",
      "\n",
      "Fold: 17  Epoch: 263  Training loss = 4.9645  Validation loss = 2.6006  \n",
      "\n",
      "Fold: 17  Epoch: 264  Training loss = 4.9637  Validation loss = 2.6003  \n",
      "\n",
      "Fold: 17  Epoch: 265  Training loss = 4.9630  Validation loss = 2.6000  \n",
      "\n",
      "Fold: 17  Epoch: 266  Training loss = 4.9621  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 17  Epoch: 267  Training loss = 4.9612  Validation loss = 2.5992  \n",
      "\n",
      "Fold: 17  Epoch: 268  Training loss = 4.9605  Validation loss = 2.5988  \n",
      "\n",
      "Fold: 17  Epoch: 269  Training loss = 4.9599  Validation loss = 2.5985  \n",
      "\n",
      "Fold: 17  Epoch: 270  Training loss = 4.9591  Validation loss = 2.5981  \n",
      "\n",
      "Fold: 17  Epoch: 271  Training loss = 4.9583  Validation loss = 2.5977  \n",
      "\n",
      "Fold: 17  Epoch: 272  Training loss = 4.9575  Validation loss = 2.5972  \n",
      "\n",
      "Fold: 17  Epoch: 273  Training loss = 4.9567  Validation loss = 2.5969  \n",
      "\n",
      "Fold: 17  Epoch: 274  Training loss = 4.9557  Validation loss = 2.5964  \n",
      "\n",
      "Fold: 17  Epoch: 275  Training loss = 4.9550  Validation loss = 2.5960  \n",
      "\n",
      "Fold: 17  Epoch: 276  Training loss = 4.9540  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 17  Epoch: 277  Training loss = 4.9534  Validation loss = 2.5952  \n",
      "\n",
      "Fold: 17  Epoch: 278  Training loss = 4.9526  Validation loss = 2.5949  \n",
      "\n",
      "Fold: 17  Epoch: 279  Training loss = 4.9517  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 17  Epoch: 280  Training loss = 4.9508  Validation loss = 2.5940  \n",
      "\n",
      "Fold: 17  Epoch: 281  Training loss = 4.9502  Validation loss = 2.5937  \n",
      "\n",
      "Fold: 17  Epoch: 282  Training loss = 4.9494  Validation loss = 2.5932  \n",
      "\n",
      "Fold: 17  Epoch: 283  Training loss = 4.9487  Validation loss = 2.5930  \n",
      "\n",
      "Fold: 17  Epoch: 284  Training loss = 4.9481  Validation loss = 2.5926  \n",
      "\n",
      "Fold: 17  Epoch: 285  Training loss = 4.9473  Validation loss = 2.5923  \n",
      "\n",
      "Fold: 17  Epoch: 286  Training loss = 4.9464  Validation loss = 2.5919  \n",
      "\n",
      "Fold: 17  Epoch: 287  Training loss = 4.9454  Validation loss = 2.5917  \n",
      "\n",
      "Fold: 17  Epoch: 288  Training loss = 4.9446  Validation loss = 2.5913  \n",
      "\n",
      "Fold: 17  Epoch: 289  Training loss = 4.9439  Validation loss = 2.5908  \n",
      "\n",
      "Fold: 17  Epoch: 290  Training loss = 4.9431  Validation loss = 2.5905  \n",
      "\n",
      "Fold: 17  Epoch: 291  Training loss = 4.9423  Validation loss = 2.5900  \n",
      "\n",
      "Fold: 17  Epoch: 292  Training loss = 4.9415  Validation loss = 2.5897  \n",
      "\n",
      "Fold: 17  Epoch: 293  Training loss = 4.9407  Validation loss = 2.5893  \n",
      "\n",
      "Fold: 17  Epoch: 294  Training loss = 4.9401  Validation loss = 2.5889  \n",
      "\n",
      "Fold: 17  Epoch: 295  Training loss = 4.9393  Validation loss = 2.5885  \n",
      "\n",
      "Fold: 17  Epoch: 296  Training loss = 4.9382  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 17  Epoch: 297  Training loss = 4.9373  Validation loss = 2.5876  \n",
      "\n",
      "Fold: 17  Epoch: 298  Training loss = 4.9365  Validation loss = 2.5871  \n",
      "\n",
      "Fold: 17  Epoch: 299  Training loss = 4.9358  Validation loss = 2.5868  \n",
      "\n",
      "Fold: 17  Epoch: 300  Training loss = 4.9349  Validation loss = 2.5865  \n",
      "\n",
      "Fold: 17  Epoch: 301  Training loss = 4.9341  Validation loss = 2.5862  \n",
      "\n",
      "Fold: 17  Epoch: 302  Training loss = 4.9333  Validation loss = 2.5859  \n",
      "\n",
      "Fold: 17  Epoch: 303  Training loss = 4.9324  Validation loss = 2.5856  \n",
      "\n",
      "Fold: 17  Epoch: 304  Training loss = 4.9317  Validation loss = 2.5853  \n",
      "\n",
      "Fold: 17  Epoch: 305  Training loss = 4.9310  Validation loss = 2.5849  \n",
      "\n",
      "Fold: 17  Epoch: 306  Training loss = 4.9300  Validation loss = 2.5846  \n",
      "\n",
      "Fold: 17  Epoch: 307  Training loss = 4.9292  Validation loss = 2.5843  \n",
      "\n",
      "Fold: 17  Epoch: 308  Training loss = 4.9284  Validation loss = 2.5840  \n",
      "\n",
      "Fold: 17  Epoch: 309  Training loss = 4.9276  Validation loss = 2.5837  \n",
      "\n",
      "Fold: 17  Epoch: 310  Training loss = 4.9270  Validation loss = 2.5833  \n",
      "\n",
      "Fold: 17  Epoch: 311  Training loss = 4.9259  Validation loss = 2.5830  \n",
      "\n",
      "Fold: 17  Epoch: 312  Training loss = 4.9252  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 17  Epoch: 313  Training loss = 4.9245  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 17  Epoch: 314  Training loss = 4.9237  Validation loss = 2.5820  \n",
      "\n",
      "Fold: 17  Epoch: 315  Training loss = 4.9230  Validation loss = 2.5816  \n",
      "\n",
      "Fold: 17  Epoch: 316  Training loss = 4.9224  Validation loss = 2.5813  \n",
      "\n",
      "Fold: 17  Epoch: 317  Training loss = 4.9214  Validation loss = 2.5809  \n",
      "\n",
      "Fold: 17  Epoch: 318  Training loss = 4.9205  Validation loss = 2.5805  \n",
      "\n",
      "Fold: 17  Epoch: 319  Training loss = 4.9197  Validation loss = 2.5800  \n",
      "\n",
      "Fold: 17  Epoch: 320  Training loss = 4.9190  Validation loss = 2.5796  \n",
      "\n",
      "Fold: 17  Epoch: 321  Training loss = 4.9181  Validation loss = 2.5792  \n",
      "\n",
      "Fold: 17  Epoch: 322  Training loss = 4.9173  Validation loss = 2.5789  \n",
      "\n",
      "Fold: 17  Epoch: 323  Training loss = 4.9164  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 17  Epoch: 324  Training loss = 4.9157  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 17  Epoch: 325  Training loss = 4.9149  Validation loss = 2.5777  \n",
      "\n",
      "Fold: 17  Epoch: 326  Training loss = 4.9142  Validation loss = 2.5774  \n",
      "\n",
      "Fold: 17  Epoch: 327  Training loss = 4.9134  Validation loss = 2.5770  \n",
      "\n",
      "Fold: 17  Epoch: 328  Training loss = 4.9129  Validation loss = 2.5766  \n",
      "\n",
      "Fold: 17  Epoch: 329  Training loss = 4.9120  Validation loss = 2.5762  \n",
      "\n",
      "Fold: 17  Epoch: 330  Training loss = 4.9112  Validation loss = 2.5758  \n",
      "\n",
      "Fold: 17  Epoch: 331  Training loss = 4.9103  Validation loss = 2.5753  \n",
      "\n",
      "Fold: 17  Epoch: 332  Training loss = 4.9092  Validation loss = 2.5749  \n",
      "\n",
      "Fold: 17  Epoch: 333  Training loss = 4.9083  Validation loss = 2.5744  \n",
      "\n",
      "Fold: 17  Epoch: 334  Training loss = 4.9075  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 17  Epoch: 335  Training loss = 4.9066  Validation loss = 2.5737  \n",
      "\n",
      "Fold: 17  Epoch: 336  Training loss = 4.9061  Validation loss = 2.5734  \n",
      "\n",
      "Fold: 17  Epoch: 337  Training loss = 4.9053  Validation loss = 2.5730  \n",
      "\n",
      "Fold: 17  Epoch: 338  Training loss = 4.9044  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 17  Epoch: 339  Training loss = 4.9037  Validation loss = 2.5724  \n",
      "\n",
      "Fold: 17  Epoch: 340  Training loss = 4.9027  Validation loss = 2.5720  \n",
      "\n",
      "Fold: 17  Epoch: 341  Training loss = 4.9019  Validation loss = 2.5716  \n",
      "\n",
      "Fold: 17  Epoch: 342  Training loss = 4.9010  Validation loss = 2.5711  \n",
      "\n",
      "Fold: 17  Epoch: 343  Training loss = 4.9001  Validation loss = 2.5708  \n",
      "\n",
      "Fold: 17  Epoch: 344  Training loss = 4.8991  Validation loss = 2.5705  \n",
      "\n",
      "Fold: 17  Epoch: 345  Training loss = 4.8982  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 17  Epoch: 346  Training loss = 4.8973  Validation loss = 2.5698  \n",
      "\n",
      "Fold: 17  Epoch: 347  Training loss = 4.8966  Validation loss = 2.5694  \n",
      "\n",
      "Fold: 17  Epoch: 348  Training loss = 4.8958  Validation loss = 2.5690  \n",
      "\n",
      "Fold: 17  Epoch: 349  Training loss = 4.8950  Validation loss = 2.5687  \n",
      "\n",
      "Fold: 17  Epoch: 350  Training loss = 4.8945  Validation loss = 2.5684  \n",
      "\n",
      "Fold: 17  Epoch: 351  Training loss = 4.8937  Validation loss = 2.5680  \n",
      "\n",
      "Fold: 17  Epoch: 352  Training loss = 4.8930  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 17  Epoch: 353  Training loss = 4.8924  Validation loss = 2.5674  \n",
      "\n",
      "Fold: 17  Epoch: 354  Training loss = 4.8916  Validation loss = 2.5670  \n",
      "\n",
      "Fold: 17  Epoch: 355  Training loss = 4.8906  Validation loss = 2.5664  \n",
      "\n",
      "Fold: 17  Epoch: 356  Training loss = 4.8898  Validation loss = 2.5660  \n",
      "\n",
      "Fold: 17  Epoch: 357  Training loss = 4.8890  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 17  Epoch: 358  Training loss = 4.8882  Validation loss = 2.5652  \n",
      "\n",
      "Fold: 17  Epoch: 359  Training loss = 4.8875  Validation loss = 2.5648  \n",
      "\n",
      "Fold: 17  Epoch: 360  Training loss = 4.8866  Validation loss = 2.5644  \n",
      "\n",
      "Fold: 17  Epoch: 361  Training loss = 4.8861  Validation loss = 2.5641  \n",
      "\n",
      "Fold: 17  Epoch: 362  Training loss = 4.8853  Validation loss = 2.5638  \n",
      "\n",
      "Fold: 17  Epoch: 363  Training loss = 4.8847  Validation loss = 2.5635  \n",
      "\n",
      "Fold: 17  Epoch: 364  Training loss = 4.8838  Validation loss = 2.5631  \n",
      "\n",
      "Fold: 17  Epoch: 365  Training loss = 4.8829  Validation loss = 2.5626  \n",
      "\n",
      "Fold: 17  Epoch: 366  Training loss = 4.8822  Validation loss = 2.5622  \n",
      "\n",
      "Fold: 17  Epoch: 367  Training loss = 4.8812  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 17  Epoch: 368  Training loss = 4.8802  Validation loss = 2.5614  \n",
      "\n",
      "Fold: 17  Epoch: 369  Training loss = 4.8794  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 17  Epoch: 370  Training loss = 4.8784  Validation loss = 2.5607  \n",
      "\n",
      "Fold: 17  Epoch: 371  Training loss = 4.8777  Validation loss = 2.5603  \n",
      "\n",
      "Fold: 17  Epoch: 372  Training loss = 4.8769  Validation loss = 2.5599  \n",
      "\n",
      "Fold: 17  Epoch: 373  Training loss = 4.8761  Validation loss = 2.5595  \n",
      "\n",
      "Fold: 17  Epoch: 374  Training loss = 4.8752  Validation loss = 2.5592  \n",
      "\n",
      "Fold: 17  Epoch: 375  Training loss = 4.8745  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 17  Epoch: 376  Training loss = 4.8738  Validation loss = 2.5586  \n",
      "\n",
      "Fold: 17  Epoch: 377  Training loss = 4.8729  Validation loss = 2.5583  \n",
      "\n",
      "Fold: 17  Epoch: 378  Training loss = 4.8722  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 17  Epoch: 379  Training loss = 4.8714  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 17  Epoch: 380  Training loss = 4.8705  Validation loss = 2.5574  \n",
      "\n",
      "Fold: 17  Epoch: 381  Training loss = 4.8695  Validation loss = 2.5570  \n",
      "\n",
      "Fold: 17  Epoch: 382  Training loss = 4.8688  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 17  Epoch: 383  Training loss = 4.8680  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 17  Epoch: 384  Training loss = 4.8670  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 17  Epoch: 385  Training loss = 4.8661  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 17  Epoch: 386  Training loss = 4.8651  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 17  Epoch: 387  Training loss = 4.8642  Validation loss = 2.5545  \n",
      "\n",
      "Fold: 17  Epoch: 388  Training loss = 4.8632  Validation loss = 2.5540  \n",
      "\n",
      "Fold: 17  Epoch: 389  Training loss = 4.8625  Validation loss = 2.5537  \n",
      "\n",
      "Fold: 17  Epoch: 390  Training loss = 4.8619  Validation loss = 2.5533  \n",
      "\n",
      "Fold: 17  Epoch: 391  Training loss = 4.8612  Validation loss = 2.5529  \n",
      "\n",
      "Fold: 17  Epoch: 392  Training loss = 4.8606  Validation loss = 2.5527  \n",
      "\n",
      "Fold: 17  Epoch: 393  Training loss = 4.8598  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 17  Epoch: 394  Training loss = 4.8589  Validation loss = 2.5520  \n",
      "\n",
      "Fold: 17  Epoch: 395  Training loss = 4.8581  Validation loss = 2.5516  \n",
      "\n",
      "Fold: 17  Epoch: 396  Training loss = 4.8573  Validation loss = 2.5513  \n",
      "\n",
      "Fold: 17  Epoch: 397  Training loss = 4.8566  Validation loss = 2.5509  \n",
      "\n",
      "Fold: 17  Epoch: 398  Training loss = 4.8558  Validation loss = 2.5506  \n",
      "\n",
      "Fold: 17  Epoch: 399  Training loss = 4.8551  Validation loss = 2.5503  \n",
      "\n",
      "Fold: 17  Epoch: 400  Training loss = 4.8541  Validation loss = 2.5500  \n",
      "\n",
      "Fold: 17  Epoch: 401  Training loss = 4.8534  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 17  Epoch: 402  Training loss = 4.8525  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 17  Epoch: 403  Training loss = 4.8517  Validation loss = 2.5487  \n",
      "\n",
      "Fold: 17  Epoch: 404  Training loss = 4.8511  Validation loss = 2.5484  \n",
      "\n",
      "Fold: 17  Epoch: 405  Training loss = 4.8504  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 17  Epoch: 406  Training loss = 4.8494  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 17  Epoch: 407  Training loss = 4.8488  Validation loss = 2.5472  \n",
      "\n",
      "Fold: 17  Epoch: 408  Training loss = 4.8479  Validation loss = 2.5468  \n",
      "\n",
      "Fold: 17  Epoch: 409  Training loss = 4.8470  Validation loss = 2.5465  \n",
      "\n",
      "Fold: 17  Epoch: 410  Training loss = 4.8461  Validation loss = 2.5462  \n",
      "\n",
      "Fold: 17  Epoch: 411  Training loss = 4.8454  Validation loss = 2.5459  \n",
      "\n",
      "Fold: 17  Epoch: 412  Training loss = 4.8447  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 17  Epoch: 413  Training loss = 4.8438  Validation loss = 2.5451  \n",
      "\n",
      "Fold: 17  Epoch: 414  Training loss = 4.8429  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 17  Epoch: 415  Training loss = 4.8422  Validation loss = 2.5443  \n",
      "\n",
      "Fold: 17  Epoch: 416  Training loss = 4.8415  Validation loss = 2.5440  \n",
      "\n",
      "Fold: 17  Epoch: 417  Training loss = 4.8409  Validation loss = 2.5437  \n",
      "\n",
      "Fold: 17  Epoch: 418  Training loss = 4.8403  Validation loss = 2.5433  \n",
      "\n",
      "Fold: 17  Epoch: 419  Training loss = 4.8396  Validation loss = 2.5431  \n",
      "\n",
      "Fold: 17  Epoch: 420  Training loss = 4.8387  Validation loss = 2.5427  \n",
      "\n",
      "Fold: 17  Epoch: 421  Training loss = 4.8377  Validation loss = 2.5422  \n",
      "\n",
      "Fold: 17  Epoch: 422  Training loss = 4.8370  Validation loss = 2.5419  \n",
      "\n",
      "Fold: 17  Epoch: 423  Training loss = 4.8361  Validation loss = 2.5415  \n",
      "\n",
      "Fold: 17  Epoch: 424  Training loss = 4.8354  Validation loss = 2.5412  \n",
      "\n",
      "Fold: 17  Epoch: 425  Training loss = 4.8346  Validation loss = 2.5409  \n",
      "\n",
      "Fold: 17  Epoch: 426  Training loss = 4.8338  Validation loss = 2.5404  \n",
      "\n",
      "Fold: 17  Epoch: 427  Training loss = 4.8330  Validation loss = 2.5401  \n",
      "\n",
      "Fold: 17  Epoch: 428  Training loss = 4.8322  Validation loss = 2.5399  \n",
      "\n",
      "Fold: 17  Epoch: 429  Training loss = 4.8316  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 17  Epoch: 430  Training loss = 4.8308  Validation loss = 2.5392  \n",
      "\n",
      "Fold: 17  Epoch: 431  Training loss = 4.8301  Validation loss = 2.5389  \n",
      "\n",
      "Fold: 17  Epoch: 432  Training loss = 4.8293  Validation loss = 2.5384  \n",
      "\n",
      "Fold: 17  Epoch: 433  Training loss = 4.8286  Validation loss = 2.5382  \n",
      "\n",
      "Fold: 17  Epoch: 434  Training loss = 4.8278  Validation loss = 2.5379  \n",
      "\n",
      "Fold: 17  Epoch: 435  Training loss = 4.8271  Validation loss = 2.5375  \n",
      "\n",
      "Fold: 17  Epoch: 436  Training loss = 4.8264  Validation loss = 2.5371  \n",
      "\n",
      "Fold: 17  Epoch: 437  Training loss = 4.8257  Validation loss = 2.5367  \n",
      "\n",
      "Fold: 17  Epoch: 438  Training loss = 4.8248  Validation loss = 2.5364  \n",
      "\n",
      "Fold: 17  Epoch: 439  Training loss = 4.8241  Validation loss = 2.5361  \n",
      "\n",
      "Fold: 17  Epoch: 440  Training loss = 4.8233  Validation loss = 2.5358  \n",
      "\n",
      "Fold: 17  Epoch: 441  Training loss = 4.8225  Validation loss = 2.5355  \n",
      "\n",
      "Fold: 17  Epoch: 442  Training loss = 4.8217  Validation loss = 2.5351  \n",
      "\n",
      "Fold: 17  Epoch: 443  Training loss = 4.8210  Validation loss = 2.5348  \n",
      "\n",
      "Fold: 17  Epoch: 444  Training loss = 4.8201  Validation loss = 2.5344  \n",
      "\n",
      "Fold: 17  Epoch: 445  Training loss = 4.8193  Validation loss = 2.5341  \n",
      "\n",
      "Fold: 17  Epoch: 446  Training loss = 4.8184  Validation loss = 2.5336  \n",
      "\n",
      "Fold: 17  Epoch: 447  Training loss = 4.8178  Validation loss = 2.5333  \n",
      "\n",
      "Fold: 17  Epoch: 448  Training loss = 4.8169  Validation loss = 2.5330  \n",
      "\n",
      "Fold: 17  Epoch: 449  Training loss = 4.8162  Validation loss = 2.5326  \n",
      "\n",
      "Fold: 17  Epoch: 450  Training loss = 4.8154  Validation loss = 2.5323  \n",
      "\n",
      "Fold: 17  Epoch: 451  Training loss = 4.8145  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 17  Epoch: 452  Training loss = 4.8138  Validation loss = 2.5316  \n",
      "\n",
      "Fold: 17  Epoch: 453  Training loss = 4.8132  Validation loss = 2.5314  \n",
      "\n",
      "Fold: 17  Epoch: 454  Training loss = 4.8124  Validation loss = 2.5311  \n",
      "\n",
      "Fold: 17  Epoch: 455  Training loss = 4.8116  Validation loss = 2.5308  \n",
      "\n",
      "Fold: 17  Epoch: 456  Training loss = 4.8108  Validation loss = 2.5305  \n",
      "\n",
      "Fold: 17  Epoch: 457  Training loss = 4.8100  Validation loss = 2.5302  \n",
      "\n",
      "Fold: 17  Epoch: 458  Training loss = 4.8091  Validation loss = 2.5297  \n",
      "\n",
      "Fold: 17  Epoch: 459  Training loss = 4.8084  Validation loss = 2.5294  \n",
      "\n",
      "Fold: 17  Epoch: 460  Training loss = 4.8076  Validation loss = 2.5292  \n",
      "\n",
      "Fold: 17  Epoch: 461  Training loss = 4.8068  Validation loss = 2.5288  \n",
      "\n",
      "Fold: 17  Epoch: 462  Training loss = 4.8062  Validation loss = 2.5285  \n",
      "\n",
      "Fold: 17  Epoch: 463  Training loss = 4.8055  Validation loss = 2.5281  \n",
      "\n",
      "Fold: 17  Epoch: 464  Training loss = 4.8047  Validation loss = 2.5278  \n",
      "\n",
      "Fold: 17  Epoch: 465  Training loss = 4.8038  Validation loss = 2.5274  \n",
      "\n",
      "Fold: 17  Epoch: 466  Training loss = 4.8031  Validation loss = 2.5271  \n",
      "\n",
      "Fold: 17  Epoch: 467  Training loss = 4.8023  Validation loss = 2.5267  \n",
      "\n",
      "Fold: 17  Epoch: 468  Training loss = 4.8016  Validation loss = 2.5264  \n",
      "\n",
      "Fold: 17  Epoch: 469  Training loss = 4.8008  Validation loss = 2.5260  \n",
      "\n",
      "Fold: 17  Epoch: 470  Training loss = 4.8000  Validation loss = 2.5256  \n",
      "\n",
      "Fold: 17  Epoch: 471  Training loss = 4.7994  Validation loss = 2.5252  \n",
      "\n",
      "Fold: 17  Epoch: 472  Training loss = 4.7987  Validation loss = 2.5249  \n",
      "\n",
      "Fold: 17  Epoch: 473  Training loss = 4.7981  Validation loss = 2.5247  \n",
      "\n",
      "Fold: 17  Epoch: 474  Training loss = 4.7975  Validation loss = 2.5244  \n",
      "\n",
      "Fold: 17  Epoch: 475  Training loss = 4.7966  Validation loss = 2.5241  \n",
      "\n",
      "Fold: 17  Epoch: 476  Training loss = 4.7960  Validation loss = 2.5238  \n",
      "\n",
      "Fold: 17  Epoch: 477  Training loss = 4.7953  Validation loss = 2.5235  \n",
      "\n",
      "Fold: 17  Epoch: 478  Training loss = 4.7946  Validation loss = 2.5231  \n",
      "\n",
      "Fold: 17  Epoch: 479  Training loss = 4.7938  Validation loss = 2.5225  \n",
      "\n",
      "Fold: 17  Epoch: 480  Training loss = 4.7930  Validation loss = 2.5221  \n",
      "\n",
      "Fold: 17  Epoch: 481  Training loss = 4.7922  Validation loss = 2.5217  \n",
      "\n",
      "Fold: 17  Epoch: 482  Training loss = 4.7915  Validation loss = 2.5213  \n",
      "\n",
      "Fold: 17  Epoch: 483  Training loss = 4.7907  Validation loss = 2.5210  \n",
      "\n",
      "Fold: 17  Epoch: 484  Training loss = 4.7899  Validation loss = 2.5206  \n",
      "\n",
      "Fold: 17  Epoch: 485  Training loss = 4.7890  Validation loss = 2.5204  \n",
      "\n",
      "Fold: 17  Epoch: 486  Training loss = 4.7881  Validation loss = 2.5200  \n",
      "\n",
      "Fold: 17  Epoch: 487  Training loss = 4.7874  Validation loss = 2.5196  \n",
      "\n",
      "Fold: 17  Epoch: 488  Training loss = 4.7866  Validation loss = 2.5192  \n",
      "\n",
      "Fold: 17  Epoch: 489  Training loss = 4.7857  Validation loss = 2.5187  \n",
      "\n",
      "Fold: 17  Epoch: 490  Training loss = 4.7850  Validation loss = 2.5184  \n",
      "\n",
      "Fold: 17  Epoch: 491  Training loss = 4.7842  Validation loss = 2.5180  \n",
      "\n",
      "Fold: 17  Epoch: 492  Training loss = 4.7835  Validation loss = 2.5178  \n",
      "\n",
      "Fold: 17  Epoch: 493  Training loss = 4.7826  Validation loss = 2.5173  \n",
      "\n",
      "Fold: 17  Epoch: 494  Training loss = 4.7817  Validation loss = 2.5170  \n",
      "\n",
      "Fold: 17  Epoch: 495  Training loss = 4.7809  Validation loss = 2.5167  \n",
      "\n",
      "Fold: 17  Epoch: 496  Training loss = 4.7802  Validation loss = 2.5164  \n",
      "\n",
      "Fold: 17  Epoch: 497  Training loss = 4.7794  Validation loss = 2.5162  \n",
      "\n",
      "Fold: 17  Epoch: 498  Training loss = 4.7787  Validation loss = 2.5159  \n",
      "\n",
      "Fold: 17  Epoch: 499  Training loss = 4.7782  Validation loss = 2.5156  \n",
      "\n",
      "Fold: 17  Epoch: 500  Training loss = 4.7776  Validation loss = 2.5153  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 500  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 4.8146  Validation loss = 0.9296  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 4.8139  Validation loss = 0.9293  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 4.8131  Validation loss = 0.9289  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 4.8123  Validation loss = 0.9285  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 4.8115  Validation loss = 0.9281  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 4.8107  Validation loss = 0.9278  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 4.8099  Validation loss = 0.9274  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 4.8089  Validation loss = 0.9269  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 4.8082  Validation loss = 0.9265  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 4.8075  Validation loss = 0.9262  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 4.8069  Validation loss = 0.9259  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 4.8059  Validation loss = 0.9254  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 4.8052  Validation loss = 0.9252  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 4.8045  Validation loss = 0.9248  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 4.8038  Validation loss = 0.9246  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 4.8030  Validation loss = 0.9242  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 4.8023  Validation loss = 0.9238  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 4.8014  Validation loss = 0.9235  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 4.8004  Validation loss = 0.9230  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 4.7994  Validation loss = 0.9225  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 4.7986  Validation loss = 0.9222  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 4.7978  Validation loss = 0.9218  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 4.7971  Validation loss = 0.9216  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 4.7965  Validation loss = 0.9214  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 4.7957  Validation loss = 0.9210  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 4.7948  Validation loss = 0.9206  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 4.7940  Validation loss = 0.9204  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 4.7931  Validation loss = 0.9198  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 4.7923  Validation loss = 0.9195  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 4.7914  Validation loss = 0.9191  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 4.7906  Validation loss = 0.9187  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 4.7898  Validation loss = 0.9184  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 4.7889  Validation loss = 0.9179  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 4.7881  Validation loss = 0.9176  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 4.7875  Validation loss = 0.9172  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 4.7867  Validation loss = 0.9169  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 4.7860  Validation loss = 0.9166  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 4.7852  Validation loss = 0.9162  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 4.7846  Validation loss = 0.9160  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 4.7837  Validation loss = 0.9155  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 4.7831  Validation loss = 0.9153  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 4.7821  Validation loss = 0.9149  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 4.7814  Validation loss = 0.9147  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 4.7806  Validation loss = 0.9143  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 4.7799  Validation loss = 0.9141  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 4.7791  Validation loss = 0.9137  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 4.7783  Validation loss = 0.9135  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 4.7777  Validation loss = 0.9132  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 4.7768  Validation loss = 0.9127  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 4.7760  Validation loss = 0.9123  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 4.7752  Validation loss = 0.9121  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 4.7745  Validation loss = 0.9118  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 4.7737  Validation loss = 0.9115  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 4.7728  Validation loss = 0.9110  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 4.7720  Validation loss = 0.9107  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 4.7712  Validation loss = 0.9104  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 4.7705  Validation loss = 0.9101  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 4.7698  Validation loss = 0.9098  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 4.7692  Validation loss = 0.9095  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 4.7684  Validation loss = 0.9092  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 4.7677  Validation loss = 0.9090  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 4.7669  Validation loss = 0.9086  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 4.7661  Validation loss = 0.9083  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 4.7651  Validation loss = 0.9078  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 4.7643  Validation loss = 0.9074  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 4.7635  Validation loss = 0.9071  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 4.7626  Validation loss = 0.9067  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 4.7619  Validation loss = 0.9064  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 4.7610  Validation loss = 0.9061  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 4.7602  Validation loss = 0.9058  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 4.7594  Validation loss = 0.9054  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 4.7586  Validation loss = 0.9051  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 4.7578  Validation loss = 0.9046  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 4.7569  Validation loss = 0.9041  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 4.7561  Validation loss = 0.9037  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 4.7555  Validation loss = 0.9035  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 4.7547  Validation loss = 0.9030  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 4.7540  Validation loss = 0.9028  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 4.7533  Validation loss = 0.9026  \n",
      "\n",
      "Fold: 18  Epoch: 80  Training loss = 4.7525  Validation loss = 0.9023  \n",
      "\n",
      "Fold: 18  Epoch: 81  Training loss = 4.7518  Validation loss = 0.9021  \n",
      "\n",
      "Fold: 18  Epoch: 82  Training loss = 4.7512  Validation loss = 0.9018  \n",
      "\n",
      "Fold: 18  Epoch: 83  Training loss = 4.7505  Validation loss = 0.9016  \n",
      "\n",
      "Fold: 18  Epoch: 84  Training loss = 4.7498  Validation loss = 0.9013  \n",
      "\n",
      "Fold: 18  Epoch: 85  Training loss = 4.7491  Validation loss = 0.9011  \n",
      "\n",
      "Fold: 18  Epoch: 86  Training loss = 4.7484  Validation loss = 0.9008  \n",
      "\n",
      "Fold: 18  Epoch: 87  Training loss = 4.7477  Validation loss = 0.9004  \n",
      "\n",
      "Fold: 18  Epoch: 88  Training loss = 4.7471  Validation loss = 0.9002  \n",
      "\n",
      "Fold: 18  Epoch: 89  Training loss = 4.7464  Validation loss = 0.8999  \n",
      "\n",
      "Fold: 18  Epoch: 90  Training loss = 4.7458  Validation loss = 0.8996  \n",
      "\n",
      "Fold: 18  Epoch: 91  Training loss = 4.7451  Validation loss = 0.8994  \n",
      "\n",
      "Fold: 18  Epoch: 92  Training loss = 4.7444  Validation loss = 0.8991  \n",
      "\n",
      "Fold: 18  Epoch: 93  Training loss = 4.7438  Validation loss = 0.8990  \n",
      "\n",
      "Fold: 18  Epoch: 94  Training loss = 4.7431  Validation loss = 0.8987  \n",
      "\n",
      "Fold: 18  Epoch: 95  Training loss = 4.7424  Validation loss = 0.8985  \n",
      "\n",
      "Fold: 18  Epoch: 96  Training loss = 4.7416  Validation loss = 0.8981  \n",
      "\n",
      "Fold: 18  Epoch: 97  Training loss = 4.7408  Validation loss = 0.8978  \n",
      "\n",
      "Fold: 18  Epoch: 98  Training loss = 4.7400  Validation loss = 0.8974  \n",
      "\n",
      "Fold: 18  Epoch: 99  Training loss = 4.7392  Validation loss = 0.8970  \n",
      "\n",
      "Fold: 18  Epoch: 100  Training loss = 4.7385  Validation loss = 0.8968  \n",
      "\n",
      "Fold: 18  Epoch: 101  Training loss = 4.7379  Validation loss = 0.8965  \n",
      "\n",
      "Fold: 18  Epoch: 102  Training loss = 4.7371  Validation loss = 0.8963  \n",
      "\n",
      "Fold: 18  Epoch: 103  Training loss = 4.7364  Validation loss = 0.8960  \n",
      "\n",
      "Fold: 18  Epoch: 104  Training loss = 4.7356  Validation loss = 0.8956  \n",
      "\n",
      "Fold: 18  Epoch: 105  Training loss = 4.7350  Validation loss = 0.8954  \n",
      "\n",
      "Fold: 18  Epoch: 106  Training loss = 4.7343  Validation loss = 0.8951  \n",
      "\n",
      "Fold: 18  Epoch: 107  Training loss = 4.7337  Validation loss = 0.8950  \n",
      "\n",
      "Fold: 18  Epoch: 108  Training loss = 4.7331  Validation loss = 0.8947  \n",
      "\n",
      "Fold: 18  Epoch: 109  Training loss = 4.7324  Validation loss = 0.8945  \n",
      "\n",
      "Fold: 18  Epoch: 110  Training loss = 4.7317  Validation loss = 0.8943  \n",
      "\n",
      "Fold: 18  Epoch: 111  Training loss = 4.7312  Validation loss = 0.8941  \n",
      "\n",
      "Fold: 18  Epoch: 112  Training loss = 4.7305  Validation loss = 0.8938  \n",
      "\n",
      "Fold: 18  Epoch: 113  Training loss = 4.7299  Validation loss = 0.8936  \n",
      "\n",
      "Fold: 18  Epoch: 114  Training loss = 4.7292  Validation loss = 0.8932  \n",
      "\n",
      "Fold: 18  Epoch: 115  Training loss = 4.7286  Validation loss = 0.8930  \n",
      "\n",
      "Fold: 18  Epoch: 116  Training loss = 4.7280  Validation loss = 0.8928  \n",
      "\n",
      "Fold: 18  Epoch: 117  Training loss = 4.7273  Validation loss = 0.8926  \n",
      "\n",
      "Fold: 18  Epoch: 118  Training loss = 4.7266  Validation loss = 0.8923  \n",
      "\n",
      "Fold: 18  Epoch: 119  Training loss = 4.7259  Validation loss = 0.8921  \n",
      "\n",
      "Fold: 18  Epoch: 120  Training loss = 4.7252  Validation loss = 0.8918  \n",
      "\n",
      "Fold: 18  Epoch: 121  Training loss = 4.7247  Validation loss = 0.8917  \n",
      "\n",
      "Fold: 18  Epoch: 122  Training loss = 4.7239  Validation loss = 0.8913  \n",
      "\n",
      "Fold: 18  Epoch: 123  Training loss = 4.7233  Validation loss = 0.8911  \n",
      "\n",
      "Fold: 18  Epoch: 124  Training loss = 4.7226  Validation loss = 0.8909  \n",
      "\n",
      "Fold: 18  Epoch: 125  Training loss = 4.7220  Validation loss = 0.8906  \n",
      "\n",
      "Fold: 18  Epoch: 126  Training loss = 4.7212  Validation loss = 0.8904  \n",
      "\n",
      "Fold: 18  Epoch: 127  Training loss = 4.7206  Validation loss = 0.8902  \n",
      "\n",
      "Fold: 18  Epoch: 128  Training loss = 4.7200  Validation loss = 0.8899  \n",
      "\n",
      "Fold: 18  Epoch: 129  Training loss = 4.7192  Validation loss = 0.8897  \n",
      "\n",
      "Fold: 18  Epoch: 130  Training loss = 4.7186  Validation loss = 0.8895  \n",
      "\n",
      "Fold: 18  Epoch: 131  Training loss = 4.7179  Validation loss = 0.8892  \n",
      "\n",
      "Fold: 18  Epoch: 132  Training loss = 4.7172  Validation loss = 0.8890  \n",
      "\n",
      "Fold: 18  Epoch: 133  Training loss = 4.7166  Validation loss = 0.8887  \n",
      "\n",
      "Fold: 18  Epoch: 134  Training loss = 4.7159  Validation loss = 0.8884  \n",
      "\n",
      "Fold: 18  Epoch: 135  Training loss = 4.7153  Validation loss = 0.8882  \n",
      "\n",
      "Fold: 18  Epoch: 136  Training loss = 4.7145  Validation loss = 0.8880  \n",
      "\n",
      "Fold: 18  Epoch: 137  Training loss = 4.7137  Validation loss = 0.8877  \n",
      "\n",
      "Fold: 18  Epoch: 138  Training loss = 4.7131  Validation loss = 0.8875  \n",
      "\n",
      "Fold: 18  Epoch: 139  Training loss = 4.7125  Validation loss = 0.8873  \n",
      "\n",
      "Fold: 18  Epoch: 140  Training loss = 4.7117  Validation loss = 0.8871  \n",
      "\n",
      "Fold: 18  Epoch: 141  Training loss = 4.7108  Validation loss = 0.8869  \n",
      "\n",
      "Fold: 18  Epoch: 142  Training loss = 4.7100  Validation loss = 0.8866  \n",
      "\n",
      "Fold: 18  Epoch: 143  Training loss = 4.7089  Validation loss = 0.8861  \n",
      "\n",
      "Fold: 18  Epoch: 144  Training loss = 4.7076  Validation loss = 0.8857  \n",
      "\n",
      "Fold: 18  Epoch: 145  Training loss = 4.7056  Validation loss = 0.8851  \n",
      "\n",
      "Fold: 18  Epoch: 146  Training loss = 4.7034  Validation loss = 0.8843  \n",
      "\n",
      "Fold: 18  Epoch: 147  Training loss = 4.7025  Validation loss = 0.8840  \n",
      "\n",
      "Fold: 18  Epoch: 148  Training loss = 4.7018  Validation loss = 0.8839  \n",
      "\n",
      "Fold: 18  Epoch: 149  Training loss = 4.7010  Validation loss = 0.8836  \n",
      "\n",
      "Fold: 18  Epoch: 150  Training loss = 4.7001  Validation loss = 0.8831  \n",
      "\n",
      "Fold: 18  Epoch: 151  Training loss = 4.6994  Validation loss = 0.8830  \n",
      "\n",
      "Fold: 18  Epoch: 152  Training loss = 4.6988  Validation loss = 0.8827  \n",
      "\n",
      "Fold: 18  Epoch: 153  Training loss = 4.6981  Validation loss = 0.8824  \n",
      "\n",
      "Fold: 18  Epoch: 154  Training loss = 4.6975  Validation loss = 0.8822  \n",
      "\n",
      "Fold: 18  Epoch: 155  Training loss = 4.6970  Validation loss = 0.8820  \n",
      "\n",
      "Fold: 18  Epoch: 156  Training loss = 4.6963  Validation loss = 0.8817  \n",
      "\n",
      "Fold: 18  Epoch: 157  Training loss = 4.6957  Validation loss = 0.8814  \n",
      "\n",
      "Fold: 18  Epoch: 158  Training loss = 4.6951  Validation loss = 0.8813  \n",
      "\n",
      "Fold: 18  Epoch: 159  Training loss = 4.6945  Validation loss = 0.8811  \n",
      "\n",
      "Fold: 18  Epoch: 160  Training loss = 4.6938  Validation loss = 0.8810  \n",
      "\n",
      "Fold: 18  Epoch: 161  Training loss = 4.6932  Validation loss = 0.8808  \n",
      "\n",
      "Fold: 18  Epoch: 162  Training loss = 4.6926  Validation loss = 0.8806  \n",
      "\n",
      "Fold: 18  Epoch: 163  Training loss = 4.6919  Validation loss = 0.8805  \n",
      "\n",
      "Fold: 18  Epoch: 164  Training loss = 4.6912  Validation loss = 0.8804  \n",
      "\n",
      "Fold: 18  Epoch: 165  Training loss = 4.6906  Validation loss = 0.8802  \n",
      "\n",
      "Fold: 18  Epoch: 166  Training loss = 4.6899  Validation loss = 0.8800  \n",
      "\n",
      "Fold: 18  Epoch: 167  Training loss = 4.6894  Validation loss = 0.8799  \n",
      "\n",
      "Fold: 18  Epoch: 168  Training loss = 4.6887  Validation loss = 0.8797  \n",
      "\n",
      "Fold: 18  Epoch: 169  Training loss = 4.6879  Validation loss = 0.8794  \n",
      "\n",
      "Fold: 18  Epoch: 170  Training loss = 4.6873  Validation loss = 0.8793  \n",
      "\n",
      "Fold: 18  Epoch: 171  Training loss = 4.6866  Validation loss = 0.8791  \n",
      "\n",
      "Fold: 18  Epoch: 172  Training loss = 4.6860  Validation loss = 0.8789  \n",
      "\n",
      "Fold: 18  Epoch: 173  Training loss = 4.6853  Validation loss = 0.8787  \n",
      "\n",
      "Fold: 18  Epoch: 174  Training loss = 4.6846  Validation loss = 0.8786  \n",
      "\n",
      "Fold: 18  Epoch: 175  Training loss = 4.6838  Validation loss = 0.8784  \n",
      "\n",
      "Fold: 18  Epoch: 176  Training loss = 4.6833  Validation loss = 0.8782  \n",
      "\n",
      "Fold: 18  Epoch: 177  Training loss = 4.6826  Validation loss = 0.8780  \n",
      "\n",
      "Fold: 18  Epoch: 178  Training loss = 4.6819  Validation loss = 0.8779  \n",
      "\n",
      "Fold: 18  Epoch: 179  Training loss = 4.6812  Validation loss = 0.8777  \n",
      "\n",
      "Fold: 18  Epoch: 180  Training loss = 4.6806  Validation loss = 0.8775  \n",
      "\n",
      "Fold: 18  Epoch: 181  Training loss = 4.6800  Validation loss = 0.8773  \n",
      "\n",
      "Fold: 18  Epoch: 182  Training loss = 4.6793  Validation loss = 0.8771  \n",
      "\n",
      "Fold: 18  Epoch: 183  Training loss = 4.6787  Validation loss = 0.8770  \n",
      "\n",
      "Fold: 18  Epoch: 184  Training loss = 4.6779  Validation loss = 0.8768  \n",
      "\n",
      "Fold: 18  Epoch: 185  Training loss = 4.6773  Validation loss = 0.8766  \n",
      "\n",
      "Fold: 18  Epoch: 186  Training loss = 4.6766  Validation loss = 0.8765  \n",
      "\n",
      "Fold: 18  Epoch: 187  Training loss = 4.6758  Validation loss = 0.8763  \n",
      "\n",
      "Fold: 18  Epoch: 188  Training loss = 4.6752  Validation loss = 0.8761  \n",
      "\n",
      "Fold: 18  Epoch: 189  Training loss = 4.6746  Validation loss = 0.8760  \n",
      "\n",
      "Fold: 18  Epoch: 190  Training loss = 4.6740  Validation loss = 0.8759  \n",
      "\n",
      "Fold: 18  Epoch: 191  Training loss = 4.6734  Validation loss = 0.8757  \n",
      "\n",
      "Fold: 18  Epoch: 192  Training loss = 4.6727  Validation loss = 0.8756  \n",
      "\n",
      "Fold: 18  Epoch: 193  Training loss = 4.6719  Validation loss = 0.8753  \n",
      "\n",
      "Fold: 18  Epoch: 194  Training loss = 4.6711  Validation loss = 0.8750  \n",
      "\n",
      "Fold: 18  Epoch: 195  Training loss = 4.6705  Validation loss = 0.8749  \n",
      "\n",
      "Fold: 18  Epoch: 196  Training loss = 4.6695  Validation loss = 0.8746  \n",
      "\n",
      "Fold: 18  Epoch: 197  Training loss = 4.6688  Validation loss = 0.8745  \n",
      "\n",
      "Fold: 18  Epoch: 198  Training loss = 4.6673  Validation loss = 0.8741  \n",
      "\n",
      "Fold: 18  Epoch: 199  Training loss = 4.6643  Validation loss = 0.8734  \n",
      "\n",
      "Fold: 18  Epoch: 200  Training loss = 4.6634  Validation loss = 0.8731  \n",
      "\n",
      "Fold: 18  Epoch: 201  Training loss = 4.6626  Validation loss = 0.8728  \n",
      "\n",
      "Fold: 18  Epoch: 202  Training loss = 4.6618  Validation loss = 0.8726  \n",
      "\n",
      "Fold: 18  Epoch: 203  Training loss = 4.6611  Validation loss = 0.8724  \n",
      "\n",
      "Fold: 18  Epoch: 204  Training loss = 4.6604  Validation loss = 0.8723  \n",
      "\n",
      "Fold: 18  Epoch: 205  Training loss = 4.6597  Validation loss = 0.8721  \n",
      "\n",
      "Fold: 18  Epoch: 206  Training loss = 4.6590  Validation loss = 0.8720  \n",
      "\n",
      "Fold: 18  Epoch: 207  Training loss = 4.6584  Validation loss = 0.8718  \n",
      "\n",
      "Fold: 18  Epoch: 208  Training loss = 4.6577  Validation loss = 0.8717  \n",
      "\n",
      "Fold: 18  Epoch: 209  Training loss = 4.6571  Validation loss = 0.8715  \n",
      "\n",
      "Fold: 18  Epoch: 210  Training loss = 4.6564  Validation loss = 0.8714  \n",
      "\n",
      "Fold: 18  Epoch: 211  Training loss = 4.6558  Validation loss = 0.8713  \n",
      "\n",
      "Fold: 18  Epoch: 212  Training loss = 4.6552  Validation loss = 0.8711  \n",
      "\n",
      "Fold: 18  Epoch: 213  Training loss = 4.6546  Validation loss = 0.8710  \n",
      "\n",
      "Fold: 18  Epoch: 214  Training loss = 4.6538  Validation loss = 0.8708  \n",
      "\n",
      "Fold: 18  Epoch: 215  Training loss = 4.6532  Validation loss = 0.8707  \n",
      "\n",
      "Fold: 18  Epoch: 216  Training loss = 4.6524  Validation loss = 0.8706  \n",
      "\n",
      "Fold: 18  Epoch: 217  Training loss = 4.6518  Validation loss = 0.8705  \n",
      "\n",
      "Fold: 18  Epoch: 218  Training loss = 4.6511  Validation loss = 0.8703  \n",
      "\n",
      "Fold: 18  Epoch: 219  Training loss = 4.6505  Validation loss = 0.8702  \n",
      "\n",
      "Fold: 18  Epoch: 220  Training loss = 4.6499  Validation loss = 0.8701  \n",
      "\n",
      "Fold: 18  Epoch: 221  Training loss = 4.6492  Validation loss = 0.8699  \n",
      "\n",
      "Fold: 18  Epoch: 222  Training loss = 4.6487  Validation loss = 0.8698  \n",
      "\n",
      "Fold: 18  Epoch: 223  Training loss = 4.6480  Validation loss = 0.8697  \n",
      "\n",
      "Fold: 18  Epoch: 224  Training loss = 4.6473  Validation loss = 0.8695  \n",
      "\n",
      "Fold: 18  Epoch: 225  Training loss = 4.6467  Validation loss = 0.8694  \n",
      "\n",
      "Fold: 18  Epoch: 226  Training loss = 4.6461  Validation loss = 0.8693  \n",
      "\n",
      "Fold: 18  Epoch: 227  Training loss = 4.6454  Validation loss = 0.8692  \n",
      "\n",
      "Fold: 18  Epoch: 228  Training loss = 4.6449  Validation loss = 0.8692  \n",
      "\n",
      "Fold: 18  Epoch: 229  Training loss = 4.6442  Validation loss = 0.8691  \n",
      "\n",
      "Fold: 18  Epoch: 230  Training loss = 4.6435  Validation loss = 0.8690  \n",
      "\n",
      "Fold: 18  Epoch: 231  Training loss = 4.6430  Validation loss = 0.8689  \n",
      "\n",
      "Fold: 18  Epoch: 232  Training loss = 4.6424  Validation loss = 0.8688  \n",
      "\n",
      "Fold: 18  Epoch: 233  Training loss = 4.6418  Validation loss = 0.8686  \n",
      "\n",
      "Fold: 18  Epoch: 234  Training loss = 4.6410  Validation loss = 0.8685  \n",
      "\n",
      "Fold: 18  Epoch: 235  Training loss = 4.6404  Validation loss = 0.8685  \n",
      "\n",
      "Fold: 18  Epoch: 236  Training loss = 4.6398  Validation loss = 0.8684  \n",
      "\n",
      "Fold: 18  Epoch: 237  Training loss = 4.6392  Validation loss = 0.8682  \n",
      "\n",
      "Fold: 18  Epoch: 238  Training loss = 4.6386  Validation loss = 0.8681  \n",
      "\n",
      "Fold: 18  Epoch: 239  Training loss = 4.6380  Validation loss = 0.8681  \n",
      "\n",
      "Fold: 18  Epoch: 240  Training loss = 4.6372  Validation loss = 0.8680  \n",
      "\n",
      "Fold: 18  Epoch: 241  Training loss = 4.6367  Validation loss = 0.8679  \n",
      "\n",
      "Fold: 18  Epoch: 242  Training loss = 4.6361  Validation loss = 0.8677  \n",
      "\n",
      "Fold: 18  Epoch: 243  Training loss = 4.6354  Validation loss = 0.8676  \n",
      "\n",
      "Fold: 18  Epoch: 244  Training loss = 4.6349  Validation loss = 0.8675  \n",
      "\n",
      "Fold: 18  Epoch: 245  Training loss = 4.6342  Validation loss = 0.8674  \n",
      "\n",
      "Fold: 18  Epoch: 246  Training loss = 4.6337  Validation loss = 0.8672  \n",
      "\n",
      "Fold: 18  Epoch: 247  Training loss = 4.6330  Validation loss = 0.8672  \n",
      "\n",
      "Fold: 18  Epoch: 248  Training loss = 4.6323  Validation loss = 0.8671  \n",
      "\n",
      "Fold: 18  Epoch: 249  Training loss = 4.6316  Validation loss = 0.8670  \n",
      "\n",
      "Fold: 18  Epoch: 250  Training loss = 4.6309  Validation loss = 0.8669  \n",
      "\n",
      "Fold: 18  Epoch: 251  Training loss = 4.6303  Validation loss = 0.8667  \n",
      "\n",
      "Fold: 18  Epoch: 252  Training loss = 4.6297  Validation loss = 0.8666  \n",
      "\n",
      "Fold: 18  Epoch: 253  Training loss = 4.6290  Validation loss = 0.8665  \n",
      "\n",
      "Fold: 18  Epoch: 254  Training loss = 4.6283  Validation loss = 0.8664  \n",
      "\n",
      "Fold: 18  Epoch: 255  Training loss = 4.6278  Validation loss = 0.8664  \n",
      "\n",
      "Fold: 18  Epoch: 256  Training loss = 4.6272  Validation loss = 0.8663  \n",
      "\n",
      "Fold: 18  Epoch: 257  Training loss = 4.6265  Validation loss = 0.8662  \n",
      "\n",
      "Fold: 18  Epoch: 258  Training loss = 4.6259  Validation loss = 0.8661  \n",
      "\n",
      "Fold: 18  Epoch: 259  Training loss = 4.6252  Validation loss = 0.8660  \n",
      "\n",
      "Fold: 18  Epoch: 260  Training loss = 4.6245  Validation loss = 0.8659  \n",
      "\n",
      "Fold: 18  Epoch: 261  Training loss = 4.6239  Validation loss = 0.8658  \n",
      "\n",
      "Fold: 18  Epoch: 262  Training loss = 4.6231  Validation loss = 0.8657  \n",
      "\n",
      "Fold: 18  Epoch: 263  Training loss = 4.6226  Validation loss = 0.8655  \n",
      "\n",
      "Fold: 18  Epoch: 264  Training loss = 4.6221  Validation loss = 0.8655  \n",
      "\n",
      "Fold: 18  Epoch: 265  Training loss = 4.6216  Validation loss = 0.8654  \n",
      "\n",
      "Fold: 18  Epoch: 266  Training loss = 4.6210  Validation loss = 0.8653  \n",
      "\n",
      "Fold: 18  Epoch: 267  Training loss = 4.6204  Validation loss = 0.8652  \n",
      "\n",
      "Fold: 18  Epoch: 268  Training loss = 4.6198  Validation loss = 0.8651  \n",
      "\n",
      "Fold: 18  Epoch: 269  Training loss = 4.6193  Validation loss = 0.8650  \n",
      "\n",
      "Fold: 18  Epoch: 270  Training loss = 4.6188  Validation loss = 0.8649  \n",
      "\n",
      "Fold: 18  Epoch: 271  Training loss = 4.6183  Validation loss = 0.8648  \n",
      "\n",
      "Fold: 18  Epoch: 272  Training loss = 4.6177  Validation loss = 0.8648  \n",
      "\n",
      "Fold: 18  Epoch: 273  Training loss = 4.6172  Validation loss = 0.8647  \n",
      "\n",
      "Fold: 18  Epoch: 274  Training loss = 4.6166  Validation loss = 0.8646  \n",
      "\n",
      "Fold: 18  Epoch: 275  Training loss = 4.6160  Validation loss = 0.8646  \n",
      "\n",
      "Fold: 18  Epoch: 276  Training loss = 4.6154  Validation loss = 0.8646  \n",
      "\n",
      "Fold: 18  Epoch: 277  Training loss = 4.6149  Validation loss = 0.8645  \n",
      "\n",
      "Fold: 18  Epoch: 278  Training loss = 4.6143  Validation loss = 0.8644  \n",
      "\n",
      "Fold: 18  Epoch: 279  Training loss = 4.6136  Validation loss = 0.8643  \n",
      "\n",
      "Fold: 18  Epoch: 280  Training loss = 4.6131  Validation loss = 0.8642  \n",
      "\n",
      "Fold: 18  Epoch: 281  Training loss = 4.6125  Validation loss = 0.8642  \n",
      "\n",
      "Fold: 18  Epoch: 282  Training loss = 4.6119  Validation loss = 0.8641  \n",
      "\n",
      "Fold: 18  Epoch: 283  Training loss = 4.6113  Validation loss = 0.8640  \n",
      "\n",
      "Fold: 18  Epoch: 284  Training loss = 4.6107  Validation loss = 0.8639  \n",
      "\n",
      "Fold: 18  Epoch: 285  Training loss = 4.6101  Validation loss = 0.8638  \n",
      "\n",
      "Fold: 18  Epoch: 286  Training loss = 4.6095  Validation loss = 0.8638  \n",
      "\n",
      "Fold: 18  Epoch: 287  Training loss = 4.6088  Validation loss = 0.8637  \n",
      "\n",
      "Fold: 18  Epoch: 288  Training loss = 4.6080  Validation loss = 0.8636  \n",
      "\n",
      "Fold: 18  Epoch: 289  Training loss = 4.6074  Validation loss = 0.8635  \n",
      "\n",
      "Fold: 18  Epoch: 290  Training loss = 4.6070  Validation loss = 0.8635  \n",
      "\n",
      "Fold: 18  Epoch: 291  Training loss = 4.6065  Validation loss = 0.8635  \n",
      "\n",
      "Fold: 18  Epoch: 292  Training loss = 4.6059  Validation loss = 0.8634  \n",
      "\n",
      "Fold: 18  Epoch: 293  Training loss = 4.6055  Validation loss = 0.8633  \n",
      "\n",
      "Fold: 18  Epoch: 294  Training loss = 4.6048  Validation loss = 0.8633  \n",
      "\n",
      "Fold: 18  Epoch: 295  Training loss = 4.6042  Validation loss = 0.8632  \n",
      "\n",
      "Fold: 18  Epoch: 296  Training loss = 4.6037  Validation loss = 0.8631  \n",
      "\n",
      "Fold: 18  Epoch: 297  Training loss = 4.6032  Validation loss = 0.8631  \n",
      "\n",
      "Fold: 18  Epoch: 298  Training loss = 4.6026  Validation loss = 0.8630  \n",
      "\n",
      "Fold: 18  Epoch: 299  Training loss = 4.6018  Validation loss = 0.8630  \n",
      "\n",
      "Fold: 18  Epoch: 300  Training loss = 4.6012  Validation loss = 0.8629  \n",
      "\n",
      "Fold: 18  Epoch: 301  Training loss = 4.6006  Validation loss = 0.8629  \n",
      "\n",
      "Fold: 18  Epoch: 302  Training loss = 4.5999  Validation loss = 0.8628  \n",
      "\n",
      "Fold: 18  Epoch: 303  Training loss = 4.5992  Validation loss = 0.8628  \n",
      "\n",
      "Fold: 18  Epoch: 304  Training loss = 4.5986  Validation loss = 0.8627  \n",
      "\n",
      "Fold: 18  Epoch: 305  Training loss = 4.5979  Validation loss = 0.8627  \n",
      "\n",
      "Fold: 18  Epoch: 306  Training loss = 4.5974  Validation loss = 0.8627  \n",
      "\n",
      "Fold: 18  Epoch: 307  Training loss = 4.5967  Validation loss = 0.8626  \n",
      "\n",
      "Fold: 18  Epoch: 308  Training loss = 4.5962  Validation loss = 0.8625  \n",
      "\n",
      "Fold: 18  Epoch: 309  Training loss = 4.5956  Validation loss = 0.8625  \n",
      "\n",
      "Fold: 18  Epoch: 310  Training loss = 4.5951  Validation loss = 0.8624  \n",
      "\n",
      "Fold: 18  Epoch: 311  Training loss = 4.5946  Validation loss = 0.8623  \n",
      "\n",
      "Fold: 18  Epoch: 312  Training loss = 4.5938  Validation loss = 0.8623  \n",
      "\n",
      "Fold: 18  Epoch: 313  Training loss = 4.5932  Validation loss = 0.8622  \n",
      "\n",
      "Fold: 18  Epoch: 314  Training loss = 4.5927  Validation loss = 0.8622  \n",
      "\n",
      "Fold: 18  Epoch: 315  Training loss = 4.5919  Validation loss = 0.8621  \n",
      "\n",
      "Fold: 18  Epoch: 316  Training loss = 4.5913  Validation loss = 0.8621  \n",
      "\n",
      "Fold: 18  Epoch: 317  Training loss = 4.5909  Validation loss = 0.8620  \n",
      "\n",
      "Fold: 18  Epoch: 318  Training loss = 4.5903  Validation loss = 0.8620  \n",
      "\n",
      "Fold: 18  Epoch: 319  Training loss = 4.5896  Validation loss = 0.8619  \n",
      "\n",
      "Fold: 18  Epoch: 320  Training loss = 4.5890  Validation loss = 0.8619  \n",
      "\n",
      "Fold: 18  Epoch: 321  Training loss = 4.5883  Validation loss = 0.8618  \n",
      "\n",
      "Fold: 18  Epoch: 322  Training loss = 4.5878  Validation loss = 0.8618  \n",
      "\n",
      "Fold: 18  Epoch: 323  Training loss = 4.5872  Validation loss = 0.8617  \n",
      "\n",
      "Fold: 18  Epoch: 324  Training loss = 4.5865  Validation loss = 0.8617  \n",
      "\n",
      "Fold: 18  Epoch: 325  Training loss = 4.5859  Validation loss = 0.8617  \n",
      "\n",
      "Fold: 18  Epoch: 326  Training loss = 4.5851  Validation loss = 0.8616  \n",
      "\n",
      "Fold: 18  Epoch: 327  Training loss = 4.5845  Validation loss = 0.8615  \n",
      "\n",
      "Fold: 18  Epoch: 328  Training loss = 4.5839  Validation loss = 0.8615  \n",
      "\n",
      "Fold: 18  Epoch: 329  Training loss = 4.5833  Validation loss = 0.8614  \n",
      "\n",
      "Fold: 18  Epoch: 330  Training loss = 4.5826  Validation loss = 0.8614  \n",
      "\n",
      "Fold: 18  Epoch: 331  Training loss = 4.5820  Validation loss = 0.8613  \n",
      "\n",
      "Fold: 18  Epoch: 332  Training loss = 4.5813  Validation loss = 0.8612  \n",
      "\n",
      "Fold: 18  Epoch: 333  Training loss = 4.5806  Validation loss = 0.8612  \n",
      "\n",
      "Fold: 18  Epoch: 334  Training loss = 4.5800  Validation loss = 0.8612  \n",
      "\n",
      "Fold: 18  Epoch: 335  Training loss = 4.5793  Validation loss = 0.8611  \n",
      "\n",
      "Fold: 18  Epoch: 336  Training loss = 4.5788  Validation loss = 0.8611  \n",
      "\n",
      "Fold: 18  Epoch: 337  Training loss = 4.5781  Validation loss = 0.8610  \n",
      "\n",
      "Fold: 18  Epoch: 338  Training loss = 4.5776  Validation loss = 0.8610  \n",
      "\n",
      "Fold: 18  Epoch: 339  Training loss = 4.5771  Validation loss = 0.8610  \n",
      "\n",
      "Fold: 18  Epoch: 340  Training loss = 4.5765  Validation loss = 0.8609  \n",
      "\n",
      "Fold: 18  Epoch: 341  Training loss = 4.5758  Validation loss = 0.8609  \n",
      "\n",
      "Fold: 18  Epoch: 342  Training loss = 4.5753  Validation loss = 0.8609  \n",
      "\n",
      "Fold: 18  Epoch: 343  Training loss = 4.5745  Validation loss = 0.8608  \n",
      "\n",
      "Fold: 18  Epoch: 344  Training loss = 4.5740  Validation loss = 0.8607  \n",
      "\n",
      "Fold: 18  Epoch: 345  Training loss = 4.5734  Validation loss = 0.8607  \n",
      "\n",
      "Fold: 18  Epoch: 346  Training loss = 4.5729  Validation loss = 0.8607  \n",
      "\n",
      "Fold: 18  Epoch: 347  Training loss = 4.5722  Validation loss = 0.8607  \n",
      "\n",
      "Fold: 18  Epoch: 348  Training loss = 4.5717  Validation loss = 0.8607  \n",
      "\n",
      "Fold: 18  Epoch: 349  Training loss = 4.5711  Validation loss = 0.8607  \n",
      "\n",
      "Fold: 18  Epoch: 350  Training loss = 4.5703  Validation loss = 0.8606  \n",
      "\n",
      "Fold: 18  Epoch: 351  Training loss = 4.5696  Validation loss = 0.8606  \n",
      "\n",
      "Fold: 18  Epoch: 352  Training loss = 4.5691  Validation loss = 0.8605  \n",
      "\n",
      "Fold: 18  Epoch: 353  Training loss = 4.5686  Validation loss = 0.8605  \n",
      "\n",
      "Fold: 18  Epoch: 354  Training loss = 4.5681  Validation loss = 0.8605  \n",
      "\n",
      "Fold: 18  Epoch: 355  Training loss = 4.5674  Validation loss = 0.8605  \n",
      "\n",
      "Fold: 18  Epoch: 356  Training loss = 4.5668  Validation loss = 0.8605  \n",
      "\n",
      "Fold: 18  Epoch: 357  Training loss = 4.5662  Validation loss = 0.8605  \n",
      "\n",
      "Fold: 18  Epoch: 358  Training loss = 4.5656  Validation loss = 0.8604  \n",
      "\n",
      "Fold: 18  Epoch: 359  Training loss = 4.5652  Validation loss = 0.8604  \n",
      "\n",
      "Fold: 18  Epoch: 360  Training loss = 4.5647  Validation loss = 0.8604  \n",
      "\n",
      "Fold: 18  Epoch: 361  Training loss = 4.5641  Validation loss = 0.8603  \n",
      "\n",
      "Fold: 18  Epoch: 362  Training loss = 4.5635  Validation loss = 0.8603  \n",
      "\n",
      "Fold: 18  Epoch: 363  Training loss = 4.5628  Validation loss = 0.8603  \n",
      "\n",
      "Fold: 18  Epoch: 364  Training loss = 4.5622  Validation loss = 0.8602  \n",
      "\n",
      "Fold: 18  Epoch: 365  Training loss = 4.5614  Validation loss = 0.8602  \n",
      "\n",
      "Fold: 18  Epoch: 366  Training loss = 4.5608  Validation loss = 0.8601  \n",
      "\n",
      "Fold: 18  Epoch: 367  Training loss = 4.5603  Validation loss = 0.8601  \n",
      "\n",
      "Fold: 18  Epoch: 368  Training loss = 4.5597  Validation loss = 0.8601  \n",
      "\n",
      "Fold: 18  Epoch: 369  Training loss = 4.5590  Validation loss = 0.8601  \n",
      "\n",
      "Fold: 18  Epoch: 370  Training loss = 4.5584  Validation loss = 0.8601  \n",
      "\n",
      "Fold: 18  Epoch: 371  Training loss = 4.5578  Validation loss = 0.8601  \n",
      "\n",
      "Fold: 18  Epoch: 372  Training loss = 4.5572  Validation loss = 0.8601  \n",
      "\n",
      "Fold: 18  Epoch: 373  Training loss = 4.5567  Validation loss = 0.8600  \n",
      "\n",
      "Fold: 18  Epoch: 374  Training loss = 4.5561  Validation loss = 0.8600  \n",
      "\n",
      "Fold: 18  Epoch: 375  Training loss = 4.5554  Validation loss = 0.8600  \n",
      "\n",
      "Fold: 18  Epoch: 376  Training loss = 4.5549  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 18  Epoch: 377  Training loss = 4.5544  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 18  Epoch: 378  Training loss = 4.5538  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 18  Epoch: 379  Training loss = 4.5533  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 18  Epoch: 380  Training loss = 4.5527  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 18  Epoch: 381  Training loss = 4.5520  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 18  Epoch: 382  Training loss = 4.5515  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 18  Epoch: 383  Training loss = 4.5508  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 18  Epoch: 384  Training loss = 4.5503  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 18  Epoch: 385  Training loss = 4.5497  Validation loss = 0.8598  \n",
      "\n",
      "Fold: 18  Epoch: 386  Training loss = 4.5493  Validation loss = 0.8598  \n",
      "\n",
      "Fold: 18  Epoch: 387  Training loss = 4.5485  Validation loss = 0.8598  \n",
      "\n",
      "Fold: 18  Epoch: 388  Training loss = 4.5479  Validation loss = 0.8597  \n",
      "\n",
      "Fold: 18  Epoch: 389  Training loss = 4.5472  Validation loss = 0.8598  \n",
      "\n",
      "Fold: 18  Epoch: 390  Training loss = 4.5465  Validation loss = 0.8597  \n",
      "\n",
      "Fold: 18  Epoch: 391  Training loss = 4.5460  Validation loss = 0.8597  \n",
      "\n",
      "Fold: 18  Epoch: 392  Training loss = 4.5454  Validation loss = 0.8598  \n",
      "\n",
      "Fold: 18  Epoch: 393  Training loss = 4.5448  Validation loss = 0.8598  \n",
      "\n",
      "Fold: 18  Epoch: 394  Training loss = 4.5442  Validation loss = 0.8599  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 391  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 4.5343  Validation loss = 2.0090  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 4.5337  Validation loss = 2.0090  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 4.5330  Validation loss = 2.0089  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 4.5324  Validation loss = 2.0087  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 4.5317  Validation loss = 2.0086  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 4.5311  Validation loss = 2.0086  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 4.5305  Validation loss = 2.0085  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 4.5299  Validation loss = 2.0085  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 4.5292  Validation loss = 2.0084  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 4.5286  Validation loss = 2.0084  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 4.5280  Validation loss = 2.0081  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 4.5273  Validation loss = 2.0082  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 4.5268  Validation loss = 2.0082  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 4.5263  Validation loss = 2.0082  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 4.5256  Validation loss = 2.0081  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 4.5252  Validation loss = 2.0080  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 4.5246  Validation loss = 2.0079  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 4.5240  Validation loss = 2.0078  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 4.5234  Validation loss = 2.0076  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 4.5230  Validation loss = 2.0075  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 4.5225  Validation loss = 2.0076  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 4.5218  Validation loss = 2.0075  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 4.5212  Validation loss = 2.0074  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 4.5205  Validation loss = 2.0072  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 4.5199  Validation loss = 2.0071  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 4.5193  Validation loss = 2.0071  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 4.5188  Validation loss = 2.0070  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 4.5183  Validation loss = 2.0069  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 4.5176  Validation loss = 2.0069  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 4.5171  Validation loss = 2.0068  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 4.5164  Validation loss = 2.0068  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 4.5158  Validation loss = 2.0068  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 4.5152  Validation loss = 2.0067  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 4.5146  Validation loss = 2.0067  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 4.5141  Validation loss = 2.0067  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 4.5136  Validation loss = 2.0066  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 4.5130  Validation loss = 2.0065  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 4.5125  Validation loss = 2.0064  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 4.5119  Validation loss = 2.0064  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 4.5112  Validation loss = 2.0065  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 4.5107  Validation loss = 2.0063  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 4.5100  Validation loss = 2.0062  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 4.5094  Validation loss = 2.0060  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 4.5089  Validation loss = 2.0058  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 4.5082  Validation loss = 2.0058  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 4.5076  Validation loss = 2.0058  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 4.5069  Validation loss = 2.0058  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 4.5063  Validation loss = 2.0058  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 4.5056  Validation loss = 2.0057  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 4.5050  Validation loss = 2.0056  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 4.5044  Validation loss = 2.0056  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 4.5038  Validation loss = 2.0054  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 4.5033  Validation loss = 2.0054  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 4.5027  Validation loss = 2.0053  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 4.5021  Validation loss = 2.0053  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 4.5016  Validation loss = 2.0053  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 4.5011  Validation loss = 2.0053  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 4.5005  Validation loss = 2.0052  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 4.5000  Validation loss = 2.0051  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 4.4992  Validation loss = 2.0051  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 4.4987  Validation loss = 2.0051  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 4.4981  Validation loss = 2.0050  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 4.4976  Validation loss = 2.0050  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 4.4970  Validation loss = 2.0049  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 4.4963  Validation loss = 2.0049  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 4.4957  Validation loss = 2.0049  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 4.4949  Validation loss = 2.0047  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 4.4943  Validation loss = 2.0046  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 4.4936  Validation loss = 2.0045  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 4.4930  Validation loss = 2.0044  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 4.4924  Validation loss = 2.0044  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 4.4919  Validation loss = 2.0044  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 4.4911  Validation loss = 2.0043  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 4.4905  Validation loss = 2.0042  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 4.4901  Validation loss = 2.0042  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 4.4894  Validation loss = 2.0041  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 4.4888  Validation loss = 2.0041  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 4.4883  Validation loss = 2.0040  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 4.4878  Validation loss = 2.0040  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 4.4872  Validation loss = 2.0040  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 4.4866  Validation loss = 2.0040  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 4.4861  Validation loss = 2.0040  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 4.4855  Validation loss = 2.0039  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 4.4850  Validation loss = 2.0039  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 4.4845  Validation loss = 2.0037  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 4.4839  Validation loss = 2.0037  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 4.4834  Validation loss = 2.0036  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 4.4828  Validation loss = 2.0037  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 4.4824  Validation loss = 2.0037  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 4.4818  Validation loss = 2.0037  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 4.4813  Validation loss = 2.0037  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 4.4805  Validation loss = 2.0038  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 4.4798  Validation loss = 2.0037  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 4.4793  Validation loss = 2.0036  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 4.4786  Validation loss = 2.0035  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 4.4780  Validation loss = 2.0036  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 4.4775  Validation loss = 2.0036  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 4.4769  Validation loss = 2.0036  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 4.4764  Validation loss = 2.0035  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 4.4758  Validation loss = 2.0034  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 4.4752  Validation loss = 2.0033  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 4.4745  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 4.4739  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 4.4733  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 4.4727  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 4.4721  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 4.4715  Validation loss = 2.0033  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 4.4709  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 4.4703  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 4.4698  Validation loss = 2.0031  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 4.4692  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 4.4688  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 4.4682  Validation loss = 2.0031  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 4.4676  Validation loss = 2.0031  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 4.4670  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 4.4664  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 4.4658  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 4.4653  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 4.4649  Validation loss = 2.0031  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 4.4644  Validation loss = 2.0031  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 4.4638  Validation loss = 2.0029  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 4.4633  Validation loss = 2.0029  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 4.4626  Validation loss = 2.0028  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 4.4620  Validation loss = 2.0028  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 4.4614  Validation loss = 2.0027  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 4.4609  Validation loss = 2.0027  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 4.4604  Validation loss = 2.0027  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 4.4598  Validation loss = 2.0027  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 4.4591  Validation loss = 2.0027  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 4.4585  Validation loss = 2.0027  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 4.4578  Validation loss = 2.0027  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 4.4574  Validation loss = 2.0027  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 4.4568  Validation loss = 2.0026  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 4.4562  Validation loss = 2.0025  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 4.4556  Validation loss = 2.0025  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 4.4551  Validation loss = 2.0025  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 4.4546  Validation loss = 2.0024  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 4.4540  Validation loss = 2.0023  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 4.4533  Validation loss = 2.0023  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 4.4528  Validation loss = 2.0023  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 4.4522  Validation loss = 2.0022  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 4.4516  Validation loss = 2.0020  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 4.4510  Validation loss = 2.0020  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 4.4503  Validation loss = 2.0020  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 4.4498  Validation loss = 2.0019  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 4.4494  Validation loss = 2.0019  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 4.4487  Validation loss = 2.0019  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 4.4482  Validation loss = 2.0018  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 4.4475  Validation loss = 2.0017  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 4.4470  Validation loss = 2.0016  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 4.4464  Validation loss = 2.0015  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 4.4459  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 4.4453  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 4.4447  Validation loss = 2.0015  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 4.4442  Validation loss = 2.0015  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 4.4436  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 4.4431  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 19  Epoch: 158  Training loss = 4.4427  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 19  Epoch: 159  Training loss = 4.4420  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 19  Epoch: 160  Training loss = 4.4415  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 19  Epoch: 161  Training loss = 4.4409  Validation loss = 2.0013  \n",
      "\n",
      "Fold: 19  Epoch: 162  Training loss = 4.4404  Validation loss = 2.0013  \n",
      "\n",
      "Fold: 19  Epoch: 163  Training loss = 4.4397  Validation loss = 2.0013  \n",
      "\n",
      "Fold: 19  Epoch: 164  Training loss = 4.4391  Validation loss = 2.0012  \n",
      "\n",
      "Fold: 19  Epoch: 165  Training loss = 4.4386  Validation loss = 2.0012  \n",
      "\n",
      "Fold: 19  Epoch: 166  Training loss = 4.4381  Validation loss = 2.0012  \n",
      "\n",
      "Fold: 19  Epoch: 167  Training loss = 4.4376  Validation loss = 2.0012  \n",
      "\n",
      "Fold: 19  Epoch: 168  Training loss = 4.4371  Validation loss = 2.0011  \n",
      "\n",
      "Fold: 19  Epoch: 169  Training loss = 4.4365  Validation loss = 2.0011  \n",
      "\n",
      "Fold: 19  Epoch: 170  Training loss = 4.4360  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 19  Epoch: 171  Training loss = 4.4354  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 19  Epoch: 172  Training loss = 4.4347  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 19  Epoch: 173  Training loss = 4.4340  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 19  Epoch: 174  Training loss = 4.4333  Validation loss = 2.0008  \n",
      "\n",
      "Fold: 19  Epoch: 175  Training loss = 4.4328  Validation loss = 2.0007  \n",
      "\n",
      "Fold: 19  Epoch: 176  Training loss = 4.4322  Validation loss = 2.0007  \n",
      "\n",
      "Fold: 19  Epoch: 177  Training loss = 4.4318  Validation loss = 2.0006  \n",
      "\n",
      "Fold: 19  Epoch: 178  Training loss = 4.4312  Validation loss = 2.0006  \n",
      "\n",
      "Fold: 19  Epoch: 179  Training loss = 4.4307  Validation loss = 2.0006  \n",
      "\n",
      "Fold: 19  Epoch: 180  Training loss = 4.4300  Validation loss = 2.0006  \n",
      "\n",
      "Fold: 19  Epoch: 181  Training loss = 4.4294  Validation loss = 2.0005  \n",
      "\n",
      "Fold: 19  Epoch: 182  Training loss = 4.4290  Validation loss = 2.0005  \n",
      "\n",
      "Fold: 19  Epoch: 183  Training loss = 4.4284  Validation loss = 2.0005  \n",
      "\n",
      "Fold: 19  Epoch: 184  Training loss = 4.4279  Validation loss = 2.0005  \n",
      "\n",
      "Fold: 19  Epoch: 185  Training loss = 4.4274  Validation loss = 2.0005  \n",
      "\n",
      "Fold: 19  Epoch: 186  Training loss = 4.4266  Validation loss = 2.0005  \n",
      "\n",
      "Fold: 19  Epoch: 187  Training loss = 4.4260  Validation loss = 2.0005  \n",
      "\n",
      "Fold: 19  Epoch: 188  Training loss = 4.4252  Validation loss = 2.0004  \n",
      "\n",
      "Fold: 19  Epoch: 189  Training loss = 4.4246  Validation loss = 2.0002  \n",
      "\n",
      "Fold: 19  Epoch: 190  Training loss = 4.4240  Validation loss = 2.0003  \n",
      "\n",
      "Fold: 19  Epoch: 191  Training loss = 4.4235  Validation loss = 2.0003  \n",
      "\n",
      "Fold: 19  Epoch: 192  Training loss = 4.4230  Validation loss = 2.0003  \n",
      "\n",
      "Fold: 19  Epoch: 193  Training loss = 4.4225  Validation loss = 2.0003  \n",
      "\n",
      "Fold: 19  Epoch: 194  Training loss = 4.4219  Validation loss = 2.0004  \n",
      "\n",
      "Fold: 19  Epoch: 195  Training loss = 4.4212  Validation loss = 2.0005  \n",
      "\n",
      "Fold: 19  Epoch: 196  Training loss = 4.4206  Validation loss = 2.0006  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 189  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 4.4396  Validation loss = 0.7446  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 4.4391  Validation loss = 0.7444  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 4.4385  Validation loss = 0.7443  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 4.4379  Validation loss = 0.7442  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 4.4372  Validation loss = 0.7441  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 4.4366  Validation loss = 0.7441  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 4.4359  Validation loss = 0.7440  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 4.4354  Validation loss = 0.7439  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 4.4346  Validation loss = 0.7439  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 4.4340  Validation loss = 0.7438  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 4.4334  Validation loss = 0.7437  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 4.4328  Validation loss = 0.7437  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 4.4323  Validation loss = 0.7437  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 4.4317  Validation loss = 0.7435  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 4.4311  Validation loss = 0.7434  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 4.4307  Validation loss = 0.7432  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 4.4301  Validation loss = 0.7431  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 4.4296  Validation loss = 0.7431  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 4.4290  Validation loss = 0.7430  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 4.4283  Validation loss = 0.7430  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 4.4278  Validation loss = 0.7429  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 4.4273  Validation loss = 0.7429  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 4.4267  Validation loss = 0.7427  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 4.4263  Validation loss = 0.7427  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 4.4258  Validation loss = 0.7426  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 4.4252  Validation loss = 0.7426  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 4.4246  Validation loss = 0.7425  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 4.4242  Validation loss = 0.7425  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 4.4236  Validation loss = 0.7422  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 4.4231  Validation loss = 0.7421  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 4.4226  Validation loss = 0.7420  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 4.4221  Validation loss = 0.7420  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 4.4216  Validation loss = 0.7419  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 4.4211  Validation loss = 0.7418  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 4.4204  Validation loss = 0.7418  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 4.4197  Validation loss = 0.7417  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 4.4193  Validation loss = 0.7416  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 4.4187  Validation loss = 0.7415  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 4.4182  Validation loss = 0.7414  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 4.4178  Validation loss = 0.7413  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 4.4172  Validation loss = 0.7411  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 4.4166  Validation loss = 0.7410  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 4.4161  Validation loss = 0.7410  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 4.4155  Validation loss = 0.7408  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 4.4152  Validation loss = 0.7408  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 4.4146  Validation loss = 0.7407  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 4.4142  Validation loss = 0.7406  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 4.4136  Validation loss = 0.7405  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 4.4130  Validation loss = 0.7404  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 4.4125  Validation loss = 0.7403  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 4.4120  Validation loss = 0.7403  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 4.4114  Validation loss = 0.7403  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 4.4107  Validation loss = 0.7402  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 4.4101  Validation loss = 0.7401  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 4.4095  Validation loss = 0.7401  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 4.4089  Validation loss = 0.7399  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 4.4083  Validation loss = 0.7399  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 4.4077  Validation loss = 0.7398  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 4.4072  Validation loss = 0.7398  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 4.4067  Validation loss = 0.7397  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 4.4061  Validation loss = 0.7396  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 4.4057  Validation loss = 0.7395  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 4.4051  Validation loss = 0.7395  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 4.4046  Validation loss = 0.7395  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 4.4041  Validation loss = 0.7394  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 4.4037  Validation loss = 0.7394  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 4.4032  Validation loss = 0.7394  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 4.4026  Validation loss = 0.7393  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 4.4020  Validation loss = 0.7393  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 4.4013  Validation loss = 0.7392  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 4.4009  Validation loss = 0.7392  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 4.4003  Validation loss = 0.7390  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 4.3996  Validation loss = 0.7391  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 4.3990  Validation loss = 0.7389  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 4.3985  Validation loss = 0.7389  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 4.3980  Validation loss = 0.7388  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 4.3975  Validation loss = 0.7387  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 4.3970  Validation loss = 0.7387  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 4.3965  Validation loss = 0.7386  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 4.3959  Validation loss = 0.7384  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 4.3954  Validation loss = 0.7383  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 4.3948  Validation loss = 0.7383  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 4.3943  Validation loss = 0.7383  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 4.3938  Validation loss = 0.7382  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 4.3932  Validation loss = 0.7382  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 4.3927  Validation loss = 0.7381  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 4.3921  Validation loss = 0.7380  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 4.3915  Validation loss = 0.7380  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 4.3910  Validation loss = 0.7381  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 4.3905  Validation loss = 0.7381  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 4.3899  Validation loss = 0.7380  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 4.3893  Validation loss = 0.7381  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 4.3888  Validation loss = 0.7379  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 4.3883  Validation loss = 0.7379  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 4.3877  Validation loss = 0.7380  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 4.3871  Validation loss = 0.7380  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 4.3865  Validation loss = 0.7380  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 4.3858  Validation loss = 0.7379  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 4.3852  Validation loss = 0.7379  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 4.3845  Validation loss = 0.7379  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 4.3840  Validation loss = 0.7379  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 4.3835  Validation loss = 0.7379  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 4.3830  Validation loss = 0.7379  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 4.3824  Validation loss = 0.7379  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 4.3817  Validation loss = 0.7378  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 4.3813  Validation loss = 0.7377  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 4.3807  Validation loss = 0.7377  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 4.3801  Validation loss = 0.7376  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 4.3796  Validation loss = 0.7376  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 4.3789  Validation loss = 0.7376  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 4.3784  Validation loss = 0.7376  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 4.3778  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 4.3773  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 4.3768  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 4.3763  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 4.3757  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 4.3753  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 4.3747  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 4.3743  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 4.3737  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 4.3733  Validation loss = 0.7374  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 4.3728  Validation loss = 0.7374  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 4.3723  Validation loss = 0.7374  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 4.3719  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 4.3714  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 4.3709  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 4.3704  Validation loss = 0.7375  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 4.3699  Validation loss = 0.7375  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 122  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 4.3502  Validation loss = 3.4092  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 4.3498  Validation loss = 3.4096  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 4.3495  Validation loss = 3.4100  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 4.3490  Validation loss = 3.4106  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 4.3485  Validation loss = 3.4112  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 4.3481  Validation loss = 3.4117  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 4.3477  Validation loss = 3.4121  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 4.3471  Validation loss = 3.4127  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 4.3465  Validation loss = 3.4134  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 4.3462  Validation loss = 3.4138  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 4.3457  Validation loss = 3.4144  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 4.4033  Validation loss = 2.2315  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 4.4029  Validation loss = 2.2315  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 4.4024  Validation loss = 2.2314  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 4.4019  Validation loss = 2.2314  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 4.4016  Validation loss = 2.2312  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 4.4013  Validation loss = 2.2310  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 4.4009  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 4.4005  Validation loss = 2.2307  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 4.4001  Validation loss = 2.2304  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 4.3997  Validation loss = 2.2305  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 4.3994  Validation loss = 2.2303  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 4.3990  Validation loss = 2.2301  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 4.3985  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 4.3981  Validation loss = 2.2296  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 4.3976  Validation loss = 2.2293  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 4.3971  Validation loss = 2.2291  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 4.3968  Validation loss = 2.2292  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 4.3965  Validation loss = 2.2290  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 4.3960  Validation loss = 2.2287  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 4.3954  Validation loss = 2.2285  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 4.3950  Validation loss = 2.2285  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 4.3946  Validation loss = 2.2283  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 4.3940  Validation loss = 2.2281  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 4.3935  Validation loss = 2.2280  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 4.3932  Validation loss = 2.2279  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 4.3928  Validation loss = 2.2277  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 4.3925  Validation loss = 2.2276  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 4.3921  Validation loss = 2.2275  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 4.3917  Validation loss = 2.2274  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 4.3914  Validation loss = 2.2274  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 4.3911  Validation loss = 2.2273  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 4.3906  Validation loss = 2.2274  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 4.3901  Validation loss = 2.2274  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 4.3896  Validation loss = 2.2272  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 4.3892  Validation loss = 2.2270  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 4.3888  Validation loss = 2.2271  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 4.3883  Validation loss = 2.2268  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 4.3878  Validation loss = 2.2266  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 4.3874  Validation loss = 2.2267  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 4.3870  Validation loss = 2.2266  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 4.3866  Validation loss = 2.2265  \n",
      "\n",
      "Fold: 22  Epoch: 42  Training loss = 4.3862  Validation loss = 2.2263  \n",
      "\n",
      "Fold: 22  Epoch: 43  Training loss = 4.3858  Validation loss = 2.2262  \n",
      "\n",
      "Fold: 22  Epoch: 44  Training loss = 4.3855  Validation loss = 2.2261  \n",
      "\n",
      "Fold: 22  Epoch: 45  Training loss = 4.3851  Validation loss = 2.2259  \n",
      "\n",
      "Fold: 22  Epoch: 46  Training loss = 4.3847  Validation loss = 2.2256  \n",
      "\n",
      "Fold: 22  Epoch: 47  Training loss = 4.3843  Validation loss = 2.2252  \n",
      "\n",
      "Fold: 22  Epoch: 48  Training loss = 4.3840  Validation loss = 2.2253  \n",
      "\n",
      "Fold: 22  Epoch: 49  Training loss = 4.3836  Validation loss = 2.2252  \n",
      "\n",
      "Fold: 22  Epoch: 50  Training loss = 4.3831  Validation loss = 2.2251  \n",
      "\n",
      "Fold: 22  Epoch: 51  Training loss = 4.3827  Validation loss = 2.2251  \n",
      "\n",
      "Fold: 22  Epoch: 52  Training loss = 4.3824  Validation loss = 2.2250  \n",
      "\n",
      "Fold: 22  Epoch: 53  Training loss = 4.3819  Validation loss = 2.2250  \n",
      "\n",
      "Fold: 22  Epoch: 54  Training loss = 4.3814  Validation loss = 2.2250  \n",
      "\n",
      "Fold: 22  Epoch: 55  Training loss = 4.3811  Validation loss = 2.2248  \n",
      "\n",
      "Fold: 22  Epoch: 56  Training loss = 4.3805  Validation loss = 2.2246  \n",
      "\n",
      "Fold: 22  Epoch: 57  Training loss = 4.3799  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 22  Epoch: 58  Training loss = 4.3793  Validation loss = 2.2246  \n",
      "\n",
      "Fold: 22  Epoch: 59  Training loss = 4.3787  Validation loss = 2.2245  \n",
      "\n",
      "Fold: 22  Epoch: 60  Training loss = 4.3782  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 22  Epoch: 61  Training loss = 4.3777  Validation loss = 2.2245  \n",
      "\n",
      "Fold: 22  Epoch: 62  Training loss = 4.3772  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 22  Epoch: 63  Training loss = 4.3768  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 22  Epoch: 64  Training loss = 4.3762  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 22  Epoch: 65  Training loss = 4.3758  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 22  Epoch: 66  Training loss = 4.3753  Validation loss = 2.2242  \n",
      "\n",
      "Fold: 22  Epoch: 67  Training loss = 4.3749  Validation loss = 2.2243  \n",
      "\n",
      "Fold: 22  Epoch: 68  Training loss = 4.3745  Validation loss = 2.2243  \n",
      "\n",
      "Fold: 22  Epoch: 69  Training loss = 4.3740  Validation loss = 2.2241  \n",
      "\n",
      "Fold: 22  Epoch: 70  Training loss = 4.3736  Validation loss = 2.2241  \n",
      "\n",
      "Fold: 22  Epoch: 71  Training loss = 4.3732  Validation loss = 2.2240  \n",
      "\n",
      "Fold: 22  Epoch: 72  Training loss = 4.3729  Validation loss = 2.2240  \n",
      "\n",
      "Fold: 22  Epoch: 73  Training loss = 4.3725  Validation loss = 2.2236  \n",
      "\n",
      "Fold: 22  Epoch: 74  Training loss = 4.3720  Validation loss = 2.2235  \n",
      "\n",
      "Fold: 22  Epoch: 75  Training loss = 4.3717  Validation loss = 2.2234  \n",
      "\n",
      "Fold: 22  Epoch: 76  Training loss = 4.3713  Validation loss = 2.2232  \n",
      "\n",
      "Fold: 22  Epoch: 77  Training loss = 4.3708  Validation loss = 2.2231  \n",
      "\n",
      "Fold: 22  Epoch: 78  Training loss = 4.3705  Validation loss = 2.2230  \n",
      "\n",
      "Fold: 22  Epoch: 79  Training loss = 4.3701  Validation loss = 2.2230  \n",
      "\n",
      "Fold: 22  Epoch: 80  Training loss = 4.3696  Validation loss = 2.2229  \n",
      "\n",
      "Fold: 22  Epoch: 81  Training loss = 4.3691  Validation loss = 2.2228  \n",
      "\n",
      "Fold: 22  Epoch: 82  Training loss = 4.3688  Validation loss = 2.2228  \n",
      "\n",
      "Fold: 22  Epoch: 83  Training loss = 4.3684  Validation loss = 2.2227  \n",
      "\n",
      "Fold: 22  Epoch: 84  Training loss = 4.3679  Validation loss = 2.2225  \n",
      "\n",
      "Fold: 22  Epoch: 85  Training loss = 4.3674  Validation loss = 2.2223  \n",
      "\n",
      "Fold: 22  Epoch: 86  Training loss = 4.3671  Validation loss = 2.2221  \n",
      "\n",
      "Fold: 22  Epoch: 87  Training loss = 4.3667  Validation loss = 2.2220  \n",
      "\n",
      "Fold: 22  Epoch: 88  Training loss = 4.3662  Validation loss = 2.2221  \n",
      "\n",
      "Fold: 22  Epoch: 89  Training loss = 4.3658  Validation loss = 2.2221  \n",
      "\n",
      "Fold: 22  Epoch: 90  Training loss = 4.3654  Validation loss = 2.2220  \n",
      "\n",
      "Fold: 22  Epoch: 91  Training loss = 4.3649  Validation loss = 2.2218  \n",
      "\n",
      "Fold: 22  Epoch: 92  Training loss = 4.3644  Validation loss = 2.2218  \n",
      "\n",
      "Fold: 22  Epoch: 93  Training loss = 4.3640  Validation loss = 2.2217  \n",
      "\n",
      "Fold: 22  Epoch: 94  Training loss = 4.3636  Validation loss = 2.2214  \n",
      "\n",
      "Fold: 22  Epoch: 95  Training loss = 4.3632  Validation loss = 2.2212  \n",
      "\n",
      "Fold: 22  Epoch: 96  Training loss = 4.3627  Validation loss = 2.2212  \n",
      "\n",
      "Fold: 22  Epoch: 97  Training loss = 4.3624  Validation loss = 2.2211  \n",
      "\n",
      "Fold: 22  Epoch: 98  Training loss = 4.3620  Validation loss = 2.2209  \n",
      "\n",
      "Fold: 22  Epoch: 99  Training loss = 4.3618  Validation loss = 2.2208  \n",
      "\n",
      "Fold: 22  Epoch: 100  Training loss = 4.3614  Validation loss = 2.2208  \n",
      "\n",
      "Fold: 22  Epoch: 101  Training loss = 4.3610  Validation loss = 2.2206  \n",
      "\n",
      "Fold: 22  Epoch: 102  Training loss = 4.3606  Validation loss = 2.2204  \n",
      "\n",
      "Fold: 22  Epoch: 103  Training loss = 4.3602  Validation loss = 2.2204  \n",
      "\n",
      "Fold: 22  Epoch: 104  Training loss = 4.3598  Validation loss = 2.2201  \n",
      "\n",
      "Fold: 22  Epoch: 105  Training loss = 4.3593  Validation loss = 2.2199  \n",
      "\n",
      "Fold: 22  Epoch: 106  Training loss = 4.3587  Validation loss = 2.2195  \n",
      "\n",
      "Fold: 22  Epoch: 107  Training loss = 4.3584  Validation loss = 2.2194  \n",
      "\n",
      "Fold: 22  Epoch: 108  Training loss = 4.3580  Validation loss = 2.2193  \n",
      "\n",
      "Fold: 22  Epoch: 109  Training loss = 4.3576  Validation loss = 2.2192  \n",
      "\n",
      "Fold: 22  Epoch: 110  Training loss = 4.3572  Validation loss = 2.2190  \n",
      "\n",
      "Fold: 22  Epoch: 111  Training loss = 4.3567  Validation loss = 2.2189  \n",
      "\n",
      "Fold: 22  Epoch: 112  Training loss = 4.3563  Validation loss = 2.2189  \n",
      "\n",
      "Fold: 22  Epoch: 113  Training loss = 4.3559  Validation loss = 2.2188  \n",
      "\n",
      "Fold: 22  Epoch: 114  Training loss = 4.3556  Validation loss = 2.2188  \n",
      "\n",
      "Fold: 22  Epoch: 115  Training loss = 4.3553  Validation loss = 2.2188  \n",
      "\n",
      "Fold: 22  Epoch: 116  Training loss = 4.3550  Validation loss = 2.2188  \n",
      "\n",
      "Fold: 22  Epoch: 117  Training loss = 4.3546  Validation loss = 2.2187  \n",
      "\n",
      "Fold: 22  Epoch: 118  Training loss = 4.3541  Validation loss = 2.2186  \n",
      "\n",
      "Fold: 22  Epoch: 119  Training loss = 4.3537  Validation loss = 2.2185  \n",
      "\n",
      "Fold: 22  Epoch: 120  Training loss = 4.3533  Validation loss = 2.2185  \n",
      "\n",
      "Fold: 22  Epoch: 121  Training loss = 4.3528  Validation loss = 2.2185  \n",
      "\n",
      "Fold: 22  Epoch: 122  Training loss = 4.3525  Validation loss = 2.2184  \n",
      "\n",
      "Fold: 22  Epoch: 123  Training loss = 4.3521  Validation loss = 2.2184  \n",
      "\n",
      "Fold: 22  Epoch: 124  Training loss = 4.3516  Validation loss = 2.2183  \n",
      "\n",
      "Fold: 22  Epoch: 125  Training loss = 4.3512  Validation loss = 2.2182  \n",
      "\n",
      "Fold: 22  Epoch: 126  Training loss = 4.3507  Validation loss = 2.2182  \n",
      "\n",
      "Fold: 22  Epoch: 127  Training loss = 4.3503  Validation loss = 2.2181  \n",
      "\n",
      "Fold: 22  Epoch: 128  Training loss = 4.3498  Validation loss = 2.2179  \n",
      "\n",
      "Fold: 22  Epoch: 129  Training loss = 4.3494  Validation loss = 2.2177  \n",
      "\n",
      "Fold: 22  Epoch: 130  Training loss = 4.3490  Validation loss = 2.2177  \n",
      "\n",
      "Fold: 22  Epoch: 131  Training loss = 4.3485  Validation loss = 2.2174  \n",
      "\n",
      "Fold: 22  Epoch: 132  Training loss = 4.3481  Validation loss = 2.2174  \n",
      "\n",
      "Fold: 22  Epoch: 133  Training loss = 4.3476  Validation loss = 2.2173  \n",
      "\n",
      "Fold: 22  Epoch: 134  Training loss = 4.3472  Validation loss = 2.2170  \n",
      "\n",
      "Fold: 22  Epoch: 135  Training loss = 4.3469  Validation loss = 2.2169  \n",
      "\n",
      "Fold: 22  Epoch: 136  Training loss = 4.3464  Validation loss = 2.2167  \n",
      "\n",
      "Fold: 22  Epoch: 137  Training loss = 4.3461  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 22  Epoch: 138  Training loss = 4.3457  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 22  Epoch: 139  Training loss = 4.3453  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 22  Epoch: 140  Training loss = 4.3449  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 22  Epoch: 141  Training loss = 4.3446  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 22  Epoch: 142  Training loss = 4.3442  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 22  Epoch: 143  Training loss = 4.3439  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 22  Epoch: 144  Training loss = 4.3435  Validation loss = 2.2163  \n",
      "\n",
      "Fold: 22  Epoch: 145  Training loss = 4.3431  Validation loss = 2.2162  \n",
      "\n",
      "Fold: 22  Epoch: 146  Training loss = 4.3427  Validation loss = 2.2162  \n",
      "\n",
      "Fold: 22  Epoch: 147  Training loss = 4.3425  Validation loss = 2.2160  \n",
      "\n",
      "Fold: 22  Epoch: 148  Training loss = 4.3422  Validation loss = 2.2157  \n",
      "\n",
      "Fold: 22  Epoch: 149  Training loss = 4.3418  Validation loss = 2.2154  \n",
      "\n",
      "Fold: 22  Epoch: 150  Training loss = 4.3413  Validation loss = 2.2152  \n",
      "\n",
      "Fold: 22  Epoch: 151  Training loss = 4.3410  Validation loss = 2.2151  \n",
      "\n",
      "Fold: 22  Epoch: 152  Training loss = 4.3406  Validation loss = 2.2150  \n",
      "\n",
      "Fold: 22  Epoch: 153  Training loss = 4.3401  Validation loss = 2.2148  \n",
      "\n",
      "Fold: 22  Epoch: 154  Training loss = 4.3396  Validation loss = 2.2146  \n",
      "\n",
      "Fold: 22  Epoch: 155  Training loss = 4.3392  Validation loss = 2.2144  \n",
      "\n",
      "Fold: 22  Epoch: 156  Training loss = 4.3388  Validation loss = 2.2143  \n",
      "\n",
      "Fold: 22  Epoch: 157  Training loss = 4.3384  Validation loss = 2.2139  \n",
      "\n",
      "Fold: 22  Epoch: 158  Training loss = 4.3380  Validation loss = 2.2138  \n",
      "\n",
      "Fold: 22  Epoch: 159  Training loss = 4.3376  Validation loss = 2.2137  \n",
      "\n",
      "Fold: 22  Epoch: 160  Training loss = 4.3372  Validation loss = 2.2134  \n",
      "\n",
      "Fold: 22  Epoch: 161  Training loss = 4.3367  Validation loss = 2.2132  \n",
      "\n",
      "Fold: 22  Epoch: 162  Training loss = 4.3363  Validation loss = 2.2130  \n",
      "\n",
      "Fold: 22  Epoch: 163  Training loss = 4.3360  Validation loss = 2.2129  \n",
      "\n",
      "Fold: 22  Epoch: 164  Training loss = 4.3355  Validation loss = 2.2127  \n",
      "\n",
      "Fold: 22  Epoch: 165  Training loss = 4.3352  Validation loss = 2.2126  \n",
      "\n",
      "Fold: 22  Epoch: 166  Training loss = 4.3347  Validation loss = 2.2125  \n",
      "\n",
      "Fold: 22  Epoch: 167  Training loss = 4.3344  Validation loss = 2.2122  \n",
      "\n",
      "Fold: 22  Epoch: 168  Training loss = 4.3339  Validation loss = 2.2121  \n",
      "\n",
      "Fold: 22  Epoch: 169  Training loss = 4.3335  Validation loss = 2.2121  \n",
      "\n",
      "Fold: 22  Epoch: 170  Training loss = 4.3332  Validation loss = 2.2120  \n",
      "\n",
      "Fold: 22  Epoch: 171  Training loss = 4.3329  Validation loss = 2.2119  \n",
      "\n",
      "Fold: 22  Epoch: 172  Training loss = 4.3326  Validation loss = 2.2118  \n",
      "\n",
      "Fold: 22  Epoch: 173  Training loss = 4.3321  Validation loss = 2.2117  \n",
      "\n",
      "Fold: 22  Epoch: 174  Training loss = 4.3317  Validation loss = 2.2117  \n",
      "\n",
      "Fold: 22  Epoch: 175  Training loss = 4.3313  Validation loss = 2.2116  \n",
      "\n",
      "Fold: 22  Epoch: 176  Training loss = 4.3308  Validation loss = 2.2115  \n",
      "\n",
      "Fold: 22  Epoch: 177  Training loss = 4.3304  Validation loss = 2.2113  \n",
      "\n",
      "Fold: 22  Epoch: 178  Training loss = 4.3299  Validation loss = 2.2110  \n",
      "\n",
      "Fold: 22  Epoch: 179  Training loss = 4.3295  Validation loss = 2.2109  \n",
      "\n",
      "Fold: 22  Epoch: 180  Training loss = 4.3292  Validation loss = 2.2105  \n",
      "\n",
      "Fold: 22  Epoch: 181  Training loss = 4.3289  Validation loss = 2.2105  \n",
      "\n",
      "Fold: 22  Epoch: 182  Training loss = 4.3285  Validation loss = 2.2105  \n",
      "\n",
      "Fold: 22  Epoch: 183  Training loss = 4.3280  Validation loss = 2.2103  \n",
      "\n",
      "Fold: 22  Epoch: 184  Training loss = 4.3276  Validation loss = 2.2102  \n",
      "\n",
      "Fold: 22  Epoch: 185  Training loss = 4.3272  Validation loss = 2.2101  \n",
      "\n",
      "Fold: 22  Epoch: 186  Training loss = 4.3269  Validation loss = 2.2098  \n",
      "\n",
      "Fold: 22  Epoch: 187  Training loss = 4.3266  Validation loss = 2.2097  \n",
      "\n",
      "Fold: 22  Epoch: 188  Training loss = 4.3263  Validation loss = 2.2097  \n",
      "\n",
      "Fold: 22  Epoch: 189  Training loss = 4.3260  Validation loss = 2.2097  \n",
      "\n",
      "Fold: 22  Epoch: 190  Training loss = 4.3256  Validation loss = 2.2095  \n",
      "\n",
      "Fold: 22  Epoch: 191  Training loss = 4.3252  Validation loss = 2.2094  \n",
      "\n",
      "Fold: 22  Epoch: 192  Training loss = 4.3247  Validation loss = 2.2092  \n",
      "\n",
      "Fold: 22  Epoch: 193  Training loss = 4.3241  Validation loss = 2.2090  \n",
      "\n",
      "Fold: 22  Epoch: 194  Training loss = 4.3237  Validation loss = 2.2087  \n",
      "\n",
      "Fold: 22  Epoch: 195  Training loss = 4.3234  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 22  Epoch: 196  Training loss = 4.3231  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 22  Epoch: 197  Training loss = 4.3227  Validation loss = 2.2083  \n",
      "\n",
      "Fold: 22  Epoch: 198  Training loss = 4.3225  Validation loss = 2.2082  \n",
      "\n",
      "Fold: 22  Epoch: 199  Training loss = 4.3221  Validation loss = 2.2081  \n",
      "\n",
      "Fold: 22  Epoch: 200  Training loss = 4.3217  Validation loss = 2.2078  \n",
      "\n",
      "Fold: 22  Epoch: 201  Training loss = 4.3214  Validation loss = 2.2077  \n",
      "\n",
      "Fold: 22  Epoch: 202  Training loss = 4.3211  Validation loss = 2.2076  \n",
      "\n",
      "Fold: 22  Epoch: 203  Training loss = 4.3207  Validation loss = 2.2074  \n",
      "\n",
      "Fold: 22  Epoch: 204  Training loss = 4.3203  Validation loss = 2.2074  \n",
      "\n",
      "Fold: 22  Epoch: 205  Training loss = 4.3198  Validation loss = 2.2071  \n",
      "\n",
      "Fold: 22  Epoch: 206  Training loss = 4.3195  Validation loss = 2.2070  \n",
      "\n",
      "Fold: 22  Epoch: 207  Training loss = 4.3192  Validation loss = 2.2070  \n",
      "\n",
      "Fold: 22  Epoch: 208  Training loss = 4.3187  Validation loss = 2.2068  \n",
      "\n",
      "Fold: 22  Epoch: 209  Training loss = 4.3183  Validation loss = 2.2068  \n",
      "\n",
      "Fold: 22  Epoch: 210  Training loss = 4.3180  Validation loss = 2.2067  \n",
      "\n",
      "Fold: 22  Epoch: 211  Training loss = 4.3175  Validation loss = 2.2065  \n",
      "\n",
      "Fold: 22  Epoch: 212  Training loss = 4.3170  Validation loss = 2.2063  \n",
      "\n",
      "Fold: 22  Epoch: 213  Training loss = 4.3166  Validation loss = 2.2062  \n",
      "\n",
      "Fold: 22  Epoch: 214  Training loss = 4.3163  Validation loss = 2.2062  \n",
      "\n",
      "Fold: 22  Epoch: 215  Training loss = 4.3160  Validation loss = 2.2062  \n",
      "\n",
      "Fold: 22  Epoch: 216  Training loss = 4.3156  Validation loss = 2.2060  \n",
      "\n",
      "Fold: 22  Epoch: 217  Training loss = 4.3153  Validation loss = 2.2059  \n",
      "\n",
      "Fold: 22  Epoch: 218  Training loss = 4.3148  Validation loss = 2.2059  \n",
      "\n",
      "Fold: 22  Epoch: 219  Training loss = 4.3145  Validation loss = 2.2057  \n",
      "\n",
      "Fold: 22  Epoch: 220  Training loss = 4.3142  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 22  Epoch: 221  Training loss = 4.3137  Validation loss = 2.2053  \n",
      "\n",
      "Fold: 22  Epoch: 222  Training loss = 4.3132  Validation loss = 2.2052  \n",
      "\n",
      "Fold: 22  Epoch: 223  Training loss = 4.3128  Validation loss = 2.2049  \n",
      "\n",
      "Fold: 22  Epoch: 224  Training loss = 4.3124  Validation loss = 2.2049  \n",
      "\n",
      "Fold: 22  Epoch: 225  Training loss = 4.3119  Validation loss = 2.2047  \n",
      "\n",
      "Fold: 22  Epoch: 226  Training loss = 4.3116  Validation loss = 2.2045  \n",
      "\n",
      "Fold: 22  Epoch: 227  Training loss = 4.3112  Validation loss = 2.2044  \n",
      "\n",
      "Fold: 22  Epoch: 228  Training loss = 4.3107  Validation loss = 2.2041  \n",
      "\n",
      "Fold: 22  Epoch: 229  Training loss = 4.3101  Validation loss = 2.2041  \n",
      "\n",
      "Fold: 22  Epoch: 230  Training loss = 4.3098  Validation loss = 2.2039  \n",
      "\n",
      "Fold: 22  Epoch: 231  Training loss = 4.3094  Validation loss = 2.2038  \n",
      "\n",
      "Fold: 22  Epoch: 232  Training loss = 4.3090  Validation loss = 2.2037  \n",
      "\n",
      "Fold: 22  Epoch: 233  Training loss = 4.3087  Validation loss = 2.2037  \n",
      "\n",
      "Fold: 22  Epoch: 234  Training loss = 4.3082  Validation loss = 2.2036  \n",
      "\n",
      "Fold: 22  Epoch: 235  Training loss = 4.3079  Validation loss = 2.2036  \n",
      "\n",
      "Fold: 22  Epoch: 236  Training loss = 4.3075  Validation loss = 2.2033  \n",
      "\n",
      "Fold: 22  Epoch: 237  Training loss = 4.3071  Validation loss = 2.2032  \n",
      "\n",
      "Fold: 22  Epoch: 238  Training loss = 4.3069  Validation loss = 2.2032  \n",
      "\n",
      "Fold: 22  Epoch: 239  Training loss = 4.3065  Validation loss = 2.2031  \n",
      "\n",
      "Fold: 22  Epoch: 240  Training loss = 4.3062  Validation loss = 2.2030  \n",
      "\n",
      "Fold: 22  Epoch: 241  Training loss = 4.3057  Validation loss = 2.2031  \n",
      "\n",
      "Fold: 22  Epoch: 242  Training loss = 4.3054  Validation loss = 2.2029  \n",
      "\n",
      "Fold: 22  Epoch: 243  Training loss = 4.3051  Validation loss = 2.2029  \n",
      "\n",
      "Fold: 22  Epoch: 244  Training loss = 4.3048  Validation loss = 2.2027  \n",
      "\n",
      "Fold: 22  Epoch: 245  Training loss = 4.3043  Validation loss = 2.2028  \n",
      "\n",
      "Fold: 22  Epoch: 246  Training loss = 4.3038  Validation loss = 2.2027  \n",
      "\n",
      "Fold: 22  Epoch: 247  Training loss = 4.3034  Validation loss = 2.2027  \n",
      "\n",
      "Fold: 22  Epoch: 248  Training loss = 4.3031  Validation loss = 2.2026  \n",
      "\n",
      "Fold: 22  Epoch: 249  Training loss = 4.3028  Validation loss = 2.2025  \n",
      "\n",
      "Fold: 22  Epoch: 250  Training loss = 4.3025  Validation loss = 2.2024  \n",
      "\n",
      "Fold: 22  Epoch: 251  Training loss = 4.3022  Validation loss = 2.2022  \n",
      "\n",
      "Fold: 22  Epoch: 252  Training loss = 4.3019  Validation loss = 2.2023  \n",
      "\n",
      "Fold: 22  Epoch: 253  Training loss = 4.3014  Validation loss = 2.2021  \n",
      "\n",
      "Fold: 22  Epoch: 254  Training loss = 4.3010  Validation loss = 2.2020  \n",
      "\n",
      "Fold: 22  Epoch: 255  Training loss = 4.3006  Validation loss = 2.2020  \n",
      "\n",
      "Fold: 22  Epoch: 256  Training loss = 4.3003  Validation loss = 2.2019  \n",
      "\n",
      "Fold: 22  Epoch: 257  Training loss = 4.2999  Validation loss = 2.2015  \n",
      "\n",
      "Fold: 22  Epoch: 258  Training loss = 4.2995  Validation loss = 2.2013  \n",
      "\n",
      "Fold: 22  Epoch: 259  Training loss = 4.2990  Validation loss = 2.2013  \n",
      "\n",
      "Fold: 22  Epoch: 260  Training loss = 4.2987  Validation loss = 2.2010  \n",
      "\n",
      "Fold: 22  Epoch: 261  Training loss = 4.2983  Validation loss = 2.2009  \n",
      "\n",
      "Fold: 22  Epoch: 262  Training loss = 4.2980  Validation loss = 2.2008  \n",
      "\n",
      "Fold: 22  Epoch: 263  Training loss = 4.2975  Validation loss = 2.2007  \n",
      "\n",
      "Fold: 22  Epoch: 264  Training loss = 4.2971  Validation loss = 2.2008  \n",
      "\n",
      "Fold: 22  Epoch: 265  Training loss = 4.2968  Validation loss = 2.2008  \n",
      "\n",
      "Fold: 22  Epoch: 266  Training loss = 4.2963  Validation loss = 2.2005  \n",
      "\n",
      "Fold: 22  Epoch: 267  Training loss = 4.2960  Validation loss = 2.2005  \n",
      "\n",
      "Fold: 22  Epoch: 268  Training loss = 4.2956  Validation loss = 2.2005  \n",
      "\n",
      "Fold: 22  Epoch: 269  Training loss = 4.2953  Validation loss = 2.2003  \n",
      "\n",
      "Fold: 22  Epoch: 270  Training loss = 4.2950  Validation loss = 2.2002  \n",
      "\n",
      "Fold: 22  Epoch: 271  Training loss = 4.2947  Validation loss = 2.2002  \n",
      "\n",
      "Fold: 22  Epoch: 272  Training loss = 4.2943  Validation loss = 2.2001  \n",
      "\n",
      "Fold: 22  Epoch: 273  Training loss = 4.2939  Validation loss = 2.2001  \n",
      "\n",
      "Fold: 22  Epoch: 274  Training loss = 4.2936  Validation loss = 2.1999  \n",
      "\n",
      "Fold: 22  Epoch: 275  Training loss = 4.2931  Validation loss = 2.1997  \n",
      "\n",
      "Fold: 22  Epoch: 276  Training loss = 4.2929  Validation loss = 2.1996  \n",
      "\n",
      "Fold: 22  Epoch: 277  Training loss = 4.2924  Validation loss = 2.1994  \n",
      "\n",
      "Fold: 22  Epoch: 278  Training loss = 4.2919  Validation loss = 2.1993  \n",
      "\n",
      "Fold: 22  Epoch: 279  Training loss = 4.2916  Validation loss = 2.1993  \n",
      "\n",
      "Fold: 22  Epoch: 280  Training loss = 4.2913  Validation loss = 2.1992  \n",
      "\n",
      "Fold: 22  Epoch: 281  Training loss = 4.2910  Validation loss = 2.1990  \n",
      "\n",
      "Fold: 22  Epoch: 282  Training loss = 4.2907  Validation loss = 2.1990  \n",
      "\n",
      "Fold: 22  Epoch: 283  Training loss = 4.2905  Validation loss = 2.1988  \n",
      "\n",
      "Fold: 22  Epoch: 284  Training loss = 4.2901  Validation loss = 2.1985  \n",
      "\n",
      "Fold: 22  Epoch: 285  Training loss = 4.2898  Validation loss = 2.1984  \n",
      "\n",
      "Fold: 22  Epoch: 286  Training loss = 4.2894  Validation loss = 2.1981  \n",
      "\n",
      "Fold: 22  Epoch: 287  Training loss = 4.2890  Validation loss = 2.1980  \n",
      "\n",
      "Fold: 22  Epoch: 288  Training loss = 4.2885  Validation loss = 2.1979  \n",
      "\n",
      "Fold: 22  Epoch: 289  Training loss = 4.2882  Validation loss = 2.1977  \n",
      "\n",
      "Fold: 22  Epoch: 290  Training loss = 4.2879  Validation loss = 2.1976  \n",
      "\n",
      "Fold: 22  Epoch: 291  Training loss = 4.2876  Validation loss = 2.1975  \n",
      "\n",
      "Fold: 22  Epoch: 292  Training loss = 4.2872  Validation loss = 2.1973  \n",
      "\n",
      "Fold: 22  Epoch: 293  Training loss = 4.2867  Validation loss = 2.1973  \n",
      "\n",
      "Fold: 22  Epoch: 294  Training loss = 4.2864  Validation loss = 2.1971  \n",
      "\n",
      "Fold: 22  Epoch: 295  Training loss = 4.2860  Validation loss = 2.1969  \n",
      "\n",
      "Fold: 22  Epoch: 296  Training loss = 4.2857  Validation loss = 2.1968  \n",
      "\n",
      "Fold: 22  Epoch: 297  Training loss = 4.2853  Validation loss = 2.1968  \n",
      "\n",
      "Fold: 22  Epoch: 298  Training loss = 4.2848  Validation loss = 2.1967  \n",
      "\n",
      "Fold: 22  Epoch: 299  Training loss = 4.2845  Validation loss = 2.1966  \n",
      "\n",
      "Fold: 22  Epoch: 300  Training loss = 4.2842  Validation loss = 2.1965  \n",
      "\n",
      "Fold: 22  Epoch: 301  Training loss = 4.2838  Validation loss = 2.1964  \n",
      "\n",
      "Fold: 22  Epoch: 302  Training loss = 4.2835  Validation loss = 2.1963  \n",
      "\n",
      "Fold: 22  Epoch: 303  Training loss = 4.2832  Validation loss = 2.1963  \n",
      "\n",
      "Fold: 22  Epoch: 304  Training loss = 4.2828  Validation loss = 2.1961  \n",
      "\n",
      "Fold: 22  Epoch: 305  Training loss = 4.2824  Validation loss = 2.1960  \n",
      "\n",
      "Fold: 22  Epoch: 306  Training loss = 4.2820  Validation loss = 2.1960  \n",
      "\n",
      "Fold: 22  Epoch: 307  Training loss = 4.2817  Validation loss = 2.1958  \n",
      "\n",
      "Fold: 22  Epoch: 308  Training loss = 4.2813  Validation loss = 2.1958  \n",
      "\n",
      "Fold: 22  Epoch: 309  Training loss = 4.2809  Validation loss = 2.1957  \n",
      "\n",
      "Fold: 22  Epoch: 310  Training loss = 4.2807  Validation loss = 2.1956  \n",
      "\n",
      "Fold: 22  Epoch: 311  Training loss = 4.2802  Validation loss = 2.1955  \n",
      "\n",
      "Fold: 22  Epoch: 312  Training loss = 4.2798  Validation loss = 2.1955  \n",
      "\n",
      "Fold: 22  Epoch: 313  Training loss = 4.2795  Validation loss = 2.1954  \n",
      "\n",
      "Fold: 22  Epoch: 314  Training loss = 4.2792  Validation loss = 2.1952  \n",
      "\n",
      "Fold: 22  Epoch: 315  Training loss = 4.2787  Validation loss = 2.1951  \n",
      "\n",
      "Fold: 22  Epoch: 316  Training loss = 4.2783  Validation loss = 2.1950  \n",
      "\n",
      "Fold: 22  Epoch: 317  Training loss = 4.2780  Validation loss = 2.1947  \n",
      "\n",
      "Fold: 22  Epoch: 318  Training loss = 4.2776  Validation loss = 2.1944  \n",
      "\n",
      "Fold: 22  Epoch: 319  Training loss = 4.2772  Validation loss = 2.1942  \n",
      "\n",
      "Fold: 22  Epoch: 320  Training loss = 4.2769  Validation loss = 2.1940  \n",
      "\n",
      "Fold: 22  Epoch: 321  Training loss = 4.2766  Validation loss = 2.1939  \n",
      "\n",
      "Fold: 22  Epoch: 322  Training loss = 4.2763  Validation loss = 2.1939  \n",
      "\n",
      "Fold: 22  Epoch: 323  Training loss = 4.2758  Validation loss = 2.1939  \n",
      "\n",
      "Fold: 22  Epoch: 324  Training loss = 4.2755  Validation loss = 2.1938  \n",
      "\n",
      "Fold: 22  Epoch: 325  Training loss = 4.2752  Validation loss = 2.1937  \n",
      "\n",
      "Fold: 22  Epoch: 326  Training loss = 4.2749  Validation loss = 2.1935  \n",
      "\n",
      "Fold: 22  Epoch: 327  Training loss = 4.2746  Validation loss = 2.1934  \n",
      "\n",
      "Fold: 22  Epoch: 328  Training loss = 4.2743  Validation loss = 2.1934  \n",
      "\n",
      "Fold: 22  Epoch: 329  Training loss = 4.2738  Validation loss = 2.1933  \n",
      "\n",
      "Fold: 22  Epoch: 330  Training loss = 4.2735  Validation loss = 2.1932  \n",
      "\n",
      "Fold: 22  Epoch: 331  Training loss = 4.2731  Validation loss = 2.1931  \n",
      "\n",
      "Fold: 22  Epoch: 332  Training loss = 4.2727  Validation loss = 2.1928  \n",
      "\n",
      "Fold: 22  Epoch: 333  Training loss = 4.2724  Validation loss = 2.1928  \n",
      "\n",
      "Fold: 22  Epoch: 334  Training loss = 4.2720  Validation loss = 2.1928  \n",
      "\n",
      "Fold: 22  Epoch: 335  Training loss = 4.2716  Validation loss = 2.1928  \n",
      "\n",
      "Fold: 22  Epoch: 336  Training loss = 4.2712  Validation loss = 2.1927  \n",
      "\n",
      "Fold: 22  Epoch: 337  Training loss = 4.2708  Validation loss = 2.1926  \n",
      "\n",
      "Fold: 22  Epoch: 338  Training loss = 4.2704  Validation loss = 2.1925  \n",
      "\n",
      "Fold: 22  Epoch: 339  Training loss = 4.2700  Validation loss = 2.1923  \n",
      "\n",
      "Fold: 22  Epoch: 340  Training loss = 4.2696  Validation loss = 2.1922  \n",
      "\n",
      "Fold: 22  Epoch: 341  Training loss = 4.2692  Validation loss = 2.1921  \n",
      "\n",
      "Fold: 22  Epoch: 342  Training loss = 4.2689  Validation loss = 2.1917  \n",
      "\n",
      "Fold: 22  Epoch: 343  Training loss = 4.2685  Validation loss = 2.1918  \n",
      "\n",
      "Fold: 22  Epoch: 344  Training loss = 4.2682  Validation loss = 2.1917  \n",
      "\n",
      "Fold: 22  Epoch: 345  Training loss = 4.2679  Validation loss = 2.1917  \n",
      "\n",
      "Fold: 22  Epoch: 346  Training loss = 4.2676  Validation loss = 2.1914  \n",
      "\n",
      "Fold: 22  Epoch: 347  Training loss = 4.2671  Validation loss = 2.1909  \n",
      "\n",
      "Fold: 22  Epoch: 348  Training loss = 4.2668  Validation loss = 2.1909  \n",
      "\n",
      "Fold: 22  Epoch: 349  Training loss = 4.2664  Validation loss = 2.1908  \n",
      "\n",
      "Fold: 22  Epoch: 350  Training loss = 4.2661  Validation loss = 2.1905  \n",
      "\n",
      "Fold: 22  Epoch: 351  Training loss = 4.2658  Validation loss = 2.1907  \n",
      "\n",
      "Fold: 22  Epoch: 352  Training loss = 4.2654  Validation loss = 2.1907  \n",
      "\n",
      "Fold: 22  Epoch: 353  Training loss = 4.2650  Validation loss = 2.1906  \n",
      "\n",
      "Fold: 22  Epoch: 354  Training loss = 4.2647  Validation loss = 2.1902  \n",
      "\n",
      "Fold: 22  Epoch: 355  Training loss = 4.2644  Validation loss = 2.1903  \n",
      "\n",
      "Fold: 22  Epoch: 356  Training loss = 4.2641  Validation loss = 2.1902  \n",
      "\n",
      "Fold: 22  Epoch: 357  Training loss = 4.2637  Validation loss = 2.1901  \n",
      "\n",
      "Fold: 22  Epoch: 358  Training loss = 4.2634  Validation loss = 2.1900  \n",
      "\n",
      "Fold: 22  Epoch: 359  Training loss = 4.2630  Validation loss = 2.1900  \n",
      "\n",
      "Fold: 22  Epoch: 360  Training loss = 4.2627  Validation loss = 2.1899  \n",
      "\n",
      "Fold: 22  Epoch: 361  Training loss = 4.2623  Validation loss = 2.1898  \n",
      "\n",
      "Fold: 22  Epoch: 362  Training loss = 4.2620  Validation loss = 2.1897  \n",
      "\n",
      "Fold: 22  Epoch: 363  Training loss = 4.2617  Validation loss = 2.1895  \n",
      "\n",
      "Fold: 22  Epoch: 364  Training loss = 4.2614  Validation loss = 2.1892  \n",
      "\n",
      "Fold: 22  Epoch: 365  Training loss = 4.2611  Validation loss = 2.1891  \n",
      "\n",
      "Fold: 22  Epoch: 366  Training loss = 4.2608  Validation loss = 2.1891  \n",
      "\n",
      "Fold: 22  Epoch: 367  Training loss = 4.2605  Validation loss = 2.1890  \n",
      "\n",
      "Fold: 22  Epoch: 368  Training loss = 4.2603  Validation loss = 2.1889  \n",
      "\n",
      "Fold: 22  Epoch: 369  Training loss = 4.2599  Validation loss = 2.1887  \n",
      "\n",
      "Fold: 22  Epoch: 370  Training loss = 4.2596  Validation loss = 2.1887  \n",
      "\n",
      "Fold: 22  Epoch: 371  Training loss = 4.2593  Validation loss = 2.1886  \n",
      "\n",
      "Fold: 22  Epoch: 372  Training loss = 4.2588  Validation loss = 2.1886  \n",
      "\n",
      "Fold: 22  Epoch: 373  Training loss = 4.2584  Validation loss = 2.1884  \n",
      "\n",
      "Fold: 22  Epoch: 374  Training loss = 4.2581  Validation loss = 2.1884  \n",
      "\n",
      "Fold: 22  Epoch: 375  Training loss = 4.2577  Validation loss = 2.1883  \n",
      "\n",
      "Fold: 22  Epoch: 376  Training loss = 4.2573  Validation loss = 2.1882  \n",
      "\n",
      "Fold: 22  Epoch: 377  Training loss = 4.2570  Validation loss = 2.1880  \n",
      "\n",
      "Fold: 22  Epoch: 378  Training loss = 4.2566  Validation loss = 2.1880  \n",
      "\n",
      "Fold: 22  Epoch: 379  Training loss = 4.2562  Validation loss = 2.1879  \n",
      "\n",
      "Fold: 22  Epoch: 380  Training loss = 4.2558  Validation loss = 2.1878  \n",
      "\n",
      "Fold: 22  Epoch: 381  Training loss = 4.2555  Validation loss = 2.1876  \n",
      "\n",
      "Fold: 22  Epoch: 382  Training loss = 4.2551  Validation loss = 2.1877  \n",
      "\n",
      "Fold: 22  Epoch: 383  Training loss = 4.2548  Validation loss = 2.1876  \n",
      "\n",
      "Fold: 22  Epoch: 384  Training loss = 4.2544  Validation loss = 2.1874  \n",
      "\n",
      "Fold: 22  Epoch: 385  Training loss = 4.2541  Validation loss = 2.1873  \n",
      "\n",
      "Fold: 22  Epoch: 386  Training loss = 4.2537  Validation loss = 2.1872  \n",
      "\n",
      "Fold: 22  Epoch: 387  Training loss = 4.2535  Validation loss = 2.1871  \n",
      "\n",
      "Fold: 22  Epoch: 388  Training loss = 4.2532  Validation loss = 2.1870  \n",
      "\n",
      "Fold: 22  Epoch: 389  Training loss = 4.2529  Validation loss = 2.1870  \n",
      "\n",
      "Fold: 22  Epoch: 390  Training loss = 4.2526  Validation loss = 2.1869  \n",
      "\n",
      "Fold: 22  Epoch: 391  Training loss = 4.2522  Validation loss = 2.1868  \n",
      "\n",
      "Fold: 22  Epoch: 392  Training loss = 4.2520  Validation loss = 2.1865  \n",
      "\n",
      "Fold: 22  Epoch: 393  Training loss = 4.2518  Validation loss = 2.1865  \n",
      "\n",
      "Fold: 22  Epoch: 394  Training loss = 4.2515  Validation loss = 2.1863  \n",
      "\n",
      "Fold: 22  Epoch: 395  Training loss = 4.2513  Validation loss = 2.1864  \n",
      "\n",
      "Fold: 22  Epoch: 396  Training loss = 4.2509  Validation loss = 2.1864  \n",
      "\n",
      "Fold: 22  Epoch: 397  Training loss = 4.2506  Validation loss = 2.1863  \n",
      "\n",
      "Fold: 22  Epoch: 398  Training loss = 4.2502  Validation loss = 2.1862  \n",
      "\n",
      "Fold: 22  Epoch: 399  Training loss = 4.2498  Validation loss = 2.1862  \n",
      "\n",
      "Fold: 22  Epoch: 400  Training loss = 4.2493  Validation loss = 2.1861  \n",
      "\n",
      "Fold: 22  Epoch: 401  Training loss = 4.2491  Validation loss = 2.1861  \n",
      "\n",
      "Fold: 22  Epoch: 402  Training loss = 4.2487  Validation loss = 2.1858  \n",
      "\n",
      "Fold: 22  Epoch: 403  Training loss = 4.2484  Validation loss = 2.1857  \n",
      "\n",
      "Fold: 22  Epoch: 404  Training loss = 4.2481  Validation loss = 2.1856  \n",
      "\n",
      "Fold: 22  Epoch: 405  Training loss = 4.2477  Validation loss = 2.1857  \n",
      "\n",
      "Fold: 22  Epoch: 406  Training loss = 4.2474  Validation loss = 2.1857  \n",
      "\n",
      "Fold: 22  Epoch: 407  Training loss = 4.2471  Validation loss = 2.1856  \n",
      "\n",
      "Fold: 22  Epoch: 408  Training loss = 4.2467  Validation loss = 2.1855  \n",
      "\n",
      "Fold: 22  Epoch: 409  Training loss = 4.2464  Validation loss = 2.1854  \n",
      "\n",
      "Fold: 22  Epoch: 410  Training loss = 4.2461  Validation loss = 2.1854  \n",
      "\n",
      "Fold: 22  Epoch: 411  Training loss = 4.2456  Validation loss = 2.1853  \n",
      "\n",
      "Fold: 22  Epoch: 412  Training loss = 4.2453  Validation loss = 2.1852  \n",
      "\n",
      "Fold: 22  Epoch: 413  Training loss = 4.2450  Validation loss = 2.1851  \n",
      "\n",
      "Fold: 22  Epoch: 414  Training loss = 4.2447  Validation loss = 2.1851  \n",
      "\n",
      "Fold: 22  Epoch: 415  Training loss = 4.2443  Validation loss = 2.1849  \n",
      "\n",
      "Fold: 22  Epoch: 416  Training loss = 4.2439  Validation loss = 2.1848  \n",
      "\n",
      "Fold: 22  Epoch: 417  Training loss = 4.2436  Validation loss = 2.1848  \n",
      "\n",
      "Fold: 22  Epoch: 418  Training loss = 4.2432  Validation loss = 2.1848  \n",
      "\n",
      "Fold: 22  Epoch: 419  Training loss = 4.2429  Validation loss = 2.1846  \n",
      "\n",
      "Fold: 22  Epoch: 420  Training loss = 4.2425  Validation loss = 2.1844  \n",
      "\n",
      "Fold: 22  Epoch: 421  Training loss = 4.2421  Validation loss = 2.1842  \n",
      "\n",
      "Fold: 22  Epoch: 422  Training loss = 4.2417  Validation loss = 2.1843  \n",
      "\n",
      "Fold: 22  Epoch: 423  Training loss = 4.2414  Validation loss = 2.1843  \n",
      "\n",
      "Fold: 22  Epoch: 424  Training loss = 4.2411  Validation loss = 2.1843  \n",
      "\n",
      "Fold: 22  Epoch: 425  Training loss = 4.2407  Validation loss = 2.1841  \n",
      "\n",
      "Fold: 22  Epoch: 426  Training loss = 4.2404  Validation loss = 2.1840  \n",
      "\n",
      "Fold: 22  Epoch: 427  Training loss = 4.2401  Validation loss = 2.1838  \n",
      "\n",
      "Fold: 22  Epoch: 428  Training loss = 4.2396  Validation loss = 2.1836  \n",
      "\n",
      "Fold: 22  Epoch: 429  Training loss = 4.2394  Validation loss = 2.1837  \n",
      "\n",
      "Fold: 22  Epoch: 430  Training loss = 4.2390  Validation loss = 2.1836  \n",
      "\n",
      "Fold: 22  Epoch: 431  Training loss = 4.2388  Validation loss = 2.1835  \n",
      "\n",
      "Fold: 22  Epoch: 432  Training loss = 4.2384  Validation loss = 2.1833  \n",
      "\n",
      "Fold: 22  Epoch: 433  Training loss = 4.2381  Validation loss = 2.1833  \n",
      "\n",
      "Fold: 22  Epoch: 434  Training loss = 4.2378  Validation loss = 2.1831  \n",
      "\n",
      "Fold: 22  Epoch: 435  Training loss = 4.2375  Validation loss = 2.1830  \n",
      "\n",
      "Fold: 22  Epoch: 436  Training loss = 4.2372  Validation loss = 2.1828  \n",
      "\n",
      "Fold: 22  Epoch: 437  Training loss = 4.2370  Validation loss = 2.1828  \n",
      "\n",
      "Fold: 22  Epoch: 438  Training loss = 4.2366  Validation loss = 2.1826  \n",
      "\n",
      "Fold: 22  Epoch: 439  Training loss = 4.2363  Validation loss = 2.1827  \n",
      "\n",
      "Fold: 22  Epoch: 440  Training loss = 4.2360  Validation loss = 2.1826  \n",
      "\n",
      "Fold: 22  Epoch: 441  Training loss = 4.2356  Validation loss = 2.1827  \n",
      "\n",
      "Fold: 22  Epoch: 442  Training loss = 4.2354  Validation loss = 2.1827  \n",
      "\n",
      "Fold: 22  Epoch: 443  Training loss = 4.2350  Validation loss = 2.1826  \n",
      "\n",
      "Fold: 22  Epoch: 444  Training loss = 4.2347  Validation loss = 2.1823  \n",
      "\n",
      "Fold: 22  Epoch: 445  Training loss = 4.2344  Validation loss = 2.1821  \n",
      "\n",
      "Fold: 22  Epoch: 446  Training loss = 4.2342  Validation loss = 2.1821  \n",
      "\n",
      "Fold: 22  Epoch: 447  Training loss = 4.2339  Validation loss = 2.1820  \n",
      "\n",
      "Fold: 22  Epoch: 448  Training loss = 4.2336  Validation loss = 2.1819  \n",
      "\n",
      "Fold: 22  Epoch: 449  Training loss = 4.2332  Validation loss = 2.1819  \n",
      "\n",
      "Fold: 22  Epoch: 450  Training loss = 4.2329  Validation loss = 2.1819  \n",
      "\n",
      "Fold: 22  Epoch: 451  Training loss = 4.2326  Validation loss = 2.1819  \n",
      "\n",
      "Fold: 22  Epoch: 452  Training loss = 4.2323  Validation loss = 2.1818  \n",
      "\n",
      "Fold: 22  Epoch: 453  Training loss = 4.2320  Validation loss = 2.1817  \n",
      "\n",
      "Fold: 22  Epoch: 454  Training loss = 4.2315  Validation loss = 2.1815  \n",
      "\n",
      "Fold: 22  Epoch: 455  Training loss = 4.2311  Validation loss = 2.1813  \n",
      "\n",
      "Fold: 22  Epoch: 456  Training loss = 4.2308  Validation loss = 2.1814  \n",
      "\n",
      "Fold: 22  Epoch: 457  Training loss = 4.2304  Validation loss = 2.1811  \n",
      "\n",
      "Fold: 22  Epoch: 458  Training loss = 4.2301  Validation loss = 2.1812  \n",
      "\n",
      "Fold: 22  Epoch: 459  Training loss = 4.2297  Validation loss = 2.1810  \n",
      "\n",
      "Fold: 22  Epoch: 460  Training loss = 4.2293  Validation loss = 2.1809  \n",
      "\n",
      "Fold: 22  Epoch: 461  Training loss = 4.2289  Validation loss = 2.1809  \n",
      "\n",
      "Fold: 22  Epoch: 462  Training loss = 4.2285  Validation loss = 2.1809  \n",
      "\n",
      "Fold: 22  Epoch: 463  Training loss = 4.2282  Validation loss = 2.1809  \n",
      "\n",
      "Fold: 22  Epoch: 464  Training loss = 4.2280  Validation loss = 2.1808  \n",
      "\n",
      "Fold: 22  Epoch: 465  Training loss = 4.2278  Validation loss = 2.1807  \n",
      "\n",
      "Fold: 22  Epoch: 466  Training loss = 4.2274  Validation loss = 2.1807  \n",
      "\n",
      "Fold: 22  Epoch: 467  Training loss = 4.2271  Validation loss = 2.1805  \n",
      "\n",
      "Fold: 22  Epoch: 468  Training loss = 4.2267  Validation loss = 2.1803  \n",
      "\n",
      "Fold: 22  Epoch: 469  Training loss = 4.2264  Validation loss = 2.1801  \n",
      "\n",
      "Fold: 22  Epoch: 470  Training loss = 4.2261  Validation loss = 2.1802  \n",
      "\n",
      "Fold: 22  Epoch: 471  Training loss = 4.2257  Validation loss = 2.1799  \n",
      "\n",
      "Fold: 22  Epoch: 472  Training loss = 4.2253  Validation loss = 2.1799  \n",
      "\n",
      "Fold: 22  Epoch: 473  Training loss = 4.2248  Validation loss = 2.1797  \n",
      "\n",
      "Fold: 22  Epoch: 474  Training loss = 4.2245  Validation loss = 2.1795  \n",
      "\n",
      "Fold: 22  Epoch: 475  Training loss = 4.2242  Validation loss = 2.1794  \n",
      "\n",
      "Fold: 22  Epoch: 476  Training loss = 4.2238  Validation loss = 2.1791  \n",
      "\n",
      "Fold: 22  Epoch: 477  Training loss = 4.2235  Validation loss = 2.1791  \n",
      "\n",
      "Fold: 22  Epoch: 478  Training loss = 4.2231  Validation loss = 2.1790  \n",
      "\n",
      "Fold: 22  Epoch: 479  Training loss = 4.2228  Validation loss = 2.1788  \n",
      "\n",
      "Fold: 22  Epoch: 480  Training loss = 4.2225  Validation loss = 2.1789  \n",
      "\n",
      "Fold: 22  Epoch: 481  Training loss = 4.2222  Validation loss = 2.1789  \n",
      "\n",
      "Fold: 22  Epoch: 482  Training loss = 4.2220  Validation loss = 2.1790  \n",
      "\n",
      "Fold: 22  Epoch: 483  Training loss = 4.2216  Validation loss = 2.1789  \n",
      "\n",
      "Fold: 22  Epoch: 484  Training loss = 4.2214  Validation loss = 2.1787  \n",
      "\n",
      "Fold: 22  Epoch: 485  Training loss = 4.2211  Validation loss = 2.1788  \n",
      "\n",
      "Fold: 22  Epoch: 486  Training loss = 4.2207  Validation loss = 2.1787  \n",
      "\n",
      "Fold: 22  Epoch: 487  Training loss = 4.2205  Validation loss = 2.1786  \n",
      "\n",
      "Fold: 22  Epoch: 488  Training loss = 4.2202  Validation loss = 2.1786  \n",
      "\n",
      "Fold: 22  Epoch: 489  Training loss = 4.2197  Validation loss = 2.1786  \n",
      "\n",
      "Fold: 22  Epoch: 490  Training loss = 4.2193  Validation loss = 2.1785  \n",
      "\n",
      "Fold: 22  Epoch: 491  Training loss = 4.2189  Validation loss = 2.1784  \n",
      "\n",
      "Fold: 22  Epoch: 492  Training loss = 4.2187  Validation loss = 2.1784  \n",
      "\n",
      "Fold: 22  Epoch: 493  Training loss = 4.2183  Validation loss = 2.1783  \n",
      "\n",
      "Fold: 22  Epoch: 494  Training loss = 4.2180  Validation loss = 2.1781  \n",
      "\n",
      "Fold: 22  Epoch: 495  Training loss = 4.2176  Validation loss = 2.1781  \n",
      "\n",
      "Fold: 22  Epoch: 496  Training loss = 4.2171  Validation loss = 2.1778  \n",
      "\n",
      "Fold: 22  Epoch: 497  Training loss = 4.2168  Validation loss = 2.1777  \n",
      "\n",
      "Fold: 22  Epoch: 498  Training loss = 4.2164  Validation loss = 2.1776  \n",
      "\n",
      "Fold: 22  Epoch: 499  Training loss = 4.2160  Validation loss = 2.1774  \n",
      "\n",
      "Fold: 22  Epoch: 500  Training loss = 4.2155  Validation loss = 2.1774  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 499  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 4.2412  Validation loss = 1.6525  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 4.2408  Validation loss = 1.6526  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 4.2404  Validation loss = 1.6525  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 4.2401  Validation loss = 1.6525  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 4.2396  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 4.2393  Validation loss = 1.6523  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 4.2389  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 4.2386  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 4.2383  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 4.2379  Validation loss = 1.6525  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 4.2375  Validation loss = 1.6525  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 4.2372  Validation loss = 1.6525  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 4.2368  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 4.2365  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 4.2362  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 4.2358  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 4.2354  Validation loss = 1.6525  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 4.2349  Validation loss = 1.6526  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 6  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 4.2374  Validation loss = 1.9551  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 4.2370  Validation loss = 1.9546  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 4.2365  Validation loss = 1.9541  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 4.2362  Validation loss = 1.9536  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 4.2359  Validation loss = 1.9532  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 4.2355  Validation loss = 1.9529  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 4.2352  Validation loss = 1.9525  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 4.2348  Validation loss = 1.9521  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 4.2345  Validation loss = 1.9515  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 4.2340  Validation loss = 1.9509  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 4.2335  Validation loss = 1.9504  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 4.2331  Validation loss = 1.9499  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 4.2327  Validation loss = 1.9495  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 4.2323  Validation loss = 1.9490  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 4.2320  Validation loss = 1.9484  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 4.2318  Validation loss = 1.9483  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 4.2313  Validation loss = 1.9477  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 4.2309  Validation loss = 1.9471  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 4.2305  Validation loss = 1.9467  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 4.2301  Validation loss = 1.9462  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 4.2297  Validation loss = 1.9457  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 4.2293  Validation loss = 1.9451  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 4.2290  Validation loss = 1.9448  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 4.2286  Validation loss = 1.9444  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 4.2283  Validation loss = 1.9439  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 4.2279  Validation loss = 1.9435  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 4.2276  Validation loss = 1.9431  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 4.2273  Validation loss = 1.9427  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 4.2269  Validation loss = 1.9422  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 4.2265  Validation loss = 1.9418  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 4.2261  Validation loss = 1.9413  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 4.2258  Validation loss = 1.9409  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 4.2253  Validation loss = 1.9403  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 4.2249  Validation loss = 1.9397  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 4.2246  Validation loss = 1.9393  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 4.2243  Validation loss = 1.9389  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 4.2239  Validation loss = 1.9385  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 4.2236  Validation loss = 1.9382  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 4.2233  Validation loss = 1.9377  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 4.2230  Validation loss = 1.9375  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 4.2227  Validation loss = 1.9373  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 4.2223  Validation loss = 1.9367  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 4.2219  Validation loss = 1.9363  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 4.2216  Validation loss = 1.9360  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 4.2212  Validation loss = 1.9354  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 4.2209  Validation loss = 1.9350  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 4.2205  Validation loss = 1.9346  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 4.2202  Validation loss = 1.9343  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 4.2198  Validation loss = 1.9339  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 4.2194  Validation loss = 1.9335  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 4.2191  Validation loss = 1.9331  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 4.2187  Validation loss = 1.9326  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 4.2183  Validation loss = 1.9322  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 4.2178  Validation loss = 1.9318  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 4.2175  Validation loss = 1.9315  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 4.2172  Validation loss = 1.9312  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 4.2169  Validation loss = 1.9309  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 4.2166  Validation loss = 1.9307  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 4.2162  Validation loss = 1.9302  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 4.2159  Validation loss = 1.9298  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 4.2156  Validation loss = 1.9295  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 4.2152  Validation loss = 1.9290  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 4.2148  Validation loss = 1.9285  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 4.2143  Validation loss = 1.9279  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 4.2141  Validation loss = 1.9277  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 4.2138  Validation loss = 1.9273  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 4.2134  Validation loss = 1.9268  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 4.2132  Validation loss = 1.9266  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 4.2128  Validation loss = 1.9261  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 4.2124  Validation loss = 1.9256  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 4.2119  Validation loss = 1.9251  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 4.2115  Validation loss = 1.9246  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 4.2112  Validation loss = 1.9243  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 4.2109  Validation loss = 1.9238  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 4.2105  Validation loss = 1.9234  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 4.2101  Validation loss = 1.9230  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 4.2098  Validation loss = 1.9228  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 4.2094  Validation loss = 1.9224  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 4.2091  Validation loss = 1.9221  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 4.2087  Validation loss = 1.9214  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 4.2084  Validation loss = 1.9211  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 4.2079  Validation loss = 1.9205  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 4.2075  Validation loss = 1.9200  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 4.2070  Validation loss = 1.9195  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 4.2067  Validation loss = 1.9192  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 4.2063  Validation loss = 1.9186  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 4.2060  Validation loss = 1.9183  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 4.2055  Validation loss = 1.9178  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 4.2051  Validation loss = 1.9173  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 4.2046  Validation loss = 1.9167  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 4.2043  Validation loss = 1.9164  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 4.2039  Validation loss = 1.9159  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 4.2035  Validation loss = 1.9156  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 4.2031  Validation loss = 1.9150  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 4.2028  Validation loss = 1.9147  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 4.2025  Validation loss = 1.9144  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 4.2021  Validation loss = 1.9139  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 4.2018  Validation loss = 1.9135  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 4.2015  Validation loss = 1.9131  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 4.2011  Validation loss = 1.9126  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 4.2007  Validation loss = 1.9122  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 4.2003  Validation loss = 1.9116  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 4.1999  Validation loss = 1.9111  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 4.1995  Validation loss = 1.9105  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 4.1992  Validation loss = 1.9102  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 4.1988  Validation loss = 1.9098  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 4.1986  Validation loss = 1.9095  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 4.1982  Validation loss = 1.9090  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 4.1979  Validation loss = 1.9086  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 4.1975  Validation loss = 1.9082  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 4.1971  Validation loss = 1.9077  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 4.1969  Validation loss = 1.9074  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 4.1965  Validation loss = 1.9069  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 4.1961  Validation loss = 1.9066  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 4.1958  Validation loss = 1.9063  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 4.1955  Validation loss = 1.9060  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 4.1952  Validation loss = 1.9056  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 4.1948  Validation loss = 1.9050  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 4.1945  Validation loss = 1.9046  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 4.1942  Validation loss = 1.9043  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 4.1938  Validation loss = 1.9037  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 4.1935  Validation loss = 1.9034  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 4.1932  Validation loss = 1.9031  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 4.1928  Validation loss = 1.9023  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 4.1925  Validation loss = 1.9020  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 4.1920  Validation loss = 1.9013  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 4.1917  Validation loss = 1.9010  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 4.1915  Validation loss = 1.9009  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 4.1913  Validation loss = 1.9007  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 4.1908  Validation loss = 1.9002  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 4.1905  Validation loss = 1.8996  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 4.1900  Validation loss = 1.8991  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 4.1897  Validation loss = 1.8986  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 4.1894  Validation loss = 1.8981  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 4.1891  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 4.1888  Validation loss = 1.8974  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 4.1883  Validation loss = 1.8967  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 4.1878  Validation loss = 1.8962  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 4.1875  Validation loss = 1.8958  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 4.1871  Validation loss = 1.8954  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 4.1867  Validation loss = 1.8949  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 4.1864  Validation loss = 1.8945  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 4.1860  Validation loss = 1.8941  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 4.1856  Validation loss = 1.8936  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 4.1852  Validation loss = 1.8931  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 4.1849  Validation loss = 1.8928  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 4.1844  Validation loss = 1.8924  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 4.1840  Validation loss = 1.8920  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 4.1836  Validation loss = 1.8916  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 4.1833  Validation loss = 1.8913  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 4.1830  Validation loss = 1.8910  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 4.1826  Validation loss = 1.8906  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 4.1823  Validation loss = 1.8901  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 4.1820  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 4.1816  Validation loss = 1.8892  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 4.1812  Validation loss = 1.8887  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 4.1809  Validation loss = 1.8883  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 4.1805  Validation loss = 1.8880  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 4.1802  Validation loss = 1.8876  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 4.1799  Validation loss = 1.8872  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 4.1795  Validation loss = 1.8867  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 4.1793  Validation loss = 1.8864  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 4.1790  Validation loss = 1.8861  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 4.1787  Validation loss = 1.8858  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 4.1782  Validation loss = 1.8854  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 4.1779  Validation loss = 1.8849  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 4.1776  Validation loss = 1.8846  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 4.1773  Validation loss = 1.8842  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 4.1768  Validation loss = 1.8838  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 4.1765  Validation loss = 1.8834  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 4.1761  Validation loss = 1.8830  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 4.1758  Validation loss = 1.8825  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 4.1754  Validation loss = 1.8820  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 4.1750  Validation loss = 1.8816  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 4.1746  Validation loss = 1.8812  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 4.1745  Validation loss = 1.8810  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 4.1741  Validation loss = 1.8805  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 4.1738  Validation loss = 1.8800  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 4.1734  Validation loss = 1.8794  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 4.1731  Validation loss = 1.8792  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 4.1726  Validation loss = 1.8787  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 4.1723  Validation loss = 1.8783  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 4.1719  Validation loss = 1.8779  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 4.1716  Validation loss = 1.8774  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 4.1713  Validation loss = 1.8770  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 4.1710  Validation loss = 1.8765  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 4.1707  Validation loss = 1.8761  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 4.1702  Validation loss = 1.8757  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 4.1698  Validation loss = 1.8754  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 4.1696  Validation loss = 1.8749  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 4.1690  Validation loss = 1.8741  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 4.1687  Validation loss = 1.8738  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 4.1684  Validation loss = 1.8734  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 4.1681  Validation loss = 1.8731  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 4.1677  Validation loss = 1.8726  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 4.1673  Validation loss = 1.8722  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 4.1669  Validation loss = 1.8716  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 4.1665  Validation loss = 1.8711  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 4.1662  Validation loss = 1.8707  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 4.1658  Validation loss = 1.8703  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 4.1655  Validation loss = 1.8698  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 4.1650  Validation loss = 1.8692  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 4.1646  Validation loss = 1.8687  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 4.1642  Validation loss = 1.8680  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 4.1639  Validation loss = 1.8676  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 4.1635  Validation loss = 1.8673  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 4.1631  Validation loss = 1.8667  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 4.1629  Validation loss = 1.8663  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 4.1626  Validation loss = 1.8661  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 4.1623  Validation loss = 1.8658  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 4.1620  Validation loss = 1.8655  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 4.1616  Validation loss = 1.8651  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 4.1612  Validation loss = 1.8647  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 4.1609  Validation loss = 1.8643  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 4.1606  Validation loss = 1.8638  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 4.1603  Validation loss = 1.8635  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 4.1598  Validation loss = 1.8631  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 4.1595  Validation loss = 1.8628  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 4.1591  Validation loss = 1.8622  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 4.1587  Validation loss = 1.8619  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 4.1583  Validation loss = 1.8615  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 4.1579  Validation loss = 1.8609  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 4.1577  Validation loss = 1.8605  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 4.1574  Validation loss = 1.8602  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 4.1571  Validation loss = 1.8599  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 4.1567  Validation loss = 1.8594  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 4.1563  Validation loss = 1.8590  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 4.1560  Validation loss = 1.8585  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 4.1557  Validation loss = 1.8581  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 4.1553  Validation loss = 1.8577  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 4.1550  Validation loss = 1.8573  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 4.1547  Validation loss = 1.8569  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 4.1543  Validation loss = 1.8566  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 4.1540  Validation loss = 1.8562  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 4.1536  Validation loss = 1.8556  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 4.1533  Validation loss = 1.8552  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 4.1530  Validation loss = 1.8549  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 4.1526  Validation loss = 1.8544  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 4.1521  Validation loss = 1.8539  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 4.1518  Validation loss = 1.8536  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 4.1514  Validation loss = 1.8532  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 4.1511  Validation loss = 1.8528  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 4.1508  Validation loss = 1.8525  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 4.1505  Validation loss = 1.8520  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 4.1501  Validation loss = 1.8516  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 4.1497  Validation loss = 1.8510  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 4.1493  Validation loss = 1.8506  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 4.1489  Validation loss = 1.8500  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 4.1486  Validation loss = 1.8498  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 4.1481  Validation loss = 1.8492  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 4.1477  Validation loss = 1.8485  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 4.1473  Validation loss = 1.8482  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 4.1469  Validation loss = 1.8476  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 4.1466  Validation loss = 1.8472  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 4.1463  Validation loss = 1.8470  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 4.1459  Validation loss = 1.8464  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 4.1456  Validation loss = 1.8461  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 4.1454  Validation loss = 1.8456  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 4.1451  Validation loss = 1.8453  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 4.1447  Validation loss = 1.8448  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 4.1444  Validation loss = 1.8444  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 4.1439  Validation loss = 1.8439  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 4.1435  Validation loss = 1.8434  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 4.1432  Validation loss = 1.8430  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 4.1430  Validation loss = 1.8426  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 4.1426  Validation loss = 1.8421  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 4.1423  Validation loss = 1.8416  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 4.1419  Validation loss = 1.8412  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 4.1416  Validation loss = 1.8408  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 4.1412  Validation loss = 1.8403  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 4.1408  Validation loss = 1.8399  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 4.1406  Validation loss = 1.8396  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 4.1402  Validation loss = 1.8391  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 4.1399  Validation loss = 1.8387  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 4.1396  Validation loss = 1.8384  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 4.1394  Validation loss = 1.8381  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 4.1389  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 4.1385  Validation loss = 1.8370  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 4.1383  Validation loss = 1.8368  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 4.1379  Validation loss = 1.8363  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 4.1376  Validation loss = 1.8360  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 4.1372  Validation loss = 1.8356  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 4.1370  Validation loss = 1.8354  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 4.1364  Validation loss = 1.8348  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 4.1361  Validation loss = 1.8344  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 4.1356  Validation loss = 1.8338  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 4.1353  Validation loss = 1.8335  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 4.1350  Validation loss = 1.8329  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 4.1346  Validation loss = 1.8325  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 4.1343  Validation loss = 1.8321  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 4.1342  Validation loss = 1.8319  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 4.1340  Validation loss = 1.8319  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 4.1337  Validation loss = 1.8314  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 4.1334  Validation loss = 1.8310  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 4.1330  Validation loss = 1.8307  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 4.1328  Validation loss = 1.8305  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 4.1325  Validation loss = 1.8301  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 4.1321  Validation loss = 1.8296  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 4.1318  Validation loss = 1.8293  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 4.1314  Validation loss = 1.8288  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 4.1310  Validation loss = 1.8284  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 4.1307  Validation loss = 1.8279  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 4.1303  Validation loss = 1.8274  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 4.1300  Validation loss = 1.8271  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 4.1298  Validation loss = 1.8268  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 4.1295  Validation loss = 1.8264  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 4.1292  Validation loss = 1.8261  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 4.1289  Validation loss = 1.8257  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 4.1286  Validation loss = 1.8253  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 4.1284  Validation loss = 1.8250  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 4.1280  Validation loss = 1.8246  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 4.1277  Validation loss = 1.8240  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 4.1273  Validation loss = 1.8237  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 4.1269  Validation loss = 1.8230  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 4.1264  Validation loss = 1.8225  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 4.1259  Validation loss = 1.8219  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 4.1256  Validation loss = 1.8216  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 4.1253  Validation loss = 1.8213  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 4.1250  Validation loss = 1.8209  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 4.1246  Validation loss = 1.8203  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 4.1243  Validation loss = 1.8198  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 4.1239  Validation loss = 1.8194  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 4.1238  Validation loss = 1.8192  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 4.1234  Validation loss = 1.8188  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 4.1230  Validation loss = 1.8183  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 4.1228  Validation loss = 1.8180  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 4.1225  Validation loss = 1.8177  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 4.1222  Validation loss = 1.8175  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 4.1218  Validation loss = 1.8170  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 4.1215  Validation loss = 1.8167  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 4.1212  Validation loss = 1.8163  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 4.1210  Validation loss = 1.8159  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 4.1207  Validation loss = 1.8154  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 4.1203  Validation loss = 1.8150  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 4.1200  Validation loss = 1.8148  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 4.1197  Validation loss = 1.8145  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 4.1194  Validation loss = 1.8141  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 4.1189  Validation loss = 1.8136  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 4.1185  Validation loss = 1.8129  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 4.1183  Validation loss = 1.8126  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 4.1179  Validation loss = 1.8121  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 4.1175  Validation loss = 1.8115  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 4.1172  Validation loss = 1.8111  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 4.1169  Validation loss = 1.8108  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 4.1166  Validation loss = 1.8105  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 4.1162  Validation loss = 1.8101  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 4.1158  Validation loss = 1.8096  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 4.1156  Validation loss = 1.8094  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 4.1151  Validation loss = 1.8089  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 4.1148  Validation loss = 1.8086  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 4.1144  Validation loss = 1.8081  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 4.1141  Validation loss = 1.8078  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 4.1140  Validation loss = 1.8077  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 4.1135  Validation loss = 1.8071  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 4.1132  Validation loss = 1.8068  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 4.1130  Validation loss = 1.8065  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 4.1125  Validation loss = 1.8060  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 4.1121  Validation loss = 1.8054  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 4.1119  Validation loss = 1.8050  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 4.1116  Validation loss = 1.8047  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 4.1113  Validation loss = 1.8045  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 4.1110  Validation loss = 1.8042  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 4.1106  Validation loss = 1.8036  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 4.1102  Validation loss = 1.8032  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 4.1100  Validation loss = 1.8028  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 4.1096  Validation loss = 1.8023  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 4.1093  Validation loss = 1.8020  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 4.1090  Validation loss = 1.8016  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 4.1086  Validation loss = 1.8010  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 4.1083  Validation loss = 1.8005  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 4.1079  Validation loss = 1.8002  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 4.1076  Validation loss = 1.7997  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 4.1075  Validation loss = 1.7997  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 4.1071  Validation loss = 1.7994  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 4.1068  Validation loss = 1.7990  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 4.1065  Validation loss = 1.7987  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 4.1061  Validation loss = 1.7983  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 4.1059  Validation loss = 1.7982  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 4.1055  Validation loss = 1.7978  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 4.1052  Validation loss = 1.7972  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 4.1048  Validation loss = 1.7968  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 4.1045  Validation loss = 1.7964  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 4.1042  Validation loss = 1.7959  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 4.1039  Validation loss = 1.7956  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 4.1035  Validation loss = 1.7953  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 4.1030  Validation loss = 1.7948  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 4.1027  Validation loss = 1.7943  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 4.1024  Validation loss = 1.7940  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 4.1021  Validation loss = 1.7937  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 4.1017  Validation loss = 1.7933  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 4.1013  Validation loss = 1.7930  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 4.1011  Validation loss = 1.7927  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 4.1007  Validation loss = 1.7921  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 4.1004  Validation loss = 1.7917  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 4.1000  Validation loss = 1.7912  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 4.0997  Validation loss = 1.7909  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 4.0994  Validation loss = 1.7906  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 4.0991  Validation loss = 1.7903  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 4.0987  Validation loss = 1.7898  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 4.0984  Validation loss = 1.7895  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 4.0981  Validation loss = 1.7892  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 4.0978  Validation loss = 1.7887  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 4.0974  Validation loss = 1.7882  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 4.0969  Validation loss = 1.7877  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 4.0967  Validation loss = 1.7875  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 4.0963  Validation loss = 1.7870  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 4.0960  Validation loss = 1.7867  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 4.0957  Validation loss = 1.7864  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 4.0954  Validation loss = 1.7860  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 4.0951  Validation loss = 1.7855  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 4.0947  Validation loss = 1.7850  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 4.0944  Validation loss = 1.7847  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 4.0940  Validation loss = 1.7842  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 4.0937  Validation loss = 1.7838  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 4.0935  Validation loss = 1.7833  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 4.0931  Validation loss = 1.7828  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 4.0927  Validation loss = 1.7823  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 4.0923  Validation loss = 1.7818  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 4.0920  Validation loss = 1.7815  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 4.0917  Validation loss = 1.7809  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 4.0914  Validation loss = 1.7806  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 4.0912  Validation loss = 1.7803  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 4.0909  Validation loss = 1.7800  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 4.0906  Validation loss = 1.7796  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 4.0902  Validation loss = 1.7792  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 4.0899  Validation loss = 1.7788  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 4.0896  Validation loss = 1.7785  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 4.0893  Validation loss = 1.7782  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 4.0891  Validation loss = 1.7777  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 4.0888  Validation loss = 1.7776  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 4.0884  Validation loss = 1.7771  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 4.0881  Validation loss = 1.7767  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 4.0877  Validation loss = 1.7762  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 4.0874  Validation loss = 1.7758  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 4.0870  Validation loss = 1.7753  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 4.0867  Validation loss = 1.7750  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 4.0864  Validation loss = 1.7746  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 4.0860  Validation loss = 1.7742  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 4.0857  Validation loss = 1.7740  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 4.0854  Validation loss = 1.7736  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 4.0851  Validation loss = 1.7733  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 4.0848  Validation loss = 1.7729  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 4.0845  Validation loss = 1.7725  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 4.0842  Validation loss = 1.7722  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 4.0838  Validation loss = 1.7718  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 4.0834  Validation loss = 1.7713  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 4.0832  Validation loss = 1.7710  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 4.0829  Validation loss = 1.7707  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 4.0826  Validation loss = 1.7704  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 4.0823  Validation loss = 1.7700  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 4.0820  Validation loss = 1.7694  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 4.0816  Validation loss = 1.7690  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 4.0812  Validation loss = 1.7687  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 4.0809  Validation loss = 1.7683  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 4.0805  Validation loss = 1.7679  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 4.0802  Validation loss = 1.7675  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 4.0799  Validation loss = 1.7670  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 4.0797  Validation loss = 1.7668  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 4.0793  Validation loss = 1.7664  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 4.0790  Validation loss = 1.7660  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 4.0787  Validation loss = 1.7655  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 4.0783  Validation loss = 1.7651  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 4.0779  Validation loss = 1.7647  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 4.0776  Validation loss = 1.7644  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 4.0773  Validation loss = 1.7638  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 4.0769  Validation loss = 1.7634  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 4.0765  Validation loss = 1.7629  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 4.0761  Validation loss = 1.7624  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 4.0758  Validation loss = 1.7620  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 4.0754  Validation loss = 1.7617  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 4.0751  Validation loss = 1.7612  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 4.0748  Validation loss = 1.7608  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 4.0745  Validation loss = 1.7605  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 4.0742  Validation loss = 1.7601  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 4.0740  Validation loss = 1.7599  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 4.0736  Validation loss = 1.7595  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 4.0732  Validation loss = 1.7590  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 4.0729  Validation loss = 1.7586  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 4.0726  Validation loss = 1.7582  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 4.0722  Validation loss = 1.7577  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 4.0719  Validation loss = 1.7573  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 4.0716  Validation loss = 1.7569  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 4.0712  Validation loss = 1.7565  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 4.0709  Validation loss = 1.7561  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 4.0705  Validation loss = 1.7556  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 4.0701  Validation loss = 1.7551  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 4.0697  Validation loss = 1.7546  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 4.0694  Validation loss = 1.7542  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 4.0691  Validation loss = 1.7538  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 4.0687  Validation loss = 1.7532  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 4.0684  Validation loss = 1.7529  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 4.0681  Validation loss = 1.7527  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 4.0678  Validation loss = 1.7525  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 4.0674  Validation loss = 1.7520  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 4.0672  Validation loss = 1.7518  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 4.0667  Validation loss = 1.7514  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 4.0663  Validation loss = 1.7509  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 4.0659  Validation loss = 1.7503  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 4.0656  Validation loss = 1.7503  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 4.0651  Validation loss = 1.7501  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 500  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 4.0236  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 4.0233  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 4.0230  Validation loss = 2.5491  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 4.0226  Validation loss = 2.5488  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 4.0223  Validation loss = 2.5484  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 4.0221  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 4.0218  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 4.0215  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 4.0211  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 4.0208  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 4.0205  Validation loss = 2.5464  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 4.0202  Validation loss = 2.5460  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 4.0200  Validation loss = 2.5458  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 4.0197  Validation loss = 2.5455  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 4.0194  Validation loss = 2.5451  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 4.0191  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 4.0188  Validation loss = 2.5446  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 4.0186  Validation loss = 2.5443  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 4.0181  Validation loss = 2.5438  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 4.0178  Validation loss = 2.5435  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 4.0175  Validation loss = 2.5430  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 4.0171  Validation loss = 2.5426  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 4.0168  Validation loss = 2.5423  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 4.0165  Validation loss = 2.5419  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 4.0163  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 4.0160  Validation loss = 2.5416  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 4.0156  Validation loss = 2.5412  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 4.0153  Validation loss = 2.5409  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 4.0151  Validation loss = 2.5407  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 4.0147  Validation loss = 2.5403  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 4.0145  Validation loss = 2.5402  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 4.0143  Validation loss = 2.5399  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 4.0140  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 4.0138  Validation loss = 2.5394  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 4.0134  Validation loss = 2.5390  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 4.0131  Validation loss = 2.5386  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 4.0127  Validation loss = 2.5382  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 4.0123  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 4.0120  Validation loss = 2.5374  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 4.0116  Validation loss = 2.5371  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 4.0113  Validation loss = 2.5367  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 4.0110  Validation loss = 2.5364  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 4.0107  Validation loss = 2.5361  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 4.0105  Validation loss = 2.5359  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 4.0102  Validation loss = 2.5355  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 4.0098  Validation loss = 2.5350  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 4.0096  Validation loss = 2.5348  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 4.0093  Validation loss = 2.5345  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 4.0090  Validation loss = 2.5341  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 4.0087  Validation loss = 2.5337  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 4.0084  Validation loss = 2.5334  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 4.0080  Validation loss = 2.5331  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 4.0077  Validation loss = 2.5327  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 4.0074  Validation loss = 2.5324  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 4.0072  Validation loss = 2.5321  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 4.0069  Validation loss = 2.5318  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 4.0067  Validation loss = 2.5316  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 4.0065  Validation loss = 2.5314  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 4.0062  Validation loss = 2.5310  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 4.0058  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 4.0056  Validation loss = 2.5303  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 4.0054  Validation loss = 2.5301  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 4.0050  Validation loss = 2.5297  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 4.0046  Validation loss = 2.5293  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 4.0043  Validation loss = 2.5291  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 4.0040  Validation loss = 2.5288  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 4.0037  Validation loss = 2.5285  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 4.0033  Validation loss = 2.5280  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 4.0030  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 4.0028  Validation loss = 2.5274  \n",
      "\n",
      "Fold: 25  Epoch: 71  Training loss = 4.0027  Validation loss = 2.5273  \n",
      "\n",
      "Fold: 25  Epoch: 72  Training loss = 4.0025  Validation loss = 2.5270  \n",
      "\n",
      "Fold: 25  Epoch: 73  Training loss = 4.0023  Validation loss = 2.5269  \n",
      "\n",
      "Fold: 25  Epoch: 74  Training loss = 4.0021  Validation loss = 2.5267  \n",
      "\n",
      "Fold: 25  Epoch: 75  Training loss = 4.0017  Validation loss = 2.5263  \n",
      "\n",
      "Fold: 25  Epoch: 76  Training loss = 4.0015  Validation loss = 2.5261  \n",
      "\n",
      "Fold: 25  Epoch: 77  Training loss = 4.0011  Validation loss = 2.5258  \n",
      "\n",
      "Fold: 25  Epoch: 78  Training loss = 4.0009  Validation loss = 2.5255  \n",
      "\n",
      "Fold: 25  Epoch: 79  Training loss = 4.0007  Validation loss = 2.5253  \n",
      "\n",
      "Fold: 25  Epoch: 80  Training loss = 4.0004  Validation loss = 2.5250  \n",
      "\n",
      "Fold: 25  Epoch: 81  Training loss = 4.0001  Validation loss = 2.5247  \n",
      "\n",
      "Fold: 25  Epoch: 82  Training loss = 4.0000  Validation loss = 2.5245  \n",
      "\n",
      "Fold: 25  Epoch: 83  Training loss = 3.9997  Validation loss = 2.5242  \n",
      "\n",
      "Fold: 25  Epoch: 84  Training loss = 3.9994  Validation loss = 2.5238  \n",
      "\n",
      "Fold: 25  Epoch: 85  Training loss = 3.9992  Validation loss = 2.5236  \n",
      "\n",
      "Fold: 25  Epoch: 86  Training loss = 3.9989  Validation loss = 2.5233  \n",
      "\n",
      "Fold: 25  Epoch: 87  Training loss = 3.9985  Validation loss = 2.5229  \n",
      "\n",
      "Fold: 25  Epoch: 88  Training loss = 3.9981  Validation loss = 2.5224  \n",
      "\n",
      "Fold: 25  Epoch: 89  Training loss = 3.9979  Validation loss = 2.5222  \n",
      "\n",
      "Fold: 25  Epoch: 90  Training loss = 3.9976  Validation loss = 2.5219  \n",
      "\n",
      "Fold: 25  Epoch: 91  Training loss = 3.9973  Validation loss = 2.5216  \n",
      "\n",
      "Fold: 25  Epoch: 92  Training loss = 3.9969  Validation loss = 2.5212  \n",
      "\n",
      "Fold: 25  Epoch: 93  Training loss = 3.9967  Validation loss = 2.5210  \n",
      "\n",
      "Fold: 25  Epoch: 94  Training loss = 3.9964  Validation loss = 2.5207  \n",
      "\n",
      "Fold: 25  Epoch: 95  Training loss = 3.9962  Validation loss = 2.5204  \n",
      "\n",
      "Fold: 25  Epoch: 96  Training loss = 3.9959  Validation loss = 2.5200  \n",
      "\n",
      "Fold: 25  Epoch: 97  Training loss = 3.9956  Validation loss = 2.5197  \n",
      "\n",
      "Fold: 25  Epoch: 98  Training loss = 3.9953  Validation loss = 2.5193  \n",
      "\n",
      "Fold: 25  Epoch: 99  Training loss = 3.9950  Validation loss = 2.5190  \n",
      "\n",
      "Fold: 25  Epoch: 100  Training loss = 3.9947  Validation loss = 2.5187  \n",
      "\n",
      "Fold: 25  Epoch: 101  Training loss = 3.9946  Validation loss = 2.5186  \n",
      "\n",
      "Fold: 25  Epoch: 102  Training loss = 3.9943  Validation loss = 2.5182  \n",
      "\n",
      "Fold: 25  Epoch: 103  Training loss = 3.9939  Validation loss = 2.5178  \n",
      "\n",
      "Fold: 25  Epoch: 104  Training loss = 3.9936  Validation loss = 2.5176  \n",
      "\n",
      "Fold: 25  Epoch: 105  Training loss = 3.9934  Validation loss = 2.5174  \n",
      "\n",
      "Fold: 25  Epoch: 106  Training loss = 3.9931  Validation loss = 2.5171  \n",
      "\n",
      "Fold: 25  Epoch: 107  Training loss = 3.9928  Validation loss = 2.5168  \n",
      "\n",
      "Fold: 25  Epoch: 108  Training loss = 3.9925  Validation loss = 2.5164  \n",
      "\n",
      "Fold: 25  Epoch: 109  Training loss = 3.9921  Validation loss = 2.5159  \n",
      "\n",
      "Fold: 25  Epoch: 110  Training loss = 3.9918  Validation loss = 2.5156  \n",
      "\n",
      "Fold: 25  Epoch: 111  Training loss = 3.9916  Validation loss = 2.5154  \n",
      "\n",
      "Fold: 25  Epoch: 112  Training loss = 3.9913  Validation loss = 2.5150  \n",
      "\n",
      "Fold: 25  Epoch: 113  Training loss = 3.9911  Validation loss = 2.5149  \n",
      "\n",
      "Fold: 25  Epoch: 114  Training loss = 3.9909  Validation loss = 2.5146  \n",
      "\n",
      "Fold: 25  Epoch: 115  Training loss = 3.9907  Validation loss = 2.5143  \n",
      "\n",
      "Fold: 25  Epoch: 116  Training loss = 3.9904  Validation loss = 2.5140  \n",
      "\n",
      "Fold: 25  Epoch: 117  Training loss = 3.9901  Validation loss = 2.5136  \n",
      "\n",
      "Fold: 25  Epoch: 118  Training loss = 3.9898  Validation loss = 2.5134  \n",
      "\n",
      "Fold: 25  Epoch: 119  Training loss = 3.9896  Validation loss = 2.5131  \n",
      "\n",
      "Fold: 25  Epoch: 120  Training loss = 3.9894  Validation loss = 2.5129  \n",
      "\n",
      "Fold: 25  Epoch: 121  Training loss = 3.9891  Validation loss = 2.5126  \n",
      "\n",
      "Fold: 25  Epoch: 122  Training loss = 3.9888  Validation loss = 2.5122  \n",
      "\n",
      "Fold: 25  Epoch: 123  Training loss = 3.9885  Validation loss = 2.5119  \n",
      "\n",
      "Fold: 25  Epoch: 124  Training loss = 3.9881  Validation loss = 2.5116  \n",
      "\n",
      "Fold: 25  Epoch: 125  Training loss = 3.9878  Validation loss = 2.5113  \n",
      "\n",
      "Fold: 25  Epoch: 126  Training loss = 3.9876  Validation loss = 2.5110  \n",
      "\n",
      "Fold: 25  Epoch: 127  Training loss = 3.9873  Validation loss = 2.5108  \n",
      "\n",
      "Fold: 25  Epoch: 128  Training loss = 3.9871  Validation loss = 2.5105  \n",
      "\n",
      "Fold: 25  Epoch: 129  Training loss = 3.9870  Validation loss = 2.5104  \n",
      "\n",
      "Fold: 25  Epoch: 130  Training loss = 3.9867  Validation loss = 2.5101  \n",
      "\n",
      "Fold: 25  Epoch: 131  Training loss = 3.9864  Validation loss = 2.5098  \n",
      "\n",
      "Fold: 25  Epoch: 132  Training loss = 3.9861  Validation loss = 2.5095  \n",
      "\n",
      "Fold: 25  Epoch: 133  Training loss = 3.9859  Validation loss = 2.5093  \n",
      "\n",
      "Fold: 25  Epoch: 134  Training loss = 3.9856  Validation loss = 2.5090  \n",
      "\n",
      "Fold: 25  Epoch: 135  Training loss = 3.9853  Validation loss = 2.5087  \n",
      "\n",
      "Fold: 25  Epoch: 136  Training loss = 3.9850  Validation loss = 2.5081  \n",
      "\n",
      "Fold: 25  Epoch: 137  Training loss = 3.9847  Validation loss = 2.5079  \n",
      "\n",
      "Fold: 25  Epoch: 138  Training loss = 3.9845  Validation loss = 2.5078  \n",
      "\n",
      "Fold: 25  Epoch: 139  Training loss = 3.9842  Validation loss = 2.5075  \n",
      "\n",
      "Fold: 25  Epoch: 140  Training loss = 3.9839  Validation loss = 2.5071  \n",
      "\n",
      "Fold: 25  Epoch: 141  Training loss = 3.9836  Validation loss = 2.5068  \n",
      "\n",
      "Fold: 25  Epoch: 142  Training loss = 3.9833  Validation loss = 2.5064  \n",
      "\n",
      "Fold: 25  Epoch: 143  Training loss = 3.9831  Validation loss = 2.5061  \n",
      "\n",
      "Fold: 25  Epoch: 144  Training loss = 3.9828  Validation loss = 2.5059  \n",
      "\n",
      "Fold: 25  Epoch: 145  Training loss = 3.9825  Validation loss = 2.5055  \n",
      "\n",
      "Fold: 25  Epoch: 146  Training loss = 3.9822  Validation loss = 2.5053  \n",
      "\n",
      "Fold: 25  Epoch: 147  Training loss = 3.9820  Validation loss = 2.5051  \n",
      "\n",
      "Fold: 25  Epoch: 148  Training loss = 3.9817  Validation loss = 2.5048  \n",
      "\n",
      "Fold: 25  Epoch: 149  Training loss = 3.9814  Validation loss = 2.5045  \n",
      "\n",
      "Fold: 25  Epoch: 150  Training loss = 3.9811  Validation loss = 2.5042  \n",
      "\n",
      "Fold: 25  Epoch: 151  Training loss = 3.9808  Validation loss = 2.5040  \n",
      "\n",
      "Fold: 25  Epoch: 152  Training loss = 3.9806  Validation loss = 2.5037  \n",
      "\n",
      "Fold: 25  Epoch: 153  Training loss = 3.9803  Validation loss = 2.5034  \n",
      "\n",
      "Fold: 25  Epoch: 154  Training loss = 3.9800  Validation loss = 2.5030  \n",
      "\n",
      "Fold: 25  Epoch: 155  Training loss = 3.9797  Validation loss = 2.5028  \n",
      "\n",
      "Fold: 25  Epoch: 156  Training loss = 3.9794  Validation loss = 2.5024  \n",
      "\n",
      "Fold: 25  Epoch: 157  Training loss = 3.9791  Validation loss = 2.5021  \n",
      "\n",
      "Fold: 25  Epoch: 158  Training loss = 3.9788  Validation loss = 2.5017  \n",
      "\n",
      "Fold: 25  Epoch: 159  Training loss = 3.9785  Validation loss = 2.5014  \n",
      "\n",
      "Fold: 25  Epoch: 160  Training loss = 3.9783  Validation loss = 2.5012  \n",
      "\n",
      "Fold: 25  Epoch: 161  Training loss = 3.9780  Validation loss = 2.5009  \n",
      "\n",
      "Fold: 25  Epoch: 162  Training loss = 3.9777  Validation loss = 2.5006  \n",
      "\n",
      "Fold: 25  Epoch: 163  Training loss = 3.9775  Validation loss = 2.5003  \n",
      "\n",
      "Fold: 25  Epoch: 164  Training loss = 3.9772  Validation loss = 2.5000  \n",
      "\n",
      "Fold: 25  Epoch: 165  Training loss = 3.9769  Validation loss = 2.4997  \n",
      "\n",
      "Fold: 25  Epoch: 166  Training loss = 3.9766  Validation loss = 2.4994  \n",
      "\n",
      "Fold: 25  Epoch: 167  Training loss = 3.9763  Validation loss = 2.4991  \n",
      "\n",
      "Fold: 25  Epoch: 168  Training loss = 3.9761  Validation loss = 2.4987  \n",
      "\n",
      "Fold: 25  Epoch: 169  Training loss = 3.9758  Validation loss = 2.4985  \n",
      "\n",
      "Fold: 25  Epoch: 170  Training loss = 3.9754  Validation loss = 2.4981  \n",
      "\n",
      "Fold: 25  Epoch: 171  Training loss = 3.9751  Validation loss = 2.4977  \n",
      "\n",
      "Fold: 25  Epoch: 172  Training loss = 3.9748  Validation loss = 2.4973  \n",
      "\n",
      "Fold: 25  Epoch: 173  Training loss = 3.9745  Validation loss = 2.4970  \n",
      "\n",
      "Fold: 25  Epoch: 174  Training loss = 3.9742  Validation loss = 2.4966  \n",
      "\n",
      "Fold: 25  Epoch: 175  Training loss = 3.9740  Validation loss = 2.4964  \n",
      "\n",
      "Fold: 25  Epoch: 176  Training loss = 3.9738  Validation loss = 2.4961  \n",
      "\n",
      "Fold: 25  Epoch: 177  Training loss = 3.9735  Validation loss = 2.4958  \n",
      "\n",
      "Fold: 25  Epoch: 178  Training loss = 3.9732  Validation loss = 2.4956  \n",
      "\n",
      "Fold: 25  Epoch: 179  Training loss = 3.9730  Validation loss = 2.4956  \n",
      "\n",
      "Fold: 25  Epoch: 180  Training loss = 3.9728  Validation loss = 2.4953  \n",
      "\n",
      "Fold: 25  Epoch: 181  Training loss = 3.9724  Validation loss = 2.4950  \n",
      "\n",
      "Fold: 25  Epoch: 182  Training loss = 3.9722  Validation loss = 2.4948  \n",
      "\n",
      "Fold: 25  Epoch: 183  Training loss = 3.9718  Validation loss = 2.4945  \n",
      "\n",
      "Fold: 25  Epoch: 184  Training loss = 3.9715  Validation loss = 2.4941  \n",
      "\n",
      "Fold: 25  Epoch: 185  Training loss = 3.9713  Validation loss = 2.4939  \n",
      "\n",
      "Fold: 25  Epoch: 186  Training loss = 3.9710  Validation loss = 2.4936  \n",
      "\n",
      "Fold: 25  Epoch: 187  Training loss = 3.9707  Validation loss = 2.4932  \n",
      "\n",
      "Fold: 25  Epoch: 188  Training loss = 3.9704  Validation loss = 2.4929  \n",
      "\n",
      "Fold: 25  Epoch: 189  Training loss = 3.9701  Validation loss = 2.4928  \n",
      "\n",
      "Fold: 25  Epoch: 190  Training loss = 3.9698  Validation loss = 2.4925  \n",
      "\n",
      "Fold: 25  Epoch: 191  Training loss = 3.9696  Validation loss = 2.4922  \n",
      "\n",
      "Fold: 25  Epoch: 192  Training loss = 3.9692  Validation loss = 2.4919  \n",
      "\n",
      "Fold: 25  Epoch: 193  Training loss = 3.9689  Validation loss = 2.4917  \n",
      "\n",
      "Fold: 25  Epoch: 194  Training loss = 3.9687  Validation loss = 2.4915  \n",
      "\n",
      "Fold: 25  Epoch: 195  Training loss = 3.9684  Validation loss = 2.4911  \n",
      "\n",
      "Fold: 25  Epoch: 196  Training loss = 3.9681  Validation loss = 2.4909  \n",
      "\n",
      "Fold: 25  Epoch: 197  Training loss = 3.9678  Validation loss = 2.4905  \n",
      "\n",
      "Fold: 25  Epoch: 198  Training loss = 3.9676  Validation loss = 2.4902  \n",
      "\n",
      "Fold: 25  Epoch: 199  Training loss = 3.9673  Validation loss = 2.4899  \n",
      "\n",
      "Fold: 25  Epoch: 200  Training loss = 3.9670  Validation loss = 2.4895  \n",
      "\n",
      "Fold: 25  Epoch: 201  Training loss = 3.9667  Validation loss = 2.4892  \n",
      "\n",
      "Fold: 25  Epoch: 202  Training loss = 3.9664  Validation loss = 2.4889  \n",
      "\n",
      "Fold: 25  Epoch: 203  Training loss = 3.9661  Validation loss = 2.4886  \n",
      "\n",
      "Fold: 25  Epoch: 204  Training loss = 3.9659  Validation loss = 2.4884  \n",
      "\n",
      "Fold: 25  Epoch: 205  Training loss = 3.9656  Validation loss = 2.4881  \n",
      "\n",
      "Fold: 25  Epoch: 206  Training loss = 3.9653  Validation loss = 2.4879  \n",
      "\n",
      "Fold: 25  Epoch: 207  Training loss = 3.9649  Validation loss = 2.4875  \n",
      "\n",
      "Fold: 25  Epoch: 208  Training loss = 3.9647  Validation loss = 2.4872  \n",
      "\n",
      "Fold: 25  Epoch: 209  Training loss = 3.9644  Validation loss = 2.4868  \n",
      "\n",
      "Fold: 25  Epoch: 210  Training loss = 3.9641  Validation loss = 2.4866  \n",
      "\n",
      "Fold: 25  Epoch: 211  Training loss = 3.9639  Validation loss = 2.4863  \n",
      "\n",
      "Fold: 25  Epoch: 212  Training loss = 3.9637  Validation loss = 2.4860  \n",
      "\n",
      "Fold: 25  Epoch: 213  Training loss = 3.9635  Validation loss = 2.4858  \n",
      "\n",
      "Fold: 25  Epoch: 214  Training loss = 3.9633  Validation loss = 2.4857  \n",
      "\n",
      "Fold: 25  Epoch: 215  Training loss = 3.9631  Validation loss = 2.4855  \n",
      "\n",
      "Fold: 25  Epoch: 216  Training loss = 3.9627  Validation loss = 2.4851  \n",
      "\n",
      "Fold: 25  Epoch: 217  Training loss = 3.9625  Validation loss = 2.4849  \n",
      "\n",
      "Fold: 25  Epoch: 218  Training loss = 3.9622  Validation loss = 2.4846  \n",
      "\n",
      "Fold: 25  Epoch: 219  Training loss = 3.9620  Validation loss = 2.4844  \n",
      "\n",
      "Fold: 25  Epoch: 220  Training loss = 3.9617  Validation loss = 2.4841  \n",
      "\n",
      "Fold: 25  Epoch: 221  Training loss = 3.9614  Validation loss = 2.4837  \n",
      "\n",
      "Fold: 25  Epoch: 222  Training loss = 3.9611  Validation loss = 2.4834  \n",
      "\n",
      "Fold: 25  Epoch: 223  Training loss = 3.9608  Validation loss = 2.4831  \n",
      "\n",
      "Fold: 25  Epoch: 224  Training loss = 3.9606  Validation loss = 2.4828  \n",
      "\n",
      "Fold: 25  Epoch: 225  Training loss = 3.9602  Validation loss = 2.4825  \n",
      "\n",
      "Fold: 25  Epoch: 226  Training loss = 3.9600  Validation loss = 2.4822  \n",
      "\n",
      "Fold: 25  Epoch: 227  Training loss = 3.9596  Validation loss = 2.4818  \n",
      "\n",
      "Fold: 25  Epoch: 228  Training loss = 3.9594  Validation loss = 2.4816  \n",
      "\n",
      "Fold: 25  Epoch: 229  Training loss = 3.9591  Validation loss = 2.4813  \n",
      "\n",
      "Fold: 25  Epoch: 230  Training loss = 3.9589  Validation loss = 2.4811  \n",
      "\n",
      "Fold: 25  Epoch: 231  Training loss = 3.9586  Validation loss = 2.4807  \n",
      "\n",
      "Fold: 25  Epoch: 232  Training loss = 3.9583  Validation loss = 2.4804  \n",
      "\n",
      "Fold: 25  Epoch: 233  Training loss = 3.9581  Validation loss = 2.4802  \n",
      "\n",
      "Fold: 25  Epoch: 234  Training loss = 3.9577  Validation loss = 2.4797  \n",
      "\n",
      "Fold: 25  Epoch: 235  Training loss = 3.9574  Validation loss = 2.4794  \n",
      "\n",
      "Fold: 25  Epoch: 236  Training loss = 3.9572  Validation loss = 2.4791  \n",
      "\n",
      "Fold: 25  Epoch: 237  Training loss = 3.9569  Validation loss = 2.4788  \n",
      "\n",
      "Fold: 25  Epoch: 238  Training loss = 3.9566  Validation loss = 2.4784  \n",
      "\n",
      "Fold: 25  Epoch: 239  Training loss = 3.9563  Validation loss = 2.4781  \n",
      "\n",
      "Fold: 25  Epoch: 240  Training loss = 3.9560  Validation loss = 2.4777  \n",
      "\n",
      "Fold: 25  Epoch: 241  Training loss = 3.9557  Validation loss = 2.4774  \n",
      "\n",
      "Fold: 25  Epoch: 242  Training loss = 3.9554  Validation loss = 2.4771  \n",
      "\n",
      "Fold: 25  Epoch: 243  Training loss = 3.9550  Validation loss = 2.4768  \n",
      "\n",
      "Fold: 25  Epoch: 244  Training loss = 3.9548  Validation loss = 2.4765  \n",
      "\n",
      "Fold: 25  Epoch: 245  Training loss = 3.9546  Validation loss = 2.4762  \n",
      "\n",
      "Fold: 25  Epoch: 246  Training loss = 3.9543  Validation loss = 2.4759  \n",
      "\n",
      "Fold: 25  Epoch: 247  Training loss = 3.9541  Validation loss = 2.4758  \n",
      "\n",
      "Fold: 25  Epoch: 248  Training loss = 3.9540  Validation loss = 2.4757  \n",
      "\n",
      "Fold: 25  Epoch: 249  Training loss = 3.9537  Validation loss = 2.4755  \n",
      "\n",
      "Fold: 25  Epoch: 250  Training loss = 3.9534  Validation loss = 2.4752  \n",
      "\n",
      "Fold: 25  Epoch: 251  Training loss = 3.9531  Validation loss = 2.4750  \n",
      "\n",
      "Fold: 25  Epoch: 252  Training loss = 3.9529  Validation loss = 2.4747  \n",
      "\n",
      "Fold: 25  Epoch: 253  Training loss = 3.9527  Validation loss = 2.4746  \n",
      "\n",
      "Fold: 25  Epoch: 254  Training loss = 3.9524  Validation loss = 2.4742  \n",
      "\n",
      "Fold: 25  Epoch: 255  Training loss = 3.9522  Validation loss = 2.4740  \n",
      "\n",
      "Fold: 25  Epoch: 256  Training loss = 3.9520  Validation loss = 2.4738  \n",
      "\n",
      "Fold: 25  Epoch: 257  Training loss = 3.9517  Validation loss = 2.4735  \n",
      "\n",
      "Fold: 25  Epoch: 258  Training loss = 3.9514  Validation loss = 2.4731  \n",
      "\n",
      "Fold: 25  Epoch: 259  Training loss = 3.9511  Validation loss = 2.4728  \n",
      "\n",
      "Fold: 25  Epoch: 260  Training loss = 3.9508  Validation loss = 2.4725  \n",
      "\n",
      "Fold: 25  Epoch: 261  Training loss = 3.9505  Validation loss = 2.4723  \n",
      "\n",
      "Fold: 25  Epoch: 262  Training loss = 3.9501  Validation loss = 2.4719  \n",
      "\n",
      "Fold: 25  Epoch: 263  Training loss = 3.9500  Validation loss = 2.4717  \n",
      "\n",
      "Fold: 25  Epoch: 264  Training loss = 3.9497  Validation loss = 2.4714  \n",
      "\n",
      "Fold: 25  Epoch: 265  Training loss = 3.9495  Validation loss = 2.4712  \n",
      "\n",
      "Fold: 25  Epoch: 266  Training loss = 3.9492  Validation loss = 2.4709  \n",
      "\n",
      "Fold: 25  Epoch: 267  Training loss = 3.9491  Validation loss = 2.4708  \n",
      "\n",
      "Fold: 25  Epoch: 268  Training loss = 3.9488  Validation loss = 2.4706  \n",
      "\n",
      "Fold: 25  Epoch: 269  Training loss = 3.9485  Validation loss = 2.4702  \n",
      "\n",
      "Fold: 25  Epoch: 270  Training loss = 3.9481  Validation loss = 2.4698  \n",
      "\n",
      "Fold: 25  Epoch: 271  Training loss = 3.9479  Validation loss = 2.4697  \n",
      "\n",
      "Fold: 25  Epoch: 272  Training loss = 3.9477  Validation loss = 2.4694  \n",
      "\n",
      "Fold: 25  Epoch: 273  Training loss = 3.9475  Validation loss = 2.4692  \n",
      "\n",
      "Fold: 25  Epoch: 274  Training loss = 3.9472  Validation loss = 2.4689  \n",
      "\n",
      "Fold: 25  Epoch: 275  Training loss = 3.9469  Validation loss = 2.4686  \n",
      "\n",
      "Fold: 25  Epoch: 276  Training loss = 3.9467  Validation loss = 2.4684  \n",
      "\n",
      "Fold: 25  Epoch: 277  Training loss = 3.9464  Validation loss = 2.4681  \n",
      "\n",
      "Fold: 25  Epoch: 278  Training loss = 3.9461  Validation loss = 2.4679  \n",
      "\n",
      "Fold: 25  Epoch: 279  Training loss = 3.9458  Validation loss = 2.4676  \n",
      "\n",
      "Fold: 25  Epoch: 280  Training loss = 3.9455  Validation loss = 2.4672  \n",
      "\n",
      "Fold: 25  Epoch: 281  Training loss = 3.9452  Validation loss = 2.4670  \n",
      "\n",
      "Fold: 25  Epoch: 282  Training loss = 3.9449  Validation loss = 2.4667  \n",
      "\n",
      "Fold: 25  Epoch: 283  Training loss = 3.9447  Validation loss = 2.4664  \n",
      "\n",
      "Fold: 25  Epoch: 284  Training loss = 3.9445  Validation loss = 2.4662  \n",
      "\n",
      "Fold: 25  Epoch: 285  Training loss = 3.9443  Validation loss = 2.4659  \n",
      "\n",
      "Fold: 25  Epoch: 286  Training loss = 3.9439  Validation loss = 2.4656  \n",
      "\n",
      "Fold: 25  Epoch: 287  Training loss = 3.9437  Validation loss = 2.4653  \n",
      "\n",
      "Fold: 25  Epoch: 288  Training loss = 3.9434  Validation loss = 2.4650  \n",
      "\n",
      "Fold: 25  Epoch: 289  Training loss = 3.9431  Validation loss = 2.4646  \n",
      "\n",
      "Fold: 25  Epoch: 290  Training loss = 3.9429  Validation loss = 2.4644  \n",
      "\n",
      "Fold: 25  Epoch: 291  Training loss = 3.9425  Validation loss = 2.4641  \n",
      "\n",
      "Fold: 25  Epoch: 292  Training loss = 3.9422  Validation loss = 2.4637  \n",
      "\n",
      "Fold: 25  Epoch: 293  Training loss = 3.9419  Validation loss = 2.4633  \n",
      "\n",
      "Fold: 25  Epoch: 294  Training loss = 3.9417  Validation loss = 2.4632  \n",
      "\n",
      "Fold: 25  Epoch: 295  Training loss = 3.9415  Validation loss = 2.4629  \n",
      "\n",
      "Fold: 25  Epoch: 296  Training loss = 3.9411  Validation loss = 2.4626  \n",
      "\n",
      "Fold: 25  Epoch: 297  Training loss = 3.9409  Validation loss = 2.4624  \n",
      "\n",
      "Fold: 25  Epoch: 298  Training loss = 3.9406  Validation loss = 2.4620  \n",
      "\n",
      "Fold: 25  Epoch: 299  Training loss = 3.9404  Validation loss = 2.4617  \n",
      "\n",
      "Fold: 25  Epoch: 300  Training loss = 3.9401  Validation loss = 2.4613  \n",
      "\n",
      "Fold: 25  Epoch: 301  Training loss = 3.9399  Validation loss = 2.4611  \n",
      "\n",
      "Fold: 25  Epoch: 302  Training loss = 3.9396  Validation loss = 2.4609  \n",
      "\n",
      "Fold: 25  Epoch: 303  Training loss = 3.9395  Validation loss = 2.4608  \n",
      "\n",
      "Fold: 25  Epoch: 304  Training loss = 3.9392  Validation loss = 2.4604  \n",
      "\n",
      "Fold: 25  Epoch: 305  Training loss = 3.9389  Validation loss = 2.4601  \n",
      "\n",
      "Fold: 25  Epoch: 306  Training loss = 3.9386  Validation loss = 2.4596  \n",
      "\n",
      "Fold: 25  Epoch: 307  Training loss = 3.9383  Validation loss = 2.4593  \n",
      "\n",
      "Fold: 25  Epoch: 308  Training loss = 3.9380  Validation loss = 2.4589  \n",
      "\n",
      "Fold: 25  Epoch: 309  Training loss = 3.9378  Validation loss = 2.4587  \n",
      "\n",
      "Fold: 25  Epoch: 310  Training loss = 3.9375  Validation loss = 2.4585  \n",
      "\n",
      "Fold: 25  Epoch: 311  Training loss = 3.9372  Validation loss = 2.4580  \n",
      "\n",
      "Fold: 25  Epoch: 312  Training loss = 3.9368  Validation loss = 2.4577  \n",
      "\n",
      "Fold: 25  Epoch: 313  Training loss = 3.9366  Validation loss = 2.4574  \n",
      "\n",
      "Fold: 25  Epoch: 314  Training loss = 3.9363  Validation loss = 2.4572  \n",
      "\n",
      "Fold: 25  Epoch: 315  Training loss = 3.9361  Validation loss = 2.4570  \n",
      "\n",
      "Fold: 25  Epoch: 316  Training loss = 3.9359  Validation loss = 2.4568  \n",
      "\n",
      "Fold: 25  Epoch: 317  Training loss = 3.9357  Validation loss = 2.4565  \n",
      "\n",
      "Fold: 25  Epoch: 318  Training loss = 3.9354  Validation loss = 2.4562  \n",
      "\n",
      "Fold: 25  Epoch: 319  Training loss = 3.9351  Validation loss = 2.4559  \n",
      "\n",
      "Fold: 25  Epoch: 320  Training loss = 3.9348  Validation loss = 2.4556  \n",
      "\n",
      "Fold: 25  Epoch: 321  Training loss = 3.9345  Validation loss = 2.4553  \n",
      "\n",
      "Fold: 25  Epoch: 322  Training loss = 3.9342  Validation loss = 2.4548  \n",
      "\n",
      "Fold: 25  Epoch: 323  Training loss = 3.9339  Validation loss = 2.4545  \n",
      "\n",
      "Fold: 25  Epoch: 324  Training loss = 3.9336  Validation loss = 2.4543  \n",
      "\n",
      "Fold: 25  Epoch: 325  Training loss = 3.9334  Validation loss = 2.4540  \n",
      "\n",
      "Fold: 25  Epoch: 326  Training loss = 3.9332  Validation loss = 2.4539  \n",
      "\n",
      "Fold: 25  Epoch: 327  Training loss = 3.9329  Validation loss = 2.4535  \n",
      "\n",
      "Fold: 25  Epoch: 328  Training loss = 3.9327  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 25  Epoch: 329  Training loss = 3.9326  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 25  Epoch: 330  Training loss = 3.9323  Validation loss = 2.4530  \n",
      "\n",
      "Fold: 25  Epoch: 331  Training loss = 3.9320  Validation loss = 2.4527  \n",
      "\n",
      "Fold: 25  Epoch: 332  Training loss = 3.9318  Validation loss = 2.4524  \n",
      "\n",
      "Fold: 25  Epoch: 333  Training loss = 3.9314  Validation loss = 2.4520  \n",
      "\n",
      "Fold: 25  Epoch: 334  Training loss = 3.9311  Validation loss = 2.4516  \n",
      "\n",
      "Fold: 25  Epoch: 335  Training loss = 3.9306  Validation loss = 2.4512  \n",
      "\n",
      "Fold: 25  Epoch: 336  Training loss = 3.9304  Validation loss = 2.4509  \n",
      "\n",
      "Fold: 25  Epoch: 337  Training loss = 3.9301  Validation loss = 2.4506  \n",
      "\n",
      "Fold: 25  Epoch: 338  Training loss = 3.9298  Validation loss = 2.4504  \n",
      "\n",
      "Fold: 25  Epoch: 339  Training loss = 3.9296  Validation loss = 2.4502  \n",
      "\n",
      "Fold: 25  Epoch: 340  Training loss = 3.9294  Validation loss = 2.4499  \n",
      "\n",
      "Fold: 25  Epoch: 341  Training loss = 3.9292  Validation loss = 2.4496  \n",
      "\n",
      "Fold: 25  Epoch: 342  Training loss = 3.9289  Validation loss = 2.4494  \n",
      "\n",
      "Fold: 25  Epoch: 343  Training loss = 3.9287  Validation loss = 2.4491  \n",
      "\n",
      "Fold: 25  Epoch: 344  Training loss = 3.9284  Validation loss = 2.4489  \n",
      "\n",
      "Fold: 25  Epoch: 345  Training loss = 3.9282  Validation loss = 2.4486  \n",
      "\n",
      "Fold: 25  Epoch: 346  Training loss = 3.9279  Validation loss = 2.4483  \n",
      "\n",
      "Fold: 25  Epoch: 347  Training loss = 3.9275  Validation loss = 2.4480  \n",
      "\n",
      "Fold: 25  Epoch: 348  Training loss = 3.9273  Validation loss = 2.4478  \n",
      "\n",
      "Fold: 25  Epoch: 349  Training loss = 3.9271  Validation loss = 2.4476  \n",
      "\n",
      "Fold: 25  Epoch: 350  Training loss = 3.9268  Validation loss = 2.4472  \n",
      "\n",
      "Fold: 25  Epoch: 351  Training loss = 3.9265  Validation loss = 2.4469  \n",
      "\n",
      "Fold: 25  Epoch: 352  Training loss = 3.9263  Validation loss = 2.4466  \n",
      "\n",
      "Fold: 25  Epoch: 353  Training loss = 3.9260  Validation loss = 2.4463  \n",
      "\n",
      "Fold: 25  Epoch: 354  Training loss = 3.9258  Validation loss = 2.4461  \n",
      "\n",
      "Fold: 25  Epoch: 355  Training loss = 3.9255  Validation loss = 2.4457  \n",
      "\n",
      "Fold: 25  Epoch: 356  Training loss = 3.9252  Validation loss = 2.4454  \n",
      "\n",
      "Fold: 25  Epoch: 357  Training loss = 3.9249  Validation loss = 2.4451  \n",
      "\n",
      "Fold: 25  Epoch: 358  Training loss = 3.9246  Validation loss = 2.4447  \n",
      "\n",
      "Fold: 25  Epoch: 359  Training loss = 3.9243  Validation loss = 2.4444  \n",
      "\n",
      "Fold: 25  Epoch: 360  Training loss = 3.9240  Validation loss = 2.4441  \n",
      "\n",
      "Fold: 25  Epoch: 361  Training loss = 3.9238  Validation loss = 2.4439  \n",
      "\n",
      "Fold: 25  Epoch: 362  Training loss = 3.9236  Validation loss = 2.4436  \n",
      "\n",
      "Fold: 25  Epoch: 363  Training loss = 3.9234  Validation loss = 2.4435  \n",
      "\n",
      "Fold: 25  Epoch: 364  Training loss = 3.9230  Validation loss = 2.4430  \n",
      "\n",
      "Fold: 25  Epoch: 365  Training loss = 3.9228  Validation loss = 2.4428  \n",
      "\n",
      "Fold: 25  Epoch: 366  Training loss = 3.9226  Validation loss = 2.4426  \n",
      "\n",
      "Fold: 25  Epoch: 367  Training loss = 3.9223  Validation loss = 2.4424  \n",
      "\n",
      "Fold: 25  Epoch: 368  Training loss = 3.9221  Validation loss = 2.4422  \n",
      "\n",
      "Fold: 25  Epoch: 369  Training loss = 3.9217  Validation loss = 2.4418  \n",
      "\n",
      "Fold: 25  Epoch: 370  Training loss = 3.9214  Validation loss = 2.4415  \n",
      "\n",
      "Fold: 25  Epoch: 371  Training loss = 3.9212  Validation loss = 2.4413  \n",
      "\n",
      "Fold: 25  Epoch: 372  Training loss = 3.9210  Validation loss = 2.4411  \n",
      "\n",
      "Fold: 25  Epoch: 373  Training loss = 3.9208  Validation loss = 2.4410  \n",
      "\n",
      "Fold: 25  Epoch: 374  Training loss = 3.9205  Validation loss = 2.4407  \n",
      "\n",
      "Fold: 25  Epoch: 375  Training loss = 3.9203  Validation loss = 2.4404  \n",
      "\n",
      "Fold: 25  Epoch: 376  Training loss = 3.9200  Validation loss = 2.4400  \n",
      "\n",
      "Fold: 25  Epoch: 377  Training loss = 3.9198  Validation loss = 2.4399  \n",
      "\n",
      "Fold: 25  Epoch: 378  Training loss = 3.9197  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 25  Epoch: 379  Training loss = 3.9193  Validation loss = 2.4394  \n",
      "\n",
      "Fold: 25  Epoch: 380  Training loss = 3.9190  Validation loss = 2.4391  \n",
      "\n",
      "Fold: 25  Epoch: 381  Training loss = 3.9187  Validation loss = 2.4387  \n",
      "\n",
      "Fold: 25  Epoch: 382  Training loss = 3.9185  Validation loss = 2.4386  \n",
      "\n",
      "Fold: 25  Epoch: 383  Training loss = 3.9183  Validation loss = 2.4383  \n",
      "\n",
      "Fold: 25  Epoch: 384  Training loss = 3.9180  Validation loss = 2.4380  \n",
      "\n",
      "Fold: 25  Epoch: 385  Training loss = 3.9178  Validation loss = 2.4377  \n",
      "\n",
      "Fold: 25  Epoch: 386  Training loss = 3.9176  Validation loss = 2.4376  \n",
      "\n",
      "Fold: 25  Epoch: 387  Training loss = 3.9172  Validation loss = 2.4373  \n",
      "\n",
      "Fold: 25  Epoch: 388  Training loss = 3.9171  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 25  Epoch: 389  Training loss = 3.9169  Validation loss = 2.4369  \n",
      "\n",
      "Fold: 25  Epoch: 390  Training loss = 3.9167  Validation loss = 2.4367  \n",
      "\n",
      "Fold: 25  Epoch: 391  Training loss = 3.9165  Validation loss = 2.4365  \n",
      "\n",
      "Fold: 25  Epoch: 392  Training loss = 3.9163  Validation loss = 2.4363  \n",
      "\n",
      "Fold: 25  Epoch: 393  Training loss = 3.9160  Validation loss = 2.4360  \n",
      "\n",
      "Fold: 25  Epoch: 394  Training loss = 3.9158  Validation loss = 2.4358  \n",
      "\n",
      "Fold: 25  Epoch: 395  Training loss = 3.9155  Validation loss = 2.4353  \n",
      "\n",
      "Fold: 25  Epoch: 396  Training loss = 3.9152  Validation loss = 2.4350  \n",
      "\n",
      "Fold: 25  Epoch: 397  Training loss = 3.9150  Validation loss = 2.4347  \n",
      "\n",
      "Fold: 25  Epoch: 398  Training loss = 3.9147  Validation loss = 2.4343  \n",
      "\n",
      "Fold: 25  Epoch: 399  Training loss = 3.9144  Validation loss = 2.4341  \n",
      "\n",
      "Fold: 25  Epoch: 400  Training loss = 3.9142  Validation loss = 2.4338  \n",
      "\n",
      "Fold: 25  Epoch: 401  Training loss = 3.9140  Validation loss = 2.4336  \n",
      "\n",
      "Fold: 25  Epoch: 402  Training loss = 3.9138  Validation loss = 2.4333  \n",
      "\n",
      "Fold: 25  Epoch: 403  Training loss = 3.9135  Validation loss = 2.4331  \n",
      "\n",
      "Fold: 25  Epoch: 404  Training loss = 3.9133  Validation loss = 2.4328  \n",
      "\n",
      "Fold: 25  Epoch: 405  Training loss = 3.9131  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 25  Epoch: 406  Training loss = 3.9127  Validation loss = 2.4322  \n",
      "\n",
      "Fold: 25  Epoch: 407  Training loss = 3.9125  Validation loss = 2.4320  \n",
      "\n",
      "Fold: 25  Epoch: 408  Training loss = 3.9123  Validation loss = 2.4318  \n",
      "\n",
      "Fold: 25  Epoch: 409  Training loss = 3.9122  Validation loss = 2.4316  \n",
      "\n",
      "Fold: 25  Epoch: 410  Training loss = 3.9118  Validation loss = 2.4313  \n",
      "\n",
      "Fold: 25  Epoch: 411  Training loss = 3.9116  Validation loss = 2.4311  \n",
      "\n",
      "Fold: 25  Epoch: 412  Training loss = 3.9114  Validation loss = 2.4309  \n",
      "\n",
      "Fold: 25  Epoch: 413  Training loss = 3.9111  Validation loss = 2.4306  \n",
      "\n",
      "Fold: 25  Epoch: 414  Training loss = 3.9109  Validation loss = 2.4303  \n",
      "\n",
      "Fold: 25  Epoch: 415  Training loss = 3.9107  Validation loss = 2.4301  \n",
      "\n",
      "Fold: 25  Epoch: 416  Training loss = 3.9104  Validation loss = 2.4299  \n",
      "\n",
      "Fold: 25  Epoch: 417  Training loss = 3.9101  Validation loss = 2.4295  \n",
      "\n",
      "Fold: 25  Epoch: 418  Training loss = 3.9099  Validation loss = 2.4293  \n",
      "\n",
      "Fold: 25  Epoch: 419  Training loss = 3.9098  Validation loss = 2.4292  \n",
      "\n",
      "Fold: 25  Epoch: 420  Training loss = 3.9095  Validation loss = 2.4288  \n",
      "\n",
      "Fold: 25  Epoch: 421  Training loss = 3.9093  Validation loss = 2.4287  \n",
      "\n",
      "Fold: 25  Epoch: 422  Training loss = 3.9090  Validation loss = 2.4285  \n",
      "\n",
      "Fold: 25  Epoch: 423  Training loss = 3.9088  Validation loss = 2.4281  \n",
      "\n",
      "Fold: 25  Epoch: 424  Training loss = 3.9085  Validation loss = 2.4278  \n",
      "\n",
      "Fold: 25  Epoch: 425  Training loss = 3.9083  Validation loss = 2.4276  \n",
      "\n",
      "Fold: 25  Epoch: 426  Training loss = 3.9081  Validation loss = 2.4273  \n",
      "\n",
      "Fold: 25  Epoch: 427  Training loss = 3.9079  Validation loss = 2.4272  \n",
      "\n",
      "Fold: 25  Epoch: 428  Training loss = 3.9076  Validation loss = 2.4269  \n",
      "\n",
      "Fold: 25  Epoch: 429  Training loss = 3.9073  Validation loss = 2.4266  \n",
      "\n",
      "Fold: 25  Epoch: 430  Training loss = 3.9070  Validation loss = 2.4263  \n",
      "\n",
      "Fold: 25  Epoch: 431  Training loss = 3.9068  Validation loss = 2.4260  \n",
      "\n",
      "Fold: 25  Epoch: 432  Training loss = 3.9065  Validation loss = 2.4257  \n",
      "\n",
      "Fold: 25  Epoch: 433  Training loss = 3.9063  Validation loss = 2.4255  \n",
      "\n",
      "Fold: 25  Epoch: 434  Training loss = 3.9060  Validation loss = 2.4252  \n",
      "\n",
      "Fold: 25  Epoch: 435  Training loss = 3.9057  Validation loss = 2.4248  \n",
      "\n",
      "Fold: 25  Epoch: 436  Training loss = 3.9055  Validation loss = 2.4246  \n",
      "\n",
      "Fold: 25  Epoch: 437  Training loss = 3.9052  Validation loss = 2.4243  \n",
      "\n",
      "Fold: 25  Epoch: 438  Training loss = 3.9050  Validation loss = 2.4241  \n",
      "\n",
      "Fold: 25  Epoch: 439  Training loss = 3.9047  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 25  Epoch: 440  Training loss = 3.9044  Validation loss = 2.4235  \n",
      "\n",
      "Fold: 25  Epoch: 441  Training loss = 3.9041  Validation loss = 2.4231  \n",
      "\n",
      "Fold: 25  Epoch: 442  Training loss = 3.9038  Validation loss = 2.4229  \n",
      "\n",
      "Fold: 25  Epoch: 443  Training loss = 3.9036  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 25  Epoch: 444  Training loss = 3.9034  Validation loss = 2.4224  \n",
      "\n",
      "Fold: 25  Epoch: 445  Training loss = 3.9031  Validation loss = 2.4222  \n",
      "\n",
      "Fold: 25  Epoch: 446  Training loss = 3.9029  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 25  Epoch: 447  Training loss = 3.9026  Validation loss = 2.4216  \n",
      "\n",
      "Fold: 25  Epoch: 448  Training loss = 3.9023  Validation loss = 2.4213  \n",
      "\n",
      "Fold: 25  Epoch: 449  Training loss = 3.9021  Validation loss = 2.4211  \n",
      "\n",
      "Fold: 25  Epoch: 450  Training loss = 3.9018  Validation loss = 2.4208  \n",
      "\n",
      "Fold: 25  Epoch: 451  Training loss = 3.9016  Validation loss = 2.4205  \n",
      "\n",
      "Fold: 25  Epoch: 452  Training loss = 3.9014  Validation loss = 2.4203  \n",
      "\n",
      "Fold: 25  Epoch: 453  Training loss = 3.9011  Validation loss = 2.4201  \n",
      "\n",
      "Fold: 25  Epoch: 454  Training loss = 3.9008  Validation loss = 2.4198  \n",
      "\n",
      "Fold: 25  Epoch: 455  Training loss = 3.9005  Validation loss = 2.4195  \n",
      "\n",
      "Fold: 25  Epoch: 456  Training loss = 3.9002  Validation loss = 2.4192  \n",
      "\n",
      "Fold: 25  Epoch: 457  Training loss = 3.9000  Validation loss = 2.4190  \n",
      "\n",
      "Fold: 25  Epoch: 458  Training loss = 3.8999  Validation loss = 2.4188  \n",
      "\n",
      "Fold: 25  Epoch: 459  Training loss = 3.8997  Validation loss = 2.4186  \n",
      "\n",
      "Fold: 25  Epoch: 460  Training loss = 3.8995  Validation loss = 2.4183  \n",
      "\n",
      "Fold: 25  Epoch: 461  Training loss = 3.8992  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 25  Epoch: 462  Training loss = 3.8990  Validation loss = 2.4178  \n",
      "\n",
      "Fold: 25  Epoch: 463  Training loss = 3.8986  Validation loss = 2.4175  \n",
      "\n",
      "Fold: 25  Epoch: 464  Training loss = 3.8984  Validation loss = 2.4173  \n",
      "\n",
      "Fold: 25  Epoch: 465  Training loss = 3.8981  Validation loss = 2.4170  \n",
      "\n",
      "Fold: 25  Epoch: 466  Training loss = 3.8979  Validation loss = 2.4168  \n",
      "\n",
      "Fold: 25  Epoch: 467  Training loss = 3.8976  Validation loss = 2.4165  \n",
      "\n",
      "Fold: 25  Epoch: 468  Training loss = 3.8974  Validation loss = 2.4163  \n",
      "\n",
      "Fold: 25  Epoch: 469  Training loss = 3.8971  Validation loss = 2.4160  \n",
      "\n",
      "Fold: 25  Epoch: 470  Training loss = 3.8969  Validation loss = 2.4158  \n",
      "\n",
      "Fold: 25  Epoch: 471  Training loss = 3.8966  Validation loss = 2.4156  \n",
      "\n",
      "Fold: 25  Epoch: 472  Training loss = 3.8963  Validation loss = 2.4154  \n",
      "\n",
      "Fold: 25  Epoch: 473  Training loss = 3.8961  Validation loss = 2.4151  \n",
      "\n",
      "Fold: 25  Epoch: 474  Training loss = 3.8958  Validation loss = 2.4149  \n",
      "\n",
      "Fold: 25  Epoch: 475  Training loss = 3.8955  Validation loss = 2.4146  \n",
      "\n",
      "Fold: 25  Epoch: 476  Training loss = 3.8954  Validation loss = 2.4145  \n",
      "\n",
      "Fold: 25  Epoch: 477  Training loss = 3.8953  Validation loss = 2.4145  \n",
      "\n",
      "Fold: 25  Epoch: 478  Training loss = 3.8950  Validation loss = 2.4141  \n",
      "\n",
      "Fold: 25  Epoch: 479  Training loss = 3.8947  Validation loss = 2.4138  \n",
      "\n",
      "Fold: 25  Epoch: 480  Training loss = 3.8945  Validation loss = 2.4136  \n",
      "\n",
      "Fold: 25  Epoch: 481  Training loss = 3.8943  Validation loss = 2.4133  \n",
      "\n",
      "Fold: 25  Epoch: 482  Training loss = 3.8941  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 25  Epoch: 483  Training loss = 3.8939  Validation loss = 2.4128  \n",
      "\n",
      "Fold: 25  Epoch: 484  Training loss = 3.8937  Validation loss = 2.4127  \n",
      "\n",
      "Fold: 25  Epoch: 485  Training loss = 3.8936  Validation loss = 2.4126  \n",
      "\n",
      "Fold: 25  Epoch: 486  Training loss = 3.8933  Validation loss = 2.4123  \n",
      "\n",
      "Fold: 25  Epoch: 487  Training loss = 3.8931  Validation loss = 2.4120  \n",
      "\n",
      "Fold: 25  Epoch: 488  Training loss = 3.8928  Validation loss = 2.4118  \n",
      "\n",
      "Fold: 25  Epoch: 489  Training loss = 3.8926  Validation loss = 2.4114  \n",
      "\n",
      "Fold: 25  Epoch: 490  Training loss = 3.8923  Validation loss = 2.4111  \n",
      "\n",
      "Fold: 25  Epoch: 491  Training loss = 3.8921  Validation loss = 2.4109  \n",
      "\n",
      "Fold: 25  Epoch: 492  Training loss = 3.8920  Validation loss = 2.4107  \n",
      "\n",
      "Fold: 25  Epoch: 493  Training loss = 3.8918  Validation loss = 2.4105  \n",
      "\n",
      "Fold: 25  Epoch: 494  Training loss = 3.8915  Validation loss = 2.4102  \n",
      "\n",
      "Fold: 25  Epoch: 495  Training loss = 3.8913  Validation loss = 2.4100  \n",
      "\n",
      "Fold: 25  Epoch: 496  Training loss = 3.8911  Validation loss = 2.4098  \n",
      "\n",
      "Fold: 25  Epoch: 497  Training loss = 3.8909  Validation loss = 2.4097  \n",
      "\n",
      "Fold: 25  Epoch: 498  Training loss = 3.8907  Validation loss = 2.4095  \n",
      "\n",
      "Fold: 25  Epoch: 499  Training loss = 3.8904  Validation loss = 2.4091  \n",
      "\n",
      "Fold: 25  Epoch: 500  Training loss = 3.8901  Validation loss = 2.4088  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 500  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.6308  Validation loss = 1.8305  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.6307  Validation loss = 1.8303  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.6306  Validation loss = 1.8303  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.6305  Validation loss = 1.8304  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.6303  Validation loss = 1.8308  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.6301  Validation loss = 1.8309  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.6300  Validation loss = 1.8312  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.6298  Validation loss = 1.8315  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.6296  Validation loss = 1.8321  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.6294  Validation loss = 1.8323  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.6292  Validation loss = 1.8327  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 2  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.5134  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.5132  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.5130  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.5129  Validation loss = 1.2097  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.5127  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.5125  Validation loss = 1.2097  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.5124  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.5123  Validation loss = 1.2099  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.5121  Validation loss = 1.2099  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.5119  Validation loss = 1.2101  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.5118  Validation loss = 1.2102  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 6  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.5063  Validation loss = 2.0149  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.5061  Validation loss = 2.0150  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.5059  Validation loss = 2.0151  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.5057  Validation loss = 2.0152  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.5056  Validation loss = 2.0150  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.5055  Validation loss = 2.0151  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.5053  Validation loss = 2.0153  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.5051  Validation loss = 2.0154  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.5049  Validation loss = 2.0156  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.5048  Validation loss = 2.0154  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.5046  Validation loss = 2.0153  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.5044  Validation loss = 2.0153  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 3.5042  Validation loss = 2.0153  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 3.5040  Validation loss = 2.0154  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 3.5038  Validation loss = 2.0155  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 3.5037  Validation loss = 2.0154  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 3.5035  Validation loss = 2.0152  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 3.5033  Validation loss = 2.0153  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 3.5031  Validation loss = 2.0153  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 3.5028  Validation loss = 2.0154  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 3.5027  Validation loss = 2.0155  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 1  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.5166  Validation loss = 1.1867  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.5163  Validation loss = 1.1867  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.5162  Validation loss = 1.1868  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.5160  Validation loss = 1.1869  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.5158  Validation loss = 1.1870  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.5157  Validation loss = 1.1871  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.5156  Validation loss = 1.1870  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.5154  Validation loss = 1.1871  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.5152  Validation loss = 1.1872  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.5150  Validation loss = 1.1872  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.5147  Validation loss = 1.1873  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 1  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.4506  Validation loss = 2.0025  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.4505  Validation loss = 2.0022  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.4504  Validation loss = 2.0022  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.4502  Validation loss = 2.0020  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.4501  Validation loss = 2.0018  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.4499  Validation loss = 2.0015  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.4497  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.4495  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.4494  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.4492  Validation loss = 2.0009  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.4491  Validation loss = 2.0009  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.4489  Validation loss = 2.0011  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.4486  Validation loss = 2.0008  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 3.4484  Validation loss = 2.0005  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 3.4483  Validation loss = 2.0003  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 3.4481  Validation loss = 2.0002  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 3.4479  Validation loss = 2.0003  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 3.4478  Validation loss = 2.0001  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 3.4477  Validation loss = 2.0002  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 3.4476  Validation loss = 2.0001  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 3.4474  Validation loss = 2.0000  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 3.4472  Validation loss = 1.9998  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 3.4470  Validation loss = 1.9996  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 3.4468  Validation loss = 1.9992  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 3.4464  Validation loss = 1.9988  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 3.4462  Validation loss = 1.9986  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 3.4461  Validation loss = 1.9984  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 3.4460  Validation loss = 1.9983  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 3.4459  Validation loss = 1.9981  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 3.4457  Validation loss = 1.9976  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 3.4455  Validation loss = 1.9975  \n",
      "\n",
      "Fold: 30  Epoch: 32  Training loss = 3.4454  Validation loss = 1.9975  \n",
      "\n",
      "Fold: 30  Epoch: 33  Training loss = 3.4452  Validation loss = 1.9976  \n",
      "\n",
      "Fold: 30  Epoch: 34  Training loss = 3.4449  Validation loss = 1.9974  \n",
      "\n",
      "Fold: 30  Epoch: 35  Training loss = 3.4447  Validation loss = 1.9972  \n",
      "\n",
      "Fold: 30  Epoch: 36  Training loss = 3.4447  Validation loss = 1.9972  \n",
      "\n",
      "Fold: 30  Epoch: 37  Training loss = 3.4444  Validation loss = 1.9969  \n",
      "\n",
      "Fold: 30  Epoch: 38  Training loss = 3.4442  Validation loss = 1.9962  \n",
      "\n",
      "Fold: 30  Epoch: 39  Training loss = 3.4440  Validation loss = 1.9963  \n",
      "\n",
      "Fold: 30  Epoch: 40  Training loss = 3.4439  Validation loss = 1.9959  \n",
      "\n",
      "Fold: 30  Epoch: 41  Training loss = 3.4437  Validation loss = 1.9955  \n",
      "\n",
      "Fold: 30  Epoch: 42  Training loss = 3.4434  Validation loss = 1.9953  \n",
      "\n",
      "Fold: 30  Epoch: 43  Training loss = 3.4434  Validation loss = 1.9952  \n",
      "\n",
      "Fold: 30  Epoch: 44  Training loss = 3.4432  Validation loss = 1.9948  \n",
      "\n",
      "Fold: 30  Epoch: 45  Training loss = 3.4430  Validation loss = 1.9943  \n",
      "\n",
      "Fold: 30  Epoch: 46  Training loss = 3.4428  Validation loss = 1.9941  \n",
      "\n",
      "Fold: 30  Epoch: 47  Training loss = 3.4426  Validation loss = 1.9938  \n",
      "\n",
      "Fold: 30  Epoch: 48  Training loss = 3.4425  Validation loss = 1.9937  \n",
      "\n",
      "Fold: 30  Epoch: 49  Training loss = 3.4423  Validation loss = 1.9935  \n",
      "\n",
      "Fold: 30  Epoch: 50  Training loss = 3.4422  Validation loss = 1.9933  \n",
      "\n",
      "Fold: 30  Epoch: 51  Training loss = 3.4420  Validation loss = 1.9931  \n",
      "\n",
      "Fold: 30  Epoch: 52  Training loss = 3.4418  Validation loss = 1.9926  \n",
      "\n",
      "Fold: 30  Epoch: 53  Training loss = 3.4416  Validation loss = 1.9926  \n",
      "\n",
      "Fold: 30  Epoch: 54  Training loss = 3.4413  Validation loss = 1.9922  \n",
      "\n",
      "Fold: 30  Epoch: 55  Training loss = 3.4412  Validation loss = 1.9920  \n",
      "\n",
      "Fold: 30  Epoch: 56  Training loss = 3.4409  Validation loss = 1.9920  \n",
      "\n",
      "Fold: 30  Epoch: 57  Training loss = 3.4408  Validation loss = 1.9918  \n",
      "\n",
      "Fold: 30  Epoch: 58  Training loss = 3.4406  Validation loss = 1.9914  \n",
      "\n",
      "Fold: 30  Epoch: 59  Training loss = 3.4404  Validation loss = 1.9914  \n",
      "\n",
      "Fold: 30  Epoch: 60  Training loss = 3.4403  Validation loss = 1.9913  \n",
      "\n",
      "Fold: 30  Epoch: 61  Training loss = 3.4401  Validation loss = 1.9914  \n",
      "\n",
      "Fold: 30  Epoch: 62  Training loss = 3.4399  Validation loss = 1.9912  \n",
      "\n",
      "Fold: 30  Epoch: 63  Training loss = 3.4398  Validation loss = 1.9906  \n",
      "\n",
      "Fold: 30  Epoch: 64  Training loss = 3.4396  Validation loss = 1.9903  \n",
      "\n",
      "Fold: 30  Epoch: 65  Training loss = 3.4395  Validation loss = 1.9905  \n",
      "\n",
      "Fold: 30  Epoch: 66  Training loss = 3.4394  Validation loss = 1.9904  \n",
      "\n",
      "Fold: 30  Epoch: 67  Training loss = 3.4391  Validation loss = 1.9902  \n",
      "\n",
      "Fold: 30  Epoch: 68  Training loss = 3.4391  Validation loss = 1.9901  \n",
      "\n",
      "Fold: 30  Epoch: 69  Training loss = 3.4389  Validation loss = 1.9899  \n",
      "\n",
      "Fold: 30  Epoch: 70  Training loss = 3.4388  Validation loss = 1.9894  \n",
      "\n",
      "Fold: 30  Epoch: 71  Training loss = 3.4387  Validation loss = 1.9893  \n",
      "\n",
      "Fold: 30  Epoch: 72  Training loss = 3.4385  Validation loss = 1.9893  \n",
      "\n",
      "Fold: 30  Epoch: 73  Training loss = 3.4384  Validation loss = 1.9893  \n",
      "\n",
      "Fold: 30  Epoch: 74  Training loss = 3.4383  Validation loss = 1.9890  \n",
      "\n",
      "Fold: 30  Epoch: 75  Training loss = 3.4382  Validation loss = 1.9888  \n",
      "\n",
      "Fold: 30  Epoch: 76  Training loss = 3.4381  Validation loss = 1.9887  \n",
      "\n",
      "Fold: 30  Epoch: 77  Training loss = 3.4379  Validation loss = 1.9884  \n",
      "\n",
      "Fold: 30  Epoch: 78  Training loss = 3.4378  Validation loss = 1.9880  \n",
      "\n",
      "Fold: 30  Epoch: 79  Training loss = 3.4377  Validation loss = 1.9882  \n",
      "\n",
      "Fold: 30  Epoch: 80  Training loss = 3.4376  Validation loss = 1.9877  \n",
      "\n",
      "Fold: 30  Epoch: 81  Training loss = 3.4375  Validation loss = 1.9875  \n",
      "\n",
      "Fold: 30  Epoch: 82  Training loss = 3.4374  Validation loss = 1.9875  \n",
      "\n",
      "Fold: 30  Epoch: 83  Training loss = 3.4372  Validation loss = 1.9875  \n",
      "\n",
      "Fold: 30  Epoch: 84  Training loss = 3.4371  Validation loss = 1.9875  \n",
      "\n",
      "Fold: 30  Epoch: 85  Training loss = 3.4369  Validation loss = 1.9872  \n",
      "\n",
      "Fold: 30  Epoch: 86  Training loss = 3.4368  Validation loss = 1.9870  \n",
      "\n",
      "Fold: 30  Epoch: 87  Training loss = 3.4365  Validation loss = 1.9861  \n",
      "\n",
      "Fold: 30  Epoch: 88  Training loss = 3.4364  Validation loss = 1.9861  \n",
      "\n",
      "Fold: 30  Epoch: 89  Training loss = 3.4363  Validation loss = 1.9861  \n",
      "\n",
      "Fold: 30  Epoch: 90  Training loss = 3.4361  Validation loss = 1.9860  \n",
      "\n",
      "Fold: 30  Epoch: 91  Training loss = 3.4359  Validation loss = 1.9857  \n",
      "\n",
      "Fold: 30  Epoch: 92  Training loss = 3.4358  Validation loss = 1.9859  \n",
      "\n",
      "Fold: 30  Epoch: 93  Training loss = 3.4357  Validation loss = 1.9858  \n",
      "\n",
      "Fold: 30  Epoch: 94  Training loss = 3.4356  Validation loss = 1.9857  \n",
      "\n",
      "Fold: 30  Epoch: 95  Training loss = 3.4355  Validation loss = 1.9851  \n",
      "\n",
      "Fold: 30  Epoch: 96  Training loss = 3.4354  Validation loss = 1.9848  \n",
      "\n",
      "Fold: 30  Epoch: 97  Training loss = 3.4353  Validation loss = 1.9848  \n",
      "\n",
      "Fold: 30  Epoch: 98  Training loss = 3.4352  Validation loss = 1.9849  \n",
      "\n",
      "Fold: 30  Epoch: 99  Training loss = 3.4351  Validation loss = 1.9848  \n",
      "\n",
      "Fold: 30  Epoch: 100  Training loss = 3.4350  Validation loss = 1.9850  \n",
      "\n",
      "Fold: 30  Epoch: 101  Training loss = 3.4349  Validation loss = 1.9847  \n",
      "\n",
      "Fold: 30  Epoch: 102  Training loss = 3.4347  Validation loss = 1.9844  \n",
      "\n",
      "Fold: 30  Epoch: 103  Training loss = 3.4346  Validation loss = 1.9842  \n",
      "\n",
      "Fold: 30  Epoch: 104  Training loss = 3.4345  Validation loss = 1.9845  \n",
      "\n",
      "Fold: 30  Epoch: 105  Training loss = 3.4343  Validation loss = 1.9846  \n",
      "\n",
      "Fold: 30  Epoch: 106  Training loss = 3.4341  Validation loss = 1.9845  \n",
      "\n",
      "Fold: 30  Epoch: 107  Training loss = 3.4340  Validation loss = 1.9844  \n",
      "\n",
      "Fold: 30  Epoch: 108  Training loss = 3.4339  Validation loss = 1.9843  \n",
      "\n",
      "Fold: 30  Epoch: 109  Training loss = 3.4337  Validation loss = 1.9841  \n",
      "\n",
      "Fold: 30  Epoch: 110  Training loss = 3.4335  Validation loss = 1.9836  \n",
      "\n",
      "Fold: 30  Epoch: 111  Training loss = 3.4334  Validation loss = 1.9835  \n",
      "\n",
      "Fold: 30  Epoch: 112  Training loss = 3.4332  Validation loss = 1.9837  \n",
      "\n",
      "Fold: 30  Epoch: 113  Training loss = 3.4331  Validation loss = 1.9831  \n",
      "\n",
      "Fold: 30  Epoch: 114  Training loss = 3.4329  Validation loss = 1.9829  \n",
      "\n",
      "Fold: 30  Epoch: 115  Training loss = 3.4329  Validation loss = 1.9830  \n",
      "\n",
      "Fold: 30  Epoch: 116  Training loss = 3.4327  Validation loss = 1.9828  \n",
      "\n",
      "Fold: 30  Epoch: 117  Training loss = 3.4326  Validation loss = 1.9827  \n",
      "\n",
      "Fold: 30  Epoch: 118  Training loss = 3.4325  Validation loss = 1.9827  \n",
      "\n",
      "Fold: 30  Epoch: 119  Training loss = 3.4324  Validation loss = 1.9823  \n",
      "\n",
      "Fold: 30  Epoch: 120  Training loss = 3.4323  Validation loss = 1.9822  \n",
      "\n",
      "Fold: 30  Epoch: 121  Training loss = 3.4322  Validation loss = 1.9822  \n",
      "\n",
      "Fold: 30  Epoch: 122  Training loss = 3.4321  Validation loss = 1.9815  \n",
      "\n",
      "Fold: 30  Epoch: 123  Training loss = 3.4319  Validation loss = 1.9813  \n",
      "\n",
      "Fold: 30  Epoch: 124  Training loss = 3.4317  Validation loss = 1.9813  \n",
      "\n",
      "Fold: 30  Epoch: 125  Training loss = 3.4316  Validation loss = 1.9814  \n",
      "\n",
      "Fold: 30  Epoch: 126  Training loss = 3.4315  Validation loss = 1.9816  \n",
      "\n",
      "Fold: 30  Epoch: 127  Training loss = 3.4314  Validation loss = 1.9818  \n",
      "\n",
      "Fold: 30  Epoch: 128  Training loss = 3.4314  Validation loss = 1.9816  \n",
      "\n",
      "Fold: 30  Epoch: 129  Training loss = 3.4313  Validation loss = 1.9816  \n",
      "\n",
      "Fold: 30  Epoch: 130  Training loss = 3.4312  Validation loss = 1.9815  \n",
      "\n",
      "Fold: 30  Epoch: 131  Training loss = 3.4311  Validation loss = 1.9812  \n",
      "\n",
      "Fold: 30  Epoch: 132  Training loss = 3.4310  Validation loss = 1.9811  \n",
      "\n",
      "Fold: 30  Epoch: 133  Training loss = 3.4308  Validation loss = 1.9808  \n",
      "\n",
      "Fold: 30  Epoch: 134  Training loss = 3.4307  Validation loss = 1.9807  \n",
      "\n",
      "Fold: 30  Epoch: 135  Training loss = 3.4306  Validation loss = 1.9802  \n",
      "\n",
      "Fold: 30  Epoch: 136  Training loss = 3.4304  Validation loss = 1.9799  \n",
      "\n",
      "Fold: 30  Epoch: 137  Training loss = 3.4303  Validation loss = 1.9801  \n",
      "\n",
      "Fold: 30  Epoch: 138  Training loss = 3.4302  Validation loss = 1.9798  \n",
      "\n",
      "Fold: 30  Epoch: 139  Training loss = 3.4301  Validation loss = 1.9797  \n",
      "\n",
      "Fold: 30  Epoch: 140  Training loss = 3.4300  Validation loss = 1.9794  \n",
      "\n",
      "Fold: 30  Epoch: 141  Training loss = 3.4299  Validation loss = 1.9790  \n",
      "\n",
      "Fold: 30  Epoch: 142  Training loss = 3.4297  Validation loss = 1.9785  \n",
      "\n",
      "Fold: 30  Epoch: 143  Training loss = 3.4296  Validation loss = 1.9778  \n",
      "\n",
      "Fold: 30  Epoch: 144  Training loss = 3.4295  Validation loss = 1.9777  \n",
      "\n",
      "Fold: 30  Epoch: 145  Training loss = 3.4294  Validation loss = 1.9775  \n",
      "\n",
      "Fold: 30  Epoch: 146  Training loss = 3.4293  Validation loss = 1.9778  \n",
      "\n",
      "Fold: 30  Epoch: 147  Training loss = 3.4291  Validation loss = 1.9777  \n",
      "\n",
      "Fold: 30  Epoch: 148  Training loss = 3.4291  Validation loss = 1.9774  \n",
      "\n",
      "Fold: 30  Epoch: 149  Training loss = 3.4289  Validation loss = 1.9766  \n",
      "\n",
      "Fold: 30  Epoch: 150  Training loss = 3.4288  Validation loss = 1.9764  \n",
      "\n",
      "Fold: 30  Epoch: 151  Training loss = 3.4287  Validation loss = 1.9764  \n",
      "\n",
      "Fold: 30  Epoch: 152  Training loss = 3.4286  Validation loss = 1.9765  \n",
      "\n",
      "Fold: 30  Epoch: 153  Training loss = 3.4285  Validation loss = 1.9766  \n",
      "\n",
      "Fold: 30  Epoch: 154  Training loss = 3.4284  Validation loss = 1.9762  \n",
      "\n",
      "Fold: 30  Epoch: 155  Training loss = 3.4282  Validation loss = 1.9759  \n",
      "\n",
      "Fold: 30  Epoch: 156  Training loss = 3.4281  Validation loss = 1.9761  \n",
      "\n",
      "Fold: 30  Epoch: 157  Training loss = 3.4280  Validation loss = 1.9763  \n",
      "\n",
      "Fold: 30  Epoch: 158  Training loss = 3.4278  Validation loss = 1.9762  \n",
      "\n",
      "Fold: 30  Epoch: 159  Training loss = 3.4277  Validation loss = 1.9759  \n",
      "\n",
      "Fold: 30  Epoch: 160  Training loss = 3.4276  Validation loss = 1.9752  \n",
      "\n",
      "Fold: 30  Epoch: 161  Training loss = 3.4275  Validation loss = 1.9747  \n",
      "\n",
      "Fold: 30  Epoch: 162  Training loss = 3.4274  Validation loss = 1.9744  \n",
      "\n",
      "Fold: 30  Epoch: 163  Training loss = 3.4273  Validation loss = 1.9745  \n",
      "\n",
      "Fold: 30  Epoch: 164  Training loss = 3.4272  Validation loss = 1.9742  \n",
      "\n",
      "Fold: 30  Epoch: 165  Training loss = 3.4271  Validation loss = 1.9741  \n",
      "\n",
      "Fold: 30  Epoch: 166  Training loss = 3.4270  Validation loss = 1.9736  \n",
      "\n",
      "Fold: 30  Epoch: 167  Training loss = 3.4270  Validation loss = 1.9736  \n",
      "\n",
      "Fold: 30  Epoch: 168  Training loss = 3.4269  Validation loss = 1.9738  \n",
      "\n",
      "Fold: 30  Epoch: 169  Training loss = 3.4268  Validation loss = 1.9733  \n",
      "\n",
      "Fold: 30  Epoch: 170  Training loss = 3.4267  Validation loss = 1.9734  \n",
      "\n",
      "Fold: 30  Epoch: 171  Training loss = 3.4266  Validation loss = 1.9735  \n",
      "\n",
      "Fold: 30  Epoch: 172  Training loss = 3.4265  Validation loss = 1.9733  \n",
      "\n",
      "Fold: 30  Epoch: 173  Training loss = 3.4264  Validation loss = 1.9731  \n",
      "\n",
      "Fold: 30  Epoch: 174  Training loss = 3.4263  Validation loss = 1.9729  \n",
      "\n",
      "Fold: 30  Epoch: 175  Training loss = 3.4261  Validation loss = 1.9734  \n",
      "\n",
      "Fold: 30  Epoch: 176  Training loss = 3.4260  Validation loss = 1.9730  \n",
      "\n",
      "Fold: 30  Epoch: 177  Training loss = 3.4259  Validation loss = 1.9729  \n",
      "\n",
      "Fold: 30  Epoch: 178  Training loss = 3.4258  Validation loss = 1.9729  \n",
      "\n",
      "Fold: 30  Epoch: 179  Training loss = 3.4257  Validation loss = 1.9728  \n",
      "\n",
      "Fold: 30  Epoch: 180  Training loss = 3.4256  Validation loss = 1.9724  \n",
      "\n",
      "Fold: 30  Epoch: 181  Training loss = 3.4255  Validation loss = 1.9721  \n",
      "\n",
      "Fold: 30  Epoch: 182  Training loss = 3.4253  Validation loss = 1.9717  \n",
      "\n",
      "Fold: 30  Epoch: 183  Training loss = 3.4252  Validation loss = 1.9714  \n",
      "\n",
      "Fold: 30  Epoch: 184  Training loss = 3.4251  Validation loss = 1.9708  \n",
      "\n",
      "Fold: 30  Epoch: 185  Training loss = 3.4250  Validation loss = 1.9705  \n",
      "\n",
      "Fold: 30  Epoch: 186  Training loss = 3.4249  Validation loss = 1.9701  \n",
      "\n",
      "Fold: 30  Epoch: 187  Training loss = 3.4248  Validation loss = 1.9698  \n",
      "\n",
      "Fold: 30  Epoch: 188  Training loss = 3.4247  Validation loss = 1.9697  \n",
      "\n",
      "Fold: 30  Epoch: 189  Training loss = 3.4245  Validation loss = 1.9696  \n",
      "\n",
      "Fold: 30  Epoch: 190  Training loss = 3.4244  Validation loss = 1.9694  \n",
      "\n",
      "Fold: 30  Epoch: 191  Training loss = 3.4244  Validation loss = 1.9688  \n",
      "\n",
      "Fold: 30  Epoch: 192  Training loss = 3.4242  Validation loss = 1.9689  \n",
      "\n",
      "Fold: 30  Epoch: 193  Training loss = 3.4241  Validation loss = 1.9689  \n",
      "\n",
      "Fold: 30  Epoch: 194  Training loss = 3.4240  Validation loss = 1.9688  \n",
      "\n",
      "Fold: 30  Epoch: 195  Training loss = 3.4238  Validation loss = 1.9685  \n",
      "\n",
      "Fold: 30  Epoch: 196  Training loss = 3.4237  Validation loss = 1.9678  \n",
      "\n",
      "Fold: 30  Epoch: 197  Training loss = 3.4236  Validation loss = 1.9681  \n",
      "\n",
      "Fold: 30  Epoch: 198  Training loss = 3.4236  Validation loss = 1.9683  \n",
      "\n",
      "Fold: 30  Epoch: 199  Training loss = 3.4234  Validation loss = 1.9681  \n",
      "\n",
      "Fold: 30  Epoch: 200  Training loss = 3.4233  Validation loss = 1.9678  \n",
      "\n",
      "Fold: 30  Epoch: 201  Training loss = 3.4232  Validation loss = 1.9680  \n",
      "\n",
      "Fold: 30  Epoch: 202  Training loss = 3.4231  Validation loss = 1.9684  \n",
      "\n",
      "Fold: 30  Epoch: 203  Training loss = 3.4230  Validation loss = 1.9685  \n",
      "\n",
      "Fold: 30  Epoch: 204  Training loss = 3.4229  Validation loss = 1.9681  \n",
      "\n",
      "Fold: 30  Epoch: 205  Training loss = 3.4228  Validation loss = 1.9679  \n",
      "\n",
      "Fold: 30  Epoch: 206  Training loss = 3.4226  Validation loss = 1.9674  \n",
      "\n",
      "Fold: 30  Epoch: 207  Training loss = 3.4225  Validation loss = 1.9676  \n",
      "\n",
      "Fold: 30  Epoch: 208  Training loss = 3.4224  Validation loss = 1.9675  \n",
      "\n",
      "Fold: 30  Epoch: 209  Training loss = 3.4223  Validation loss = 1.9673  \n",
      "\n",
      "Fold: 30  Epoch: 210  Training loss = 3.4222  Validation loss = 1.9669  \n",
      "\n",
      "Fold: 30  Epoch: 211  Training loss = 3.4221  Validation loss = 1.9668  \n",
      "\n",
      "Fold: 30  Epoch: 212  Training loss = 3.4220  Validation loss = 1.9665  \n",
      "\n",
      "Fold: 30  Epoch: 213  Training loss = 3.4219  Validation loss = 1.9666  \n",
      "\n",
      "Fold: 30  Epoch: 214  Training loss = 3.4218  Validation loss = 1.9665  \n",
      "\n",
      "Fold: 30  Epoch: 215  Training loss = 3.4216  Validation loss = 1.9658  \n",
      "\n",
      "Fold: 30  Epoch: 216  Training loss = 3.4215  Validation loss = 1.9658  \n",
      "\n",
      "Fold: 30  Epoch: 217  Training loss = 3.4214  Validation loss = 1.9658  \n",
      "\n",
      "Fold: 30  Epoch: 218  Training loss = 3.4214  Validation loss = 1.9662  \n",
      "\n",
      "Fold: 30  Epoch: 219  Training loss = 3.4213  Validation loss = 1.9660  \n",
      "\n",
      "Fold: 30  Epoch: 220  Training loss = 3.4211  Validation loss = 1.9654  \n",
      "\n",
      "Fold: 30  Epoch: 221  Training loss = 3.4210  Validation loss = 1.9650  \n",
      "\n",
      "Fold: 30  Epoch: 222  Training loss = 3.4209  Validation loss = 1.9653  \n",
      "\n",
      "Fold: 30  Epoch: 223  Training loss = 3.4208  Validation loss = 1.9648  \n",
      "\n",
      "Fold: 30  Epoch: 224  Training loss = 3.4207  Validation loss = 1.9646  \n",
      "\n",
      "Fold: 30  Epoch: 225  Training loss = 3.4206  Validation loss = 1.9644  \n",
      "\n",
      "Fold: 30  Epoch: 226  Training loss = 3.4206  Validation loss = 1.9647  \n",
      "\n",
      "Fold: 30  Epoch: 227  Training loss = 3.4204  Validation loss = 1.9645  \n",
      "\n",
      "Fold: 30  Epoch: 228  Training loss = 3.4203  Validation loss = 1.9639  \n",
      "\n",
      "Fold: 30  Epoch: 229  Training loss = 3.4203  Validation loss = 1.9640  \n",
      "\n",
      "Fold: 30  Epoch: 230  Training loss = 3.4202  Validation loss = 1.9637  \n",
      "\n",
      "Fold: 30  Epoch: 231  Training loss = 3.4201  Validation loss = 1.9633  \n",
      "\n",
      "Fold: 30  Epoch: 232  Training loss = 3.4200  Validation loss = 1.9633  \n",
      "\n",
      "Fold: 30  Epoch: 233  Training loss = 3.4199  Validation loss = 1.9627  \n",
      "\n",
      "Fold: 30  Epoch: 234  Training loss = 3.4198  Validation loss = 1.9624  \n",
      "\n",
      "Fold: 30  Epoch: 235  Training loss = 3.4198  Validation loss = 1.9625  \n",
      "\n",
      "Fold: 30  Epoch: 236  Training loss = 3.4197  Validation loss = 1.9623  \n",
      "\n",
      "Fold: 30  Epoch: 237  Training loss = 3.4196  Validation loss = 1.9621  \n",
      "\n",
      "Fold: 30  Epoch: 238  Training loss = 3.4194  Validation loss = 1.9614  \n",
      "\n",
      "Fold: 30  Epoch: 239  Training loss = 3.4193  Validation loss = 1.9608  \n",
      "\n",
      "Fold: 30  Epoch: 240  Training loss = 3.4192  Validation loss = 1.9603  \n",
      "\n",
      "Fold: 30  Epoch: 241  Training loss = 3.4191  Validation loss = 1.9599  \n",
      "\n",
      "Fold: 30  Epoch: 242  Training loss = 3.4190  Validation loss = 1.9599  \n",
      "\n",
      "Fold: 30  Epoch: 243  Training loss = 3.4189  Validation loss = 1.9596  \n",
      "\n",
      "Fold: 30  Epoch: 244  Training loss = 3.4188  Validation loss = 1.9595  \n",
      "\n",
      "Fold: 30  Epoch: 245  Training loss = 3.4187  Validation loss = 1.9599  \n",
      "\n",
      "Fold: 30  Epoch: 246  Training loss = 3.4187  Validation loss = 1.9601  \n",
      "\n",
      "Fold: 30  Epoch: 247  Training loss = 3.4186  Validation loss = 1.9598  \n",
      "\n",
      "Fold: 30  Epoch: 248  Training loss = 3.4185  Validation loss = 1.9594  \n",
      "\n",
      "Fold: 30  Epoch: 249  Training loss = 3.4184  Validation loss = 1.9594  \n",
      "\n",
      "Fold: 30  Epoch: 250  Training loss = 3.4183  Validation loss = 1.9592  \n",
      "\n",
      "Fold: 30  Epoch: 251  Training loss = 3.4181  Validation loss = 1.9592  \n",
      "\n",
      "Fold: 30  Epoch: 252  Training loss = 3.4180  Validation loss = 1.9593  \n",
      "\n",
      "Fold: 30  Epoch: 253  Training loss = 3.4180  Validation loss = 1.9591  \n",
      "\n",
      "Fold: 30  Epoch: 254  Training loss = 3.4179  Validation loss = 1.9593  \n",
      "\n",
      "Fold: 30  Epoch: 255  Training loss = 3.4177  Validation loss = 1.9594  \n",
      "\n",
      "Fold: 30  Epoch: 256  Training loss = 3.4177  Validation loss = 1.9590  \n",
      "\n",
      "Fold: 30  Epoch: 257  Training loss = 3.4176  Validation loss = 1.9593  \n",
      "\n",
      "Fold: 30  Epoch: 258  Training loss = 3.4175  Validation loss = 1.9592  \n",
      "\n",
      "Fold: 30  Epoch: 259  Training loss = 3.4174  Validation loss = 1.9590  \n",
      "\n",
      "Fold: 30  Epoch: 260  Training loss = 3.4174  Validation loss = 1.9591  \n",
      "\n",
      "Fold: 30  Epoch: 261  Training loss = 3.4173  Validation loss = 1.9590  \n",
      "\n",
      "Fold: 30  Epoch: 262  Training loss = 3.4172  Validation loss = 1.9593  \n",
      "\n",
      "Fold: 30  Epoch: 263  Training loss = 3.4171  Validation loss = 1.9587  \n",
      "\n",
      "Fold: 30  Epoch: 264  Training loss = 3.4170  Validation loss = 1.9587  \n",
      "\n",
      "Fold: 30  Epoch: 265  Training loss = 3.4168  Validation loss = 1.9579  \n",
      "\n",
      "Fold: 30  Epoch: 266  Training loss = 3.4168  Validation loss = 1.9576  \n",
      "\n",
      "Fold: 30  Epoch: 267  Training loss = 3.4167  Validation loss = 1.9574  \n",
      "\n",
      "Fold: 30  Epoch: 268  Training loss = 3.4166  Validation loss = 1.9575  \n",
      "\n",
      "Fold: 30  Epoch: 269  Training loss = 3.4165  Validation loss = 1.9577  \n",
      "\n",
      "Fold: 30  Epoch: 270  Training loss = 3.4164  Validation loss = 1.9574  \n",
      "\n",
      "Fold: 30  Epoch: 271  Training loss = 3.4164  Validation loss = 1.9578  \n",
      "\n",
      "Fold: 30  Epoch: 272  Training loss = 3.4163  Validation loss = 1.9578  \n",
      "\n",
      "Fold: 30  Epoch: 273  Training loss = 3.4163  Validation loss = 1.9580  \n",
      "\n",
      "Fold: 30  Epoch: 274  Training loss = 3.4162  Validation loss = 1.9584  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 267  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 3.0739  Validation loss = 1.0800  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 3.0737  Validation loss = 1.0792  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 3.0736  Validation loss = 1.0790  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 3.0736  Validation loss = 1.0790  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 3.0734  Validation loss = 1.0792  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 3.0733  Validation loss = 1.0789  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 3.0732  Validation loss = 1.0787  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 3.0731  Validation loss = 1.0786  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 3.0730  Validation loss = 1.0784  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 3.0730  Validation loss = 1.0784  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 3.0729  Validation loss = 1.0783  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 3.0729  Validation loss = 1.0781  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 3.0728  Validation loss = 1.0781  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 3.0728  Validation loss = 1.0779  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 3.0727  Validation loss = 1.0780  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 3.0726  Validation loss = 1.0778  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 3.0724  Validation loss = 1.0774  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 3.0723  Validation loss = 1.0773  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 3.0722  Validation loss = 1.0771  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 3.0721  Validation loss = 1.0770  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 3.0720  Validation loss = 1.0771  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 3.0719  Validation loss = 1.0768  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 3.0718  Validation loss = 1.0770  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 3.0718  Validation loss = 1.0768  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 3.0717  Validation loss = 1.0768  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 3.0717  Validation loss = 1.0767  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 3.0716  Validation loss = 1.0764  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 3.0715  Validation loss = 1.0764  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 3.0715  Validation loss = 1.0764  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 3.0714  Validation loss = 1.0762  \n",
      "\n",
      "Fold: 31  Epoch: 31  Training loss = 3.0714  Validation loss = 1.0762  \n",
      "\n",
      "Fold: 31  Epoch: 32  Training loss = 3.0713  Validation loss = 1.0760  \n",
      "\n",
      "Fold: 31  Epoch: 33  Training loss = 3.0712  Validation loss = 1.0761  \n",
      "\n",
      "Fold: 31  Epoch: 34  Training loss = 3.0711  Validation loss = 1.0757  \n",
      "\n",
      "Fold: 31  Epoch: 35  Training loss = 3.0710  Validation loss = 1.0758  \n",
      "\n",
      "Fold: 31  Epoch: 36  Training loss = 3.0709  Validation loss = 1.0757  \n",
      "\n",
      "Fold: 31  Epoch: 37  Training loss = 3.0708  Validation loss = 1.0755  \n",
      "\n",
      "Fold: 31  Epoch: 38  Training loss = 3.0707  Validation loss = 1.0756  \n",
      "\n",
      "Fold: 31  Epoch: 39  Training loss = 3.0706  Validation loss = 1.0754  \n",
      "\n",
      "Fold: 31  Epoch: 40  Training loss = 3.0706  Validation loss = 1.0756  \n",
      "\n",
      "Fold: 31  Epoch: 41  Training loss = 3.0705  Validation loss = 1.0754  \n",
      "\n",
      "Fold: 31  Epoch: 42  Training loss = 3.0705  Validation loss = 1.0752  \n",
      "\n",
      "Fold: 31  Epoch: 43  Training loss = 3.0704  Validation loss = 1.0752  \n",
      "\n",
      "Fold: 31  Epoch: 44  Training loss = 3.0704  Validation loss = 1.0753  \n",
      "\n",
      "Fold: 31  Epoch: 45  Training loss = 3.0704  Validation loss = 1.0750  \n",
      "\n",
      "Fold: 31  Epoch: 46  Training loss = 3.0703  Validation loss = 1.0748  \n",
      "\n",
      "Fold: 31  Epoch: 47  Training loss = 3.0702  Validation loss = 1.0745  \n",
      "\n",
      "Fold: 31  Epoch: 48  Training loss = 3.0701  Validation loss = 1.0743  \n",
      "\n",
      "Fold: 31  Epoch: 49  Training loss = 3.0700  Validation loss = 1.0743  \n",
      "\n",
      "Fold: 31  Epoch: 50  Training loss = 3.0699  Validation loss = 1.0741  \n",
      "\n",
      "Fold: 31  Epoch: 51  Training loss = 3.0699  Validation loss = 1.0740  \n",
      "\n",
      "Fold: 31  Epoch: 52  Training loss = 3.0698  Validation loss = 1.0740  \n",
      "\n",
      "Fold: 31  Epoch: 53  Training loss = 3.0697  Validation loss = 1.0738  \n",
      "\n",
      "Fold: 31  Epoch: 54  Training loss = 3.0697  Validation loss = 1.0736  \n",
      "\n",
      "Fold: 31  Epoch: 55  Training loss = 3.0696  Validation loss = 1.0731  \n",
      "\n",
      "Fold: 31  Epoch: 56  Training loss = 3.0696  Validation loss = 1.0732  \n",
      "\n",
      "Fold: 31  Epoch: 57  Training loss = 3.0695  Validation loss = 1.0730  \n",
      "\n",
      "Fold: 31  Epoch: 58  Training loss = 3.0694  Validation loss = 1.0730  \n",
      "\n",
      "Fold: 31  Epoch: 59  Training loss = 3.0694  Validation loss = 1.0729  \n",
      "\n",
      "Fold: 31  Epoch: 60  Training loss = 3.0693  Validation loss = 1.0728  \n",
      "\n",
      "Fold: 31  Epoch: 61  Training loss = 3.0692  Validation loss = 1.0726  \n",
      "\n",
      "Fold: 31  Epoch: 62  Training loss = 3.0691  Validation loss = 1.0724  \n",
      "\n",
      "Fold: 31  Epoch: 63  Training loss = 3.0690  Validation loss = 1.0721  \n",
      "\n",
      "Fold: 31  Epoch: 64  Training loss = 3.0690  Validation loss = 1.0719  \n",
      "\n",
      "Fold: 31  Epoch: 65  Training loss = 3.0689  Validation loss = 1.0717  \n",
      "\n",
      "Fold: 31  Epoch: 66  Training loss = 3.0689  Validation loss = 1.0720  \n",
      "\n",
      "Fold: 31  Epoch: 67  Training loss = 3.0688  Validation loss = 1.0717  \n",
      "\n",
      "Fold: 31  Epoch: 68  Training loss = 3.0687  Validation loss = 1.0713  \n",
      "\n",
      "Fold: 31  Epoch: 69  Training loss = 3.0686  Validation loss = 1.0711  \n",
      "\n",
      "Fold: 31  Epoch: 70  Training loss = 3.0685  Validation loss = 1.0711  \n",
      "\n",
      "Fold: 31  Epoch: 71  Training loss = 3.0685  Validation loss = 1.0709  \n",
      "\n",
      "Fold: 31  Epoch: 72  Training loss = 3.0684  Validation loss = 1.0707  \n",
      "\n",
      "Fold: 31  Epoch: 73  Training loss = 3.0683  Validation loss = 1.0705  \n",
      "\n",
      "Fold: 31  Epoch: 74  Training loss = 3.0682  Validation loss = 1.0703  \n",
      "\n",
      "Fold: 31  Epoch: 75  Training loss = 3.0682  Validation loss = 1.0703  \n",
      "\n",
      "Fold: 31  Epoch: 76  Training loss = 3.0681  Validation loss = 1.0701  \n",
      "\n",
      "Fold: 31  Epoch: 77  Training loss = 3.0680  Validation loss = 1.0698  \n",
      "\n",
      "Fold: 31  Epoch: 78  Training loss = 3.0680  Validation loss = 1.0696  \n",
      "\n",
      "Fold: 31  Epoch: 79  Training loss = 3.0679  Validation loss = 1.0696  \n",
      "\n",
      "Fold: 31  Epoch: 80  Training loss = 3.0679  Validation loss = 1.0694  \n",
      "\n",
      "Fold: 31  Epoch: 81  Training loss = 3.0678  Validation loss = 1.0692  \n",
      "\n",
      "Fold: 31  Epoch: 82  Training loss = 3.0677  Validation loss = 1.0690  \n",
      "\n",
      "Fold: 31  Epoch: 83  Training loss = 3.0677  Validation loss = 1.0689  \n",
      "\n",
      "Fold: 31  Epoch: 84  Training loss = 3.0676  Validation loss = 1.0686  \n",
      "\n",
      "Fold: 31  Epoch: 85  Training loss = 3.0675  Validation loss = 1.0682  \n",
      "\n",
      "Fold: 31  Epoch: 86  Training loss = 3.0674  Validation loss = 1.0679  \n",
      "\n",
      "Fold: 31  Epoch: 87  Training loss = 3.0673  Validation loss = 1.0677  \n",
      "\n",
      "Fold: 31  Epoch: 88  Training loss = 3.0673  Validation loss = 1.0675  \n",
      "\n",
      "Fold: 31  Epoch: 89  Training loss = 3.0672  Validation loss = 1.0673  \n",
      "\n",
      "Fold: 31  Epoch: 90  Training loss = 3.0671  Validation loss = 1.0670  \n",
      "\n",
      "Fold: 31  Epoch: 91  Training loss = 3.0671  Validation loss = 1.0671  \n",
      "\n",
      "Fold: 31  Epoch: 92  Training loss = 3.0671  Validation loss = 1.0671  \n",
      "\n",
      "Fold: 31  Epoch: 93  Training loss = 3.0670  Validation loss = 1.0671  \n",
      "\n",
      "Fold: 31  Epoch: 94  Training loss = 3.0669  Validation loss = 1.0670  \n",
      "\n",
      "Fold: 31  Epoch: 95  Training loss = 3.0669  Validation loss = 1.0668  \n",
      "\n",
      "Fold: 31  Epoch: 96  Training loss = 3.0668  Validation loss = 1.0669  \n",
      "\n",
      "Fold: 31  Epoch: 97  Training loss = 3.0668  Validation loss = 1.0668  \n",
      "\n",
      "Fold: 31  Epoch: 98  Training loss = 3.0667  Validation loss = 1.0667  \n",
      "\n",
      "Fold: 31  Epoch: 99  Training loss = 3.0666  Validation loss = 1.0666  \n",
      "\n",
      "Fold: 31  Epoch: 100  Training loss = 3.0666  Validation loss = 1.0667  \n",
      "\n",
      "Fold: 31  Epoch: 101  Training loss = 3.0665  Validation loss = 1.0664  \n",
      "\n",
      "Fold: 31  Epoch: 102  Training loss = 3.0665  Validation loss = 1.0663  \n",
      "\n",
      "Fold: 31  Epoch: 103  Training loss = 3.0664  Validation loss = 1.0659  \n",
      "\n",
      "Fold: 31  Epoch: 104  Training loss = 3.0663  Validation loss = 1.0659  \n",
      "\n",
      "Fold: 31  Epoch: 105  Training loss = 3.0663  Validation loss = 1.0659  \n",
      "\n",
      "Fold: 31  Epoch: 106  Training loss = 3.0662  Validation loss = 1.0656  \n",
      "\n",
      "Fold: 31  Epoch: 107  Training loss = 3.0662  Validation loss = 1.0653  \n",
      "\n",
      "Fold: 31  Epoch: 108  Training loss = 3.0661  Validation loss = 1.0652  \n",
      "\n",
      "Fold: 31  Epoch: 109  Training loss = 3.0660  Validation loss = 1.0652  \n",
      "\n",
      "Fold: 31  Epoch: 110  Training loss = 3.0660  Validation loss = 1.0647  \n",
      "\n",
      "Fold: 31  Epoch: 111  Training loss = 3.0660  Validation loss = 1.0650  \n",
      "\n",
      "Fold: 31  Epoch: 112  Training loss = 3.0659  Validation loss = 1.0647  \n",
      "\n",
      "Fold: 31  Epoch: 113  Training loss = 3.0659  Validation loss = 1.0646  \n",
      "\n",
      "Fold: 31  Epoch: 114  Training loss = 3.0658  Validation loss = 1.0646  \n",
      "\n",
      "Fold: 31  Epoch: 115  Training loss = 3.0657  Validation loss = 1.0642  \n",
      "\n",
      "Fold: 31  Epoch: 116  Training loss = 3.0657  Validation loss = 1.0640  \n",
      "\n",
      "Fold: 31  Epoch: 117  Training loss = 3.0656  Validation loss = 1.0638  \n",
      "\n",
      "Fold: 31  Epoch: 118  Training loss = 3.0656  Validation loss = 1.0638  \n",
      "\n",
      "Fold: 31  Epoch: 119  Training loss = 3.0655  Validation loss = 1.0636  \n",
      "\n",
      "Fold: 31  Epoch: 120  Training loss = 3.0655  Validation loss = 1.0634  \n",
      "\n",
      "Fold: 31  Epoch: 121  Training loss = 3.0654  Validation loss = 1.0633  \n",
      "\n",
      "Fold: 31  Epoch: 122  Training loss = 3.0654  Validation loss = 1.0635  \n",
      "\n",
      "Fold: 31  Epoch: 123  Training loss = 3.0653  Validation loss = 1.0630  \n",
      "\n",
      "Fold: 31  Epoch: 124  Training loss = 3.0653  Validation loss = 1.0631  \n",
      "\n",
      "Fold: 31  Epoch: 125  Training loss = 3.0652  Validation loss = 1.0629  \n",
      "\n",
      "Fold: 31  Epoch: 126  Training loss = 3.0652  Validation loss = 1.0629  \n",
      "\n",
      "Fold: 31  Epoch: 127  Training loss = 3.0652  Validation loss = 1.0624  \n",
      "\n",
      "Fold: 31  Epoch: 128  Training loss = 3.0651  Validation loss = 1.0624  \n",
      "\n",
      "Fold: 31  Epoch: 129  Training loss = 3.0651  Validation loss = 1.0624  \n",
      "\n",
      "Fold: 31  Epoch: 130  Training loss = 3.0650  Validation loss = 1.0623  \n",
      "\n",
      "Fold: 31  Epoch: 131  Training loss = 3.0650  Validation loss = 1.0624  \n",
      "\n",
      "Fold: 31  Epoch: 132  Training loss = 3.0649  Validation loss = 1.0621  \n",
      "\n",
      "Fold: 31  Epoch: 133  Training loss = 3.0649  Validation loss = 1.0622  \n",
      "\n",
      "Fold: 31  Epoch: 134  Training loss = 3.0648  Validation loss = 1.0622  \n",
      "\n",
      "Fold: 31  Epoch: 135  Training loss = 3.0647  Validation loss = 1.0618  \n",
      "\n",
      "Fold: 31  Epoch: 136  Training loss = 3.0646  Validation loss = 1.0614  \n",
      "\n",
      "Fold: 31  Epoch: 137  Training loss = 3.0646  Validation loss = 1.0615  \n",
      "\n",
      "Fold: 31  Epoch: 138  Training loss = 3.0645  Validation loss = 1.0610  \n",
      "\n",
      "Fold: 31  Epoch: 139  Training loss = 3.0645  Validation loss = 1.0609  \n",
      "\n",
      "Fold: 31  Epoch: 140  Training loss = 3.0645  Validation loss = 1.0608  \n",
      "\n",
      "Fold: 31  Epoch: 141  Training loss = 3.0644  Validation loss = 1.0607  \n",
      "\n",
      "Fold: 31  Epoch: 142  Training loss = 3.0644  Validation loss = 1.0605  \n",
      "\n",
      "Fold: 31  Epoch: 143  Training loss = 3.0643  Validation loss = 1.0601  \n",
      "\n",
      "Fold: 31  Epoch: 144  Training loss = 3.0643  Validation loss = 1.0604  \n",
      "\n",
      "Fold: 31  Epoch: 145  Training loss = 3.0642  Validation loss = 1.0605  \n",
      "\n",
      "Fold: 31  Epoch: 146  Training loss = 3.0642  Validation loss = 1.0603  \n",
      "\n",
      "Fold: 31  Epoch: 147  Training loss = 3.0642  Validation loss = 1.0603  \n",
      "\n",
      "Fold: 31  Epoch: 148  Training loss = 3.0641  Validation loss = 1.0601  \n",
      "\n",
      "Fold: 31  Epoch: 149  Training loss = 3.0641  Validation loss = 1.0602  \n",
      "\n",
      "Fold: 31  Epoch: 150  Training loss = 3.0641  Validation loss = 1.0601  \n",
      "\n",
      "Fold: 31  Epoch: 151  Training loss = 3.0640  Validation loss = 1.0598  \n",
      "\n",
      "Fold: 31  Epoch: 152  Training loss = 3.0640  Validation loss = 1.0597  \n",
      "\n",
      "Fold: 31  Epoch: 153  Training loss = 3.0639  Validation loss = 1.0596  \n",
      "\n",
      "Fold: 31  Epoch: 154  Training loss = 3.0638  Validation loss = 1.0595  \n",
      "\n",
      "Fold: 31  Epoch: 155  Training loss = 3.0638  Validation loss = 1.0597  \n",
      "\n",
      "Fold: 31  Epoch: 156  Training loss = 3.0638  Validation loss = 1.0596  \n",
      "\n",
      "Fold: 31  Epoch: 157  Training loss = 3.0637  Validation loss = 1.0596  \n",
      "\n",
      "Fold: 31  Epoch: 158  Training loss = 3.0637  Validation loss = 1.0597  \n",
      "\n",
      "Fold: 31  Epoch: 159  Training loss = 3.0636  Validation loss = 1.0596  \n",
      "\n",
      "Fold: 31  Epoch: 160  Training loss = 3.0636  Validation loss = 1.0594  \n",
      "\n",
      "Fold: 31  Epoch: 161  Training loss = 3.0635  Validation loss = 1.0592  \n",
      "\n",
      "Fold: 31  Epoch: 162  Training loss = 3.0635  Validation loss = 1.0591  \n",
      "\n",
      "Fold: 31  Epoch: 163  Training loss = 3.0634  Validation loss = 1.0592  \n",
      "\n",
      "Fold: 31  Epoch: 164  Training loss = 3.0634  Validation loss = 1.0593  \n",
      "\n",
      "Fold: 31  Epoch: 165  Training loss = 3.0633  Validation loss = 1.0591  \n",
      "\n",
      "Fold: 31  Epoch: 166  Training loss = 3.0633  Validation loss = 1.0590  \n",
      "\n",
      "Fold: 31  Epoch: 167  Training loss = 3.0633  Validation loss = 1.0590  \n",
      "\n",
      "Fold: 31  Epoch: 168  Training loss = 3.0632  Validation loss = 1.0593  \n",
      "\n",
      "Fold: 31  Epoch: 169  Training loss = 3.0632  Validation loss = 1.0592  \n",
      "\n",
      "Fold: 31  Epoch: 170  Training loss = 3.0631  Validation loss = 1.0587  \n",
      "\n",
      "Fold: 31  Epoch: 171  Training loss = 3.0631  Validation loss = 1.0586  \n",
      "\n",
      "Fold: 31  Epoch: 172  Training loss = 3.0630  Validation loss = 1.0584  \n",
      "\n",
      "Fold: 31  Epoch: 173  Training loss = 3.0629  Validation loss = 1.0581  \n",
      "\n",
      "Fold: 31  Epoch: 174  Training loss = 3.0628  Validation loss = 1.0579  \n",
      "\n",
      "Fold: 31  Epoch: 175  Training loss = 3.0628  Validation loss = 1.0578  \n",
      "\n",
      "Fold: 31  Epoch: 176  Training loss = 3.0628  Validation loss = 1.0581  \n",
      "\n",
      "Fold: 31  Epoch: 177  Training loss = 3.0627  Validation loss = 1.0582  \n",
      "\n",
      "Fold: 31  Epoch: 178  Training loss = 3.0627  Validation loss = 1.0577  \n",
      "\n",
      "Fold: 31  Epoch: 179  Training loss = 3.0626  Validation loss = 1.0574  \n",
      "\n",
      "Fold: 31  Epoch: 180  Training loss = 3.0626  Validation loss = 1.0574  \n",
      "\n",
      "Fold: 31  Epoch: 181  Training loss = 3.0625  Validation loss = 1.0574  \n",
      "\n",
      "Fold: 31  Epoch: 182  Training loss = 3.0625  Validation loss = 1.0573  \n",
      "\n",
      "Fold: 31  Epoch: 183  Training loss = 3.0624  Validation loss = 1.0570  \n",
      "\n",
      "Fold: 31  Epoch: 184  Training loss = 3.0624  Validation loss = 1.0570  \n",
      "\n",
      "Fold: 31  Epoch: 185  Training loss = 3.0623  Validation loss = 1.0572  \n",
      "\n",
      "Fold: 31  Epoch: 186  Training loss = 3.0623  Validation loss = 1.0570  \n",
      "\n",
      "Fold: 31  Epoch: 187  Training loss = 3.0622  Validation loss = 1.0567  \n",
      "\n",
      "Fold: 31  Epoch: 188  Training loss = 3.0622  Validation loss = 1.0567  \n",
      "\n",
      "Fold: 31  Epoch: 189  Training loss = 3.0621  Validation loss = 1.0565  \n",
      "\n",
      "Fold: 31  Epoch: 190  Training loss = 3.0621  Validation loss = 1.0560  \n",
      "\n",
      "Fold: 31  Epoch: 191  Training loss = 3.0620  Validation loss = 1.0558  \n",
      "\n",
      "Fold: 31  Epoch: 192  Training loss = 3.0619  Validation loss = 1.0555  \n",
      "\n",
      "Fold: 31  Epoch: 193  Training loss = 3.0619  Validation loss = 1.0557  \n",
      "\n",
      "Fold: 31  Epoch: 194  Training loss = 3.0618  Validation loss = 1.0558  \n",
      "\n",
      "Fold: 31  Epoch: 195  Training loss = 3.0617  Validation loss = 1.0558  \n",
      "\n",
      "Fold: 31  Epoch: 196  Training loss = 3.0617  Validation loss = 1.0559  \n",
      "\n",
      "Fold: 31  Epoch: 197  Training loss = 3.0616  Validation loss = 1.0559  \n",
      "\n",
      "Fold: 31  Epoch: 198  Training loss = 3.0616  Validation loss = 1.0559  \n",
      "\n",
      "Fold: 31  Epoch: 199  Training loss = 3.0615  Validation loss = 1.0556  \n",
      "\n",
      "Fold: 31  Epoch: 200  Training loss = 3.0615  Validation loss = 1.0556  \n",
      "\n",
      "Fold: 31  Epoch: 201  Training loss = 3.0615  Validation loss = 1.0555  \n",
      "\n",
      "Fold: 31  Epoch: 202  Training loss = 3.0614  Validation loss = 1.0556  \n",
      "\n",
      "Fold: 31  Epoch: 203  Training loss = 3.0613  Validation loss = 1.0557  \n",
      "\n",
      "Fold: 31  Epoch: 204  Training loss = 3.0613  Validation loss = 1.0551  \n",
      "\n",
      "Fold: 31  Epoch: 205  Training loss = 3.0612  Validation loss = 1.0549  \n",
      "\n",
      "Fold: 31  Epoch: 206  Training loss = 3.0612  Validation loss = 1.0549  \n",
      "\n",
      "Fold: 31  Epoch: 207  Training loss = 3.0611  Validation loss = 1.0553  \n",
      "\n",
      "Fold: 31  Epoch: 208  Training loss = 3.0611  Validation loss = 1.0553  \n",
      "\n",
      "Fold: 31  Epoch: 209  Training loss = 3.0610  Validation loss = 1.0551  \n",
      "\n",
      "Fold: 31  Epoch: 210  Training loss = 3.0610  Validation loss = 1.0550  \n",
      "\n",
      "Fold: 31  Epoch: 211  Training loss = 3.0609  Validation loss = 1.0547  \n",
      "\n",
      "Fold: 31  Epoch: 212  Training loss = 3.0609  Validation loss = 1.0544  \n",
      "\n",
      "Fold: 31  Epoch: 213  Training loss = 3.0608  Validation loss = 1.0544  \n",
      "\n",
      "Fold: 31  Epoch: 214  Training loss = 3.0608  Validation loss = 1.0542  \n",
      "\n",
      "Fold: 31  Epoch: 215  Training loss = 3.0607  Validation loss = 1.0543  \n",
      "\n",
      "Fold: 31  Epoch: 216  Training loss = 3.0607  Validation loss = 1.0540  \n",
      "\n",
      "Fold: 31  Epoch: 217  Training loss = 3.0606  Validation loss = 1.0540  \n",
      "\n",
      "Fold: 31  Epoch: 218  Training loss = 3.0606  Validation loss = 1.0540  \n",
      "\n",
      "Fold: 31  Epoch: 219  Training loss = 3.0605  Validation loss = 1.0540  \n",
      "\n",
      "Fold: 31  Epoch: 220  Training loss = 3.0605  Validation loss = 1.0540  \n",
      "\n",
      "Fold: 31  Epoch: 221  Training loss = 3.0604  Validation loss = 1.0538  \n",
      "\n",
      "Fold: 31  Epoch: 222  Training loss = 3.0604  Validation loss = 1.0534  \n",
      "\n",
      "Fold: 31  Epoch: 223  Training loss = 3.0603  Validation loss = 1.0533  \n",
      "\n",
      "Fold: 31  Epoch: 224  Training loss = 3.0603  Validation loss = 1.0533  \n",
      "\n",
      "Fold: 31  Epoch: 225  Training loss = 3.0602  Validation loss = 1.0530  \n",
      "\n",
      "Fold: 31  Epoch: 226  Training loss = 3.0602  Validation loss = 1.0530  \n",
      "\n",
      "Fold: 31  Epoch: 227  Training loss = 3.0602  Validation loss = 1.0530  \n",
      "\n",
      "Fold: 31  Epoch: 228  Training loss = 3.0601  Validation loss = 1.0525  \n",
      "\n",
      "Fold: 31  Epoch: 229  Training loss = 3.0601  Validation loss = 1.0524  \n",
      "\n",
      "Fold: 31  Epoch: 230  Training loss = 3.0600  Validation loss = 1.0525  \n",
      "\n",
      "Fold: 31  Epoch: 231  Training loss = 3.0599  Validation loss = 1.0525  \n",
      "\n",
      "Fold: 31  Epoch: 232  Training loss = 3.0599  Validation loss = 1.0524  \n",
      "\n",
      "Fold: 31  Epoch: 233  Training loss = 3.0599  Validation loss = 1.0524  \n",
      "\n",
      "Fold: 31  Epoch: 234  Training loss = 3.0598  Validation loss = 1.0522  \n",
      "\n",
      "Fold: 31  Epoch: 235  Training loss = 3.0597  Validation loss = 1.0518  \n",
      "\n",
      "Fold: 31  Epoch: 236  Training loss = 3.0597  Validation loss = 1.0518  \n",
      "\n",
      "Fold: 31  Epoch: 237  Training loss = 3.0597  Validation loss = 1.0521  \n",
      "\n",
      "Fold: 31  Epoch: 238  Training loss = 3.0596  Validation loss = 1.0522  \n",
      "\n",
      "Fold: 31  Epoch: 239  Training loss = 3.0595  Validation loss = 1.0522  \n",
      "\n",
      "Fold: 31  Epoch: 240  Training loss = 3.0595  Validation loss = 1.0521  \n",
      "\n",
      "Fold: 31  Epoch: 241  Training loss = 3.0595  Validation loss = 1.0519  \n",
      "\n",
      "Fold: 31  Epoch: 242  Training loss = 3.0594  Validation loss = 1.0522  \n",
      "\n",
      "Fold: 31  Epoch: 243  Training loss = 3.0594  Validation loss = 1.0519  \n",
      "\n",
      "Fold: 31  Epoch: 244  Training loss = 3.0593  Validation loss = 1.0520  \n",
      "\n",
      "Fold: 31  Epoch: 245  Training loss = 3.0593  Validation loss = 1.0521  \n",
      "\n",
      "Fold: 31  Epoch: 246  Training loss = 3.0592  Validation loss = 1.0519  \n",
      "\n",
      "Fold: 31  Epoch: 247  Training loss = 3.0592  Validation loss = 1.0517  \n",
      "\n",
      "Fold: 31  Epoch: 248  Training loss = 3.0591  Validation loss = 1.0517  \n",
      "\n",
      "Fold: 31  Epoch: 249  Training loss = 3.0591  Validation loss = 1.0516  \n",
      "\n",
      "Fold: 31  Epoch: 250  Training loss = 3.0591  Validation loss = 1.0513  \n",
      "\n",
      "Fold: 31  Epoch: 251  Training loss = 3.0590  Validation loss = 1.0513  \n",
      "\n",
      "Fold: 31  Epoch: 252  Training loss = 3.0590  Validation loss = 1.0515  \n",
      "\n",
      "Fold: 31  Epoch: 253  Training loss = 3.0589  Validation loss = 1.0513  \n",
      "\n",
      "Fold: 31  Epoch: 254  Training loss = 3.0589  Validation loss = 1.0509  \n",
      "\n",
      "Fold: 31  Epoch: 255  Training loss = 3.0589  Validation loss = 1.0507  \n",
      "\n",
      "Fold: 31  Epoch: 256  Training loss = 3.0588  Validation loss = 1.0505  \n",
      "\n",
      "Fold: 31  Epoch: 257  Training loss = 3.0588  Validation loss = 1.0506  \n",
      "\n",
      "Fold: 31  Epoch: 258  Training loss = 3.0587  Validation loss = 1.0507  \n",
      "\n",
      "Fold: 31  Epoch: 259  Training loss = 3.0587  Validation loss = 1.0509  \n",
      "\n",
      "Fold: 31  Epoch: 260  Training loss = 3.0586  Validation loss = 1.0510  \n",
      "\n",
      "Fold: 31  Epoch: 261  Training loss = 3.0586  Validation loss = 1.0509  \n",
      "\n",
      "Fold: 31  Epoch: 262  Training loss = 3.0586  Validation loss = 1.0510  \n",
      "\n",
      "Fold: 31  Epoch: 263  Training loss = 3.0585  Validation loss = 1.0509  \n",
      "\n",
      "Fold: 31  Epoch: 264  Training loss = 3.0585  Validation loss = 1.0506  \n",
      "\n",
      "Fold: 31  Epoch: 265  Training loss = 3.0584  Validation loss = 1.0503  \n",
      "\n",
      "Fold: 31  Epoch: 266  Training loss = 3.0584  Validation loss = 1.0500  \n",
      "\n",
      "Fold: 31  Epoch: 267  Training loss = 3.0583  Validation loss = 1.0500  \n",
      "\n",
      "Fold: 31  Epoch: 268  Training loss = 3.0583  Validation loss = 1.0498  \n",
      "\n",
      "Fold: 31  Epoch: 269  Training loss = 3.0583  Validation loss = 1.0497  \n",
      "\n",
      "Fold: 31  Epoch: 270  Training loss = 3.0582  Validation loss = 1.0496  \n",
      "\n",
      "Fold: 31  Epoch: 271  Training loss = 3.0582  Validation loss = 1.0494  \n",
      "\n",
      "Fold: 31  Epoch: 272  Training loss = 3.0582  Validation loss = 1.0495  \n",
      "\n",
      "Fold: 31  Epoch: 273  Training loss = 3.0581  Validation loss = 1.0494  \n",
      "\n",
      "Fold: 31  Epoch: 274  Training loss = 3.0580  Validation loss = 1.0493  \n",
      "\n",
      "Fold: 31  Epoch: 275  Training loss = 3.0580  Validation loss = 1.0491  \n",
      "\n",
      "Fold: 31  Epoch: 276  Training loss = 3.0580  Validation loss = 1.0488  \n",
      "\n",
      "Fold: 31  Epoch: 277  Training loss = 3.0579  Validation loss = 1.0486  \n",
      "\n",
      "Fold: 31  Epoch: 278  Training loss = 3.0579  Validation loss = 1.0489  \n",
      "\n",
      "Fold: 31  Epoch: 279  Training loss = 3.0578  Validation loss = 1.0488  \n",
      "\n",
      "Fold: 31  Epoch: 280  Training loss = 3.0578  Validation loss = 1.0487  \n",
      "\n",
      "Fold: 31  Epoch: 281  Training loss = 3.0577  Validation loss = 1.0489  \n",
      "\n",
      "Fold: 31  Epoch: 282  Training loss = 3.0577  Validation loss = 1.0487  \n",
      "\n",
      "Fold: 31  Epoch: 283  Training loss = 3.0577  Validation loss = 1.0486  \n",
      "\n",
      "Fold: 31  Epoch: 284  Training loss = 3.0576  Validation loss = 1.0486  \n",
      "\n",
      "Fold: 31  Epoch: 285  Training loss = 3.0576  Validation loss = 1.0487  \n",
      "\n",
      "Fold: 31  Epoch: 286  Training loss = 3.0575  Validation loss = 1.0485  \n",
      "\n",
      "Fold: 31  Epoch: 287  Training loss = 3.0575  Validation loss = 1.0487  \n",
      "\n",
      "Fold: 31  Epoch: 288  Training loss = 3.0575  Validation loss = 1.0485  \n",
      "\n",
      "Fold: 31  Epoch: 289  Training loss = 3.0574  Validation loss = 1.0484  \n",
      "\n",
      "Fold: 31  Epoch: 290  Training loss = 3.0574  Validation loss = 1.0484  \n",
      "\n",
      "Fold: 31  Epoch: 291  Training loss = 3.0573  Validation loss = 1.0481  \n",
      "\n",
      "Fold: 31  Epoch: 292  Training loss = 3.0572  Validation loss = 1.0483  \n",
      "\n",
      "Fold: 31  Epoch: 293  Training loss = 3.0572  Validation loss = 1.0480  \n",
      "\n",
      "Fold: 31  Epoch: 294  Training loss = 3.0572  Validation loss = 1.0480  \n",
      "\n",
      "Fold: 31  Epoch: 295  Training loss = 3.0571  Validation loss = 1.0484  \n",
      "\n",
      "Fold: 31  Epoch: 296  Training loss = 3.0571  Validation loss = 1.0484  \n",
      "\n",
      "Fold: 31  Epoch: 297  Training loss = 3.0570  Validation loss = 1.0487  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 293  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.2873  Validation loss = 3.1407  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.2873  Validation loss = 3.1406  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.2871  Validation loss = 3.1400  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.2869  Validation loss = 3.1389  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.2868  Validation loss = 3.1383  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.2866  Validation loss = 3.1375  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.2865  Validation loss = 3.1369  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.2863  Validation loss = 3.1361  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.2861  Validation loss = 3.1352  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.2859  Validation loss = 3.1340  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.2858  Validation loss = 3.1334  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.2857  Validation loss = 3.1328  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.2856  Validation loss = 3.1321  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.2852  Validation loss = 3.1302  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.2852  Validation loss = 3.1297  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.2850  Validation loss = 3.1286  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.2848  Validation loss = 3.1273  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.2846  Validation loss = 3.1269  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.2845  Validation loss = 3.1261  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.2843  Validation loss = 3.1251  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.2841  Validation loss = 3.1238  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.2840  Validation loss = 3.1231  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.2838  Validation loss = 3.1219  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.2836  Validation loss = 3.1212  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.2835  Validation loss = 3.1208  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.2834  Validation loss = 3.1203  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.2834  Validation loss = 3.1199  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.2833  Validation loss = 3.1193  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.2832  Validation loss = 3.1188  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.2830  Validation loss = 3.1180  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.2829  Validation loss = 3.1176  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.2828  Validation loss = 3.1170  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.2826  Validation loss = 3.1156  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.2825  Validation loss = 3.1151  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.2823  Validation loss = 3.1141  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.2823  Validation loss = 3.1139  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.2821  Validation loss = 3.1131  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.2819  Validation loss = 3.1121  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.2819  Validation loss = 3.1117  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.2817  Validation loss = 3.1108  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.2816  Validation loss = 3.1105  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.2815  Validation loss = 3.1103  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.2815  Validation loss = 3.1100  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.2813  Validation loss = 3.1088  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.2812  Validation loss = 3.1088  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.2811  Validation loss = 3.1078  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.2810  Validation loss = 3.1072  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.2809  Validation loss = 3.1067  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.2807  Validation loss = 3.1060  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.2806  Validation loss = 3.1053  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.2805  Validation loss = 3.1046  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.2804  Validation loss = 3.1044  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.2804  Validation loss = 3.1041  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.2803  Validation loss = 3.1037  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.2802  Validation loss = 3.1030  \n",
      "\n",
      "Fold: 32  Epoch: 56  Training loss = 2.2801  Validation loss = 3.1029  \n",
      "\n",
      "Fold: 32  Epoch: 57  Training loss = 2.2801  Validation loss = 3.1025  \n",
      "\n",
      "Fold: 32  Epoch: 58  Training loss = 2.2800  Validation loss = 3.1024  \n",
      "\n",
      "Fold: 32  Epoch: 59  Training loss = 2.2800  Validation loss = 3.1020  \n",
      "\n",
      "Fold: 32  Epoch: 60  Training loss = 2.2799  Validation loss = 3.1014  \n",
      "\n",
      "Fold: 32  Epoch: 61  Training loss = 2.2798  Validation loss = 3.1013  \n",
      "\n",
      "Fold: 32  Epoch: 62  Training loss = 2.2797  Validation loss = 3.1007  \n",
      "\n",
      "Fold: 32  Epoch: 63  Training loss = 2.2796  Validation loss = 3.0999  \n",
      "\n",
      "Fold: 32  Epoch: 64  Training loss = 2.2794  Validation loss = 3.0995  \n",
      "\n",
      "Fold: 32  Epoch: 65  Training loss = 2.2793  Validation loss = 3.0990  \n",
      "\n",
      "Fold: 32  Epoch: 66  Training loss = 2.2792  Validation loss = 3.0984  \n",
      "\n",
      "Fold: 32  Epoch: 67  Training loss = 2.2790  Validation loss = 3.0978  \n",
      "\n",
      "Fold: 32  Epoch: 68  Training loss = 2.2789  Validation loss = 3.0971  \n",
      "\n",
      "Fold: 32  Epoch: 69  Training loss = 2.2787  Validation loss = 3.0958  \n",
      "\n",
      "Fold: 32  Epoch: 70  Training loss = 2.2786  Validation loss = 3.0950  \n",
      "\n",
      "Fold: 32  Epoch: 71  Training loss = 2.2785  Validation loss = 3.0945  \n",
      "\n",
      "Fold: 32  Epoch: 72  Training loss = 2.2783  Validation loss = 3.0942  \n",
      "\n",
      "Fold: 32  Epoch: 73  Training loss = 2.2782  Validation loss = 3.0936  \n",
      "\n",
      "Fold: 32  Epoch: 74  Training loss = 2.2781  Validation loss = 3.0928  \n",
      "\n",
      "Fold: 32  Epoch: 75  Training loss = 2.2780  Validation loss = 3.0923  \n",
      "\n",
      "Fold: 32  Epoch: 76  Training loss = 2.2779  Validation loss = 3.0915  \n",
      "\n",
      "Fold: 32  Epoch: 77  Training loss = 2.2778  Validation loss = 3.0912  \n",
      "\n",
      "Fold: 32  Epoch: 78  Training loss = 2.2777  Validation loss = 3.0903  \n",
      "\n",
      "Fold: 32  Epoch: 79  Training loss = 2.2775  Validation loss = 3.0893  \n",
      "\n",
      "Fold: 32  Epoch: 80  Training loss = 2.2774  Validation loss = 3.0887  \n",
      "\n",
      "Fold: 32  Epoch: 81  Training loss = 2.2773  Validation loss = 3.0881  \n",
      "\n",
      "Fold: 32  Epoch: 82  Training loss = 2.2771  Validation loss = 3.0872  \n",
      "\n",
      "Fold: 32  Epoch: 83  Training loss = 2.2769  Validation loss = 3.0860  \n",
      "\n",
      "Fold: 32  Epoch: 84  Training loss = 2.2767  Validation loss = 3.0846  \n",
      "\n",
      "Fold: 32  Epoch: 85  Training loss = 2.2766  Validation loss = 3.0839  \n",
      "\n",
      "Fold: 32  Epoch: 86  Training loss = 2.2764  Validation loss = 3.0832  \n",
      "\n",
      "Fold: 32  Epoch: 87  Training loss = 2.2763  Validation loss = 3.0823  \n",
      "\n",
      "Fold: 32  Epoch: 88  Training loss = 2.2763  Validation loss = 3.0823  \n",
      "\n",
      "Fold: 32  Epoch: 89  Training loss = 2.2762  Validation loss = 3.0815  \n",
      "\n",
      "Fold: 32  Epoch: 90  Training loss = 2.2761  Validation loss = 3.0810  \n",
      "\n",
      "Fold: 32  Epoch: 91  Training loss = 2.2760  Validation loss = 3.0806  \n",
      "\n",
      "Fold: 32  Epoch: 92  Training loss = 2.2759  Validation loss = 3.0805  \n",
      "\n",
      "Fold: 32  Epoch: 93  Training loss = 2.2758  Validation loss = 3.0799  \n",
      "\n",
      "Fold: 32  Epoch: 94  Training loss = 2.2757  Validation loss = 3.0791  \n",
      "\n",
      "Fold: 32  Epoch: 95  Training loss = 2.2756  Validation loss = 3.0784  \n",
      "\n",
      "Fold: 32  Epoch: 96  Training loss = 2.2755  Validation loss = 3.0780  \n",
      "\n",
      "Fold: 32  Epoch: 97  Training loss = 2.2754  Validation loss = 3.0772  \n",
      "\n",
      "Fold: 32  Epoch: 98  Training loss = 2.2753  Validation loss = 3.0767  \n",
      "\n",
      "Fold: 32  Epoch: 99  Training loss = 2.2752  Validation loss = 3.0763  \n",
      "\n",
      "Fold: 32  Epoch: 100  Training loss = 2.2752  Validation loss = 3.0765  \n",
      "\n",
      "Fold: 32  Epoch: 101  Training loss = 2.2751  Validation loss = 3.0758  \n",
      "\n",
      "Fold: 32  Epoch: 102  Training loss = 2.2749  Validation loss = 3.0748  \n",
      "\n",
      "Fold: 32  Epoch: 103  Training loss = 2.2748  Validation loss = 3.0742  \n",
      "\n",
      "Fold: 32  Epoch: 104  Training loss = 2.2747  Validation loss = 3.0737  \n",
      "\n",
      "Fold: 32  Epoch: 105  Training loss = 2.2746  Validation loss = 3.0733  \n",
      "\n",
      "Fold: 32  Epoch: 106  Training loss = 2.2745  Validation loss = 3.0727  \n",
      "\n",
      "Fold: 32  Epoch: 107  Training loss = 2.2743  Validation loss = 3.0714  \n",
      "\n",
      "Fold: 32  Epoch: 108  Training loss = 2.2743  Validation loss = 3.0714  \n",
      "\n",
      "Fold: 32  Epoch: 109  Training loss = 2.2742  Validation loss = 3.0711  \n",
      "\n",
      "Fold: 32  Epoch: 110  Training loss = 2.2741  Validation loss = 3.0708  \n",
      "\n",
      "Fold: 32  Epoch: 111  Training loss = 2.2740  Validation loss = 3.0698  \n",
      "\n",
      "Fold: 32  Epoch: 112  Training loss = 2.2739  Validation loss = 3.0692  \n",
      "\n",
      "Fold: 32  Epoch: 113  Training loss = 2.2738  Validation loss = 3.0690  \n",
      "\n",
      "Fold: 32  Epoch: 114  Training loss = 2.2738  Validation loss = 3.0689  \n",
      "\n",
      "Fold: 32  Epoch: 115  Training loss = 2.2736  Validation loss = 3.0679  \n",
      "\n",
      "Fold: 32  Epoch: 116  Training loss = 2.2735  Validation loss = 3.0675  \n",
      "\n",
      "Fold: 32  Epoch: 117  Training loss = 2.2735  Validation loss = 3.0673  \n",
      "\n",
      "Fold: 32  Epoch: 118  Training loss = 2.2733  Validation loss = 3.0664  \n",
      "\n",
      "Fold: 32  Epoch: 119  Training loss = 2.2733  Validation loss = 3.0660  \n",
      "\n",
      "Fold: 32  Epoch: 120  Training loss = 2.2732  Validation loss = 3.0654  \n",
      "\n",
      "Fold: 32  Epoch: 121  Training loss = 2.2731  Validation loss = 3.0653  \n",
      "\n",
      "Fold: 32  Epoch: 122  Training loss = 2.2730  Validation loss = 3.0648  \n",
      "\n",
      "Fold: 32  Epoch: 123  Training loss = 2.2729  Validation loss = 3.0642  \n",
      "\n",
      "Fold: 32  Epoch: 124  Training loss = 2.2729  Validation loss = 3.0639  \n",
      "\n",
      "Fold: 32  Epoch: 125  Training loss = 2.2728  Validation loss = 3.0632  \n",
      "\n",
      "Fold: 32  Epoch: 126  Training loss = 2.2727  Validation loss = 3.0625  \n",
      "\n",
      "Fold: 32  Epoch: 127  Training loss = 2.2726  Validation loss = 3.0617  \n",
      "\n",
      "Fold: 32  Epoch: 128  Training loss = 2.2724  Validation loss = 3.0605  \n",
      "\n",
      "Fold: 32  Epoch: 129  Training loss = 2.2723  Validation loss = 3.0600  \n",
      "\n",
      "Fold: 32  Epoch: 130  Training loss = 2.2722  Validation loss = 3.0592  \n",
      "\n",
      "Fold: 32  Epoch: 131  Training loss = 2.2720  Validation loss = 3.0585  \n",
      "\n",
      "Fold: 32  Epoch: 132  Training loss = 2.2719  Validation loss = 3.0573  \n",
      "\n",
      "Fold: 32  Epoch: 133  Training loss = 2.2717  Validation loss = 3.0566  \n",
      "\n",
      "Fold: 32  Epoch: 134  Training loss = 2.2717  Validation loss = 3.0564  \n",
      "\n",
      "Fold: 32  Epoch: 135  Training loss = 2.2715  Validation loss = 3.0551  \n",
      "\n",
      "Fold: 32  Epoch: 136  Training loss = 2.2714  Validation loss = 3.0543  \n",
      "\n",
      "Fold: 32  Epoch: 137  Training loss = 2.2713  Validation loss = 3.0533  \n",
      "\n",
      "Fold: 32  Epoch: 138  Training loss = 2.2711  Validation loss = 3.0525  \n",
      "\n",
      "Fold: 32  Epoch: 139  Training loss = 2.2710  Validation loss = 3.0517  \n",
      "\n",
      "Fold: 32  Epoch: 140  Training loss = 2.2709  Validation loss = 3.0511  \n",
      "\n",
      "Fold: 32  Epoch: 141  Training loss = 2.2708  Validation loss = 3.0505  \n",
      "\n",
      "Fold: 32  Epoch: 142  Training loss = 2.2707  Validation loss = 3.0495  \n",
      "\n",
      "Fold: 32  Epoch: 143  Training loss = 2.2706  Validation loss = 3.0493  \n",
      "\n",
      "Fold: 32  Epoch: 144  Training loss = 2.2705  Validation loss = 3.0484  \n",
      "\n",
      "Fold: 32  Epoch: 145  Training loss = 2.2704  Validation loss = 3.0477  \n",
      "\n",
      "Fold: 32  Epoch: 146  Training loss = 2.2702  Validation loss = 3.0466  \n",
      "\n",
      "Fold: 32  Epoch: 147  Training loss = 2.2701  Validation loss = 3.0456  \n",
      "\n",
      "Fold: 32  Epoch: 148  Training loss = 2.2700  Validation loss = 3.0451  \n",
      "\n",
      "Fold: 32  Epoch: 149  Training loss = 2.2699  Validation loss = 3.0451  \n",
      "\n",
      "Fold: 32  Epoch: 150  Training loss = 2.2698  Validation loss = 3.0439  \n",
      "\n",
      "Fold: 32  Epoch: 151  Training loss = 2.2697  Validation loss = 3.0438  \n",
      "\n",
      "Fold: 32  Epoch: 152  Training loss = 2.2696  Validation loss = 3.0432  \n",
      "\n",
      "Fold: 32  Epoch: 153  Training loss = 2.2695  Validation loss = 3.0427  \n",
      "\n",
      "Fold: 32  Epoch: 154  Training loss = 2.2695  Validation loss = 3.0427  \n",
      "\n",
      "Fold: 32  Epoch: 155  Training loss = 2.2694  Validation loss = 3.0422  \n",
      "\n",
      "Fold: 32  Epoch: 156  Training loss = 2.2694  Validation loss = 3.0422  \n",
      "\n",
      "Fold: 32  Epoch: 157  Training loss = 2.2692  Validation loss = 3.0411  \n",
      "\n",
      "Fold: 32  Epoch: 158  Training loss = 2.2691  Validation loss = 3.0404  \n",
      "\n",
      "Fold: 32  Epoch: 159  Training loss = 2.2690  Validation loss = 3.0400  \n",
      "\n",
      "Fold: 32  Epoch: 160  Training loss = 2.2689  Validation loss = 3.0393  \n",
      "\n",
      "Fold: 32  Epoch: 161  Training loss = 2.2689  Validation loss = 3.0394  \n",
      "\n",
      "Fold: 32  Epoch: 162  Training loss = 2.2688  Validation loss = 3.0384  \n",
      "\n",
      "Fold: 32  Epoch: 163  Training loss = 2.2687  Validation loss = 3.0379  \n",
      "\n",
      "Fold: 32  Epoch: 164  Training loss = 2.2686  Validation loss = 3.0373  \n",
      "\n",
      "Fold: 32  Epoch: 165  Training loss = 2.2685  Validation loss = 3.0368  \n",
      "\n",
      "Fold: 32  Epoch: 166  Training loss = 2.2684  Validation loss = 3.0356  \n",
      "\n",
      "Fold: 32  Epoch: 167  Training loss = 2.2682  Validation loss = 3.0348  \n",
      "\n",
      "Fold: 32  Epoch: 168  Training loss = 2.2681  Validation loss = 3.0337  \n",
      "\n",
      "Fold: 32  Epoch: 169  Training loss = 2.2680  Validation loss = 3.0329  \n",
      "\n",
      "Fold: 32  Epoch: 170  Training loss = 2.2679  Validation loss = 3.0327  \n",
      "\n",
      "Fold: 32  Epoch: 171  Training loss = 2.2678  Validation loss = 3.0325  \n",
      "\n",
      "Fold: 32  Epoch: 172  Training loss = 2.2677  Validation loss = 3.0317  \n",
      "\n",
      "Fold: 32  Epoch: 173  Training loss = 2.2676  Validation loss = 3.0304  \n",
      "\n",
      "Fold: 32  Epoch: 174  Training loss = 2.2675  Validation loss = 3.0299  \n",
      "\n",
      "Fold: 32  Epoch: 175  Training loss = 2.2674  Validation loss = 3.0290  \n",
      "\n",
      "Fold: 32  Epoch: 176  Training loss = 2.2672  Validation loss = 3.0281  \n",
      "\n",
      "Fold: 32  Epoch: 177  Training loss = 2.2672  Validation loss = 3.0275  \n",
      "\n",
      "Fold: 32  Epoch: 178  Training loss = 2.2670  Validation loss = 3.0264  \n",
      "\n",
      "Fold: 32  Epoch: 179  Training loss = 2.2669  Validation loss = 3.0255  \n",
      "\n",
      "Fold: 32  Epoch: 180  Training loss = 2.2667  Validation loss = 3.0246  \n",
      "\n",
      "Fold: 32  Epoch: 181  Training loss = 2.2666  Validation loss = 3.0240  \n",
      "\n",
      "Fold: 32  Epoch: 182  Training loss = 2.2666  Validation loss = 3.0238  \n",
      "\n",
      "Fold: 32  Epoch: 183  Training loss = 2.2664  Validation loss = 3.0231  \n",
      "\n",
      "Fold: 32  Epoch: 184  Training loss = 2.2664  Validation loss = 3.0230  \n",
      "\n",
      "Fold: 32  Epoch: 185  Training loss = 2.2663  Validation loss = 3.0227  \n",
      "\n",
      "Fold: 32  Epoch: 186  Training loss = 2.2662  Validation loss = 3.0215  \n",
      "\n",
      "Fold: 32  Epoch: 187  Training loss = 2.2661  Validation loss = 3.0211  \n",
      "\n",
      "Fold: 32  Epoch: 188  Training loss = 2.2660  Validation loss = 3.0203  \n",
      "\n",
      "Fold: 32  Epoch: 189  Training loss = 2.2659  Validation loss = 3.0199  \n",
      "\n",
      "Fold: 32  Epoch: 190  Training loss = 2.2658  Validation loss = 3.0190  \n",
      "\n",
      "Fold: 32  Epoch: 191  Training loss = 2.2657  Validation loss = 3.0188  \n",
      "\n",
      "Fold: 32  Epoch: 192  Training loss = 2.2656  Validation loss = 3.0174  \n",
      "\n",
      "Fold: 32  Epoch: 193  Training loss = 2.2655  Validation loss = 3.0169  \n",
      "\n",
      "Fold: 32  Epoch: 194  Training loss = 2.2654  Validation loss = 3.0166  \n",
      "\n",
      "Fold: 32  Epoch: 195  Training loss = 2.2654  Validation loss = 3.0164  \n",
      "\n",
      "Fold: 32  Epoch: 196  Training loss = 2.2653  Validation loss = 3.0158  \n",
      "\n",
      "Fold: 32  Epoch: 197  Training loss = 2.2652  Validation loss = 3.0151  \n",
      "\n",
      "Fold: 32  Epoch: 198  Training loss = 2.2651  Validation loss = 3.0142  \n",
      "\n",
      "Fold: 32  Epoch: 199  Training loss = 2.2650  Validation loss = 3.0135  \n",
      "\n",
      "Fold: 32  Epoch: 200  Training loss = 2.2649  Validation loss = 3.0131  \n",
      "\n",
      "Fold: 32  Epoch: 201  Training loss = 2.2648  Validation loss = 3.0126  \n",
      "\n",
      "Fold: 32  Epoch: 202  Training loss = 2.2647  Validation loss = 3.0119  \n",
      "\n",
      "Fold: 32  Epoch: 203  Training loss = 2.2647  Validation loss = 3.0113  \n",
      "\n",
      "Fold: 32  Epoch: 204  Training loss = 2.2646  Validation loss = 3.0108  \n",
      "\n",
      "Fold: 32  Epoch: 205  Training loss = 2.2645  Validation loss = 3.0103  \n",
      "\n",
      "Fold: 32  Epoch: 206  Training loss = 2.2643  Validation loss = 3.0095  \n",
      "\n",
      "Fold: 32  Epoch: 207  Training loss = 2.2643  Validation loss = 3.0092  \n",
      "\n",
      "Fold: 32  Epoch: 208  Training loss = 2.2642  Validation loss = 3.0086  \n",
      "\n",
      "Fold: 32  Epoch: 209  Training loss = 2.2641  Validation loss = 3.0076  \n",
      "\n",
      "Fold: 32  Epoch: 210  Training loss = 2.2639  Validation loss = 3.0066  \n",
      "\n",
      "Fold: 32  Epoch: 211  Training loss = 2.2639  Validation loss = 3.0062  \n",
      "\n",
      "Fold: 32  Epoch: 212  Training loss = 2.2638  Validation loss = 3.0057  \n",
      "\n",
      "Fold: 32  Epoch: 213  Training loss = 2.2637  Validation loss = 3.0056  \n",
      "\n",
      "Fold: 32  Epoch: 214  Training loss = 2.2637  Validation loss = 3.0051  \n",
      "\n",
      "Fold: 32  Epoch: 215  Training loss = 2.2636  Validation loss = 3.0044  \n",
      "\n",
      "Fold: 32  Epoch: 216  Training loss = 2.2635  Validation loss = 3.0043  \n",
      "\n",
      "Fold: 32  Epoch: 217  Training loss = 2.2634  Validation loss = 3.0039  \n",
      "\n",
      "Fold: 32  Epoch: 218  Training loss = 2.2633  Validation loss = 3.0031  \n",
      "\n",
      "Fold: 32  Epoch: 219  Training loss = 2.2632  Validation loss = 3.0027  \n",
      "\n",
      "Fold: 32  Epoch: 220  Training loss = 2.2632  Validation loss = 3.0029  \n",
      "\n",
      "Fold: 32  Epoch: 221  Training loss = 2.2631  Validation loss = 3.0022  \n",
      "\n",
      "Fold: 32  Epoch: 222  Training loss = 2.2631  Validation loss = 3.0020  \n",
      "\n",
      "Fold: 32  Epoch: 223  Training loss = 2.2630  Validation loss = 3.0009  \n",
      "\n",
      "Fold: 32  Epoch: 224  Training loss = 2.2628  Validation loss = 2.9998  \n",
      "\n",
      "Fold: 32  Epoch: 225  Training loss = 2.2627  Validation loss = 2.9991  \n",
      "\n",
      "Fold: 32  Epoch: 226  Training loss = 2.2626  Validation loss = 2.9982  \n",
      "\n",
      "Fold: 32  Epoch: 227  Training loss = 2.2625  Validation loss = 2.9976  \n",
      "\n",
      "Fold: 32  Epoch: 228  Training loss = 2.2624  Validation loss = 2.9973  \n",
      "\n",
      "Fold: 32  Epoch: 229  Training loss = 2.2624  Validation loss = 2.9973  \n",
      "\n",
      "Fold: 32  Epoch: 230  Training loss = 2.2624  Validation loss = 2.9972  \n",
      "\n",
      "Fold: 32  Epoch: 231  Training loss = 2.2623  Validation loss = 2.9969  \n",
      "\n",
      "Fold: 32  Epoch: 232  Training loss = 2.2622  Validation loss = 2.9964  \n",
      "\n",
      "Fold: 32  Epoch: 233  Training loss = 2.2621  Validation loss = 2.9949  \n",
      "\n",
      "Fold: 32  Epoch: 234  Training loss = 2.2620  Validation loss = 2.9944  \n",
      "\n",
      "Fold: 32  Epoch: 235  Training loss = 2.2618  Validation loss = 2.9933  \n",
      "\n",
      "Fold: 32  Epoch: 236  Training loss = 2.2617  Validation loss = 2.9924  \n",
      "\n",
      "Fold: 32  Epoch: 237  Training loss = 2.2616  Validation loss = 2.9918  \n",
      "\n",
      "Fold: 32  Epoch: 238  Training loss = 2.2615  Validation loss = 2.9908  \n",
      "\n",
      "Fold: 32  Epoch: 239  Training loss = 2.2615  Validation loss = 2.9907  \n",
      "\n",
      "Fold: 32  Epoch: 240  Training loss = 2.2614  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 32  Epoch: 241  Training loss = 2.2613  Validation loss = 2.9899  \n",
      "\n",
      "Fold: 32  Epoch: 242  Training loss = 2.2612  Validation loss = 2.9890  \n",
      "\n",
      "Fold: 32  Epoch: 243  Training loss = 2.2611  Validation loss = 2.9879  \n",
      "\n",
      "Fold: 32  Epoch: 244  Training loss = 2.2610  Validation loss = 2.9876  \n",
      "\n",
      "Fold: 32  Epoch: 245  Training loss = 2.2609  Validation loss = 2.9872  \n",
      "\n",
      "Fold: 32  Epoch: 246  Training loss = 2.2608  Validation loss = 2.9861  \n",
      "\n",
      "Fold: 32  Epoch: 247  Training loss = 2.2608  Validation loss = 2.9861  \n",
      "\n",
      "Fold: 32  Epoch: 248  Training loss = 2.2608  Validation loss = 2.9865  \n",
      "\n",
      "Fold: 32  Epoch: 249  Training loss = 2.2607  Validation loss = 2.9863  \n",
      "\n",
      "Fold: 32  Epoch: 250  Training loss = 2.2607  Validation loss = 2.9860  \n",
      "\n",
      "Fold: 32  Epoch: 251  Training loss = 2.2606  Validation loss = 2.9861  \n",
      "\n",
      "Fold: 32  Epoch: 252  Training loss = 2.2605  Validation loss = 2.9853  \n",
      "\n",
      "Fold: 32  Epoch: 253  Training loss = 2.2605  Validation loss = 2.9848  \n",
      "\n",
      "Fold: 32  Epoch: 254  Training loss = 2.2604  Validation loss = 2.9844  \n",
      "\n",
      "Fold: 32  Epoch: 255  Training loss = 2.2603  Validation loss = 2.9837  \n",
      "\n",
      "Fold: 32  Epoch: 256  Training loss = 2.2602  Validation loss = 2.9833  \n",
      "\n",
      "Fold: 32  Epoch: 257  Training loss = 2.2601  Validation loss = 2.9822  \n",
      "\n",
      "Fold: 32  Epoch: 258  Training loss = 2.2600  Validation loss = 2.9814  \n",
      "\n",
      "Fold: 32  Epoch: 259  Training loss = 2.2600  Validation loss = 2.9816  \n",
      "\n",
      "Fold: 32  Epoch: 260  Training loss = 2.2598  Validation loss = 2.9803  \n",
      "\n",
      "Fold: 32  Epoch: 261  Training loss = 2.2597  Validation loss = 2.9797  \n",
      "\n",
      "Fold: 32  Epoch: 262  Training loss = 2.2596  Validation loss = 2.9790  \n",
      "\n",
      "Fold: 32  Epoch: 263  Training loss = 2.2596  Validation loss = 2.9787  \n",
      "\n",
      "Fold: 32  Epoch: 264  Training loss = 2.2595  Validation loss = 2.9783  \n",
      "\n",
      "Fold: 32  Epoch: 265  Training loss = 2.2594  Validation loss = 2.9772  \n",
      "\n",
      "Fold: 32  Epoch: 266  Training loss = 2.2594  Validation loss = 2.9771  \n",
      "\n",
      "Fold: 32  Epoch: 267  Training loss = 2.2593  Validation loss = 2.9772  \n",
      "\n",
      "Fold: 32  Epoch: 268  Training loss = 2.2592  Validation loss = 2.9762  \n",
      "\n",
      "Fold: 32  Epoch: 269  Training loss = 2.2591  Validation loss = 2.9753  \n",
      "\n",
      "Fold: 32  Epoch: 270  Training loss = 2.2590  Validation loss = 2.9750  \n",
      "\n",
      "Fold: 32  Epoch: 271  Training loss = 2.2590  Validation loss = 2.9756  \n",
      "\n",
      "Fold: 32  Epoch: 272  Training loss = 2.2590  Validation loss = 2.9753  \n",
      "\n",
      "Fold: 32  Epoch: 273  Training loss = 2.2589  Validation loss = 2.9749  \n",
      "\n",
      "Fold: 32  Epoch: 274  Training loss = 2.2588  Validation loss = 2.9742  \n",
      "\n",
      "Fold: 32  Epoch: 275  Training loss = 2.2587  Validation loss = 2.9732  \n",
      "\n",
      "Fold: 32  Epoch: 276  Training loss = 2.2586  Validation loss = 2.9723  \n",
      "\n",
      "Fold: 32  Epoch: 277  Training loss = 2.2584  Validation loss = 2.9713  \n",
      "\n",
      "Fold: 32  Epoch: 278  Training loss = 2.2584  Validation loss = 2.9709  \n",
      "\n",
      "Fold: 32  Epoch: 279  Training loss = 2.2583  Validation loss = 2.9700  \n",
      "\n",
      "Fold: 32  Epoch: 280  Training loss = 2.2582  Validation loss = 2.9692  \n",
      "\n",
      "Fold: 32  Epoch: 281  Training loss = 2.2581  Validation loss = 2.9685  \n",
      "\n",
      "Fold: 32  Epoch: 282  Training loss = 2.2580  Validation loss = 2.9683  \n",
      "\n",
      "Fold: 32  Epoch: 283  Training loss = 2.2580  Validation loss = 2.9679  \n",
      "\n",
      "Fold: 32  Epoch: 284  Training loss = 2.2578  Validation loss = 2.9670  \n",
      "\n",
      "Fold: 32  Epoch: 285  Training loss = 2.2578  Validation loss = 2.9668  \n",
      "\n",
      "Fold: 32  Epoch: 286  Training loss = 2.2577  Validation loss = 2.9658  \n",
      "\n",
      "Fold: 32  Epoch: 287  Training loss = 2.2576  Validation loss = 2.9651  \n",
      "\n",
      "Fold: 32  Epoch: 288  Training loss = 2.2575  Validation loss = 2.9645  \n",
      "\n",
      "Fold: 32  Epoch: 289  Training loss = 2.2574  Validation loss = 2.9632  \n",
      "\n",
      "Fold: 32  Epoch: 290  Training loss = 2.2573  Validation loss = 2.9625  \n",
      "\n",
      "Fold: 32  Epoch: 291  Training loss = 2.2572  Validation loss = 2.9617  \n",
      "\n",
      "Fold: 32  Epoch: 292  Training loss = 2.2571  Validation loss = 2.9606  \n",
      "\n",
      "Fold: 32  Epoch: 293  Training loss = 2.2570  Validation loss = 2.9599  \n",
      "\n",
      "Fold: 32  Epoch: 294  Training loss = 2.2569  Validation loss = 2.9595  \n",
      "\n",
      "Fold: 32  Epoch: 295  Training loss = 2.2568  Validation loss = 2.9592  \n",
      "\n",
      "Fold: 32  Epoch: 296  Training loss = 2.2568  Validation loss = 2.9586  \n",
      "\n",
      "Fold: 32  Epoch: 297  Training loss = 2.2567  Validation loss = 2.9582  \n",
      "\n",
      "Fold: 32  Epoch: 298  Training loss = 2.2566  Validation loss = 2.9579  \n",
      "\n",
      "Fold: 32  Epoch: 299  Training loss = 2.2566  Validation loss = 2.9575  \n",
      "\n",
      "Fold: 32  Epoch: 300  Training loss = 2.2565  Validation loss = 2.9574  \n",
      "\n",
      "Fold: 32  Epoch: 301  Training loss = 2.2565  Validation loss = 2.9570  \n",
      "\n",
      "Fold: 32  Epoch: 302  Training loss = 2.2564  Validation loss = 2.9562  \n",
      "\n",
      "Fold: 32  Epoch: 303  Training loss = 2.2563  Validation loss = 2.9554  \n",
      "\n",
      "Fold: 32  Epoch: 304  Training loss = 2.2563  Validation loss = 2.9550  \n",
      "\n",
      "Fold: 32  Epoch: 305  Training loss = 2.2562  Validation loss = 2.9545  \n",
      "\n",
      "Fold: 32  Epoch: 306  Training loss = 2.2561  Validation loss = 2.9538  \n",
      "\n",
      "Fold: 32  Epoch: 307  Training loss = 2.2560  Validation loss = 2.9526  \n",
      "\n",
      "Fold: 32  Epoch: 308  Training loss = 2.2559  Validation loss = 2.9522  \n",
      "\n",
      "Fold: 32  Epoch: 309  Training loss = 2.2558  Validation loss = 2.9509  \n",
      "\n",
      "Fold: 32  Epoch: 310  Training loss = 2.2557  Validation loss = 2.9504  \n",
      "\n",
      "Fold: 32  Epoch: 311  Training loss = 2.2556  Validation loss = 2.9496  \n",
      "\n",
      "Fold: 32  Epoch: 312  Training loss = 2.2555  Validation loss = 2.9490  \n",
      "\n",
      "Fold: 32  Epoch: 313  Training loss = 2.2554  Validation loss = 2.9484  \n",
      "\n",
      "Fold: 32  Epoch: 314  Training loss = 2.2553  Validation loss = 2.9479  \n",
      "\n",
      "Fold: 32  Epoch: 315  Training loss = 2.2552  Validation loss = 2.9470  \n",
      "\n",
      "Fold: 32  Epoch: 316  Training loss = 2.2552  Validation loss = 2.9471  \n",
      "\n",
      "Fold: 32  Epoch: 317  Training loss = 2.2552  Validation loss = 2.9468  \n",
      "\n",
      "Fold: 32  Epoch: 318  Training loss = 2.2551  Validation loss = 2.9466  \n",
      "\n",
      "Fold: 32  Epoch: 319  Training loss = 2.2550  Validation loss = 2.9462  \n",
      "\n",
      "Fold: 32  Epoch: 320  Training loss = 2.2549  Validation loss = 2.9453  \n",
      "\n",
      "Fold: 32  Epoch: 321  Training loss = 2.2549  Validation loss = 2.9449  \n",
      "\n",
      "Fold: 32  Epoch: 322  Training loss = 2.2548  Validation loss = 2.9446  \n",
      "\n",
      "Fold: 32  Epoch: 323  Training loss = 2.2547  Validation loss = 2.9441  \n",
      "\n",
      "Fold: 32  Epoch: 324  Training loss = 2.2547  Validation loss = 2.9436  \n",
      "\n",
      "Fold: 32  Epoch: 325  Training loss = 2.2546  Validation loss = 2.9429  \n",
      "\n",
      "Fold: 32  Epoch: 326  Training loss = 2.2545  Validation loss = 2.9420  \n",
      "\n",
      "Fold: 32  Epoch: 327  Training loss = 2.2543  Validation loss = 2.9411  \n",
      "\n",
      "Fold: 32  Epoch: 328  Training loss = 2.2543  Validation loss = 2.9406  \n",
      "\n",
      "Fold: 32  Epoch: 329  Training loss = 2.2542  Validation loss = 2.9397  \n",
      "\n",
      "Fold: 32  Epoch: 330  Training loss = 2.2541  Validation loss = 2.9387  \n",
      "\n",
      "Fold: 32  Epoch: 331  Training loss = 2.2540  Validation loss = 2.9381  \n",
      "\n",
      "Fold: 32  Epoch: 332  Training loss = 2.2539  Validation loss = 2.9373  \n",
      "\n",
      "Fold: 32  Epoch: 333  Training loss = 2.2538  Validation loss = 2.9366  \n",
      "\n",
      "Fold: 32  Epoch: 334  Training loss = 2.2538  Validation loss = 2.9368  \n",
      "\n",
      "Fold: 32  Epoch: 335  Training loss = 2.2537  Validation loss = 2.9355  \n",
      "\n",
      "Fold: 32  Epoch: 336  Training loss = 2.2536  Validation loss = 2.9347  \n",
      "\n",
      "Fold: 32  Epoch: 337  Training loss = 2.2535  Validation loss = 2.9337  \n",
      "\n",
      "Fold: 32  Epoch: 338  Training loss = 2.2534  Validation loss = 2.9337  \n",
      "\n",
      "Fold: 32  Epoch: 339  Training loss = 2.2534  Validation loss = 2.9336  \n",
      "\n",
      "Fold: 32  Epoch: 340  Training loss = 2.2533  Validation loss = 2.9325  \n",
      "\n",
      "Fold: 32  Epoch: 341  Training loss = 2.2531  Validation loss = 2.9312  \n",
      "\n",
      "Fold: 32  Epoch: 342  Training loss = 2.2531  Validation loss = 2.9309  \n",
      "\n",
      "Fold: 32  Epoch: 343  Training loss = 2.2530  Validation loss = 2.9300  \n",
      "\n",
      "Fold: 32  Epoch: 344  Training loss = 2.2529  Validation loss = 2.9287  \n",
      "\n",
      "Fold: 32  Epoch: 345  Training loss = 2.2528  Validation loss = 2.9284  \n",
      "\n",
      "Fold: 32  Epoch: 346  Training loss = 2.2528  Validation loss = 2.9285  \n",
      "\n",
      "Fold: 32  Epoch: 347  Training loss = 2.2527  Validation loss = 2.9279  \n",
      "\n",
      "Fold: 32  Epoch: 348  Training loss = 2.2526  Validation loss = 2.9273  \n",
      "\n",
      "Fold: 32  Epoch: 349  Training loss = 2.2525  Validation loss = 2.9269  \n",
      "\n",
      "Fold: 32  Epoch: 350  Training loss = 2.2524  Validation loss = 2.9263  \n",
      "\n",
      "Fold: 32  Epoch: 351  Training loss = 2.2524  Validation loss = 2.9259  \n",
      "\n",
      "Fold: 32  Epoch: 352  Training loss = 2.2523  Validation loss = 2.9256  \n",
      "\n",
      "Fold: 32  Epoch: 353  Training loss = 2.2522  Validation loss = 2.9245  \n",
      "\n",
      "Fold: 32  Epoch: 354  Training loss = 2.2521  Validation loss = 2.9242  \n",
      "\n",
      "Fold: 32  Epoch: 355  Training loss = 2.2521  Validation loss = 2.9242  \n",
      "\n",
      "Fold: 32  Epoch: 356  Training loss = 2.2520  Validation loss = 2.9233  \n",
      "\n",
      "Fold: 32  Epoch: 357  Training loss = 2.2520  Validation loss = 2.9227  \n",
      "\n",
      "Fold: 32  Epoch: 358  Training loss = 2.2519  Validation loss = 2.9225  \n",
      "\n",
      "Fold: 32  Epoch: 359  Training loss = 2.2518  Validation loss = 2.9224  \n",
      "\n",
      "Fold: 32  Epoch: 360  Training loss = 2.2518  Validation loss = 2.9222  \n",
      "\n",
      "Fold: 32  Epoch: 361  Training loss = 2.2517  Validation loss = 2.9216  \n",
      "\n",
      "Fold: 32  Epoch: 362  Training loss = 2.2517  Validation loss = 2.9218  \n",
      "\n",
      "Fold: 32  Epoch: 363  Training loss = 2.2516  Validation loss = 2.9208  \n",
      "\n",
      "Fold: 32  Epoch: 364  Training loss = 2.2515  Validation loss = 2.9208  \n",
      "\n",
      "Fold: 32  Epoch: 365  Training loss = 2.2515  Validation loss = 2.9206  \n",
      "\n",
      "Fold: 32  Epoch: 366  Training loss = 2.2514  Validation loss = 2.9201  \n",
      "\n",
      "Fold: 32  Epoch: 367  Training loss = 2.2514  Validation loss = 2.9200  \n",
      "\n",
      "Fold: 32  Epoch: 368  Training loss = 2.2514  Validation loss = 2.9196  \n",
      "\n",
      "Fold: 32  Epoch: 369  Training loss = 2.2513  Validation loss = 2.9192  \n",
      "\n",
      "Fold: 32  Epoch: 370  Training loss = 2.2513  Validation loss = 2.9191  \n",
      "\n",
      "Fold: 32  Epoch: 371  Training loss = 2.2512  Validation loss = 2.9180  \n",
      "\n",
      "Fold: 32  Epoch: 372  Training loss = 2.2511  Validation loss = 2.9177  \n",
      "\n",
      "Fold: 32  Epoch: 373  Training loss = 2.2510  Validation loss = 2.9170  \n",
      "\n",
      "Fold: 32  Epoch: 374  Training loss = 2.2510  Validation loss = 2.9168  \n",
      "\n",
      "Fold: 32  Epoch: 375  Training loss = 2.2509  Validation loss = 2.9167  \n",
      "\n",
      "Fold: 32  Epoch: 376  Training loss = 2.2508  Validation loss = 2.9162  \n",
      "\n",
      "Fold: 32  Epoch: 377  Training loss = 2.2508  Validation loss = 2.9157  \n",
      "\n",
      "Fold: 32  Epoch: 378  Training loss = 2.2507  Validation loss = 2.9153  \n",
      "\n",
      "Fold: 32  Epoch: 379  Training loss = 2.2506  Validation loss = 2.9146  \n",
      "\n",
      "Fold: 32  Epoch: 380  Training loss = 2.2505  Validation loss = 2.9137  \n",
      "\n",
      "Fold: 32  Epoch: 381  Training loss = 2.2504  Validation loss = 2.9134  \n",
      "\n",
      "Fold: 32  Epoch: 382  Training loss = 2.2504  Validation loss = 2.9132  \n",
      "\n",
      "Fold: 32  Epoch: 383  Training loss = 2.2503  Validation loss = 2.9126  \n",
      "\n",
      "Fold: 32  Epoch: 384  Training loss = 2.2502  Validation loss = 2.9116  \n",
      "\n",
      "Fold: 32  Epoch: 385  Training loss = 2.2502  Validation loss = 2.9118  \n",
      "\n",
      "Fold: 32  Epoch: 386  Training loss = 2.2502  Validation loss = 2.9122  \n",
      "\n",
      "Fold: 32  Epoch: 387  Training loss = 2.2501  Validation loss = 2.9119  \n",
      "\n",
      "Fold: 32  Epoch: 388  Training loss = 2.2500  Validation loss = 2.9107  \n",
      "\n",
      "Fold: 32  Epoch: 389  Training loss = 2.2499  Validation loss = 2.9101  \n",
      "\n",
      "Fold: 32  Epoch: 390  Training loss = 2.2498  Validation loss = 2.9098  \n",
      "\n",
      "Fold: 32  Epoch: 391  Training loss = 2.2498  Validation loss = 2.9093  \n",
      "\n",
      "Fold: 32  Epoch: 392  Training loss = 2.2497  Validation loss = 2.9092  \n",
      "\n",
      "Fold: 32  Epoch: 393  Training loss = 2.2497  Validation loss = 2.9087  \n",
      "\n",
      "Fold: 32  Epoch: 394  Training loss = 2.2495  Validation loss = 2.9076  \n",
      "\n",
      "Fold: 32  Epoch: 395  Training loss = 2.2494  Validation loss = 2.9066  \n",
      "\n",
      "Fold: 32  Epoch: 396  Training loss = 2.2493  Validation loss = 2.9055  \n",
      "\n",
      "Fold: 32  Epoch: 397  Training loss = 2.2493  Validation loss = 2.9053  \n",
      "\n",
      "Fold: 32  Epoch: 398  Training loss = 2.2492  Validation loss = 2.9044  \n",
      "\n",
      "Fold: 32  Epoch: 399  Training loss = 2.2491  Validation loss = 2.9038  \n",
      "\n",
      "Fold: 32  Epoch: 400  Training loss = 2.2490  Validation loss = 2.9035  \n",
      "\n",
      "Fold: 32  Epoch: 401  Training loss = 2.2489  Validation loss = 2.9023  \n",
      "\n",
      "Fold: 32  Epoch: 402  Training loss = 2.2488  Validation loss = 2.9016  \n",
      "\n",
      "Fold: 32  Epoch: 403  Training loss = 2.2487  Validation loss = 2.9004  \n",
      "\n",
      "Fold: 32  Epoch: 404  Training loss = 2.2486  Validation loss = 2.8993  \n",
      "\n",
      "Fold: 32  Epoch: 405  Training loss = 2.2484  Validation loss = 2.8982  \n",
      "\n",
      "Fold: 32  Epoch: 406  Training loss = 2.2484  Validation loss = 2.8983  \n",
      "\n",
      "Fold: 32  Epoch: 407  Training loss = 2.2483  Validation loss = 2.8978  \n",
      "\n",
      "Fold: 32  Epoch: 408  Training loss = 2.2484  Validation loss = 2.8984  \n",
      "\n",
      "Fold: 32  Epoch: 409  Training loss = 2.2483  Validation loss = 2.8977  \n",
      "\n",
      "Fold: 32  Epoch: 410  Training loss = 2.2482  Validation loss = 2.8972  \n",
      "\n",
      "Fold: 32  Epoch: 411  Training loss = 2.2481  Validation loss = 2.8967  \n",
      "\n",
      "Fold: 32  Epoch: 412  Training loss = 2.2481  Validation loss = 2.8961  \n",
      "\n",
      "Fold: 32  Epoch: 413  Training loss = 2.2480  Validation loss = 2.8952  \n",
      "\n",
      "Fold: 32  Epoch: 414  Training loss = 2.2479  Validation loss = 2.8952  \n",
      "\n",
      "Fold: 32  Epoch: 415  Training loss = 2.2478  Validation loss = 2.8940  \n",
      "\n",
      "Fold: 32  Epoch: 416  Training loss = 2.2478  Validation loss = 2.8935  \n",
      "\n",
      "Fold: 32  Epoch: 417  Training loss = 2.2477  Validation loss = 2.8928  \n",
      "\n",
      "Fold: 32  Epoch: 418  Training loss = 2.2476  Validation loss = 2.8925  \n",
      "\n",
      "Fold: 32  Epoch: 419  Training loss = 2.2475  Validation loss = 2.8917  \n",
      "\n",
      "Fold: 32  Epoch: 420  Training loss = 2.2475  Validation loss = 2.8912  \n",
      "\n",
      "Fold: 32  Epoch: 421  Training loss = 2.2474  Validation loss = 2.8904  \n",
      "\n",
      "Fold: 32  Epoch: 422  Training loss = 2.2473  Validation loss = 2.8901  \n",
      "\n",
      "Fold: 32  Epoch: 423  Training loss = 2.2473  Validation loss = 2.8901  \n",
      "\n",
      "Fold: 32  Epoch: 424  Training loss = 2.2472  Validation loss = 2.8894  \n",
      "\n",
      "Fold: 32  Epoch: 425  Training loss = 2.2472  Validation loss = 2.8898  \n",
      "\n",
      "Fold: 32  Epoch: 426  Training loss = 2.2472  Validation loss = 2.8894  \n",
      "\n",
      "Fold: 32  Epoch: 427  Training loss = 2.2471  Validation loss = 2.8885  \n",
      "\n",
      "Fold: 32  Epoch: 428  Training loss = 2.2470  Validation loss = 2.8883  \n",
      "\n",
      "Fold: 32  Epoch: 429  Training loss = 2.2470  Validation loss = 2.8883  \n",
      "\n",
      "Fold: 32  Epoch: 430  Training loss = 2.2470  Validation loss = 2.8882  \n",
      "\n",
      "Fold: 32  Epoch: 431  Training loss = 2.2470  Validation loss = 2.8885  \n",
      "\n",
      "Fold: 32  Epoch: 432  Training loss = 2.2469  Validation loss = 2.8883  \n",
      "\n",
      "Fold: 32  Epoch: 433  Training loss = 2.2469  Validation loss = 2.8883  \n",
      "\n",
      "Fold: 32  Epoch: 434  Training loss = 2.2468  Validation loss = 2.8876  \n",
      "\n",
      "Fold: 32  Epoch: 435  Training loss = 2.2467  Validation loss = 2.8867  \n",
      "\n",
      "Fold: 32  Epoch: 436  Training loss = 2.2466  Validation loss = 2.8861  \n",
      "\n",
      "Fold: 32  Epoch: 437  Training loss = 2.2466  Validation loss = 2.8854  \n",
      "\n",
      "Fold: 32  Epoch: 438  Training loss = 2.2465  Validation loss = 2.8850  \n",
      "\n",
      "Fold: 32  Epoch: 439  Training loss = 2.2465  Validation loss = 2.8845  \n",
      "\n",
      "Fold: 32  Epoch: 440  Training loss = 2.2464  Validation loss = 2.8845  \n",
      "\n",
      "Fold: 32  Epoch: 441  Training loss = 2.2463  Validation loss = 2.8838  \n",
      "\n",
      "Fold: 32  Epoch: 442  Training loss = 2.2463  Validation loss = 2.8834  \n",
      "\n",
      "Fold: 32  Epoch: 443  Training loss = 2.2462  Validation loss = 2.8826  \n",
      "\n",
      "Fold: 32  Epoch: 444  Training loss = 2.2461  Validation loss = 2.8817  \n",
      "\n",
      "Fold: 32  Epoch: 445  Training loss = 2.2460  Validation loss = 2.8809  \n",
      "\n",
      "Fold: 32  Epoch: 446  Training loss = 2.2459  Validation loss = 2.8802  \n",
      "\n",
      "Fold: 32  Epoch: 447  Training loss = 2.2458  Validation loss = 2.8791  \n",
      "\n",
      "Fold: 32  Epoch: 448  Training loss = 2.2458  Validation loss = 2.8796  \n",
      "\n",
      "Fold: 32  Epoch: 449  Training loss = 2.2458  Validation loss = 2.8790  \n",
      "\n",
      "Fold: 32  Epoch: 450  Training loss = 2.2457  Validation loss = 2.8786  \n",
      "\n",
      "Fold: 32  Epoch: 451  Training loss = 2.2456  Validation loss = 2.8774  \n",
      "\n",
      "Fold: 32  Epoch: 452  Training loss = 2.2455  Validation loss = 2.8770  \n",
      "\n",
      "Fold: 32  Epoch: 453  Training loss = 2.2454  Validation loss = 2.8765  \n",
      "\n",
      "Fold: 32  Epoch: 454  Training loss = 2.2454  Validation loss = 2.8760  \n",
      "\n",
      "Fold: 32  Epoch: 455  Training loss = 2.2453  Validation loss = 2.8755  \n",
      "\n",
      "Fold: 32  Epoch: 456  Training loss = 2.2453  Validation loss = 2.8747  \n",
      "\n",
      "Fold: 32  Epoch: 457  Training loss = 2.2452  Validation loss = 2.8741  \n",
      "\n",
      "Fold: 32  Epoch: 458  Training loss = 2.2452  Validation loss = 2.8747  \n",
      "\n",
      "Fold: 32  Epoch: 459  Training loss = 2.2451  Validation loss = 2.8741  \n",
      "\n",
      "Fold: 32  Epoch: 460  Training loss = 2.2451  Validation loss = 2.8735  \n",
      "\n",
      "Fold: 32  Epoch: 461  Training loss = 2.2450  Validation loss = 2.8735  \n",
      "\n",
      "Fold: 32  Epoch: 462  Training loss = 2.2450  Validation loss = 2.8730  \n",
      "\n",
      "Fold: 32  Epoch: 463  Training loss = 2.2449  Validation loss = 2.8728  \n",
      "\n",
      "Fold: 32  Epoch: 464  Training loss = 2.2448  Validation loss = 2.8723  \n",
      "\n",
      "Fold: 32  Epoch: 465  Training loss = 2.2448  Validation loss = 2.8718  \n",
      "\n",
      "Fold: 32  Epoch: 466  Training loss = 2.2447  Validation loss = 2.8708  \n",
      "\n",
      "Fold: 32  Epoch: 467  Training loss = 2.2446  Validation loss = 2.8701  \n",
      "\n",
      "Fold: 32  Epoch: 468  Training loss = 2.2445  Validation loss = 2.8698  \n",
      "\n",
      "Fold: 32  Epoch: 469  Training loss = 2.2444  Validation loss = 2.8691  \n",
      "\n",
      "Fold: 32  Epoch: 470  Training loss = 2.2444  Validation loss = 2.8690  \n",
      "\n",
      "Fold: 32  Epoch: 471  Training loss = 2.2443  Validation loss = 2.8682  \n",
      "\n",
      "Fold: 32  Epoch: 472  Training loss = 2.2442  Validation loss = 2.8677  \n",
      "\n",
      "Fold: 32  Epoch: 473  Training loss = 2.2441  Validation loss = 2.8673  \n",
      "\n",
      "Fold: 32  Epoch: 474  Training loss = 2.2440  Validation loss = 2.8663  \n",
      "\n",
      "Fold: 32  Epoch: 475  Training loss = 2.2440  Validation loss = 2.8659  \n",
      "\n",
      "Fold: 32  Epoch: 476  Training loss = 2.2439  Validation loss = 2.8656  \n",
      "\n",
      "Fold: 32  Epoch: 477  Training loss = 2.2438  Validation loss = 2.8649  \n",
      "\n",
      "Fold: 32  Epoch: 478  Training loss = 2.2437  Validation loss = 2.8645  \n",
      "\n",
      "Fold: 32  Epoch: 479  Training loss = 2.2436  Validation loss = 2.8634  \n",
      "\n",
      "Fold: 32  Epoch: 480  Training loss = 2.2436  Validation loss = 2.8633  \n",
      "\n",
      "Fold: 32  Epoch: 481  Training loss = 2.2435  Validation loss = 2.8627  \n",
      "\n",
      "Fold: 32  Epoch: 482  Training loss = 2.2435  Validation loss = 2.8626  \n",
      "\n",
      "Fold: 32  Epoch: 483  Training loss = 2.2434  Validation loss = 2.8618  \n",
      "\n",
      "Fold: 32  Epoch: 484  Training loss = 2.2434  Validation loss = 2.8618  \n",
      "\n",
      "Fold: 32  Epoch: 485  Training loss = 2.2433  Validation loss = 2.8616  \n",
      "\n",
      "Fold: 32  Epoch: 486  Training loss = 2.2433  Validation loss = 2.8612  \n",
      "\n",
      "Fold: 32  Epoch: 487  Training loss = 2.2432  Validation loss = 2.8606  \n",
      "\n",
      "Fold: 32  Epoch: 488  Training loss = 2.2432  Validation loss = 2.8604  \n",
      "\n",
      "Fold: 32  Epoch: 489  Training loss = 2.2431  Validation loss = 2.8608  \n",
      "\n",
      "Fold: 32  Epoch: 490  Training loss = 2.2431  Validation loss = 2.8603  \n",
      "\n",
      "Fold: 32  Epoch: 491  Training loss = 2.2430  Validation loss = 2.8595  \n",
      "\n",
      "Fold: 32  Epoch: 492  Training loss = 2.2429  Validation loss = 2.8588  \n",
      "\n",
      "Fold: 32  Epoch: 493  Training loss = 2.2429  Validation loss = 2.8587  \n",
      "\n",
      "Fold: 32  Epoch: 494  Training loss = 2.2428  Validation loss = 2.8581  \n",
      "\n",
      "Fold: 32  Epoch: 495  Training loss = 2.2427  Validation loss = 2.8572  \n",
      "\n",
      "Fold: 32  Epoch: 496  Training loss = 2.2427  Validation loss = 2.8568  \n",
      "\n",
      "Fold: 32  Epoch: 497  Training loss = 2.2426  Validation loss = 2.8565  \n",
      "\n",
      "Fold: 32  Epoch: 498  Training loss = 2.2425  Validation loss = 2.8561  \n",
      "\n",
      "Fold: 32  Epoch: 499  Training loss = 2.2425  Validation loss = 2.8552  \n",
      "\n",
      "Fold: 32  Epoch: 500  Training loss = 2.2424  Validation loss = 2.8547  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 500  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 368\n",
      "Average validation error: 3.98414\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.9291  Test loss = 2.8613  \n",
      "\n",
      "Epoch: 2  Training loss = 1.9291  Test loss = 2.8613  \n",
      "\n",
      "Epoch: 3  Training loss = 1.9291  Test loss = 2.8612  \n",
      "\n",
      "Epoch: 4  Training loss = 1.9290  Test loss = 2.8612  \n",
      "\n",
      "Epoch: 5  Training loss = 1.9290  Test loss = 2.8611  \n",
      "\n",
      "Epoch: 6  Training loss = 1.9290  Test loss = 2.8611  \n",
      "\n",
      "Epoch: 7  Training loss = 1.9289  Test loss = 2.8610  \n",
      "\n",
      "Epoch: 8  Training loss = 1.9289  Test loss = 2.8610  \n",
      "\n",
      "Epoch: 9  Training loss = 1.9289  Test loss = 2.8609  \n",
      "\n",
      "Epoch: 10  Training loss = 1.9289  Test loss = 2.8609  \n",
      "\n",
      "Epoch: 11  Training loss = 1.9288  Test loss = 2.8608  \n",
      "\n",
      "Epoch: 12  Training loss = 1.9288  Test loss = 2.8608  \n",
      "\n",
      "Epoch: 13  Training loss = 1.9288  Test loss = 2.8608  \n",
      "\n",
      "Epoch: 14  Training loss = 1.9287  Test loss = 2.8607  \n",
      "\n",
      "Epoch: 15  Training loss = 1.9287  Test loss = 2.8607  \n",
      "\n",
      "Epoch: 16  Training loss = 1.9287  Test loss = 2.8606  \n",
      "\n",
      "Epoch: 17  Training loss = 1.9287  Test loss = 2.8606  \n",
      "\n",
      "Epoch: 18  Training loss = 1.9286  Test loss = 2.8605  \n",
      "\n",
      "Epoch: 19  Training loss = 1.9286  Test loss = 2.8605  \n",
      "\n",
      "Epoch: 20  Training loss = 1.9286  Test loss = 2.8604  \n",
      "\n",
      "Epoch: 21  Training loss = 1.9286  Test loss = 2.8604  \n",
      "\n",
      "Epoch: 22  Training loss = 1.9285  Test loss = 2.8603  \n",
      "\n",
      "Epoch: 23  Training loss = 1.9285  Test loss = 2.8603  \n",
      "\n",
      "Epoch: 24  Training loss = 1.9285  Test loss = 2.8602  \n",
      "\n",
      "Epoch: 25  Training loss = 1.9284  Test loss = 2.8602  \n",
      "\n",
      "Epoch: 26  Training loss = 1.9284  Test loss = 2.8601  \n",
      "\n",
      "Epoch: 27  Training loss = 1.9284  Test loss = 2.8601  \n",
      "\n",
      "Epoch: 28  Training loss = 1.9284  Test loss = 2.8601  \n",
      "\n",
      "Epoch: 29  Training loss = 1.9283  Test loss = 2.8600  \n",
      "\n",
      "Epoch: 30  Training loss = 1.9283  Test loss = 2.8600  \n",
      "\n",
      "Epoch: 31  Training loss = 1.9283  Test loss = 2.8599  \n",
      "\n",
      "Epoch: 32  Training loss = 1.9282  Test loss = 2.8599  \n",
      "\n",
      "Epoch: 33  Training loss = 1.9282  Test loss = 2.8598  \n",
      "\n",
      "Epoch: 34  Training loss = 1.9282  Test loss = 2.8598  \n",
      "\n",
      "Epoch: 35  Training loss = 1.9282  Test loss = 2.8597  \n",
      "\n",
      "Epoch: 36  Training loss = 1.9281  Test loss = 2.8597  \n",
      "\n",
      "Epoch: 37  Training loss = 1.9281  Test loss = 2.8596  \n",
      "\n",
      "Epoch: 38  Training loss = 1.9281  Test loss = 2.8596  \n",
      "\n",
      "Epoch: 39  Training loss = 1.9280  Test loss = 2.8595  \n",
      "\n",
      "Epoch: 40  Training loss = 1.9280  Test loss = 2.8595  \n",
      "\n",
      "Epoch: 41  Training loss = 1.9280  Test loss = 2.8594  \n",
      "\n",
      "Epoch: 42  Training loss = 1.9280  Test loss = 2.8594  \n",
      "\n",
      "Epoch: 43  Training loss = 1.9279  Test loss = 2.8594  \n",
      "\n",
      "Epoch: 44  Training loss = 1.9279  Test loss = 2.8593  \n",
      "\n",
      "Epoch: 45  Training loss = 1.9279  Test loss = 2.8593  \n",
      "\n",
      "Epoch: 46  Training loss = 1.9279  Test loss = 2.8592  \n",
      "\n",
      "Epoch: 47  Training loss = 1.9278  Test loss = 2.8592  \n",
      "\n",
      "Epoch: 48  Training loss = 1.9278  Test loss = 2.8591  \n",
      "\n",
      "Epoch: 49  Training loss = 1.9278  Test loss = 2.8591  \n",
      "\n",
      "Epoch: 50  Training loss = 1.9277  Test loss = 2.8590  \n",
      "\n",
      "Epoch: 51  Training loss = 1.9277  Test loss = 2.8590  \n",
      "\n",
      "Epoch: 52  Training loss = 1.9277  Test loss = 2.8589  \n",
      "\n",
      "Epoch: 53  Training loss = 1.9277  Test loss = 2.8589  \n",
      "\n",
      "Epoch: 54  Training loss = 1.9276  Test loss = 2.8588  \n",
      "\n",
      "Epoch: 55  Training loss = 1.9276  Test loss = 2.8588  \n",
      "\n",
      "Epoch: 56  Training loss = 1.9276  Test loss = 2.8588  \n",
      "\n",
      "Epoch: 57  Training loss = 1.9275  Test loss = 2.8587  \n",
      "\n",
      "Epoch: 58  Training loss = 1.9275  Test loss = 2.8587  \n",
      "\n",
      "Epoch: 59  Training loss = 1.9275  Test loss = 2.8586  \n",
      "\n",
      "Epoch: 60  Training loss = 1.9275  Test loss = 2.8586  \n",
      "\n",
      "Epoch: 61  Training loss = 1.9274  Test loss = 2.8585  \n",
      "\n",
      "Epoch: 62  Training loss = 1.9274  Test loss = 2.8585  \n",
      "\n",
      "Epoch: 63  Training loss = 1.9274  Test loss = 2.8584  \n",
      "\n",
      "Epoch: 64  Training loss = 1.9274  Test loss = 2.8584  \n",
      "\n",
      "Epoch: 65  Training loss = 1.9273  Test loss = 2.8583  \n",
      "\n",
      "Epoch: 66  Training loss = 1.9273  Test loss = 2.8583  \n",
      "\n",
      "Epoch: 67  Training loss = 1.9273  Test loss = 2.8582  \n",
      "\n",
      "Epoch: 68  Training loss = 1.9272  Test loss = 2.8582  \n",
      "\n",
      "Epoch: 69  Training loss = 1.9272  Test loss = 2.8582  \n",
      "\n",
      "Epoch: 70  Training loss = 1.9272  Test loss = 2.8581  \n",
      "\n",
      "Epoch: 71  Training loss = 1.9272  Test loss = 2.8581  \n",
      "\n",
      "Epoch: 72  Training loss = 1.9271  Test loss = 2.8580  \n",
      "\n",
      "Epoch: 73  Training loss = 1.9271  Test loss = 2.8580  \n",
      "\n",
      "Epoch: 74  Training loss = 1.9271  Test loss = 2.8579  \n",
      "\n",
      "Epoch: 75  Training loss = 1.9270  Test loss = 2.8579  \n",
      "\n",
      "Epoch: 76  Training loss = 1.9270  Test loss = 2.8578  \n",
      "\n",
      "Epoch: 77  Training loss = 1.9270  Test loss = 2.8578  \n",
      "\n",
      "Epoch: 78  Training loss = 1.9270  Test loss = 2.8577  \n",
      "\n",
      "Epoch: 79  Training loss = 1.9269  Test loss = 2.8577  \n",
      "\n",
      "Epoch: 80  Training loss = 1.9269  Test loss = 2.8576  \n",
      "\n",
      "Epoch: 81  Training loss = 1.9269  Test loss = 2.8576  \n",
      "\n",
      "Epoch: 82  Training loss = 1.9269  Test loss = 2.8576  \n",
      "\n",
      "Epoch: 83  Training loss = 1.9268  Test loss = 2.8575  \n",
      "\n",
      "Epoch: 84  Training loss = 1.9268  Test loss = 2.8575  \n",
      "\n",
      "Epoch: 85  Training loss = 1.9268  Test loss = 2.8574  \n",
      "\n",
      "Epoch: 86  Training loss = 1.9267  Test loss = 2.8574  \n",
      "\n",
      "Epoch: 87  Training loss = 1.9267  Test loss = 2.8573  \n",
      "\n",
      "Epoch: 88  Training loss = 1.9267  Test loss = 2.8573  \n",
      "\n",
      "Epoch: 89  Training loss = 1.9267  Test loss = 2.8572  \n",
      "\n",
      "Epoch: 90  Training loss = 1.9266  Test loss = 2.8572  \n",
      "\n",
      "Epoch: 91  Training loss = 1.9266  Test loss = 2.8571  \n",
      "\n",
      "Epoch: 92  Training loss = 1.9266  Test loss = 2.8571  \n",
      "\n",
      "Epoch: 93  Training loss = 1.9265  Test loss = 2.8570  \n",
      "\n",
      "Epoch: 94  Training loss = 1.9265  Test loss = 2.8570  \n",
      "\n",
      "Epoch: 95  Training loss = 1.9265  Test loss = 2.8570  \n",
      "\n",
      "Epoch: 96  Training loss = 1.9265  Test loss = 2.8569  \n",
      "\n",
      "Epoch: 97  Training loss = 1.9264  Test loss = 2.8569  \n",
      "\n",
      "Epoch: 98  Training loss = 1.9264  Test loss = 2.8568  \n",
      "\n",
      "Epoch: 99  Training loss = 1.9264  Test loss = 2.8568  \n",
      "\n",
      "Epoch: 100  Training loss = 1.9264  Test loss = 2.8567  \n",
      "\n",
      "Epoch: 101  Training loss = 1.9263  Test loss = 2.8567  \n",
      "\n",
      "Epoch: 102  Training loss = 1.9263  Test loss = 2.8566  \n",
      "\n",
      "Epoch: 103  Training loss = 1.9263  Test loss = 2.8566  \n",
      "\n",
      "Epoch: 104  Training loss = 1.9262  Test loss = 2.8565  \n",
      "\n",
      "Epoch: 105  Training loss = 1.9262  Test loss = 2.8565  \n",
      "\n",
      "Epoch: 106  Training loss = 1.9262  Test loss = 2.8564  \n",
      "\n",
      "Epoch: 107  Training loss = 1.9262  Test loss = 2.8564  \n",
      "\n",
      "Epoch: 108  Training loss = 1.9261  Test loss = 2.8564  \n",
      "\n",
      "Epoch: 109  Training loss = 1.9261  Test loss = 2.8563  \n",
      "\n",
      "Epoch: 110  Training loss = 1.9261  Test loss = 2.8563  \n",
      "\n",
      "Epoch: 111  Training loss = 1.9260  Test loss = 2.8562  \n",
      "\n",
      "Epoch: 112  Training loss = 1.9260  Test loss = 2.8562  \n",
      "\n",
      "Epoch: 113  Training loss = 1.9260  Test loss = 2.8561  \n",
      "\n",
      "Epoch: 114  Training loss = 1.9260  Test loss = 2.8561  \n",
      "\n",
      "Epoch: 115  Training loss = 1.9259  Test loss = 2.8560  \n",
      "\n",
      "Epoch: 116  Training loss = 1.9259  Test loss = 2.8560  \n",
      "\n",
      "Epoch: 117  Training loss = 1.9259  Test loss = 2.8559  \n",
      "\n",
      "Epoch: 118  Training loss = 1.9259  Test loss = 2.8559  \n",
      "\n",
      "Epoch: 119  Training loss = 1.9258  Test loss = 2.8558  \n",
      "\n",
      "Epoch: 120  Training loss = 1.9258  Test loss = 2.8558  \n",
      "\n",
      "Epoch: 121  Training loss = 1.9258  Test loss = 2.8558  \n",
      "\n",
      "Epoch: 122  Training loss = 1.9257  Test loss = 2.8557  \n",
      "\n",
      "Epoch: 123  Training loss = 1.9257  Test loss = 2.8557  \n",
      "\n",
      "Epoch: 124  Training loss = 1.9257  Test loss = 2.8556  \n",
      "\n",
      "Epoch: 125  Training loss = 1.9257  Test loss = 2.8556  \n",
      "\n",
      "Epoch: 126  Training loss = 1.9256  Test loss = 2.8555  \n",
      "\n",
      "Epoch: 127  Training loss = 1.9256  Test loss = 2.8555  \n",
      "\n",
      "Epoch: 128  Training loss = 1.9256  Test loss = 2.8554  \n",
      "\n",
      "Epoch: 129  Training loss = 1.9255  Test loss = 2.8554  \n",
      "\n",
      "Epoch: 130  Training loss = 1.9255  Test loss = 2.8553  \n",
      "\n",
      "Epoch: 131  Training loss = 1.9255  Test loss = 2.8553  \n",
      "\n",
      "Epoch: 132  Training loss = 1.9255  Test loss = 2.8553  \n",
      "\n",
      "Epoch: 133  Training loss = 1.9254  Test loss = 2.8552  \n",
      "\n",
      "Epoch: 134  Training loss = 1.9254  Test loss = 2.8552  \n",
      "\n",
      "Epoch: 135  Training loss = 1.9254  Test loss = 2.8551  \n",
      "\n",
      "Epoch: 136  Training loss = 1.9254  Test loss = 2.8551  \n",
      "\n",
      "Epoch: 137  Training loss = 1.9253  Test loss = 2.8550  \n",
      "\n",
      "Epoch: 138  Training loss = 1.9253  Test loss = 2.8550  \n",
      "\n",
      "Epoch: 139  Training loss = 1.9253  Test loss = 2.8549  \n",
      "\n",
      "Epoch: 140  Training loss = 1.9252  Test loss = 2.8549  \n",
      "\n",
      "Epoch: 141  Training loss = 1.9252  Test loss = 2.8548  \n",
      "\n",
      "Epoch: 142  Training loss = 1.9252  Test loss = 2.8548  \n",
      "\n",
      "Epoch: 143  Training loss = 1.9252  Test loss = 2.8547  \n",
      "\n",
      "Epoch: 144  Training loss = 1.9251  Test loss = 2.8547  \n",
      "\n",
      "Epoch: 145  Training loss = 1.9251  Test loss = 2.8547  \n",
      "\n",
      "Epoch: 146  Training loss = 1.9251  Test loss = 2.8546  \n",
      "\n",
      "Epoch: 147  Training loss = 1.9250  Test loss = 2.8546  \n",
      "\n",
      "Epoch: 148  Training loss = 1.9250  Test loss = 2.8545  \n",
      "\n",
      "Epoch: 149  Training loss = 1.9250  Test loss = 2.8545  \n",
      "\n",
      "Epoch: 150  Training loss = 1.9250  Test loss = 2.8544  \n",
      "\n",
      "Epoch: 151  Training loss = 1.9249  Test loss = 2.8544  \n",
      "\n",
      "Epoch: 152  Training loss = 1.9249  Test loss = 2.8543  \n",
      "\n",
      "Epoch: 153  Training loss = 1.9249  Test loss = 2.8543  \n",
      "\n",
      "Epoch: 154  Training loss = 1.9249  Test loss = 2.8542  \n",
      "\n",
      "Epoch: 155  Training loss = 1.9248  Test loss = 2.8542  \n",
      "\n",
      "Epoch: 156  Training loss = 1.9248  Test loss = 2.8542  \n",
      "\n",
      "Epoch: 157  Training loss = 1.9248  Test loss = 2.8541  \n",
      "\n",
      "Epoch: 158  Training loss = 1.9247  Test loss = 2.8541  \n",
      "\n",
      "Epoch: 159  Training loss = 1.9247  Test loss = 2.8540  \n",
      "\n",
      "Epoch: 160  Training loss = 1.9247  Test loss = 2.8540  \n",
      "\n",
      "Epoch: 161  Training loss = 1.9247  Test loss = 2.8539  \n",
      "\n",
      "Epoch: 162  Training loss = 1.9246  Test loss = 2.8539  \n",
      "\n",
      "Epoch: 163  Training loss = 1.9246  Test loss = 2.8538  \n",
      "\n",
      "Epoch: 164  Training loss = 1.9246  Test loss = 2.8538  \n",
      "\n",
      "Epoch: 165  Training loss = 1.9246  Test loss = 2.8537  \n",
      "\n",
      "Epoch: 166  Training loss = 1.9245  Test loss = 2.8537  \n",
      "\n",
      "Epoch: 167  Training loss = 1.9245  Test loss = 2.8536  \n",
      "\n",
      "Epoch: 168  Training loss = 1.9245  Test loss = 2.8536  \n",
      "\n",
      "Epoch: 169  Training loss = 1.9244  Test loss = 2.8536  \n",
      "\n",
      "Epoch: 170  Training loss = 1.9244  Test loss = 2.8535  \n",
      "\n",
      "Epoch: 171  Training loss = 1.9244  Test loss = 2.8535  \n",
      "\n",
      "Epoch: 172  Training loss = 1.9244  Test loss = 2.8534  \n",
      "\n",
      "Epoch: 173  Training loss = 1.9243  Test loss = 2.8534  \n",
      "\n",
      "Epoch: 174  Training loss = 1.9243  Test loss = 2.8533  \n",
      "\n",
      "Epoch: 175  Training loss = 1.9243  Test loss = 2.8533  \n",
      "\n",
      "Epoch: 176  Training loss = 1.9242  Test loss = 2.8532  \n",
      "\n",
      "Epoch: 177  Training loss = 1.9242  Test loss = 2.8532  \n",
      "\n",
      "Epoch: 178  Training loss = 1.9242  Test loss = 2.8531  \n",
      "\n",
      "Epoch: 179  Training loss = 1.9242  Test loss = 2.8531  \n",
      "\n",
      "Epoch: 180  Training loss = 1.9241  Test loss = 2.8531  \n",
      "\n",
      "Epoch: 181  Training loss = 1.9241  Test loss = 2.8530  \n",
      "\n",
      "Epoch: 182  Training loss = 1.9241  Test loss = 2.8530  \n",
      "\n",
      "Epoch: 183  Training loss = 1.9241  Test loss = 2.8529  \n",
      "\n",
      "Epoch: 184  Training loss = 1.9240  Test loss = 2.8529  \n",
      "\n",
      "Epoch: 185  Training loss = 1.9240  Test loss = 2.8528  \n",
      "\n",
      "Epoch: 186  Training loss = 1.9240  Test loss = 2.8528  \n",
      "\n",
      "Epoch: 187  Training loss = 1.9239  Test loss = 2.8527  \n",
      "\n",
      "Epoch: 188  Training loss = 1.9239  Test loss = 2.8527  \n",
      "\n",
      "Epoch: 189  Training loss = 1.9239  Test loss = 2.8526  \n",
      "\n",
      "Epoch: 190  Training loss = 1.9239  Test loss = 2.8526  \n",
      "\n",
      "Epoch: 191  Training loss = 1.9238  Test loss = 2.8526  \n",
      "\n",
      "Epoch: 192  Training loss = 1.9238  Test loss = 2.8525  \n",
      "\n",
      "Epoch: 193  Training loss = 1.9238  Test loss = 2.8525  \n",
      "\n",
      "Epoch: 194  Training loss = 1.9238  Test loss = 2.8524  \n",
      "\n",
      "Epoch: 195  Training loss = 1.9237  Test loss = 2.8524  \n",
      "\n",
      "Epoch: 196  Training loss = 1.9237  Test loss = 2.8523  \n",
      "\n",
      "Epoch: 197  Training loss = 1.9237  Test loss = 2.8523  \n",
      "\n",
      "Epoch: 198  Training loss = 1.9236  Test loss = 2.8522  \n",
      "\n",
      "Epoch: 199  Training loss = 1.9236  Test loss = 2.8522  \n",
      "\n",
      "Epoch: 200  Training loss = 1.9236  Test loss = 2.8521  \n",
      "\n",
      "Epoch: 201  Training loss = 1.9236  Test loss = 2.8521  \n",
      "\n",
      "Epoch: 202  Training loss = 1.9235  Test loss = 2.8521  \n",
      "\n",
      "Epoch: 203  Training loss = 1.9235  Test loss = 2.8520  \n",
      "\n",
      "Epoch: 204  Training loss = 1.9235  Test loss = 2.8520  \n",
      "\n",
      "Epoch: 205  Training loss = 1.9234  Test loss = 2.8519  \n",
      "\n",
      "Epoch: 206  Training loss = 1.9234  Test loss = 2.8519  \n",
      "\n",
      "Epoch: 207  Training loss = 1.9234  Test loss = 2.8518  \n",
      "\n",
      "Epoch: 208  Training loss = 1.9234  Test loss = 2.8518  \n",
      "\n",
      "Epoch: 209  Training loss = 1.9233  Test loss = 2.8517  \n",
      "\n",
      "Epoch: 210  Training loss = 1.9233  Test loss = 2.8517  \n",
      "\n",
      "Epoch: 211  Training loss = 1.9233  Test loss = 2.8516  \n",
      "\n",
      "Epoch: 212  Training loss = 1.9233  Test loss = 2.8516  \n",
      "\n",
      "Epoch: 213  Training loss = 1.9232  Test loss = 2.8516  \n",
      "\n",
      "Epoch: 214  Training loss = 1.9232  Test loss = 2.8515  \n",
      "\n",
      "Epoch: 215  Training loss = 1.9232  Test loss = 2.8515  \n",
      "\n",
      "Epoch: 216  Training loss = 1.9231  Test loss = 2.8514  \n",
      "\n",
      "Epoch: 217  Training loss = 1.9231  Test loss = 2.8514  \n",
      "\n",
      "Epoch: 218  Training loss = 1.9231  Test loss = 2.8513  \n",
      "\n",
      "Epoch: 219  Training loss = 1.9231  Test loss = 2.8513  \n",
      "\n",
      "Epoch: 220  Training loss = 1.9230  Test loss = 2.8512  \n",
      "\n",
      "Epoch: 221  Training loss = 1.9230  Test loss = 2.8512  \n",
      "\n",
      "Epoch: 222  Training loss = 1.9230  Test loss = 2.8511  \n",
      "\n",
      "Epoch: 223  Training loss = 1.9230  Test loss = 2.8511  \n",
      "\n",
      "Epoch: 224  Training loss = 1.9229  Test loss = 2.8511  \n",
      "\n",
      "Epoch: 225  Training loss = 1.9229  Test loss = 2.8510  \n",
      "\n",
      "Epoch: 226  Training loss = 1.9229  Test loss = 2.8510  \n",
      "\n",
      "Epoch: 227  Training loss = 1.9228  Test loss = 2.8509  \n",
      "\n",
      "Epoch: 228  Training loss = 1.9228  Test loss = 2.8509  \n",
      "\n",
      "Epoch: 229  Training loss = 1.9228  Test loss = 2.8508  \n",
      "\n",
      "Epoch: 230  Training loss = 1.9228  Test loss = 2.8508  \n",
      "\n",
      "Epoch: 231  Training loss = 1.9227  Test loss = 2.8507  \n",
      "\n",
      "Epoch: 232  Training loss = 1.9227  Test loss = 2.8507  \n",
      "\n",
      "Epoch: 233  Training loss = 1.9227  Test loss = 2.8506  \n",
      "\n",
      "Epoch: 234  Training loss = 1.9227  Test loss = 2.8506  \n",
      "\n",
      "Epoch: 235  Training loss = 1.9226  Test loss = 2.8506  \n",
      "\n",
      "Epoch: 236  Training loss = 1.9226  Test loss = 2.8505  \n",
      "\n",
      "Epoch: 237  Training loss = 1.9226  Test loss = 2.8505  \n",
      "\n",
      "Epoch: 238  Training loss = 1.9225  Test loss = 2.8504  \n",
      "\n",
      "Epoch: 239  Training loss = 1.9225  Test loss = 2.8504  \n",
      "\n",
      "Epoch: 240  Training loss = 1.9225  Test loss = 2.8503  \n",
      "\n",
      "Epoch: 241  Training loss = 1.9225  Test loss = 2.8503  \n",
      "\n",
      "Epoch: 242  Training loss = 1.9224  Test loss = 2.8502  \n",
      "\n",
      "Epoch: 243  Training loss = 1.9224  Test loss = 2.8502  \n",
      "\n",
      "Epoch: 244  Training loss = 1.9224  Test loss = 2.8502  \n",
      "\n",
      "Epoch: 245  Training loss = 1.9224  Test loss = 2.8501  \n",
      "\n",
      "Epoch: 246  Training loss = 1.9223  Test loss = 2.8501  \n",
      "\n",
      "Epoch: 247  Training loss = 1.9223  Test loss = 2.8500  \n",
      "\n",
      "Epoch: 248  Training loss = 1.9223  Test loss = 2.8500  \n",
      "\n",
      "Epoch: 249  Training loss = 1.9222  Test loss = 2.8499  \n",
      "\n",
      "Epoch: 250  Training loss = 1.9222  Test loss = 2.8499  \n",
      "\n",
      "Epoch: 251  Training loss = 1.9222  Test loss = 2.8498  \n",
      "\n",
      "Epoch: 252  Training loss = 1.9222  Test loss = 2.8498  \n",
      "\n",
      "Epoch: 253  Training loss = 1.9221  Test loss = 2.8497  \n",
      "\n",
      "Epoch: 254  Training loss = 1.9221  Test loss = 2.8497  \n",
      "\n",
      "Epoch: 255  Training loss = 1.9221  Test loss = 2.8497  \n",
      "\n",
      "Epoch: 256  Training loss = 1.9221  Test loss = 2.8496  \n",
      "\n",
      "Epoch: 257  Training loss = 1.9220  Test loss = 2.8496  \n",
      "\n",
      "Epoch: 258  Training loss = 1.9220  Test loss = 2.8495  \n",
      "\n",
      "Epoch: 259  Training loss = 1.9220  Test loss = 2.8495  \n",
      "\n",
      "Epoch: 260  Training loss = 1.9219  Test loss = 2.8494  \n",
      "\n",
      "Epoch: 261  Training loss = 1.9219  Test loss = 2.8494  \n",
      "\n",
      "Epoch: 262  Training loss = 1.9219  Test loss = 2.8493  \n",
      "\n",
      "Epoch: 263  Training loss = 1.9219  Test loss = 2.8493  \n",
      "\n",
      "Epoch: 264  Training loss = 1.9218  Test loss = 2.8493  \n",
      "\n",
      "Epoch: 265  Training loss = 1.9218  Test loss = 2.8492  \n",
      "\n",
      "Epoch: 266  Training loss = 1.9218  Test loss = 2.8492  \n",
      "\n",
      "Epoch: 267  Training loss = 1.9217  Test loss = 2.8491  \n",
      "\n",
      "Epoch: 268  Training loss = 1.9217  Test loss = 2.8491  \n",
      "\n",
      "Epoch: 269  Training loss = 1.9217  Test loss = 2.8490  \n",
      "\n",
      "Epoch: 270  Training loss = 1.9217  Test loss = 2.8490  \n",
      "\n",
      "Epoch: 271  Training loss = 1.9216  Test loss = 2.8489  \n",
      "\n",
      "Epoch: 272  Training loss = 1.9216  Test loss = 2.8489  \n",
      "\n",
      "Epoch: 273  Training loss = 1.9216  Test loss = 2.8488  \n",
      "\n",
      "Epoch: 274  Training loss = 1.9216  Test loss = 2.8488  \n",
      "\n",
      "Epoch: 275  Training loss = 1.9215  Test loss = 2.8488  \n",
      "\n",
      "Epoch: 276  Training loss = 1.9215  Test loss = 2.8487  \n",
      "\n",
      "Epoch: 277  Training loss = 1.9215  Test loss = 2.8487  \n",
      "\n",
      "Epoch: 278  Training loss = 1.9214  Test loss = 2.8486  \n",
      "\n",
      "Epoch: 279  Training loss = 1.9214  Test loss = 2.8486  \n",
      "\n",
      "Epoch: 280  Training loss = 1.9214  Test loss = 2.8485  \n",
      "\n",
      "Epoch: 281  Training loss = 1.9214  Test loss = 2.8485  \n",
      "\n",
      "Epoch: 282  Training loss = 1.9213  Test loss = 2.8484  \n",
      "\n",
      "Epoch: 283  Training loss = 1.9213  Test loss = 2.8484  \n",
      "\n",
      "Epoch: 284  Training loss = 1.9213  Test loss = 2.8484  \n",
      "\n",
      "Epoch: 285  Training loss = 1.9213  Test loss = 2.8483  \n",
      "\n",
      "Epoch: 286  Training loss = 1.9212  Test loss = 2.8483  \n",
      "\n",
      "Epoch: 287  Training loss = 1.9212  Test loss = 2.8482  \n",
      "\n",
      "Epoch: 288  Training loss = 1.9212  Test loss = 2.8482  \n",
      "\n",
      "Epoch: 289  Training loss = 1.9211  Test loss = 2.8481  \n",
      "\n",
      "Epoch: 290  Training loss = 1.9211  Test loss = 2.8481  \n",
      "\n",
      "Epoch: 291  Training loss = 1.9211  Test loss = 2.8480  \n",
      "\n",
      "Epoch: 292  Training loss = 1.9211  Test loss = 2.8480  \n",
      "\n",
      "Epoch: 293  Training loss = 1.9210  Test loss = 2.8479  \n",
      "\n",
      "Epoch: 294  Training loss = 1.9210  Test loss = 2.8479  \n",
      "\n",
      "Epoch: 295  Training loss = 1.9210  Test loss = 2.8479  \n",
      "\n",
      "Epoch: 296  Training loss = 1.9210  Test loss = 2.8478  \n",
      "\n",
      "Epoch: 297  Training loss = 1.9209  Test loss = 2.8478  \n",
      "\n",
      "Epoch: 298  Training loss = 1.9209  Test loss = 2.8477  \n",
      "\n",
      "Epoch: 299  Training loss = 1.9209  Test loss = 2.8477  \n",
      "\n",
      "Epoch: 300  Training loss = 1.9208  Test loss = 2.8476  \n",
      "\n",
      "Epoch: 301  Training loss = 1.9208  Test loss = 2.8476  \n",
      "\n",
      "Epoch: 302  Training loss = 1.9208  Test loss = 2.8475  \n",
      "\n",
      "Epoch: 303  Training loss = 1.9208  Test loss = 2.8475  \n",
      "\n",
      "Epoch: 304  Training loss = 1.9207  Test loss = 2.8475  \n",
      "\n",
      "Epoch: 305  Training loss = 1.9207  Test loss = 2.8474  \n",
      "\n",
      "Epoch: 306  Training loss = 1.9207  Test loss = 2.8474  \n",
      "\n",
      "Epoch: 307  Training loss = 1.9207  Test loss = 2.8473  \n",
      "\n",
      "Epoch: 308  Training loss = 1.9206  Test loss = 2.8473  \n",
      "\n",
      "Epoch: 309  Training loss = 1.9206  Test loss = 2.8472  \n",
      "\n",
      "Epoch: 310  Training loss = 1.9206  Test loss = 2.8472  \n",
      "\n",
      "Epoch: 311  Training loss = 1.9205  Test loss = 2.8471  \n",
      "\n",
      "Epoch: 312  Training loss = 1.9205  Test loss = 2.8471  \n",
      "\n",
      "Epoch: 313  Training loss = 1.9205  Test loss = 2.8470  \n",
      "\n",
      "Epoch: 314  Training loss = 1.9205  Test loss = 2.8470  \n",
      "\n",
      "Epoch: 315  Training loss = 1.9204  Test loss = 2.8470  \n",
      "\n",
      "Epoch: 316  Training loss = 1.9204  Test loss = 2.8469  \n",
      "\n",
      "Epoch: 317  Training loss = 1.9204  Test loss = 2.8469  \n",
      "\n",
      "Epoch: 318  Training loss = 1.9204  Test loss = 2.8468  \n",
      "\n",
      "Epoch: 319  Training loss = 1.9203  Test loss = 2.8468  \n",
      "\n",
      "Epoch: 320  Training loss = 1.9203  Test loss = 2.8467  \n",
      "\n",
      "Epoch: 321  Training loss = 1.9203  Test loss = 2.8467  \n",
      "\n",
      "Epoch: 322  Training loss = 1.9203  Test loss = 2.8466  \n",
      "\n",
      "Epoch: 323  Training loss = 1.9202  Test loss = 2.8466  \n",
      "\n",
      "Epoch: 324  Training loss = 1.9202  Test loss = 2.8466  \n",
      "\n",
      "Epoch: 325  Training loss = 1.9202  Test loss = 2.8465  \n",
      "\n",
      "Epoch: 326  Training loss = 1.9201  Test loss = 2.8465  \n",
      "\n",
      "Epoch: 327  Training loss = 1.9201  Test loss = 2.8464  \n",
      "\n",
      "Epoch: 328  Training loss = 1.9201  Test loss = 2.8464  \n",
      "\n",
      "Epoch: 329  Training loss = 1.9201  Test loss = 2.8463  \n",
      "\n",
      "Epoch: 330  Training loss = 1.9200  Test loss = 2.8463  \n",
      "\n",
      "Epoch: 331  Training loss = 1.9200  Test loss = 2.8462  \n",
      "\n",
      "Epoch: 332  Training loss = 1.9200  Test loss = 2.8462  \n",
      "\n",
      "Epoch: 333  Training loss = 1.9200  Test loss = 2.8462  \n",
      "\n",
      "Epoch: 334  Training loss = 1.9199  Test loss = 2.8461  \n",
      "\n",
      "Epoch: 335  Training loss = 1.9199  Test loss = 2.8461  \n",
      "\n",
      "Epoch: 336  Training loss = 1.9199  Test loss = 2.8460  \n",
      "\n",
      "Epoch: 337  Training loss = 1.9198  Test loss = 2.8460  \n",
      "\n",
      "Epoch: 338  Training loss = 1.9198  Test loss = 2.8459  \n",
      "\n",
      "Epoch: 339  Training loss = 1.9198  Test loss = 2.8459  \n",
      "\n",
      "Epoch: 340  Training loss = 1.9198  Test loss = 2.8458  \n",
      "\n",
      "Epoch: 341  Training loss = 1.9197  Test loss = 2.8458  \n",
      "\n",
      "Epoch: 342  Training loss = 1.9197  Test loss = 2.8458  \n",
      "\n",
      "Epoch: 343  Training loss = 1.9197  Test loss = 2.8457  \n",
      "\n",
      "Epoch: 344  Training loss = 1.9197  Test loss = 2.8457  \n",
      "\n",
      "Epoch: 345  Training loss = 1.9196  Test loss = 2.8456  \n",
      "\n",
      "Epoch: 346  Training loss = 1.9196  Test loss = 2.8456  \n",
      "\n",
      "Epoch: 347  Training loss = 1.9196  Test loss = 2.8455  \n",
      "\n",
      "Epoch: 348  Training loss = 1.9195  Test loss = 2.8455  \n",
      "\n",
      "Epoch: 349  Training loss = 1.9195  Test loss = 2.8454  \n",
      "\n",
      "Epoch: 350  Training loss = 1.9195  Test loss = 2.8454  \n",
      "\n",
      "Epoch: 351  Training loss = 1.9195  Test loss = 2.8454  \n",
      "\n",
      "Epoch: 352  Training loss = 1.9194  Test loss = 2.8453  \n",
      "\n",
      "Epoch: 353  Training loss = 1.9194  Test loss = 2.8453  \n",
      "\n",
      "Epoch: 354  Training loss = 1.9194  Test loss = 2.8452  \n",
      "\n",
      "Epoch: 355  Training loss = 1.9194  Test loss = 2.8452  \n",
      "\n",
      "Epoch: 356  Training loss = 1.9193  Test loss = 2.8451  \n",
      "\n",
      "Epoch: 357  Training loss = 1.9193  Test loss = 2.8451  \n",
      "\n",
      "Epoch: 358  Training loss = 1.9193  Test loss = 2.8450  \n",
      "\n",
      "Epoch: 359  Training loss = 1.9192  Test loss = 2.8450  \n",
      "\n",
      "Epoch: 360  Training loss = 1.9192  Test loss = 2.8450  \n",
      "\n",
      "Epoch: 361  Training loss = 1.9192  Test loss = 2.8449  \n",
      "\n",
      "Epoch: 362  Training loss = 1.9192  Test loss = 2.8449  \n",
      "\n",
      "Epoch: 363  Training loss = 1.9191  Test loss = 2.8448  \n",
      "\n",
      "Epoch: 364  Training loss = 1.9191  Test loss = 2.8448  \n",
      "\n",
      "Epoch: 365  Training loss = 1.9191  Test loss = 2.8447  \n",
      "\n",
      "Epoch: 366  Training loss = 1.9191  Test loss = 2.8447  \n",
      "\n",
      "Epoch: 367  Training loss = 1.9190  Test loss = 2.8446  \n",
      "\n",
      "Epoch: 368  Training loss = 1.9190  Test loss = 2.8446  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb71ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngkRZqOsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcce1d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.84459958264 \n",
      "Fixed scheme MAE:  1.99468510288\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.9190  Test loss = 1.8137  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.9247  Test loss = 1.2257  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.9151  Test loss = 1.4839  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.9206  Test loss = 1.0575  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.8068  Test loss = 0.3385  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.7552  Test loss = 0.6854  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.7219  Test loss = 0.2556  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.7201  Test loss = 0.0533  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.6508  Test loss = 0.6289  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.6524  Test loss = 0.3574  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.6239  Test loss = 0.4564  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.6191  Test loss = 1.3635  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.5849  Test loss = 0.3897  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.5852  Test loss = 1.1071  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.5850  Test loss = 2.8056  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.6210  Test loss = 3.1687  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.6327  Test loss = 0.6208  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.6334  Test loss = 0.2572  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.6004  Test loss = 0.9939  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.3807  Test loss = 0.6258  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.3558  Test loss = 0.2160  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.3520  Test loss = 4.6453  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.4521  Test loss = 1.0610  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.4481  Test loss = 2.0877  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.4489  Test loss = 0.2546  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.4488  Test loss = 0.0636  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.4483  Test loss = 1.0506  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.4507  Test loss = 1.0768  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.4281  Test loss = 1.1426  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.4184  Test loss = 0.6984  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.4043  Test loss = 3.0680  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.4105  Test loss = 0.3894  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.3966  Test loss = 1.2010  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.4017  Test loss = 0.3607  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.3128  Test loss = 0.7461  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.3146  Test loss = 4.8891  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.3468  Test loss = 0.2874  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2805  Test loss = 1.1351  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2859  Test loss = 1.0795  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2920  Test loss = 1.9651  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.2888  Test loss = 1.2219  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.2956  Test loss = 2.2948  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.3261  Test loss = 3.4407  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.3931  Test loss = 11.8450  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0123  Test loss = 6.1029  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1497  Test loss = 0.5225  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1506  Test loss = 0.7626  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1521  Test loss = 0.5446  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.1249  Test loss = 1.9777  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.1361  Test loss = 3.1409  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.1698  Test loss = 2.2763  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.1879  Test loss = 0.5314  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.1597  Test loss = 0.6111  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.1604  Test loss = 0.8672  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.1624  Test loss = 0.8702  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.1644  Test loss = 1.0887  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.1422  Test loss = 0.7196  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.1428  Test loss = 1.9746  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.1555  Test loss = 0.8108  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.1568  Test loss = 0.1965  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.1399  Test loss = 0.5638  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.1404  Test loss = 3.0330  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.1729  Test loss = 1.1895  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.1669  Test loss = 1.0900  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.1548  Test loss = 0.0317  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.1548  Test loss = 0.4462  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.1479  Test loss = 1.2784  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.1510  Test loss = 3.2214  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.1754  Test loss = 5.1816  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.2683  Test loss = 0.2358  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.2684  Test loss = 0.7326  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.2666  Test loss = 1.7867  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.2591  Test loss = 1.8270  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.2697  Test loss = 0.2620  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.2635  Test loss = 0.5941  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.2629  Test loss = 0.6435  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.2491  Test loss = 1.0154  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXlcVPX6x9/fgQEVBUTcN1BRC9wSl1xuZWlmZl27tlrp\n1VxulnWzRbt1b/dWv26b2W6lZjfL0rqZVlpa2nVLCZdQEzHFHXEDVBZhnt8fhzMOMAMDzDADfN+v\n17xgzvI9z5w58znPeb7P9/kqEUGj0Wg0NQeLrw3QaDQajWfRwq7RaDQ1DC3sGo1GU8PQwq7RaDQ1\nDC3sGo1GU8PQwq7RaDQ1DC3sGo1GU8PQwq7RaDQ1DC3sGo1GU8MI9MVBIyMjJSoqyheH1mg0mmrL\nL7/8ckJEGpe1nU+EPSoqioSEBF8cWqPRaKotSqlUd7bToRiNRqOpYWhh12g0mhqGFnaNRqOpYWhh\n12g0mhqGFnaNRqOpYWhh12g0mhqGFnaNRqOpYWhh12g8REZGBvPnz/e1GRqNFnaNxlPMmjWLMWPG\ncOjQIV+boqnleETYlVLhSqnFSqnflFK7lFKXe6JdTe1i+/btTJo0iYKCAl+bUiGWLVsGQHZ2to8t\n0dR2POWxzwKWi0hnoBuwy0PtamoRS5YsYfbs2aSmujVq2q84evQomzdvBuDChQs+tkZT26m0sCul\nwoA/AHMARCRPRM5Utl1N7SMtLQ2A/fv3+9aQCvD111/b/9fCrvE1nvDYo4F0YJ5SaotS6n2lVIgH\n2tXUMo4fPw7Avn37fGxJ+THDMKCFXeN7PCHsgcBlwNsi0gM4BzxefCOl1ASlVIJSKiE9Pd0Dh9XU\nNKqrx56Tk8P3339P+/btAS3sGt/jCWE/BBwSkZ8L3y/GEPoiiMi7IhIvIvGNG5dZTlhTCzGFvbp5\n7D/++CPnz59n5MiRgBZ2je+ptLCLyDHgoFKqU+Giq4GdlW1XU/uorh770qVLCQkJYciQIQDk5eX5\n2CJNbcdTE23cDyxQSgUBvwNjPdSuppaQl5fHmTNGn3t18thFhGXLljF48GDq168PaI9d43s8ku4o\nIlsLwyxdReQmETntiXY1tQez47RVq1YcOXKEnJwcH1vkHtu3b+fgwYPccMMNWK1WQAu7xvfokaca\nv8AMw/Tp0weAAwcO+NIctzGzYYYNG6aFXeM3aGHX+AWmx24Ke3UJxyxdupTevXvTrFkzgoKCAC3s\nGt+jhV3jFxT32KtDB2paWhqbNm1i+PDhAHaPXXeeanyNFnaNX2AKe/fu3bFardXCY1+6dCkiUkLY\ntceu8TVa2DV+wfHjx6lXrx6hoaG0bdu2WnjsH3/8MR06dKB79+6AFnaN/6CFXeMXpKWl0bRpUwCi\noqL83mM/dOgQq1evZvTo0SilAC3sGv9BC7vGL3AU9ujoaL8X9k8++QQR4c4777Qv052nGn9BC7vG\nLzh+/DhNmjQBDGFPT0/n3LlzPrVp3759PPLII+Tm5pZYt2DBAvr06UOHDh3sy3TnqcZf0MKu8QuK\nh2LA95kxixcv5qWXXuKVV14psjwpKYlt27YV8dZBh2I0/oMWdo3PKSgoID09vUgoBnwv7GY46Jln\nniky3d2CBQsICAjg1ltvLbJ9QEAAoIVd43u0sGt8zsmTJ7HZbPZQjOmx+zrOvn//flq1aoXNZmPa\ntGkA2Gw2Pv74Y4YMGWK310QphdVq1cKu8Tla2DU+xxx1anrsTZs2pU6dOl4X9mPHjvHmm28iIk7X\n79u3j969e/P444/z6aefsnr1atauXcuBAwdKhGFMqpOwnz59mjlz5mCz2XxtisbDaGHX+BxzcJIp\n7EopoqKivB6K+dvf/saUKVNISUkpsU5E2L9/P1FRUTz66KNERUVx//33M3/+fEJCQrjpppucthkU\nFFQthD0rK4trr72W8ePH2+dq1dQctLBrfI4p7I6hDW+nPKanp/PRRx8BsGfPHqc25eTkEB0dTd26\ndXnllVdISkpi7ty53HTTTYSEOJ/90Wq1+n1WTHZ2NjfccINd0H/77TcfW6TxNFrYNT6neCgG8LrH\nPnv2bHsaY3Jycon15rHNeP9NN93E4MGDARg9erTLdv09FJOXl8eoUaP46aefmD9/PoGBgezevdvX\nZmk8jBZ2jdf46aefGDFiBPn5+aVul5aWRmBgIA0bNrQvi46O5vTp02RkZHjcrry8PN58802GDBlC\nWFiYU4/dfFowM3SUUrz//vv885//tAu8M/xZ2AsKCrj77rv5+uuvefvtt7n77rtp3769FvYaiKdm\nUNIURwT27IEtW+D4ceOVng4tWsCMGRBY80/94sWLWbp0KQcOHKBdu3Yut0tLS6NJkyb2oflQNJe9\nW7duHrXrs88+49ixY8ybN4+nnnrKqbCbHnvbtm3ty9q0acOTTz5Zatv+LOyffvopn376Kc8//zwT\nJ04EoFOnTjoUUwPxmLoopQKABOCwiAz3VLvVirw8WLIEvvvOeDlOFmGxQEQEnDgB+/fD++8by6qQ\nU6dOsW3bNq666qoqOV5SUhIAv//+e6nCfvz48SJhGLjoKe/bt8+jwi4izJw5k86dOzNkyBD+85//\nsG7duhLb7d+/n8jISPt0d+7iz52nS5YsoVmzZjzyyCP2ZZ06dWL58uUUFBTY8/A11R9PKstUYJcH\n26t+PPAA3HILLFoE8fHw9tuwfbvhqeflGX///neYNw+mTTO8+irk5ZdfZsiQIU6HyAOQm2vceDyE\nKexldYI6jjo1cRR2T7Ju3ToSExOZOnUqFouFjh07cuDAgRJT8e3bt89uQ3nw187TCxcusHz5cq6/\n/nosDg5F586dycvL8/lgMI1n8YiwK6VaAdcD73uiPX/lzJkzdrEqwYEDMGcO3HuvIY6ffw6TJkGX\nLhAZCaY39Pe/w/33w8yZ8NxzVWc8sG3bNvLz8+2TRtvtnj0bbroJGjWCtm3BAzHX48ePk56eDhge\ne2k4E/aIiAjq16/vccGZNWsWDRs25K677gIgJiYGESlho5nqWF78NRSzdu1aMjMz7bXjTTp16gSg\n4+w1DE957K8CjwI1eqTD9OnT6dWrF6dPO5mr+9//BqXgySdLj58rBa++CnfdBX/7m/H69FP47DNY\nvBh++cVr9uclJvIhUP/GG6FzZwgNNYR80iTYutWwKTgYxo2DgoJKHcvxBliasItIkQJgJkopj6c8\npqam8sUXXzBhwgR7umJMTAxQNDPGZrORmppaYY/dH4V92bJlBAUFcc011xRZroW9ZlLpGLtSajhw\nXER+UUpdWcp2E4AJYHRCVTdEhCVLlpCTk8OiRYuYMGHCxZVHjhje+pgx0Lq1yzZ2797Nhg0bGDNm\njLF9ZiY8+2zRjYKCjI7WsDCP2p+VlcU9R49yM3Dh/HnjSeLaayE62vjbubNx07n8crjnHnjjDZg6\ntcLHM4W9W7dupQp7ZmYmubm5JTx28HzK49dff43NZmP8+PH2ZaawO3agHj16lLy8vBrlsS9btoyr\nrrqqRJ9BZGQkERERugO1huEJj70/MEIptR9YCAxSSn1UfCMReVdE4kUkvnHjxh44bNWyZcsWjh49\nisVi4T//+U/RlS+/DPn58Pjjpbbx1FNPMXbsWA4fPgxWK/z3v5CcDDt3QlISLFhgxOJXrvS4/bu2\nbmU4sABY/+KLRj/ArFnw4INwySWGqIPhtQ8bBtOnw969FT5eUlISkZGR9O3bt1Svu/ioU0dMj93V\nkH9Hzpw5w6OPPsqQIUNcxrjNEFRrh5tveHg4jRs3LiLsxVMdy4NfdZ7u3g3jx3N05kwOJieXCMOQ\nmwtpaXTq1El77DWMSgu7iEwXkVYiEgXcBvwgIq5HcFRTli1bhlKKqVOnsnbt2otilZ4O77wDd9zB\n+WbNnA5PB8jNzeXbb78F4JtvvjEWKgUxMYawxsbCqFGGp164nSc5s3gxYcDn4DyUZKKUEXO3WmH8\neKhgHZGkpCRiY2Np3749J0+edJmP7mzUqUl0dDRnz561D2ByxoULF3jttddo3749L774It9//z3H\njh1zum1mZiZBQUEEBwcXWR4TE1MkFFN8cFJ58JvO05Mn4frrYc4cmv/1rxwHxqxaBfPnw6OPwoAB\nxrXWrBmP5OSwW3vsNQo9QMlNli1bRt++fXnwwQcB7MPRmTkTsrNhxgzGjBlDt27dinZOFrJmzRqy\nsrKwWCx8/fXXzg9itcLgwYawezhjJnTVKjKAVeDUviK0amU8haxebYi8u9hscPgwIkJSUhJxcXH2\nNEdXXruzUacmXbp0AeDXX391um9KSgqxsbFMnTqVHj162HPMMzMznW5fb/9+XrNYYNu2Iss7duxo\neOwFBXDypN1Wxxx2d/GLUExeHtx8Mxw6BGvX8lCPHnzTsCH116wxwoWvvmp8V1OmwG238cctW3gu\nLY2Mws5uTfXHo8IuIqt9msN+7pxxMXuYY8eOsXnzZoYPH06bNm248sor+fDDD5GTJ41Y9KhRrElL\nY9GiRZw/f57PPvusRBtLliyhXr163H333axcudJ1yuGwYUbMfvt2z32A/HwuSU7mf2Fh5OGGsIPR\ngXrNNYZ3V0ZWi50HH4Q2bTgxdy5ZWVnExcXZwxmu4uylhWK6du0KGNk8zpg7dy779u1j2bJlfP/9\n9wwYMABwIexnzjDh66+ZmJMD3bsb3uzatSDCH+rW5eEjR7C1agUtWpC9bRvNmjWjbt267n1uB3wu\n7CLwl7/AmjUwZw4ZcXG88euvJE6YAMeOGTe1zExYvx5eegk+/pjfbr2VsQDDh4MXRvpqqp6a5bFP\nm2aENDyYiw0XQydmjPKu0aOJTkkha9AgyMqi4PHHmTp1Km3atKFTp07Mnz+/yP4iwldffcW1117L\nn/70J86dO8eaNWucH2zoUOOvJ8Mxa9YQduEC+y+7jODg4NJDMSZKGR28FgvcfXfZWTKJifDmmxAc\nTMRf/sIAcMtjT0tLQylFZGRkiXWNGzemefPmbHdxk0tMTCQ2Npbrr78epRShoaEAJcM+IjB2LJHn\nzvFAu3bwzDOwaRMMHAhNmzL27beZAmR16gSBgVy5dm2F4utQOWHPy8tj48aNbvUpuOSVV4zv7Ykn\n4M47WbFiBfn5+ca1GxQEXbtCnToXt1cK+fvfuQdo8MsvRohGi3u1p+YIe0EBfPGF4Y289JJHm162\nbBmtW7emyyWXwMcfc8+sWXwH2FJS4J13mJuQwLZt23jhhRcYN24c69evLxKz3bJlC4cOHWLEiBFc\nddVV1KlTx3U4pnlz6NEDzDi8B8hZsIBzQMHgwYSHh7vnsQO0aWOI9bp18OKLpKSk8OSTT5b0iG02\nuO8+I19/+3bOhIWxFOiiFOHh4TRs2NC5x75mDQOWLKF1RASBzlJEbTau7tSJbVu3llglIvzyyy9c\ndtll9mWmsJew76WX4MsveSc6mu2tWxuil5pqdB5fcQUH//53mgLf3XcfTJ7M1Wlp9G3UyL1zVIzK\ndJ7+5z//4fLLL+fll1+u0P788AM88ogRhvnnPwHj2o2IiKBv374ud2vfvj0LAgL4cNQooxPfw78f\njQ8QkSp/9ezZUzzO+vUiINK8uUi9eiJpaR5pNjs7W0JCQmTy5MkiY8cax7jkEnmrVy9p1rChHD9+\nXBo3biwDBgwQm80mR44cEYvFIk888YS9jaeeekosFoukp6eLiMiwYcOkffv2YrPZnB90xgyRgACR\n06cr/wEKCiQnIkIWgSxfvlw6deokt9xyi/v722wio0aJWK3yyl13CSCXXHKJJCcnX9xmzhzjvMyf\nLyIiD40cKUctFuO72LdPevbsKUOHDi3a5ptvGp8RZHO9eiKZmUWPe+aMyODBIiD7QfInTRJZsUIk\nJ0dERA4cOCCAvPHGG/ZdDh06JIDMnj37Yjtr1hjH+dOfpHu3bnLDDTeU+Ihnz54VQJ599lm5cPCg\nnAdJ6NrV/XPkwLhx46Rly5bOV+bkiPzyi8t97yo8v4B88skn5Tvw+fMi7duLxMSInD0rIiL5+fnS\nqFEjufPOO8vcPSYmRv70pz+J3Hqr8fs5dqx8x/cEeXkiX34pUlBQ9ceuJgAJ4obG1hxhf+wxkcBA\nkY0bRSwWkb/+tfxtHDoksnRpkUXLly8XQDY/9ZRxuh55RKSgQL7++msB5LLLLhOllPzi8IO97rrr\npHXr1lJQeIF269ZNBg4caF//5ptvCiC//fabczvWrjWOtWhR+T+Di7ZuAzl48KD07dtXhgwZUr42\nTpwQad5c9tevL1FNm0qjRo0kPDxcli9fLnLypEhkpMiAAYZgi8hll10mE/r1EwkPF2nbVj7o2lUG\ntGtntJWbKzJhgvH5hg+XZ9q3l3ylRPr2NcRcRGT/fpHYWJHAQEm64Qb5EqSgTh1jH6VEAgKkIDBQ\nskFymjYVWbJEREQyMzMFkBdffNFo5/ffRZo1E+nYUSQjQ9q1a+dS5Fq0aCH33HOP7N+/X14BKbBY\nRPbuLffpnjRpkjRu3LjkivPnRa65xvgMq1c73Tc6OlqGDRsmf/jDHyQoKEh+/PFH9w/8xBNG26tW\n2RetX7/e7ZvE8OHDJS4uTiQ52bgRTpni/rE9xVtvGZ/ho4+q/thVhMvfvJvUPmG/5BKRq682/r/7\nbpE6dUSOHClfGyNHGqfk1Vfti6ZMmSIt6tQRW7NmIl26GMIkIhcuXJAmTZoIIOPGjSvSzMKFCwWQ\nlStXyv79+4uKjYh92csvv+zcjgsXDFEcO7ZUc48dOyYrVqy4uCA7W2TPnqIbPfSQ5Fks0io0VGw2\nmwwdOlR69erlxskoxvLlIiAr27WTA//7n3Tt0kUsFots6dfPEIJt20TE8BLr1KkjDz/8sMiGDSLx\n8SIgBSC2q68Wufxy4xxPny6Sny8dOnSQlwYMELFajW1XrBBp2lQkLExk5UpJSkoSQD6eM8e46T75\npMiMGbKmXz95HqSga1ejvXHjxJaRIUop+ddjjxlCV6eOSP36Itu3i4hIZGSk8eTlhCuvvFL69esn\nq1evluYg+VariOP3mpdntBkdLfLppy5P0/333y/h4eFFF2Zni1x7rXFTql/f+L8YR44csV8Tp06d\nkksvvVTCwsLk119/Lfu7SUoynJq77y6y+PXXXxdADh8+XGYTDz/8sAQHB0t+fr7IxInG91GBG1uF\nsdmM3xeIXHaZ3UmoKZw7d04eeughUUrJkkJHpCLULmFPTjY+yqxZxvuUFENs7r/f/Taysi4KQWFY\nwWazSVRUlPzQsqXxwyn2GP3oo49KeHi4HCv22JqdnS1hYWEyevRoee211wQoGroQkdjYWBk0aJBr\ne2691fA2S7nAH3300Ys/3L17Rbp1s3vCkpBg7Nu2rayLiJD+/fuLiMhtt90mMTEx7p+XQs6dOyev\nGt2QIiC28HBJioyUApAjt95q3y45OVkAmTdvnn3ZJ//4hzwNcqFNG5GQEJGPP7ava9CggUydOtUQ\n7aAgo/2oKJEdO0TEuIEGBQXJtGnTithz/fXXS2xsrHGjnT7dEM127eSpOnXkTL16Rjt33CGSmmrf\nJygoSB577DGnn+/ee++Vxo0by7x58wSQ03fdZXzn+/YZL/OG1KbNxbZPnSrRzl//+lcJCQm5uCAn\nR2TYMGOfOXNEnnvO+D8xsch+ixYtEkA2btwoIiKpqanSokULadWqlZwtDK04paBApH9/kUaNRI4f\nL7LqgQcekPr167sO+Tnw7rvvCiC///67yOHDxm9h9Ogy9/MYZii1Xz/j75o1VXdsL7N69Wpp3769\nADJ58mTJLB52LAe1S9hfesn4KPv2XVw2frwhFAcPutwtNTVV3nzzTVmwYIFsffxxEZAj8+fLhSuu\nEFtAgKS+/rqMMMXsqadK7J+XlycnT5502vbEiROlbt260qdPH7nkkktKrH/00UclMDBQMjIynBv3\nwQdOBcCRYcOGCSDfTJliePgNG4o89JDxF0QGDhQBua9ePZk4caKIlBIqECPWvL3Quy1OYmKiALLq\nuedE3n5bZNIkye/VS7YEBsofHW5QX3zxhRG62rzZvuy7774TQNasXm08jRRy/vx5e2xbRERWrhS5\n554S8d0ePXqUCB81a9ZM7rrrrosL/vc/44YAkhIZaQiFAzk5OUWPVYwXXnhBAJk6daoopSQnJcW4\nfgYONJ4eQkNFFi407P/nPw3HoWVL4wnDgccee0yCgoLMEypyww3Gd/Huu8ay06dFGjQQKdbP8eCD\nD0qdOnUkt/CJUERk8eLFAsiGDRuc2iwiIrNnG+073EhNrrvuOunevbvrfR346aefBJBvv/3W/CDG\nzbLwSczr3H23cV6OHzduUjfeWDXH9SL5+fkyZcoUAaRdu3byww8/VLrN2iXsAweKFO/s2r/feJx0\n8egtYnR0mZ1Vn4McBrGA1Af5GSQb5DhI7qWX2kMw7rJhwwZ72868xDVr1gggixcvdt7AsWPG1+NC\niEREotu2lb8Xhjmke/eLj84ZGSL/+pdIeLjY6tSRCJDXX39dRESmT58ugYGBTr24F198UaxWq5x2\n0mm7YMECASQpKanIclMQ165dKyIi//znP0UpVcTL3LNnTwkvXuRiSOr99993+RlFRMaMGSNNmza1\nvzfDFq86hMxERCQzU8ZER8vIm24q0cbx48cFh/NQnC+//FIAufTSS6VVq1bGwr/8xfgO+vY14vWO\nbN4s0qmTsb57d5HXXxc5eVKefPJJiQOx3XefcTMA40boyGOPGf1ADk9x8fHxcsUVVxTZzB6GcnjC\nKUJqqnFDv+IKp092HTp0cLujPC0treg5PXXKaPu660SOHrV3WnuFkyeNJwTzt/rkk8ZNpdhTbnVj\n2bJlAsikSZNKf+oqB7VH2NPTjR/Jk0+WXHfvvcYFc/680127d+8uV111lexOSJD8oCDZe/31Mnfu\nXHnppZfkXw8+KIcbNpR8i0Vky5Zym2Wz2aRjx44CyPpi3qOIEWIIDw+XsaXF0Xv2NDolnXDu3Dkp\nrOguH1oscrYw46YIZ87IT4WhBbMj7t///rcATi+0+++/3943UJwnnnhCAgICiniUIoaX36RJE3tY\n6ZZbbpH27dsX2SY3N1csFos8Wew7+vnnnwWQpcU6rIszc+ZMAewhr6VLlwogP/30U4lt+/XrJ1eb\nfS0OpKSkCCDzCzN3irNjxw77jXiAec4zMgwvPS/PuWHnzom88YZIjx7GTyk4WI42ayYCYgsKErnz\nzhJPDiJiCGVwsHF9inEOAwICZMaMGUU2c8zWKcGPP4o0aWKEDnftKrE6Ly9PAgICimRnlYbNZpPw\n8HCZNGnSxYX/939iht4EjN9Sq1ZGH8GjjxqdnLt3u9V+qcycabS/davx/uhR42npvvsq37YPmTZt\nmgQHB0t2drbH2nRX2Kt/Hvs33xh51CNGlFx3002Qk2PkYRcjJyeHpKQk+vbtS8fkZALy8mj32GOM\nHTuWhx9+mL/NnEmL338nYNs2Y6RiOVFK8cgjj9CvXz969+5dYn1gYCBDhw7lm2++Me6wzhg2zBgh\n6GTA1e7du7kF2NekCXfbbKx08hkJCyOhcDBSbGwsYBS9AuejT83h/QkJCSXW7dq1iw4dOhAUFFRk\neUhICI8//jg//PADq1evtpcScCQoKIjWrVuXGKRUWp0YR4qPQE1MTEQpRXcn30tYWJjTkafmoCUz\n17047dq1s0/NZx+cFBoKt95qlHpwRr16Rv5+YqLxuvdeCqxWpgE5KSnw0UdGtcziNGsGY8cadVuO\nHGHTpk0UFBTQv3//IpuFhITQpEmToudNxCj3cM010LChMdCqc+cSh9i3bx8FBQX26pVloZQqWQzs\n0UeNGcHeesuoQjplClx1FaSlGaU0Ro+GTp2MCWaKTVSCzWaMgejb15gxzBUiRq2lvn3BnCmrWTO4\n805jQppTp9yy3x9ZvXo1ffr0oY7jgLAqovoL+5IlxjyiPXuWXHfFFcaP8rvvSqxKSkoiPz/fGODy\n2WfGwKBiPyzCw6GYSJWH8ePHs27dOpdTjg0cOJC0tDSj2qMzbrrJ+IEsXVpi1b516+gFBN9yC2Fh\nYXz11VdOm0hKSqJJkyaYFTVLE3ZzYozNmzeXWLdr1y4uueQSp8eYNGkSzZs3Z8aMGSQnJ5cQdjCE\ns/ggpdLqxDhiTo1njkD95Zdf6NixIw0aNCixbWhoqNOCY6bYuxL2OnXq2GvDVKT4Fz16wOuvs3Dq\nVF4GLpRVdnnaNKMi6MyZrP/pJ6KAgbm5xiC7c+fsm0VHR18sXXzsmHGjmTbNuDY2bTIKyDnBrFbp\nrrADJYXdYjEcpsmTjXl6X3wRPvzQmMf33Dmj7MUDD8DrrxvCbBYS27sXBg0ybgQ//2xMLuOKNWuM\nKpSTJhVd/tBDcP48vPuu2/b7ExkZGSQmJnLllVf65PjVS9jXrTMmozA9spwcWLHCuPgcJkK2ExIC\n/frB99+XWPVL4YQW8Z06GcP3R42q8jlIy6qFQo8exkQY//1viVWWwpIDjceO5brrrmPp0qUUOBn2\nX9yDbtiwIeC8wqMptMWF/cKFC+zZs8elsNetW5cZM2awYcMG8vPznQp7dHR0CWFfuXIloaGhNG/e\n3Gm7Jo0aNaJly5ZFPPaezm7kGMLtzGM3l4WVIrimCFa0nAAYJQWAskeftm9viPTMmTz29NPsAxqM\nHGmMGm3ZEv76V0hJIToqivBdu+COO4yRwJ9/bgjsokXGE4ULzJHPHTt2dNv2zp07c+TIEbKyssre\n2Go1avrPmgXLlsHhw4Zzdd99RtmCLVuwvfceR+64A/7zH9ixw3k7s2cbDtQttxRd3qWLURBv1iyj\nHPadd2IbOJATnTpR4GoWs9IQMcpiDx1a+hOEh1i3bh02m00Lu1u8954hwJGRxpf+0EOG53Djja73\nGTzYmB2oWOnXxMREGjZsSNvt24261KNGedn4kpjVC13VQkEp+OMfjSeOYj+2lomJHA4MxNqjByNG\njCA9PZ1NmzYV2cZms7Fjx44iQluWxx4QEMCBAweKlMpNSUkhPz+fSy+91OVnGT9+PK1atQJw6bEf\nO3aM8+fHzUoNAAAgAElEQVTPA3DgwAEWLVrEvffeWyK844xu3bqxbds2jh8/zqFDh4qUEnAkLCys\nQh47XBT2CnnshZifxa2yAs88g+2OO3jNauXDK66AH380ygJcd53hBcfE8Oby5Sw6fBj55htDNH/7\nzfDYnTkyDuzZs4fw8HAalaM0gnk9rl+/3u19AKOg2rZthtf+1ltw5ZWwYwcfBgbS5eOPya9bF556\nquR+x44ZN6p77gFnBdcef9zY5pVXYMMG44kyOZmzQ4cWeaopk8REowbO6NGGIzh9evk+XwVYvXo1\nQUFBpZZy8CbVS9jffx9++smoInj4sBGbCwsz4n6uGDLE+LtqVZHFZp0RtXixEcrp18+LhjsnLCyM\nqKgo18IOMHKkceNZvvzisuxs4tLS2Nq6NSjF0KFDCQgIYGmxkE1qairnzp1zS9htNhsnTpygX+F5\ncIyz79plzFHuymMHI5Txwgsv0L17d6deolkMzAwrvPHGG4gI999/v+vP7kDXrl3ZtWsXGzduBHAp\n7KGhoWRnZ5cQVneE3fx87du3d8smZ5geu1s12du1I2naNB7Oy0ONG2cI4lVXwSefGHPRPv0051q2\nZAJwaONGI67tZmhlz549xMTE2PsN3GHw4MFEREQwb948t/ex06KF4YBs32548K1aMXfuXE4B38bG\nGiEmxyfBs2eNcJJSRqjHGYVF9sjJgd9/5+H4eG4DGhw+bNzkyuLgQZg40ZhYfs8eozja9OmwcCE4\n6UfyJGZ8vSIVQj2COz2snn55LCsmJaXsXvn8fCOv2yH7JDc3V4KCguRvDzxgZCdMneoZeyrAiBEj\nnOa528nPF2ncWOS22+yL8r74QgRkrsOyq666yhiw48BXX31VIisnPT1dAHnttdeKbHvixAkB5Jln\nnhGllPzjH/+wr/vXv/7lMpPGXTZu3GjPgMnKypKwsDAZNWqU2/t/8sknAsgtt9xiDCByUUdn1qxZ\nAsiJEyeKLP+///s/AeS8iwwpESPTaPny5W7b5Iz58+cLICkpKW5t/9Zbbwkge12M8jTHAKx2UYbA\nFW3btpU77rijXPuIGJlRQUFBJc5feTFTXIOCgqR9kyZii4wUMcciZGcbo8QDAozaMG5QUFAgkZGR\nYrVa5WkzS8dJ7r6IGLn3o0cbA8wCAkQefPBi3aWMDKMExqBB3hndevq0ZCYnSxOl5Llp04zMKQ9C\nrciKad8eyoohBgTA1VcbcfbC7JMdO3aQl5fH9Tabz8IwJl27dmX37t3kFM8qMAkIMDybr782bAXO\nfvIJWUCw+TQCjBgxgh07drC3cDq7tLQ0Xn31VZRSRUIoZoy5uMdudpy2a9eOzp07F4mz79q1i7Zt\n29ongK4Ipsf++++/88EHH5CRkcFDDz3k9v5mB+qXX35J+/bt7U8exXFV4TEzM5PAwMBSMxTq1avH\ntdde67ZNznA7xl7IunXraNasmcu4vrm8PJN65+TkcODAgXLF103GjRtHXl4eH3/8cbn3deTDDz/E\nYrHwzDPPsPf4cfbffrvh0a9aBbffbvydO7f0MKoDiYmJnDhxgr/97W88DaS2a2fUnTfj7ampRqj2\n2muN7Jr//tfovN2713jSMa+X0FBjwvkffqDg22+ZN29epWa8OuWYtTN/PkRG0qBjR9JEmP7SS1C/\nvhFqOniwwseoCNVb2N1l8GBjAo7CHv/ExEQsQI+VK43JnJ2lpFURXbt2xWazsXPnTtcb/fGPxiPp\nqlUgQp1Vq1gBdCrsfAW44YYbAFi6dClffvklcXFxrF+/nrfffrtIh6HVaiUkJKSEsJsx9caNG9Or\nVy8SEhLsaZilZcS4S2RkJCEhIaSkpDBr1iz69OnD5eU47zExMQQHB5OXl+ey4xRKF/bQ0NByhSYq\nQnmFfe3atfTv39+lXW3atEEpVS5h37t3LyJSrowYk27dutGzZ0/mzJnjOg23DGw2G/Pnz2fIkCFM\nnDiRoKAg3gEjXDN8OHz5Jbz2mlHn302WL1+OUorJkyfTb8AARlssSGioEd/v1AmiomDCBNi1y0jN\nPHDAEHRns2BNnAjR0Zx/4AHG/fnPfPjhh8byEyeMDtajR92yafv27URGRrJ48WIjc23cOBg4kP8O\nHsxUi4W8F14wbi4LFxoO6IwZVVfr3h23vrQX0Br4EdgJ7ACmlrWPV4qAlcbvvxuPboXhh8mTJ8sD\nZrXAUgo6VQW7d+92OiqzCDk5xijG8eONGjAgdzsJjcTGxkpoaKgA0qNHD9lRWG+lOC1btpQ///nP\nRZaZw9e3bdtmLx514MABKSgokLp168pDDz1U2Y8qXbp0kYYNGwogn1bgvPfs2VMAef75511us3Ll\nSqN8QbFaI3fddZdERUWV+5jlZcmSJQIUqfbpCrPM8MyZM0vdrnXr1kXLJ5TBf//7XwFk06ZNbu/j\niFl9NCEhocjykydPyhtvvGEUCisF8ztYuHChiBilL6KiosRmlj94+uly29S/f3978br33ntPANn5\n5psiLVoYtXhefVVk5073wysffywCcifI0F69jHpDZp2ooCCRMWPsxeNc8cEHHwggNzduLLY6dUR6\n9RLJzJTevXtfHOQmYpQ6ueMOo+3IyCIVOMsLVRiKyQceFpFLgb7AfUop1+kTviA62gjbFKY97t60\niX8UFBgz6PgwDANGR13dunVdpzwCBAcbnsmSJfDll9iAX1u1KhEaueWWWzh79iwzZsxg48aNLrNY\nGjZsWCLd0QzFNG7cmPj4eMBIe0xNTSU7O7vUjBh3adeuHadPn6ZNmzaMHDmy3Pub4ZjKeOzepjwe\n+88//wxg77B2RVRU1MVcdjeoSA67I3fccQd16tRhzpw59mXZ2dnccMMNTJkyhR9++KHU/T/44APC\nwsK4sTDMcvPNN7N//362xsdDSooRCnHC3r176dWrlz2caHL69Gk2bNhgD5ONGjWKunXr8npSkpFE\n8fXXMHWqkdPv7hPZrbeS3qYNM4FPN29Gnn/e+I2tXAn33muMbena1QjtbNnitImUlBS6AXPS0zkR\nEgLffEMWRmJGkTTHqCjjSWDzZujVy3jC8DKVFnYROSoiiYX/ZwG7gJaVbbcivPfeewwYMICVK1eW\nXDl4MKxeTX52Njds3UrYhQtGjqyXH83LIiAggLi4uNIzY8DIjklPh1mz2B4SQrPC1DRHZsyYwcGD\nB3n22WdLTSF0NouSGYqJjIyke/fuBAYGsnnzZrcyYtzFjLPff//9zmdMKoOBAwcSEhJSqrCbYafi\nKY9VLezuxG2PHTsGlJ1eGR0dXa5QTHJyMo0bN3bZD1EW4eHh3HzzzXz88cdkZ2dTUFDA6NGj2bBh\nA0op1q5d63LfzMxMPv/8c26//XZ7f8aIESMICAjg8y++MBwsF7+5tWvXkpCQYJ+U3GTVqlXYbDaG\nFk4bGRYWxsiRI/nkk09c902VhcXCyqFDCQOWA7PGjTNCJldfbcxjfPAgPPecIerx8UZIxdEZOnWK\ndt9+y0qLhQv16nF5Vha/Z2aybt06CgoKnOevx8cbI+Vbel8ePRpjV0pFAT2Anz3ZrjtcuHCBf/zj\nH6xbt47Bgwdz4403kpKScnGDwYMhK4tjL73EXwoK+P2KK4wBQH5A165d2bZtW+kxzaFDDc89K4vP\nc3OdCm1gYCAtWrQo83jOhD09PZ2GDRtitVqpU6cOXbp0ISEhwR7794Sw/+EPfyAmJobx48dXaP+7\n776bgwcP2gdZOcOVx56RkeF3Hrv5HZQ2aAoMYT98+LDrCdCLYaY6VoY///nPZGRk8MUXX/Dwww/z\nxRdf8PLLL9O9e/dShf2zzz4jOzubMWPG2JdFRkZyxRVX8MUXX5R6zAMHDgCwcOFCfv31V/vy5cuX\nExYWRp8+fezL7rnnHs6cOVMixbc8/NqoEaEBAXx4/fW89O23RQf4RUQYqZHJyUYn7dtvG572Cy8Y\ng6maN2fsL79wOiSEgm++4ZjVyl//+ldWr16N1WotV/+RV3AnXuPOC6gP/AKMdLF+ApAAJLRp06bC\nMSZXfP755/bY7XPPPSf169cXq9Uqf//7341KhqdPi1gskh8YKBkgyf/7n8dtqChmzfYjZU0MMmKE\nCEgsyHvvvVfh440ePbpEvPmWW26Rjh072t9PmDDBXqTMsbKiv3Pu3DmncfgOHTrI7bff7vXjr1u3\nTgC30iYfeeQRqVu3bpnbmbHc4jX9XWHOBlUZCgoKJDo6Who1amQvZyxipEOGhIRInovCaP3795dL\nLrmkRPXQN954w4iL79zp8pjjx4+X8PBwCQ0NlRsLy/babDZp2bKlMW2fA/n5+dKqVSsZNmxYhT/j\n5MmTJTIy0t6/VOp3tmXLxZr8kZEiU6fKwAYN7EXTnn/+eQGkUaNG9rkPvAFVme6olLICnwMLRMTp\nbVlE3hWReBGJN+uWeJK33nqLNm3acPPNNzN9+nSSk5O5+eabefrpp41e7/Bw6NWLgPx8/m210s7X\nd1QHyiwtYPL44+wdOZIdUKmYd8OGDZ167I7FuOLj4zlz5gzffvutR7z1qqJu3boEBgb6PBTjrsfu\nTrikPCmPZ8+e5ciRIxVKdXTEYrEwduxYTp48yciRI+0TbA8YMIBz5845vVb37NnDunXrGDNmTIks\nnz/+8Y8ApXrtqampdOzYkWnTprFkyRI2bdrEjh07OHz4sD0MYxIQEMBdd93FihUrOOpmFktxTp8+\nTcOGDRk+fHjZA7O6d4e1a+HXX+HwYU499RT/y8qiQ4cOADz44IPExMRw8uRJn5URcKTSwq6Mb3AO\nsEtEXqm8SeVn9+7drFq1iokTJ9oLbjVv3pyPPvqIK6+8kvvuu8+onTFmDNsaNGBDr14uC3P5gjJL\nC5hcfjlfFA5RrozYhoeHk5GRgc1msy87fvw4jjfcXr16AUYcuDoJu1LKab2YqhL28pQU8Iawm+HH\nyoZiAB566CHeeecdPvroI/vvxaxA6Swc8+mnnwJw5513lljXokULLr/88lKF/cCBA7Rp04YHH3yQ\nyMhInnjiCZYXjrh2Nr5g7NixFBQUMHfu3PJ/OC6e/+DgYO68806+/PJLpzWU7FgsRlHAoCB7B685\nSjk4OJjXXnsNi8XCddddVyF7PIknPPb+wF3AIKXU1sLXMA+06zbvvPMOVquVcePGFVkeEBDARx99\nRJ06dbjttts4f/fd9CsooEth1oe/EBERQatWrcoWdoyc8qZNm5YaZy6L8PBwRKRIsaf09PQiwh4b\nG2vv/PJERkxVUrxeTF5eHjk5OX7XeequsLdo0QKr1eqWsFc2I8aR+vXrM3HixCLD4lu2bEl0dLRT\nYV+8eDH9+vWjpYvOwZEjR5KYmEhqamqJdSJiF/YGDRowffp0Vq5cycyZM4mLi7PXIXIkJiaGa665\nhtmzZzstgFcWjud/zJgx5ObmsnDhQrf2NW+gpscOMHToUE6dOlWi/LIv8ERWzFoRUSLSVUS6F76+\n8YRx7nDu3DnmzZvHzTff7LT8a8uWLZk3bx5btmxh1KhRnD9/vtSsCl/RrVs3t4R9586dlRba4hUe\nzToxjqEYq9Vqr3denTx2KFnh0byBVddQTEBAAG3atHEr5dEUdkfB8TQDBgxg7dq1RTr7U1JS2LZt\nG3/6059c7jdw4EDAecjx5MmTZGdn20snT548mRYtWnDkyJESYRhHJk+ezMGDB/n666/L/Tkcz3+P\nHj3o2rWr23VyTI/dzPQyKasjvKqo9iNPFy5cSEZGBn/5y19cbnPDDTfwwAMP8M03xv3GVQEpX2IW\nuSot80FEPDIKtHghsFOnTmGz2Sje92GGY6q7sLtTAMxTeEPYwf2Ux+TkZFq0aEH9+vXdarciDBgw\ngLS0tCL55p9//jlg5Ky7wnyKMG8+jpgZMW3atAGMvpKnCitCXn/99S7bHDFiBC1atODtt98u56co\nev6VUowdO5bNmzeXPgq8kJSUFFq0aEG9evXKfdyqoFoLu4jw1ltvERcXx4ABA0rd1qw8WL9+fTo7\nmXHG13Tt2pX8/Hx+MycrcMLRo0fJzMystMdeXNjNwUnFZzKaMmUKL7zwQpn10v2N4qGY2iTsnkh1\nLAvzt+YYjlm8eDG9evWyC7MzIiIiiIiIcCrsZnjGcf8JEyaQkJBQamdkYGAg9957LytWrChR778s\nzM5TE/OmtGLFijL3TUlJ8epTUWWp1sK+efNmEhMTmTx5cpk1QIKDg1mxYgU//PBDhQbHeBszM6a0\ncIyncspNMTFDMY51Yhzp2LEjjzzyiNfrq3gaX3rs7naeiki5hT09PZ2zZ8+Wul1VCHvnzp2JiIiw\nC3tqaioJCQmlhmFMYmJiio4vKaS4xw6GF+1O2PTee+/FYrEwe/Zsdz8COTk55ObmFjn/rVu3JiYm\npsyRtWCEYrSwe4lnn32W+vXrM3r0aLe2b9KkiT284G907NiR4ODgUoXdU6NATS+lLI+9uuIPHntZ\nnadmzXh3Y7JmZkxpcfYzZ86Qnp7udWG3WCz079/fLuzuhGFMOnTo4DIUU7du3XJNDGLSsmVLRowY\nwdy5c90eiWpe+8VvrIMGDWLNmjXk5+e73Pfs2bMcO3asUnX7vU21FfYlS5bw1Vdf8eSTT1bJD9bb\nBAYGEhsbW2ou+/bt24mIiKBZs2aVOparUIw3xhf4guoQY3clLK5wJ+XRFMzK5rC7w4ABA9i9ezfp\n6eksXryY7t27uyV0MTExHDx4sIQAHzhwgLZt21b46XDy5MmcOHHCqLToBqUJe1ZWln3qTGeYfQva\nY/cwZ8+e5f777ycuLq5cNb39HbO0gCsSExONWZ8qGRoxy9eaF7cZiqmIt+SPhIaGkpeXZ++INr33\nqshY8Jawm/VkShN284muKoTdTOlbtGgRGzZscCsMA4awi0iJeHhqamqp8fmyuPrqq+nQoYPbnaiu\nzr8Zzy8tHKOF3Us8/fTTHDx4kNmzZ9t/SDWBHj162Of0LE5eXh5JSUkeyeixWCyEhobaY+zp6elE\nRETUmHNZvBBYTfDYmzRpQr169UoV9o0bN9KgQQM6VUH1wPj4eIKDg/nHP/4BUC5hh5KZMWYOe0Wx\nWCxMmjSJ9evX229wpWFe+8XHgzRp0oQuXbqUKuxmH4EOxXiQbdu2MXPmTO69994yy51WN8wiR2Y5\nV0d27txJXl6ex1I1HcsKFB91Wt0pXggsMzMTi8VSJalpSikCAwM9LuxKqTLL965fv56+fftWyajq\n4OBgevXqRXp6OrGxsW7fTEwv11HYc3JySEtLq5SwAwwbZoyLTHBjPtPSzv+gQYNYu3aty9TjlJQU\nIiMj/SZn3RnVSthtNhuTJk0iIiKC559/3tfmeJzu3bsTFBTEpk2bSqxLTEwEDK/eEzhWeCxeJ6a6\n48xjr4rZk0ysVmuZnaflFXYoPeUxMzOTX3/9tUqdHTPt0V1vHQyHolGjRkWE3XxCbetstqNy0KFD\nB4KCgkgyp8srhbKEPScnxz5xenH8PSMGqpmwv/fee2zcuJGXX36ZiIgIX5vjcYKDg+nevbtTj33L\nli3Ur1/fYxdUeHh4kXTHmu6xV2UHu9Vq9bjHDheF3XHEp8mmTZuw2WxVKuzDhw+nbt263H777eXa\nr3jKo7Mc9opgtVrp3LlzpYX9D3/4AxaLxWU4xt9z2KGaCXtubi7XX3+92+mN1ZE+ffqQkJBQovZF\nYmIiPXr0wGLxzFfmGIopXiemumOKeHGPvaooj7CX53E+OjqazMxMp4Wq1q9fj1KqSM1yb9O/f3+y\nsrLKHdOPiYkp4rE7y2GvKLGxsezYsaPM7U6fPk2dOnWcTm4eHh5Oz549nQp7bm4uBw8e9Ov4OlQz\nYX/ggQdYunRptRswUx569+7NuXPnilycBQUFbN261WNhGLgYiikoKODkyZM1MhTj7x67K2FxhVkF\n1FkBrvXr1xMXF1flcd+KxPM7dOjAwYMHyc7OBgxhV0q5LB5WHuLi4khNTS1S4M4ZZQ0OGzRoEBs3\nbuTcuXNFlptPTNpj9zA1WdTBeQdqcnIy58+f92iNG1PYXdWJqc74OhQTFBTklrCXd+q6K6+8koYN\nG7Jo0aIiy202Gxs2bKg2yQRmZoyZ8njgwAGaNWtGcHBwpduOi4sDKLPeizvCnp+fX+Im6qyqoz9S\n7YS9ptOhQwciIiKKdKBuKZxM19PCbk7KADVn1ClUn1BMeYXdarXyxz/+ka+++qpIxsbOnTvJzMys\ndsJuhmPMwUmeIDY2FqDMOHtZ579///5YrdYS4Rgt7JoKoZSid+/eRTz2xMREgoODPVq8zMzfNX9c\nNcljDw4OJjg42KehGHeyYioy2fSoUaPIzMzku+++sy9bv349QLUR9uIpj5UdnORIdHQ0devWrbSw\nh4SE0Ldv3xLCvnfvXkJDQ/1+MJ8Wdj+kT58+7Nixw17wKTExka5du3p0AJF5UddEYQfDazc99oyM\njCqNPXvLYwdjhGXxcMz69etp3Lix33fomYSHhxMZGcmePXuKTLDhCSwWi1sdqMUrOzpj0KBBJCYm\nFumsNjNi/D0krIXdD+nTpw82m42EhAREhC1btni8hrwpKsnJyUDNCsWA0YGamZlJfn4+58+frxGh\nGLPtm266iSVLltjDMevXr6d///5+LzaOmCmP6enp5ObmekzYwQjHVNZjB2PAk81mY+jQofb+gOqQ\n6ggeEnal1FCl1G6lVIpS6nFPtFmbMStQ/vzzz+zfv58zZ854NCMGSgq7vz9alhezEFhVzp5k4k1h\nh6LhmPT0dPbs2VNtwjAmZsqjmeroqRg7GB2oR48e5dSpU07Xu1syuXfv3ixevJjk5GR69OjBggUL\n2L9/f7V4MvLEZNYBwJvAdcClwO1Kqeo1SaafERkZSfv27dm0aZN9xKmnPXbHGHujRo38skZ9ZTBL\n91ZlnRiTsrJiyluLvTiO4ZgNGzYA1Se+btKhQwcOHTpkn1jG0x474DIcc/78efLz8906/zfffDNb\nt24lNjaW0aNHk5+fX2s89t5Aioj8LiJ5wELgRg+0W6vp06cPP//8M1u2bCEgIMCew+wpzIu6pg1O\nMjE9dl8Ie1mdp2Yt9ooKe1BQkD0c8+OPP2K1Wv1yHt/SMDNjfvzxR8Czwm6mPLoKx5R31G/btm1Z\ns2YNM2bMoF69elU6CKyieELYWwIHHd4fKlymqQR9+vTh8OHDLF26lNjY2HINZHEHx4u6pgq7rzz2\nskIxFSknUBwzHPPuu+/Ss2dPj18f3sYU9lWrVhESElJmR2Z5aNWqFaGhoS49dleVHUvDarXy7LPP\ncvbsWfsTgT9TZZ2nSqkJSqkEpVSCObGDxjWmV7B9+3aPx9fBSOcywy81reMULnae1lRhv/rqqwkP\nD+f8+fPVLgwDF1MeU1NTKzXBhjOUUqV2oFbm/FeXDmpPCPthoLXD+1aFy4ogIu+KSLyIxNdED9HT\nmJUewfPxdTAuUPPCronfhxmKMVMe/UnYTZsqI+xmOAaqX3wdjBuved15MgxjEhcXR1JSktOCaZ64\nsfo7nhD2zUCMUipaKRUE3AZ85YF2azVmpUfwjrDDxQu7pnrsBQUFHDt2DPCvzlNPCcukSZPo0qWL\nfdaf6oYZjvGWsJ88edI+O5gjWtjdQETygSnACmAX8JmIlF1eTVMmffv2xWKx0K1bN6+0X9M9drhY\n69ufOk8rUtnRGX369GH79u3VNlXVm8JeWmmBisTYqxseibGLyDci0lFE2ovIs55oUwMzZsxg+fLl\nNGjQwCvtmxd2TRb2gwcPopSifv36VXbsqoix1wS87bGD85RHT91Y/Rk98tSPadq0KYMHD/Za+zU9\nFAOGsDdo0MBjdezdQQu7e5jCbk7U7UmaNGlCZGSkU4/9zJkzhISE1Jg5fp2hhb0WU1tCMVUZhgH3\nhD04OLjapSh6mhtvvJHZs2d7pfO3tMyYygwOqy5oYa/FmKGYmuyxHzlypMqF3Z3O05ouLO4QHBzM\nhAkTvDb5dlxcHDt27CiRGVMbzr8W9lpMt27d6NChQ7XtfCsNU8wLCgr80mOv6cLiD8TGxpKZmWnv\nQDdxp7JjdUcLey3mjjvuYM+ePV7zmHyJo5j7QtjLyorRwu59XJUWqA3nXwu7pkbia2G32WzYbDan\n62uDsPgDWtg1mhpGYGAg9erVA3wj7IDLcExtEBZ/oGHDhrRs2VILu0ZTkzA7UH3ReQpa2P0Bs7SA\nic1mIyMjo8affy3smhqLKej+5LFXtha7pnzExcWxc+dOCgoKAMjKysJms+nOU42muuJrYXfWgZqT\nk0NeXp4W9ioiLi6OnJwc9u7dC9SewWFa2DU1FjMUU9VDx0vz2GuLsPgLxTtQa8v518KuqbH42mPX\nwu57Lr30UpRSWtg1mpqCrzpPtbD7D/Xq1aN9+/Za2DWamoKvPPbSsmJqi7D4E46ZMbWhZC9oYdfU\nYHwdinHWeaqFveqJi4sjOTmZ3NzcWnP+tbBraiw6FKMBQ9gLCgr47bff7Oe/qq+JqkYLu6bGMmTI\nEO68805atGhRpcfVwu5fOGbGnDlzhtDQ0BpZH8mRSgm7UupFpdRvSqntSqn/KqX01arxG7p06cJH\nH31EYGBglR63LGHXtdirlo4dO2K1WklKSqoVlR2h8h7790CciHQFkoHplTdJo6nelNV5qr31qsVq\ntdK5c2e7x14bzn+lhF1EviuczBpgI9Cq8iZpNNWbsjz22iAs/kZcXBy//vprrTn/noyx/xn41oPt\naTTVkrKyYmryJMr+SlxcHKmpqRw4cEALO4BSaqVSKsnJ60aHbZ4A8oEFpbQzQSmVoJRKSE9P94z1\nGo0foj12/8PsQN2/f3+tOP9l9iqJyDWlrVdKjQGGA1dL8ckFi7bzLvAuQHx8vMvtNJrqTlnCHhUV\nVcUWaUxhh5o/OAkqnxUzFHgUGCEi5z1jkkZTvdGdp/5HVFQUISEhQO1INa1sjP0NoAHwvVJqq1Lq\nHfhYm4UAAAtvSURBVA/YpNFUa1x57LoWu++wWCzExsYCtUPYK5XgKyIdPGWIRlNTcNV5qmux+5a4\nuDg2bdpUK86/Hnmq0XgYVx67HnXqW8w4e204/1rYNRoPo4XdP+nTpw8Abdu29bEl3qdqx1prNLUA\nV52nGRkZgBZ2X9GvXz9+//13oqOjfW2K19Eeu0bjYbTH7r/UBlEHLewajcexWCxYLJYSnada2DVV\nhRZ2jcYLWK1Wl6GYml4LXON7tLBrNF7AmbBnZWUB0KBBA1+YpKlFaGHXaLxAacJev359X5ikqUVo\nYddovEBQUJBTYQ8JCcFi0T87jXfRV5hG4wWsVmuJztOsrCwdhtFUCVrYNRov4CoUo4VdUxVoYddo\nvIAWdo0v0cKu0XgBLewaX6KFXaPxAq46T7Wwa6oCLewajRfQHrvGl2hh12i8gM6K0fgSLewajRfQ\nHrvGl3hE2JVSDyulRCkV6Yn2NJrqTnFhz8/PJzs7Wwu7pkqotLArpVoDQ4ADlTdHo6kZFO88PXv2\nLKDrxGiqBk947DOBRwHxQFsaTY2guMeuC4BpqpJKCbtS6kbgsIhs85A9Gk2NoHjnqRZ2TVVS5tR4\nSqmVQDMnq54AZmCEYcpEKTUBmADQpk2bcpio0VQ/tMeu8SVlCruIXONsuVKqCxANbFNKAbQCEpVS\nvUXkmJN23gXeBYiPj9dhG02NRgu7xpdUeDJrEfkVaGK+V0rtB+JF5IQH7NJoqjVa2DW+ROexazRe\noHhWjBZ2TVVSYY+9OCIS5am2NJrqju481fgS7bFrNF5Ah2I0vkQLu0bjBZwJu8VioW7duj60SlNb\n0MKu0XgBq9VKfn4+IkYCmFknpjCDTKPxKlrYNRovEBQUBBg1YkAXANNULVrYNRovYLVaAezhGC3s\nmqpEC7tG4wVMYTczY7Swa6oSLewajRfQHrvGl2hh12i8gBZ2jS/Rwq7ReAGz81QLu8YXaGHXaLyA\n9tg1vkQLu0bjBXTnqcaXaGHXaLyAo8eem5vLhQsXtLBrqgwt7BqNF3AUdl0nRlPVaGHXaLyAY+ep\nFnZNVaOFXaPxAtpj1/gSLewajRdw7DzVwq6pajw20YZGo7mIo8duFgLTwq6pKirtsSul7ldK/aaU\n2qGUesETRmk01R0ditH4kkp57Eqpq4AbgW4ikquUalLWPhpNbUALu8aXVNZjnww8LyK5ACJyvPIm\naTTVH50Vo/EllRX2jsBApdTPSqk1SqlenjBKo6nuaI9d40vKDMUopVYCzZyseqJw/wigL9AL+Ewp\n1U7M+cCKtjMBmADQpk2bytis0fg9xbNigoKC7F68RuNtyhR2EbnG1Tql1GTgi0Ih36SUsgGRQLqT\ndt4F3gWIj48vIfwaTU2iuMeuvXVNVVLZUMyXwFUASqmOQBBworJGaTTVHS3sGl9S2Tz2ucBcpVQS\nkAfc4ywMo9HUNop3nmph11QllRJ2EckDRnvIFo2mxqA9do0v0SUFNBovULzzVAu7pirRwq7ReIGA\ngABAe+wa36CFXaPxAkoprFarFnaNT9DCrtF4iaCgIC3sGp+ghV2j8RJWq5W8vDzOnj2rhV1TpWhh\n12i8hNVqJSMjA5vNpoVdU6VoYddovITVauXUqVOArhOjqVq0sGs0XsJqtXL69GlAC7umatHCrtF4\niaCgIO2xa3yCFnaNxkvoUIzGV2hh12i8hNVq5eTJk4AWdk3VooVdo/ESVqtVT2St8Qla2DUaL2HW\niwEt7JqqRQu7RuMltLBrfIUWdo3GSzhOhVe/fn0fWqKpbWhh12i8hOmx16tXz17tUaOpCrSwazRe\nwhR2HYbRVDWVEnalVHel1Eal1FalVIJSqrenDNNoqjta2DW+orIe+wvA0yLSHXiq8L1Go0ELu8Z3\nVFbYBQgt/D8MOFLJ9jSaGoPZeaqFXVPVVGoya+BBYIVS6iWMm0S/ypuk0dQMtMeu8RVlCrtSaiXQ\nzMmqJ4CrgYdE5HOl1C3AHOAaF+1MACYAtGnTpsIGazTVBS3sGl9RprCLiFOhBlBKfQhMLXy7CHi/\nlHbeBd4FiI+Pl/KZqdFUP7Swa3xFZWPsR4ArCv8fBOypZHsaTY1BC7vGV1Q2xn4vMEspFQjkUBhq\n0Wg0uvNU4zsqJewishbo6SFbNJoahfbYNb5CjzzVaLyEFnaNr9DCrtF4CS3sGl+hhV2j8RJa2DW+\nQgu7RuMltLBrfIUWdo3GS+isGI2v0MKu0XgJLewaX6GFXaPxEtdddx1PPPEE7du397UpmlqGEqn6\n0f3x8fGSkJBQ5cfVaDSa6oxS6hcRiS9rO+2xazQaTQ1DC7tGo9HUMLSwazQaTQ1DC7tGo9HUMLSw\nazQaTQ1DC7tGo9HUMLSwazQaTQ1DC7tGo9HUMHwyQEkplQ6kVnD3SOCEB83xNNq+yqHtqxzavsrj\nzza2FZHGZW3kE2GvDEqpBHdGXvkKbV/l0PZVDm1f5akONpaFDsVoNBpNDUMLu0aj0dQwqqOwv+tr\nA8pA21c5tH2VQ9tXeaqDjaVS7WLsGo1Goymd6uixazQajaYUqpWwK6WGKqV2K6VSlFKP+4E9c5VS\nx5VSSQ7LIpRS3yul9hT+behD+1orpX5USu1USu1QSk31JxuVUnWUUpuUUtsK7Xu6cHm0Uurnwu/5\nU6VUkC/sc7AzQCm1RSm1zN/sU0rtV0r9qpTaqpRKKFzmF99voS3hSqnFSqnflFK7lFKX+4t9SqlO\nhefNfGUqpR70F/sqQ7URdqVUAPAmcB1wKXC7UupS31rFB8DQYsseB1aJSAywqvC9r8gHHhaRS4G+\nwH2F58xfbMwFBolIN6A7MFQp1Rf4NzBTRDoAp4FxPrLPZCqwy+G9v9l3lYh0d0jR85fvF2AWsFxE\nOgPdMM6jX9gnIrsLz1t3oCdwHvivv9hXKUSkWryAy4EVDu+nA9P9wK4oIMnh/W6geeH/zYHdvrbR\nwbYlwGB/tBGoByQCfTAGhwQ6+959YFcrjB/3IGAZoPzMvv1AZLFlfvH9AmHAPgr78vzNvmI2DQHW\n+at95X1VG48daAkcdHh/qHCZv9FURI4W/n8MaOpLY0yUUlFAD+Bn/MjGwjDHVuA48D2wFzgjIvmF\nm/j6e34VeBSwFb5vhH/ZJ8B3SqlflFITCpf5y/cbDaQD8wpDWe8rpUL8yD5HbgM+KfzfH+0rF9VJ\n2KsdYtzyfZ52pJSqD3wOPCgimY7rfG2jiBSI8SjcCugNdPaVLcVRSg0HjovIL762pRQGiMhlGCHK\n+5RSf3Bc6ePvNxC4DHhbRHoA5ygW1vD19QdQ2EcyAlhUfJ0/2FcRqpOwHwZaO7xvVbjM30hTSjUH\nKPx73JfGKKWsGKK+QES+KFzsVzYCiMgZ4EeM0Ea4UiqwcJUvv+f+wAil1H5gIUY4Zhb+Yx8icrjw\n73GM+HBv/Of7PQQcEpGfC98vxhB6f7HP5DogUUTSCt/7m33lpjoJ+2YgpjAjIQjj0ekrH9vkjK+A\newr/vwcjru0TlFIKmAPsEpFXHFb9f/v2jhJBEMRh/KtIZBEfYGYgJmbiAQwEM2MTMfQUIngdUwND\n9QAi+MAHqJmBJp7AoAy6Fzd0TbZtvh80DB39oWaK6RqmiYwRsRgRc/V6mjL/f6I0+J1J58vMg8xc\nysxlyv12kZl7reSLiEFEzAyvKXPiexqpb2Z+AG8RsVq3toBHGsk3YpefMQy0l298kx7yj/mBYxt4\npsxhDxvIcwy8A1+Ut5N9ygz2HHgBzoCFCebboBwj74CburZbyQisAdc13z1wVPdXgEvglXI8nmqg\n1pvAaUv5ao7buh6Gz0Qr9a1Z1oGrWuMTYL6xfAPgE5gd2Wsm31+Xf55KUmf+0yhGkvQLNnZJ6oyN\nXZI6Y2OXpM7Y2CWpMzZ2SeqMjV2SOmNjl6TOfAOrsiUvkD6r3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xca06ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.25225678278 \n",
      "Updating scheme MAE:  1.45505629909\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
