{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/32_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-2\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 32 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 32 \n",
      "Learning rate = 0.01 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.01\n",
      "Fold: 1  Epoch: 1  Training loss = 2.7396  Validation loss = 2.1246  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.6665  Validation loss = 1.0660  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.6264  Validation loss = 1.6964  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.6001  Validation loss = 1.0076  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.5551  Validation loss = 0.9800  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.5685  Validation loss = 0.7871  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.5089  Validation loss = 1.3893  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.4811  Validation loss = 1.1140  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.4244  Validation loss = 1.1828  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.4036  Validation loss = 0.8404  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.4369  Validation loss = 0.5316  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.1873  Validation loss = 1.1215  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.1553  Validation loss = 1.4618  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 11  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 1.9265  Validation loss = 2.0410  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 1.8849  Validation loss = 2.1378  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 1.9969  Validation loss = 2.4300  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 1.9254  Validation loss = 2.6385  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 1.7318  Validation loss = 2.2021  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 1.6893  Validation loss = 2.4695  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 1.5427  Validation loss = 2.3988  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 1.6672  Validation loss = 2.6167  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 1.4902  Validation loss = 2.0113  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 1.5148  Validation loss = 2.0237  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 1.4833  Validation loss = 1.8433  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 1.5848  Validation loss = 2.0255  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 1.4849  Validation loss = 1.7772  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 1.5187  Validation loss = 1.9430  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 1.4285  Validation loss = 1.8770  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 1.4366  Validation loss = 2.6710  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 13  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.2364  Validation loss = 1.5864  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.2107  Validation loss = 1.6936  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.1715  Validation loss = 1.7402  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.1996  Validation loss = 1.7330  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.2229  Validation loss = 1.6595  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.1818  Validation loss = 1.5953  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.2503  Validation loss = 1.5806  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.2023  Validation loss = 1.5841  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.1314  Validation loss = 1.5947  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.1656  Validation loss = 1.6756  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.1304  Validation loss = 1.6060  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.1388  Validation loss = 1.6155  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.1109  Validation loss = 1.6245  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.1339  Validation loss = 1.6348  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.1920  Validation loss = 1.7773  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 7  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.1015  Validation loss = 2.4263  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.1453  Validation loss = 2.9389  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.0754  Validation loss = 2.3365  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.0489  Validation loss = 2.4041  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.1170  Validation loss = 2.2958  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.1230  Validation loss = 2.4029  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.0609  Validation loss = 2.1228  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.0121  Validation loss = 2.1603  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 0.9929  Validation loss = 1.9664  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 0.9770  Validation loss = 1.6864  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 0.9722  Validation loss = 1.8841  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.0771  Validation loss = 1.8104  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 0.9893  Validation loss = 1.8447  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.0357  Validation loss = 1.7645  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 0.9896  Validation loss = 1.7200  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 0.9863  Validation loss = 1.7361  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 0.9523  Validation loss = 1.4532  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 0.9515  Validation loss = 1.6414  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 0.9275  Validation loss = 1.6567  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.0717  Validation loss = 1.4970  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 0.9456  Validation loss = 1.4782  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.0297  Validation loss = 1.6739  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.0002  Validation loss = 1.6360  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.0530  Validation loss = 1.2437  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 0.9418  Validation loss = 1.4380  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.0034  Validation loss = 1.2957  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 0.9216  Validation loss = 1.4895  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 0.9330  Validation loss = 1.7279  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 24  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 0.8526  Validation loss = 1.1821  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 0.9020  Validation loss = 1.1666  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 0.9595  Validation loss = 1.4798  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 0.8544  Validation loss = 1.3468  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 0.8219  Validation loss = 1.3316  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 0.8168  Validation loss = 1.3019  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 0.8115  Validation loss = 1.2678  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 0.8258  Validation loss = 1.0664  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 0.8564  Validation loss = 1.2057  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.8484  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.8497  Validation loss = 1.2186  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 0.8091  Validation loss = 1.2108  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 0.8098  Validation loss = 1.2478  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 0.8600  Validation loss = 1.2327  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.8252  Validation loss = 1.2612  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 0.8068  Validation loss = 1.2471  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 0.8187  Validation loss = 1.2571  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 0.7835  Validation loss = 1.2577  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 0.8182  Validation loss = 1.1994  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 0.8623  Validation loss = 1.2212  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 0.8005  Validation loss = 1.2138  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 0.8067  Validation loss = 1.2743  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 8  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.8673  Validation loss = 1.4813  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 0.8442  Validation loss = 1.4045  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.8383  Validation loss = 1.4468  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.9401  Validation loss = 1.5454  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.8483  Validation loss = 1.4418  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.8911  Validation loss = 1.5136  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.8388  Validation loss = 1.4409  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.8264  Validation loss = 1.5625  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.8386  Validation loss = 1.3632  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.8563  Validation loss = 1.3474  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.8115  Validation loss = 1.4893  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.8278  Validation loss = 1.3414  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.8662  Validation loss = 1.4012  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.8014  Validation loss = 1.4836  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.8217  Validation loss = 1.3756  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.8247  Validation loss = 1.3457  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 0.7960  Validation loss = 1.3349  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 0.9261  Validation loss = 1.3711  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 0.7913  Validation loss = 1.3609  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 0.7769  Validation loss = 1.4350  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 0.8072  Validation loss = 1.3966  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 0.8355  Validation loss = 1.4006  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 0.8110  Validation loss = 1.4392  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 0.7831  Validation loss = 1.4614  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 17  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.8255  Validation loss = 1.7595  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.8086  Validation loss = 2.1389  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.8821  Validation loss = 2.3453  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.8403  Validation loss = 2.0631  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.8097  Validation loss = 1.7546  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.8152  Validation loss = 1.5654  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.7747  Validation loss = 1.7868  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.8134  Validation loss = 1.9577  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.7926  Validation loss = 1.7292  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.8121  Validation loss = 2.0239  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.7875  Validation loss = 2.0450  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.8106  Validation loss = 2.0116  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.8063  Validation loss = 1.6876  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.7536  Validation loss = 1.7262  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.7832  Validation loss = 1.5693  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 0.7585  Validation loss = 1.7746  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 0.8666  Validation loss = 1.8391  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 0.9321  Validation loss = 1.6937  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 0.7630  Validation loss = 1.8933  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 0.7467  Validation loss = 1.7449  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 0.9293  Validation loss = 2.4462  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 6  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.8110  Validation loss = 4.1392  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.7985  Validation loss = 4.2615  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.7621  Validation loss = 4.0013  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.7321  Validation loss = 4.0244  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.7183  Validation loss = 4.0490  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.7366  Validation loss = 4.1698  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.7403  Validation loss = 4.2552  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.7091  Validation loss = 4.0979  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.7056  Validation loss = 4.1949  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.7314  Validation loss = 3.9530  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.7273  Validation loss = 4.0446  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.7077  Validation loss = 3.9208  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 0.7705  Validation loss = 3.9071  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 0.7284  Validation loss = 4.0492  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 0.6891  Validation loss = 4.1854  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 0.7937  Validation loss = 4.5495  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 13  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.1702  Validation loss = 6.8806  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.0990  Validation loss = 6.7277  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.0688  Validation loss = 6.8078  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.0013  Validation loss = 7.0993  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.0211  Validation loss = 6.9546  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 0.9821  Validation loss = 6.8912  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.0012  Validation loss = 7.0101  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 0.9853  Validation loss = 6.8172  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 0.9318  Validation loss = 6.8318  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.0004  Validation loss = 6.9899  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 0.9806  Validation loss = 6.9789  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 0.9750  Validation loss = 6.9898  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 0.9169  Validation loss = 6.9209  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 0.8863  Validation loss = 6.8113  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 0.9728  Validation loss = 6.7964  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 0.9165  Validation loss = 6.8948  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 0.9209  Validation loss = 6.9981  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 2  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.8149  Validation loss = 2.9715  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.7110  Validation loss = 3.8602  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.3125  Validation loss = 3.2584  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.7264  Validation loss = 3.1488  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.2749  Validation loss = 2.9450  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.2783  Validation loss = 3.2845  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.2759  Validation loss = 3.1864  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.2801  Validation loss = 3.0381  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.3937  Validation loss = 3.0699  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.0957  Validation loss = 3.4483  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.2764  Validation loss = 2.4163  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.5020  Validation loss = 2.4512  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 1.5337  Validation loss = 2.4812  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.2142  Validation loss = 2.4151  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.0033  Validation loss = 3.0722  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 1.1466  Validation loss = 3.4873  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 14  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.1986  Validation loss = 2.7286  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.1445  Validation loss = 2.7935  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.3635  Validation loss = 3.6823  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.1293  Validation loss = 2.7437  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.1777  Validation loss = 2.2682  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.0537  Validation loss = 2.5173  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.0875  Validation loss = 3.0647  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.0649  Validation loss = 2.4020  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 0.9981  Validation loss = 3.7040  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.1086  Validation loss = 2.8070  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.1421  Validation loss = 2.6776  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 0.9853  Validation loss = 3.3765  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.0309  Validation loss = 2.9099  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.3621  Validation loss = 4.2978  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 5  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.5151  Validation loss = 1.3227  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.2508  Validation loss = 1.1946  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.2336  Validation loss = 1.4563  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.2685  Validation loss = 1.4994  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.3118  Validation loss = 0.8427  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.1751  Validation loss = 0.8681  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.2272  Validation loss = 0.9255  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.0407  Validation loss = 1.0317  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.2983  Validation loss = 1.6569  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.0505  Validation loss = 1.3786  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.2378  Validation loss = 1.2710  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.0109  Validation loss = 1.2645  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 0.9377  Validation loss = 1.1773  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.0148  Validation loss = 1.1144  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 0.9760  Validation loss = 1.1989  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.0339  Validation loss = 1.4899  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 1.0544  Validation loss = 1.4528  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 0.9932  Validation loss = 1.3564  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 1.1105  Validation loss = 1.4860  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 0.9761  Validation loss = 0.9776  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 1.1692  Validation loss = 1.5107  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 5  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.3368  Validation loss = 3.7624  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.2439  Validation loss = 3.6315  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 0.9920  Validation loss = 2.2628  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 0.9142  Validation loss = 2.6240  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.0979  Validation loss = 2.3266  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.0603  Validation loss = 2.4596  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.0351  Validation loss = 3.2896  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.1719  Validation loss = 2.1258  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 0.9497  Validation loss = 2.5954  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.0028  Validation loss = 2.1435  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 0.9460  Validation loss = 2.8159  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 0.9050  Validation loss = 2.9377  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 0.9229  Validation loss = 2.8926  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 0.8746  Validation loss = 2.8674  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 0.9464  Validation loss = 2.6105  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 0.9102  Validation loss = 2.9314  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 0.8435  Validation loss = 2.6300  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 0.8556  Validation loss = 2.3162  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 0.8961  Validation loss = 2.7679  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 0.8980  Validation loss = 3.0695  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 8  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.0027  Validation loss = 4.2315  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.0360  Validation loss = 3.3881  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.0320  Validation loss = 4.4361  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.0676  Validation loss = 4.5908  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.0313  Validation loss = 3.3305  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.0697  Validation loss = 4.4954  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 0.9862  Validation loss = 3.9836  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 0.9214  Validation loss = 3.9408  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 0.9301  Validation loss = 3.5656  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.1053  Validation loss = 3.2292  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.0255  Validation loss = 2.9364  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.0106  Validation loss = 4.5564  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 0.9855  Validation loss = 2.9034  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 0.9213  Validation loss = 4.8917  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 13  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 1.3367  Validation loss = 4.4129  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.4377  Validation loss = 4.2617  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 1.2470  Validation loss = 5.4699  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.4094  Validation loss = 5.0596  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.1905  Validation loss = 5.0051  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.1227  Validation loss = 5.3799  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.1389  Validation loss = 5.5199  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.1925  Validation loss = 5.1904  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.1491  Validation loss = 5.0063  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.1368  Validation loss = 4.9999  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 1.1184  Validation loss = 4.7020  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 1.1094  Validation loss = 5.0043  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 1.3130  Validation loss = 4.8916  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 1.1806  Validation loss = 4.7645  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 1.0723  Validation loss = 4.7969  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 1.2167  Validation loss = 4.5976  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 1.0110  Validation loss = 4.4228  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 1.1776  Validation loss = 4.6829  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 0.9941  Validation loss = 4.6087  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 1.1035  Validation loss = 4.8469  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 1.0627  Validation loss = 4.9118  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 1.1860  Validation loss = 5.8579  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 2  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 1.8207  Validation loss = 3.6594  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 1.7580  Validation loss = 2.9668  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 1.5063  Validation loss = 3.8910  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 1.5278  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 1.4126  Validation loss = 3.3118  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 1.5995  Validation loss = 3.0648  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 1.4636  Validation loss = 3.1546  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 1.5556  Validation loss = 3.1520  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 1.5409  Validation loss = 2.7419  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 1.8193  Validation loss = 2.7700  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 1.7001  Validation loss = 3.0875  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 1.5450  Validation loss = 2.9636  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 1.5844  Validation loss = 2.7243  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 1.4996  Validation loss = 2.6200  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 1.5011  Validation loss = 2.7611  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 1.4198  Validation loss = 2.7426  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 1.9106  Validation loss = 2.9685  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 1.5383  Validation loss = 2.7905  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 1.5840  Validation loss = 2.9834  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 1.4151  Validation loss = 2.8948  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 1.4548  Validation loss = 2.8724  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 1.4938  Validation loss = 2.5322  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 1.4738  Validation loss = 2.6299  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 1.4946  Validation loss = 2.7438  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 2.0466  Validation loss = 2.7995  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 1.5422  Validation loss = 2.8084  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 1.5859  Validation loss = 2.9187  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 1.4898  Validation loss = 2.7835  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 1.5761  Validation loss = 2.8336  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 1.8843  Validation loss = 2.9481  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 22  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.2334  Validation loss = 4.4690  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 1.6701  Validation loss = 4.6307  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 1.4800  Validation loss = 5.0908  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 1.4979  Validation loss = 4.7761  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 1.6284  Validation loss = 4.2648  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 1.5237  Validation loss = 5.2586  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 1.3918  Validation loss = 5.0336  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 1.5351  Validation loss = 5.5052  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 1.4063  Validation loss = 5.0185  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 1.3955  Validation loss = 5.7471  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 1.7281  Validation loss = 6.1150  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 5  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 1.8613  Validation loss = 0.8043  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 1.4877  Validation loss = 1.8598  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 1.7255  Validation loss = 1.4825  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.0626  Validation loss = 1.9465  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 1.8939  Validation loss = 2.0793  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 1.8226  Validation loss = 2.0448  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.5087  Validation loss = 2.7927  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 1.6985  Validation loss = 2.4643  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 1.8597  Validation loss = 3.6372  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 1.9645  Validation loss = 2.9051  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 1.9497  Validation loss = 2.8013  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 1.5869  Validation loss = 3.3054  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 1.7397  Validation loss = 3.4757  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 1.7876  Validation loss = 3.3102  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 1.6668  Validation loss = 3.3951  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 2.3370  Validation loss = 2.7021  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 1.7274  Validation loss = 2.6903  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 1.5387  Validation loss = 2.8318  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 1.5339  Validation loss = 2.8678  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 1.6971  Validation loss = 2.7962  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 1.4920  Validation loss = 2.9681  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 1.6300  Validation loss = 3.1871  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 1.5372  Validation loss = 3.1721  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 1.4309  Validation loss = 3.0459  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 1.7236  Validation loss = 2.7762  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 1.6624  Validation loss = 3.1195  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 1.4166  Validation loss = 3.0016  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 1.6430  Validation loss = 2.9543  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 1.3566  Validation loss = 3.3301  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 1  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 1.6359  Validation loss = 2.7032  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 1.3960  Validation loss = 3.8298  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 1.4136  Validation loss = 3.7451  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 1.4815  Validation loss = 3.3507  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 1.4931  Validation loss = 3.3395  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 1.3120  Validation loss = 2.9399  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 1.3480  Validation loss = 3.0406  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 1.3119  Validation loss = 3.7144  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 1.5993  Validation loss = 3.8748  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 1.4092  Validation loss = 3.4519  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 1.3565  Validation loss = 3.6784  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 1.2747  Validation loss = 3.5820  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 1.3467  Validation loss = 3.2263  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 1.3052  Validation loss = 3.4109  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 1.3156  Validation loss = 2.5063  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 1.2682  Validation loss = 2.9878  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 1.5511  Validation loss = 3.5909  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 1.3133  Validation loss = 2.0247  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 1.2117  Validation loss = 3.0140  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 1.1685  Validation loss = 2.8585  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 1.2722  Validation loss = 2.6132  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 1.1294  Validation loss = 2.9564  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 1.2363  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 1.5508  Validation loss = 3.1561  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 1.1436  Validation loss = 3.5187  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 1.1335  Validation loss = 3.7268  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 18  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 1.3135  Validation loss = 2.0534  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 1.2933  Validation loss = 2.7472  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 1.2276  Validation loss = 2.6047  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 1.3047  Validation loss = 2.7285  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 1.1461  Validation loss = 2.2066  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 1.0675  Validation loss = 2.4425  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 1.0461  Validation loss = 2.4202  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 1.0821  Validation loss = 2.8318  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 1.2068  Validation loss = 2.6515  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 1.0332  Validation loss = 2.7675  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 1.0974  Validation loss = 2.9999  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 1  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.2344  Validation loss = 3.3444  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.8237  Validation loss = 4.3905  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 1.8513  Validation loss = 4.9603  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.4629  Validation loss = 4.6380  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 1.4082  Validation loss = 3.2973  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 1.5189  Validation loss = 2.6944  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 1.5731  Validation loss = 3.1210  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 1.5618  Validation loss = 2.4373  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.4504  Validation loss = 2.8855  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 1.3058  Validation loss = 2.8855  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 1.4191  Validation loss = 2.8331  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 1.8496  Validation loss = 3.3558  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 1.2726  Validation loss = 2.9013  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 1.2810  Validation loss = 3.0820  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 1.3823  Validation loss = 2.9920  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 1.2592  Validation loss = 2.9061  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 1.2030  Validation loss = 3.3224  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 1.3113  Validation loss = 3.0644  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 1.1043  Validation loss = 3.2115  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 1.0620  Validation loss = 3.2024  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 1.0780  Validation loss = 3.1835  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 1.1564  Validation loss = 2.7981  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 1.1477  Validation loss = 3.0571  \n",
      "\n",
      "Fold: 21  Epoch: 24  Training loss = 1.0256  Validation loss = 3.2027  \n",
      "\n",
      "Fold: 21  Epoch: 25  Training loss = 1.0115  Validation loss = 3.2057  \n",
      "\n",
      "Fold: 21  Epoch: 26  Training loss = 1.0044  Validation loss = 3.0021  \n",
      "\n",
      "Fold: 21  Epoch: 27  Training loss = 0.9509  Validation loss = 2.9029  \n",
      "\n",
      "Fold: 21  Epoch: 28  Training loss = 0.9782  Validation loss = 2.9278  \n",
      "\n",
      "Fold: 21  Epoch: 29  Training loss = 0.8967  Validation loss = 3.0342  \n",
      "\n",
      "Fold: 21  Epoch: 30  Training loss = 1.0192  Validation loss = 3.2002  \n",
      "\n",
      "Fold: 21  Epoch: 31  Training loss = 1.1056  Validation loss = 3.5364  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 8  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.6223  Validation loss = 4.5270  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 1.5407  Validation loss = 4.6866  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.4270  Validation loss = 4.7563  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 1.4010  Validation loss = 4.2006  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 1.2565  Validation loss = 4.1573  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 1.1846  Validation loss = 3.8819  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.1886  Validation loss = 4.7081  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 1.3843  Validation loss = 4.1255  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.2674  Validation loss = 4.4741  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.3468  Validation loss = 4.3016  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 1.3428  Validation loss = 3.6987  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 1.2550  Validation loss = 3.9081  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 1.1343  Validation loss = 4.2190  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 1.3190  Validation loss = 4.4196  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 1.3001  Validation loss = 4.5495  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 1.2481  Validation loss = 4.2968  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 1.0301  Validation loss = 4.1931  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 0.8871  Validation loss = 4.1025  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 1.0270  Validation loss = 4.6161  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 11  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 1.2147  Validation loss = 3.1533  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 1.4573  Validation loss = 3.2619  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 1.3417  Validation loss = 2.7470  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 1.4074  Validation loss = 2.7397  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 1.3098  Validation loss = 2.2693  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 1.5203  Validation loss = 2.3468  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 1.3104  Validation loss = 4.0110  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 1.2300  Validation loss = 3.1676  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 1.3219  Validation loss = 2.7810  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 1.2526  Validation loss = 2.8594  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.2413  Validation loss = 3.5902  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 1.2510  Validation loss = 3.1388  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 1.1817  Validation loss = 1.5861  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 1.4245  Validation loss = 1.8733  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 1.4581  Validation loss = 2.9555  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 1.4051  Validation loss = 3.0208  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 1.6580  Validation loss = 2.9778  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 1.3186  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 1.3034  Validation loss = 3.2319  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 1.3612  Validation loss = 2.9028  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 1.6624  Validation loss = 3.2290  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 2.1473  Validation loss = 5.1753  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 13  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.9500  Validation loss = 2.5849  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.9739  Validation loss = 2.3572  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.8663  Validation loss = 1.9452  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.7835  Validation loss = 2.4703  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.7183  Validation loss = 1.8267  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.7447  Validation loss = 2.4724  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.8116  Validation loss = 1.3279  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.4695  Validation loss = 1.0478  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.1458  Validation loss = 1.2390  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.1698  Validation loss = 1.6741  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.2282  Validation loss = 1.0866  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 1.9782  Validation loss = 2.3590  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 1.9771  Validation loss = 2.1315  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 1.8490  Validation loss = 1.8584  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 1.9078  Validation loss = 1.4996  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 1.8521  Validation loss = 1.8024  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.3142  Validation loss = 1.9978  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.0748  Validation loss = 2.1786  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.0399  Validation loss = 1.8853  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 1.9407  Validation loss = 1.3952  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 1.8698  Validation loss = 2.1387  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 1.8649  Validation loss = 1.5481  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 1.8434  Validation loss = 1.7105  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 1.8842  Validation loss = 1.3860  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 1.6975  Validation loss = 1.7498  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 2.0416  Validation loss = 1.3447  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 1.7919  Validation loss = 2.0862  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 1.8081  Validation loss = 2.1094  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 1.7825  Validation loss = 2.3031  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 8  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 1.8623  Validation loss = 3.2533  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 1.7463  Validation loss = 3.0833  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 1.7075  Validation loss = 3.0078  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 1.8013  Validation loss = 3.1129  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 1.6744  Validation loss = 2.9503  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 1.7542  Validation loss = 2.7961  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 1.7443  Validation loss = 3.4738  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 1.6703  Validation loss = 3.0208  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 1.6484  Validation loss = 2.8976  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 1.6315  Validation loss = 2.6100  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 1.5976  Validation loss = 2.9140  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 1.5726  Validation loss = 2.9666  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 1.5153  Validation loss = 2.8146  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 1.7602  Validation loss = 2.0940  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 1.7513  Validation loss = 2.2742  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 1.8446  Validation loss = 3.0626  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 1.5864  Validation loss = 2.7394  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 1.4956  Validation loss = 2.4485  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 1.6958  Validation loss = 2.8054  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 1.5016  Validation loss = 2.4630  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 1.8105  Validation loss = 2.7763  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 1.8427  Validation loss = 2.1259  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 2.0078  Validation loss = 2.3531  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 1.7759  Validation loss = 2.4587  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 1.7494  Validation loss = 2.6755  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 1.6417  Validation loss = 2.5461  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 1.7615  Validation loss = 2.6967  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 1.6218  Validation loss = 2.8602  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 14  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 1.7810  Validation loss = 1.6389  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 1.8130  Validation loss = 1.4868  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 1.8004  Validation loss = 1.8174  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 1.7797  Validation loss = 1.9056  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 1.7221  Validation loss = 1.3434  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 1.8260  Validation loss = 3.2571  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 1.8337  Validation loss = 2.3226  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 1.7889  Validation loss = 2.7856  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 1.7329  Validation loss = 2.2473  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 1.9666  Validation loss = 1.1980  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 1.7110  Validation loss = 2.0782  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 1.8667  Validation loss = 1.1915  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 1.8218  Validation loss = 2.1323  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 1.7587  Validation loss = 1.6726  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.2434  Validation loss = 3.1472  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 1.7672  Validation loss = 2.5390  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 1.7558  Validation loss = 2.6238  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 1.6895  Validation loss = 3.1982  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 12  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 1.9170  Validation loss = 3.0114  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 1.7993  Validation loss = 2.6467  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.7971  Validation loss = 2.2890  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 1.8331  Validation loss = 2.4689  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 1.7165  Validation loss = 2.5205  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 1.5295  Validation loss = 2.4287  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 1.5306  Validation loss = 2.7167  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 1.5583  Validation loss = 2.3816  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 1.5294  Validation loss = 2.4613  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.6413  Validation loss = 2.9211  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 1.6121  Validation loss = 2.1917  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 1.6287  Validation loss = 2.3614  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 1.6066  Validation loss = 3.2095  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 11  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 1.6813  Validation loss = 1.7343  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 1.7281  Validation loss = 1.7232  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 1.7390  Validation loss = 1.8098  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 1.8010  Validation loss = 1.8491  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 1.7486  Validation loss = 1.8555  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 1.7645  Validation loss = 1.2499  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 1.6520  Validation loss = 1.4428  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 1.7567  Validation loss = 1.6240  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 1.6745  Validation loss = 1.9480  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 1.5822  Validation loss = 2.0606  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 1.5859  Validation loss = 1.7992  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 1.5452  Validation loss = 1.7200  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 1.4931  Validation loss = 1.7957  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 1.4888  Validation loss = 1.5962  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 1.4955  Validation loss = 1.5951  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 1.4471  Validation loss = 1.8411  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 1.5094  Validation loss = 1.7894  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 1.5667  Validation loss = 2.1192  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 6  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 1.9297  Validation loss = 1.4955  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 1.5158  Validation loss = 1.3319  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 1.6191  Validation loss = 1.4316  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 1.6706  Validation loss = 1.5596  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 1.6041  Validation loss = 1.5971  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 1.5394  Validation loss = 1.3459  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 1.4641  Validation loss = 1.4401  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 1.5299  Validation loss = 1.4597  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 1.4933  Validation loss = 1.6476  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.4433  Validation loss = 1.4411  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 1.4409  Validation loss = 1.8312  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 2  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.4363  Validation loss = 1.8701  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 1.4414  Validation loss = 1.7745  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 1.3881  Validation loss = 2.1217  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 1.4271  Validation loss = 2.2004  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 1.3805  Validation loss = 2.0350  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.5347  Validation loss = 1.9863  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 1.3875  Validation loss = 1.8715  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.3556  Validation loss = 2.1334  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.3508  Validation loss = 2.0213  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.3010  Validation loss = 2.2781  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.2629  Validation loss = 2.1046  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 1.2211  Validation loss = 1.9948  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 1.3782  Validation loss = 1.9121  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 1.3686  Validation loss = 1.9923  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 1.3856  Validation loss = 2.5618  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 2  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 1.2974  Validation loss = 3.4075  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.3824  Validation loss = 3.4333  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.2731  Validation loss = 3.4907  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.3167  Validation loss = 3.3574  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 1.5237  Validation loss = 2.8361  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 1.3990  Validation loss = 3.5740  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.4986  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.4077  Validation loss = 2.7608  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.4160  Validation loss = 3.3357  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 1.4150  Validation loss = 3.1874  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.3739  Validation loss = 3.1165  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.3761  Validation loss = 3.1979  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.4398  Validation loss = 3.4831  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 1.5175  Validation loss = 3.6012  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 8  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.3221  Validation loss = 3.9675  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.5586  Validation loss = 2.8265  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.4666  Validation loss = 3.3335  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.1715  Validation loss = 2.7045  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.2452  Validation loss = 2.9755  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.1838  Validation loss = 3.7962  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.1958  Validation loss = 2.8200  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.0995  Validation loss = 3.1602  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.2681  Validation loss = 3.4299  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.4735  Validation loss = 3.1147  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.4382  Validation loss = 3.4415  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.2591  Validation loss = 3.3221  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.2448  Validation loss = 3.5565  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.1761  Validation loss = 3.1135  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.1436  Validation loss = 2.8753  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.1355  Validation loss = 3.0209  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.1343  Validation loss = 3.3781  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.0874  Validation loss = 3.1656  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.1278  Validation loss = 3.3071  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.2670  Validation loss = 3.4744  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.1010  Validation loss = 3.6818  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 4  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 9\n",
      "Average validation error: 3.29051\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.2827  Test loss = 3.4004  \n",
      "\n",
      "Epoch: 2  Training loss = 1.2475  Test loss = 3.3360  \n",
      "\n",
      "Epoch: 3  Training loss = 1.2244  Test loss = 3.2948  \n",
      "\n",
      "Epoch: 4  Training loss = 1.2066  Test loss = 3.2612  \n",
      "\n",
      "Epoch: 5  Training loss = 1.1908  Test loss = 3.2326  \n",
      "\n",
      "Epoch: 6  Training loss = 1.1784  Test loss = 3.2102  \n",
      "\n",
      "Epoch: 7  Training loss = 1.1681  Test loss = 3.1902  \n",
      "\n",
      "Epoch: 8  Training loss = 1.1590  Test loss = 3.1722  \n",
      "\n",
      "Epoch: 9  Training loss = 1.1507  Test loss = 3.1559  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc5bfef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC8FhRVPN5kuOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc8dda58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.1559430003 \n",
      "Fixed scheme MAE:  2.10955837846\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.1507  Test loss = 1.4271  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.1642  Test loss = 0.9112  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.1695  Test loss = 0.1768  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.1696  Test loss = 0.1151  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 0.9781  Test loss = 0.3861  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 0.9793  Test loss = 0.6373  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 0.9743  Test loss = 1.6260  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 0.9950  Test loss = 0.0331  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.8967  Test loss = 0.8566  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.9029  Test loss = 3.2485  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 0.9886  Test loss = 2.3080  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.0289  Test loss = 2.4168  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.9179  Test loss = 0.4998  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.9199  Test loss = 2.3781  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 0.9660  Test loss = 0.6354  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 0.9689  Test loss = 3.3793  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.9781  Test loss = 0.9032  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.9844  Test loss = 0.3650  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.9855  Test loss = 1.1308  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 0.9954  Test loss = 0.7232  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.7979  Test loss = 0.4034  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.7976  Test loss = 4.1411  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 0.9483  Test loss = 1.8246  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 0.9746  Test loss = 0.0501  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.9490  Test loss = 1.4128  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.9650  Test loss = 0.3420  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.9659  Test loss = 2.2625  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.0025  Test loss = 0.0480  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.9326  Test loss = 1.3757  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.9469  Test loss = 0.7261  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.9510  Test loss = 2.7692  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.0099  Test loss = 0.2966  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.9642  Test loss = 1.5560  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.9833  Test loss = 0.5837  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.9268  Test loss = 1.8988  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.9560  Test loss = 7.1794  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.2261  Test loss = 0.4728  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.1804  Test loss = 2.8920  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2191  Test loss = 0.5115  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2207  Test loss = 2.0201  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.7813  Test loss = 2.6560  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.8472  Test loss = 1.3914  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.8638  Test loss = 2.7959  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.9283  Test loss = 14.4113  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9476  Test loss = 8.8471  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2355  Test loss = 3.8074  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2847  Test loss = 3.6748  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.3296  Test loss = 0.5481  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.9416  Test loss = 2.4490  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.9651  Test loss = 2.8585  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.9967  Test loss = 0.5777  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.9979  Test loss = 1.2225  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.9237  Test loss = 3.6063  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.9723  Test loss = 3.4258  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.0169  Test loss = 3.5015  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.0593  Test loss = 0.0464  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.8781  Test loss = 1.3301  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.8850  Test loss = 3.3480  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.9290  Test loss = 0.7092  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.9309  Test loss = 2.1171  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.9173  Test loss = 2.8608  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.9492  Test loss = 5.8046  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.0779  Test loss = 2.0607  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.0934  Test loss = 1.3616  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.8807  Test loss = 0.0894  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.8786  Test loss = 0.4764  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.8792  Test loss = 1.2785  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.8852  Test loss = 0.4898  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.8609  Test loss = 4.4707  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.9418  Test loss = 1.3570  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.9482  Test loss = 1.0620  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.9526  Test loss = 2.9560  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.8902  Test loss = 3.1804  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.9308  Test loss = 0.8313  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.9312  Test loss = 1.5114  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.9375  Test loss = 0.0094  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.6608  Test loss = 2.1023  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfBA61X9FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xead88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.92606250161 \n",
      "Updating scheme MAE:  1.97597843972\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
