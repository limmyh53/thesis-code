{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/1_cell/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 750\n",
    "learning_rate = 1e-6\n",
    "batch_size = 5\n",
    "early_stop_iters = 15\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 12 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell]*3, state_is_tuple = True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 12 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 750 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 15 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.1087  Validation loss = 3.1264  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.1087  Validation loss = 3.1263  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.1086  Validation loss = 3.1262  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.1086  Validation loss = 3.1261  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.1085  Validation loss = 3.1259  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.1085  Validation loss = 3.1258  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.1084  Validation loss = 3.1257  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.1083  Validation loss = 3.1256  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.1083  Validation loss = 3.1255  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.1082  Validation loss = 3.1254  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.1082  Validation loss = 3.1252  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.1081  Validation loss = 3.1251  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.1081  Validation loss = 3.1250  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.1080  Validation loss = 3.1249  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.1080  Validation loss = 3.1248  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.1079  Validation loss = 3.1246  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.1079  Validation loss = 3.1245  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.1078  Validation loss = 3.1244  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.1077  Validation loss = 3.1243  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.1077  Validation loss = 3.1242  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.1076  Validation loss = 3.1241  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.1076  Validation loss = 3.1240  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.1075  Validation loss = 3.1238  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.1074  Validation loss = 3.1236  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.1074  Validation loss = 3.1235  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.1073  Validation loss = 3.1234  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.1072  Validation loss = 3.1232  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.1072  Validation loss = 3.1231  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.1071  Validation loss = 3.1230  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.1070  Validation loss = 3.1229  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.1070  Validation loss = 3.1227  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.1070  Validation loss = 3.1227  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.1069  Validation loss = 3.1226  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.1069  Validation loss = 3.1224  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.1068  Validation loss = 3.1223  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.1067  Validation loss = 3.1222  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.1067  Validation loss = 3.1221  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.1066  Validation loss = 3.1220  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.1066  Validation loss = 3.1218  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.1065  Validation loss = 3.1216  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.1064  Validation loss = 3.1215  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.1063  Validation loss = 3.1213  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.1063  Validation loss = 3.1212  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.1062  Validation loss = 3.1211  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.1061  Validation loss = 3.1210  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.1061  Validation loss = 3.1208  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.1060  Validation loss = 3.1207  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.1060  Validation loss = 3.1206  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.1059  Validation loss = 3.1205  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.1058  Validation loss = 3.1204  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.1058  Validation loss = 3.1202  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.1057  Validation loss = 3.1201  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.1057  Validation loss = 3.1200  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.1056  Validation loss = 3.1198  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.1055  Validation loss = 3.1197  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.1054  Validation loss = 3.1195  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.1054  Validation loss = 3.1193  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.1053  Validation loss = 3.1192  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.1052  Validation loss = 3.1190  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.1052  Validation loss = 3.1189  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.1051  Validation loss = 3.1188  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.1051  Validation loss = 3.1187  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.1050  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.1049  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.1048  Validation loss = 3.1183  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.1048  Validation loss = 3.1181  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.1047  Validation loss = 3.1179  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.1046  Validation loss = 3.1178  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.1045  Validation loss = 3.1176  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.1045  Validation loss = 3.1175  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.1044  Validation loss = 3.1174  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.1044  Validation loss = 3.1173  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.1043  Validation loss = 3.1171  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.1042  Validation loss = 3.1170  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.1042  Validation loss = 3.1168  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.1041  Validation loss = 3.1167  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.1041  Validation loss = 3.1166  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.1040  Validation loss = 3.1165  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.1039  Validation loss = 3.1163  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.1038  Validation loss = 3.1161  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.1038  Validation loss = 3.1160  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.1037  Validation loss = 3.1159  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.1037  Validation loss = 3.1158  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.1036  Validation loss = 3.1156  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.1035  Validation loss = 3.1155  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.1035  Validation loss = 3.1153  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.1034  Validation loss = 3.1152  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.1033  Validation loss = 3.1151  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.1033  Validation loss = 3.1149  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.1032  Validation loss = 3.1148  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.1031  Validation loss = 3.1147  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.1031  Validation loss = 3.1145  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.1030  Validation loss = 3.1144  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.1029  Validation loss = 3.1143  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.1029  Validation loss = 3.1141  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.1028  Validation loss = 3.1140  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.1027  Validation loss = 3.1138  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.1027  Validation loss = 3.1137  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.1026  Validation loss = 3.1135  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.1025  Validation loss = 3.1134  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.1025  Validation loss = 3.1133  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.1024  Validation loss = 3.1131  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.1023  Validation loss = 3.1130  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.1023  Validation loss = 3.1129  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.1022  Validation loss = 3.1128  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.1022  Validation loss = 3.1127  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.1021  Validation loss = 3.1126  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.1021  Validation loss = 3.1124  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.1020  Validation loss = 3.1123  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.1019  Validation loss = 3.1122  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.1019  Validation loss = 3.1121  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.1018  Validation loss = 3.1119  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.1018  Validation loss = 3.1118  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.1017  Validation loss = 3.1116  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.1016  Validation loss = 3.1115  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.1016  Validation loss = 3.1114  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.1015  Validation loss = 3.1113  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.1015  Validation loss = 3.1111  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.1014  Validation loss = 3.1110  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.1013  Validation loss = 3.1109  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.1012  Validation loss = 3.1107  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.1012  Validation loss = 3.1106  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.1011  Validation loss = 3.1104  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.1010  Validation loss = 3.1103  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.1010  Validation loss = 3.1102  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.1009  Validation loss = 3.1101  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.1009  Validation loss = 3.1099  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.1008  Validation loss = 3.1098  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.1007  Validation loss = 3.1096  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.1007  Validation loss = 3.1095  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.1006  Validation loss = 3.1093  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.1005  Validation loss = 3.1092  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.1005  Validation loss = 3.1091  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.1005  Validation loss = 3.1090  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.1004  Validation loss = 3.1089  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.1003  Validation loss = 3.1087  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.1002  Validation loss = 3.1086  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.1002  Validation loss = 3.1085  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.1001  Validation loss = 3.1083  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.1001  Validation loss = 3.1082  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.1000  Validation loss = 3.1081  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.0999  Validation loss = 3.1080  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.0999  Validation loss = 3.1078  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.0998  Validation loss = 3.1077  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.0997  Validation loss = 3.1075  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.0997  Validation loss = 3.1074  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.0996  Validation loss = 3.1073  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.0995  Validation loss = 3.1071  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.0995  Validation loss = 3.1070  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.0994  Validation loss = 3.1069  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.0994  Validation loss = 3.1068  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.0993  Validation loss = 3.1067  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.0993  Validation loss = 3.1066  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.0992  Validation loss = 3.1065  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.0992  Validation loss = 3.1063  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.0991  Validation loss = 3.1062  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.0991  Validation loss = 3.1061  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.0990  Validation loss = 3.1060  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.0989  Validation loss = 3.1058  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.0988  Validation loss = 3.1056  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.0988  Validation loss = 3.1055  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.0987  Validation loss = 3.1053  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.0986  Validation loss = 3.1052  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.0986  Validation loss = 3.1051  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.0985  Validation loss = 3.1050  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.0985  Validation loss = 3.1048  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.0984  Validation loss = 3.1047  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.0983  Validation loss = 3.1046  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.0983  Validation loss = 3.1045  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.0982  Validation loss = 3.1044  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.0982  Validation loss = 3.1043  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.0981  Validation loss = 3.1041  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.0981  Validation loss = 3.1040  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.0980  Validation loss = 3.1039  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.0979  Validation loss = 3.1038  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.0979  Validation loss = 3.1036  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.0978  Validation loss = 3.1035  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.0978  Validation loss = 3.1034  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.0977  Validation loss = 3.1032  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.0976  Validation loss = 3.1031  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.0975  Validation loss = 3.1029  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.0975  Validation loss = 3.1028  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.0974  Validation loss = 3.1027  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.0974  Validation loss = 3.1025  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.0973  Validation loss = 3.1024  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.0972  Validation loss = 3.1022  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.0972  Validation loss = 3.1021  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.0971  Validation loss = 3.1020  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.0971  Validation loss = 3.1019  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.0970  Validation loss = 3.1018  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.0969  Validation loss = 3.1016  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.0969  Validation loss = 3.1015  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.0968  Validation loss = 3.1014  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.0968  Validation loss = 3.1012  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.0967  Validation loss = 3.1011  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.0966  Validation loss = 3.1009  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.0965  Validation loss = 3.1008  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.0965  Validation loss = 3.1007  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.0964  Validation loss = 3.1006  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.0964  Validation loss = 3.1004  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.0963  Validation loss = 3.1003  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.0963  Validation loss = 3.1002  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.0962  Validation loss = 3.1000  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.0961  Validation loss = 3.0999  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.0961  Validation loss = 3.0998  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.0960  Validation loss = 3.0997  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.0960  Validation loss = 3.0995  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.0959  Validation loss = 3.0994  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.0958  Validation loss = 3.0993  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.0958  Validation loss = 3.0992  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.0957  Validation loss = 3.0990  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.0956  Validation loss = 3.0989  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.0956  Validation loss = 3.0987  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.0955  Validation loss = 3.0986  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.0955  Validation loss = 3.0985  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.0954  Validation loss = 3.0984  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.0953  Validation loss = 3.0982  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.0953  Validation loss = 3.0981  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.0952  Validation loss = 3.0979  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.0951  Validation loss = 3.0978  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.0951  Validation loss = 3.0977  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.0950  Validation loss = 3.0976  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.0950  Validation loss = 3.0974  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.0949  Validation loss = 3.0973  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.0948  Validation loss = 3.0972  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.0948  Validation loss = 3.0970  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.0947  Validation loss = 3.0969  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.0946  Validation loss = 3.0967  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.0946  Validation loss = 3.0966  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.0945  Validation loss = 3.0965  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.0945  Validation loss = 3.0964  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.0944  Validation loss = 3.0962  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.0943  Validation loss = 3.0961  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.0942  Validation loss = 3.0959  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.0942  Validation loss = 3.0958  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.0942  Validation loss = 3.0957  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.0941  Validation loss = 3.0956  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.0940  Validation loss = 3.0955  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.0940  Validation loss = 3.0954  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.0939  Validation loss = 3.0952  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.0939  Validation loss = 3.0951  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.0938  Validation loss = 3.0950  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.0937  Validation loss = 3.0948  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.0937  Validation loss = 3.0947  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.0936  Validation loss = 3.0945  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.0935  Validation loss = 3.0944  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.0934  Validation loss = 3.0942  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.0933  Validation loss = 3.0940  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.0932  Validation loss = 3.0938  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.0932  Validation loss = 3.0936  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.0931  Validation loss = 3.0935  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.0931  Validation loss = 3.0934  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.0930  Validation loss = 3.0933  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.0929  Validation loss = 3.0931  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.0929  Validation loss = 3.0930  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.0928  Validation loss = 3.0929  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.0928  Validation loss = 3.0928  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.0927  Validation loss = 3.0927  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.0926  Validation loss = 3.0925  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.0926  Validation loss = 3.0925  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.0925  Validation loss = 3.0923  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.0925  Validation loss = 3.0922  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.0924  Validation loss = 3.0921  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.0924  Validation loss = 3.0920  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.0923  Validation loss = 3.0919  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.0923  Validation loss = 3.0918  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.0922  Validation loss = 3.0917  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.0922  Validation loss = 3.0916  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.0921  Validation loss = 3.0914  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.0921  Validation loss = 3.0913  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.0920  Validation loss = 3.0912  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.0920  Validation loss = 3.0911  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.0919  Validation loss = 3.0910  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.0919  Validation loss = 3.0909  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.0918  Validation loss = 3.0907  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.0918  Validation loss = 3.0907  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.0917  Validation loss = 3.0905  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.0916  Validation loss = 3.0904  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.0916  Validation loss = 3.0903  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.0915  Validation loss = 3.0901  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.0915  Validation loss = 3.0900  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.0914  Validation loss = 3.0899  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.0914  Validation loss = 3.0898  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.0913  Validation loss = 3.0897  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.0913  Validation loss = 3.0896  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.0912  Validation loss = 3.0894  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.0911  Validation loss = 3.0893  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.0911  Validation loss = 3.0892  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.0910  Validation loss = 3.0890  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.0909  Validation loss = 3.0889  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.0909  Validation loss = 3.0888  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.0909  Validation loss = 3.0887  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.0908  Validation loss = 3.0886  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.0907  Validation loss = 3.0885  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.0907  Validation loss = 3.0884  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.0906  Validation loss = 3.0882  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.0906  Validation loss = 3.0881  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.0905  Validation loss = 3.0880  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.0904  Validation loss = 3.0878  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.0904  Validation loss = 3.0877  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.0903  Validation loss = 3.0876  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.0902  Validation loss = 3.0874  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.0902  Validation loss = 3.0873  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.0901  Validation loss = 3.0872  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.0901  Validation loss = 3.0871  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.0900  Validation loss = 3.0870  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.0900  Validation loss = 3.0868  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.0899  Validation loss = 3.0867  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.0898  Validation loss = 3.0866  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.0898  Validation loss = 3.0864  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.0897  Validation loss = 3.0863  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.0897  Validation loss = 3.0862  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.0896  Validation loss = 3.0861  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.0896  Validation loss = 3.0859  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.0895  Validation loss = 3.0858  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.0894  Validation loss = 3.0857  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.0894  Validation loss = 3.0856  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.0893  Validation loss = 3.0855  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.0893  Validation loss = 3.0854  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.0892  Validation loss = 3.0853  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.0892  Validation loss = 3.0851  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.0891  Validation loss = 3.0850  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.0891  Validation loss = 3.0849  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.0890  Validation loss = 3.0848  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.0889  Validation loss = 3.0846  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.0889  Validation loss = 3.0845  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.0888  Validation loss = 3.0844  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.0888  Validation loss = 3.0843  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.0888  Validation loss = 3.0843  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.0887  Validation loss = 3.0842  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.0887  Validation loss = 3.0841  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.0886  Validation loss = 3.0840  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.0886  Validation loss = 3.0838  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.0885  Validation loss = 3.0837  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.0884  Validation loss = 3.0836  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.0884  Validation loss = 3.0834  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.0883  Validation loss = 3.0833  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.0883  Validation loss = 3.0832  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.0882  Validation loss = 3.0831  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.0882  Validation loss = 3.0830  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.0881  Validation loss = 3.0828  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.0881  Validation loss = 3.0827  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.0880  Validation loss = 3.0826  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.0879  Validation loss = 3.0825  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.0879  Validation loss = 3.0824  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.0878  Validation loss = 3.0822  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.0878  Validation loss = 3.0821  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.0877  Validation loss = 3.0819  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.0876  Validation loss = 3.0818  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.0876  Validation loss = 3.0817  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.0875  Validation loss = 3.0815  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.0874  Validation loss = 3.0814  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.0874  Validation loss = 3.0813  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.0873  Validation loss = 3.0812  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.0872  Validation loss = 3.0810  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.0872  Validation loss = 3.0809  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.0871  Validation loss = 3.0807  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.0871  Validation loss = 3.0806  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.0870  Validation loss = 3.0805  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.0869  Validation loss = 3.0804  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.0869  Validation loss = 3.0802  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.0868  Validation loss = 3.0801  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.0867  Validation loss = 3.0799  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.0867  Validation loss = 3.0799  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.0866  Validation loss = 3.0797  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.0866  Validation loss = 3.0796  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.0865  Validation loss = 3.0795  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.0865  Validation loss = 3.0793  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.0864  Validation loss = 3.0792  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.0863  Validation loss = 3.0790  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.0862  Validation loss = 3.0789  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.0862  Validation loss = 3.0788  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.0861  Validation loss = 3.0786  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.0861  Validation loss = 3.0785  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.0860  Validation loss = 3.0784  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.0859  Validation loss = 3.0782  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.0859  Validation loss = 3.0781  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.0858  Validation loss = 3.0779  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.0857  Validation loss = 3.0778  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.0857  Validation loss = 3.0777  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.0856  Validation loss = 3.0776  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.0856  Validation loss = 3.0774  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.0855  Validation loss = 3.0773  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.0854  Validation loss = 3.0771  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.0854  Validation loss = 3.0770  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.0853  Validation loss = 3.0769  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.0853  Validation loss = 3.0768  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.0852  Validation loss = 3.0767  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.0852  Validation loss = 3.0766  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.0851  Validation loss = 3.0764  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.0850  Validation loss = 3.0763  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.0849  Validation loss = 3.0761  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.0849  Validation loss = 3.0760  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.0848  Validation loss = 3.0758  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.0847  Validation loss = 3.0757  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.0847  Validation loss = 3.0755  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.0846  Validation loss = 3.0755  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.0846  Validation loss = 3.0753  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.0846  Validation loss = 3.0753  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.0845  Validation loss = 3.0751  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.0844  Validation loss = 3.0750  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.0844  Validation loss = 3.0749  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.0843  Validation loss = 3.0747  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.0842  Validation loss = 3.0746  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.0842  Validation loss = 3.0744  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.0841  Validation loss = 3.0743  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.0841  Validation loss = 3.0742  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.0840  Validation loss = 3.0741  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.0839  Validation loss = 3.0739  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.0839  Validation loss = 3.0738  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.0838  Validation loss = 3.0737  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.0838  Validation loss = 3.0736  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.0837  Validation loss = 3.0735  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.0837  Validation loss = 3.0733  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.0836  Validation loss = 3.0732  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.0835  Validation loss = 3.0731  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.0835  Validation loss = 3.0730  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.0834  Validation loss = 3.0728  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.0834  Validation loss = 3.0727  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.0833  Validation loss = 3.0726  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.0833  Validation loss = 3.0725  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.0832  Validation loss = 3.0723  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.0831  Validation loss = 3.0722  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.0831  Validation loss = 3.0720  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.0830  Validation loss = 3.0719  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.0829  Validation loss = 3.0717  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.0829  Validation loss = 3.0717  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.0828  Validation loss = 3.0715  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.0828  Validation loss = 3.0714  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.0827  Validation loss = 3.0713  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.0826  Validation loss = 3.0711  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.0826  Validation loss = 3.0710  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.0825  Validation loss = 3.0709  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.0825  Validation loss = 3.0708  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.0824  Validation loss = 3.0707  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.0824  Validation loss = 3.0706  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.0823  Validation loss = 3.0705  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.0823  Validation loss = 3.0703  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.0822  Validation loss = 3.0701  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.0821  Validation loss = 3.0700  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.0820  Validation loss = 3.0698  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.0820  Validation loss = 3.0697  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.0819  Validation loss = 3.0696  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.0819  Validation loss = 3.0695  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.0818  Validation loss = 3.0693  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.0817  Validation loss = 3.0692  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.0817  Validation loss = 3.0691  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.0816  Validation loss = 3.0690  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.0816  Validation loss = 3.0689  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.0815  Validation loss = 3.0688  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.0815  Validation loss = 3.0687  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.0814  Validation loss = 3.0686  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.0814  Validation loss = 3.0685  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.0813  Validation loss = 3.0683  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.0813  Validation loss = 3.0682  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.0812  Validation loss = 3.0681  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.0812  Validation loss = 3.0680  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.0811  Validation loss = 3.0679  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.0810  Validation loss = 3.0677  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.0810  Validation loss = 3.0676  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.0809  Validation loss = 3.0675  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.0809  Validation loss = 3.0673  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.0808  Validation loss = 3.0672  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.0807  Validation loss = 3.0670  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.0806  Validation loss = 3.0669  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.0806  Validation loss = 3.0667  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.0805  Validation loss = 3.0666  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.0805  Validation loss = 3.0665  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.0804  Validation loss = 3.0663  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.0803  Validation loss = 3.0662  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.0803  Validation loss = 3.0661  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.0802  Validation loss = 3.0660  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.0802  Validation loss = 3.0659  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.0801  Validation loss = 3.0658  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.0801  Validation loss = 3.0656  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.0800  Validation loss = 3.0655  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.0799  Validation loss = 3.0654  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.0799  Validation loss = 3.0652  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.0798  Validation loss = 3.0651  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.0798  Validation loss = 3.0650  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.0797  Validation loss = 3.0649  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.0797  Validation loss = 3.0648  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.0796  Validation loss = 3.0647  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.0796  Validation loss = 3.0645  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.0795  Validation loss = 3.0644  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.0794  Validation loss = 3.0643  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.0794  Validation loss = 3.0641  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.0793  Validation loss = 3.0640  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.0792  Validation loss = 3.0639  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.0792  Validation loss = 3.0638  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.0792  Validation loss = 3.0637  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.0791  Validation loss = 3.0635  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.0790  Validation loss = 3.0634  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.0790  Validation loss = 3.0633  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.0789  Validation loss = 3.0632  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.0789  Validation loss = 3.0631  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.0788  Validation loss = 3.0629  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.0787  Validation loss = 3.0628  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.0787  Validation loss = 3.0627  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.0786  Validation loss = 3.0625  \n",
      "\n",
      "Fold: 1  Epoch: 501  Training loss = 3.0786  Validation loss = 3.0624  \n",
      "\n",
      "Fold: 1  Epoch: 502  Training loss = 3.0785  Validation loss = 3.0623  \n",
      "\n",
      "Fold: 1  Epoch: 503  Training loss = 3.0784  Validation loss = 3.0621  \n",
      "\n",
      "Fold: 1  Epoch: 504  Training loss = 3.0784  Validation loss = 3.0620  \n",
      "\n",
      "Fold: 1  Epoch: 505  Training loss = 3.0784  Validation loss = 3.0619  \n",
      "\n",
      "Fold: 1  Epoch: 506  Training loss = 3.0783  Validation loss = 3.0618  \n",
      "\n",
      "Fold: 1  Epoch: 507  Training loss = 3.0783  Validation loss = 3.0617  \n",
      "\n",
      "Fold: 1  Epoch: 508  Training loss = 3.0782  Validation loss = 3.0616  \n",
      "\n",
      "Fold: 1  Epoch: 509  Training loss = 3.0781  Validation loss = 3.0615  \n",
      "\n",
      "Fold: 1  Epoch: 510  Training loss = 3.0781  Validation loss = 3.0614  \n",
      "\n",
      "Fold: 1  Epoch: 511  Training loss = 3.0780  Validation loss = 3.0612  \n",
      "\n",
      "Fold: 1  Epoch: 512  Training loss = 3.0780  Validation loss = 3.0611  \n",
      "\n",
      "Fold: 1  Epoch: 513  Training loss = 3.0779  Validation loss = 3.0610  \n",
      "\n",
      "Fold: 1  Epoch: 514  Training loss = 3.0778  Validation loss = 3.0608  \n",
      "\n",
      "Fold: 1  Epoch: 515  Training loss = 3.0778  Validation loss = 3.0607  \n",
      "\n",
      "Fold: 1  Epoch: 516  Training loss = 3.0777  Validation loss = 3.0605  \n",
      "\n",
      "Fold: 1  Epoch: 517  Training loss = 3.0776  Validation loss = 3.0604  \n",
      "\n",
      "Fold: 1  Epoch: 518  Training loss = 3.0776  Validation loss = 3.0603  \n",
      "\n",
      "Fold: 1  Epoch: 519  Training loss = 3.0775  Validation loss = 3.0602  \n",
      "\n",
      "Fold: 1  Epoch: 520  Training loss = 3.0775  Validation loss = 3.0600  \n",
      "\n",
      "Fold: 1  Epoch: 521  Training loss = 3.0774  Validation loss = 3.0599  \n",
      "\n",
      "Fold: 1  Epoch: 522  Training loss = 3.0773  Validation loss = 3.0597  \n",
      "\n",
      "Fold: 1  Epoch: 523  Training loss = 3.0773  Validation loss = 3.0596  \n",
      "\n",
      "Fold: 1  Epoch: 524  Training loss = 3.0772  Validation loss = 3.0594  \n",
      "\n",
      "Fold: 1  Epoch: 525  Training loss = 3.0772  Validation loss = 3.0594  \n",
      "\n",
      "Fold: 1  Epoch: 526  Training loss = 3.0771  Validation loss = 3.0592  \n",
      "\n",
      "Fold: 1  Epoch: 527  Training loss = 3.0770  Validation loss = 3.0591  \n",
      "\n",
      "Fold: 1  Epoch: 528  Training loss = 3.0770  Validation loss = 3.0590  \n",
      "\n",
      "Fold: 1  Epoch: 529  Training loss = 3.0769  Validation loss = 3.0589  \n",
      "\n",
      "Fold: 1  Epoch: 530  Training loss = 3.0769  Validation loss = 3.0587  \n",
      "\n",
      "Fold: 1  Epoch: 531  Training loss = 3.0768  Validation loss = 3.0586  \n",
      "\n",
      "Fold: 1  Epoch: 532  Training loss = 3.0767  Validation loss = 3.0584  \n",
      "\n",
      "Fold: 1  Epoch: 533  Training loss = 3.0767  Validation loss = 3.0583  \n",
      "\n",
      "Fold: 1  Epoch: 534  Training loss = 3.0766  Validation loss = 3.0581  \n",
      "\n",
      "Fold: 1  Epoch: 535  Training loss = 3.0765  Validation loss = 3.0580  \n",
      "\n",
      "Fold: 1  Epoch: 536  Training loss = 3.0765  Validation loss = 3.0578  \n",
      "\n",
      "Fold: 1  Epoch: 537  Training loss = 3.0764  Validation loss = 3.0577  \n",
      "\n",
      "Fold: 1  Epoch: 538  Training loss = 3.0764  Validation loss = 3.0576  \n",
      "\n",
      "Fold: 1  Epoch: 539  Training loss = 3.0763  Validation loss = 3.0575  \n",
      "\n",
      "Fold: 1  Epoch: 540  Training loss = 3.0762  Validation loss = 3.0574  \n",
      "\n",
      "Fold: 1  Epoch: 541  Training loss = 3.0762  Validation loss = 3.0572  \n",
      "\n",
      "Fold: 1  Epoch: 542  Training loss = 3.0761  Validation loss = 3.0571  \n",
      "\n",
      "Fold: 1  Epoch: 543  Training loss = 3.0761  Validation loss = 3.0570  \n",
      "\n",
      "Fold: 1  Epoch: 544  Training loss = 3.0760  Validation loss = 3.0568  \n",
      "\n",
      "Fold: 1  Epoch: 545  Training loss = 3.0759  Validation loss = 3.0567  \n",
      "\n",
      "Fold: 1  Epoch: 546  Training loss = 3.0759  Validation loss = 3.0566  \n",
      "\n",
      "Fold: 1  Epoch: 547  Training loss = 3.0758  Validation loss = 3.0565  \n",
      "\n",
      "Fold: 1  Epoch: 548  Training loss = 3.0757  Validation loss = 3.0563  \n",
      "\n",
      "Fold: 1  Epoch: 549  Training loss = 3.0757  Validation loss = 3.0562  \n",
      "\n",
      "Fold: 1  Epoch: 550  Training loss = 3.0756  Validation loss = 3.0561  \n",
      "\n",
      "Fold: 1  Epoch: 551  Training loss = 3.0756  Validation loss = 3.0559  \n",
      "\n",
      "Fold: 1  Epoch: 552  Training loss = 3.0755  Validation loss = 3.0558  \n",
      "\n",
      "Fold: 1  Epoch: 553  Training loss = 3.0754  Validation loss = 3.0557  \n",
      "\n",
      "Fold: 1  Epoch: 554  Training loss = 3.0754  Validation loss = 3.0555  \n",
      "\n",
      "Fold: 1  Epoch: 555  Training loss = 3.0753  Validation loss = 3.0554  \n",
      "\n",
      "Fold: 1  Epoch: 556  Training loss = 3.0753  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 1  Epoch: 557  Training loss = 3.0752  Validation loss = 3.0552  \n",
      "\n",
      "Fold: 1  Epoch: 558  Training loss = 3.0752  Validation loss = 3.0550  \n",
      "\n",
      "Fold: 1  Epoch: 559  Training loss = 3.0751  Validation loss = 3.0549  \n",
      "\n",
      "Fold: 1  Epoch: 560  Training loss = 3.0750  Validation loss = 3.0548  \n",
      "\n",
      "Fold: 1  Epoch: 561  Training loss = 3.0750  Validation loss = 3.0546  \n",
      "\n",
      "Fold: 1  Epoch: 562  Training loss = 3.0749  Validation loss = 3.0545  \n",
      "\n",
      "Fold: 1  Epoch: 563  Training loss = 3.0749  Validation loss = 3.0544  \n",
      "\n",
      "Fold: 1  Epoch: 564  Training loss = 3.0748  Validation loss = 3.0543  \n",
      "\n",
      "Fold: 1  Epoch: 565  Training loss = 3.0748  Validation loss = 3.0542  \n",
      "\n",
      "Fold: 1  Epoch: 566  Training loss = 3.0747  Validation loss = 3.0541  \n",
      "\n",
      "Fold: 1  Epoch: 567  Training loss = 3.0747  Validation loss = 3.0540  \n",
      "\n",
      "Fold: 1  Epoch: 568  Training loss = 3.0746  Validation loss = 3.0539  \n",
      "\n",
      "Fold: 1  Epoch: 569  Training loss = 3.0746  Validation loss = 3.0538  \n",
      "\n",
      "Fold: 1  Epoch: 570  Training loss = 3.0745  Validation loss = 3.0537  \n",
      "\n",
      "Fold: 1  Epoch: 571  Training loss = 3.0745  Validation loss = 3.0535  \n",
      "\n",
      "Fold: 1  Epoch: 572  Training loss = 3.0744  Validation loss = 3.0535  \n",
      "\n",
      "Fold: 1  Epoch: 573  Training loss = 3.0744  Validation loss = 3.0534  \n",
      "\n",
      "Fold: 1  Epoch: 574  Training loss = 3.0743  Validation loss = 3.0532  \n",
      "\n",
      "Fold: 1  Epoch: 575  Training loss = 3.0742  Validation loss = 3.0531  \n",
      "\n",
      "Fold: 1  Epoch: 576  Training loss = 3.0742  Validation loss = 3.0529  \n",
      "\n",
      "Fold: 1  Epoch: 577  Training loss = 3.0741  Validation loss = 3.0528  \n",
      "\n",
      "Fold: 1  Epoch: 578  Training loss = 3.0741  Validation loss = 3.0527  \n",
      "\n",
      "Fold: 1  Epoch: 579  Training loss = 3.0740  Validation loss = 3.0526  \n",
      "\n",
      "Fold: 1  Epoch: 580  Training loss = 3.0740  Validation loss = 3.0525  \n",
      "\n",
      "Fold: 1  Epoch: 581  Training loss = 3.0739  Validation loss = 3.0523  \n",
      "\n",
      "Fold: 1  Epoch: 582  Training loss = 3.0738  Validation loss = 3.0522  \n",
      "\n",
      "Fold: 1  Epoch: 583  Training loss = 3.0738  Validation loss = 3.0521  \n",
      "\n",
      "Fold: 1  Epoch: 584  Training loss = 3.0737  Validation loss = 3.0520  \n",
      "\n",
      "Fold: 1  Epoch: 585  Training loss = 3.0737  Validation loss = 3.0518  \n",
      "\n",
      "Fold: 1  Epoch: 586  Training loss = 3.0736  Validation loss = 3.0517  \n",
      "\n",
      "Fold: 1  Epoch: 587  Training loss = 3.0736  Validation loss = 3.0516  \n",
      "\n",
      "Fold: 1  Epoch: 588  Training loss = 3.0736  Validation loss = 3.0516  \n",
      "\n",
      "Fold: 1  Epoch: 589  Training loss = 3.0735  Validation loss = 3.0514  \n",
      "\n",
      "Fold: 1  Epoch: 590  Training loss = 3.0734  Validation loss = 3.0513  \n",
      "\n",
      "Fold: 1  Epoch: 591  Training loss = 3.0734  Validation loss = 3.0512  \n",
      "\n",
      "Fold: 1  Epoch: 592  Training loss = 3.0733  Validation loss = 3.0510  \n",
      "\n",
      "Fold: 1  Epoch: 593  Training loss = 3.0733  Validation loss = 3.0510  \n",
      "\n",
      "Fold: 1  Epoch: 594  Training loss = 3.0732  Validation loss = 3.0508  \n",
      "\n",
      "Fold: 1  Epoch: 595  Training loss = 3.0731  Validation loss = 3.0507  \n",
      "\n",
      "Fold: 1  Epoch: 596  Training loss = 3.0731  Validation loss = 3.0505  \n",
      "\n",
      "Fold: 1  Epoch: 597  Training loss = 3.0730  Validation loss = 3.0504  \n",
      "\n",
      "Fold: 1  Epoch: 598  Training loss = 3.0730  Validation loss = 3.0503  \n",
      "\n",
      "Fold: 1  Epoch: 599  Training loss = 3.0729  Validation loss = 3.0502  \n",
      "\n",
      "Fold: 1  Epoch: 600  Training loss = 3.0729  Validation loss = 3.0501  \n",
      "\n",
      "Fold: 1  Epoch: 601  Training loss = 3.0728  Validation loss = 3.0500  \n",
      "\n",
      "Fold: 1  Epoch: 602  Training loss = 3.0728  Validation loss = 3.0499  \n",
      "\n",
      "Fold: 1  Epoch: 603  Training loss = 3.0727  Validation loss = 3.0497  \n",
      "\n",
      "Fold: 1  Epoch: 604  Training loss = 3.0727  Validation loss = 3.0496  \n",
      "\n",
      "Fold: 1  Epoch: 605  Training loss = 3.0726  Validation loss = 3.0495  \n",
      "\n",
      "Fold: 1  Epoch: 606  Training loss = 3.0725  Validation loss = 3.0494  \n",
      "\n",
      "Fold: 1  Epoch: 607  Training loss = 3.0725  Validation loss = 3.0492  \n",
      "\n",
      "Fold: 1  Epoch: 608  Training loss = 3.0724  Validation loss = 3.0491  \n",
      "\n",
      "Fold: 1  Epoch: 609  Training loss = 3.0724  Validation loss = 3.0490  \n",
      "\n",
      "Fold: 1  Epoch: 610  Training loss = 3.0723  Validation loss = 3.0489  \n",
      "\n",
      "Fold: 1  Epoch: 611  Training loss = 3.0723  Validation loss = 3.0488  \n",
      "\n",
      "Fold: 1  Epoch: 612  Training loss = 3.0722  Validation loss = 3.0487  \n",
      "\n",
      "Fold: 1  Epoch: 613  Training loss = 3.0722  Validation loss = 3.0486  \n",
      "\n",
      "Fold: 1  Epoch: 614  Training loss = 3.0721  Validation loss = 3.0484  \n",
      "\n",
      "Fold: 1  Epoch: 615  Training loss = 3.0720  Validation loss = 3.0483  \n",
      "\n",
      "Fold: 1  Epoch: 616  Training loss = 3.0720  Validation loss = 3.0481  \n",
      "\n",
      "Fold: 1  Epoch: 617  Training loss = 3.0719  Validation loss = 3.0480  \n",
      "\n",
      "Fold: 1  Epoch: 618  Training loss = 3.0719  Validation loss = 3.0479  \n",
      "\n",
      "Fold: 1  Epoch: 619  Training loss = 3.0718  Validation loss = 3.0478  \n",
      "\n",
      "Fold: 1  Epoch: 620  Training loss = 3.0718  Validation loss = 3.0477  \n",
      "\n",
      "Fold: 1  Epoch: 621  Training loss = 3.0717  Validation loss = 3.0475  \n",
      "\n",
      "Fold: 1  Epoch: 622  Training loss = 3.0716  Validation loss = 3.0474  \n",
      "\n",
      "Fold: 1  Epoch: 623  Training loss = 3.0716  Validation loss = 3.0473  \n",
      "\n",
      "Fold: 1  Epoch: 624  Training loss = 3.0715  Validation loss = 3.0472  \n",
      "\n",
      "Fold: 1  Epoch: 625  Training loss = 3.0715  Validation loss = 3.0471  \n",
      "\n",
      "Fold: 1  Epoch: 626  Training loss = 3.0714  Validation loss = 3.0469  \n",
      "\n",
      "Fold: 1  Epoch: 627  Training loss = 3.0713  Validation loss = 3.0468  \n",
      "\n",
      "Fold: 1  Epoch: 628  Training loss = 3.0713  Validation loss = 3.0466  \n",
      "\n",
      "Fold: 1  Epoch: 629  Training loss = 3.0712  Validation loss = 3.0465  \n",
      "\n",
      "Fold: 1  Epoch: 630  Training loss = 3.0712  Validation loss = 3.0464  \n",
      "\n",
      "Fold: 1  Epoch: 631  Training loss = 3.0711  Validation loss = 3.0462  \n",
      "\n",
      "Fold: 1  Epoch: 632  Training loss = 3.0710  Validation loss = 3.0461  \n",
      "\n",
      "Fold: 1  Epoch: 633  Training loss = 3.0710  Validation loss = 3.0459  \n",
      "\n",
      "Fold: 1  Epoch: 634  Training loss = 3.0709  Validation loss = 3.0458  \n",
      "\n",
      "Fold: 1  Epoch: 635  Training loss = 3.0709  Validation loss = 3.0457  \n",
      "\n",
      "Fold: 1  Epoch: 636  Training loss = 3.0708  Validation loss = 3.0456  \n",
      "\n",
      "Fold: 1  Epoch: 637  Training loss = 3.0708  Validation loss = 3.0455  \n",
      "\n",
      "Fold: 1  Epoch: 638  Training loss = 3.0707  Validation loss = 3.0454  \n",
      "\n",
      "Fold: 1  Epoch: 639  Training loss = 3.0707  Validation loss = 3.0453  \n",
      "\n",
      "Fold: 1  Epoch: 640  Training loss = 3.0706  Validation loss = 3.0452  \n",
      "\n",
      "Fold: 1  Epoch: 641  Training loss = 3.0705  Validation loss = 3.0450  \n",
      "\n",
      "Fold: 1  Epoch: 642  Training loss = 3.0705  Validation loss = 3.0449  \n",
      "\n",
      "Fold: 1  Epoch: 643  Training loss = 3.0704  Validation loss = 3.0447  \n",
      "\n",
      "Fold: 1  Epoch: 644  Training loss = 3.0704  Validation loss = 3.0446  \n",
      "\n",
      "Fold: 1  Epoch: 645  Training loss = 3.0703  Validation loss = 3.0445  \n",
      "\n",
      "Fold: 1  Epoch: 646  Training loss = 3.0702  Validation loss = 3.0444  \n",
      "\n",
      "Fold: 1  Epoch: 647  Training loss = 3.0702  Validation loss = 3.0443  \n",
      "\n",
      "Fold: 1  Epoch: 648  Training loss = 3.0701  Validation loss = 3.0442  \n",
      "\n",
      "Fold: 1  Epoch: 649  Training loss = 3.0701  Validation loss = 3.0440  \n",
      "\n",
      "Fold: 1  Epoch: 650  Training loss = 3.0700  Validation loss = 3.0439  \n",
      "\n",
      "Fold: 1  Epoch: 651  Training loss = 3.0700  Validation loss = 3.0438  \n",
      "\n",
      "Fold: 1  Epoch: 652  Training loss = 3.0699  Validation loss = 3.0436  \n",
      "\n",
      "Fold: 1  Epoch: 653  Training loss = 3.0698  Validation loss = 3.0435  \n",
      "\n",
      "Fold: 1  Epoch: 654  Training loss = 3.0698  Validation loss = 3.0434  \n",
      "\n",
      "Fold: 1  Epoch: 655  Training loss = 3.0697  Validation loss = 3.0433  \n",
      "\n",
      "Fold: 1  Epoch: 656  Training loss = 3.0697  Validation loss = 3.0431  \n",
      "\n",
      "Fold: 1  Epoch: 657  Training loss = 3.0696  Validation loss = 3.0430  \n",
      "\n",
      "Fold: 1  Epoch: 658  Training loss = 3.0696  Validation loss = 3.0429  \n",
      "\n",
      "Fold: 1  Epoch: 659  Training loss = 3.0695  Validation loss = 3.0428  \n",
      "\n",
      "Fold: 1  Epoch: 660  Training loss = 3.0695  Validation loss = 3.0427  \n",
      "\n",
      "Fold: 1  Epoch: 661  Training loss = 3.0694  Validation loss = 3.0425  \n",
      "\n",
      "Fold: 1  Epoch: 662  Training loss = 3.0693  Validation loss = 3.0424  \n",
      "\n",
      "Fold: 1  Epoch: 663  Training loss = 3.0693  Validation loss = 3.0422  \n",
      "\n",
      "Fold: 1  Epoch: 664  Training loss = 3.0692  Validation loss = 3.0421  \n",
      "\n",
      "Fold: 1  Epoch: 665  Training loss = 3.0691  Validation loss = 3.0419  \n",
      "\n",
      "Fold: 1  Epoch: 666  Training loss = 3.0691  Validation loss = 3.0418  \n",
      "\n",
      "Fold: 1  Epoch: 667  Training loss = 3.0690  Validation loss = 3.0417  \n",
      "\n",
      "Fold: 1  Epoch: 668  Training loss = 3.0690  Validation loss = 3.0416  \n",
      "\n",
      "Fold: 1  Epoch: 669  Training loss = 3.0689  Validation loss = 3.0415  \n",
      "\n",
      "Fold: 1  Epoch: 670  Training loss = 3.0688  Validation loss = 3.0413  \n",
      "\n",
      "Fold: 1  Epoch: 671  Training loss = 3.0688  Validation loss = 3.0412  \n",
      "\n",
      "Fold: 1  Epoch: 672  Training loss = 3.0687  Validation loss = 3.0411  \n",
      "\n",
      "Fold: 1  Epoch: 673  Training loss = 3.0687  Validation loss = 3.0410  \n",
      "\n",
      "Fold: 1  Epoch: 674  Training loss = 3.0686  Validation loss = 3.0409  \n",
      "\n",
      "Fold: 1  Epoch: 675  Training loss = 3.0686  Validation loss = 3.0408  \n",
      "\n",
      "Fold: 1  Epoch: 676  Training loss = 3.0685  Validation loss = 3.0406  \n",
      "\n",
      "Fold: 1  Epoch: 677  Training loss = 3.0685  Validation loss = 3.0405  \n",
      "\n",
      "Fold: 1  Epoch: 678  Training loss = 3.0684  Validation loss = 3.0404  \n",
      "\n",
      "Fold: 1  Epoch: 679  Training loss = 3.0684  Validation loss = 3.0403  \n",
      "\n",
      "Fold: 1  Epoch: 680  Training loss = 3.0683  Validation loss = 3.0402  \n",
      "\n",
      "Fold: 1  Epoch: 681  Training loss = 3.0683  Validation loss = 3.0401  \n",
      "\n",
      "Fold: 1  Epoch: 682  Training loss = 3.0682  Validation loss = 3.0399  \n",
      "\n",
      "Fold: 1  Epoch: 683  Training loss = 3.0681  Validation loss = 3.0397  \n",
      "\n",
      "Fold: 1  Epoch: 684  Training loss = 3.0681  Validation loss = 3.0396  \n",
      "\n",
      "Fold: 1  Epoch: 685  Training loss = 3.0680  Validation loss = 3.0395  \n",
      "\n",
      "Fold: 1  Epoch: 686  Training loss = 3.0680  Validation loss = 3.0394  \n",
      "\n",
      "Fold: 1  Epoch: 687  Training loss = 3.0679  Validation loss = 3.0392  \n",
      "\n",
      "Fold: 1  Epoch: 688  Training loss = 3.0678  Validation loss = 3.0391  \n",
      "\n",
      "Fold: 1  Epoch: 689  Training loss = 3.0678  Validation loss = 3.0390  \n",
      "\n",
      "Fold: 1  Epoch: 690  Training loss = 3.0677  Validation loss = 3.0389  \n",
      "\n",
      "Fold: 1  Epoch: 691  Training loss = 3.0676  Validation loss = 3.0387  \n",
      "\n",
      "Fold: 1  Epoch: 692  Training loss = 3.0676  Validation loss = 3.0387  \n",
      "\n",
      "Fold: 1  Epoch: 693  Training loss = 3.0675  Validation loss = 3.0385  \n",
      "\n",
      "Fold: 1  Epoch: 694  Training loss = 3.0675  Validation loss = 3.0384  \n",
      "\n",
      "Fold: 1  Epoch: 695  Training loss = 3.0674  Validation loss = 3.0383  \n",
      "\n",
      "Fold: 1  Epoch: 696  Training loss = 3.0674  Validation loss = 3.0381  \n",
      "\n",
      "Fold: 1  Epoch: 697  Training loss = 3.0673  Validation loss = 3.0380  \n",
      "\n",
      "Fold: 1  Epoch: 698  Training loss = 3.0673  Validation loss = 3.0379  \n",
      "\n",
      "Fold: 1  Epoch: 699  Training loss = 3.0672  Validation loss = 3.0378  \n",
      "\n",
      "Fold: 1  Epoch: 700  Training loss = 3.0671  Validation loss = 3.0377  \n",
      "\n",
      "Fold: 1  Epoch: 701  Training loss = 3.0671  Validation loss = 3.0375  \n",
      "\n",
      "Fold: 1  Epoch: 702  Training loss = 3.0670  Validation loss = 3.0374  \n",
      "\n",
      "Fold: 1  Epoch: 703  Training loss = 3.0670  Validation loss = 3.0373  \n",
      "\n",
      "Fold: 1  Epoch: 704  Training loss = 3.0669  Validation loss = 3.0372  \n",
      "\n",
      "Fold: 1  Epoch: 705  Training loss = 3.0669  Validation loss = 3.0371  \n",
      "\n",
      "Fold: 1  Epoch: 706  Training loss = 3.0668  Validation loss = 3.0370  \n",
      "\n",
      "Fold: 1  Epoch: 707  Training loss = 3.0668  Validation loss = 3.0368  \n",
      "\n",
      "Fold: 1  Epoch: 708  Training loss = 3.0667  Validation loss = 3.0367  \n",
      "\n",
      "Fold: 1  Epoch: 709  Training loss = 3.0666  Validation loss = 3.0365  \n",
      "\n",
      "Fold: 1  Epoch: 710  Training loss = 3.0666  Validation loss = 3.0364  \n",
      "\n",
      "Fold: 1  Epoch: 711  Training loss = 3.0665  Validation loss = 3.0362  \n",
      "\n",
      "Fold: 1  Epoch: 712  Training loss = 3.0664  Validation loss = 3.0361  \n",
      "\n",
      "Fold: 1  Epoch: 713  Training loss = 3.0664  Validation loss = 3.0360  \n",
      "\n",
      "Fold: 1  Epoch: 714  Training loss = 3.0663  Validation loss = 3.0358  \n",
      "\n",
      "Fold: 1  Epoch: 715  Training loss = 3.0663  Validation loss = 3.0357  \n",
      "\n",
      "Fold: 1  Epoch: 716  Training loss = 3.0662  Validation loss = 3.0356  \n",
      "\n",
      "Fold: 1  Epoch: 717  Training loss = 3.0661  Validation loss = 3.0355  \n",
      "\n",
      "Fold: 1  Epoch: 718  Training loss = 3.0661  Validation loss = 3.0353  \n",
      "\n",
      "Fold: 1  Epoch: 719  Training loss = 3.0660  Validation loss = 3.0352  \n",
      "\n",
      "Fold: 1  Epoch: 720  Training loss = 3.0660  Validation loss = 3.0351  \n",
      "\n",
      "Fold: 1  Epoch: 721  Training loss = 3.0659  Validation loss = 3.0350  \n",
      "\n",
      "Fold: 1  Epoch: 722  Training loss = 3.0659  Validation loss = 3.0349  \n",
      "\n",
      "Fold: 1  Epoch: 723  Training loss = 3.0658  Validation loss = 3.0348  \n",
      "\n",
      "Fold: 1  Epoch: 724  Training loss = 3.0658  Validation loss = 3.0346  \n",
      "\n",
      "Fold: 1  Epoch: 725  Training loss = 3.0657  Validation loss = 3.0345  \n",
      "\n",
      "Fold: 1  Epoch: 726  Training loss = 3.0657  Validation loss = 3.0344  \n",
      "\n",
      "Fold: 1  Epoch: 727  Training loss = 3.0656  Validation loss = 3.0342  \n",
      "\n",
      "Fold: 1  Epoch: 728  Training loss = 3.0655  Validation loss = 3.0341  \n",
      "\n",
      "Fold: 1  Epoch: 729  Training loss = 3.0655  Validation loss = 3.0340  \n",
      "\n",
      "Fold: 1  Epoch: 730  Training loss = 3.0654  Validation loss = 3.0338  \n",
      "\n",
      "Fold: 1  Epoch: 731  Training loss = 3.0654  Validation loss = 3.0338  \n",
      "\n",
      "Fold: 1  Epoch: 732  Training loss = 3.0653  Validation loss = 3.0337  \n",
      "\n",
      "Fold: 1  Epoch: 733  Training loss = 3.0653  Validation loss = 3.0336  \n",
      "\n",
      "Fold: 1  Epoch: 734  Training loss = 3.0652  Validation loss = 3.0335  \n",
      "\n",
      "Fold: 1  Epoch: 735  Training loss = 3.0652  Validation loss = 3.0333  \n",
      "\n",
      "Fold: 1  Epoch: 736  Training loss = 3.0651  Validation loss = 3.0332  \n",
      "\n",
      "Fold: 1  Epoch: 737  Training loss = 3.0651  Validation loss = 3.0331  \n",
      "\n",
      "Fold: 1  Epoch: 738  Training loss = 3.0650  Validation loss = 3.0330  \n",
      "\n",
      "Fold: 1  Epoch: 739  Training loss = 3.0650  Validation loss = 3.0329  \n",
      "\n",
      "Fold: 1  Epoch: 740  Training loss = 3.0649  Validation loss = 3.0327  \n",
      "\n",
      "Fold: 1  Epoch: 741  Training loss = 3.0648  Validation loss = 3.0326  \n",
      "\n",
      "Fold: 1  Epoch: 742  Training loss = 3.0648  Validation loss = 3.0325  \n",
      "\n",
      "Fold: 1  Epoch: 743  Training loss = 3.0647  Validation loss = 3.0324  \n",
      "\n",
      "Fold: 1  Epoch: 744  Training loss = 3.0647  Validation loss = 3.0322  \n",
      "\n",
      "Fold: 1  Epoch: 745  Training loss = 3.0646  Validation loss = 3.0321  \n",
      "\n",
      "Fold: 1  Epoch: 746  Training loss = 3.0646  Validation loss = 3.0320  \n",
      "\n",
      "Fold: 1  Epoch: 747  Training loss = 3.0645  Validation loss = 3.0318  \n",
      "\n",
      "Fold: 1  Epoch: 748  Training loss = 3.0644  Validation loss = 3.0317  \n",
      "\n",
      "Fold: 1  Epoch: 749  Training loss = 3.0644  Validation loss = 3.0316  \n",
      "\n",
      "Fold: 1  Epoch: 750  Training loss = 3.0643  Validation loss = 3.0315  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 750  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.9995  Validation loss = 3.2091  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.9994  Validation loss = 3.2090  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.9994  Validation loss = 3.2088  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.9993  Validation loss = 3.2087  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.9992  Validation loss = 3.2087  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.9992  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.9991  Validation loss = 3.2085  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.9991  Validation loss = 3.2084  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.9990  Validation loss = 3.2083  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.9989  Validation loss = 3.2082  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.9989  Validation loss = 3.2081  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.9988  Validation loss = 3.2080  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.9988  Validation loss = 3.2079  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.9987  Validation loss = 3.2078  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.9986  Validation loss = 3.2078  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.9986  Validation loss = 3.2077  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.9985  Validation loss = 3.2076  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.9985  Validation loss = 3.2075  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.9984  Validation loss = 3.2074  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.9983  Validation loss = 3.2073  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.9983  Validation loss = 3.2072  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.9982  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.9981  Validation loss = 3.2069  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.9980  Validation loss = 3.2068  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.9980  Validation loss = 3.2067  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.9979  Validation loss = 3.2066  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.9979  Validation loss = 3.2066  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.9978  Validation loss = 3.2065  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.9978  Validation loss = 3.2064  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.9977  Validation loss = 3.2063  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.9976  Validation loss = 3.2062  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.9976  Validation loss = 3.2061  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.9975  Validation loss = 3.2060  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.9975  Validation loss = 3.2060  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.9974  Validation loss = 3.2059  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.9973  Validation loss = 3.2057  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.9973  Validation loss = 3.2056  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.9972  Validation loss = 3.2055  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.9971  Validation loss = 3.2054  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.9971  Validation loss = 3.2054  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.9970  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.9969  Validation loss = 3.2051  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.9969  Validation loss = 3.2051  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.9968  Validation loss = 3.2049  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.9968  Validation loss = 3.2049  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.9967  Validation loss = 3.2048  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.9967  Validation loss = 3.2047  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.9966  Validation loss = 3.2046  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.9966  Validation loss = 3.2045  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.9965  Validation loss = 3.2045  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.9965  Validation loss = 3.2044  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.9964  Validation loss = 3.2043  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.9964  Validation loss = 3.2042  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.9963  Validation loss = 3.2041  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.9962  Validation loss = 3.2041  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.9962  Validation loss = 3.2040  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.9961  Validation loss = 3.2039  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.9961  Validation loss = 3.2038  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.9960  Validation loss = 3.2037  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.9960  Validation loss = 3.2036  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.9959  Validation loss = 3.2036  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.9958  Validation loss = 3.2034  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.9958  Validation loss = 3.2033  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.9957  Validation loss = 3.2033  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.9957  Validation loss = 3.2032  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.9956  Validation loss = 3.2031  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.9956  Validation loss = 3.2030  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.9955  Validation loss = 3.2029  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.9954  Validation loss = 3.2028  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.9954  Validation loss = 3.2027  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.9953  Validation loss = 3.2026  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.9952  Validation loss = 3.2025  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.9952  Validation loss = 3.2024  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.9951  Validation loss = 3.2023  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.9950  Validation loss = 3.2022  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.9950  Validation loss = 3.2021  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.9949  Validation loss = 3.2020  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.9949  Validation loss = 3.2019  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.9948  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.9948  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.9947  Validation loss = 3.2016  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.9946  Validation loss = 3.2016  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.9946  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.9945  Validation loss = 3.2014  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.9945  Validation loss = 3.2013  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.9944  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.9943  Validation loss = 3.2011  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.9943  Validation loss = 3.2010  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.9942  Validation loss = 3.2009  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.9942  Validation loss = 3.2008  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.9941  Validation loss = 3.2007  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.9941  Validation loss = 3.2007  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.9940  Validation loss = 3.2005  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.9939  Validation loss = 3.2005  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.9939  Validation loss = 3.2004  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.9938  Validation loss = 3.2003  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.9938  Validation loss = 3.2002  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.9937  Validation loss = 3.2001  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.9937  Validation loss = 3.2000  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.9936  Validation loss = 3.1999  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.9935  Validation loss = 3.1998  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.9935  Validation loss = 3.1997  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.9934  Validation loss = 3.1996  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.9933  Validation loss = 3.1995  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.9932  Validation loss = 3.1994  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.9932  Validation loss = 3.1993  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.9931  Validation loss = 3.1992  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.9931  Validation loss = 3.1991  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.9930  Validation loss = 3.1990  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.9930  Validation loss = 3.1990  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.9929  Validation loss = 3.1989  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.9929  Validation loss = 3.1988  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.9928  Validation loss = 3.1987  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.9928  Validation loss = 3.1986  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.9927  Validation loss = 3.1985  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.9927  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.9926  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.9925  Validation loss = 3.1983  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.9925  Validation loss = 3.1982  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.9924  Validation loss = 3.1981  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.9924  Validation loss = 3.1980  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.9923  Validation loss = 3.1979  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.9922  Validation loss = 3.1978  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.9922  Validation loss = 3.1977  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.9921  Validation loss = 3.1976  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.9920  Validation loss = 3.1975  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.9920  Validation loss = 3.1974  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.9919  Validation loss = 3.1973  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.9919  Validation loss = 3.1972  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.9918  Validation loss = 3.1971  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.9917  Validation loss = 3.1970  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.9917  Validation loss = 3.1969  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.9916  Validation loss = 3.1968  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.9916  Validation loss = 3.1967  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.9915  Validation loss = 3.1966  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.9915  Validation loss = 3.1965  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.9914  Validation loss = 3.1964  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.9913  Validation loss = 3.1963  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.9913  Validation loss = 3.1962  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.9912  Validation loss = 3.1961  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.9911  Validation loss = 3.1960  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.9910  Validation loss = 3.1959  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.9910  Validation loss = 3.1958  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.9909  Validation loss = 3.1957  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.9909  Validation loss = 3.1956  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.9908  Validation loss = 3.1955  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.9908  Validation loss = 3.1955  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.9907  Validation loss = 3.1954  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.9907  Validation loss = 3.1953  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.9906  Validation loss = 3.1952  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.9905  Validation loss = 3.1951  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.9905  Validation loss = 3.1950  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.9904  Validation loss = 3.1949  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.9904  Validation loss = 3.1948  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.9903  Validation loss = 3.1947  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.9902  Validation loss = 3.1946  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.9902  Validation loss = 3.1945  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.9901  Validation loss = 3.1945  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.9900  Validation loss = 3.1943  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.9900  Validation loss = 3.1942  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.9899  Validation loss = 3.1941  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.9899  Validation loss = 3.1941  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.9898  Validation loss = 3.1939  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.9897  Validation loss = 3.1938  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.9897  Validation loss = 3.1937  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.9896  Validation loss = 3.1937  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.9895  Validation loss = 3.1936  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.9895  Validation loss = 3.1934  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.9894  Validation loss = 3.1934  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.9894  Validation loss = 3.1933  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.9893  Validation loss = 3.1932  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.9892  Validation loss = 3.1931  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.9892  Validation loss = 3.1930  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.9891  Validation loss = 3.1929  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.9891  Validation loss = 3.1928  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.9890  Validation loss = 3.1927  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.9889  Validation loss = 3.1926  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.9889  Validation loss = 3.1925  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.9888  Validation loss = 3.1925  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.9888  Validation loss = 3.1924  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.9887  Validation loss = 3.1923  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.9887  Validation loss = 3.1922  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.9886  Validation loss = 3.1921  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.9886  Validation loss = 3.1920  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.9885  Validation loss = 3.1919  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.9884  Validation loss = 3.1918  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.9884  Validation loss = 3.1917  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.9883  Validation loss = 3.1917  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.9883  Validation loss = 3.1916  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.9882  Validation loss = 3.1915  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.9882  Validation loss = 3.1914  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.9881  Validation loss = 3.1913  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.9880  Validation loss = 3.1912  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.9880  Validation loss = 3.1911  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.9879  Validation loss = 3.1910  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.9878  Validation loss = 3.1909  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.9878  Validation loss = 3.1907  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.9877  Validation loss = 3.1907  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.9876  Validation loss = 3.1905  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.9876  Validation loss = 3.1905  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.9875  Validation loss = 3.1904  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.9875  Validation loss = 3.1903  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.9874  Validation loss = 3.1902  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.9874  Validation loss = 3.1901  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.9873  Validation loss = 3.1900  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.9872  Validation loss = 3.1899  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.9872  Validation loss = 3.1898  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.9871  Validation loss = 3.1897  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.9870  Validation loss = 3.1896  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.9870  Validation loss = 3.1895  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.9869  Validation loss = 3.1894  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.9869  Validation loss = 3.1893  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.9868  Validation loss = 3.1893  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.9868  Validation loss = 3.1892  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.9867  Validation loss = 3.1891  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.9867  Validation loss = 3.1890  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.9866  Validation loss = 3.1889  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.9865  Validation loss = 3.1888  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.9865  Validation loss = 3.1887  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.9864  Validation loss = 3.1886  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.9863  Validation loss = 3.1885  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.9863  Validation loss = 3.1884  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.9862  Validation loss = 3.1883  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.9862  Validation loss = 3.1882  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.9861  Validation loss = 3.1882  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.9860  Validation loss = 3.1881  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.9860  Validation loss = 3.1880  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.9859  Validation loss = 3.1878  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.9858  Validation loss = 3.1877  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.9857  Validation loss = 3.1876  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.9856  Validation loss = 3.1875  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.9856  Validation loss = 3.1874  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.9855  Validation loss = 3.1873  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.9855  Validation loss = 3.1872  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.9854  Validation loss = 3.1871  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.9854  Validation loss = 3.1871  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.9853  Validation loss = 3.1869  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.9852  Validation loss = 3.1868  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.9852  Validation loss = 3.1867  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.9851  Validation loss = 3.1866  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.9851  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.9850  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.9850  Validation loss = 3.1864  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.9849  Validation loss = 3.1863  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.9848  Validation loss = 3.1862  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.9848  Validation loss = 3.1861  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.9847  Validation loss = 3.1860  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.9847  Validation loss = 3.1859  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.9846  Validation loss = 3.1859  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.9846  Validation loss = 3.1858  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.9845  Validation loss = 3.1856  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.9844  Validation loss = 3.1855  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.9843  Validation loss = 3.1854  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.9843  Validation loss = 3.1853  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.9842  Validation loss = 3.1852  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.9841  Validation loss = 3.1851  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.9841  Validation loss = 3.1850  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.9840  Validation loss = 3.1849  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.9840  Validation loss = 3.1849  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.9839  Validation loss = 3.1847  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.9839  Validation loss = 3.1847  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.9838  Validation loss = 3.1846  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.9837  Validation loss = 3.1845  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.9837  Validation loss = 3.1844  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.9836  Validation loss = 3.1843  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.9835  Validation loss = 3.1842  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.9835  Validation loss = 3.1841  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.9834  Validation loss = 3.1840  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.9834  Validation loss = 3.1839  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.9833  Validation loss = 3.1838  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.9832  Validation loss = 3.1837  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.9832  Validation loss = 3.1836  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.9831  Validation loss = 3.1835  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.9830  Validation loss = 3.1834  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.9829  Validation loss = 3.1833  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.9829  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.9828  Validation loss = 3.1831  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.9828  Validation loss = 3.1830  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.9827  Validation loss = 3.1829  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.9827  Validation loss = 3.1828  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.9826  Validation loss = 3.1828  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.9826  Validation loss = 3.1827  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.9825  Validation loss = 3.1826  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.9825  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.9824  Validation loss = 3.1824  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.9824  Validation loss = 3.1823  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.9823  Validation loss = 3.1822  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.9822  Validation loss = 3.1821  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.9822  Validation loss = 3.1820  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.9821  Validation loss = 3.1819  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.9821  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.9820  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.9819  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.9819  Validation loss = 3.1815  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.9818  Validation loss = 3.1815  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.9818  Validation loss = 3.1814  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.9817  Validation loss = 3.1813  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.9816  Validation loss = 3.1812  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.9816  Validation loss = 3.1811  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.9815  Validation loss = 3.1810  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.9815  Validation loss = 3.1809  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.9814  Validation loss = 3.1808  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.9813  Validation loss = 3.1807  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.9813  Validation loss = 3.1806  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.9812  Validation loss = 3.1805  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.9811  Validation loss = 3.1804  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.9811  Validation loss = 3.1803  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.9810  Validation loss = 3.1802  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.9809  Validation loss = 3.1801  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.9809  Validation loss = 3.1800  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.9809  Validation loss = 3.1800  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.9808  Validation loss = 3.1798  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.9807  Validation loss = 3.1798  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.9807  Validation loss = 3.1797  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.9806  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.9806  Validation loss = 3.1795  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.9805  Validation loss = 3.1794  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.9805  Validation loss = 3.1793  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.9804  Validation loss = 3.1793  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.9804  Validation loss = 3.1792  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.9803  Validation loss = 3.1791  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.9803  Validation loss = 3.1790  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.9802  Validation loss = 3.1789  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.9802  Validation loss = 3.1788  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.9801  Validation loss = 3.1787  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.9800  Validation loss = 3.1787  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.9800  Validation loss = 3.1786  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.9800  Validation loss = 3.1785  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.9799  Validation loss = 3.1784  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.9798  Validation loss = 3.1783  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.9798  Validation loss = 3.1782  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.9797  Validation loss = 3.1781  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.9797  Validation loss = 3.1781  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.9796  Validation loss = 3.1780  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.9796  Validation loss = 3.1779  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.9795  Validation loss = 3.1778  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.9794  Validation loss = 3.1777  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.9794  Validation loss = 3.1776  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.9793  Validation loss = 3.1775  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.9793  Validation loss = 3.1774  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.9792  Validation loss = 3.1773  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.9791  Validation loss = 3.1772  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.9791  Validation loss = 3.1771  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.9790  Validation loss = 3.1771  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.9790  Validation loss = 3.1770  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.9789  Validation loss = 3.1769  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.9789  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.9788  Validation loss = 3.1767  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.9787  Validation loss = 3.1766  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.9787  Validation loss = 3.1765  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.9786  Validation loss = 3.1764  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.9786  Validation loss = 3.1763  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.9785  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.9785  Validation loss = 3.1761  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.9784  Validation loss = 3.1761  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.9784  Validation loss = 3.1760  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.9783  Validation loss = 3.1759  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.9783  Validation loss = 3.1758  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.9782  Validation loss = 3.1757  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.9781  Validation loss = 3.1756  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.9781  Validation loss = 3.1755  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.9780  Validation loss = 3.1754  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.9779  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.9779  Validation loss = 3.1752  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.9778  Validation loss = 3.1751  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.9778  Validation loss = 3.1750  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.9777  Validation loss = 3.1749  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.9777  Validation loss = 3.1748  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.9776  Validation loss = 3.1747  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.9776  Validation loss = 3.1747  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.9775  Validation loss = 3.1746  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.9775  Validation loss = 3.1745  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.9774  Validation loss = 3.1744  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.9773  Validation loss = 3.1743  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.9773  Validation loss = 3.1742  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.9772  Validation loss = 3.1741  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.9771  Validation loss = 3.1740  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.9771  Validation loss = 3.1740  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.9771  Validation loss = 3.1739  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.9770  Validation loss = 3.1738  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.9770  Validation loss = 3.1737  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.9769  Validation loss = 3.1736  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.9768  Validation loss = 3.1735  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.9768  Validation loss = 3.1734  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.9767  Validation loss = 3.1733  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.9767  Validation loss = 3.1732  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.9766  Validation loss = 3.1731  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.9765  Validation loss = 3.1730  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.9765  Validation loss = 3.1730  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.9764  Validation loss = 3.1729  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.9764  Validation loss = 3.1728  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.9763  Validation loss = 3.1727  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.9763  Validation loss = 3.1726  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.9762  Validation loss = 3.1725  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.9761  Validation loss = 3.1724  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.9761  Validation loss = 3.1723  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.9760  Validation loss = 3.1722  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.9760  Validation loss = 3.1721  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.9759  Validation loss = 3.1720  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.9758  Validation loss = 3.1719  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.9758  Validation loss = 3.1718  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.9757  Validation loss = 3.1717  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.9757  Validation loss = 3.1716  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.9756  Validation loss = 3.1716  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.9756  Validation loss = 3.1715  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.9755  Validation loss = 3.1714  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.9755  Validation loss = 3.1713  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.9754  Validation loss = 3.1712  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.9753  Validation loss = 3.1711  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.9753  Validation loss = 3.1710  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.9752  Validation loss = 3.1709  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.9751  Validation loss = 3.1708  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.9751  Validation loss = 3.1707  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.9750  Validation loss = 3.1706  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.9750  Validation loss = 3.1705  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.9750  Validation loss = 3.1705  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.9749  Validation loss = 3.1703  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.9748  Validation loss = 3.1703  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.9748  Validation loss = 3.1701  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.9747  Validation loss = 3.1701  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.9746  Validation loss = 3.1700  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.9746  Validation loss = 3.1699  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.9745  Validation loss = 3.1698  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.9745  Validation loss = 3.1697  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.9744  Validation loss = 3.1697  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.9744  Validation loss = 3.1695  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.9743  Validation loss = 3.1694  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.9743  Validation loss = 3.1694  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.9742  Validation loss = 3.1693  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.9742  Validation loss = 3.1692  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.9741  Validation loss = 3.1691  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.9741  Validation loss = 3.1690  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.9740  Validation loss = 3.1689  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.9740  Validation loss = 3.1688  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.9739  Validation loss = 3.1687  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.9738  Validation loss = 3.1686  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.9738  Validation loss = 3.1685  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.9737  Validation loss = 3.1684  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.9736  Validation loss = 3.1683  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.9736  Validation loss = 3.1682  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.9735  Validation loss = 3.1682  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.9735  Validation loss = 3.1680  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.9734  Validation loss = 3.1679  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.9733  Validation loss = 3.1678  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.9733  Validation loss = 3.1677  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.9732  Validation loss = 3.1676  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.9731  Validation loss = 3.1676  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.9731  Validation loss = 3.1675  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.9730  Validation loss = 3.1674  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.9730  Validation loss = 3.1673  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.9729  Validation loss = 3.1672  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.9729  Validation loss = 3.1671  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.9728  Validation loss = 3.1670  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.9728  Validation loss = 3.1669  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.9727  Validation loss = 3.1668  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.9726  Validation loss = 3.1667  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.9726  Validation loss = 3.1667  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.9725  Validation loss = 3.1666  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.9725  Validation loss = 3.1665  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.9724  Validation loss = 3.1664  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.9724  Validation loss = 3.1663  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.9723  Validation loss = 3.1662  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.9722  Validation loss = 3.1661  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.9722  Validation loss = 3.1660  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.9721  Validation loss = 3.1659  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.9720  Validation loss = 3.1658  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.9720  Validation loss = 3.1657  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.9719  Validation loss = 3.1656  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.9719  Validation loss = 3.1655  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.9718  Validation loss = 3.1654  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.9718  Validation loss = 3.1653  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.9717  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.9716  Validation loss = 3.1651  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.9716  Validation loss = 3.1650  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.9715  Validation loss = 3.1649  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.9714  Validation loss = 3.1647  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.9714  Validation loss = 3.1646  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.9713  Validation loss = 3.1646  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.9713  Validation loss = 3.1645  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.9712  Validation loss = 3.1644  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.9711  Validation loss = 3.1643  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.9711  Validation loss = 3.1642  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.9710  Validation loss = 3.1641  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.9710  Validation loss = 3.1640  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.9709  Validation loss = 3.1639  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.9709  Validation loss = 3.1638  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.9708  Validation loss = 3.1638  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.9708  Validation loss = 3.1636  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.9707  Validation loss = 3.1636  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.9707  Validation loss = 3.1635  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.9706  Validation loss = 3.1634  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.9705  Validation loss = 3.1633  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.9705  Validation loss = 3.1632  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.9704  Validation loss = 3.1631  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.9704  Validation loss = 3.1630  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.9703  Validation loss = 3.1629  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.9703  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.9702  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.9701  Validation loss = 3.1627  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.9701  Validation loss = 3.1626  \n",
      "\n",
      "Fold: 2  Epoch: 501  Training loss = 2.9700  Validation loss = 3.1625  \n",
      "\n",
      "Fold: 2  Epoch: 502  Training loss = 2.9700  Validation loss = 3.1624  \n",
      "\n",
      "Fold: 2  Epoch: 503  Training loss = 2.9699  Validation loss = 3.1623  \n",
      "\n",
      "Fold: 2  Epoch: 504  Training loss = 2.9699  Validation loss = 3.1622  \n",
      "\n",
      "Fold: 2  Epoch: 505  Training loss = 2.9698  Validation loss = 3.1621  \n",
      "\n",
      "Fold: 2  Epoch: 506  Training loss = 2.9697  Validation loss = 3.1620  \n",
      "\n",
      "Fold: 2  Epoch: 507  Training loss = 2.9697  Validation loss = 3.1619  \n",
      "\n",
      "Fold: 2  Epoch: 508  Training loss = 2.9696  Validation loss = 3.1618  \n",
      "\n",
      "Fold: 2  Epoch: 509  Training loss = 2.9695  Validation loss = 3.1617  \n",
      "\n",
      "Fold: 2  Epoch: 510  Training loss = 2.9695  Validation loss = 3.1616  \n",
      "\n",
      "Fold: 2  Epoch: 511  Training loss = 2.9694  Validation loss = 3.1615  \n",
      "\n",
      "Fold: 2  Epoch: 512  Training loss = 2.9694  Validation loss = 3.1614  \n",
      "\n",
      "Fold: 2  Epoch: 513  Training loss = 2.9693  Validation loss = 3.1613  \n",
      "\n",
      "Fold: 2  Epoch: 514  Training loss = 2.9693  Validation loss = 3.1612  \n",
      "\n",
      "Fold: 2  Epoch: 515  Training loss = 2.9692  Validation loss = 3.1612  \n",
      "\n",
      "Fold: 2  Epoch: 516  Training loss = 2.9692  Validation loss = 3.1611  \n",
      "\n",
      "Fold: 2  Epoch: 517  Training loss = 2.9691  Validation loss = 3.1610  \n",
      "\n",
      "Fold: 2  Epoch: 518  Training loss = 2.9690  Validation loss = 3.1609  \n",
      "\n",
      "Fold: 2  Epoch: 519  Training loss = 2.9690  Validation loss = 3.1608  \n",
      "\n",
      "Fold: 2  Epoch: 520  Training loss = 2.9690  Validation loss = 3.1607  \n",
      "\n",
      "Fold: 2  Epoch: 521  Training loss = 2.9689  Validation loss = 3.1607  \n",
      "\n",
      "Fold: 2  Epoch: 522  Training loss = 2.9688  Validation loss = 3.1606  \n",
      "\n",
      "Fold: 2  Epoch: 523  Training loss = 2.9688  Validation loss = 3.1605  \n",
      "\n",
      "Fold: 2  Epoch: 524  Training loss = 2.9688  Validation loss = 3.1604  \n",
      "\n",
      "Fold: 2  Epoch: 525  Training loss = 2.9687  Validation loss = 3.1603  \n",
      "\n",
      "Fold: 2  Epoch: 526  Training loss = 2.9687  Validation loss = 3.1602  \n",
      "\n",
      "Fold: 2  Epoch: 527  Training loss = 2.9686  Validation loss = 3.1601  \n",
      "\n",
      "Fold: 2  Epoch: 528  Training loss = 2.9686  Validation loss = 3.1601  \n",
      "\n",
      "Fold: 2  Epoch: 529  Training loss = 2.9685  Validation loss = 3.1600  \n",
      "\n",
      "Fold: 2  Epoch: 530  Training loss = 2.9684  Validation loss = 3.1599  \n",
      "\n",
      "Fold: 2  Epoch: 531  Training loss = 2.9684  Validation loss = 3.1598  \n",
      "\n",
      "Fold: 2  Epoch: 532  Training loss = 2.9683  Validation loss = 3.1596  \n",
      "\n",
      "Fold: 2  Epoch: 533  Training loss = 2.9682  Validation loss = 3.1596  \n",
      "\n",
      "Fold: 2  Epoch: 534  Training loss = 2.9682  Validation loss = 3.1595  \n",
      "\n",
      "Fold: 2  Epoch: 535  Training loss = 2.9681  Validation loss = 3.1593  \n",
      "\n",
      "Fold: 2  Epoch: 536  Training loss = 2.9681  Validation loss = 3.1592  \n",
      "\n",
      "Fold: 2  Epoch: 537  Training loss = 2.9680  Validation loss = 3.1591  \n",
      "\n",
      "Fold: 2  Epoch: 538  Training loss = 2.9680  Validation loss = 3.1591  \n",
      "\n",
      "Fold: 2  Epoch: 539  Training loss = 2.9679  Validation loss = 3.1590  \n",
      "\n",
      "Fold: 2  Epoch: 540  Training loss = 2.9678  Validation loss = 3.1589  \n",
      "\n",
      "Fold: 2  Epoch: 541  Training loss = 2.9678  Validation loss = 3.1588  \n",
      "\n",
      "Fold: 2  Epoch: 542  Training loss = 2.9677  Validation loss = 3.1587  \n",
      "\n",
      "Fold: 2  Epoch: 543  Training loss = 2.9677  Validation loss = 3.1586  \n",
      "\n",
      "Fold: 2  Epoch: 544  Training loss = 2.9676  Validation loss = 3.1585  \n",
      "\n",
      "Fold: 2  Epoch: 545  Training loss = 2.9675  Validation loss = 3.1584  \n",
      "\n",
      "Fold: 2  Epoch: 546  Training loss = 2.9675  Validation loss = 3.1583  \n",
      "\n",
      "Fold: 2  Epoch: 547  Training loss = 2.9674  Validation loss = 3.1582  \n",
      "\n",
      "Fold: 2  Epoch: 548  Training loss = 2.9674  Validation loss = 3.1581  \n",
      "\n",
      "Fold: 2  Epoch: 549  Training loss = 2.9673  Validation loss = 3.1580  \n",
      "\n",
      "Fold: 2  Epoch: 550  Training loss = 2.9673  Validation loss = 3.1579  \n",
      "\n",
      "Fold: 2  Epoch: 551  Training loss = 2.9672  Validation loss = 3.1579  \n",
      "\n",
      "Fold: 2  Epoch: 552  Training loss = 2.9672  Validation loss = 3.1578  \n",
      "\n",
      "Fold: 2  Epoch: 553  Training loss = 2.9671  Validation loss = 3.1577  \n",
      "\n",
      "Fold: 2  Epoch: 554  Training loss = 2.9670  Validation loss = 3.1576  \n",
      "\n",
      "Fold: 2  Epoch: 555  Training loss = 2.9670  Validation loss = 3.1575  \n",
      "\n",
      "Fold: 2  Epoch: 556  Training loss = 2.9669  Validation loss = 3.1574  \n",
      "\n",
      "Fold: 2  Epoch: 557  Training loss = 2.9669  Validation loss = 3.1573  \n",
      "\n",
      "Fold: 2  Epoch: 558  Training loss = 2.9668  Validation loss = 3.1572  \n",
      "\n",
      "Fold: 2  Epoch: 559  Training loss = 2.9667  Validation loss = 3.1571  \n",
      "\n",
      "Fold: 2  Epoch: 560  Training loss = 2.9667  Validation loss = 3.1570  \n",
      "\n",
      "Fold: 2  Epoch: 561  Training loss = 2.9666  Validation loss = 3.1569  \n",
      "\n",
      "Fold: 2  Epoch: 562  Training loss = 2.9666  Validation loss = 3.1569  \n",
      "\n",
      "Fold: 2  Epoch: 563  Training loss = 2.9665  Validation loss = 3.1568  \n",
      "\n",
      "Fold: 2  Epoch: 564  Training loss = 2.9665  Validation loss = 3.1567  \n",
      "\n",
      "Fold: 2  Epoch: 565  Training loss = 2.9665  Validation loss = 3.1566  \n",
      "\n",
      "Fold: 2  Epoch: 566  Training loss = 2.9664  Validation loss = 3.1565  \n",
      "\n",
      "Fold: 2  Epoch: 567  Training loss = 2.9663  Validation loss = 3.1564  \n",
      "\n",
      "Fold: 2  Epoch: 568  Training loss = 2.9663  Validation loss = 3.1564  \n",
      "\n",
      "Fold: 2  Epoch: 569  Training loss = 2.9662  Validation loss = 3.1563  \n",
      "\n",
      "Fold: 2  Epoch: 570  Training loss = 2.9662  Validation loss = 3.1562  \n",
      "\n",
      "Fold: 2  Epoch: 571  Training loss = 2.9661  Validation loss = 3.1561  \n",
      "\n",
      "Fold: 2  Epoch: 572  Training loss = 2.9661  Validation loss = 3.1561  \n",
      "\n",
      "Fold: 2  Epoch: 573  Training loss = 2.9660  Validation loss = 3.1560  \n",
      "\n",
      "Fold: 2  Epoch: 574  Training loss = 2.9660  Validation loss = 3.1559  \n",
      "\n",
      "Fold: 2  Epoch: 575  Training loss = 2.9659  Validation loss = 3.1558  \n",
      "\n",
      "Fold: 2  Epoch: 576  Training loss = 2.9659  Validation loss = 3.1557  \n",
      "\n",
      "Fold: 2  Epoch: 577  Training loss = 2.9658  Validation loss = 3.1556  \n",
      "\n",
      "Fold: 2  Epoch: 578  Training loss = 2.9658  Validation loss = 3.1555  \n",
      "\n",
      "Fold: 2  Epoch: 579  Training loss = 2.9657  Validation loss = 3.1554  \n",
      "\n",
      "Fold: 2  Epoch: 580  Training loss = 2.9657  Validation loss = 3.1554  \n",
      "\n",
      "Fold: 2  Epoch: 581  Training loss = 2.9656  Validation loss = 3.1553  \n",
      "\n",
      "Fold: 2  Epoch: 582  Training loss = 2.9656  Validation loss = 3.1552  \n",
      "\n",
      "Fold: 2  Epoch: 583  Training loss = 2.9655  Validation loss = 3.1551  \n",
      "\n",
      "Fold: 2  Epoch: 584  Training loss = 2.9655  Validation loss = 3.1550  \n",
      "\n",
      "Fold: 2  Epoch: 585  Training loss = 2.9654  Validation loss = 3.1549  \n",
      "\n",
      "Fold: 2  Epoch: 586  Training loss = 2.9653  Validation loss = 3.1548  \n",
      "\n",
      "Fold: 2  Epoch: 587  Training loss = 2.9653  Validation loss = 3.1547  \n",
      "\n",
      "Fold: 2  Epoch: 588  Training loss = 2.9652  Validation loss = 3.1547  \n",
      "\n",
      "Fold: 2  Epoch: 589  Training loss = 2.9652  Validation loss = 3.1546  \n",
      "\n",
      "Fold: 2  Epoch: 590  Training loss = 2.9651  Validation loss = 3.1545  \n",
      "\n",
      "Fold: 2  Epoch: 591  Training loss = 2.9650  Validation loss = 3.1543  \n",
      "\n",
      "Fold: 2  Epoch: 592  Training loss = 2.9650  Validation loss = 3.1542  \n",
      "\n",
      "Fold: 2  Epoch: 593  Training loss = 2.9649  Validation loss = 3.1542  \n",
      "\n",
      "Fold: 2  Epoch: 594  Training loss = 2.9649  Validation loss = 3.1541  \n",
      "\n",
      "Fold: 2  Epoch: 595  Training loss = 2.9648  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 2  Epoch: 596  Training loss = 2.9648  Validation loss = 3.1539  \n",
      "\n",
      "Fold: 2  Epoch: 597  Training loss = 2.9647  Validation loss = 3.1538  \n",
      "\n",
      "Fold: 2  Epoch: 598  Training loss = 2.9647  Validation loss = 3.1537  \n",
      "\n",
      "Fold: 2  Epoch: 599  Training loss = 2.9646  Validation loss = 3.1536  \n",
      "\n",
      "Fold: 2  Epoch: 600  Training loss = 2.9645  Validation loss = 3.1535  \n",
      "\n",
      "Fold: 2  Epoch: 601  Training loss = 2.9645  Validation loss = 3.1534  \n",
      "\n",
      "Fold: 2  Epoch: 602  Training loss = 2.9644  Validation loss = 3.1533  \n",
      "\n",
      "Fold: 2  Epoch: 603  Training loss = 2.9644  Validation loss = 3.1533  \n",
      "\n",
      "Fold: 2  Epoch: 604  Training loss = 2.9643  Validation loss = 3.1532  \n",
      "\n",
      "Fold: 2  Epoch: 605  Training loss = 2.9643  Validation loss = 3.1531  \n",
      "\n",
      "Fold: 2  Epoch: 606  Training loss = 2.9642  Validation loss = 3.1530  \n",
      "\n",
      "Fold: 2  Epoch: 607  Training loss = 2.9642  Validation loss = 3.1529  \n",
      "\n",
      "Fold: 2  Epoch: 608  Training loss = 2.9641  Validation loss = 3.1528  \n",
      "\n",
      "Fold: 2  Epoch: 609  Training loss = 2.9640  Validation loss = 3.1527  \n",
      "\n",
      "Fold: 2  Epoch: 610  Training loss = 2.9640  Validation loss = 3.1526  \n",
      "\n",
      "Fold: 2  Epoch: 611  Training loss = 2.9639  Validation loss = 3.1525  \n",
      "\n",
      "Fold: 2  Epoch: 612  Training loss = 2.9639  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 2  Epoch: 613  Training loss = 2.9638  Validation loss = 3.1523  \n",
      "\n",
      "Fold: 2  Epoch: 614  Training loss = 2.9637  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 2  Epoch: 615  Training loss = 2.9637  Validation loss = 3.1521  \n",
      "\n",
      "Fold: 2  Epoch: 616  Training loss = 2.9636  Validation loss = 3.1520  \n",
      "\n",
      "Fold: 2  Epoch: 617  Training loss = 2.9636  Validation loss = 3.1519  \n",
      "\n",
      "Fold: 2  Epoch: 618  Training loss = 2.9635  Validation loss = 3.1518  \n",
      "\n",
      "Fold: 2  Epoch: 619  Training loss = 2.9634  Validation loss = 3.1517  \n",
      "\n",
      "Fold: 2  Epoch: 620  Training loss = 2.9634  Validation loss = 3.1516  \n",
      "\n",
      "Fold: 2  Epoch: 621  Training loss = 2.9633  Validation loss = 3.1515  \n",
      "\n",
      "Fold: 2  Epoch: 622  Training loss = 2.9632  Validation loss = 3.1514  \n",
      "\n",
      "Fold: 2  Epoch: 623  Training loss = 2.9632  Validation loss = 3.1513  \n",
      "\n",
      "Fold: 2  Epoch: 624  Training loss = 2.9631  Validation loss = 3.1512  \n",
      "\n",
      "Fold: 2  Epoch: 625  Training loss = 2.9631  Validation loss = 3.1511  \n",
      "\n",
      "Fold: 2  Epoch: 626  Training loss = 2.9630  Validation loss = 3.1510  \n",
      "\n",
      "Fold: 2  Epoch: 627  Training loss = 2.9630  Validation loss = 3.1509  \n",
      "\n",
      "Fold: 2  Epoch: 628  Training loss = 2.9629  Validation loss = 3.1509  \n",
      "\n",
      "Fold: 2  Epoch: 629  Training loss = 2.9629  Validation loss = 3.1508  \n",
      "\n",
      "Fold: 2  Epoch: 630  Training loss = 2.9628  Validation loss = 3.1507  \n",
      "\n",
      "Fold: 2  Epoch: 631  Training loss = 2.9627  Validation loss = 3.1506  \n",
      "\n",
      "Fold: 2  Epoch: 632  Training loss = 2.9627  Validation loss = 3.1505  \n",
      "\n",
      "Fold: 2  Epoch: 633  Training loss = 2.9626  Validation loss = 3.1504  \n",
      "\n",
      "Fold: 2  Epoch: 634  Training loss = 2.9626  Validation loss = 3.1503  \n",
      "\n",
      "Fold: 2  Epoch: 635  Training loss = 2.9625  Validation loss = 3.1502  \n",
      "\n",
      "Fold: 2  Epoch: 636  Training loss = 2.9624  Validation loss = 3.1501  \n",
      "\n",
      "Fold: 2  Epoch: 637  Training loss = 2.9624  Validation loss = 3.1500  \n",
      "\n",
      "Fold: 2  Epoch: 638  Training loss = 2.9623  Validation loss = 3.1499  \n",
      "\n",
      "Fold: 2  Epoch: 639  Training loss = 2.9622  Validation loss = 3.1498  \n",
      "\n",
      "Fold: 2  Epoch: 640  Training loss = 2.9622  Validation loss = 3.1497  \n",
      "\n",
      "Fold: 2  Epoch: 641  Training loss = 2.9621  Validation loss = 3.1496  \n",
      "\n",
      "Fold: 2  Epoch: 642  Training loss = 2.9621  Validation loss = 3.1495  \n",
      "\n",
      "Fold: 2  Epoch: 643  Training loss = 2.9620  Validation loss = 3.1494  \n",
      "\n",
      "Fold: 2  Epoch: 644  Training loss = 2.9619  Validation loss = 3.1493  \n",
      "\n",
      "Fold: 2  Epoch: 645  Training loss = 2.9619  Validation loss = 3.1492  \n",
      "\n",
      "Fold: 2  Epoch: 646  Training loss = 2.9618  Validation loss = 3.1491  \n",
      "\n",
      "Fold: 2  Epoch: 647  Training loss = 2.9618  Validation loss = 3.1490  \n",
      "\n",
      "Fold: 2  Epoch: 648  Training loss = 2.9617  Validation loss = 3.1489  \n",
      "\n",
      "Fold: 2  Epoch: 649  Training loss = 2.9617  Validation loss = 3.1488  \n",
      "\n",
      "Fold: 2  Epoch: 650  Training loss = 2.9616  Validation loss = 3.1487  \n",
      "\n",
      "Fold: 2  Epoch: 651  Training loss = 2.9615  Validation loss = 3.1486  \n",
      "\n",
      "Fold: 2  Epoch: 652  Training loss = 2.9615  Validation loss = 3.1485  \n",
      "\n",
      "Fold: 2  Epoch: 653  Training loss = 2.9614  Validation loss = 3.1484  \n",
      "\n",
      "Fold: 2  Epoch: 654  Training loss = 2.9614  Validation loss = 3.1483  \n",
      "\n",
      "Fold: 2  Epoch: 655  Training loss = 2.9613  Validation loss = 3.1482  \n",
      "\n",
      "Fold: 2  Epoch: 656  Training loss = 2.9612  Validation loss = 3.1481  \n",
      "\n",
      "Fold: 2  Epoch: 657  Training loss = 2.9612  Validation loss = 3.1480  \n",
      "\n",
      "Fold: 2  Epoch: 658  Training loss = 2.9611  Validation loss = 3.1479  \n",
      "\n",
      "Fold: 2  Epoch: 659  Training loss = 2.9611  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 2  Epoch: 660  Training loss = 2.9610  Validation loss = 3.1477  \n",
      "\n",
      "Fold: 2  Epoch: 661  Training loss = 2.9610  Validation loss = 3.1477  \n",
      "\n",
      "Fold: 2  Epoch: 662  Training loss = 2.9609  Validation loss = 3.1476  \n",
      "\n",
      "Fold: 2  Epoch: 663  Training loss = 2.9609  Validation loss = 3.1475  \n",
      "\n",
      "Fold: 2  Epoch: 664  Training loss = 2.9608  Validation loss = 3.1474  \n",
      "\n",
      "Fold: 2  Epoch: 665  Training loss = 2.9608  Validation loss = 3.1473  \n",
      "\n",
      "Fold: 2  Epoch: 666  Training loss = 2.9607  Validation loss = 3.1473  \n",
      "\n",
      "Fold: 2  Epoch: 667  Training loss = 2.9607  Validation loss = 3.1472  \n",
      "\n",
      "Fold: 2  Epoch: 668  Training loss = 2.9606  Validation loss = 3.1471  \n",
      "\n",
      "Fold: 2  Epoch: 669  Training loss = 2.9605  Validation loss = 3.1470  \n",
      "\n",
      "Fold: 2  Epoch: 670  Training loss = 2.9605  Validation loss = 3.1469  \n",
      "\n",
      "Fold: 2  Epoch: 671  Training loss = 2.9605  Validation loss = 3.1468  \n",
      "\n",
      "Fold: 2  Epoch: 672  Training loss = 2.9604  Validation loss = 3.1467  \n",
      "\n",
      "Fold: 2  Epoch: 673  Training loss = 2.9603  Validation loss = 3.1466  \n",
      "\n",
      "Fold: 2  Epoch: 674  Training loss = 2.9603  Validation loss = 3.1465  \n",
      "\n",
      "Fold: 2  Epoch: 675  Training loss = 2.9602  Validation loss = 3.1465  \n",
      "\n",
      "Fold: 2  Epoch: 676  Training loss = 2.9602  Validation loss = 3.1464  \n",
      "\n",
      "Fold: 2  Epoch: 677  Training loss = 2.9601  Validation loss = 3.1463  \n",
      "\n",
      "Fold: 2  Epoch: 678  Training loss = 2.9600  Validation loss = 3.1462  \n",
      "\n",
      "Fold: 2  Epoch: 679  Training loss = 2.9600  Validation loss = 3.1461  \n",
      "\n",
      "Fold: 2  Epoch: 680  Training loss = 2.9599  Validation loss = 3.1460  \n",
      "\n",
      "Fold: 2  Epoch: 681  Training loss = 2.9599  Validation loss = 3.1459  \n",
      "\n",
      "Fold: 2  Epoch: 682  Training loss = 2.9598  Validation loss = 3.1458  \n",
      "\n",
      "Fold: 2  Epoch: 683  Training loss = 2.9598  Validation loss = 3.1457  \n",
      "\n",
      "Fold: 2  Epoch: 684  Training loss = 2.9597  Validation loss = 3.1456  \n",
      "\n",
      "Fold: 2  Epoch: 685  Training loss = 2.9597  Validation loss = 3.1456  \n",
      "\n",
      "Fold: 2  Epoch: 686  Training loss = 2.9596  Validation loss = 3.1455  \n",
      "\n",
      "Fold: 2  Epoch: 687  Training loss = 2.9596  Validation loss = 3.1454  \n",
      "\n",
      "Fold: 2  Epoch: 688  Training loss = 2.9595  Validation loss = 3.1453  \n",
      "\n",
      "Fold: 2  Epoch: 689  Training loss = 2.9594  Validation loss = 3.1452  \n",
      "\n",
      "Fold: 2  Epoch: 690  Training loss = 2.9594  Validation loss = 3.1451  \n",
      "\n",
      "Fold: 2  Epoch: 691  Training loss = 2.9593  Validation loss = 3.1449  \n",
      "\n",
      "Fold: 2  Epoch: 692  Training loss = 2.9592  Validation loss = 3.1448  \n",
      "\n",
      "Fold: 2  Epoch: 693  Training loss = 2.9592  Validation loss = 3.1447  \n",
      "\n",
      "Fold: 2  Epoch: 694  Training loss = 2.9591  Validation loss = 3.1447  \n",
      "\n",
      "Fold: 2  Epoch: 695  Training loss = 2.9591  Validation loss = 3.1446  \n",
      "\n",
      "Fold: 2  Epoch: 696  Training loss = 2.9590  Validation loss = 3.1445  \n",
      "\n",
      "Fold: 2  Epoch: 697  Training loss = 2.9590  Validation loss = 3.1444  \n",
      "\n",
      "Fold: 2  Epoch: 698  Training loss = 2.9589  Validation loss = 3.1443  \n",
      "\n",
      "Fold: 2  Epoch: 699  Training loss = 2.9589  Validation loss = 3.1442  \n",
      "\n",
      "Fold: 2  Epoch: 700  Training loss = 2.9588  Validation loss = 3.1441  \n",
      "\n",
      "Fold: 2  Epoch: 701  Training loss = 2.9587  Validation loss = 3.1440  \n",
      "\n",
      "Fold: 2  Epoch: 702  Training loss = 2.9587  Validation loss = 3.1439  \n",
      "\n",
      "Fold: 2  Epoch: 703  Training loss = 2.9587  Validation loss = 3.1439  \n",
      "\n",
      "Fold: 2  Epoch: 704  Training loss = 2.9586  Validation loss = 3.1438  \n",
      "\n",
      "Fold: 2  Epoch: 705  Training loss = 2.9586  Validation loss = 3.1437  \n",
      "\n",
      "Fold: 2  Epoch: 706  Training loss = 2.9585  Validation loss = 3.1436  \n",
      "\n",
      "Fold: 2  Epoch: 707  Training loss = 2.9585  Validation loss = 3.1435  \n",
      "\n",
      "Fold: 2  Epoch: 708  Training loss = 2.9584  Validation loss = 3.1435  \n",
      "\n",
      "Fold: 2  Epoch: 709  Training loss = 2.9584  Validation loss = 3.1434  \n",
      "\n",
      "Fold: 2  Epoch: 710  Training loss = 2.9583  Validation loss = 3.1433  \n",
      "\n",
      "Fold: 2  Epoch: 711  Training loss = 2.9583  Validation loss = 3.1432  \n",
      "\n",
      "Fold: 2  Epoch: 712  Training loss = 2.9582  Validation loss = 3.1431  \n",
      "\n",
      "Fold: 2  Epoch: 713  Training loss = 2.9582  Validation loss = 3.1430  \n",
      "\n",
      "Fold: 2  Epoch: 714  Training loss = 2.9581  Validation loss = 3.1430  \n",
      "\n",
      "Fold: 2  Epoch: 715  Training loss = 2.9581  Validation loss = 3.1429  \n",
      "\n",
      "Fold: 2  Epoch: 716  Training loss = 2.9580  Validation loss = 3.1428  \n",
      "\n",
      "Fold: 2  Epoch: 717  Training loss = 2.9580  Validation loss = 3.1427  \n",
      "\n",
      "Fold: 2  Epoch: 718  Training loss = 2.9579  Validation loss = 3.1426  \n",
      "\n",
      "Fold: 2  Epoch: 719  Training loss = 2.9579  Validation loss = 3.1425  \n",
      "\n",
      "Fold: 2  Epoch: 720  Training loss = 2.9578  Validation loss = 3.1425  \n",
      "\n",
      "Fold: 2  Epoch: 721  Training loss = 2.9578  Validation loss = 3.1424  \n",
      "\n",
      "Fold: 2  Epoch: 722  Training loss = 2.9577  Validation loss = 3.1423  \n",
      "\n",
      "Fold: 2  Epoch: 723  Training loss = 2.9576  Validation loss = 3.1422  \n",
      "\n",
      "Fold: 2  Epoch: 724  Training loss = 2.9576  Validation loss = 3.1421  \n",
      "\n",
      "Fold: 2  Epoch: 725  Training loss = 2.9575  Validation loss = 3.1420  \n",
      "\n",
      "Fold: 2  Epoch: 726  Training loss = 2.9575  Validation loss = 3.1419  \n",
      "\n",
      "Fold: 2  Epoch: 727  Training loss = 2.9574  Validation loss = 3.1418  \n",
      "\n",
      "Fold: 2  Epoch: 728  Training loss = 2.9573  Validation loss = 3.1417  \n",
      "\n",
      "Fold: 2  Epoch: 729  Training loss = 2.9573  Validation loss = 3.1416  \n",
      "\n",
      "Fold: 2  Epoch: 730  Training loss = 2.9573  Validation loss = 3.1415  \n",
      "\n",
      "Fold: 2  Epoch: 731  Training loss = 2.9572  Validation loss = 3.1415  \n",
      "\n",
      "Fold: 2  Epoch: 732  Training loss = 2.9572  Validation loss = 3.1414  \n",
      "\n",
      "Fold: 2  Epoch: 733  Training loss = 2.9571  Validation loss = 3.1413  \n",
      "\n",
      "Fold: 2  Epoch: 734  Training loss = 2.9571  Validation loss = 3.1412  \n",
      "\n",
      "Fold: 2  Epoch: 735  Training loss = 2.9570  Validation loss = 3.1411  \n",
      "\n",
      "Fold: 2  Epoch: 736  Training loss = 2.9569  Validation loss = 3.1410  \n",
      "\n",
      "Fold: 2  Epoch: 737  Training loss = 2.9569  Validation loss = 3.1409  \n",
      "\n",
      "Fold: 2  Epoch: 738  Training loss = 2.9568  Validation loss = 3.1408  \n",
      "\n",
      "Fold: 2  Epoch: 739  Training loss = 2.9568  Validation loss = 3.1407  \n",
      "\n",
      "Fold: 2  Epoch: 740  Training loss = 2.9567  Validation loss = 3.1406  \n",
      "\n",
      "Fold: 2  Epoch: 741  Training loss = 2.9567  Validation loss = 3.1405  \n",
      "\n",
      "Fold: 2  Epoch: 742  Training loss = 2.9566  Validation loss = 3.1404  \n",
      "\n",
      "Fold: 2  Epoch: 743  Training loss = 2.9566  Validation loss = 3.1404  \n",
      "\n",
      "Fold: 2  Epoch: 744  Training loss = 2.9565  Validation loss = 3.1403  \n",
      "\n",
      "Fold: 2  Epoch: 745  Training loss = 2.9564  Validation loss = 3.1402  \n",
      "\n",
      "Fold: 2  Epoch: 746  Training loss = 2.9564  Validation loss = 3.1401  \n",
      "\n",
      "Fold: 2  Epoch: 747  Training loss = 2.9564  Validation loss = 3.1400  \n",
      "\n",
      "Fold: 2  Epoch: 748  Training loss = 2.9563  Validation loss = 3.1399  \n",
      "\n",
      "Fold: 2  Epoch: 749  Training loss = 2.9563  Validation loss = 3.1398  \n",
      "\n",
      "Fold: 2  Epoch: 750  Training loss = 2.9562  Validation loss = 3.1397  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 750  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.9692  Validation loss = 4.3392  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.9692  Validation loss = 4.3391  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.9691  Validation loss = 4.3390  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.9691  Validation loss = 4.3389  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.9690  Validation loss = 4.3387  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.9689  Validation loss = 4.3385  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.9689  Validation loss = 4.3384  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.9688  Validation loss = 4.3383  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.9688  Validation loss = 4.3382  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.9687  Validation loss = 4.3381  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.9686  Validation loss = 4.3379  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.9686  Validation loss = 4.3378  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.9685  Validation loss = 4.3376  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.9685  Validation loss = 4.3375  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.9684  Validation loss = 4.3374  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.9683  Validation loss = 4.3372  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.9683  Validation loss = 4.3371  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.9682  Validation loss = 4.3370  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.9681  Validation loss = 4.3368  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.9681  Validation loss = 4.3366  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.9680  Validation loss = 4.3364  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.9679  Validation loss = 4.3363  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.9679  Validation loss = 4.3361  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.9678  Validation loss = 4.3360  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.9678  Validation loss = 4.3359  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.9677  Validation loss = 4.3357  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.9676  Validation loss = 4.3356  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.9676  Validation loss = 4.3355  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.9675  Validation loss = 4.3353  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.9675  Validation loss = 4.3352  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.9674  Validation loss = 4.3351  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.9674  Validation loss = 4.3350  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.9673  Validation loss = 4.3348  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.9672  Validation loss = 4.3347  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.9672  Validation loss = 4.3346  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.9671  Validation loss = 4.3344  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.9671  Validation loss = 4.3343  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.9670  Validation loss = 4.3342  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.9670  Validation loss = 4.3341  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.9669  Validation loss = 4.3340  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.9668  Validation loss = 4.3338  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.9668  Validation loss = 4.3337  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.9667  Validation loss = 4.3336  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.9667  Validation loss = 4.3334  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.9666  Validation loss = 4.3333  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.9666  Validation loss = 4.3332  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.9665  Validation loss = 4.3331  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.9664  Validation loss = 4.3329  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.9664  Validation loss = 4.3328  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.9663  Validation loss = 4.3326  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.9663  Validation loss = 4.3325  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.9662  Validation loss = 4.3323  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.9661  Validation loss = 4.3322  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.9661  Validation loss = 4.3321  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.9660  Validation loss = 4.3320  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.9660  Validation loss = 4.3318  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.9659  Validation loss = 4.3317  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.9658  Validation loss = 4.3315  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.9658  Validation loss = 4.3314  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.9657  Validation loss = 4.3312  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.9656  Validation loss = 4.3311  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.9655  Validation loss = 4.3309  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.9655  Validation loss = 4.3307  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.9654  Validation loss = 4.3306  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.9654  Validation loss = 4.3304  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.9653  Validation loss = 4.3303  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.9652  Validation loss = 4.3302  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.9652  Validation loss = 4.3301  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.9651  Validation loss = 4.3299  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.9650  Validation loss = 4.3297  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.9650  Validation loss = 4.3296  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.9649  Validation loss = 4.3294  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.9648  Validation loss = 4.3293  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.9648  Validation loss = 4.3292  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.9647  Validation loss = 4.3291  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.9647  Validation loss = 4.3289  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.9646  Validation loss = 4.3288  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.9645  Validation loss = 4.3287  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.9645  Validation loss = 4.3285  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.9644  Validation loss = 4.3284  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.9643  Validation loss = 4.3282  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.9643  Validation loss = 4.3281  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.9642  Validation loss = 4.3280  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.9642  Validation loss = 4.3279  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.9641  Validation loss = 4.3278  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.9641  Validation loss = 4.3276  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.9640  Validation loss = 4.3275  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.9640  Validation loss = 4.3274  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.9639  Validation loss = 4.3273  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.9638  Validation loss = 4.3271  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.9637  Validation loss = 4.3269  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.9637  Validation loss = 4.3268  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.9636  Validation loss = 4.3267  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.9636  Validation loss = 4.3266  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.9635  Validation loss = 4.3264  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.9635  Validation loss = 4.3263  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.9634  Validation loss = 4.3262  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.9633  Validation loss = 4.3260  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.9633  Validation loss = 4.3259  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.9632  Validation loss = 4.3257  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.9632  Validation loss = 4.3256  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.9631  Validation loss = 4.3254  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.9631  Validation loss = 4.3253  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.9630  Validation loss = 4.3252  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.9629  Validation loss = 4.3250  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.9628  Validation loss = 4.3248  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.9628  Validation loss = 4.3247  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.9627  Validation loss = 4.3246  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.9626  Validation loss = 4.3244  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.9626  Validation loss = 4.3243  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.9626  Validation loss = 4.3242  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.9625  Validation loss = 4.3241  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.9624  Validation loss = 4.3240  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.9624  Validation loss = 4.3239  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.9623  Validation loss = 4.3238  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.9623  Validation loss = 4.3236  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.9622  Validation loss = 4.3235  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.9621  Validation loss = 4.3234  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.9621  Validation loss = 4.3232  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.9620  Validation loss = 4.3232  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.9620  Validation loss = 4.3231  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.9619  Validation loss = 4.3229  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.9619  Validation loss = 4.3228  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.9618  Validation loss = 4.3227  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.9618  Validation loss = 4.3226  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.9617  Validation loss = 4.3225  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.9617  Validation loss = 4.3224  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.9616  Validation loss = 4.3222  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.9615  Validation loss = 4.3221  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.9615  Validation loss = 4.3220  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.9614  Validation loss = 4.3219  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.9613  Validation loss = 4.3217  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.9613  Validation loss = 4.3215  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.9612  Validation loss = 4.3213  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.9611  Validation loss = 4.3212  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.9611  Validation loss = 4.3211  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.9610  Validation loss = 4.3208  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.9609  Validation loss = 4.3207  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.9609  Validation loss = 4.3206  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.9608  Validation loss = 4.3204  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.9607  Validation loss = 4.3203  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.9607  Validation loss = 4.3201  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.9606  Validation loss = 4.3199  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.9605  Validation loss = 4.3199  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.9605  Validation loss = 4.3197  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.9604  Validation loss = 4.3196  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.9604  Validation loss = 4.3195  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.9603  Validation loss = 4.3193  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.9602  Validation loss = 4.3192  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.9602  Validation loss = 4.3190  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.9601  Validation loss = 4.3189  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.9600  Validation loss = 4.3187  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.9600  Validation loss = 4.3186  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.9599  Validation loss = 4.3185  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.9599  Validation loss = 4.3184  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.9598  Validation loss = 4.3183  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.9598  Validation loss = 4.3181  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.9597  Validation loss = 4.3180  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.9596  Validation loss = 4.3179  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.9596  Validation loss = 4.3177  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.9595  Validation loss = 4.3176  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.9594  Validation loss = 4.3174  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.9594  Validation loss = 4.3173  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.9593  Validation loss = 4.3172  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.9592  Validation loss = 4.3170  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.9592  Validation loss = 4.3169  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.9591  Validation loss = 4.3167  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.9590  Validation loss = 4.3166  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.9590  Validation loss = 4.3165  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.9590  Validation loss = 4.3164  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.9589  Validation loss = 4.3163  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.9588  Validation loss = 4.3161  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.9588  Validation loss = 4.3160  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.9587  Validation loss = 4.3158  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.9587  Validation loss = 4.3157  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.9586  Validation loss = 4.3156  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.9585  Validation loss = 4.3154  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.9585  Validation loss = 4.3153  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.9584  Validation loss = 4.3151  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.9583  Validation loss = 4.3149  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.9583  Validation loss = 4.3148  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.9582  Validation loss = 4.3146  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.9581  Validation loss = 4.3145  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.9581  Validation loss = 4.3143  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.9580  Validation loss = 4.3142  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.9580  Validation loss = 4.3141  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.9579  Validation loss = 4.3140  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.9578  Validation loss = 4.3138  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.9578  Validation loss = 4.3137  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.9577  Validation loss = 4.3135  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.9577  Validation loss = 4.3134  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.9576  Validation loss = 4.3133  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.9576  Validation loss = 4.3131  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.9575  Validation loss = 4.3130  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.9575  Validation loss = 4.3129  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.9574  Validation loss = 4.3128  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.9573  Validation loss = 4.3127  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.9573  Validation loss = 4.3125  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.9572  Validation loss = 4.3123  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.9571  Validation loss = 4.3122  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.9571  Validation loss = 4.3121  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.9570  Validation loss = 4.3120  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.9570  Validation loss = 4.3118  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.9569  Validation loss = 4.3117  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.9568  Validation loss = 4.3115  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.9567  Validation loss = 4.3113  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.9567  Validation loss = 4.3112  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.9566  Validation loss = 4.3111  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.9566  Validation loss = 4.3110  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.9565  Validation loss = 4.3108  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.9565  Validation loss = 4.3107  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.9564  Validation loss = 4.3106  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.9563  Validation loss = 4.3104  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.9563  Validation loss = 4.3103  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.9563  Validation loss = 4.3102  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.9562  Validation loss = 4.3101  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.9561  Validation loss = 4.3100  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.9561  Validation loss = 4.3099  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.9560  Validation loss = 4.3097  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.9559  Validation loss = 4.3096  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.9559  Validation loss = 4.3094  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.9558  Validation loss = 4.3093  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.9558  Validation loss = 4.3092  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.9557  Validation loss = 4.3090  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.9556  Validation loss = 4.3089  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.9556  Validation loss = 4.3088  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.9555  Validation loss = 4.3086  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.9555  Validation loss = 4.3085  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.9554  Validation loss = 4.3084  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.9553  Validation loss = 4.3082  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.9553  Validation loss = 4.3081  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.9552  Validation loss = 4.3080  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.9551  Validation loss = 4.3078  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.9551  Validation loss = 4.3077  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.9550  Validation loss = 4.3076  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.9550  Validation loss = 4.3075  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.9549  Validation loss = 4.3073  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.9548  Validation loss = 4.3072  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.9548  Validation loss = 4.3071  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.9547  Validation loss = 4.3070  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.9547  Validation loss = 4.3068  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.9546  Validation loss = 4.3067  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.9546  Validation loss = 4.3066  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.9545  Validation loss = 4.3065  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.9545  Validation loss = 4.3064  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.9544  Validation loss = 4.3062  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.9543  Validation loss = 4.3060  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.9543  Validation loss = 4.3059  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.9542  Validation loss = 4.3057  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.9542  Validation loss = 4.3056  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.9541  Validation loss = 4.3055  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.9540  Validation loss = 4.3053  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.9540  Validation loss = 4.3052  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.9539  Validation loss = 4.3050  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.9538  Validation loss = 4.3049  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.9538  Validation loss = 4.3048  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.9537  Validation loss = 4.3047  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.9537  Validation loss = 4.3045  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.9536  Validation loss = 4.3044  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.9536  Validation loss = 4.3043  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.9535  Validation loss = 4.3042  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.9534  Validation loss = 4.3040  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.9534  Validation loss = 4.3039  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.9533  Validation loss = 4.3038  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.9533  Validation loss = 4.3037  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.9532  Validation loss = 4.3035  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.9532  Validation loss = 4.3034  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.9531  Validation loss = 4.3033  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.9530  Validation loss = 4.3032  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.9530  Validation loss = 4.3030  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.9529  Validation loss = 4.3028  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.9529  Validation loss = 4.3027  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.9528  Validation loss = 4.3026  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.9528  Validation loss = 4.3025  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.9527  Validation loss = 4.3023  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.9527  Validation loss = 4.3023  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.9526  Validation loss = 4.3021  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.9525  Validation loss = 4.3020  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.9525  Validation loss = 4.3018  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.9524  Validation loss = 4.3017  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.9524  Validation loss = 4.3016  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.9523  Validation loss = 4.3015  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.9523  Validation loss = 4.3014  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.9522  Validation loss = 4.3012  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.9521  Validation loss = 4.3010  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.9521  Validation loss = 4.3009  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.9520  Validation loss = 4.3007  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.9520  Validation loss = 4.3006  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.9519  Validation loss = 4.3005  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.9519  Validation loss = 4.3004  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.9518  Validation loss = 4.3002  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.9517  Validation loss = 4.3001  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.9517  Validation loss = 4.3000  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.9516  Validation loss = 4.2998  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.9516  Validation loss = 4.2997  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.9515  Validation loss = 4.2995  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.9514  Validation loss = 4.2994  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.9514  Validation loss = 4.2993  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.9513  Validation loss = 4.2992  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.9513  Validation loss = 4.2991  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.9512  Validation loss = 4.2989  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.9512  Validation loss = 4.2988  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.9511  Validation loss = 4.2987  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.9510  Validation loss = 4.2985  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.9509  Validation loss = 4.2983  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.9509  Validation loss = 4.2982  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.9508  Validation loss = 4.2981  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.9507  Validation loss = 4.2979  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.9507  Validation loss = 4.2978  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.9506  Validation loss = 4.2977  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.9506  Validation loss = 4.2975  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.9505  Validation loss = 4.2974  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.9505  Validation loss = 4.2973  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.9504  Validation loss = 4.2972  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.9504  Validation loss = 4.2971  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.9503  Validation loss = 4.2970  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.9503  Validation loss = 4.2968  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.9502  Validation loss = 4.2967  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.9501  Validation loss = 4.2966  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.9501  Validation loss = 4.2965  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.9500  Validation loss = 4.2964  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.9500  Validation loss = 4.2962  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.9499  Validation loss = 4.2961  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.9499  Validation loss = 4.2959  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.9498  Validation loss = 4.2958  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.9497  Validation loss = 4.2956  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.9497  Validation loss = 4.2955  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.9496  Validation loss = 4.2954  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.9496  Validation loss = 4.2953  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.9495  Validation loss = 4.2951  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.9495  Validation loss = 4.2950  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.9494  Validation loss = 4.2949  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.9494  Validation loss = 4.2948  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.9493  Validation loss = 4.2946  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.9492  Validation loss = 4.2945  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.9492  Validation loss = 4.2944  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.9491  Validation loss = 4.2942  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.9490  Validation loss = 4.2941  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.9490  Validation loss = 4.2940  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.9489  Validation loss = 4.2939  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.9489  Validation loss = 4.2938  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.9488  Validation loss = 4.2936  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.9487  Validation loss = 4.2935  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.9487  Validation loss = 4.2933  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.9486  Validation loss = 4.2932  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.9486  Validation loss = 4.2931  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.9485  Validation loss = 4.2929  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.9484  Validation loss = 4.2928  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.9484  Validation loss = 4.2926  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.9483  Validation loss = 4.2925  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.9483  Validation loss = 4.2924  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.9482  Validation loss = 4.2922  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.9481  Validation loss = 4.2921  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.9481  Validation loss = 4.2920  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.9480  Validation loss = 4.2919  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.9480  Validation loss = 4.2918  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.9479  Validation loss = 4.2916  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.9479  Validation loss = 4.2915  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.9478  Validation loss = 4.2914  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.9477  Validation loss = 4.2912  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.9477  Validation loss = 4.2911  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.9476  Validation loss = 4.2909  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.9476  Validation loss = 4.2908  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.9475  Validation loss = 4.2907  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.9474  Validation loss = 4.2905  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.9474  Validation loss = 4.2904  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.9473  Validation loss = 4.2903  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.9472  Validation loss = 4.2902  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.9472  Validation loss = 4.2900  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.9471  Validation loss = 4.2899  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.9471  Validation loss = 4.2898  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.9470  Validation loss = 4.2896  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.9470  Validation loss = 4.2895  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.9469  Validation loss = 4.2894  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.9468  Validation loss = 4.2893  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.9468  Validation loss = 4.2892  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.9467  Validation loss = 4.2891  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.9467  Validation loss = 4.2890  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.9466  Validation loss = 4.2888  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.9466  Validation loss = 4.2887  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.9465  Validation loss = 4.2886  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.9465  Validation loss = 4.2885  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.9464  Validation loss = 4.2883  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.9464  Validation loss = 4.2882  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.9463  Validation loss = 4.2881  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.9463  Validation loss = 4.2880  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.9462  Validation loss = 4.2878  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.9461  Validation loss = 4.2876  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.9461  Validation loss = 4.2875  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.9460  Validation loss = 4.2874  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.9459  Validation loss = 4.2873  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.9459  Validation loss = 4.2871  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.9458  Validation loss = 4.2870  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.9458  Validation loss = 4.2869  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.9457  Validation loss = 4.2868  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.9457  Validation loss = 4.2867  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.9456  Validation loss = 4.2865  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.9455  Validation loss = 4.2863  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.9455  Validation loss = 4.2862  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.9454  Validation loss = 4.2860  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.9453  Validation loss = 4.2859  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.9453  Validation loss = 4.2857  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.9452  Validation loss = 4.2856  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.9452  Validation loss = 4.2855  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.9451  Validation loss = 4.2853  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.9451  Validation loss = 4.2852  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.9450  Validation loss = 4.2851  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.9450  Validation loss = 4.2850  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.9449  Validation loss = 4.2848  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.9448  Validation loss = 4.2847  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.9448  Validation loss = 4.2846  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.9448  Validation loss = 4.2845  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.9447  Validation loss = 4.2844  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.9446  Validation loss = 4.2842  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.9446  Validation loss = 4.2841  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.9445  Validation loss = 4.2839  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.9445  Validation loss = 4.2838  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.9444  Validation loss = 4.2837  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.9444  Validation loss = 4.2836  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.9443  Validation loss = 4.2835  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.9442  Validation loss = 4.2833  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.9442  Validation loss = 4.2832  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.9441  Validation loss = 4.2830  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.9441  Validation loss = 4.2829  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.9440  Validation loss = 4.2828  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.9440  Validation loss = 4.2827  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.9439  Validation loss = 4.2826  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.9439  Validation loss = 4.2824  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.9438  Validation loss = 4.2823  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.9437  Validation loss = 4.2821  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.9437  Validation loss = 4.2820  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.9436  Validation loss = 4.2819  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.9436  Validation loss = 4.2817  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.9435  Validation loss = 4.2816  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.9434  Validation loss = 4.2814  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.9434  Validation loss = 4.2813  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.9433  Validation loss = 4.2811  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.9433  Validation loss = 4.2810  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.9432  Validation loss = 4.2809  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.9431  Validation loss = 4.2807  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.9431  Validation loss = 4.2806  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.9430  Validation loss = 4.2805  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.9430  Validation loss = 4.2803  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.9429  Validation loss = 4.2802  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.9429  Validation loss = 4.2801  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.9428  Validation loss = 4.2800  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.9428  Validation loss = 4.2799  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.9427  Validation loss = 4.2797  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.9426  Validation loss = 4.2796  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.9426  Validation loss = 4.2795  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.9425  Validation loss = 4.2793  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.9425  Validation loss = 4.2792  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.9424  Validation loss = 4.2791  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.9423  Validation loss = 4.2789  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.9423  Validation loss = 4.2788  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.9422  Validation loss = 4.2787  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.9422  Validation loss = 4.2786  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.9421  Validation loss = 4.2785  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.9421  Validation loss = 4.2783  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.9420  Validation loss = 4.2782  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.9419  Validation loss = 4.2781  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.9419  Validation loss = 4.2780  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.9418  Validation loss = 4.2779  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.9418  Validation loss = 4.2778  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.9417  Validation loss = 4.2776  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.9417  Validation loss = 4.2775  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.9416  Validation loss = 4.2773  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.9416  Validation loss = 4.2772  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.9415  Validation loss = 4.2771  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.9415  Validation loss = 4.2770  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.9414  Validation loss = 4.2768  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.9413  Validation loss = 4.2767  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.9413  Validation loss = 4.2765  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.9412  Validation loss = 4.2764  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.9411  Validation loss = 4.2763  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.9411  Validation loss = 4.2762  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.9411  Validation loss = 4.2761  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.9410  Validation loss = 4.2760  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.9409  Validation loss = 4.2759  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.9409  Validation loss = 4.2758  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.9409  Validation loss = 4.2757  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.9408  Validation loss = 4.2755  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.9407  Validation loss = 4.2754  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.9407  Validation loss = 4.2752  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.9406  Validation loss = 4.2751  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.9406  Validation loss = 4.2750  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.9405  Validation loss = 4.2749  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.9405  Validation loss = 4.2748  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.9404  Validation loss = 4.2747  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.9404  Validation loss = 4.2746  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.9403  Validation loss = 4.2744  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.9402  Validation loss = 4.2743  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.9402  Validation loss = 4.2742  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.9402  Validation loss = 4.2741  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.9401  Validation loss = 4.2739  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.9400  Validation loss = 4.2738  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.9400  Validation loss = 4.2736  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.9399  Validation loss = 4.2735  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.9398  Validation loss = 4.2734  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.9398  Validation loss = 4.2732  \n",
      "\n",
      "Fold: 3  Epoch: 501  Training loss = 1.9397  Validation loss = 4.2731  \n",
      "\n",
      "Fold: 3  Epoch: 502  Training loss = 1.9397  Validation loss = 4.2730  \n",
      "\n",
      "Fold: 3  Epoch: 503  Training loss = 1.9396  Validation loss = 4.2728  \n",
      "\n",
      "Fold: 3  Epoch: 504  Training loss = 1.9395  Validation loss = 4.2727  \n",
      "\n",
      "Fold: 3  Epoch: 505  Training loss = 1.9395  Validation loss = 4.2726  \n",
      "\n",
      "Fold: 3  Epoch: 506  Training loss = 1.9394  Validation loss = 4.2724  \n",
      "\n",
      "Fold: 3  Epoch: 507  Training loss = 1.9394  Validation loss = 4.2723  \n",
      "\n",
      "Fold: 3  Epoch: 508  Training loss = 1.9393  Validation loss = 4.2722  \n",
      "\n",
      "Fold: 3  Epoch: 509  Training loss = 1.9393  Validation loss = 4.2721  \n",
      "\n",
      "Fold: 3  Epoch: 510  Training loss = 1.9392  Validation loss = 4.2720  \n",
      "\n",
      "Fold: 3  Epoch: 511  Training loss = 1.9391  Validation loss = 4.2718  \n",
      "\n",
      "Fold: 3  Epoch: 512  Training loss = 1.9391  Validation loss = 4.2717  \n",
      "\n",
      "Fold: 3  Epoch: 513  Training loss = 1.9390  Validation loss = 4.2716  \n",
      "\n",
      "Fold: 3  Epoch: 514  Training loss = 1.9390  Validation loss = 4.2714  \n",
      "\n",
      "Fold: 3  Epoch: 515  Training loss = 1.9389  Validation loss = 4.2713  \n",
      "\n",
      "Fold: 3  Epoch: 516  Training loss = 1.9389  Validation loss = 4.2712  \n",
      "\n",
      "Fold: 3  Epoch: 517  Training loss = 1.9388  Validation loss = 4.2711  \n",
      "\n",
      "Fold: 3  Epoch: 518  Training loss = 1.9387  Validation loss = 4.2709  \n",
      "\n",
      "Fold: 3  Epoch: 519  Training loss = 1.9387  Validation loss = 4.2708  \n",
      "\n",
      "Fold: 3  Epoch: 520  Training loss = 1.9386  Validation loss = 4.2706  \n",
      "\n",
      "Fold: 3  Epoch: 521  Training loss = 1.9385  Validation loss = 4.2704  \n",
      "\n",
      "Fold: 3  Epoch: 522  Training loss = 1.9385  Validation loss = 4.2703  \n",
      "\n",
      "Fold: 3  Epoch: 523  Training loss = 1.9384  Validation loss = 4.2701  \n",
      "\n",
      "Fold: 3  Epoch: 524  Training loss = 1.9383  Validation loss = 4.2700  \n",
      "\n",
      "Fold: 3  Epoch: 525  Training loss = 1.9383  Validation loss = 4.2698  \n",
      "\n",
      "Fold: 3  Epoch: 526  Training loss = 1.9382  Validation loss = 4.2697  \n",
      "\n",
      "Fold: 3  Epoch: 527  Training loss = 1.9382  Validation loss = 4.2696  \n",
      "\n",
      "Fold: 3  Epoch: 528  Training loss = 1.9381  Validation loss = 4.2695  \n",
      "\n",
      "Fold: 3  Epoch: 529  Training loss = 1.9381  Validation loss = 4.2693  \n",
      "\n",
      "Fold: 3  Epoch: 530  Training loss = 1.9380  Validation loss = 4.2692  \n",
      "\n",
      "Fold: 3  Epoch: 531  Training loss = 1.9379  Validation loss = 4.2691  \n",
      "\n",
      "Fold: 3  Epoch: 532  Training loss = 1.9379  Validation loss = 4.2690  \n",
      "\n",
      "Fold: 3  Epoch: 533  Training loss = 1.9379  Validation loss = 4.2689  \n",
      "\n",
      "Fold: 3  Epoch: 534  Training loss = 1.9378  Validation loss = 4.2687  \n",
      "\n",
      "Fold: 3  Epoch: 535  Training loss = 1.9377  Validation loss = 4.2686  \n",
      "\n",
      "Fold: 3  Epoch: 536  Training loss = 1.9377  Validation loss = 4.2685  \n",
      "\n",
      "Fold: 3  Epoch: 537  Training loss = 1.9376  Validation loss = 4.2684  \n",
      "\n",
      "Fold: 3  Epoch: 538  Training loss = 1.9376  Validation loss = 4.2683  \n",
      "\n",
      "Fold: 3  Epoch: 539  Training loss = 1.9375  Validation loss = 4.2682  \n",
      "\n",
      "Fold: 3  Epoch: 540  Training loss = 1.9375  Validation loss = 4.2680  \n",
      "\n",
      "Fold: 3  Epoch: 541  Training loss = 1.9374  Validation loss = 4.2679  \n",
      "\n",
      "Fold: 3  Epoch: 542  Training loss = 1.9374  Validation loss = 4.2678  \n",
      "\n",
      "Fold: 3  Epoch: 543  Training loss = 1.9373  Validation loss = 4.2677  \n",
      "\n",
      "Fold: 3  Epoch: 544  Training loss = 1.9373  Validation loss = 4.2675  \n",
      "\n",
      "Fold: 3  Epoch: 545  Training loss = 1.9372  Validation loss = 4.2674  \n",
      "\n",
      "Fold: 3  Epoch: 546  Training loss = 1.9372  Validation loss = 4.2673  \n",
      "\n",
      "Fold: 3  Epoch: 547  Training loss = 1.9371  Validation loss = 4.2672  \n",
      "\n",
      "Fold: 3  Epoch: 548  Training loss = 1.9371  Validation loss = 4.2671  \n",
      "\n",
      "Fold: 3  Epoch: 549  Training loss = 1.9370  Validation loss = 4.2670  \n",
      "\n",
      "Fold: 3  Epoch: 550  Training loss = 1.9370  Validation loss = 4.2668  \n",
      "\n",
      "Fold: 3  Epoch: 551  Training loss = 1.9369  Validation loss = 4.2667  \n",
      "\n",
      "Fold: 3  Epoch: 552  Training loss = 1.9368  Validation loss = 4.2665  \n",
      "\n",
      "Fold: 3  Epoch: 553  Training loss = 1.9368  Validation loss = 4.2664  \n",
      "\n",
      "Fold: 3  Epoch: 554  Training loss = 1.9367  Validation loss = 4.2662  \n",
      "\n",
      "Fold: 3  Epoch: 555  Training loss = 1.9367  Validation loss = 4.2661  \n",
      "\n",
      "Fold: 3  Epoch: 556  Training loss = 1.9366  Validation loss = 4.2660  \n",
      "\n",
      "Fold: 3  Epoch: 557  Training loss = 1.9366  Validation loss = 4.2659  \n",
      "\n",
      "Fold: 3  Epoch: 558  Training loss = 1.9365  Validation loss = 4.2657  \n",
      "\n",
      "Fold: 3  Epoch: 559  Training loss = 1.9364  Validation loss = 4.2656  \n",
      "\n",
      "Fold: 3  Epoch: 560  Training loss = 1.9364  Validation loss = 4.2655  \n",
      "\n",
      "Fold: 3  Epoch: 561  Training loss = 1.9363  Validation loss = 4.2653  \n",
      "\n",
      "Fold: 3  Epoch: 562  Training loss = 1.9362  Validation loss = 4.2651  \n",
      "\n",
      "Fold: 3  Epoch: 563  Training loss = 1.9362  Validation loss = 4.2650  \n",
      "\n",
      "Fold: 3  Epoch: 564  Training loss = 1.9361  Validation loss = 4.2648  \n",
      "\n",
      "Fold: 3  Epoch: 565  Training loss = 1.9360  Validation loss = 4.2647  \n",
      "\n",
      "Fold: 3  Epoch: 566  Training loss = 1.9360  Validation loss = 4.2646  \n",
      "\n",
      "Fold: 3  Epoch: 567  Training loss = 1.9359  Validation loss = 4.2644  \n",
      "\n",
      "Fold: 3  Epoch: 568  Training loss = 1.9359  Validation loss = 4.2643  \n",
      "\n",
      "Fold: 3  Epoch: 569  Training loss = 1.9358  Validation loss = 4.2642  \n",
      "\n",
      "Fold: 3  Epoch: 570  Training loss = 1.9358  Validation loss = 4.2641  \n",
      "\n",
      "Fold: 3  Epoch: 571  Training loss = 1.9357  Validation loss = 4.2640  \n",
      "\n",
      "Fold: 3  Epoch: 572  Training loss = 1.9357  Validation loss = 4.2638  \n",
      "\n",
      "Fold: 3  Epoch: 573  Training loss = 1.9356  Validation loss = 4.2636  \n",
      "\n",
      "Fold: 3  Epoch: 574  Training loss = 1.9355  Validation loss = 4.2635  \n",
      "\n",
      "Fold: 3  Epoch: 575  Training loss = 1.9355  Validation loss = 4.2634  \n",
      "\n",
      "Fold: 3  Epoch: 576  Training loss = 1.9354  Validation loss = 4.2633  \n",
      "\n",
      "Fold: 3  Epoch: 577  Training loss = 1.9354  Validation loss = 4.2631  \n",
      "\n",
      "Fold: 3  Epoch: 578  Training loss = 1.9353  Validation loss = 4.2630  \n",
      "\n",
      "Fold: 3  Epoch: 579  Training loss = 1.9352  Validation loss = 4.2628  \n",
      "\n",
      "Fold: 3  Epoch: 580  Training loss = 1.9352  Validation loss = 4.2627  \n",
      "\n",
      "Fold: 3  Epoch: 581  Training loss = 1.9351  Validation loss = 4.2625  \n",
      "\n",
      "Fold: 3  Epoch: 582  Training loss = 1.9351  Validation loss = 4.2624  \n",
      "\n",
      "Fold: 3  Epoch: 583  Training loss = 1.9350  Validation loss = 4.2623  \n",
      "\n",
      "Fold: 3  Epoch: 584  Training loss = 1.9349  Validation loss = 4.2622  \n",
      "\n",
      "Fold: 3  Epoch: 585  Training loss = 1.9349  Validation loss = 4.2620  \n",
      "\n",
      "Fold: 3  Epoch: 586  Training loss = 1.9348  Validation loss = 4.2619  \n",
      "\n",
      "Fold: 3  Epoch: 587  Training loss = 1.9348  Validation loss = 4.2618  \n",
      "\n",
      "Fold: 3  Epoch: 588  Training loss = 1.9347  Validation loss = 4.2617  \n",
      "\n",
      "Fold: 3  Epoch: 589  Training loss = 1.9347  Validation loss = 4.2615  \n",
      "\n",
      "Fold: 3  Epoch: 590  Training loss = 1.9346  Validation loss = 4.2614  \n",
      "\n",
      "Fold: 3  Epoch: 591  Training loss = 1.9345  Validation loss = 4.2613  \n",
      "\n",
      "Fold: 3  Epoch: 592  Training loss = 1.9345  Validation loss = 4.2611  \n",
      "\n",
      "Fold: 3  Epoch: 593  Training loss = 1.9344  Validation loss = 4.2610  \n",
      "\n",
      "Fold: 3  Epoch: 594  Training loss = 1.9344  Validation loss = 4.2609  \n",
      "\n",
      "Fold: 3  Epoch: 595  Training loss = 1.9343  Validation loss = 4.2607  \n",
      "\n",
      "Fold: 3  Epoch: 596  Training loss = 1.9343  Validation loss = 4.2606  \n",
      "\n",
      "Fold: 3  Epoch: 597  Training loss = 1.9342  Validation loss = 4.2605  \n",
      "\n",
      "Fold: 3  Epoch: 598  Training loss = 1.9341  Validation loss = 4.2603  \n",
      "\n",
      "Fold: 3  Epoch: 599  Training loss = 1.9341  Validation loss = 4.2602  \n",
      "\n",
      "Fold: 3  Epoch: 600  Training loss = 1.9340  Validation loss = 4.2600  \n",
      "\n",
      "Fold: 3  Epoch: 601  Training loss = 1.9340  Validation loss = 4.2599  \n",
      "\n",
      "Fold: 3  Epoch: 602  Training loss = 1.9339  Validation loss = 4.2597  \n",
      "\n",
      "Fold: 3  Epoch: 603  Training loss = 1.9338  Validation loss = 4.2596  \n",
      "\n",
      "Fold: 3  Epoch: 604  Training loss = 1.9338  Validation loss = 4.2594  \n",
      "\n",
      "Fold: 3  Epoch: 605  Training loss = 1.9337  Validation loss = 4.2593  \n",
      "\n",
      "Fold: 3  Epoch: 606  Training loss = 1.9336  Validation loss = 4.2591  \n",
      "\n",
      "Fold: 3  Epoch: 607  Training loss = 1.9336  Validation loss = 4.2590  \n",
      "\n",
      "Fold: 3  Epoch: 608  Training loss = 1.9335  Validation loss = 4.2588  \n",
      "\n",
      "Fold: 3  Epoch: 609  Training loss = 1.9335  Validation loss = 4.2587  \n",
      "\n",
      "Fold: 3  Epoch: 610  Training loss = 1.9334  Validation loss = 4.2585  \n",
      "\n",
      "Fold: 3  Epoch: 611  Training loss = 1.9333  Validation loss = 4.2584  \n",
      "\n",
      "Fold: 3  Epoch: 612  Training loss = 1.9333  Validation loss = 4.2583  \n",
      "\n",
      "Fold: 3  Epoch: 613  Training loss = 1.9332  Validation loss = 4.2582  \n",
      "\n",
      "Fold: 3  Epoch: 614  Training loss = 1.9332  Validation loss = 4.2581  \n",
      "\n",
      "Fold: 3  Epoch: 615  Training loss = 1.9331  Validation loss = 4.2579  \n",
      "\n",
      "Fold: 3  Epoch: 616  Training loss = 1.9331  Validation loss = 4.2578  \n",
      "\n",
      "Fold: 3  Epoch: 617  Training loss = 1.9330  Validation loss = 4.2577  \n",
      "\n",
      "Fold: 3  Epoch: 618  Training loss = 1.9330  Validation loss = 4.2576  \n",
      "\n",
      "Fold: 3  Epoch: 619  Training loss = 1.9329  Validation loss = 4.2574  \n",
      "\n",
      "Fold: 3  Epoch: 620  Training loss = 1.9329  Validation loss = 4.2573  \n",
      "\n",
      "Fold: 3  Epoch: 621  Training loss = 1.9328  Validation loss = 4.2572  \n",
      "\n",
      "Fold: 3  Epoch: 622  Training loss = 1.9327  Validation loss = 4.2570  \n",
      "\n",
      "Fold: 3  Epoch: 623  Training loss = 1.9327  Validation loss = 4.2569  \n",
      "\n",
      "Fold: 3  Epoch: 624  Training loss = 1.9326  Validation loss = 4.2567  \n",
      "\n",
      "Fold: 3  Epoch: 625  Training loss = 1.9325  Validation loss = 4.2566  \n",
      "\n",
      "Fold: 3  Epoch: 626  Training loss = 1.9325  Validation loss = 4.2564  \n",
      "\n",
      "Fold: 3  Epoch: 627  Training loss = 1.9324  Validation loss = 4.2563  \n",
      "\n",
      "Fold: 3  Epoch: 628  Training loss = 1.9324  Validation loss = 4.2562  \n",
      "\n",
      "Fold: 3  Epoch: 629  Training loss = 1.9323  Validation loss = 4.2560  \n",
      "\n",
      "Fold: 3  Epoch: 630  Training loss = 1.9323  Validation loss = 4.2559  \n",
      "\n",
      "Fold: 3  Epoch: 631  Training loss = 1.9322  Validation loss = 4.2558  \n",
      "\n",
      "Fold: 3  Epoch: 632  Training loss = 1.9322  Validation loss = 4.2557  \n",
      "\n",
      "Fold: 3  Epoch: 633  Training loss = 1.9321  Validation loss = 4.2556  \n",
      "\n",
      "Fold: 3  Epoch: 634  Training loss = 1.9321  Validation loss = 4.2555  \n",
      "\n",
      "Fold: 3  Epoch: 635  Training loss = 1.9320  Validation loss = 4.2554  \n",
      "\n",
      "Fold: 3  Epoch: 636  Training loss = 1.9320  Validation loss = 4.2553  \n",
      "\n",
      "Fold: 3  Epoch: 637  Training loss = 1.9319  Validation loss = 4.2552  \n",
      "\n",
      "Fold: 3  Epoch: 638  Training loss = 1.9319  Validation loss = 4.2550  \n",
      "\n",
      "Fold: 3  Epoch: 639  Training loss = 1.9318  Validation loss = 4.2550  \n",
      "\n",
      "Fold: 3  Epoch: 640  Training loss = 1.9318  Validation loss = 4.2548  \n",
      "\n",
      "Fold: 3  Epoch: 641  Training loss = 1.9317  Validation loss = 4.2547  \n",
      "\n",
      "Fold: 3  Epoch: 642  Training loss = 1.9316  Validation loss = 4.2546  \n",
      "\n",
      "Fold: 3  Epoch: 643  Training loss = 1.9316  Validation loss = 4.2544  \n",
      "\n",
      "Fold: 3  Epoch: 644  Training loss = 1.9315  Validation loss = 4.2543  \n",
      "\n",
      "Fold: 3  Epoch: 645  Training loss = 1.9315  Validation loss = 4.2541  \n",
      "\n",
      "Fold: 3  Epoch: 646  Training loss = 1.9314  Validation loss = 4.2540  \n",
      "\n",
      "Fold: 3  Epoch: 647  Training loss = 1.9313  Validation loss = 4.2539  \n",
      "\n",
      "Fold: 3  Epoch: 648  Training loss = 1.9313  Validation loss = 4.2538  \n",
      "\n",
      "Fold: 3  Epoch: 649  Training loss = 1.9312  Validation loss = 4.2537  \n",
      "\n",
      "Fold: 3  Epoch: 650  Training loss = 1.9312  Validation loss = 4.2535  \n",
      "\n",
      "Fold: 3  Epoch: 651  Training loss = 1.9311  Validation loss = 4.2534  \n",
      "\n",
      "Fold: 3  Epoch: 652  Training loss = 1.9311  Validation loss = 4.2533  \n",
      "\n",
      "Fold: 3  Epoch: 653  Training loss = 1.9310  Validation loss = 4.2531  \n",
      "\n",
      "Fold: 3  Epoch: 654  Training loss = 1.9310  Validation loss = 4.2530  \n",
      "\n",
      "Fold: 3  Epoch: 655  Training loss = 1.9309  Validation loss = 4.2529  \n",
      "\n",
      "Fold: 3  Epoch: 656  Training loss = 1.9308  Validation loss = 4.2528  \n",
      "\n",
      "Fold: 3  Epoch: 657  Training loss = 1.9308  Validation loss = 4.2526  \n",
      "\n",
      "Fold: 3  Epoch: 658  Training loss = 1.9307  Validation loss = 4.2525  \n",
      "\n",
      "Fold: 3  Epoch: 659  Training loss = 1.9307  Validation loss = 4.2523  \n",
      "\n",
      "Fold: 3  Epoch: 660  Training loss = 1.9306  Validation loss = 4.2522  \n",
      "\n",
      "Fold: 3  Epoch: 661  Training loss = 1.9306  Validation loss = 4.2521  \n",
      "\n",
      "Fold: 3  Epoch: 662  Training loss = 1.9305  Validation loss = 4.2520  \n",
      "\n",
      "Fold: 3  Epoch: 663  Training loss = 1.9304  Validation loss = 4.2519  \n",
      "\n",
      "Fold: 3  Epoch: 664  Training loss = 1.9304  Validation loss = 4.2518  \n",
      "\n",
      "Fold: 3  Epoch: 665  Training loss = 1.9303  Validation loss = 4.2516  \n",
      "\n",
      "Fold: 3  Epoch: 666  Training loss = 1.9303  Validation loss = 4.2515  \n",
      "\n",
      "Fold: 3  Epoch: 667  Training loss = 1.9302  Validation loss = 4.2513  \n",
      "\n",
      "Fold: 3  Epoch: 668  Training loss = 1.9302  Validation loss = 4.2512  \n",
      "\n",
      "Fold: 3  Epoch: 669  Training loss = 1.9301  Validation loss = 4.2511  \n",
      "\n",
      "Fold: 3  Epoch: 670  Training loss = 1.9301  Validation loss = 4.2510  \n",
      "\n",
      "Fold: 3  Epoch: 671  Training loss = 1.9300  Validation loss = 4.2508  \n",
      "\n",
      "Fold: 3  Epoch: 672  Training loss = 1.9299  Validation loss = 4.2507  \n",
      "\n",
      "Fold: 3  Epoch: 673  Training loss = 1.9299  Validation loss = 4.2505  \n",
      "\n",
      "Fold: 3  Epoch: 674  Training loss = 1.9298  Validation loss = 4.2504  \n",
      "\n",
      "Fold: 3  Epoch: 675  Training loss = 1.9298  Validation loss = 4.2503  \n",
      "\n",
      "Fold: 3  Epoch: 676  Training loss = 1.9297  Validation loss = 4.2501  \n",
      "\n",
      "Fold: 3  Epoch: 677  Training loss = 1.9296  Validation loss = 4.2500  \n",
      "\n",
      "Fold: 3  Epoch: 678  Training loss = 1.9296  Validation loss = 4.2499  \n",
      "\n",
      "Fold: 3  Epoch: 679  Training loss = 1.9295  Validation loss = 4.2497  \n",
      "\n",
      "Fold: 3  Epoch: 680  Training loss = 1.9295  Validation loss = 4.2496  \n",
      "\n",
      "Fold: 3  Epoch: 681  Training loss = 1.9294  Validation loss = 4.2495  \n",
      "\n",
      "Fold: 3  Epoch: 682  Training loss = 1.9294  Validation loss = 4.2494  \n",
      "\n",
      "Fold: 3  Epoch: 683  Training loss = 1.9293  Validation loss = 4.2492  \n",
      "\n",
      "Fold: 3  Epoch: 684  Training loss = 1.9292  Validation loss = 4.2491  \n",
      "\n",
      "Fold: 3  Epoch: 685  Training loss = 1.9292  Validation loss = 4.2489  \n",
      "\n",
      "Fold: 3  Epoch: 686  Training loss = 1.9291  Validation loss = 4.2488  \n",
      "\n",
      "Fold: 3  Epoch: 687  Training loss = 1.9291  Validation loss = 4.2486  \n",
      "\n",
      "Fold: 3  Epoch: 688  Training loss = 1.9290  Validation loss = 4.2484  \n",
      "\n",
      "Fold: 3  Epoch: 689  Training loss = 1.9289  Validation loss = 4.2483  \n",
      "\n",
      "Fold: 3  Epoch: 690  Training loss = 1.9289  Validation loss = 4.2482  \n",
      "\n",
      "Fold: 3  Epoch: 691  Training loss = 1.9288  Validation loss = 4.2480  \n",
      "\n",
      "Fold: 3  Epoch: 692  Training loss = 1.9287  Validation loss = 4.2478  \n",
      "\n",
      "Fold: 3  Epoch: 693  Training loss = 1.9287  Validation loss = 4.2476  \n",
      "\n",
      "Fold: 3  Epoch: 694  Training loss = 1.9286  Validation loss = 4.2476  \n",
      "\n",
      "Fold: 3  Epoch: 695  Training loss = 1.9286  Validation loss = 4.2474  \n",
      "\n",
      "Fold: 3  Epoch: 696  Training loss = 1.9285  Validation loss = 4.2473  \n",
      "\n",
      "Fold: 3  Epoch: 697  Training loss = 1.9285  Validation loss = 4.2472  \n",
      "\n",
      "Fold: 3  Epoch: 698  Training loss = 1.9284  Validation loss = 4.2471  \n",
      "\n",
      "Fold: 3  Epoch: 699  Training loss = 1.9284  Validation loss = 4.2470  \n",
      "\n",
      "Fold: 3  Epoch: 700  Training loss = 1.9283  Validation loss = 4.2469  \n",
      "\n",
      "Fold: 3  Epoch: 701  Training loss = 1.9283  Validation loss = 4.2467  \n",
      "\n",
      "Fold: 3  Epoch: 702  Training loss = 1.9282  Validation loss = 4.2466  \n",
      "\n",
      "Fold: 3  Epoch: 703  Training loss = 1.9282  Validation loss = 4.2465  \n",
      "\n",
      "Fold: 3  Epoch: 704  Training loss = 1.9281  Validation loss = 4.2463  \n",
      "\n",
      "Fold: 3  Epoch: 705  Training loss = 1.9280  Validation loss = 4.2462  \n",
      "\n",
      "Fold: 3  Epoch: 706  Training loss = 1.9280  Validation loss = 4.2461  \n",
      "\n",
      "Fold: 3  Epoch: 707  Training loss = 1.9279  Validation loss = 4.2460  \n",
      "\n",
      "Fold: 3  Epoch: 708  Training loss = 1.9279  Validation loss = 4.2459  \n",
      "\n",
      "Fold: 3  Epoch: 709  Training loss = 1.9278  Validation loss = 4.2458  \n",
      "\n",
      "Fold: 3  Epoch: 710  Training loss = 1.9278  Validation loss = 4.2456  \n",
      "\n",
      "Fold: 3  Epoch: 711  Training loss = 1.9277  Validation loss = 4.2455  \n",
      "\n",
      "Fold: 3  Epoch: 712  Training loss = 1.9277  Validation loss = 4.2454  \n",
      "\n",
      "Fold: 3  Epoch: 713  Training loss = 1.9276  Validation loss = 4.2452  \n",
      "\n",
      "Fold: 3  Epoch: 714  Training loss = 1.9276  Validation loss = 4.2451  \n",
      "\n",
      "Fold: 3  Epoch: 715  Training loss = 1.9275  Validation loss = 4.2450  \n",
      "\n",
      "Fold: 3  Epoch: 716  Training loss = 1.9274  Validation loss = 4.2449  \n",
      "\n",
      "Fold: 3  Epoch: 717  Training loss = 1.9274  Validation loss = 4.2448  \n",
      "\n",
      "Fold: 3  Epoch: 718  Training loss = 1.9273  Validation loss = 4.2447  \n",
      "\n",
      "Fold: 3  Epoch: 719  Training loss = 1.9273  Validation loss = 4.2445  \n",
      "\n",
      "Fold: 3  Epoch: 720  Training loss = 1.9272  Validation loss = 4.2444  \n",
      "\n",
      "Fold: 3  Epoch: 721  Training loss = 1.9272  Validation loss = 4.2442  \n",
      "\n",
      "Fold: 3  Epoch: 722  Training loss = 1.9271  Validation loss = 4.2441  \n",
      "\n",
      "Fold: 3  Epoch: 723  Training loss = 1.9270  Validation loss = 4.2440  \n",
      "\n",
      "Fold: 3  Epoch: 724  Training loss = 1.9270  Validation loss = 4.2438  \n",
      "\n",
      "Fold: 3  Epoch: 725  Training loss = 1.9269  Validation loss = 4.2437  \n",
      "\n",
      "Fold: 3  Epoch: 726  Training loss = 1.9269  Validation loss = 4.2436  \n",
      "\n",
      "Fold: 3  Epoch: 727  Training loss = 1.9268  Validation loss = 4.2435  \n",
      "\n",
      "Fold: 3  Epoch: 728  Training loss = 1.9267  Validation loss = 4.2433  \n",
      "\n",
      "Fold: 3  Epoch: 729  Training loss = 1.9267  Validation loss = 4.2432  \n",
      "\n",
      "Fold: 3  Epoch: 730  Training loss = 1.9266  Validation loss = 4.2430  \n",
      "\n",
      "Fold: 3  Epoch: 731  Training loss = 1.9266  Validation loss = 4.2429  \n",
      "\n",
      "Fold: 3  Epoch: 732  Training loss = 1.9265  Validation loss = 4.2428  \n",
      "\n",
      "Fold: 3  Epoch: 733  Training loss = 1.9265  Validation loss = 4.2426  \n",
      "\n",
      "Fold: 3  Epoch: 734  Training loss = 1.9264  Validation loss = 4.2425  \n",
      "\n",
      "Fold: 3  Epoch: 735  Training loss = 1.9264  Validation loss = 4.2424  \n",
      "\n",
      "Fold: 3  Epoch: 736  Training loss = 1.9263  Validation loss = 4.2422  \n",
      "\n",
      "Fold: 3  Epoch: 737  Training loss = 1.9262  Validation loss = 4.2421  \n",
      "\n",
      "Fold: 3  Epoch: 738  Training loss = 1.9262  Validation loss = 4.2420  \n",
      "\n",
      "Fold: 3  Epoch: 739  Training loss = 1.9261  Validation loss = 4.2418  \n",
      "\n",
      "Fold: 3  Epoch: 740  Training loss = 1.9261  Validation loss = 4.2417  \n",
      "\n",
      "Fold: 3  Epoch: 741  Training loss = 1.9260  Validation loss = 4.2416  \n",
      "\n",
      "Fold: 3  Epoch: 742  Training loss = 1.9260  Validation loss = 4.2414  \n",
      "\n",
      "Fold: 3  Epoch: 743  Training loss = 1.9259  Validation loss = 4.2413  \n",
      "\n",
      "Fold: 3  Epoch: 744  Training loss = 1.9259  Validation loss = 4.2412  \n",
      "\n",
      "Fold: 3  Epoch: 745  Training loss = 1.9258  Validation loss = 4.2411  \n",
      "\n",
      "Fold: 3  Epoch: 746  Training loss = 1.9257  Validation loss = 4.2409  \n",
      "\n",
      "Fold: 3  Epoch: 747  Training loss = 1.9257  Validation loss = 4.2408  \n",
      "\n",
      "Fold: 3  Epoch: 748  Training loss = 1.9256  Validation loss = 4.2406  \n",
      "\n",
      "Fold: 3  Epoch: 749  Training loss = 1.9256  Validation loss = 4.2405  \n",
      "\n",
      "Fold: 3  Epoch: 750  Training loss = 1.9255  Validation loss = 4.2404  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 750  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 2.0662  Validation loss = 5.3873  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 2.0661  Validation loss = 5.3872  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 2.0660  Validation loss = 5.3871  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 2.0659  Validation loss = 5.3870  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 2.0658  Validation loss = 5.3868  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 2.0658  Validation loss = 5.3867  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 2.0657  Validation loss = 5.3865  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 2.0656  Validation loss = 5.3864  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 2.0655  Validation loss = 5.3863  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 2.0655  Validation loss = 5.3862  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 2.0654  Validation loss = 5.3861  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 2.0653  Validation loss = 5.3860  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 2.0652  Validation loss = 5.3859  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 2.0652  Validation loss = 5.3858  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 2.0651  Validation loss = 5.3857  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 2.0650  Validation loss = 5.3856  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 2.0649  Validation loss = 5.3854  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 2.0649  Validation loss = 5.3853  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 2.0648  Validation loss = 5.3852  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 2.0647  Validation loss = 5.3850  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 2.0646  Validation loss = 5.3849  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 2.0645  Validation loss = 5.3848  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 2.0645  Validation loss = 5.3847  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 2.0644  Validation loss = 5.3846  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 2.0643  Validation loss = 5.3845  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 2.0642  Validation loss = 5.3843  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 2.0642  Validation loss = 5.3842  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 2.0641  Validation loss = 5.3841  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 2.0640  Validation loss = 5.3840  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 2.0640  Validation loss = 5.3839  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 2.0639  Validation loss = 5.3838  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 2.0638  Validation loss = 5.3837  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 2.0637  Validation loss = 5.3836  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 2.0637  Validation loss = 5.3835  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 2.0636  Validation loss = 5.3834  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 2.0635  Validation loss = 5.3832  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 2.0634  Validation loss = 5.3831  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 2.0634  Validation loss = 5.3830  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 2.0633  Validation loss = 5.3829  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 2.0632  Validation loss = 5.3827  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 2.0631  Validation loss = 5.3826  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 2.0630  Validation loss = 5.3825  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 2.0630  Validation loss = 5.3824  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 2.0629  Validation loss = 5.3822  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 2.0628  Validation loss = 5.3821  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 2.0628  Validation loss = 5.3820  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 2.0627  Validation loss = 5.3819  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 2.0626  Validation loss = 5.3818  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 2.0626  Validation loss = 5.3817  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 2.0625  Validation loss = 5.3816  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 2.0624  Validation loss = 5.3815  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 2.0623  Validation loss = 5.3814  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 2.0623  Validation loss = 5.3813  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 2.0622  Validation loss = 5.3812  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 2.0621  Validation loss = 5.3810  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 2.0620  Validation loss = 5.3809  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 2.0619  Validation loss = 5.3808  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 2.0619  Validation loss = 5.3807  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 2.0618  Validation loss = 5.3806  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 2.0617  Validation loss = 5.3805  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 2.0616  Validation loss = 5.3803  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 2.0616  Validation loss = 5.3803  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 2.0615  Validation loss = 5.3801  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 2.0614  Validation loss = 5.3800  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 2.0614  Validation loss = 5.3799  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 2.0612  Validation loss = 5.3797  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 2.0612  Validation loss = 5.3797  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 2.0611  Validation loss = 5.3796  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 2.0610  Validation loss = 5.3794  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 2.0610  Validation loss = 5.3793  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 2.0609  Validation loss = 5.3793  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 2.0609  Validation loss = 5.3792  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 2.0608  Validation loss = 5.3791  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 2.0608  Validation loss = 5.3790  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 2.0607  Validation loss = 5.3789  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 2.0606  Validation loss = 5.3788  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 2.0605  Validation loss = 5.3786  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 2.0605  Validation loss = 5.3785  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 2.0604  Validation loss = 5.3784  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 2.0603  Validation loss = 5.3783  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 2.0602  Validation loss = 5.3782  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 2.0602  Validation loss = 5.3780  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 2.0601  Validation loss = 5.3779  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 2.0600  Validation loss = 5.3778  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 2.0599  Validation loss = 5.3777  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 2.0598  Validation loss = 5.3776  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 2.0598  Validation loss = 5.3774  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 2.0597  Validation loss = 5.3773  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 2.0596  Validation loss = 5.3772  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 2.0596  Validation loss = 5.3772  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 2.0595  Validation loss = 5.3770  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 2.0594  Validation loss = 5.3768  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 2.0593  Validation loss = 5.3767  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 2.0592  Validation loss = 5.3766  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 2.0592  Validation loss = 5.3766  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 2.0591  Validation loss = 5.3764  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 2.0590  Validation loss = 5.3763  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 2.0589  Validation loss = 5.3762  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 2.0589  Validation loss = 5.3761  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 2.0588  Validation loss = 5.3759  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 2.0587  Validation loss = 5.3758  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 2.0586  Validation loss = 5.3757  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 2.0586  Validation loss = 5.3756  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 2.0585  Validation loss = 5.3755  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 2.0584  Validation loss = 5.3754  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 2.0583  Validation loss = 5.3752  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 2.0583  Validation loss = 5.3751  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 2.0582  Validation loss = 5.3750  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 2.0581  Validation loss = 5.3748  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 2.0580  Validation loss = 5.3747  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 2.0579  Validation loss = 5.3746  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 2.0579  Validation loss = 5.3745  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 2.0578  Validation loss = 5.3744  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 2.0577  Validation loss = 5.3743  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 2.0577  Validation loss = 5.3742  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 2.0576  Validation loss = 5.3741  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 2.0575  Validation loss = 5.3740  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 2.0574  Validation loss = 5.3738  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 2.0574  Validation loss = 5.3737  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 2.0573  Validation loss = 5.3736  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 2.0572  Validation loss = 5.3735  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 2.0571  Validation loss = 5.3734  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 2.0571  Validation loss = 5.3733  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 2.0570  Validation loss = 5.3732  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 2.0569  Validation loss = 5.3730  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 2.0568  Validation loss = 5.3729  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 2.0568  Validation loss = 5.3728  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 2.0567  Validation loss = 5.3727  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 2.0566  Validation loss = 5.3726  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 2.0566  Validation loss = 5.3725  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 2.0565  Validation loss = 5.3724  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 2.0564  Validation loss = 5.3723  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 2.0563  Validation loss = 5.3721  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 2.0563  Validation loss = 5.3720  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 2.0562  Validation loss = 5.3719  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 2.0561  Validation loss = 5.3718  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 2.0561  Validation loss = 5.3717  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 2.0560  Validation loss = 5.3716  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 2.0559  Validation loss = 5.3715  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 2.0558  Validation loss = 5.3714  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 2.0558  Validation loss = 5.3713  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 2.0557  Validation loss = 5.3711  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 2.0556  Validation loss = 5.3710  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 2.0555  Validation loss = 5.3709  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 2.0555  Validation loss = 5.3708  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 2.0554  Validation loss = 5.3707  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 2.0553  Validation loss = 5.3705  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 2.0553  Validation loss = 5.3705  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 2.0552  Validation loss = 5.3704  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 2.0551  Validation loss = 5.3703  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 2.0550  Validation loss = 5.3701  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 2.0550  Validation loss = 5.3700  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 2.0549  Validation loss = 5.3699  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 2.0548  Validation loss = 5.3698  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 2.0547  Validation loss = 5.3697  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 2.0547  Validation loss = 5.3696  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 2.0546  Validation loss = 5.3695  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 2.0545  Validation loss = 5.3693  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 2.0544  Validation loss = 5.3692  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 2.0544  Validation loss = 5.3691  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 2.0543  Validation loss = 5.3690  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 2.0543  Validation loss = 5.3689  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 2.0542  Validation loss = 5.3688  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 2.0541  Validation loss = 5.3687  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 2.0540  Validation loss = 5.3686  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 2.0539  Validation loss = 5.3684  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 2.0539  Validation loss = 5.3683  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 2.0538  Validation loss = 5.3682  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 2.0537  Validation loss = 5.3680  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 2.0536  Validation loss = 5.3679  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 2.0535  Validation loss = 5.3678  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 2.0535  Validation loss = 5.3677  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 2.0534  Validation loss = 5.3676  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 2.0533  Validation loss = 5.3675  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 2.0533  Validation loss = 5.3674  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 2.0532  Validation loss = 5.3673  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 2.0531  Validation loss = 5.3672  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 2.0531  Validation loss = 5.3671  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 2.0530  Validation loss = 5.3670  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 2.0529  Validation loss = 5.3668  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 2.0529  Validation loss = 5.3668  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 2.0528  Validation loss = 5.3666  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 2.0527  Validation loss = 5.3664  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 2.0526  Validation loss = 5.3663  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 2.0525  Validation loss = 5.3662  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 2.0525  Validation loss = 5.3661  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 2.0524  Validation loss = 5.3660  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 2.0524  Validation loss = 5.3660  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 2.0523  Validation loss = 5.3659  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 2.0522  Validation loss = 5.3658  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 2.0522  Validation loss = 5.3657  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 2.0521  Validation loss = 5.3656  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 2.0520  Validation loss = 5.3655  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 2.0520  Validation loss = 5.3654  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 2.0519  Validation loss = 5.3652  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 2.0518  Validation loss = 5.3651  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 2.0517  Validation loss = 5.3650  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 2.0517  Validation loss = 5.3649  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 2.0516  Validation loss = 5.3648  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 2.0515  Validation loss = 5.3646  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 2.0515  Validation loss = 5.3646  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 2.0514  Validation loss = 5.3645  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 2.0513  Validation loss = 5.3643  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 2.0512  Validation loss = 5.3642  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 2.0511  Validation loss = 5.3641  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 2.0511  Validation loss = 5.3640  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 2.0510  Validation loss = 5.3639  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 2.0509  Validation loss = 5.3638  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 2.0509  Validation loss = 5.3636  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 2.0508  Validation loss = 5.3635  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 2.0507  Validation loss = 5.3634  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 2.0506  Validation loss = 5.3633  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 2.0505  Validation loss = 5.3631  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 2.0504  Validation loss = 5.3630  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 2.0503  Validation loss = 5.3628  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 2.0503  Validation loss = 5.3627  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 2.0502  Validation loss = 5.3626  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 2.0501  Validation loss = 5.3625  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 2.0500  Validation loss = 5.3624  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 2.0500  Validation loss = 5.3622  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 2.0499  Validation loss = 5.3621  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 2.0498  Validation loss = 5.3620  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 2.0497  Validation loss = 5.3619  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 2.0497  Validation loss = 5.3618  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 2.0496  Validation loss = 5.3616  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 2.0495  Validation loss = 5.3615  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 2.0494  Validation loss = 5.3614  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 2.0494  Validation loss = 5.3613  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 2.0493  Validation loss = 5.3612  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 2.0492  Validation loss = 5.3611  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 2.0492  Validation loss = 5.3610  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 2.0491  Validation loss = 5.3609  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 2.0490  Validation loss = 5.3608  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 2.0490  Validation loss = 5.3607  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 2.0489  Validation loss = 5.3606  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 2.0489  Validation loss = 5.3605  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 2.0487  Validation loss = 5.3603  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 2.0487  Validation loss = 5.3602  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 2.0486  Validation loss = 5.3601  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 2.0486  Validation loss = 5.3600  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 2.0485  Validation loss = 5.3599  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 2.0484  Validation loss = 5.3598  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 2.0483  Validation loss = 5.3597  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 2.0482  Validation loss = 5.3595  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 2.0482  Validation loss = 5.3595  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 2.0481  Validation loss = 5.3594  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 2.0481  Validation loss = 5.3593  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 2.0480  Validation loss = 5.3592  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 2.0479  Validation loss = 5.3591  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 2.0479  Validation loss = 5.3590  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 2.0478  Validation loss = 5.3589  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 2.0477  Validation loss = 5.3587  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 2.0476  Validation loss = 5.3586  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 2.0475  Validation loss = 5.3585  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 2.0475  Validation loss = 5.3584  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 2.0474  Validation loss = 5.3583  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 2.0473  Validation loss = 5.3582  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 2.0473  Validation loss = 5.3580  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 2.0472  Validation loss = 5.3580  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 2.0471  Validation loss = 5.3578  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 2.0470  Validation loss = 5.3577  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 2.0470  Validation loss = 5.3576  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 2.0469  Validation loss = 5.3575  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 2.0468  Validation loss = 5.3574  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 2.0467  Validation loss = 5.3572  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 2.0467  Validation loss = 5.3571  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 2.0466  Validation loss = 5.3570  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 2.0465  Validation loss = 5.3569  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 2.0464  Validation loss = 5.3567  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 2.0463  Validation loss = 5.3566  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 2.0463  Validation loss = 5.3565  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 2.0462  Validation loss = 5.3564  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 2.0461  Validation loss = 5.3563  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 2.0461  Validation loss = 5.3562  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 2.0460  Validation loss = 5.3561  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 2.0459  Validation loss = 5.3560  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 2.0459  Validation loss = 5.3559  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 2.0458  Validation loss = 5.3558  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 2.0457  Validation loss = 5.3557  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 2.0456  Validation loss = 5.3555  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 2.0455  Validation loss = 5.3554  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 2.0455  Validation loss = 5.3553  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 2.0454  Validation loss = 5.3552  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 2.0453  Validation loss = 5.3551  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 2.0453  Validation loss = 5.3550  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 2.0452  Validation loss = 5.3549  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 2.0452  Validation loss = 5.3548  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 2.0451  Validation loss = 5.3546  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 2.0450  Validation loss = 5.3545  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 2.0449  Validation loss = 5.3544  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 2.0448  Validation loss = 5.3543  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 2.0448  Validation loss = 5.3541  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 2.0447  Validation loss = 5.3541  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 2.0447  Validation loss = 5.3540  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 2.0446  Validation loss = 5.3539  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 2.0445  Validation loss = 5.3537  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 2.0445  Validation loss = 5.3537  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 2.0444  Validation loss = 5.3536  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 2.0443  Validation loss = 5.3534  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 2.0442  Validation loss = 5.3533  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 2.0442  Validation loss = 5.3532  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 2.0441  Validation loss = 5.3531  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 2.0440  Validation loss = 5.3530  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 2.0440  Validation loss = 5.3529  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 2.0439  Validation loss = 5.3527  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 2.0438  Validation loss = 5.3526  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 2.0437  Validation loss = 5.3525  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 2.0437  Validation loss = 5.3524  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 2.0436  Validation loss = 5.3523  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 2.0435  Validation loss = 5.3522  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 2.0434  Validation loss = 5.3521  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 2.0434  Validation loss = 5.3519  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 2.0433  Validation loss = 5.3518  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 2.0432  Validation loss = 5.3517  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 2.0431  Validation loss = 5.3516  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 2.0431  Validation loss = 5.3515  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 2.0430  Validation loss = 5.3514  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 2.0429  Validation loss = 5.3513  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 2.0429  Validation loss = 5.3512  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 2.0428  Validation loss = 5.3510  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 2.0427  Validation loss = 5.3509  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 2.0426  Validation loss = 5.3508  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 2.0425  Validation loss = 5.3506  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 2.0425  Validation loss = 5.3505  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 2.0424  Validation loss = 5.3504  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 2.0423  Validation loss = 5.3503  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 2.0422  Validation loss = 5.3502  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 2.0422  Validation loss = 5.3501  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 2.0421  Validation loss = 5.3499  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 2.0420  Validation loss = 5.3498  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 2.0419  Validation loss = 5.3497  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 2.0419  Validation loss = 5.3496  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 2.0418  Validation loss = 5.3495  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 2.0417  Validation loss = 5.3494  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 2.0416  Validation loss = 5.3492  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 2.0416  Validation loss = 5.3491  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 2.0415  Validation loss = 5.3490  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 2.0414  Validation loss = 5.3489  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 2.0413  Validation loss = 5.3488  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 2.0412  Validation loss = 5.3486  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 2.0412  Validation loss = 5.3485  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 2.0411  Validation loss = 5.3484  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 2.0410  Validation loss = 5.3483  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 2.0409  Validation loss = 5.3482  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 2.0409  Validation loss = 5.3480  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 2.0408  Validation loss = 5.3479  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 2.0408  Validation loss = 5.3479  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 2.0407  Validation loss = 5.3478  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 2.0406  Validation loss = 5.3476  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 2.0405  Validation loss = 5.3475  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 2.0404  Validation loss = 5.3474  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 2.0404  Validation loss = 5.3473  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 2.0403  Validation loss = 5.3471  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 2.0402  Validation loss = 5.3470  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 2.0401  Validation loss = 5.3469  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 2.0401  Validation loss = 5.3468  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 2.0400  Validation loss = 5.3467  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 2.0399  Validation loss = 5.3465  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 2.0398  Validation loss = 5.3464  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 2.0398  Validation loss = 5.3464  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 2.0397  Validation loss = 5.3463  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 2.0397  Validation loss = 5.3461  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 2.0396  Validation loss = 5.3460  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 2.0395  Validation loss = 5.3459  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 2.0394  Validation loss = 5.3458  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 2.0394  Validation loss = 5.3457  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 2.0393  Validation loss = 5.3456  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 2.0392  Validation loss = 5.3455  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 2.0392  Validation loss = 5.3454  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 2.0391  Validation loss = 5.3452  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 2.0390  Validation loss = 5.3451  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 2.0389  Validation loss = 5.3450  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 2.0388  Validation loss = 5.3448  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 2.0387  Validation loss = 5.3447  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 2.0387  Validation loss = 5.3446  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 2.0386  Validation loss = 5.3445  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 2.0385  Validation loss = 5.3444  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 2.0384  Validation loss = 5.3443  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 2.0384  Validation loss = 5.3442  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 2.0383  Validation loss = 5.3440  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 2.0383  Validation loss = 5.3440  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 2.0382  Validation loss = 5.3438  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 2.0381  Validation loss = 5.3437  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 2.0381  Validation loss = 5.3436  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 2.0380  Validation loss = 5.3435  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 2.0379  Validation loss = 5.3434  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 2.0379  Validation loss = 5.3433  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 2.0378  Validation loss = 5.3432  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 2.0377  Validation loss = 5.3431  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 2.0377  Validation loss = 5.3430  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 2.0376  Validation loss = 5.3429  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 2.0375  Validation loss = 5.3427  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 2.0374  Validation loss = 5.3426  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 2.0373  Validation loss = 5.3425  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 2.0372  Validation loss = 5.3423  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 2.0372  Validation loss = 5.3422  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 2.0371  Validation loss = 5.3421  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 2.0370  Validation loss = 5.3420  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 2.0369  Validation loss = 5.3419  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 2.0369  Validation loss = 5.3417  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 2.0368  Validation loss = 5.3416  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 2.0367  Validation loss = 5.3415  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 2.0366  Validation loss = 5.3414  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 2.0366  Validation loss = 5.3413  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 2.0365  Validation loss = 5.3412  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 2.0365  Validation loss = 5.3411  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 2.0364  Validation loss = 5.3410  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 2.0363  Validation loss = 5.3409  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 2.0363  Validation loss = 5.3408  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 2.0362  Validation loss = 5.3407  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 2.0361  Validation loss = 5.3406  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 2.0361  Validation loss = 5.3405  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 2.0360  Validation loss = 5.3403  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 2.0359  Validation loss = 5.3402  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 2.0358  Validation loss = 5.3401  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 2.0358  Validation loss = 5.3400  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 2.0357  Validation loss = 5.3399  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 2.0356  Validation loss = 5.3398  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 2.0355  Validation loss = 5.3397  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 2.0355  Validation loss = 5.3396  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 2.0354  Validation loss = 5.3395  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 2.0353  Validation loss = 5.3393  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 2.0353  Validation loss = 5.3392  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 2.0352  Validation loss = 5.3391  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 2.0351  Validation loss = 5.3390  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 2.0351  Validation loss = 5.3389  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 2.0350  Validation loss = 5.3388  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 2.0349  Validation loss = 5.3387  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 2.0348  Validation loss = 5.3385  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 2.0347  Validation loss = 5.3384  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 2.0346  Validation loss = 5.3383  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 2.0346  Validation loss = 5.3381  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 2.0345  Validation loss = 5.3380  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 2.0344  Validation loss = 5.3379  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 2.0344  Validation loss = 5.3378  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 2.0343  Validation loss = 5.3377  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 2.0342  Validation loss = 5.3376  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 2.0342  Validation loss = 5.3375  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 2.0341  Validation loss = 5.3374  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 2.0340  Validation loss = 5.3373  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 2.0339  Validation loss = 5.3372  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 2.0339  Validation loss = 5.3371  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 2.0338  Validation loss = 5.3369  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 2.0337  Validation loss = 5.3368  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 2.0337  Validation loss = 5.3367  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 2.0336  Validation loss = 5.3366  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 2.0335  Validation loss = 5.3365  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 2.0335  Validation loss = 5.3364  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 2.0334  Validation loss = 5.3363  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 2.0333  Validation loss = 5.3362  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 2.0333  Validation loss = 5.3361  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 2.0332  Validation loss = 5.3359  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 2.0331  Validation loss = 5.3358  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 2.0330  Validation loss = 5.3357  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 2.0330  Validation loss = 5.3356  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 2.0329  Validation loss = 5.3355  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 2.0328  Validation loss = 5.3354  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 2.0328  Validation loss = 5.3353  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 2.0327  Validation loss = 5.3351  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 2.0326  Validation loss = 5.3350  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 2.0325  Validation loss = 5.3349  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 2.0325  Validation loss = 5.3349  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 2.0324  Validation loss = 5.3347  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 2.0323  Validation loss = 5.3346  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 2.0322  Validation loss = 5.3344  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 2.0322  Validation loss = 5.3343  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 2.0321  Validation loss = 5.3342  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 2.0321  Validation loss = 5.3342  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 2.0320  Validation loss = 5.3341  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 2.0319  Validation loss = 5.3339  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 2.0319  Validation loss = 5.3338  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 2.0318  Validation loss = 5.3337  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 2.0317  Validation loss = 5.3336  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 2.0317  Validation loss = 5.3335  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 2.0316  Validation loss = 5.3334  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 2.0315  Validation loss = 5.3333  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 2.0315  Validation loss = 5.3332  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 2.0314  Validation loss = 5.3331  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 2.0313  Validation loss = 5.3329  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 2.0312  Validation loss = 5.3328  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 2.0312  Validation loss = 5.3328  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 2.0311  Validation loss = 5.3327  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 2.0311  Validation loss = 5.3326  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 2.0310  Validation loss = 5.3325  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 2.0309  Validation loss = 5.3324  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 2.0309  Validation loss = 5.3323  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 2.0308  Validation loss = 5.3322  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 2.0307  Validation loss = 5.3321  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 2.0307  Validation loss = 5.3320  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 2.0306  Validation loss = 5.3319  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 2.0306  Validation loss = 5.3318  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 2.0305  Validation loss = 5.3317  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 2.0304  Validation loss = 5.3316  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 2.0303  Validation loss = 5.3314  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 2.0303  Validation loss = 5.3313  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 2.0302  Validation loss = 5.3313  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 2.0301  Validation loss = 5.3311  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 2.0300  Validation loss = 5.3310  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 2.0300  Validation loss = 5.3309  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 2.0299  Validation loss = 5.3308  \n",
      "\n",
      "Fold: 4  Epoch: 501  Training loss = 2.0298  Validation loss = 5.3307  \n",
      "\n",
      "Fold: 4  Epoch: 502  Training loss = 2.0298  Validation loss = 5.3305  \n",
      "\n",
      "Fold: 4  Epoch: 503  Training loss = 2.0297  Validation loss = 5.3304  \n",
      "\n",
      "Fold: 4  Epoch: 504  Training loss = 2.0296  Validation loss = 5.3303  \n",
      "\n",
      "Fold: 4  Epoch: 505  Training loss = 2.0296  Validation loss = 5.3302  \n",
      "\n",
      "Fold: 4  Epoch: 506  Training loss = 2.0295  Validation loss = 5.3301  \n",
      "\n",
      "Fold: 4  Epoch: 507  Training loss = 2.0294  Validation loss = 5.3300  \n",
      "\n",
      "Fold: 4  Epoch: 508  Training loss = 2.0294  Validation loss = 5.3299  \n",
      "\n",
      "Fold: 4  Epoch: 509  Training loss = 2.0293  Validation loss = 5.3297  \n",
      "\n",
      "Fold: 4  Epoch: 510  Training loss = 2.0292  Validation loss = 5.3296  \n",
      "\n",
      "Fold: 4  Epoch: 511  Training loss = 2.0291  Validation loss = 5.3295  \n",
      "\n",
      "Fold: 4  Epoch: 512  Training loss = 2.0291  Validation loss = 5.3294  \n",
      "\n",
      "Fold: 4  Epoch: 513  Training loss = 2.0290  Validation loss = 5.3293  \n",
      "\n",
      "Fold: 4  Epoch: 514  Training loss = 2.0290  Validation loss = 5.3293  \n",
      "\n",
      "Fold: 4  Epoch: 515  Training loss = 2.0289  Validation loss = 5.3291  \n",
      "\n",
      "Fold: 4  Epoch: 516  Training loss = 2.0288  Validation loss = 5.3290  \n",
      "\n",
      "Fold: 4  Epoch: 517  Training loss = 2.0288  Validation loss = 5.3289  \n",
      "\n",
      "Fold: 4  Epoch: 518  Training loss = 2.0287  Validation loss = 5.3288  \n",
      "\n",
      "Fold: 4  Epoch: 519  Training loss = 2.0286  Validation loss = 5.3287  \n",
      "\n",
      "Fold: 4  Epoch: 520  Training loss = 2.0285  Validation loss = 5.3286  \n",
      "\n",
      "Fold: 4  Epoch: 521  Training loss = 2.0285  Validation loss = 5.3285  \n",
      "\n",
      "Fold: 4  Epoch: 522  Training loss = 2.0284  Validation loss = 5.3284  \n",
      "\n",
      "Fold: 4  Epoch: 523  Training loss = 2.0283  Validation loss = 5.3283  \n",
      "\n",
      "Fold: 4  Epoch: 524  Training loss = 2.0283  Validation loss = 5.3281  \n",
      "\n",
      "Fold: 4  Epoch: 525  Training loss = 2.0282  Validation loss = 5.3280  \n",
      "\n",
      "Fold: 4  Epoch: 526  Training loss = 2.0281  Validation loss = 5.3279  \n",
      "\n",
      "Fold: 4  Epoch: 527  Training loss = 2.0280  Validation loss = 5.3278  \n",
      "\n",
      "Fold: 4  Epoch: 528  Training loss = 2.0280  Validation loss = 5.3277  \n",
      "\n",
      "Fold: 4  Epoch: 529  Training loss = 2.0279  Validation loss = 5.3276  \n",
      "\n",
      "Fold: 4  Epoch: 530  Training loss = 2.0279  Validation loss = 5.3275  \n",
      "\n",
      "Fold: 4  Epoch: 531  Training loss = 2.0278  Validation loss = 5.3274  \n",
      "\n",
      "Fold: 4  Epoch: 532  Training loss = 2.0277  Validation loss = 5.3273  \n",
      "\n",
      "Fold: 4  Epoch: 533  Training loss = 2.0277  Validation loss = 5.3272  \n",
      "\n",
      "Fold: 4  Epoch: 534  Training loss = 2.0276  Validation loss = 5.3271  \n",
      "\n",
      "Fold: 4  Epoch: 535  Training loss = 2.0275  Validation loss = 5.3270  \n",
      "\n",
      "Fold: 4  Epoch: 536  Training loss = 2.0275  Validation loss = 5.3269  \n",
      "\n",
      "Fold: 4  Epoch: 537  Training loss = 2.0274  Validation loss = 5.3268  \n",
      "\n",
      "Fold: 4  Epoch: 538  Training loss = 2.0273  Validation loss = 5.3266  \n",
      "\n",
      "Fold: 4  Epoch: 539  Training loss = 2.0273  Validation loss = 5.3265  \n",
      "\n",
      "Fold: 4  Epoch: 540  Training loss = 2.0272  Validation loss = 5.3264  \n",
      "\n",
      "Fold: 4  Epoch: 541  Training loss = 2.0271  Validation loss = 5.3263  \n",
      "\n",
      "Fold: 4  Epoch: 542  Training loss = 2.0271  Validation loss = 5.3262  \n",
      "\n",
      "Fold: 4  Epoch: 543  Training loss = 2.0270  Validation loss = 5.3261  \n",
      "\n",
      "Fold: 4  Epoch: 544  Training loss = 2.0269  Validation loss = 5.3260  \n",
      "\n",
      "Fold: 4  Epoch: 545  Training loss = 2.0268  Validation loss = 5.3259  \n",
      "\n",
      "Fold: 4  Epoch: 546  Training loss = 2.0268  Validation loss = 5.3258  \n",
      "\n",
      "Fold: 4  Epoch: 547  Training loss = 2.0267  Validation loss = 5.3257  \n",
      "\n",
      "Fold: 4  Epoch: 548  Training loss = 2.0266  Validation loss = 5.3255  \n",
      "\n",
      "Fold: 4  Epoch: 549  Training loss = 2.0266  Validation loss = 5.3255  \n",
      "\n",
      "Fold: 4  Epoch: 550  Training loss = 2.0265  Validation loss = 5.3254  \n",
      "\n",
      "Fold: 4  Epoch: 551  Training loss = 2.0265  Validation loss = 5.3253  \n",
      "\n",
      "Fold: 4  Epoch: 552  Training loss = 2.0264  Validation loss = 5.3252  \n",
      "\n",
      "Fold: 4  Epoch: 553  Training loss = 2.0263  Validation loss = 5.3251  \n",
      "\n",
      "Fold: 4  Epoch: 554  Training loss = 2.0263  Validation loss = 5.3249  \n",
      "\n",
      "Fold: 4  Epoch: 555  Training loss = 2.0262  Validation loss = 5.3248  \n",
      "\n",
      "Fold: 4  Epoch: 556  Training loss = 2.0261  Validation loss = 5.3247  \n",
      "\n",
      "Fold: 4  Epoch: 557  Training loss = 2.0261  Validation loss = 5.3246  \n",
      "\n",
      "Fold: 4  Epoch: 558  Training loss = 2.0260  Validation loss = 5.3245  \n",
      "\n",
      "Fold: 4  Epoch: 559  Training loss = 2.0259  Validation loss = 5.3244  \n",
      "\n",
      "Fold: 4  Epoch: 560  Training loss = 2.0259  Validation loss = 5.3243  \n",
      "\n",
      "Fold: 4  Epoch: 561  Training loss = 2.0258  Validation loss = 5.3242  \n",
      "\n",
      "Fold: 4  Epoch: 562  Training loss = 2.0257  Validation loss = 5.3241  \n",
      "\n",
      "Fold: 4  Epoch: 563  Training loss = 2.0257  Validation loss = 5.3241  \n",
      "\n",
      "Fold: 4  Epoch: 564  Training loss = 2.0256  Validation loss = 5.3240  \n",
      "\n",
      "Fold: 4  Epoch: 565  Training loss = 2.0256  Validation loss = 5.3239  \n",
      "\n",
      "Fold: 4  Epoch: 566  Training loss = 2.0255  Validation loss = 5.3237  \n",
      "\n",
      "Fold: 4  Epoch: 567  Training loss = 2.0255  Validation loss = 5.3237  \n",
      "\n",
      "Fold: 4  Epoch: 568  Training loss = 2.0254  Validation loss = 5.3236  \n",
      "\n",
      "Fold: 4  Epoch: 569  Training loss = 2.0253  Validation loss = 5.3235  \n",
      "\n",
      "Fold: 4  Epoch: 570  Training loss = 2.0253  Validation loss = 5.3234  \n",
      "\n",
      "Fold: 4  Epoch: 571  Training loss = 2.0252  Validation loss = 5.3232  \n",
      "\n",
      "Fold: 4  Epoch: 572  Training loss = 2.0251  Validation loss = 5.3231  \n",
      "\n",
      "Fold: 4  Epoch: 573  Training loss = 2.0250  Validation loss = 5.3230  \n",
      "\n",
      "Fold: 4  Epoch: 574  Training loss = 2.0250  Validation loss = 5.3229  \n",
      "\n",
      "Fold: 4  Epoch: 575  Training loss = 2.0249  Validation loss = 5.3228  \n",
      "\n",
      "Fold: 4  Epoch: 576  Training loss = 2.0248  Validation loss = 5.3227  \n",
      "\n",
      "Fold: 4  Epoch: 577  Training loss = 2.0248  Validation loss = 5.3226  \n",
      "\n",
      "Fold: 4  Epoch: 578  Training loss = 2.0247  Validation loss = 5.3225  \n",
      "\n",
      "Fold: 4  Epoch: 579  Training loss = 2.0247  Validation loss = 5.3224  \n",
      "\n",
      "Fold: 4  Epoch: 580  Training loss = 2.0246  Validation loss = 5.3223  \n",
      "\n",
      "Fold: 4  Epoch: 581  Training loss = 2.0245  Validation loss = 5.3222  \n",
      "\n",
      "Fold: 4  Epoch: 582  Training loss = 2.0244  Validation loss = 5.3220  \n",
      "\n",
      "Fold: 4  Epoch: 583  Training loss = 2.0243  Validation loss = 5.3219  \n",
      "\n",
      "Fold: 4  Epoch: 584  Training loss = 2.0243  Validation loss = 5.3218  \n",
      "\n",
      "Fold: 4  Epoch: 585  Training loss = 2.0242  Validation loss = 5.3217  \n",
      "\n",
      "Fold: 4  Epoch: 586  Training loss = 2.0241  Validation loss = 5.3216  \n",
      "\n",
      "Fold: 4  Epoch: 587  Training loss = 2.0241  Validation loss = 5.3215  \n",
      "\n",
      "Fold: 4  Epoch: 588  Training loss = 2.0240  Validation loss = 5.3214  \n",
      "\n",
      "Fold: 4  Epoch: 589  Training loss = 2.0239  Validation loss = 5.3213  \n",
      "\n",
      "Fold: 4  Epoch: 590  Training loss = 2.0239  Validation loss = 5.3212  \n",
      "\n",
      "Fold: 4  Epoch: 591  Training loss = 2.0238  Validation loss = 5.3211  \n",
      "\n",
      "Fold: 4  Epoch: 592  Training loss = 2.0238  Validation loss = 5.3210  \n",
      "\n",
      "Fold: 4  Epoch: 593  Training loss = 2.0237  Validation loss = 5.3209  \n",
      "\n",
      "Fold: 4  Epoch: 594  Training loss = 2.0236  Validation loss = 5.3208  \n",
      "\n",
      "Fold: 4  Epoch: 595  Training loss = 2.0236  Validation loss = 5.3207  \n",
      "\n",
      "Fold: 4  Epoch: 596  Training loss = 2.0235  Validation loss = 5.3206  \n",
      "\n",
      "Fold: 4  Epoch: 597  Training loss = 2.0234  Validation loss = 5.3205  \n",
      "\n",
      "Fold: 4  Epoch: 598  Training loss = 2.0233  Validation loss = 5.3203  \n",
      "\n",
      "Fold: 4  Epoch: 599  Training loss = 2.0233  Validation loss = 5.3202  \n",
      "\n",
      "Fold: 4  Epoch: 600  Training loss = 2.0232  Validation loss = 5.3201  \n",
      "\n",
      "Fold: 4  Epoch: 601  Training loss = 2.0231  Validation loss = 5.3200  \n",
      "\n",
      "Fold: 4  Epoch: 602  Training loss = 2.0231  Validation loss = 5.3199  \n",
      "\n",
      "Fold: 4  Epoch: 603  Training loss = 2.0230  Validation loss = 5.3197  \n",
      "\n",
      "Fold: 4  Epoch: 604  Training loss = 2.0229  Validation loss = 5.3196  \n",
      "\n",
      "Fold: 4  Epoch: 605  Training loss = 2.0229  Validation loss = 5.3196  \n",
      "\n",
      "Fold: 4  Epoch: 606  Training loss = 2.0228  Validation loss = 5.3195  \n",
      "\n",
      "Fold: 4  Epoch: 607  Training loss = 2.0228  Validation loss = 5.3194  \n",
      "\n",
      "Fold: 4  Epoch: 608  Training loss = 2.0227  Validation loss = 5.3193  \n",
      "\n",
      "Fold: 4  Epoch: 609  Training loss = 2.0226  Validation loss = 5.3192  \n",
      "\n",
      "Fold: 4  Epoch: 610  Training loss = 2.0226  Validation loss = 5.3191  \n",
      "\n",
      "Fold: 4  Epoch: 611  Training loss = 2.0225  Validation loss = 5.3190  \n",
      "\n",
      "Fold: 4  Epoch: 612  Training loss = 2.0224  Validation loss = 5.3188  \n",
      "\n",
      "Fold: 4  Epoch: 613  Training loss = 2.0223  Validation loss = 5.3187  \n",
      "\n",
      "Fold: 4  Epoch: 614  Training loss = 2.0223  Validation loss = 5.3186  \n",
      "\n",
      "Fold: 4  Epoch: 615  Training loss = 2.0222  Validation loss = 5.3186  \n",
      "\n",
      "Fold: 4  Epoch: 616  Training loss = 2.0222  Validation loss = 5.3184  \n",
      "\n",
      "Fold: 4  Epoch: 617  Training loss = 2.0221  Validation loss = 5.3183  \n",
      "\n",
      "Fold: 4  Epoch: 618  Training loss = 2.0220  Validation loss = 5.3182  \n",
      "\n",
      "Fold: 4  Epoch: 619  Training loss = 2.0219  Validation loss = 5.3181  \n",
      "\n",
      "Fold: 4  Epoch: 620  Training loss = 2.0219  Validation loss = 5.3180  \n",
      "\n",
      "Fold: 4  Epoch: 621  Training loss = 2.0218  Validation loss = 5.3178  \n",
      "\n",
      "Fold: 4  Epoch: 622  Training loss = 2.0217  Validation loss = 5.3177  \n",
      "\n",
      "Fold: 4  Epoch: 623  Training loss = 2.0217  Validation loss = 5.3176  \n",
      "\n",
      "Fold: 4  Epoch: 624  Training loss = 2.0216  Validation loss = 5.3175  \n",
      "\n",
      "Fold: 4  Epoch: 625  Training loss = 2.0215  Validation loss = 5.3174  \n",
      "\n",
      "Fold: 4  Epoch: 626  Training loss = 2.0214  Validation loss = 5.3173  \n",
      "\n",
      "Fold: 4  Epoch: 627  Training loss = 2.0213  Validation loss = 5.3171  \n",
      "\n",
      "Fold: 4  Epoch: 628  Training loss = 2.0213  Validation loss = 5.3170  \n",
      "\n",
      "Fold: 4  Epoch: 629  Training loss = 2.0212  Validation loss = 5.3169  \n",
      "\n",
      "Fold: 4  Epoch: 630  Training loss = 2.0211  Validation loss = 5.3168  \n",
      "\n",
      "Fold: 4  Epoch: 631  Training loss = 2.0210  Validation loss = 5.3166  \n",
      "\n",
      "Fold: 4  Epoch: 632  Training loss = 2.0210  Validation loss = 5.3166  \n",
      "\n",
      "Fold: 4  Epoch: 633  Training loss = 2.0209  Validation loss = 5.3164  \n",
      "\n",
      "Fold: 4  Epoch: 634  Training loss = 2.0208  Validation loss = 5.3163  \n",
      "\n",
      "Fold: 4  Epoch: 635  Training loss = 2.0208  Validation loss = 5.3162  \n",
      "\n",
      "Fold: 4  Epoch: 636  Training loss = 2.0207  Validation loss = 5.3161  \n",
      "\n",
      "Fold: 4  Epoch: 637  Training loss = 2.0207  Validation loss = 5.3161  \n",
      "\n",
      "Fold: 4  Epoch: 638  Training loss = 2.0206  Validation loss = 5.3160  \n",
      "\n",
      "Fold: 4  Epoch: 639  Training loss = 2.0205  Validation loss = 5.3158  \n",
      "\n",
      "Fold: 4  Epoch: 640  Training loss = 2.0204  Validation loss = 5.3157  \n",
      "\n",
      "Fold: 4  Epoch: 641  Training loss = 2.0204  Validation loss = 5.3156  \n",
      "\n",
      "Fold: 4  Epoch: 642  Training loss = 2.0203  Validation loss = 5.3155  \n",
      "\n",
      "Fold: 4  Epoch: 643  Training loss = 2.0202  Validation loss = 5.3153  \n",
      "\n",
      "Fold: 4  Epoch: 644  Training loss = 2.0202  Validation loss = 5.3152  \n",
      "\n",
      "Fold: 4  Epoch: 645  Training loss = 2.0201  Validation loss = 5.3151  \n",
      "\n",
      "Fold: 4  Epoch: 646  Training loss = 2.0200  Validation loss = 5.3150  \n",
      "\n",
      "Fold: 4  Epoch: 647  Training loss = 2.0199  Validation loss = 5.3149  \n",
      "\n",
      "Fold: 4  Epoch: 648  Training loss = 2.0199  Validation loss = 5.3148  \n",
      "\n",
      "Fold: 4  Epoch: 649  Training loss = 2.0198  Validation loss = 5.3147  \n",
      "\n",
      "Fold: 4  Epoch: 650  Training loss = 2.0198  Validation loss = 5.3146  \n",
      "\n",
      "Fold: 4  Epoch: 651  Training loss = 2.0197  Validation loss = 5.3145  \n",
      "\n",
      "Fold: 4  Epoch: 652  Training loss = 2.0196  Validation loss = 5.3144  \n",
      "\n",
      "Fold: 4  Epoch: 653  Training loss = 2.0196  Validation loss = 5.3143  \n",
      "\n",
      "Fold: 4  Epoch: 654  Training loss = 2.0195  Validation loss = 5.3142  \n",
      "\n",
      "Fold: 4  Epoch: 655  Training loss = 2.0194  Validation loss = 5.3140  \n",
      "\n",
      "Fold: 4  Epoch: 656  Training loss = 2.0194  Validation loss = 5.3139  \n",
      "\n",
      "Fold: 4  Epoch: 657  Training loss = 2.0193  Validation loss = 5.3139  \n",
      "\n",
      "Fold: 4  Epoch: 658  Training loss = 2.0193  Validation loss = 5.3138  \n",
      "\n",
      "Fold: 4  Epoch: 659  Training loss = 2.0192  Validation loss = 5.3137  \n",
      "\n",
      "Fold: 4  Epoch: 660  Training loss = 2.0191  Validation loss = 5.3136  \n",
      "\n",
      "Fold: 4  Epoch: 661  Training loss = 2.0191  Validation loss = 5.3135  \n",
      "\n",
      "Fold: 4  Epoch: 662  Training loss = 2.0190  Validation loss = 5.3133  \n",
      "\n",
      "Fold: 4  Epoch: 663  Training loss = 2.0189  Validation loss = 5.3132  \n",
      "\n",
      "Fold: 4  Epoch: 664  Training loss = 2.0188  Validation loss = 5.3131  \n",
      "\n",
      "Fold: 4  Epoch: 665  Training loss = 2.0188  Validation loss = 5.3130  \n",
      "\n",
      "Fold: 4  Epoch: 666  Training loss = 2.0187  Validation loss = 5.3129  \n",
      "\n",
      "Fold: 4  Epoch: 667  Training loss = 2.0187  Validation loss = 5.3128  \n",
      "\n",
      "Fold: 4  Epoch: 668  Training loss = 2.0186  Validation loss = 5.3127  \n",
      "\n",
      "Fold: 4  Epoch: 669  Training loss = 2.0185  Validation loss = 5.3126  \n",
      "\n",
      "Fold: 4  Epoch: 670  Training loss = 2.0185  Validation loss = 5.3125  \n",
      "\n",
      "Fold: 4  Epoch: 671  Training loss = 2.0184  Validation loss = 5.3124  \n",
      "\n",
      "Fold: 4  Epoch: 672  Training loss = 2.0183  Validation loss = 5.3123  \n",
      "\n",
      "Fold: 4  Epoch: 673  Training loss = 2.0183  Validation loss = 5.3122  \n",
      "\n",
      "Fold: 4  Epoch: 674  Training loss = 2.0182  Validation loss = 5.3121  \n",
      "\n",
      "Fold: 4  Epoch: 675  Training loss = 2.0181  Validation loss = 5.3120  \n",
      "\n",
      "Fold: 4  Epoch: 676  Training loss = 2.0181  Validation loss = 5.3119  \n",
      "\n",
      "Fold: 4  Epoch: 677  Training loss = 2.0180  Validation loss = 5.3118  \n",
      "\n",
      "Fold: 4  Epoch: 678  Training loss = 2.0180  Validation loss = 5.3117  \n",
      "\n",
      "Fold: 4  Epoch: 679  Training loss = 2.0179  Validation loss = 5.3116  \n",
      "\n",
      "Fold: 4  Epoch: 680  Training loss = 2.0178  Validation loss = 5.3115  \n",
      "\n",
      "Fold: 4  Epoch: 681  Training loss = 2.0178  Validation loss = 5.3114  \n",
      "\n",
      "Fold: 4  Epoch: 682  Training loss = 2.0177  Validation loss = 5.3113  \n",
      "\n",
      "Fold: 4  Epoch: 683  Training loss = 2.0176  Validation loss = 5.3112  \n",
      "\n",
      "Fold: 4  Epoch: 684  Training loss = 2.0176  Validation loss = 5.3111  \n",
      "\n",
      "Fold: 4  Epoch: 685  Training loss = 2.0175  Validation loss = 5.3110  \n",
      "\n",
      "Fold: 4  Epoch: 686  Training loss = 2.0175  Validation loss = 5.3109  \n",
      "\n",
      "Fold: 4  Epoch: 687  Training loss = 2.0174  Validation loss = 5.3108  \n",
      "\n",
      "Fold: 4  Epoch: 688  Training loss = 2.0173  Validation loss = 5.3107  \n",
      "\n",
      "Fold: 4  Epoch: 689  Training loss = 2.0172  Validation loss = 5.3106  \n",
      "\n",
      "Fold: 4  Epoch: 690  Training loss = 2.0172  Validation loss = 5.3105  \n",
      "\n",
      "Fold: 4  Epoch: 691  Training loss = 2.0171  Validation loss = 5.3103  \n",
      "\n",
      "Fold: 4  Epoch: 692  Training loss = 2.0170  Validation loss = 5.3102  \n",
      "\n",
      "Fold: 4  Epoch: 693  Training loss = 2.0170  Validation loss = 5.3101  \n",
      "\n",
      "Fold: 4  Epoch: 694  Training loss = 2.0169  Validation loss = 5.3100  \n",
      "\n",
      "Fold: 4  Epoch: 695  Training loss = 2.0168  Validation loss = 5.3099  \n",
      "\n",
      "Fold: 4  Epoch: 696  Training loss = 2.0168  Validation loss = 5.3098  \n",
      "\n",
      "Fold: 4  Epoch: 697  Training loss = 2.0167  Validation loss = 5.3097  \n",
      "\n",
      "Fold: 4  Epoch: 698  Training loss = 2.0166  Validation loss = 5.3096  \n",
      "\n",
      "Fold: 4  Epoch: 699  Training loss = 2.0166  Validation loss = 5.3095  \n",
      "\n",
      "Fold: 4  Epoch: 700  Training loss = 2.0165  Validation loss = 5.3094  \n",
      "\n",
      "Fold: 4  Epoch: 701  Training loss = 2.0165  Validation loss = 5.3093  \n",
      "\n",
      "Fold: 4  Epoch: 702  Training loss = 2.0164  Validation loss = 5.3092  \n",
      "\n",
      "Fold: 4  Epoch: 703  Training loss = 2.0163  Validation loss = 5.3091  \n",
      "\n",
      "Fold: 4  Epoch: 704  Training loss = 2.0163  Validation loss = 5.3090  \n",
      "\n",
      "Fold: 4  Epoch: 705  Training loss = 2.0162  Validation loss = 5.3089  \n",
      "\n",
      "Fold: 4  Epoch: 706  Training loss = 2.0162  Validation loss = 5.3088  \n",
      "\n",
      "Fold: 4  Epoch: 707  Training loss = 2.0161  Validation loss = 5.3087  \n",
      "\n",
      "Fold: 4  Epoch: 708  Training loss = 2.0160  Validation loss = 5.3085  \n",
      "\n",
      "Fold: 4  Epoch: 709  Training loss = 2.0159  Validation loss = 5.3084  \n",
      "\n",
      "Fold: 4  Epoch: 710  Training loss = 2.0159  Validation loss = 5.3083  \n",
      "\n",
      "Fold: 4  Epoch: 711  Training loss = 2.0158  Validation loss = 5.3082  \n",
      "\n",
      "Fold: 4  Epoch: 712  Training loss = 2.0157  Validation loss = 5.3081  \n",
      "\n",
      "Fold: 4  Epoch: 713  Training loss = 2.0157  Validation loss = 5.3080  \n",
      "\n",
      "Fold: 4  Epoch: 714  Training loss = 2.0156  Validation loss = 5.3079  \n",
      "\n",
      "Fold: 4  Epoch: 715  Training loss = 2.0156  Validation loss = 5.3078  \n",
      "\n",
      "Fold: 4  Epoch: 716  Training loss = 2.0155  Validation loss = 5.3077  \n",
      "\n",
      "Fold: 4  Epoch: 717  Training loss = 2.0155  Validation loss = 5.3077  \n",
      "\n",
      "Fold: 4  Epoch: 718  Training loss = 2.0154  Validation loss = 5.3076  \n",
      "\n",
      "Fold: 4  Epoch: 719  Training loss = 2.0153  Validation loss = 5.3075  \n",
      "\n",
      "Fold: 4  Epoch: 720  Training loss = 2.0153  Validation loss = 5.3073  \n",
      "\n",
      "Fold: 4  Epoch: 721  Training loss = 2.0152  Validation loss = 5.3073  \n",
      "\n",
      "Fold: 4  Epoch: 722  Training loss = 2.0151  Validation loss = 5.3071  \n",
      "\n",
      "Fold: 4  Epoch: 723  Training loss = 2.0151  Validation loss = 5.3071  \n",
      "\n",
      "Fold: 4  Epoch: 724  Training loss = 2.0150  Validation loss = 5.3069  \n",
      "\n",
      "Fold: 4  Epoch: 725  Training loss = 2.0149  Validation loss = 5.3068  \n",
      "\n",
      "Fold: 4  Epoch: 726  Training loss = 2.0149  Validation loss = 5.3067  \n",
      "\n",
      "Fold: 4  Epoch: 727  Training loss = 2.0148  Validation loss = 5.3067  \n",
      "\n",
      "Fold: 4  Epoch: 728  Training loss = 2.0148  Validation loss = 5.3066  \n",
      "\n",
      "Fold: 4  Epoch: 729  Training loss = 2.0147  Validation loss = 5.3065  \n",
      "\n",
      "Fold: 4  Epoch: 730  Training loss = 2.0146  Validation loss = 5.3064  \n",
      "\n",
      "Fold: 4  Epoch: 731  Training loss = 2.0146  Validation loss = 5.3062  \n",
      "\n",
      "Fold: 4  Epoch: 732  Training loss = 2.0145  Validation loss = 5.3061  \n",
      "\n",
      "Fold: 4  Epoch: 733  Training loss = 2.0144  Validation loss = 5.3060  \n",
      "\n",
      "Fold: 4  Epoch: 734  Training loss = 2.0144  Validation loss = 5.3059  \n",
      "\n",
      "Fold: 4  Epoch: 735  Training loss = 2.0143  Validation loss = 5.3058  \n",
      "\n",
      "Fold: 4  Epoch: 736  Training loss = 2.0143  Validation loss = 5.3057  \n",
      "\n",
      "Fold: 4  Epoch: 737  Training loss = 2.0142  Validation loss = 5.3056  \n",
      "\n",
      "Fold: 4  Epoch: 738  Training loss = 2.0141  Validation loss = 5.3055  \n",
      "\n",
      "Fold: 4  Epoch: 739  Training loss = 2.0141  Validation loss = 5.3054  \n",
      "\n",
      "Fold: 4  Epoch: 740  Training loss = 2.0140  Validation loss = 5.3053  \n",
      "\n",
      "Fold: 4  Epoch: 741  Training loss = 2.0139  Validation loss = 5.3052  \n",
      "\n",
      "Fold: 4  Epoch: 742  Training loss = 2.0138  Validation loss = 5.3051  \n",
      "\n",
      "Fold: 4  Epoch: 743  Training loss = 2.0138  Validation loss = 5.3049  \n",
      "\n",
      "Fold: 4  Epoch: 744  Training loss = 2.0137  Validation loss = 5.3049  \n",
      "\n",
      "Fold: 4  Epoch: 745  Training loss = 2.0136  Validation loss = 5.3047  \n",
      "\n",
      "Fold: 4  Epoch: 746  Training loss = 2.0136  Validation loss = 5.3046  \n",
      "\n",
      "Fold: 4  Epoch: 747  Training loss = 2.0135  Validation loss = 5.3046  \n",
      "\n",
      "Fold: 4  Epoch: 748  Training loss = 2.0135  Validation loss = 5.3044  \n",
      "\n",
      "Fold: 4  Epoch: 749  Training loss = 2.0134  Validation loss = 5.3043  \n",
      "\n",
      "Fold: 4  Epoch: 750  Training loss = 2.0133  Validation loss = 5.3042  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 750  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.3762  Validation loss = 5.0330  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.3761  Validation loss = 5.0329  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.3761  Validation loss = 5.0328  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.3760  Validation loss = 5.0327  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.3759  Validation loss = 5.0326  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.3758  Validation loss = 5.0324  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.3757  Validation loss = 5.0323  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.3756  Validation loss = 5.0321  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.3755  Validation loss = 5.0320  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.3754  Validation loss = 5.0318  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.3753  Validation loss = 5.0317  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.3753  Validation loss = 5.0316  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.3752  Validation loss = 5.0315  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.3751  Validation loss = 5.0314  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.3750  Validation loss = 5.0312  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.3749  Validation loss = 5.0311  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.3748  Validation loss = 5.0310  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.3747  Validation loss = 5.0308  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.3746  Validation loss = 5.0307  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.3745  Validation loss = 5.0306  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.3744  Validation loss = 5.0304  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.3743  Validation loss = 5.0303  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.3742  Validation loss = 5.0301  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.3742  Validation loss = 5.0300  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.3741  Validation loss = 5.0299  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.3740  Validation loss = 5.0297  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.3739  Validation loss = 5.0296  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.3737  Validation loss = 5.0294  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.3737  Validation loss = 5.0293  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.3736  Validation loss = 5.0292  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.3735  Validation loss = 5.0290  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.3734  Validation loss = 5.0288  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.3733  Validation loss = 5.0287  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.3732  Validation loss = 5.0286  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.3731  Validation loss = 5.0285  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.3730  Validation loss = 5.0283  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.3729  Validation loss = 5.0282  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.3728  Validation loss = 5.0281  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.3728  Validation loss = 5.0280  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.3727  Validation loss = 5.0278  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.3726  Validation loss = 5.0277  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.3725  Validation loss = 5.0275  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.3724  Validation loss = 5.0274  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.3723  Validation loss = 5.0273  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.3722  Validation loss = 5.0272  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.3722  Validation loss = 5.0271  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.3721  Validation loss = 5.0269  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.3720  Validation loss = 5.0268  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.3719  Validation loss = 5.0266  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.3718  Validation loss = 5.0265  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.3717  Validation loss = 5.0264  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.3716  Validation loss = 5.0263  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.3715  Validation loss = 5.0261  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.3714  Validation loss = 5.0260  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.3713  Validation loss = 5.0259  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.3712  Validation loss = 5.0257  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.3712  Validation loss = 5.0256  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.3711  Validation loss = 5.0255  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.3710  Validation loss = 5.0254  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.3709  Validation loss = 5.0252  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.3708  Validation loss = 5.0251  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.3707  Validation loss = 5.0250  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.3706  Validation loss = 5.0248  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.3705  Validation loss = 5.0247  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.3704  Validation loss = 5.0245  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.3703  Validation loss = 5.0244  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.3702  Validation loss = 5.0243  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.3702  Validation loss = 5.0242  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.3700  Validation loss = 5.0240  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.3700  Validation loss = 5.0239  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.3699  Validation loss = 5.0237  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.3698  Validation loss = 5.0236  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.3697  Validation loss = 5.0234  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.3696  Validation loss = 5.0233  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.3695  Validation loss = 5.0232  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.3694  Validation loss = 5.0231  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.3693  Validation loss = 5.0229  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.3692  Validation loss = 5.0228  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.3691  Validation loss = 5.0227  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.3691  Validation loss = 5.0225  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.3690  Validation loss = 5.0224  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.3688  Validation loss = 5.0222  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.3688  Validation loss = 5.0221  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.3687  Validation loss = 5.0220  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.3686  Validation loss = 5.0218  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.3685  Validation loss = 5.0217  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.3684  Validation loss = 5.0216  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.3683  Validation loss = 5.0214  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.3682  Validation loss = 5.0213  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.3681  Validation loss = 5.0212  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.3680  Validation loss = 5.0211  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.3680  Validation loss = 5.0209  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.3679  Validation loss = 5.0208  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.3678  Validation loss = 5.0207  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.3677  Validation loss = 5.0206  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.3676  Validation loss = 5.0204  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.3675  Validation loss = 5.0203  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.3674  Validation loss = 5.0202  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.3673  Validation loss = 5.0200  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.3672  Validation loss = 5.0199  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.3671  Validation loss = 5.0197  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.3670  Validation loss = 5.0196  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.3670  Validation loss = 5.0195  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.3669  Validation loss = 5.0194  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.3668  Validation loss = 5.0192  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.3667  Validation loss = 5.0191  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.3666  Validation loss = 5.0190  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.3665  Validation loss = 5.0189  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.3664  Validation loss = 5.0187  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.3664  Validation loss = 5.0187  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.3663  Validation loss = 5.0185  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.3662  Validation loss = 5.0184  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.3662  Validation loss = 5.0183  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.3661  Validation loss = 5.0182  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.3660  Validation loss = 5.0180  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.3659  Validation loss = 5.0179  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.3658  Validation loss = 5.0178  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.3657  Validation loss = 5.0177  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.3657  Validation loss = 5.0176  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.3656  Validation loss = 5.0175  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.3655  Validation loss = 5.0173  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.3654  Validation loss = 5.0172  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.3653  Validation loss = 5.0171  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.3652  Validation loss = 5.0170  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.3651  Validation loss = 5.0168  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.3651  Validation loss = 5.0167  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.3650  Validation loss = 5.0166  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.3649  Validation loss = 5.0164  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.3648  Validation loss = 5.0163  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.3647  Validation loss = 5.0162  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.3646  Validation loss = 5.0161  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.3645  Validation loss = 5.0159  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.3645  Validation loss = 5.0158  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.3644  Validation loss = 5.0157  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.3643  Validation loss = 5.0156  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.3642  Validation loss = 5.0154  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.3641  Validation loss = 5.0153  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.3640  Validation loss = 5.0151  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.3639  Validation loss = 5.0149  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.3638  Validation loss = 5.0148  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.3637  Validation loss = 5.0147  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.3636  Validation loss = 5.0146  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.3635  Validation loss = 5.0144  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.3634  Validation loss = 5.0143  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.3634  Validation loss = 5.0142  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.3633  Validation loss = 5.0140  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.3632  Validation loss = 5.0139  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.3631  Validation loss = 5.0138  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.3630  Validation loss = 5.0137  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.3629  Validation loss = 5.0135  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.3628  Validation loss = 5.0134  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.3627  Validation loss = 5.0132  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.3626  Validation loss = 5.0131  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.3625  Validation loss = 5.0130  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.3625  Validation loss = 5.0129  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.3624  Validation loss = 5.0128  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.3623  Validation loss = 5.0126  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.3622  Validation loss = 5.0125  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.3621  Validation loss = 5.0123  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.3620  Validation loss = 5.0122  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.3619  Validation loss = 5.0120  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.3618  Validation loss = 5.0119  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.3617  Validation loss = 5.0118  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.3616  Validation loss = 5.0117  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.3616  Validation loss = 5.0116  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.3615  Validation loss = 5.0114  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.3614  Validation loss = 5.0113  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.3613  Validation loss = 5.0112  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.3612  Validation loss = 5.0110  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.3611  Validation loss = 5.0109  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.3611  Validation loss = 5.0108  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.3610  Validation loss = 5.0107  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.3609  Validation loss = 5.0105  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.3608  Validation loss = 5.0104  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.3607  Validation loss = 5.0103  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.3607  Validation loss = 5.0102  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.3606  Validation loss = 5.0101  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.3605  Validation loss = 5.0099  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.3604  Validation loss = 5.0098  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.3603  Validation loss = 5.0096  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.3602  Validation loss = 5.0095  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.3601  Validation loss = 5.0094  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.3601  Validation loss = 5.0093  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.3600  Validation loss = 5.0092  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.3599  Validation loss = 5.0090  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.3598  Validation loss = 5.0089  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.3597  Validation loss = 5.0088  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.3596  Validation loss = 5.0086  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.3595  Validation loss = 5.0085  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.3594  Validation loss = 5.0084  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.3593  Validation loss = 5.0082  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.3592  Validation loss = 5.0081  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.3591  Validation loss = 5.0080  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.3591  Validation loss = 5.0078  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.3590  Validation loss = 5.0077  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.3589  Validation loss = 5.0076  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.3588  Validation loss = 5.0075  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.3587  Validation loss = 5.0074  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.3586  Validation loss = 5.0072  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.3586  Validation loss = 5.0071  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.3585  Validation loss = 5.0070  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.3584  Validation loss = 5.0069  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.3583  Validation loss = 5.0068  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.3582  Validation loss = 5.0066  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.3582  Validation loss = 5.0065  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.3581  Validation loss = 5.0064  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.3580  Validation loss = 5.0063  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.3579  Validation loss = 5.0062  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.3578  Validation loss = 5.0061  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.3578  Validation loss = 5.0059  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.3577  Validation loss = 5.0058  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.3576  Validation loss = 5.0057  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.3575  Validation loss = 5.0056  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.3574  Validation loss = 5.0055  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.3573  Validation loss = 5.0053  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.3572  Validation loss = 5.0051  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.3572  Validation loss = 5.0050  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.3571  Validation loss = 5.0050  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.3570  Validation loss = 5.0048  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.3569  Validation loss = 5.0047  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.3568  Validation loss = 5.0045  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.3568  Validation loss = 5.0044  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.3567  Validation loss = 5.0043  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.3566  Validation loss = 5.0042  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.3565  Validation loss = 5.0041  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.3564  Validation loss = 5.0039  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.3563  Validation loss = 5.0038  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.3562  Validation loss = 5.0036  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.3561  Validation loss = 5.0035  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.3560  Validation loss = 5.0034  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.3559  Validation loss = 5.0033  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.3558  Validation loss = 5.0031  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.3558  Validation loss = 5.0030  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.3557  Validation loss = 5.0029  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.3556  Validation loss = 5.0028  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.3555  Validation loss = 5.0026  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.3555  Validation loss = 5.0025  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.3554  Validation loss = 5.0024  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.3553  Validation loss = 5.0022  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.3552  Validation loss = 5.0021  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.3551  Validation loss = 5.0020  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.3550  Validation loss = 5.0018  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.3549  Validation loss = 5.0017  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.3548  Validation loss = 5.0015  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.3547  Validation loss = 5.0014  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.3546  Validation loss = 5.0013  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.3545  Validation loss = 5.0012  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.3544  Validation loss = 5.0010  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.3544  Validation loss = 5.0009  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.3543  Validation loss = 5.0008  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.3542  Validation loss = 5.0006  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.3541  Validation loss = 5.0005  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.3540  Validation loss = 5.0004  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.3539  Validation loss = 5.0002  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.3538  Validation loss = 5.0001  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.3537  Validation loss = 5.0000  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.3537  Validation loss = 4.9999  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.3536  Validation loss = 4.9998  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.3535  Validation loss = 4.9996  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.3534  Validation loss = 4.9995  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.3533  Validation loss = 4.9994  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.3533  Validation loss = 4.9993  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.3531  Validation loss = 4.9991  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.3531  Validation loss = 4.9990  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.3530  Validation loss = 4.9989  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.3529  Validation loss = 4.9987  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.3528  Validation loss = 4.9986  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.3527  Validation loss = 4.9985  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.3527  Validation loss = 4.9984  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.3526  Validation loss = 4.9983  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.3525  Validation loss = 4.9981  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.3524  Validation loss = 4.9980  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.3523  Validation loss = 4.9979  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.3522  Validation loss = 4.9978  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.3522  Validation loss = 4.9977  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.3521  Validation loss = 4.9975  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.3520  Validation loss = 4.9974  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.3519  Validation loss = 4.9972  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.3518  Validation loss = 4.9971  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.3517  Validation loss = 4.9970  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.3516  Validation loss = 4.9968  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.3516  Validation loss = 4.9967  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.3515  Validation loss = 4.9966  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.3514  Validation loss = 4.9965  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.3513  Validation loss = 4.9963  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.3512  Validation loss = 4.9962  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.3511  Validation loss = 4.9961  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.3510  Validation loss = 4.9960  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.3509  Validation loss = 4.9958  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.3508  Validation loss = 4.9957  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.3507  Validation loss = 4.9955  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.3507  Validation loss = 4.9954  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.3506  Validation loss = 4.9953  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.3505  Validation loss = 4.9952  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.3504  Validation loss = 4.9950  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.3503  Validation loss = 4.9949  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.3502  Validation loss = 4.9948  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.3501  Validation loss = 4.9946  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.3500  Validation loss = 4.9945  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.3500  Validation loss = 4.9944  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.3499  Validation loss = 4.9942  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.3498  Validation loss = 4.9941  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.3497  Validation loss = 4.9940  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.3496  Validation loss = 4.9938  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.3495  Validation loss = 4.9937  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.3495  Validation loss = 4.9936  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.3494  Validation loss = 4.9935  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.3493  Validation loss = 4.9934  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.3492  Validation loss = 4.9932  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.3491  Validation loss = 4.9931  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.3490  Validation loss = 4.9930  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.3489  Validation loss = 4.9928  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.3488  Validation loss = 4.9927  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.3487  Validation loss = 4.9925  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.3486  Validation loss = 4.9924  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.3486  Validation loss = 4.9923  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.3485  Validation loss = 4.9922  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.3484  Validation loss = 4.9920  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.3483  Validation loss = 4.9919  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.3482  Validation loss = 4.9917  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.3481  Validation loss = 4.9916  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.3480  Validation loss = 4.9915  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.3480  Validation loss = 4.9914  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.3479  Validation loss = 4.9912  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.3478  Validation loss = 4.9911  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.3477  Validation loss = 4.9910  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.3476  Validation loss = 4.9909  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.3475  Validation loss = 4.9907  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.3475  Validation loss = 4.9906  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.3474  Validation loss = 4.9905  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.3473  Validation loss = 4.9903  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.3472  Validation loss = 4.9902  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.3471  Validation loss = 4.9901  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.3470  Validation loss = 4.9900  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.3469  Validation loss = 4.9898  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.3469  Validation loss = 4.9898  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.3468  Validation loss = 4.9896  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.3467  Validation loss = 4.9895  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.3466  Validation loss = 4.9894  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.3465  Validation loss = 4.9893  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.3464  Validation loss = 4.9891  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.3463  Validation loss = 4.9890  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.3463  Validation loss = 4.9889  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.3462  Validation loss = 4.9887  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.3461  Validation loss = 4.9886  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.3460  Validation loss = 4.9885  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.3459  Validation loss = 4.9884  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.3459  Validation loss = 4.9883  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.3458  Validation loss = 4.9881  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.3457  Validation loss = 4.9880  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.3456  Validation loss = 4.9879  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.3455  Validation loss = 4.9877  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.3455  Validation loss = 4.9876  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.3454  Validation loss = 4.9875  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.3453  Validation loss = 4.9874  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.3452  Validation loss = 4.9873  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.3452  Validation loss = 4.9872  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.3451  Validation loss = 4.9871  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.3450  Validation loss = 4.9870  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.3449  Validation loss = 4.9868  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.3448  Validation loss = 4.9867  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.3447  Validation loss = 4.9865  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.3446  Validation loss = 4.9864  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.3446  Validation loss = 4.9863  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.3445  Validation loss = 4.9861  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.3444  Validation loss = 4.9860  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.3443  Validation loss = 4.9859  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.3442  Validation loss = 4.9857  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.3441  Validation loss = 4.9856  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.3440  Validation loss = 4.9855  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.3439  Validation loss = 4.9854  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.3438  Validation loss = 4.9852  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.3437  Validation loss = 4.9851  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.3436  Validation loss = 4.9849  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.3435  Validation loss = 4.9847  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.3435  Validation loss = 4.9847  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.3434  Validation loss = 4.9845  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.3433  Validation loss = 4.9844  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.3432  Validation loss = 4.9843  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.3432  Validation loss = 4.9842  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.3431  Validation loss = 4.9840  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.3430  Validation loss = 4.9840  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.3429  Validation loss = 4.9838  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.3428  Validation loss = 4.9837  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.3428  Validation loss = 4.9836  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.3427  Validation loss = 4.9835  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.3426  Validation loss = 4.9834  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.3425  Validation loss = 4.9832  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.3425  Validation loss = 4.9831  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.3424  Validation loss = 4.9830  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.3423  Validation loss = 4.9829  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.3422  Validation loss = 4.9828  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.3421  Validation loss = 4.9827  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.3421  Validation loss = 4.9825  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.3419  Validation loss = 4.9824  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.3419  Validation loss = 4.9823  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.3418  Validation loss = 4.9821  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.3417  Validation loss = 4.9820  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.3416  Validation loss = 4.9818  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.3415  Validation loss = 4.9817  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.3414  Validation loss = 4.9816  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.3413  Validation loss = 4.9815  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.3412  Validation loss = 4.9813  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.3412  Validation loss = 4.9812  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.3411  Validation loss = 4.9811  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.3410  Validation loss = 4.9810  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.3409  Validation loss = 4.9808  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.3408  Validation loss = 4.9807  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.3408  Validation loss = 4.9806  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.3407  Validation loss = 4.9805  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.3406  Validation loss = 4.9804  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.3405  Validation loss = 4.9803  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.3404  Validation loss = 4.9801  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.3404  Validation loss = 4.9800  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.3403  Validation loss = 4.9799  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.3402  Validation loss = 4.9798  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.3402  Validation loss = 4.9797  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.3401  Validation loss = 4.9796  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.3400  Validation loss = 4.9795  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.3399  Validation loss = 4.9794  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.3398  Validation loss = 4.9792  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.3398  Validation loss = 4.9791  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.3397  Validation loss = 4.9790  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.3396  Validation loss = 4.9789  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.3395  Validation loss = 4.9787  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.3394  Validation loss = 4.9786  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.3394  Validation loss = 4.9785  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.3393  Validation loss = 4.9784  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.3392  Validation loss = 4.9783  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.3391  Validation loss = 4.9782  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.3391  Validation loss = 4.9780  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.3390  Validation loss = 4.9779  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.3389  Validation loss = 4.9778  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.3388  Validation loss = 4.9777  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.3387  Validation loss = 4.9776  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.3387  Validation loss = 4.9775  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.3386  Validation loss = 4.9773  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.3385  Validation loss = 4.9772  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.3384  Validation loss = 4.9771  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.3384  Validation loss = 4.9770  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.3383  Validation loss = 4.9769  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.3382  Validation loss = 4.9768  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.3381  Validation loss = 4.9767  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.3381  Validation loss = 4.9766  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.3380  Validation loss = 4.9764  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.3379  Validation loss = 4.9763  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.3378  Validation loss = 4.9762  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.3377  Validation loss = 4.9761  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.3377  Validation loss = 4.9760  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.3376  Validation loss = 4.9758  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.3375  Validation loss = 4.9757  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.3374  Validation loss = 4.9756  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.3373  Validation loss = 4.9755  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.3373  Validation loss = 4.9754  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.3372  Validation loss = 4.9752  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.3371  Validation loss = 4.9751  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.3370  Validation loss = 4.9750  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.3369  Validation loss = 4.9749  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.3369  Validation loss = 4.9747  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.3368  Validation loss = 4.9746  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.3367  Validation loss = 4.9745  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.3366  Validation loss = 4.9743  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.3365  Validation loss = 4.9742  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.3364  Validation loss = 4.9741  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.3364  Validation loss = 4.9740  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.3363  Validation loss = 4.9739  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.3362  Validation loss = 4.9738  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.3362  Validation loss = 4.9737  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.3361  Validation loss = 4.9735  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.3360  Validation loss = 4.9734  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.3359  Validation loss = 4.9733  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.3358  Validation loss = 4.9732  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.3358  Validation loss = 4.9731  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.3357  Validation loss = 4.9730  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.3356  Validation loss = 4.9728  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.3355  Validation loss = 4.9727  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.3355  Validation loss = 4.9726  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.3354  Validation loss = 4.9725  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.3353  Validation loss = 4.9724  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.3353  Validation loss = 4.9723  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.3352  Validation loss = 4.9722  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.3351  Validation loss = 4.9721  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.3350  Validation loss = 4.9720  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.3350  Validation loss = 4.9719  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.3349  Validation loss = 4.9717  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.3348  Validation loss = 4.9716  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.3347  Validation loss = 4.9715  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.3346  Validation loss = 4.9714  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.3346  Validation loss = 4.9713  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.3345  Validation loss = 4.9711  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.3344  Validation loss = 4.9710  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.3342  Validation loss = 4.9708  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.3341  Validation loss = 4.9706  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.3340  Validation loss = 4.9705  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.3340  Validation loss = 4.9704  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.3339  Validation loss = 4.9702  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.3338  Validation loss = 4.9701  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.3337  Validation loss = 4.9700  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.3337  Validation loss = 4.9699  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.3336  Validation loss = 4.9698  \n",
      "\n",
      "Fold: 5  Epoch: 501  Training loss = 2.3335  Validation loss = 4.9697  \n",
      "\n",
      "Fold: 5  Epoch: 502  Training loss = 2.3334  Validation loss = 4.9695  \n",
      "\n",
      "Fold: 5  Epoch: 503  Training loss = 2.3334  Validation loss = 4.9694  \n",
      "\n",
      "Fold: 5  Epoch: 504  Training loss = 2.3333  Validation loss = 4.9693  \n",
      "\n",
      "Fold: 5  Epoch: 505  Training loss = 2.3332  Validation loss = 4.9692  \n",
      "\n",
      "Fold: 5  Epoch: 506  Training loss = 2.3331  Validation loss = 4.9691  \n",
      "\n",
      "Fold: 5  Epoch: 507  Training loss = 2.3330  Validation loss = 4.9689  \n",
      "\n",
      "Fold: 5  Epoch: 508  Training loss = 2.3329  Validation loss = 4.9688  \n",
      "\n",
      "Fold: 5  Epoch: 509  Training loss = 2.3329  Validation loss = 4.9687  \n",
      "\n",
      "Fold: 5  Epoch: 510  Training loss = 2.3328  Validation loss = 4.9686  \n",
      "\n",
      "Fold: 5  Epoch: 511  Training loss = 2.3327  Validation loss = 4.9685  \n",
      "\n",
      "Fold: 5  Epoch: 512  Training loss = 2.3326  Validation loss = 4.9683  \n",
      "\n",
      "Fold: 5  Epoch: 513  Training loss = 2.3326  Validation loss = 4.9683  \n",
      "\n",
      "Fold: 5  Epoch: 514  Training loss = 2.3325  Validation loss = 4.9681  \n",
      "\n",
      "Fold: 5  Epoch: 515  Training loss = 2.3324  Validation loss = 4.9679  \n",
      "\n",
      "Fold: 5  Epoch: 516  Training loss = 2.3323  Validation loss = 4.9678  \n",
      "\n",
      "Fold: 5  Epoch: 517  Training loss = 2.3322  Validation loss = 4.9677  \n",
      "\n",
      "Fold: 5  Epoch: 518  Training loss = 2.3321  Validation loss = 4.9675  \n",
      "\n",
      "Fold: 5  Epoch: 519  Training loss = 2.3320  Validation loss = 4.9674  \n",
      "\n",
      "Fold: 5  Epoch: 520  Training loss = 2.3319  Validation loss = 4.9673  \n",
      "\n",
      "Fold: 5  Epoch: 521  Training loss = 2.3319  Validation loss = 4.9672  \n",
      "\n",
      "Fold: 5  Epoch: 522  Training loss = 2.3318  Validation loss = 4.9670  \n",
      "\n",
      "Fold: 5  Epoch: 523  Training loss = 2.3317  Validation loss = 4.9669  \n",
      "\n",
      "Fold: 5  Epoch: 524  Training loss = 2.3316  Validation loss = 4.9668  \n",
      "\n",
      "Fold: 5  Epoch: 525  Training loss = 2.3315  Validation loss = 4.9666  \n",
      "\n",
      "Fold: 5  Epoch: 526  Training loss = 2.3314  Validation loss = 4.9665  \n",
      "\n",
      "Fold: 5  Epoch: 527  Training loss = 2.3313  Validation loss = 4.9664  \n",
      "\n",
      "Fold: 5  Epoch: 528  Training loss = 2.3312  Validation loss = 4.9662  \n",
      "\n",
      "Fold: 5  Epoch: 529  Training loss = 2.3311  Validation loss = 4.9661  \n",
      "\n",
      "Fold: 5  Epoch: 530  Training loss = 2.3311  Validation loss = 4.9660  \n",
      "\n",
      "Fold: 5  Epoch: 531  Training loss = 2.3310  Validation loss = 4.9658  \n",
      "\n",
      "Fold: 5  Epoch: 532  Training loss = 2.3309  Validation loss = 4.9657  \n",
      "\n",
      "Fold: 5  Epoch: 533  Training loss = 2.3308  Validation loss = 4.9655  \n",
      "\n",
      "Fold: 5  Epoch: 534  Training loss = 2.3307  Validation loss = 4.9654  \n",
      "\n",
      "Fold: 5  Epoch: 535  Training loss = 2.3306  Validation loss = 4.9652  \n",
      "\n",
      "Fold: 5  Epoch: 536  Training loss = 2.3305  Validation loss = 4.9651  \n",
      "\n",
      "Fold: 5  Epoch: 537  Training loss = 2.3304  Validation loss = 4.9650  \n",
      "\n",
      "Fold: 5  Epoch: 538  Training loss = 2.3303  Validation loss = 4.9649  \n",
      "\n",
      "Fold: 5  Epoch: 539  Training loss = 2.3302  Validation loss = 4.9647  \n",
      "\n",
      "Fold: 5  Epoch: 540  Training loss = 2.3302  Validation loss = 4.9646  \n",
      "\n",
      "Fold: 5  Epoch: 541  Training loss = 2.3301  Validation loss = 4.9645  \n",
      "\n",
      "Fold: 5  Epoch: 542  Training loss = 2.3300  Validation loss = 4.9643  \n",
      "\n",
      "Fold: 5  Epoch: 543  Training loss = 2.3299  Validation loss = 4.9642  \n",
      "\n",
      "Fold: 5  Epoch: 544  Training loss = 2.3298  Validation loss = 4.9641  \n",
      "\n",
      "Fold: 5  Epoch: 545  Training loss = 2.3298  Validation loss = 4.9640  \n",
      "\n",
      "Fold: 5  Epoch: 546  Training loss = 2.3297  Validation loss = 4.9639  \n",
      "\n",
      "Fold: 5  Epoch: 547  Training loss = 2.3296  Validation loss = 4.9638  \n",
      "\n",
      "Fold: 5  Epoch: 548  Training loss = 2.3295  Validation loss = 4.9637  \n",
      "\n",
      "Fold: 5  Epoch: 549  Training loss = 2.3294  Validation loss = 4.9635  \n",
      "\n",
      "Fold: 5  Epoch: 550  Training loss = 2.3293  Validation loss = 4.9634  \n",
      "\n",
      "Fold: 5  Epoch: 551  Training loss = 2.3293  Validation loss = 4.9632  \n",
      "\n",
      "Fold: 5  Epoch: 552  Training loss = 2.3292  Validation loss = 4.9631  \n",
      "\n",
      "Fold: 5  Epoch: 553  Training loss = 2.3291  Validation loss = 4.9630  \n",
      "\n",
      "Fold: 5  Epoch: 554  Training loss = 2.3290  Validation loss = 4.9628  \n",
      "\n",
      "Fold: 5  Epoch: 555  Training loss = 2.3289  Validation loss = 4.9627  \n",
      "\n",
      "Fold: 5  Epoch: 556  Training loss = 2.3288  Validation loss = 4.9625  \n",
      "\n",
      "Fold: 5  Epoch: 557  Training loss = 2.3287  Validation loss = 4.9624  \n",
      "\n",
      "Fold: 5  Epoch: 558  Training loss = 2.3286  Validation loss = 4.9623  \n",
      "\n",
      "Fold: 5  Epoch: 559  Training loss = 2.3285  Validation loss = 4.9621  \n",
      "\n",
      "Fold: 5  Epoch: 560  Training loss = 2.3284  Validation loss = 4.9620  \n",
      "\n",
      "Fold: 5  Epoch: 561  Training loss = 2.3284  Validation loss = 4.9619  \n",
      "\n",
      "Fold: 5  Epoch: 562  Training loss = 2.3283  Validation loss = 4.9618  \n",
      "\n",
      "Fold: 5  Epoch: 563  Training loss = 2.3282  Validation loss = 4.9616  \n",
      "\n",
      "Fold: 5  Epoch: 564  Training loss = 2.3281  Validation loss = 4.9615  \n",
      "\n",
      "Fold: 5  Epoch: 565  Training loss = 2.3281  Validation loss = 4.9614  \n",
      "\n",
      "Fold: 5  Epoch: 566  Training loss = 2.3280  Validation loss = 4.9613  \n",
      "\n",
      "Fold: 5  Epoch: 567  Training loss = 2.3279  Validation loss = 4.9612  \n",
      "\n",
      "Fold: 5  Epoch: 568  Training loss = 2.3278  Validation loss = 4.9611  \n",
      "\n",
      "Fold: 5  Epoch: 569  Training loss = 2.3277  Validation loss = 4.9609  \n",
      "\n",
      "Fold: 5  Epoch: 570  Training loss = 2.3277  Validation loss = 4.9608  \n",
      "\n",
      "Fold: 5  Epoch: 571  Training loss = 2.3276  Validation loss = 4.9607  \n",
      "\n",
      "Fold: 5  Epoch: 572  Training loss = 2.3275  Validation loss = 4.9606  \n",
      "\n",
      "Fold: 5  Epoch: 573  Training loss = 2.3274  Validation loss = 4.9605  \n",
      "\n",
      "Fold: 5  Epoch: 574  Training loss = 2.3273  Validation loss = 4.9603  \n",
      "\n",
      "Fold: 5  Epoch: 575  Training loss = 2.3273  Validation loss = 4.9602  \n",
      "\n",
      "Fold: 5  Epoch: 576  Training loss = 2.3272  Validation loss = 4.9601  \n",
      "\n",
      "Fold: 5  Epoch: 577  Training loss = 2.3271  Validation loss = 4.9599  \n",
      "\n",
      "Fold: 5  Epoch: 578  Training loss = 2.3270  Validation loss = 4.9598  \n",
      "\n",
      "Fold: 5  Epoch: 579  Training loss = 2.3269  Validation loss = 4.9597  \n",
      "\n",
      "Fold: 5  Epoch: 580  Training loss = 2.3269  Validation loss = 4.9596  \n",
      "\n",
      "Fold: 5  Epoch: 581  Training loss = 2.3268  Validation loss = 4.9594  \n",
      "\n",
      "Fold: 5  Epoch: 582  Training loss = 2.3266  Validation loss = 4.9592  \n",
      "\n",
      "Fold: 5  Epoch: 583  Training loss = 2.3266  Validation loss = 4.9591  \n",
      "\n",
      "Fold: 5  Epoch: 584  Training loss = 2.3265  Validation loss = 4.9590  \n",
      "\n",
      "Fold: 5  Epoch: 585  Training loss = 2.3264  Validation loss = 4.9589  \n",
      "\n",
      "Fold: 5  Epoch: 586  Training loss = 2.3263  Validation loss = 4.9588  \n",
      "\n",
      "Fold: 5  Epoch: 587  Training loss = 2.3262  Validation loss = 4.9586  \n",
      "\n",
      "Fold: 5  Epoch: 588  Training loss = 2.3262  Validation loss = 4.9585  \n",
      "\n",
      "Fold: 5  Epoch: 589  Training loss = 2.3261  Validation loss = 4.9584  \n",
      "\n",
      "Fold: 5  Epoch: 590  Training loss = 2.3260  Validation loss = 4.9583  \n",
      "\n",
      "Fold: 5  Epoch: 591  Training loss = 2.3260  Validation loss = 4.9582  \n",
      "\n",
      "Fold: 5  Epoch: 592  Training loss = 2.3259  Validation loss = 4.9581  \n",
      "\n",
      "Fold: 5  Epoch: 593  Training loss = 2.3258  Validation loss = 4.9580  \n",
      "\n",
      "Fold: 5  Epoch: 594  Training loss = 2.3257  Validation loss = 4.9578  \n",
      "\n",
      "Fold: 5  Epoch: 595  Training loss = 2.3257  Validation loss = 4.9577  \n",
      "\n",
      "Fold: 5  Epoch: 596  Training loss = 2.3256  Validation loss = 4.9576  \n",
      "\n",
      "Fold: 5  Epoch: 597  Training loss = 2.3255  Validation loss = 4.9575  \n",
      "\n",
      "Fold: 5  Epoch: 598  Training loss = 2.3254  Validation loss = 4.9573  \n",
      "\n",
      "Fold: 5  Epoch: 599  Training loss = 2.3253  Validation loss = 4.9572  \n",
      "\n",
      "Fold: 5  Epoch: 600  Training loss = 2.3252  Validation loss = 4.9571  \n",
      "\n",
      "Fold: 5  Epoch: 601  Training loss = 2.3252  Validation loss = 4.9570  \n",
      "\n",
      "Fold: 5  Epoch: 602  Training loss = 2.3251  Validation loss = 4.9568  \n",
      "\n",
      "Fold: 5  Epoch: 603  Training loss = 2.3250  Validation loss = 4.9567  \n",
      "\n",
      "Fold: 5  Epoch: 604  Training loss = 2.3249  Validation loss = 4.9566  \n",
      "\n",
      "Fold: 5  Epoch: 605  Training loss = 2.3248  Validation loss = 4.9565  \n",
      "\n",
      "Fold: 5  Epoch: 606  Training loss = 2.3248  Validation loss = 4.9564  \n",
      "\n",
      "Fold: 5  Epoch: 607  Training loss = 2.3247  Validation loss = 4.9562  \n",
      "\n",
      "Fold: 5  Epoch: 608  Training loss = 2.3246  Validation loss = 4.9561  \n",
      "\n",
      "Fold: 5  Epoch: 609  Training loss = 2.3245  Validation loss = 4.9560  \n",
      "\n",
      "Fold: 5  Epoch: 610  Training loss = 2.3244  Validation loss = 4.9559  \n",
      "\n",
      "Fold: 5  Epoch: 611  Training loss = 2.3244  Validation loss = 4.9558  \n",
      "\n",
      "Fold: 5  Epoch: 612  Training loss = 2.3243  Validation loss = 4.9557  \n",
      "\n",
      "Fold: 5  Epoch: 613  Training loss = 2.3242  Validation loss = 4.9556  \n",
      "\n",
      "Fold: 5  Epoch: 614  Training loss = 2.3242  Validation loss = 4.9554  \n",
      "\n",
      "Fold: 5  Epoch: 615  Training loss = 2.3241  Validation loss = 4.9553  \n",
      "\n",
      "Fold: 5  Epoch: 616  Training loss = 2.3240  Validation loss = 4.9552  \n",
      "\n",
      "Fold: 5  Epoch: 617  Training loss = 2.3239  Validation loss = 4.9551  \n",
      "\n",
      "Fold: 5  Epoch: 618  Training loss = 2.3238  Validation loss = 4.9550  \n",
      "\n",
      "Fold: 5  Epoch: 619  Training loss = 2.3238  Validation loss = 4.9549  \n",
      "\n",
      "Fold: 5  Epoch: 620  Training loss = 2.3237  Validation loss = 4.9547  \n",
      "\n",
      "Fold: 5  Epoch: 621  Training loss = 2.3236  Validation loss = 4.9546  \n",
      "\n",
      "Fold: 5  Epoch: 622  Training loss = 2.3235  Validation loss = 4.9545  \n",
      "\n",
      "Fold: 5  Epoch: 623  Training loss = 2.3234  Validation loss = 4.9543  \n",
      "\n",
      "Fold: 5  Epoch: 624  Training loss = 2.3234  Validation loss = 4.9542  \n",
      "\n",
      "Fold: 5  Epoch: 625  Training loss = 2.3233  Validation loss = 4.9541  \n",
      "\n",
      "Fold: 5  Epoch: 626  Training loss = 2.3232  Validation loss = 4.9540  \n",
      "\n",
      "Fold: 5  Epoch: 627  Training loss = 2.3231  Validation loss = 4.9539  \n",
      "\n",
      "Fold: 5  Epoch: 628  Training loss = 2.3230  Validation loss = 4.9538  \n",
      "\n",
      "Fold: 5  Epoch: 629  Training loss = 2.3230  Validation loss = 4.9536  \n",
      "\n",
      "Fold: 5  Epoch: 630  Training loss = 2.3229  Validation loss = 4.9535  \n",
      "\n",
      "Fold: 5  Epoch: 631  Training loss = 2.3228  Validation loss = 4.9533  \n",
      "\n",
      "Fold: 5  Epoch: 632  Training loss = 2.3227  Validation loss = 4.9532  \n",
      "\n",
      "Fold: 5  Epoch: 633  Training loss = 2.3226  Validation loss = 4.9531  \n",
      "\n",
      "Fold: 5  Epoch: 634  Training loss = 2.3225  Validation loss = 4.9529  \n",
      "\n",
      "Fold: 5  Epoch: 635  Training loss = 2.3224  Validation loss = 4.9528  \n",
      "\n",
      "Fold: 5  Epoch: 636  Training loss = 2.3223  Validation loss = 4.9527  \n",
      "\n",
      "Fold: 5  Epoch: 637  Training loss = 2.3223  Validation loss = 4.9526  \n",
      "\n",
      "Fold: 5  Epoch: 638  Training loss = 2.3222  Validation loss = 4.9525  \n",
      "\n",
      "Fold: 5  Epoch: 639  Training loss = 2.3221  Validation loss = 4.9523  \n",
      "\n",
      "Fold: 5  Epoch: 640  Training loss = 2.3220  Validation loss = 4.9522  \n",
      "\n",
      "Fold: 5  Epoch: 641  Training loss = 2.3220  Validation loss = 4.9521  \n",
      "\n",
      "Fold: 5  Epoch: 642  Training loss = 2.3219  Validation loss = 4.9519  \n",
      "\n",
      "Fold: 5  Epoch: 643  Training loss = 2.3218  Validation loss = 4.9518  \n",
      "\n",
      "Fold: 5  Epoch: 644  Training loss = 2.3217  Validation loss = 4.9517  \n",
      "\n",
      "Fold: 5  Epoch: 645  Training loss = 2.3216  Validation loss = 4.9516  \n",
      "\n",
      "Fold: 5  Epoch: 646  Training loss = 2.3215  Validation loss = 4.9514  \n",
      "\n",
      "Fold: 5  Epoch: 647  Training loss = 2.3214  Validation loss = 4.9513  \n",
      "\n",
      "Fold: 5  Epoch: 648  Training loss = 2.3214  Validation loss = 4.9512  \n",
      "\n",
      "Fold: 5  Epoch: 649  Training loss = 2.3213  Validation loss = 4.9510  \n",
      "\n",
      "Fold: 5  Epoch: 650  Training loss = 2.3212  Validation loss = 4.9509  \n",
      "\n",
      "Fold: 5  Epoch: 651  Training loss = 2.3211  Validation loss = 4.9508  \n",
      "\n",
      "Fold: 5  Epoch: 652  Training loss = 2.3210  Validation loss = 4.9507  \n",
      "\n",
      "Fold: 5  Epoch: 653  Training loss = 2.3210  Validation loss = 4.9506  \n",
      "\n",
      "Fold: 5  Epoch: 654  Training loss = 2.3209  Validation loss = 4.9505  \n",
      "\n",
      "Fold: 5  Epoch: 655  Training loss = 2.3208  Validation loss = 4.9503  \n",
      "\n",
      "Fold: 5  Epoch: 656  Training loss = 2.3207  Validation loss = 4.9502  \n",
      "\n",
      "Fold: 5  Epoch: 657  Training loss = 2.3207  Validation loss = 4.9501  \n",
      "\n",
      "Fold: 5  Epoch: 658  Training loss = 2.3206  Validation loss = 4.9499  \n",
      "\n",
      "Fold: 5  Epoch: 659  Training loss = 2.3205  Validation loss = 4.9499  \n",
      "\n",
      "Fold: 5  Epoch: 660  Training loss = 2.3204  Validation loss = 4.9497  \n",
      "\n",
      "Fold: 5  Epoch: 661  Training loss = 2.3203  Validation loss = 4.9496  \n",
      "\n",
      "Fold: 5  Epoch: 662  Training loss = 2.3203  Validation loss = 4.9495  \n",
      "\n",
      "Fold: 5  Epoch: 663  Training loss = 2.3201  Validation loss = 4.9493  \n",
      "\n",
      "Fold: 5  Epoch: 664  Training loss = 2.3200  Validation loss = 4.9491  \n",
      "\n",
      "Fold: 5  Epoch: 665  Training loss = 2.3200  Validation loss = 4.9490  \n",
      "\n",
      "Fold: 5  Epoch: 666  Training loss = 2.3199  Validation loss = 4.9489  \n",
      "\n",
      "Fold: 5  Epoch: 667  Training loss = 2.3198  Validation loss = 4.9488  \n",
      "\n",
      "Fold: 5  Epoch: 668  Training loss = 2.3197  Validation loss = 4.9486  \n",
      "\n",
      "Fold: 5  Epoch: 669  Training loss = 2.3196  Validation loss = 4.9485  \n",
      "\n",
      "Fold: 5  Epoch: 670  Training loss = 2.3196  Validation loss = 4.9484  \n",
      "\n",
      "Fold: 5  Epoch: 671  Training loss = 2.3195  Validation loss = 4.9483  \n",
      "\n",
      "Fold: 5  Epoch: 672  Training loss = 2.3194  Validation loss = 4.9481  \n",
      "\n",
      "Fold: 5  Epoch: 673  Training loss = 2.3193  Validation loss = 4.9480  \n",
      "\n",
      "Fold: 5  Epoch: 674  Training loss = 2.3192  Validation loss = 4.9479  \n",
      "\n",
      "Fold: 5  Epoch: 675  Training loss = 2.3191  Validation loss = 4.9478  \n",
      "\n",
      "Fold: 5  Epoch: 676  Training loss = 2.3191  Validation loss = 4.9476  \n",
      "\n",
      "Fold: 5  Epoch: 677  Training loss = 2.3190  Validation loss = 4.9475  \n",
      "\n",
      "Fold: 5  Epoch: 678  Training loss = 2.3189  Validation loss = 4.9474  \n",
      "\n",
      "Fold: 5  Epoch: 679  Training loss = 2.3188  Validation loss = 4.9473  \n",
      "\n",
      "Fold: 5  Epoch: 680  Training loss = 2.3187  Validation loss = 4.9471  \n",
      "\n",
      "Fold: 5  Epoch: 681  Training loss = 2.3187  Validation loss = 4.9470  \n",
      "\n",
      "Fold: 5  Epoch: 682  Training loss = 2.3186  Validation loss = 4.9469  \n",
      "\n",
      "Fold: 5  Epoch: 683  Training loss = 2.3185  Validation loss = 4.9468  \n",
      "\n",
      "Fold: 5  Epoch: 684  Training loss = 2.3184  Validation loss = 4.9467  \n",
      "\n",
      "Fold: 5  Epoch: 685  Training loss = 2.3184  Validation loss = 4.9466  \n",
      "\n",
      "Fold: 5  Epoch: 686  Training loss = 2.3183  Validation loss = 4.9465  \n",
      "\n",
      "Fold: 5  Epoch: 687  Training loss = 2.3182  Validation loss = 4.9463  \n",
      "\n",
      "Fold: 5  Epoch: 688  Training loss = 2.3182  Validation loss = 4.9463  \n",
      "\n",
      "Fold: 5  Epoch: 689  Training loss = 2.3181  Validation loss = 4.9461  \n",
      "\n",
      "Fold: 5  Epoch: 690  Training loss = 2.3180  Validation loss = 4.9460  \n",
      "\n",
      "Fold: 5  Epoch: 691  Training loss = 2.3179  Validation loss = 4.9459  \n",
      "\n",
      "Fold: 5  Epoch: 692  Training loss = 2.3179  Validation loss = 4.9458  \n",
      "\n",
      "Fold: 5  Epoch: 693  Training loss = 2.3178  Validation loss = 4.9456  \n",
      "\n",
      "Fold: 5  Epoch: 694  Training loss = 2.3177  Validation loss = 4.9455  \n",
      "\n",
      "Fold: 5  Epoch: 695  Training loss = 2.3176  Validation loss = 4.9454  \n",
      "\n",
      "Fold: 5  Epoch: 696  Training loss = 2.3175  Validation loss = 4.9453  \n",
      "\n",
      "Fold: 5  Epoch: 697  Training loss = 2.3174  Validation loss = 4.9451  \n",
      "\n",
      "Fold: 5  Epoch: 698  Training loss = 2.3174  Validation loss = 4.9451  \n",
      "\n",
      "Fold: 5  Epoch: 699  Training loss = 2.3173  Validation loss = 4.9449  \n",
      "\n",
      "Fold: 5  Epoch: 700  Training loss = 2.3172  Validation loss = 4.9448  \n",
      "\n",
      "Fold: 5  Epoch: 701  Training loss = 2.3172  Validation loss = 4.9447  \n",
      "\n",
      "Fold: 5  Epoch: 702  Training loss = 2.3171  Validation loss = 4.9446  \n",
      "\n",
      "Fold: 5  Epoch: 703  Training loss = 2.3170  Validation loss = 4.9445  \n",
      "\n",
      "Fold: 5  Epoch: 704  Training loss = 2.3169  Validation loss = 4.9444  \n",
      "\n",
      "Fold: 5  Epoch: 705  Training loss = 2.3169  Validation loss = 4.9442  \n",
      "\n",
      "Fold: 5  Epoch: 706  Training loss = 2.3167  Validation loss = 4.9441  \n",
      "\n",
      "Fold: 5  Epoch: 707  Training loss = 2.3167  Validation loss = 4.9439  \n",
      "\n",
      "Fold: 5  Epoch: 708  Training loss = 2.3166  Validation loss = 4.9438  \n",
      "\n",
      "Fold: 5  Epoch: 709  Training loss = 2.3165  Validation loss = 4.9437  \n",
      "\n",
      "Fold: 5  Epoch: 710  Training loss = 2.3164  Validation loss = 4.9436  \n",
      "\n",
      "Fold: 5  Epoch: 711  Training loss = 2.3164  Validation loss = 4.9435  \n",
      "\n",
      "Fold: 5  Epoch: 712  Training loss = 2.3163  Validation loss = 4.9433  \n",
      "\n",
      "Fold: 5  Epoch: 713  Training loss = 2.3162  Validation loss = 4.9432  \n",
      "\n",
      "Fold: 5  Epoch: 714  Training loss = 2.3161  Validation loss = 4.9431  \n",
      "\n",
      "Fold: 5  Epoch: 715  Training loss = 2.3160  Validation loss = 4.9430  \n",
      "\n",
      "Fold: 5  Epoch: 716  Training loss = 2.3160  Validation loss = 4.9429  \n",
      "\n",
      "Fold: 5  Epoch: 717  Training loss = 2.3159  Validation loss = 4.9427  \n",
      "\n",
      "Fold: 5  Epoch: 718  Training loss = 2.3158  Validation loss = 4.9426  \n",
      "\n",
      "Fold: 5  Epoch: 719  Training loss = 2.3157  Validation loss = 4.9425  \n",
      "\n",
      "Fold: 5  Epoch: 720  Training loss = 2.3157  Validation loss = 4.9424  \n",
      "\n",
      "Fold: 5  Epoch: 721  Training loss = 2.3156  Validation loss = 4.9423  \n",
      "\n",
      "Fold: 5  Epoch: 722  Training loss = 2.3155  Validation loss = 4.9422  \n",
      "\n",
      "Fold: 5  Epoch: 723  Training loss = 2.3154  Validation loss = 4.9420  \n",
      "\n",
      "Fold: 5  Epoch: 724  Training loss = 2.3153  Validation loss = 4.9418  \n",
      "\n",
      "Fold: 5  Epoch: 725  Training loss = 2.3152  Validation loss = 4.9417  \n",
      "\n",
      "Fold: 5  Epoch: 726  Training loss = 2.3152  Validation loss = 4.9416  \n",
      "\n",
      "Fold: 5  Epoch: 727  Training loss = 2.3151  Validation loss = 4.9415  \n",
      "\n",
      "Fold: 5  Epoch: 728  Training loss = 2.3150  Validation loss = 4.9414  \n",
      "\n",
      "Fold: 5  Epoch: 729  Training loss = 2.3149  Validation loss = 4.9413  \n",
      "\n",
      "Fold: 5  Epoch: 730  Training loss = 2.3148  Validation loss = 4.9412  \n",
      "\n",
      "Fold: 5  Epoch: 731  Training loss = 2.3148  Validation loss = 4.9410  \n",
      "\n",
      "Fold: 5  Epoch: 732  Training loss = 2.3147  Validation loss = 4.9409  \n",
      "\n",
      "Fold: 5  Epoch: 733  Training loss = 2.3146  Validation loss = 4.9407  \n",
      "\n",
      "Fold: 5  Epoch: 734  Training loss = 2.3145  Validation loss = 4.9406  \n",
      "\n",
      "Fold: 5  Epoch: 735  Training loss = 2.3144  Validation loss = 4.9405  \n",
      "\n",
      "Fold: 5  Epoch: 736  Training loss = 2.3143  Validation loss = 4.9404  \n",
      "\n",
      "Fold: 5  Epoch: 737  Training loss = 2.3143  Validation loss = 4.9403  \n",
      "\n",
      "Fold: 5  Epoch: 738  Training loss = 2.3142  Validation loss = 4.9402  \n",
      "\n",
      "Fold: 5  Epoch: 739  Training loss = 2.3141  Validation loss = 4.9400  \n",
      "\n",
      "Fold: 5  Epoch: 740  Training loss = 2.3140  Validation loss = 4.9399  \n",
      "\n",
      "Fold: 5  Epoch: 741  Training loss = 2.3140  Validation loss = 4.9398  \n",
      "\n",
      "Fold: 5  Epoch: 742  Training loss = 2.3139  Validation loss = 4.9397  \n",
      "\n",
      "Fold: 5  Epoch: 743  Training loss = 2.3139  Validation loss = 4.9396  \n",
      "\n",
      "Fold: 5  Epoch: 744  Training loss = 2.3138  Validation loss = 4.9395  \n",
      "\n",
      "Fold: 5  Epoch: 745  Training loss = 2.3137  Validation loss = 4.9394  \n",
      "\n",
      "Fold: 5  Epoch: 746  Training loss = 2.3136  Validation loss = 4.9393  \n",
      "\n",
      "Fold: 5  Epoch: 747  Training loss = 2.3135  Validation loss = 4.9391  \n",
      "\n",
      "Fold: 5  Epoch: 748  Training loss = 2.3135  Validation loss = 4.9390  \n",
      "\n",
      "Fold: 5  Epoch: 749  Training loss = 2.3134  Validation loss = 4.9389  \n",
      "\n",
      "Fold: 5  Epoch: 750  Training loss = 2.3133  Validation loss = 4.9388  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 750  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.6109  Validation loss = 2.8819  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.6108  Validation loss = 2.8817  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.6107  Validation loss = 2.8815  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.6106  Validation loss = 2.8813  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.6105  Validation loss = 2.8812  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.6104  Validation loss = 2.8810  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.6103  Validation loss = 2.8808  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.6102  Validation loss = 2.8806  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.6101  Validation loss = 2.8805  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.6100  Validation loss = 2.8802  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.6099  Validation loss = 2.8801  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.6098  Validation loss = 2.8799  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.6097  Validation loss = 2.8797  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.6095  Validation loss = 2.8795  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.6094  Validation loss = 2.8793  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.6093  Validation loss = 2.8791  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.6092  Validation loss = 2.8789  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.6091  Validation loss = 2.8788  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.6090  Validation loss = 2.8786  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.6089  Validation loss = 2.8784  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.6088  Validation loss = 2.8782  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.6087  Validation loss = 2.8780  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.6086  Validation loss = 2.8778  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.6085  Validation loss = 2.8776  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.6084  Validation loss = 2.8774  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.6082  Validation loss = 2.8772  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.6082  Validation loss = 2.8771  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.6081  Validation loss = 2.8769  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.6079  Validation loss = 2.8767  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.6079  Validation loss = 2.8766  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.6077  Validation loss = 2.8764  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.6076  Validation loss = 2.8762  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.6075  Validation loss = 2.8760  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.6074  Validation loss = 2.8759  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.6073  Validation loss = 2.8757  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.6072  Validation loss = 2.8755  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.6071  Validation loss = 2.8753  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.6070  Validation loss = 2.8752  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.6069  Validation loss = 2.8750  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.6068  Validation loss = 2.8748  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.6067  Validation loss = 2.8746  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.6066  Validation loss = 2.8745  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.6065  Validation loss = 2.8742  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.6064  Validation loss = 2.8741  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.6063  Validation loss = 2.8739  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.6062  Validation loss = 2.8738  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.6061  Validation loss = 2.8736  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.6060  Validation loss = 2.8734  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.6059  Validation loss = 2.8732  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.6058  Validation loss = 2.8730  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.6057  Validation loss = 2.8729  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.6056  Validation loss = 2.8727  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.6055  Validation loss = 2.8725  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.6054  Validation loss = 2.8723  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.6053  Validation loss = 2.8722  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.6052  Validation loss = 2.8720  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.6051  Validation loss = 2.8718  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.6049  Validation loss = 2.8716  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.6048  Validation loss = 2.8714  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.6047  Validation loss = 2.8712  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.6046  Validation loss = 2.8710  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.6045  Validation loss = 2.8708  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.6044  Validation loss = 2.8706  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.6043  Validation loss = 2.8705  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.6041  Validation loss = 2.8703  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.6041  Validation loss = 2.8701  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.6040  Validation loss = 2.8699  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.6039  Validation loss = 2.8698  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.6038  Validation loss = 2.8696  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.6037  Validation loss = 2.8695  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.6036  Validation loss = 2.8693  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.6035  Validation loss = 2.8691  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.6034  Validation loss = 2.8690  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.6033  Validation loss = 2.8688  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.6032  Validation loss = 2.8687  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.6031  Validation loss = 2.8685  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.6030  Validation loss = 2.8683  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.6029  Validation loss = 2.8681  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.6028  Validation loss = 2.8680  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.6027  Validation loss = 2.8678  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.6026  Validation loss = 2.8676  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.6025  Validation loss = 2.8675  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.6024  Validation loss = 2.8673  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.6023  Validation loss = 2.8671  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.6022  Validation loss = 2.8668  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.6021  Validation loss = 2.8667  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.6020  Validation loss = 2.8665  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.6019  Validation loss = 2.8664  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.6018  Validation loss = 2.8661  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.6016  Validation loss = 2.8659  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.6016  Validation loss = 2.8658  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.6015  Validation loss = 2.8656  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.6014  Validation loss = 2.8655  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.6012  Validation loss = 2.8652  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.6011  Validation loss = 2.8650  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.6010  Validation loss = 2.8649  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.6010  Validation loss = 2.8647  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.6008  Validation loss = 2.8645  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.6007  Validation loss = 2.8643  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.6006  Validation loss = 2.8642  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.6005  Validation loss = 2.8639  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.6004  Validation loss = 2.8638  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.6003  Validation loss = 2.8635  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.6002  Validation loss = 2.8633  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.6001  Validation loss = 2.8632  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.6000  Validation loss = 2.8629  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.5998  Validation loss = 2.8627  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.5997  Validation loss = 2.8625  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.5996  Validation loss = 2.8623  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.5995  Validation loss = 2.8621  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.5994  Validation loss = 2.8619  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.5993  Validation loss = 2.8617  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.5992  Validation loss = 2.8616  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.5990  Validation loss = 2.8613  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.5990  Validation loss = 2.8612  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.5989  Validation loss = 2.8610  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.5988  Validation loss = 2.8608  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.5987  Validation loss = 2.8607  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.5986  Validation loss = 2.8605  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.5985  Validation loss = 2.8603  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.5984  Validation loss = 2.8601  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.5982  Validation loss = 2.8599  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.5981  Validation loss = 2.8597  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.5980  Validation loss = 2.8595  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.5979  Validation loss = 2.8593  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.5978  Validation loss = 2.8591  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.5977  Validation loss = 2.8589  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.5976  Validation loss = 2.8587  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.5974  Validation loss = 2.8585  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.5973  Validation loss = 2.8583  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.5972  Validation loss = 2.8581  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.5971  Validation loss = 2.8579  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.5970  Validation loss = 2.8577  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.5969  Validation loss = 2.8576  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.5968  Validation loss = 2.8574  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.5967  Validation loss = 2.8572  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.5966  Validation loss = 2.8570  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.5965  Validation loss = 2.8569  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.5964  Validation loss = 2.8567  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.5963  Validation loss = 2.8566  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.5962  Validation loss = 2.8564  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.5961  Validation loss = 2.8562  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.5960  Validation loss = 2.8560  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.5959  Validation loss = 2.8558  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.5958  Validation loss = 2.8556  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.5957  Validation loss = 2.8554  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.5956  Validation loss = 2.8553  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.5955  Validation loss = 2.8551  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.5954  Validation loss = 2.8549  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.5953  Validation loss = 2.8548  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.5952  Validation loss = 2.8546  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.5951  Validation loss = 2.8544  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.5950  Validation loss = 2.8542  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.5949  Validation loss = 2.8540  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.5948  Validation loss = 2.8539  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.5947  Validation loss = 2.8537  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.5946  Validation loss = 2.8535  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.5945  Validation loss = 2.8533  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.5944  Validation loss = 2.8532  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.5943  Validation loss = 2.8530  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.5942  Validation loss = 2.8529  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.5941  Validation loss = 2.8527  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.5940  Validation loss = 2.8525  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.5939  Validation loss = 2.8524  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.5938  Validation loss = 2.8522  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.5937  Validation loss = 2.8520  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.5936  Validation loss = 2.8518  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.5935  Validation loss = 2.8516  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.5934  Validation loss = 2.8515  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.5933  Validation loss = 2.8513  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.5932  Validation loss = 2.8511  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.5931  Validation loss = 2.8509  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.5930  Validation loss = 2.8508  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.5929  Validation loss = 2.8506  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.5928  Validation loss = 2.8503  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.5927  Validation loss = 2.8501  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.5926  Validation loss = 2.8499  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.5925  Validation loss = 2.8498  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.5924  Validation loss = 2.8496  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.5923  Validation loss = 2.8494  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.5922  Validation loss = 2.8492  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.5921  Validation loss = 2.8491  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.5920  Validation loss = 2.8489  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.5919  Validation loss = 2.8487  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.5918  Validation loss = 2.8485  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.5917  Validation loss = 2.8484  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.5916  Validation loss = 2.8482  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.5915  Validation loss = 2.8480  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.5914  Validation loss = 2.8479  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.5913  Validation loss = 2.8477  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.5912  Validation loss = 2.8475  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.5911  Validation loss = 2.8473  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.5909  Validation loss = 2.8470  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.5908  Validation loss = 2.8468  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.5907  Validation loss = 2.8466  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.5906  Validation loss = 2.8464  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.5904  Validation loss = 2.8461  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.5904  Validation loss = 2.8460  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.5903  Validation loss = 2.8459  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.5902  Validation loss = 2.8457  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.5901  Validation loss = 2.8455  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.5900  Validation loss = 2.8453  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.5899  Validation loss = 2.8452  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.5898  Validation loss = 2.8450  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.5897  Validation loss = 2.8448  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.5896  Validation loss = 2.8446  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.5895  Validation loss = 2.8444  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.5894  Validation loss = 2.8443  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.5893  Validation loss = 2.8441  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.5892  Validation loss = 2.8439  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.5891  Validation loss = 2.8437  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.5890  Validation loss = 2.8435  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.5889  Validation loss = 2.8433  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.5888  Validation loss = 2.8431  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.5886  Validation loss = 2.8429  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.5885  Validation loss = 2.8427  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.5884  Validation loss = 2.8424  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.5883  Validation loss = 2.8422  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.5882  Validation loss = 2.8421  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.5881  Validation loss = 2.8419  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.5880  Validation loss = 2.8418  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.5879  Validation loss = 2.8416  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.5878  Validation loss = 2.8414  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.5878  Validation loss = 2.8413  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.5876  Validation loss = 2.8411  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.5875  Validation loss = 2.8409  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.5875  Validation loss = 2.8408  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.5874  Validation loss = 2.8406  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.5872  Validation loss = 2.8404  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.5871  Validation loss = 2.8401  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.5870  Validation loss = 2.8399  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.5869  Validation loss = 2.8397  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.5868  Validation loss = 2.8395  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.5867  Validation loss = 2.8393  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.5866  Validation loss = 2.8391  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.5865  Validation loss = 2.8390  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.5864  Validation loss = 2.8388  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.5862  Validation loss = 2.8386  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.5861  Validation loss = 2.8384  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.5860  Validation loss = 2.8382  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.5859  Validation loss = 2.8380  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.5858  Validation loss = 2.8378  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.5857  Validation loss = 2.8376  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.5856  Validation loss = 2.8375  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.5855  Validation loss = 2.8373  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.5854  Validation loss = 2.8370  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.5853  Validation loss = 2.8368  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.5852  Validation loss = 2.8367  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.5851  Validation loss = 2.8365  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.5850  Validation loss = 2.8363  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.5848  Validation loss = 2.8360  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.5848  Validation loss = 2.8359  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.5847  Validation loss = 2.8358  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.5846  Validation loss = 2.8356  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.5845  Validation loss = 2.8353  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.5843  Validation loss = 2.8351  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.5843  Validation loss = 2.8350  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.5842  Validation loss = 2.8348  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.5841  Validation loss = 2.8347  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.5839  Validation loss = 2.8344  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.5839  Validation loss = 2.8343  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.5838  Validation loss = 2.8341  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.5837  Validation loss = 2.8340  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.5836  Validation loss = 2.8338  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.5834  Validation loss = 2.8335  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.5833  Validation loss = 2.8333  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.5832  Validation loss = 2.8331  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.5831  Validation loss = 2.8329  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.5830  Validation loss = 2.8328  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.5829  Validation loss = 2.8326  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.5828  Validation loss = 2.8323  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.5827  Validation loss = 2.8321  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.5826  Validation loss = 2.8319  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.5825  Validation loss = 2.8317  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.5824  Validation loss = 2.8316  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.5822  Validation loss = 2.8313  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.5821  Validation loss = 2.8311  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.5820  Validation loss = 2.8309  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.5819  Validation loss = 2.8308  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.5818  Validation loss = 2.8305  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.5817  Validation loss = 2.8304  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.5816  Validation loss = 2.8303  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.5815  Validation loss = 2.8300  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.5814  Validation loss = 2.8298  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.5813  Validation loss = 2.8297  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.5812  Validation loss = 2.8295  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.5811  Validation loss = 2.8293  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.5810  Validation loss = 2.8292  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.5809  Validation loss = 2.8290  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.5808  Validation loss = 2.8288  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.5807  Validation loss = 2.8286  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.5807  Validation loss = 2.8285  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.5806  Validation loss = 2.8283  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.5804  Validation loss = 2.8281  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.5804  Validation loss = 2.8279  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.5803  Validation loss = 2.8277  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.5802  Validation loss = 2.8276  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.5800  Validation loss = 2.8274  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.5799  Validation loss = 2.8272  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.5799  Validation loss = 2.8270  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.5797  Validation loss = 2.8268  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.5796  Validation loss = 2.8266  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.5795  Validation loss = 2.8264  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.5794  Validation loss = 2.8261  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.5793  Validation loss = 2.8259  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.5792  Validation loss = 2.8258  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.5791  Validation loss = 2.8255  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.5789  Validation loss = 2.8254  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.5788  Validation loss = 2.8252  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.5787  Validation loss = 2.8250  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.5787  Validation loss = 2.8248  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.5786  Validation loss = 2.8247  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.5785  Validation loss = 2.8245  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.5784  Validation loss = 2.8243  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.5782  Validation loss = 2.8241  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.5782  Validation loss = 2.8239  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.5781  Validation loss = 2.8238  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.5780  Validation loss = 2.8236  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.5779  Validation loss = 2.8234  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.5778  Validation loss = 2.8232  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.5777  Validation loss = 2.8230  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.5775  Validation loss = 2.8228  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.5774  Validation loss = 2.8226  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.5773  Validation loss = 2.8224  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.5772  Validation loss = 2.8222  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.5771  Validation loss = 2.8221  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.5770  Validation loss = 2.8218  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.5769  Validation loss = 2.8216  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.5768  Validation loss = 2.8214  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.5767  Validation loss = 2.8212  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.5766  Validation loss = 2.8210  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.5765  Validation loss = 2.8208  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.5764  Validation loss = 2.8207  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.5763  Validation loss = 2.8205  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.5762  Validation loss = 2.8203  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.5761  Validation loss = 2.8201  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.5760  Validation loss = 2.8199  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.5759  Validation loss = 2.8197  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.5757  Validation loss = 2.8195  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.5756  Validation loss = 2.8193  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.5755  Validation loss = 2.8191  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.5754  Validation loss = 2.8189  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.5753  Validation loss = 2.8187  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.5752  Validation loss = 2.8185  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.5751  Validation loss = 2.8183  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.5750  Validation loss = 2.8182  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.5749  Validation loss = 2.8179  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.5748  Validation loss = 2.8178  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.5747  Validation loss = 2.8176  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.5746  Validation loss = 2.8174  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.5745  Validation loss = 2.8172  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.5744  Validation loss = 2.8170  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.5743  Validation loss = 2.8168  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.5742  Validation loss = 2.8167  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.5741  Validation loss = 2.8165  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.5740  Validation loss = 2.8163  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.5739  Validation loss = 2.8161  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.5738  Validation loss = 2.8160  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.5737  Validation loss = 2.8158  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.5736  Validation loss = 2.8156  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.5735  Validation loss = 2.8154  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.5734  Validation loss = 2.8152  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.5733  Validation loss = 2.8150  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.5732  Validation loss = 2.8149  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.5732  Validation loss = 2.8148  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.5731  Validation loss = 2.8146  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.5730  Validation loss = 2.8144  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.5729  Validation loss = 2.8142  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.5728  Validation loss = 2.8141  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.5727  Validation loss = 2.8139  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.5726  Validation loss = 2.8137  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.5725  Validation loss = 2.8135  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.5723  Validation loss = 2.8132  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.5722  Validation loss = 2.8130  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.5721  Validation loss = 2.8129  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.5720  Validation loss = 2.8127  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.5719  Validation loss = 2.8124  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.5718  Validation loss = 2.8122  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.5717  Validation loss = 2.8120  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.5716  Validation loss = 2.8119  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.5715  Validation loss = 2.8117  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.5714  Validation loss = 2.8115  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.5713  Validation loss = 2.8114  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.5712  Validation loss = 2.8111  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.5711  Validation loss = 2.8109  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.5709  Validation loss = 2.8107  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.5709  Validation loss = 2.8105  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.5708  Validation loss = 2.8103  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.5707  Validation loss = 2.8102  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.5706  Validation loss = 2.8100  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.5704  Validation loss = 2.8097  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.5703  Validation loss = 2.8095  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.5702  Validation loss = 2.8093  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.5701  Validation loss = 2.8090  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.5700  Validation loss = 2.8088  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.5699  Validation loss = 2.8086  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.5698  Validation loss = 2.8084  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.5697  Validation loss = 2.8083  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.5696  Validation loss = 2.8081  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.5695  Validation loss = 2.8080  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.5694  Validation loss = 2.8078  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.5693  Validation loss = 2.8076  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.5692  Validation loss = 2.8074  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.5691  Validation loss = 2.8072  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.5690  Validation loss = 2.8071  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.5689  Validation loss = 2.8069  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.5688  Validation loss = 2.8066  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.5687  Validation loss = 2.8065  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.5686  Validation loss = 2.8063  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.5685  Validation loss = 2.8061  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.5684  Validation loss = 2.8059  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.5683  Validation loss = 2.8057  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.5682  Validation loss = 2.8055  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.5681  Validation loss = 2.8053  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.5680  Validation loss = 2.8051  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.5679  Validation loss = 2.8049  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.5678  Validation loss = 2.8047  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.5677  Validation loss = 2.8046  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.5676  Validation loss = 2.8044  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.5675  Validation loss = 2.8042  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.5674  Validation loss = 2.8041  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.5673  Validation loss = 2.8039  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.5672  Validation loss = 2.8037  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.5671  Validation loss = 2.8036  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.5670  Validation loss = 2.8034  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.5669  Validation loss = 2.8032  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.5669  Validation loss = 2.8031  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.5667  Validation loss = 2.8028  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.5666  Validation loss = 2.8026  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.5666  Validation loss = 2.8025  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.5664  Validation loss = 2.8023  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.5664  Validation loss = 2.8021  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.5663  Validation loss = 2.8019  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.5662  Validation loss = 2.8018  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.5661  Validation loss = 2.8016  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.5660  Validation loss = 2.8014  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.5659  Validation loss = 2.8012  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.5658  Validation loss = 2.8011  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.5657  Validation loss = 2.8009  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.5657  Validation loss = 2.8008  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.5655  Validation loss = 2.8006  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.5654  Validation loss = 2.8004  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.5653  Validation loss = 2.8002  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.5652  Validation loss = 2.8000  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.5651  Validation loss = 2.7998  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.5650  Validation loss = 2.7997  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.5649  Validation loss = 2.7995  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.5648  Validation loss = 2.7993  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.5647  Validation loss = 2.7991  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.5646  Validation loss = 2.7989  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.5645  Validation loss = 2.7987  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.5644  Validation loss = 2.7986  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.5644  Validation loss = 2.7984  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.5642  Validation loss = 2.7982  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.5641  Validation loss = 2.7980  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.5640  Validation loss = 2.7978  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.5639  Validation loss = 2.7976  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.5638  Validation loss = 2.7974  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.5637  Validation loss = 2.7972  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.5636  Validation loss = 2.7970  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.5635  Validation loss = 2.7968  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.5634  Validation loss = 2.7966  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.5633  Validation loss = 2.7964  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.5632  Validation loss = 2.7962  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.5631  Validation loss = 2.7961  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.5630  Validation loss = 2.7959  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.5629  Validation loss = 2.7957  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.5628  Validation loss = 2.7955  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.5627  Validation loss = 2.7953  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.5626  Validation loss = 2.7952  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.5625  Validation loss = 2.7950  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.5625  Validation loss = 2.7948  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.5624  Validation loss = 2.7946  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.5622  Validation loss = 2.7944  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.5621  Validation loss = 2.7942  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.5621  Validation loss = 2.7941  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.5619  Validation loss = 2.7939  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.5619  Validation loss = 2.7937  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.5617  Validation loss = 2.7935  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.5616  Validation loss = 2.7932  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.5615  Validation loss = 2.7930  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.5614  Validation loss = 2.7929  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.5613  Validation loss = 2.7926  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.5612  Validation loss = 2.7924  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.5611  Validation loss = 2.7922  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.5610  Validation loss = 2.7921  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.5609  Validation loss = 2.7919  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.5608  Validation loss = 2.7917  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.5607  Validation loss = 2.7915  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.5606  Validation loss = 2.7913  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.5605  Validation loss = 2.7912  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.5604  Validation loss = 2.7910  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.5603  Validation loss = 2.7907  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.5602  Validation loss = 2.7905  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.5601  Validation loss = 2.7903  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.5600  Validation loss = 2.7901  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.5599  Validation loss = 2.7899  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.5598  Validation loss = 2.7897  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.5596  Validation loss = 2.7894  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.5595  Validation loss = 2.7892  \n",
      "\n",
      "Fold: 6  Epoch: 501  Training loss = 2.5594  Validation loss = 2.7890  \n",
      "\n",
      "Fold: 6  Epoch: 502  Training loss = 2.5593  Validation loss = 2.7888  \n",
      "\n",
      "Fold: 6  Epoch: 503  Training loss = 2.5592  Validation loss = 2.7886  \n",
      "\n",
      "Fold: 6  Epoch: 504  Training loss = 2.5591  Validation loss = 2.7885  \n",
      "\n",
      "Fold: 6  Epoch: 505  Training loss = 2.5590  Validation loss = 2.7883  \n",
      "\n",
      "Fold: 6  Epoch: 506  Training loss = 2.5590  Validation loss = 2.7881  \n",
      "\n",
      "Fold: 6  Epoch: 507  Training loss = 2.5589  Validation loss = 2.7879  \n",
      "\n",
      "Fold: 6  Epoch: 508  Training loss = 2.5587  Validation loss = 2.7877  \n",
      "\n",
      "Fold: 6  Epoch: 509  Training loss = 2.5586  Validation loss = 2.7875  \n",
      "\n",
      "Fold: 6  Epoch: 510  Training loss = 2.5585  Validation loss = 2.7873  \n",
      "\n",
      "Fold: 6  Epoch: 511  Training loss = 2.5584  Validation loss = 2.7871  \n",
      "\n",
      "Fold: 6  Epoch: 512  Training loss = 2.5583  Validation loss = 2.7870  \n",
      "\n",
      "Fold: 6  Epoch: 513  Training loss = 2.5582  Validation loss = 2.7868  \n",
      "\n",
      "Fold: 6  Epoch: 514  Training loss = 2.5581  Validation loss = 2.7866  \n",
      "\n",
      "Fold: 6  Epoch: 515  Training loss = 2.5581  Validation loss = 2.7865  \n",
      "\n",
      "Fold: 6  Epoch: 516  Training loss = 2.5580  Validation loss = 2.7863  \n",
      "\n",
      "Fold: 6  Epoch: 517  Training loss = 2.5579  Validation loss = 2.7861  \n",
      "\n",
      "Fold: 6  Epoch: 518  Training loss = 2.5577  Validation loss = 2.7858  \n",
      "\n",
      "Fold: 6  Epoch: 519  Training loss = 2.5576  Validation loss = 2.7856  \n",
      "\n",
      "Fold: 6  Epoch: 520  Training loss = 2.5575  Validation loss = 2.7854  \n",
      "\n",
      "Fold: 6  Epoch: 521  Training loss = 2.5574  Validation loss = 2.7852  \n",
      "\n",
      "Fold: 6  Epoch: 522  Training loss = 2.5573  Validation loss = 2.7850  \n",
      "\n",
      "Fold: 6  Epoch: 523  Training loss = 2.5573  Validation loss = 2.7849  \n",
      "\n",
      "Fold: 6  Epoch: 524  Training loss = 2.5572  Validation loss = 2.7847  \n",
      "\n",
      "Fold: 6  Epoch: 525  Training loss = 2.5571  Validation loss = 2.7845  \n",
      "\n",
      "Fold: 6  Epoch: 526  Training loss = 2.5570  Validation loss = 2.7843  \n",
      "\n",
      "Fold: 6  Epoch: 527  Training loss = 2.5569  Validation loss = 2.7841  \n",
      "\n",
      "Fold: 6  Epoch: 528  Training loss = 2.5568  Validation loss = 2.7840  \n",
      "\n",
      "Fold: 6  Epoch: 529  Training loss = 2.5567  Validation loss = 2.7837  \n",
      "\n",
      "Fold: 6  Epoch: 530  Training loss = 2.5566  Validation loss = 2.7835  \n",
      "\n",
      "Fold: 6  Epoch: 531  Training loss = 2.5565  Validation loss = 2.7833  \n",
      "\n",
      "Fold: 6  Epoch: 532  Training loss = 2.5563  Validation loss = 2.7830  \n",
      "\n",
      "Fold: 6  Epoch: 533  Training loss = 2.5562  Validation loss = 2.7828  \n",
      "\n",
      "Fold: 6  Epoch: 534  Training loss = 2.5561  Validation loss = 2.7826  \n",
      "\n",
      "Fold: 6  Epoch: 535  Training loss = 2.5560  Validation loss = 2.7824  \n",
      "\n",
      "Fold: 6  Epoch: 536  Training loss = 2.5559  Validation loss = 2.7822  \n",
      "\n",
      "Fold: 6  Epoch: 537  Training loss = 2.5558  Validation loss = 2.7821  \n",
      "\n",
      "Fold: 6  Epoch: 538  Training loss = 2.5557  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 6  Epoch: 539  Training loss = 2.5556  Validation loss = 2.7816  \n",
      "\n",
      "Fold: 6  Epoch: 540  Training loss = 2.5555  Validation loss = 2.7815  \n",
      "\n",
      "Fold: 6  Epoch: 541  Training loss = 2.5554  Validation loss = 2.7812  \n",
      "\n",
      "Fold: 6  Epoch: 542  Training loss = 2.5553  Validation loss = 2.7810  \n",
      "\n",
      "Fold: 6  Epoch: 543  Training loss = 2.5552  Validation loss = 2.7808  \n",
      "\n",
      "Fold: 6  Epoch: 544  Training loss = 2.5551  Validation loss = 2.7807  \n",
      "\n",
      "Fold: 6  Epoch: 545  Training loss = 2.5550  Validation loss = 2.7805  \n",
      "\n",
      "Fold: 6  Epoch: 546  Training loss = 2.5549  Validation loss = 2.7803  \n",
      "\n",
      "Fold: 6  Epoch: 547  Training loss = 2.5548  Validation loss = 2.7801  \n",
      "\n",
      "Fold: 6  Epoch: 548  Training loss = 2.5547  Validation loss = 2.7800  \n",
      "\n",
      "Fold: 6  Epoch: 549  Training loss = 2.5546  Validation loss = 2.7798  \n",
      "\n",
      "Fold: 6  Epoch: 550  Training loss = 2.5546  Validation loss = 2.7797  \n",
      "\n",
      "Fold: 6  Epoch: 551  Training loss = 2.5545  Validation loss = 2.7796  \n",
      "\n",
      "Fold: 6  Epoch: 552  Training loss = 2.5544  Validation loss = 2.7794  \n",
      "\n",
      "Fold: 6  Epoch: 553  Training loss = 2.5543  Validation loss = 2.7792  \n",
      "\n",
      "Fold: 6  Epoch: 554  Training loss = 2.5542  Validation loss = 2.7790  \n",
      "\n",
      "Fold: 6  Epoch: 555  Training loss = 2.5541  Validation loss = 2.7789  \n",
      "\n",
      "Fold: 6  Epoch: 556  Training loss = 2.5540  Validation loss = 2.7786  \n",
      "\n",
      "Fold: 6  Epoch: 557  Training loss = 2.5539  Validation loss = 2.7784  \n",
      "\n",
      "Fold: 6  Epoch: 558  Training loss = 2.5538  Validation loss = 2.7782  \n",
      "\n",
      "Fold: 6  Epoch: 559  Training loss = 2.5537  Validation loss = 2.7780  \n",
      "\n",
      "Fold: 6  Epoch: 560  Training loss = 2.5536  Validation loss = 2.7778  \n",
      "\n",
      "Fold: 6  Epoch: 561  Training loss = 2.5535  Validation loss = 2.7777  \n",
      "\n",
      "Fold: 6  Epoch: 562  Training loss = 2.5534  Validation loss = 2.7775  \n",
      "\n",
      "Fold: 6  Epoch: 563  Training loss = 2.5533  Validation loss = 2.7774  \n",
      "\n",
      "Fold: 6  Epoch: 564  Training loss = 2.5532  Validation loss = 2.7772  \n",
      "\n",
      "Fold: 6  Epoch: 565  Training loss = 2.5531  Validation loss = 2.7770  \n",
      "\n",
      "Fold: 6  Epoch: 566  Training loss = 2.5530  Validation loss = 2.7768  \n",
      "\n",
      "Fold: 6  Epoch: 567  Training loss = 2.5529  Validation loss = 2.7766  \n",
      "\n",
      "Fold: 6  Epoch: 568  Training loss = 2.5528  Validation loss = 2.7764  \n",
      "\n",
      "Fold: 6  Epoch: 569  Training loss = 2.5527  Validation loss = 2.7762  \n",
      "\n",
      "Fold: 6  Epoch: 570  Training loss = 2.5526  Validation loss = 2.7759  \n",
      "\n",
      "Fold: 6  Epoch: 571  Training loss = 2.5525  Validation loss = 2.7757  \n",
      "\n",
      "Fold: 6  Epoch: 572  Training loss = 2.5524  Validation loss = 2.7755  \n",
      "\n",
      "Fold: 6  Epoch: 573  Training loss = 2.5523  Validation loss = 2.7754  \n",
      "\n",
      "Fold: 6  Epoch: 574  Training loss = 2.5522  Validation loss = 2.7752  \n",
      "\n",
      "Fold: 6  Epoch: 575  Training loss = 2.5521  Validation loss = 2.7750  \n",
      "\n",
      "Fold: 6  Epoch: 576  Training loss = 2.5520  Validation loss = 2.7748  \n",
      "\n",
      "Fold: 6  Epoch: 577  Training loss = 2.5519  Validation loss = 2.7746  \n",
      "\n",
      "Fold: 6  Epoch: 578  Training loss = 2.5518  Validation loss = 2.7744  \n",
      "\n",
      "Fold: 6  Epoch: 579  Training loss = 2.5517  Validation loss = 2.7742  \n",
      "\n",
      "Fold: 6  Epoch: 580  Training loss = 2.5516  Validation loss = 2.7741  \n",
      "\n",
      "Fold: 6  Epoch: 581  Training loss = 2.5515  Validation loss = 2.7739  \n",
      "\n",
      "Fold: 6  Epoch: 582  Training loss = 2.5514  Validation loss = 2.7736  \n",
      "\n",
      "Fold: 6  Epoch: 583  Training loss = 2.5513  Validation loss = 2.7735  \n",
      "\n",
      "Fold: 6  Epoch: 584  Training loss = 2.5512  Validation loss = 2.7733  \n",
      "\n",
      "Fold: 6  Epoch: 585  Training loss = 2.5511  Validation loss = 2.7731  \n",
      "\n",
      "Fold: 6  Epoch: 586  Training loss = 2.5510  Validation loss = 2.7729  \n",
      "\n",
      "Fold: 6  Epoch: 587  Training loss = 2.5509  Validation loss = 2.7727  \n",
      "\n",
      "Fold: 6  Epoch: 588  Training loss = 2.5508  Validation loss = 2.7725  \n",
      "\n",
      "Fold: 6  Epoch: 589  Training loss = 2.5507  Validation loss = 2.7723  \n",
      "\n",
      "Fold: 6  Epoch: 590  Training loss = 2.5506  Validation loss = 2.7721  \n",
      "\n",
      "Fold: 6  Epoch: 591  Training loss = 2.5505  Validation loss = 2.7720  \n",
      "\n",
      "Fold: 6  Epoch: 592  Training loss = 2.5504  Validation loss = 2.7718  \n",
      "\n",
      "Fold: 6  Epoch: 593  Training loss = 2.5503  Validation loss = 2.7716  \n",
      "\n",
      "Fold: 6  Epoch: 594  Training loss = 2.5502  Validation loss = 2.7714  \n",
      "\n",
      "Fold: 6  Epoch: 595  Training loss = 2.5501  Validation loss = 2.7712  \n",
      "\n",
      "Fold: 6  Epoch: 596  Training loss = 2.5500  Validation loss = 2.7710  \n",
      "\n",
      "Fold: 6  Epoch: 597  Training loss = 2.5499  Validation loss = 2.7709  \n",
      "\n",
      "Fold: 6  Epoch: 598  Training loss = 2.5498  Validation loss = 2.7707  \n",
      "\n",
      "Fold: 6  Epoch: 599  Training loss = 2.5497  Validation loss = 2.7705  \n",
      "\n",
      "Fold: 6  Epoch: 600  Training loss = 2.5496  Validation loss = 2.7702  \n",
      "\n",
      "Fold: 6  Epoch: 601  Training loss = 2.5495  Validation loss = 2.7700  \n",
      "\n",
      "Fold: 6  Epoch: 602  Training loss = 2.5494  Validation loss = 2.7697  \n",
      "\n",
      "Fold: 6  Epoch: 603  Training loss = 2.5493  Validation loss = 2.7696  \n",
      "\n",
      "Fold: 6  Epoch: 604  Training loss = 2.5492  Validation loss = 2.7694  \n",
      "\n",
      "Fold: 6  Epoch: 605  Training loss = 2.5491  Validation loss = 2.7693  \n",
      "\n",
      "Fold: 6  Epoch: 606  Training loss = 2.5490  Validation loss = 2.7690  \n",
      "\n",
      "Fold: 6  Epoch: 607  Training loss = 2.5489  Validation loss = 2.7688  \n",
      "\n",
      "Fold: 6  Epoch: 608  Training loss = 2.5488  Validation loss = 2.7686  \n",
      "\n",
      "Fold: 6  Epoch: 609  Training loss = 2.5487  Validation loss = 2.7685  \n",
      "\n",
      "Fold: 6  Epoch: 610  Training loss = 2.5486  Validation loss = 2.7682  \n",
      "\n",
      "Fold: 6  Epoch: 611  Training loss = 2.5485  Validation loss = 2.7680  \n",
      "\n",
      "Fold: 6  Epoch: 612  Training loss = 2.5484  Validation loss = 2.7679  \n",
      "\n",
      "Fold: 6  Epoch: 613  Training loss = 2.5483  Validation loss = 2.7677  \n",
      "\n",
      "Fold: 6  Epoch: 614  Training loss = 2.5482  Validation loss = 2.7675  \n",
      "\n",
      "Fold: 6  Epoch: 615  Training loss = 2.5481  Validation loss = 2.7673  \n",
      "\n",
      "Fold: 6  Epoch: 616  Training loss = 2.5480  Validation loss = 2.7671  \n",
      "\n",
      "Fold: 6  Epoch: 617  Training loss = 2.5479  Validation loss = 2.7669  \n",
      "\n",
      "Fold: 6  Epoch: 618  Training loss = 2.5478  Validation loss = 2.7667  \n",
      "\n",
      "Fold: 6  Epoch: 619  Training loss = 2.5477  Validation loss = 2.7665  \n",
      "\n",
      "Fold: 6  Epoch: 620  Training loss = 2.5476  Validation loss = 2.7663  \n",
      "\n",
      "Fold: 6  Epoch: 621  Training loss = 2.5475  Validation loss = 2.7661  \n",
      "\n",
      "Fold: 6  Epoch: 622  Training loss = 2.5474  Validation loss = 2.7659  \n",
      "\n",
      "Fold: 6  Epoch: 623  Training loss = 2.5473  Validation loss = 2.7656  \n",
      "\n",
      "Fold: 6  Epoch: 624  Training loss = 2.5472  Validation loss = 2.7655  \n",
      "\n",
      "Fold: 6  Epoch: 625  Training loss = 2.5471  Validation loss = 2.7653  \n",
      "\n",
      "Fold: 6  Epoch: 626  Training loss = 2.5470  Validation loss = 2.7650  \n",
      "\n",
      "Fold: 6  Epoch: 627  Training loss = 2.5469  Validation loss = 2.7649  \n",
      "\n",
      "Fold: 6  Epoch: 628  Training loss = 2.5468  Validation loss = 2.7647  \n",
      "\n",
      "Fold: 6  Epoch: 629  Training loss = 2.5467  Validation loss = 2.7646  \n",
      "\n",
      "Fold: 6  Epoch: 630  Training loss = 2.5466  Validation loss = 2.7643  \n",
      "\n",
      "Fold: 6  Epoch: 631  Training loss = 2.5465  Validation loss = 2.7641  \n",
      "\n",
      "Fold: 6  Epoch: 632  Training loss = 2.5464  Validation loss = 2.7639  \n",
      "\n",
      "Fold: 6  Epoch: 633  Training loss = 2.5463  Validation loss = 2.7636  \n",
      "\n",
      "Fold: 6  Epoch: 634  Training loss = 2.5462  Validation loss = 2.7635  \n",
      "\n",
      "Fold: 6  Epoch: 635  Training loss = 2.5460  Validation loss = 2.7632  \n",
      "\n",
      "Fold: 6  Epoch: 636  Training loss = 2.5460  Validation loss = 2.7631  \n",
      "\n",
      "Fold: 6  Epoch: 637  Training loss = 2.5459  Validation loss = 2.7629  \n",
      "\n",
      "Fold: 6  Epoch: 638  Training loss = 2.5458  Validation loss = 2.7626  \n",
      "\n",
      "Fold: 6  Epoch: 639  Training loss = 2.5456  Validation loss = 2.7624  \n",
      "\n",
      "Fold: 6  Epoch: 640  Training loss = 2.5455  Validation loss = 2.7622  \n",
      "\n",
      "Fold: 6  Epoch: 641  Training loss = 2.5455  Validation loss = 2.7621  \n",
      "\n",
      "Fold: 6  Epoch: 642  Training loss = 2.5454  Validation loss = 2.7619  \n",
      "\n",
      "Fold: 6  Epoch: 643  Training loss = 2.5452  Validation loss = 2.7616  \n",
      "\n",
      "Fold: 6  Epoch: 644  Training loss = 2.5451  Validation loss = 2.7614  \n",
      "\n",
      "Fold: 6  Epoch: 645  Training loss = 2.5451  Validation loss = 2.7612  \n",
      "\n",
      "Fold: 6  Epoch: 646  Training loss = 2.5450  Validation loss = 2.7610  \n",
      "\n",
      "Fold: 6  Epoch: 647  Training loss = 2.5449  Validation loss = 2.7609  \n",
      "\n",
      "Fold: 6  Epoch: 648  Training loss = 2.5448  Validation loss = 2.7607  \n",
      "\n",
      "Fold: 6  Epoch: 649  Training loss = 2.5447  Validation loss = 2.7605  \n",
      "\n",
      "Fold: 6  Epoch: 650  Training loss = 2.5446  Validation loss = 2.7603  \n",
      "\n",
      "Fold: 6  Epoch: 651  Training loss = 2.5445  Validation loss = 2.7601  \n",
      "\n",
      "Fold: 6  Epoch: 652  Training loss = 2.5444  Validation loss = 2.7600  \n",
      "\n",
      "Fold: 6  Epoch: 653  Training loss = 2.5443  Validation loss = 2.7598  \n",
      "\n",
      "Fold: 6  Epoch: 654  Training loss = 2.5442  Validation loss = 2.7596  \n",
      "\n",
      "Fold: 6  Epoch: 655  Training loss = 2.5441  Validation loss = 2.7594  \n",
      "\n",
      "Fold: 6  Epoch: 656  Training loss = 2.5440  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 6  Epoch: 657  Training loss = 2.5439  Validation loss = 2.7590  \n",
      "\n",
      "Fold: 6  Epoch: 658  Training loss = 2.5438  Validation loss = 2.7588  \n",
      "\n",
      "Fold: 6  Epoch: 659  Training loss = 2.5437  Validation loss = 2.7586  \n",
      "\n",
      "Fold: 6  Epoch: 660  Training loss = 2.5436  Validation loss = 2.7584  \n",
      "\n",
      "Fold: 6  Epoch: 661  Training loss = 2.5435  Validation loss = 2.7582  \n",
      "\n",
      "Fold: 6  Epoch: 662  Training loss = 2.5434  Validation loss = 2.7580  \n",
      "\n",
      "Fold: 6  Epoch: 663  Training loss = 2.5433  Validation loss = 2.7578  \n",
      "\n",
      "Fold: 6  Epoch: 664  Training loss = 2.5432  Validation loss = 2.7576  \n",
      "\n",
      "Fold: 6  Epoch: 665  Training loss = 2.5431  Validation loss = 2.7574  \n",
      "\n",
      "Fold: 6  Epoch: 666  Training loss = 2.5430  Validation loss = 2.7573  \n",
      "\n",
      "Fold: 6  Epoch: 667  Training loss = 2.5429  Validation loss = 2.7571  \n",
      "\n",
      "Fold: 6  Epoch: 668  Training loss = 2.5428  Validation loss = 2.7569  \n",
      "\n",
      "Fold: 6  Epoch: 669  Training loss = 2.5427  Validation loss = 2.7567  \n",
      "\n",
      "Fold: 6  Epoch: 670  Training loss = 2.5426  Validation loss = 2.7565  \n",
      "\n",
      "Fold: 6  Epoch: 671  Training loss = 2.5426  Validation loss = 2.7564  \n",
      "\n",
      "Fold: 6  Epoch: 672  Training loss = 2.5425  Validation loss = 2.7562  \n",
      "\n",
      "Fold: 6  Epoch: 673  Training loss = 2.5424  Validation loss = 2.7560  \n",
      "\n",
      "Fold: 6  Epoch: 674  Training loss = 2.5423  Validation loss = 2.7558  \n",
      "\n",
      "Fold: 6  Epoch: 675  Training loss = 2.5422  Validation loss = 2.7557  \n",
      "\n",
      "Fold: 6  Epoch: 676  Training loss = 2.5421  Validation loss = 2.7555  \n",
      "\n",
      "Fold: 6  Epoch: 677  Training loss = 2.5420  Validation loss = 2.7554  \n",
      "\n",
      "Fold: 6  Epoch: 678  Training loss = 2.5419  Validation loss = 2.7552  \n",
      "\n",
      "Fold: 6  Epoch: 679  Training loss = 2.5418  Validation loss = 2.7550  \n",
      "\n",
      "Fold: 6  Epoch: 680  Training loss = 2.5418  Validation loss = 2.7548  \n",
      "\n",
      "Fold: 6  Epoch: 681  Training loss = 2.5417  Validation loss = 2.7547  \n",
      "\n",
      "Fold: 6  Epoch: 682  Training loss = 2.5416  Validation loss = 2.7545  \n",
      "\n",
      "Fold: 6  Epoch: 683  Training loss = 2.5415  Validation loss = 2.7543  \n",
      "\n",
      "Fold: 6  Epoch: 684  Training loss = 2.5414  Validation loss = 2.7541  \n",
      "\n",
      "Fold: 6  Epoch: 685  Training loss = 2.5413  Validation loss = 2.7539  \n",
      "\n",
      "Fold: 6  Epoch: 686  Training loss = 2.5412  Validation loss = 2.7537  \n",
      "\n",
      "Fold: 6  Epoch: 687  Training loss = 2.5411  Validation loss = 2.7536  \n",
      "\n",
      "Fold: 6  Epoch: 688  Training loss = 2.5410  Validation loss = 2.7533  \n",
      "\n",
      "Fold: 6  Epoch: 689  Training loss = 2.5409  Validation loss = 2.7532  \n",
      "\n",
      "Fold: 6  Epoch: 690  Training loss = 2.5408  Validation loss = 2.7530  \n",
      "\n",
      "Fold: 6  Epoch: 691  Training loss = 2.5407  Validation loss = 2.7529  \n",
      "\n",
      "Fold: 6  Epoch: 692  Training loss = 2.5406  Validation loss = 2.7526  \n",
      "\n",
      "Fold: 6  Epoch: 693  Training loss = 2.5405  Validation loss = 2.7524  \n",
      "\n",
      "Fold: 6  Epoch: 694  Training loss = 2.5404  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 6  Epoch: 695  Training loss = 2.5403  Validation loss = 2.7520  \n",
      "\n",
      "Fold: 6  Epoch: 696  Training loss = 2.5402  Validation loss = 2.7519  \n",
      "\n",
      "Fold: 6  Epoch: 697  Training loss = 2.5401  Validation loss = 2.7517  \n",
      "\n",
      "Fold: 6  Epoch: 698  Training loss = 2.5400  Validation loss = 2.7515  \n",
      "\n",
      "Fold: 6  Epoch: 699  Training loss = 2.5399  Validation loss = 2.7513  \n",
      "\n",
      "Fold: 6  Epoch: 700  Training loss = 2.5398  Validation loss = 2.7511  \n",
      "\n",
      "Fold: 6  Epoch: 701  Training loss = 2.5397  Validation loss = 2.7509  \n",
      "\n",
      "Fold: 6  Epoch: 702  Training loss = 2.5396  Validation loss = 2.7508  \n",
      "\n",
      "Fold: 6  Epoch: 703  Training loss = 2.5395  Validation loss = 2.7506  \n",
      "\n",
      "Fold: 6  Epoch: 704  Training loss = 2.5394  Validation loss = 2.7504  \n",
      "\n",
      "Fold: 6  Epoch: 705  Training loss = 2.5393  Validation loss = 2.7502  \n",
      "\n",
      "Fold: 6  Epoch: 706  Training loss = 2.5392  Validation loss = 2.7500  \n",
      "\n",
      "Fold: 6  Epoch: 707  Training loss = 2.5391  Validation loss = 2.7498  \n",
      "\n",
      "Fold: 6  Epoch: 708  Training loss = 2.5390  Validation loss = 2.7496  \n",
      "\n",
      "Fold: 6  Epoch: 709  Training loss = 2.5389  Validation loss = 2.7494  \n",
      "\n",
      "Fold: 6  Epoch: 710  Training loss = 2.5389  Validation loss = 2.7493  \n",
      "\n",
      "Fold: 6  Epoch: 711  Training loss = 2.5388  Validation loss = 2.7491  \n",
      "\n",
      "Fold: 6  Epoch: 712  Training loss = 2.5387  Validation loss = 2.7489  \n",
      "\n",
      "Fold: 6  Epoch: 713  Training loss = 2.5386  Validation loss = 2.7488  \n",
      "\n",
      "Fold: 6  Epoch: 714  Training loss = 2.5385  Validation loss = 2.7485  \n",
      "\n",
      "Fold: 6  Epoch: 715  Training loss = 2.5384  Validation loss = 2.7484  \n",
      "\n",
      "Fold: 6  Epoch: 716  Training loss = 2.5383  Validation loss = 2.7482  \n",
      "\n",
      "Fold: 6  Epoch: 717  Training loss = 2.5382  Validation loss = 2.7479  \n",
      "\n",
      "Fold: 6  Epoch: 718  Training loss = 2.5381  Validation loss = 2.7478  \n",
      "\n",
      "Fold: 6  Epoch: 719  Training loss = 2.5380  Validation loss = 2.7475  \n",
      "\n",
      "Fold: 6  Epoch: 720  Training loss = 2.5379  Validation loss = 2.7473  \n",
      "\n",
      "Fold: 6  Epoch: 721  Training loss = 2.5378  Validation loss = 2.7472  \n",
      "\n",
      "Fold: 6  Epoch: 722  Training loss = 2.5377  Validation loss = 2.7470  \n",
      "\n",
      "Fold: 6  Epoch: 723  Training loss = 2.5376  Validation loss = 2.7468  \n",
      "\n",
      "Fold: 6  Epoch: 724  Training loss = 2.5375  Validation loss = 2.7466  \n",
      "\n",
      "Fold: 6  Epoch: 725  Training loss = 2.5374  Validation loss = 2.7464  \n",
      "\n",
      "Fold: 6  Epoch: 726  Training loss = 2.5373  Validation loss = 2.7462  \n",
      "\n",
      "Fold: 6  Epoch: 727  Training loss = 2.5372  Validation loss = 2.7459  \n",
      "\n",
      "Fold: 6  Epoch: 728  Training loss = 2.5371  Validation loss = 2.7458  \n",
      "\n",
      "Fold: 6  Epoch: 729  Training loss = 2.5370  Validation loss = 2.7456  \n",
      "\n",
      "Fold: 6  Epoch: 730  Training loss = 2.5369  Validation loss = 2.7454  \n",
      "\n",
      "Fold: 6  Epoch: 731  Training loss = 2.5368  Validation loss = 2.7452  \n",
      "\n",
      "Fold: 6  Epoch: 732  Training loss = 2.5367  Validation loss = 2.7450  \n",
      "\n",
      "Fold: 6  Epoch: 733  Training loss = 2.5366  Validation loss = 2.7448  \n",
      "\n",
      "Fold: 6  Epoch: 734  Training loss = 2.5365  Validation loss = 2.7446  \n",
      "\n",
      "Fold: 6  Epoch: 735  Training loss = 2.5364  Validation loss = 2.7444  \n",
      "\n",
      "Fold: 6  Epoch: 736  Training loss = 2.5363  Validation loss = 2.7442  \n",
      "\n",
      "Fold: 6  Epoch: 737  Training loss = 2.5362  Validation loss = 2.7441  \n",
      "\n",
      "Fold: 6  Epoch: 738  Training loss = 2.5362  Validation loss = 2.7439  \n",
      "\n",
      "Fold: 6  Epoch: 739  Training loss = 2.5361  Validation loss = 2.7438  \n",
      "\n",
      "Fold: 6  Epoch: 740  Training loss = 2.5360  Validation loss = 2.7436  \n",
      "\n",
      "Fold: 6  Epoch: 741  Training loss = 2.5359  Validation loss = 2.7434  \n",
      "\n",
      "Fold: 6  Epoch: 742  Training loss = 2.5358  Validation loss = 2.7432  \n",
      "\n",
      "Fold: 6  Epoch: 743  Training loss = 2.5356  Validation loss = 2.7429  \n",
      "\n",
      "Fold: 6  Epoch: 744  Training loss = 2.5355  Validation loss = 2.7427  \n",
      "\n",
      "Fold: 6  Epoch: 745  Training loss = 2.5355  Validation loss = 2.7425  \n",
      "\n",
      "Fold: 6  Epoch: 746  Training loss = 2.5354  Validation loss = 2.7424  \n",
      "\n",
      "Fold: 6  Epoch: 747  Training loss = 2.5353  Validation loss = 2.7422  \n",
      "\n",
      "Fold: 6  Epoch: 748  Training loss = 2.5352  Validation loss = 2.7421  \n",
      "\n",
      "Fold: 6  Epoch: 749  Training loss = 2.5351  Validation loss = 2.7418  \n",
      "\n",
      "Fold: 6  Epoch: 750  Training loss = 2.5350  Validation loss = 2.7416  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 750  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.6050  Validation loss = 2.4275  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.6049  Validation loss = 2.4273  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.6047  Validation loss = 2.4271  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.6046  Validation loss = 2.4270  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.6045  Validation loss = 2.4269  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.6044  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.6043  Validation loss = 2.4266  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.6042  Validation loss = 2.4264  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.6041  Validation loss = 2.4263  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.6039  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.6038  Validation loss = 2.4260  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.6037  Validation loss = 2.4258  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.6036  Validation loss = 2.4257  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.6034  Validation loss = 2.4256  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.6033  Validation loss = 2.4254  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.6032  Validation loss = 2.4252  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.6030  Validation loss = 2.4250  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.6029  Validation loss = 2.4249  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.6027  Validation loss = 2.4247  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.6026  Validation loss = 2.4246  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.6025  Validation loss = 2.4244  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.6023  Validation loss = 2.4243  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.6022  Validation loss = 2.4241  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.6020  Validation loss = 2.4239  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.6019  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.6018  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.6017  Validation loss = 2.4235  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.6016  Validation loss = 2.4234  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.6014  Validation loss = 2.4232  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.6013  Validation loss = 2.4230  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.6012  Validation loss = 2.4229  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.6010  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.6009  Validation loss = 2.4226  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.6008  Validation loss = 2.4224  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.6006  Validation loss = 2.4222  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.6005  Validation loss = 2.4221  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.6003  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.6002  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.6001  Validation loss = 2.4216  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.6000  Validation loss = 2.4215  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.5999  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.5998  Validation loss = 2.4212  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.5997  Validation loss = 2.4211  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.5995  Validation loss = 2.4209  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.5994  Validation loss = 2.4208  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.5993  Validation loss = 2.4206  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.5991  Validation loss = 2.4205  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.5990  Validation loss = 2.4203  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.5989  Validation loss = 2.4202  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.5988  Validation loss = 2.4200  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.5986  Validation loss = 2.4199  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.5985  Validation loss = 2.4197  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.5984  Validation loss = 2.4196  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.5982  Validation loss = 2.4194  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.5981  Validation loss = 2.4193  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.5980  Validation loss = 2.4192  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.5979  Validation loss = 2.4190  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.5977  Validation loss = 2.4188  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.5976  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.5975  Validation loss = 2.4185  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.5973  Validation loss = 2.4183  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.5972  Validation loss = 2.4182  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.5970  Validation loss = 2.4180  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.5969  Validation loss = 2.4178  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.5968  Validation loss = 2.4177  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.5967  Validation loss = 2.4175  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.5965  Validation loss = 2.4174  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.5964  Validation loss = 2.4172  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.5963  Validation loss = 2.4171  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.5962  Validation loss = 2.4169  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.5960  Validation loss = 2.4168  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.5959  Validation loss = 2.4166  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.5958  Validation loss = 2.4165  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.5957  Validation loss = 2.4163  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.5956  Validation loss = 2.4162  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.5955  Validation loss = 2.4161  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.5953  Validation loss = 2.4159  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.5952  Validation loss = 2.4158  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.5951  Validation loss = 2.4156  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.5950  Validation loss = 2.4155  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.5948  Validation loss = 2.4154  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.5947  Validation loss = 2.4152  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.5946  Validation loss = 2.4150  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.5945  Validation loss = 2.4149  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.5943  Validation loss = 2.4147  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.5942  Validation loss = 2.4145  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.5940  Validation loss = 2.4144  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.5939  Validation loss = 2.4142  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.5938  Validation loss = 2.4141  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.5936  Validation loss = 2.4139  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.5935  Validation loss = 2.4138  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.5934  Validation loss = 2.4136  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.5933  Validation loss = 2.4134  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.5931  Validation loss = 2.4133  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.5930  Validation loss = 2.4131  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.5929  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.5928  Validation loss = 2.4128  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.5926  Validation loss = 2.4127  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.5925  Validation loss = 2.4125  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.5924  Validation loss = 2.4124  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.5922  Validation loss = 2.4122  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.5921  Validation loss = 2.4121  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.5920  Validation loss = 2.4119  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.5918  Validation loss = 2.4118  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.5917  Validation loss = 2.4116  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.5916  Validation loss = 2.4114  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.5915  Validation loss = 2.4113  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.5913  Validation loss = 2.4112  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.5912  Validation loss = 2.4110  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.5911  Validation loss = 2.4109  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.5910  Validation loss = 2.4107  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.5908  Validation loss = 2.4105  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.5907  Validation loss = 2.4104  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.5906  Validation loss = 2.4102  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.5904  Validation loss = 2.4101  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.5903  Validation loss = 2.4099  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.5902  Validation loss = 2.4098  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.5901  Validation loss = 2.4096  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.5899  Validation loss = 2.4095  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.5898  Validation loss = 2.4093  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.5897  Validation loss = 2.4092  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.5895  Validation loss = 2.4090  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.5894  Validation loss = 2.4089  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.5893  Validation loss = 2.4087  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.5892  Validation loss = 2.4086  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.5890  Validation loss = 2.4084  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.5889  Validation loss = 2.4082  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.5888  Validation loss = 2.4081  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.5886  Validation loss = 2.4079  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.5885  Validation loss = 2.4077  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.5884  Validation loss = 2.4076  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.5882  Validation loss = 2.4074  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.5881  Validation loss = 2.4072  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.5880  Validation loss = 2.4071  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.5878  Validation loss = 2.4069  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.5877  Validation loss = 2.4068  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.5876  Validation loss = 2.4066  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.5875  Validation loss = 2.4065  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.5873  Validation loss = 2.4064  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.5872  Validation loss = 2.4062  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.5871  Validation loss = 2.4060  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.5869  Validation loss = 2.4059  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.5868  Validation loss = 2.4057  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.5867  Validation loss = 2.4056  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.5866  Validation loss = 2.4054  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.5864  Validation loss = 2.4053  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.5863  Validation loss = 2.4051  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.5862  Validation loss = 2.4050  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.5860  Validation loss = 2.4048  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.5859  Validation loss = 2.4046  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.5858  Validation loss = 2.4045  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.5856  Validation loss = 2.4043  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.5855  Validation loss = 2.4042  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.5854  Validation loss = 2.4040  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.5853  Validation loss = 2.4039  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.5852  Validation loss = 2.4038  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.5850  Validation loss = 2.4036  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.5849  Validation loss = 2.4034  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.5847  Validation loss = 2.4033  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.5846  Validation loss = 2.4031  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.5845  Validation loss = 2.4029  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.5844  Validation loss = 2.4028  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.5842  Validation loss = 2.4027  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.5841  Validation loss = 2.4025  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.5840  Validation loss = 2.4024  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.5839  Validation loss = 2.4022  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.5837  Validation loss = 2.4021  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.5836  Validation loss = 2.4019  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.5835  Validation loss = 2.4018  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.5834  Validation loss = 2.4017  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.5833  Validation loss = 2.4015  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.5831  Validation loss = 2.4013  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.5830  Validation loss = 2.4012  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.5829  Validation loss = 2.4010  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.5828  Validation loss = 2.4009  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.5826  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.5825  Validation loss = 2.4006  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.5824  Validation loss = 2.4004  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.5822  Validation loss = 2.4003  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.5821  Validation loss = 2.4001  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.5820  Validation loss = 2.4000  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.5819  Validation loss = 2.3998  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.5818  Validation loss = 2.3997  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.5816  Validation loss = 2.3995  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.5815  Validation loss = 2.3994  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.5814  Validation loss = 2.3992  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.5813  Validation loss = 2.3991  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.5812  Validation loss = 2.3990  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.5810  Validation loss = 2.3988  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.5809  Validation loss = 2.3986  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.5808  Validation loss = 2.3985  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.5806  Validation loss = 2.3983  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.5805  Validation loss = 2.3982  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.5804  Validation loss = 2.3980  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.5802  Validation loss = 2.3978  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.5801  Validation loss = 2.3977  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.5800  Validation loss = 2.3975  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.5799  Validation loss = 2.3974  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.5797  Validation loss = 2.3972  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.5796  Validation loss = 2.3971  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.5795  Validation loss = 2.3969  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.5793  Validation loss = 2.3968  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.5792  Validation loss = 2.3966  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.5791  Validation loss = 2.3964  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.5789  Validation loss = 2.3963  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.5788  Validation loss = 2.3962  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.5787  Validation loss = 2.3960  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.5785  Validation loss = 2.3958  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.5784  Validation loss = 2.3957  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.5783  Validation loss = 2.3955  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.5782  Validation loss = 2.3954  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.5780  Validation loss = 2.3952  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.5779  Validation loss = 2.3951  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.5778  Validation loss = 2.3949  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.5776  Validation loss = 2.3947  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.5775  Validation loss = 2.3945  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.5773  Validation loss = 2.3944  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.5772  Validation loss = 2.3942  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.5771  Validation loss = 2.3940  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.5770  Validation loss = 2.3939  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.5768  Validation loss = 2.3938  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.5767  Validation loss = 2.3936  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.5766  Validation loss = 2.3935  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.5765  Validation loss = 2.3933  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.5764  Validation loss = 2.3932  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.5762  Validation loss = 2.3930  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.5761  Validation loss = 2.3929  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.5760  Validation loss = 2.3928  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.5759  Validation loss = 2.3926  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.5758  Validation loss = 2.3925  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.5757  Validation loss = 2.3923  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.5755  Validation loss = 2.3922  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.5754  Validation loss = 2.3920  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.5753  Validation loss = 2.3919  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.5752  Validation loss = 2.3918  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.5751  Validation loss = 2.3916  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.5749  Validation loss = 2.3915  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.5748  Validation loss = 2.3913  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.5747  Validation loss = 2.3911  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.5745  Validation loss = 2.3910  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.5744  Validation loss = 2.3908  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.5743  Validation loss = 2.3907  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.5741  Validation loss = 2.3905  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.5740  Validation loss = 2.3903  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.5738  Validation loss = 2.3902  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.5737  Validation loss = 2.3900  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.5736  Validation loss = 2.3899  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.5735  Validation loss = 2.3897  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.5734  Validation loss = 2.3896  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.5732  Validation loss = 2.3894  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.5731  Validation loss = 2.3892  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.5730  Validation loss = 2.3891  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.5729  Validation loss = 2.3890  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.5727  Validation loss = 2.3888  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.5726  Validation loss = 2.3887  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.5724  Validation loss = 2.3884  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.5723  Validation loss = 2.3883  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.5721  Validation loss = 2.3881  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.5720  Validation loss = 2.3880  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.5719  Validation loss = 2.3878  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.5717  Validation loss = 2.3876  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.5716  Validation loss = 2.3875  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.5715  Validation loss = 2.3873  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.5713  Validation loss = 2.3871  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.5712  Validation loss = 2.3870  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.5710  Validation loss = 2.3868  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.5709  Validation loss = 2.3867  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.5708  Validation loss = 2.3865  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.5707  Validation loss = 2.3864  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.5706  Validation loss = 2.3862  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.5704  Validation loss = 2.3860  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.5703  Validation loss = 2.3859  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.5702  Validation loss = 2.3857  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.5700  Validation loss = 2.3856  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.5699  Validation loss = 2.3854  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.5698  Validation loss = 2.3853  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.5697  Validation loss = 2.3852  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.5695  Validation loss = 2.3850  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.5694  Validation loss = 2.3849  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.5693  Validation loss = 2.3847  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.5691  Validation loss = 2.3845  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.5690  Validation loss = 2.3843  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.5689  Validation loss = 2.3842  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.5687  Validation loss = 2.3840  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.5686  Validation loss = 2.3838  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.5684  Validation loss = 2.3837  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.5683  Validation loss = 2.3835  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.5682  Validation loss = 2.3834  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.5680  Validation loss = 2.3832  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.5679  Validation loss = 2.3831  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.5678  Validation loss = 2.3829  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.5676  Validation loss = 2.3828  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.5675  Validation loss = 2.3826  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.5674  Validation loss = 2.3825  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.5673  Validation loss = 2.3823  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.5672  Validation loss = 2.3822  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.5671  Validation loss = 2.3820  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.5669  Validation loss = 2.3819  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.5668  Validation loss = 2.3817  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.5667  Validation loss = 2.3816  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.5666  Validation loss = 2.3814  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.5664  Validation loss = 2.3813  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.5663  Validation loss = 2.3811  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.5661  Validation loss = 2.3809  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.5660  Validation loss = 2.3808  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.5659  Validation loss = 2.3806  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.5657  Validation loss = 2.3805  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.5656  Validation loss = 2.3803  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.5655  Validation loss = 2.3801  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.5653  Validation loss = 2.3800  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.5653  Validation loss = 2.3799  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.5652  Validation loss = 2.3797  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.5650  Validation loss = 2.3796  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.5649  Validation loss = 2.3794  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.5648  Validation loss = 2.3793  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.5646  Validation loss = 2.3791  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.5645  Validation loss = 2.3790  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.5644  Validation loss = 2.3788  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.5643  Validation loss = 2.3787  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.5641  Validation loss = 2.3785  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.5640  Validation loss = 2.3784  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.5639  Validation loss = 2.3783  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.5638  Validation loss = 2.3781  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.5637  Validation loss = 2.3780  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.5636  Validation loss = 2.3778  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.5634  Validation loss = 2.3777  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.5633  Validation loss = 2.3775  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.5632  Validation loss = 2.3774  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.5630  Validation loss = 2.3772  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.5629  Validation loss = 2.3771  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.5628  Validation loss = 2.3769  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.5626  Validation loss = 2.3767  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.5625  Validation loss = 2.3766  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.5624  Validation loss = 2.3764  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.5622  Validation loss = 2.3763  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.5621  Validation loss = 2.3761  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.5620  Validation loss = 2.3760  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.5619  Validation loss = 2.3759  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.5617  Validation loss = 2.3757  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.5616  Validation loss = 2.3756  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.5615  Validation loss = 2.3754  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.5613  Validation loss = 2.3752  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.5612  Validation loss = 2.3751  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.5611  Validation loss = 2.3749  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.5609  Validation loss = 2.3748  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.5609  Validation loss = 2.3746  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.5607  Validation loss = 2.3745  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.5606  Validation loss = 2.3743  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.5605  Validation loss = 2.3742  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.5603  Validation loss = 2.3740  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.5602  Validation loss = 2.3739  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.5601  Validation loss = 2.3737  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.5600  Validation loss = 2.3736  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.5599  Validation loss = 2.3734  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.5598  Validation loss = 2.3733  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.5596  Validation loss = 2.3731  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.5595  Validation loss = 2.3730  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.5594  Validation loss = 2.3728  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.5593  Validation loss = 2.3727  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.5591  Validation loss = 2.3725  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.5590  Validation loss = 2.3724  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.5589  Validation loss = 2.3722  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.5588  Validation loss = 2.3721  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.5586  Validation loss = 2.3719  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.5585  Validation loss = 2.3717  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.5584  Validation loss = 2.3716  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.5583  Validation loss = 2.3715  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.5581  Validation loss = 2.3713  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.5579  Validation loss = 2.3711  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.5578  Validation loss = 2.3709  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.5577  Validation loss = 2.3708  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.5576  Validation loss = 2.3706  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.5575  Validation loss = 2.3705  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.5573  Validation loss = 2.3703  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.5572  Validation loss = 2.3702  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.5571  Validation loss = 2.3700  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.5570  Validation loss = 2.3699  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.5568  Validation loss = 2.3697  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.5567  Validation loss = 2.3695  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.5565  Validation loss = 2.3694  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.5564  Validation loss = 2.3692  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.5563  Validation loss = 2.3691  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.5562  Validation loss = 2.3689  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.5560  Validation loss = 2.3688  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.5559  Validation loss = 2.3686  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.5558  Validation loss = 2.3685  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.5556  Validation loss = 2.3683  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.5555  Validation loss = 2.3682  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.5554  Validation loss = 2.3680  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.5553  Validation loss = 2.3678  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.5551  Validation loss = 2.3677  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.5550  Validation loss = 2.3675  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.5549  Validation loss = 2.3674  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.5548  Validation loss = 2.3672  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.5547  Validation loss = 2.3671  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.5545  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.5544  Validation loss = 2.3667  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.5542  Validation loss = 2.3666  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.5541  Validation loss = 2.3664  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.5540  Validation loss = 2.3663  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.5539  Validation loss = 2.3661  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.5537  Validation loss = 2.3660  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.5536  Validation loss = 2.3658  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.5534  Validation loss = 2.3656  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.5533  Validation loss = 2.3655  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.5532  Validation loss = 2.3653  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.5530  Validation loss = 2.3652  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.5529  Validation loss = 2.3650  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.5528  Validation loss = 2.3649  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.5527  Validation loss = 2.3647  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.5525  Validation loss = 2.3646  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.5524  Validation loss = 2.3645  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.5523  Validation loss = 2.3643  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.5522  Validation loss = 2.3642  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.5521  Validation loss = 2.3640  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.5519  Validation loss = 2.3639  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.5518  Validation loss = 2.3637  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.5517  Validation loss = 2.3636  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.5516  Validation loss = 2.3634  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.5515  Validation loss = 2.3633  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.5514  Validation loss = 2.3632  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.5512  Validation loss = 2.3630  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.5511  Validation loss = 2.3628  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.5510  Validation loss = 2.3627  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.5508  Validation loss = 2.3625  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.5507  Validation loss = 2.3624  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.5506  Validation loss = 2.3623  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.5505  Validation loss = 2.3621  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.5504  Validation loss = 2.3620  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.5502  Validation loss = 2.3619  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.5501  Validation loss = 2.3617  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.5500  Validation loss = 2.3615  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.5499  Validation loss = 2.3614  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.5497  Validation loss = 2.3612  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.5496  Validation loss = 2.3611  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.5494  Validation loss = 2.3609  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.5493  Validation loss = 2.3607  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.5492  Validation loss = 2.3606  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.5491  Validation loss = 2.3604  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.5489  Validation loss = 2.3603  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.5488  Validation loss = 2.3601  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.5487  Validation loss = 2.3600  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.5486  Validation loss = 2.3598  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.5484  Validation loss = 2.3597  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.5483  Validation loss = 2.3595  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.5482  Validation loss = 2.3594  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.5480  Validation loss = 2.3592  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.5479  Validation loss = 2.3591  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.5478  Validation loss = 2.3589  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.5477  Validation loss = 2.3588  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.5476  Validation loss = 2.3586  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.5474  Validation loss = 2.3585  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.5473  Validation loss = 2.3583  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.5472  Validation loss = 2.3581  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.5470  Validation loss = 2.3580  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.5469  Validation loss = 2.3578  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.5468  Validation loss = 2.3577  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.5466  Validation loss = 2.3575  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.5465  Validation loss = 2.3574  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.5464  Validation loss = 2.3572  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.5463  Validation loss = 2.3571  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.5461  Validation loss = 2.3569  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.5460  Validation loss = 2.3568  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.5459  Validation loss = 2.3566  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.5458  Validation loss = 2.3565  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.5457  Validation loss = 2.3564  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.5455  Validation loss = 2.3562  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.5454  Validation loss = 2.3560  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.5453  Validation loss = 2.3559  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.5451  Validation loss = 2.3557  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.5450  Validation loss = 2.3555  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.5448  Validation loss = 2.3553  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.5447  Validation loss = 2.3552  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.5445  Validation loss = 2.3550  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.5444  Validation loss = 2.3549  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.5443  Validation loss = 2.3547  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.5441  Validation loss = 2.3546  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.5440  Validation loss = 2.3544  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.5439  Validation loss = 2.3543  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.5438  Validation loss = 2.3541  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.5436  Validation loss = 2.3540  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.5435  Validation loss = 2.3538  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.5434  Validation loss = 2.3536  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.5432  Validation loss = 2.3535  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.5431  Validation loss = 2.3534  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.5430  Validation loss = 2.3532  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.5429  Validation loss = 2.3531  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.5428  Validation loss = 2.3530  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.5427  Validation loss = 2.3528  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.5426  Validation loss = 2.3527  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.5425  Validation loss = 2.3525  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.5423  Validation loss = 2.3524  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.5422  Validation loss = 2.3522  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.5421  Validation loss = 2.3521  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.5420  Validation loss = 2.3519  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.5418  Validation loss = 2.3518  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.5417  Validation loss = 2.3516  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.5416  Validation loss = 2.3514  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.5415  Validation loss = 2.3513  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.5413  Validation loss = 2.3511  \n",
      "\n",
      "Fold: 7  Epoch: 501  Training loss = 2.5412  Validation loss = 2.3510  \n",
      "\n",
      "Fold: 7  Epoch: 502  Training loss = 2.5411  Validation loss = 2.3508  \n",
      "\n",
      "Fold: 7  Epoch: 503  Training loss = 2.5410  Validation loss = 2.3507  \n",
      "\n",
      "Fold: 7  Epoch: 504  Training loss = 2.5408  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 7  Epoch: 505  Training loss = 2.5407  Validation loss = 2.3504  \n",
      "\n",
      "Fold: 7  Epoch: 506  Training loss = 2.5406  Validation loss = 2.3502  \n",
      "\n",
      "Fold: 7  Epoch: 507  Training loss = 2.5404  Validation loss = 2.3501  \n",
      "\n",
      "Fold: 7  Epoch: 508  Training loss = 2.5403  Validation loss = 2.3499  \n",
      "\n",
      "Fold: 7  Epoch: 509  Training loss = 2.5402  Validation loss = 2.3497  \n",
      "\n",
      "Fold: 7  Epoch: 510  Training loss = 2.5401  Validation loss = 2.3496  \n",
      "\n",
      "Fold: 7  Epoch: 511  Training loss = 2.5400  Validation loss = 2.3495  \n",
      "\n",
      "Fold: 7  Epoch: 512  Training loss = 2.5399  Validation loss = 2.3494  \n",
      "\n",
      "Fold: 7  Epoch: 513  Training loss = 2.5397  Validation loss = 2.3492  \n",
      "\n",
      "Fold: 7  Epoch: 514  Training loss = 2.5396  Validation loss = 2.3491  \n",
      "\n",
      "Fold: 7  Epoch: 515  Training loss = 2.5395  Validation loss = 2.3489  \n",
      "\n",
      "Fold: 7  Epoch: 516  Training loss = 2.5394  Validation loss = 2.3488  \n",
      "\n",
      "Fold: 7  Epoch: 517  Training loss = 2.5392  Validation loss = 2.3486  \n",
      "\n",
      "Fold: 7  Epoch: 518  Training loss = 2.5391  Validation loss = 2.3485  \n",
      "\n",
      "Fold: 7  Epoch: 519  Training loss = 2.5390  Validation loss = 2.3483  \n",
      "\n",
      "Fold: 7  Epoch: 520  Training loss = 2.5389  Validation loss = 2.3482  \n",
      "\n",
      "Fold: 7  Epoch: 521  Training loss = 2.5388  Validation loss = 2.3481  \n",
      "\n",
      "Fold: 7  Epoch: 522  Training loss = 2.5387  Validation loss = 2.3479  \n",
      "\n",
      "Fold: 7  Epoch: 523  Training loss = 2.5385  Validation loss = 2.3477  \n",
      "\n",
      "Fold: 7  Epoch: 524  Training loss = 2.5383  Validation loss = 2.3475  \n",
      "\n",
      "Fold: 7  Epoch: 525  Training loss = 2.5382  Validation loss = 2.3474  \n",
      "\n",
      "Fold: 7  Epoch: 526  Training loss = 2.5381  Validation loss = 2.3473  \n",
      "\n",
      "Fold: 7  Epoch: 527  Training loss = 2.5380  Validation loss = 2.3471  \n",
      "\n",
      "Fold: 7  Epoch: 528  Training loss = 2.5379  Validation loss = 2.3470  \n",
      "\n",
      "Fold: 7  Epoch: 529  Training loss = 2.5378  Validation loss = 2.3468  \n",
      "\n",
      "Fold: 7  Epoch: 530  Training loss = 2.5377  Validation loss = 2.3467  \n",
      "\n",
      "Fold: 7  Epoch: 531  Training loss = 2.5375  Validation loss = 2.3465  \n",
      "\n",
      "Fold: 7  Epoch: 532  Training loss = 2.5374  Validation loss = 2.3464  \n",
      "\n",
      "Fold: 7  Epoch: 533  Training loss = 2.5373  Validation loss = 2.3463  \n",
      "\n",
      "Fold: 7  Epoch: 534  Training loss = 2.5372  Validation loss = 2.3462  \n",
      "\n",
      "Fold: 7  Epoch: 535  Training loss = 2.5371  Validation loss = 2.3460  \n",
      "\n",
      "Fold: 7  Epoch: 536  Training loss = 2.5370  Validation loss = 2.3459  \n",
      "\n",
      "Fold: 7  Epoch: 537  Training loss = 2.5369  Validation loss = 2.3458  \n",
      "\n",
      "Fold: 7  Epoch: 538  Training loss = 2.5368  Validation loss = 2.3457  \n",
      "\n",
      "Fold: 7  Epoch: 539  Training loss = 2.5367  Validation loss = 2.3456  \n",
      "\n",
      "Fold: 7  Epoch: 540  Training loss = 2.5365  Validation loss = 2.3454  \n",
      "\n",
      "Fold: 7  Epoch: 541  Training loss = 2.5364  Validation loss = 2.3453  \n",
      "\n",
      "Fold: 7  Epoch: 542  Training loss = 2.5363  Validation loss = 2.3451  \n",
      "\n",
      "Fold: 7  Epoch: 543  Training loss = 2.5362  Validation loss = 2.3450  \n",
      "\n",
      "Fold: 7  Epoch: 544  Training loss = 2.5360  Validation loss = 2.3448  \n",
      "\n",
      "Fold: 7  Epoch: 545  Training loss = 2.5359  Validation loss = 2.3446  \n",
      "\n",
      "Fold: 7  Epoch: 546  Training loss = 2.5358  Validation loss = 2.3445  \n",
      "\n",
      "Fold: 7  Epoch: 547  Training loss = 2.5357  Validation loss = 2.3444  \n",
      "\n",
      "Fold: 7  Epoch: 548  Training loss = 2.5356  Validation loss = 2.3442  \n",
      "\n",
      "Fold: 7  Epoch: 549  Training loss = 2.5355  Validation loss = 2.3441  \n",
      "\n",
      "Fold: 7  Epoch: 550  Training loss = 2.5353  Validation loss = 2.3439  \n",
      "\n",
      "Fold: 7  Epoch: 551  Training loss = 2.5352  Validation loss = 2.3438  \n",
      "\n",
      "Fold: 7  Epoch: 552  Training loss = 2.5351  Validation loss = 2.3437  \n",
      "\n",
      "Fold: 7  Epoch: 553  Training loss = 2.5350  Validation loss = 2.3435  \n",
      "\n",
      "Fold: 7  Epoch: 554  Training loss = 2.5349  Validation loss = 2.3434  \n",
      "\n",
      "Fold: 7  Epoch: 555  Training loss = 2.5347  Validation loss = 2.3432  \n",
      "\n",
      "Fold: 7  Epoch: 556  Training loss = 2.5346  Validation loss = 2.3431  \n",
      "\n",
      "Fold: 7  Epoch: 557  Training loss = 2.5345  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 7  Epoch: 558  Training loss = 2.5344  Validation loss = 2.3428  \n",
      "\n",
      "Fold: 7  Epoch: 559  Training loss = 2.5343  Validation loss = 2.3426  \n",
      "\n",
      "Fold: 7  Epoch: 560  Training loss = 2.5341  Validation loss = 2.3425  \n",
      "\n",
      "Fold: 7  Epoch: 561  Training loss = 2.5340  Validation loss = 2.3423  \n",
      "\n",
      "Fold: 7  Epoch: 562  Training loss = 2.5338  Validation loss = 2.3421  \n",
      "\n",
      "Fold: 7  Epoch: 563  Training loss = 2.5337  Validation loss = 2.3420  \n",
      "\n",
      "Fold: 7  Epoch: 564  Training loss = 2.5335  Validation loss = 2.3418  \n",
      "\n",
      "Fold: 7  Epoch: 565  Training loss = 2.5334  Validation loss = 2.3417  \n",
      "\n",
      "Fold: 7  Epoch: 566  Training loss = 2.5333  Validation loss = 2.3415  \n",
      "\n",
      "Fold: 7  Epoch: 567  Training loss = 2.5332  Validation loss = 2.3413  \n",
      "\n",
      "Fold: 7  Epoch: 568  Training loss = 2.5331  Validation loss = 2.3412  \n",
      "\n",
      "Fold: 7  Epoch: 569  Training loss = 2.5329  Validation loss = 2.3411  \n",
      "\n",
      "Fold: 7  Epoch: 570  Training loss = 2.5328  Validation loss = 2.3409  \n",
      "\n",
      "Fold: 7  Epoch: 571  Training loss = 2.5327  Validation loss = 2.3408  \n",
      "\n",
      "Fold: 7  Epoch: 572  Training loss = 2.5326  Validation loss = 2.3406  \n",
      "\n",
      "Fold: 7  Epoch: 573  Training loss = 2.5324  Validation loss = 2.3404  \n",
      "\n",
      "Fold: 7  Epoch: 574  Training loss = 2.5323  Validation loss = 2.3403  \n",
      "\n",
      "Fold: 7  Epoch: 575  Training loss = 2.5321  Validation loss = 2.3401  \n",
      "\n",
      "Fold: 7  Epoch: 576  Training loss = 2.5320  Validation loss = 2.3400  \n",
      "\n",
      "Fold: 7  Epoch: 577  Training loss = 2.5319  Validation loss = 2.3398  \n",
      "\n",
      "Fold: 7  Epoch: 578  Training loss = 2.5318  Validation loss = 2.3397  \n",
      "\n",
      "Fold: 7  Epoch: 579  Training loss = 2.5317  Validation loss = 2.3395  \n",
      "\n",
      "Fold: 7  Epoch: 580  Training loss = 2.5315  Validation loss = 2.3393  \n",
      "\n",
      "Fold: 7  Epoch: 581  Training loss = 2.5314  Validation loss = 2.3392  \n",
      "\n",
      "Fold: 7  Epoch: 582  Training loss = 2.5312  Validation loss = 2.3390  \n",
      "\n",
      "Fold: 7  Epoch: 583  Training loss = 2.5311  Validation loss = 2.3389  \n",
      "\n",
      "Fold: 7  Epoch: 584  Training loss = 2.5310  Validation loss = 2.3387  \n",
      "\n",
      "Fold: 7  Epoch: 585  Training loss = 2.5308  Validation loss = 2.3386  \n",
      "\n",
      "Fold: 7  Epoch: 586  Training loss = 2.5307  Validation loss = 2.3385  \n",
      "\n",
      "Fold: 7  Epoch: 587  Training loss = 2.5306  Validation loss = 2.3383  \n",
      "\n",
      "Fold: 7  Epoch: 588  Training loss = 2.5305  Validation loss = 2.3381  \n",
      "\n",
      "Fold: 7  Epoch: 589  Training loss = 2.5304  Validation loss = 2.3380  \n",
      "\n",
      "Fold: 7  Epoch: 590  Training loss = 2.5302  Validation loss = 2.3378  \n",
      "\n",
      "Fold: 7  Epoch: 591  Training loss = 2.5301  Validation loss = 2.3377  \n",
      "\n",
      "Fold: 7  Epoch: 592  Training loss = 2.5299  Validation loss = 2.3375  \n",
      "\n",
      "Fold: 7  Epoch: 593  Training loss = 2.5298  Validation loss = 2.3373  \n",
      "\n",
      "Fold: 7  Epoch: 594  Training loss = 2.5297  Validation loss = 2.3372  \n",
      "\n",
      "Fold: 7  Epoch: 595  Training loss = 2.5295  Validation loss = 2.3370  \n",
      "\n",
      "Fold: 7  Epoch: 596  Training loss = 2.5294  Validation loss = 2.3368  \n",
      "\n",
      "Fold: 7  Epoch: 597  Training loss = 2.5293  Validation loss = 2.3367  \n",
      "\n",
      "Fold: 7  Epoch: 598  Training loss = 2.5291  Validation loss = 2.3365  \n",
      "\n",
      "Fold: 7  Epoch: 599  Training loss = 2.5290  Validation loss = 2.3364  \n",
      "\n",
      "Fold: 7  Epoch: 600  Training loss = 2.5289  Validation loss = 2.3363  \n",
      "\n",
      "Fold: 7  Epoch: 601  Training loss = 2.5288  Validation loss = 2.3361  \n",
      "\n",
      "Fold: 7  Epoch: 602  Training loss = 2.5287  Validation loss = 2.3360  \n",
      "\n",
      "Fold: 7  Epoch: 603  Training loss = 2.5285  Validation loss = 2.3358  \n",
      "\n",
      "Fold: 7  Epoch: 604  Training loss = 2.5284  Validation loss = 2.3356  \n",
      "\n",
      "Fold: 7  Epoch: 605  Training loss = 2.5282  Validation loss = 2.3355  \n",
      "\n",
      "Fold: 7  Epoch: 606  Training loss = 2.5281  Validation loss = 2.3353  \n",
      "\n",
      "Fold: 7  Epoch: 607  Training loss = 2.5280  Validation loss = 2.3352  \n",
      "\n",
      "Fold: 7  Epoch: 608  Training loss = 2.5279  Validation loss = 2.3350  \n",
      "\n",
      "Fold: 7  Epoch: 609  Training loss = 2.5278  Validation loss = 2.3349  \n",
      "\n",
      "Fold: 7  Epoch: 610  Training loss = 2.5276  Validation loss = 2.3347  \n",
      "\n",
      "Fold: 7  Epoch: 611  Training loss = 2.5275  Validation loss = 2.3346  \n",
      "\n",
      "Fold: 7  Epoch: 612  Training loss = 2.5274  Validation loss = 2.3344  \n",
      "\n",
      "Fold: 7  Epoch: 613  Training loss = 2.5272  Validation loss = 2.3343  \n",
      "\n",
      "Fold: 7  Epoch: 614  Training loss = 2.5271  Validation loss = 2.3342  \n",
      "\n",
      "Fold: 7  Epoch: 615  Training loss = 2.5270  Validation loss = 2.3340  \n",
      "\n",
      "Fold: 7  Epoch: 616  Training loss = 2.5269  Validation loss = 2.3339  \n",
      "\n",
      "Fold: 7  Epoch: 617  Training loss = 2.5268  Validation loss = 2.3337  \n",
      "\n",
      "Fold: 7  Epoch: 618  Training loss = 2.5267  Validation loss = 2.3336  \n",
      "\n",
      "Fold: 7  Epoch: 619  Training loss = 2.5265  Validation loss = 2.3334  \n",
      "\n",
      "Fold: 7  Epoch: 620  Training loss = 2.5264  Validation loss = 2.3333  \n",
      "\n",
      "Fold: 7  Epoch: 621  Training loss = 2.5263  Validation loss = 2.3331  \n",
      "\n",
      "Fold: 7  Epoch: 622  Training loss = 2.5262  Validation loss = 2.3329  \n",
      "\n",
      "Fold: 7  Epoch: 623  Training loss = 2.5260  Validation loss = 2.3328  \n",
      "\n",
      "Fold: 7  Epoch: 624  Training loss = 2.5259  Validation loss = 2.3326  \n",
      "\n",
      "Fold: 7  Epoch: 625  Training loss = 2.5257  Validation loss = 2.3324  \n",
      "\n",
      "Fold: 7  Epoch: 626  Training loss = 2.5256  Validation loss = 2.3323  \n",
      "\n",
      "Fold: 7  Epoch: 627  Training loss = 2.5255  Validation loss = 2.3321  \n",
      "\n",
      "Fold: 7  Epoch: 628  Training loss = 2.5253  Validation loss = 2.3320  \n",
      "\n",
      "Fold: 7  Epoch: 629  Training loss = 2.5252  Validation loss = 2.3318  \n",
      "\n",
      "Fold: 7  Epoch: 630  Training loss = 2.5251  Validation loss = 2.3316  \n",
      "\n",
      "Fold: 7  Epoch: 631  Training loss = 2.5250  Validation loss = 2.3315  \n",
      "\n",
      "Fold: 7  Epoch: 632  Training loss = 2.5249  Validation loss = 2.3314  \n",
      "\n",
      "Fold: 7  Epoch: 633  Training loss = 2.5248  Validation loss = 2.3312  \n",
      "\n",
      "Fold: 7  Epoch: 634  Training loss = 2.5246  Validation loss = 2.3311  \n",
      "\n",
      "Fold: 7  Epoch: 635  Training loss = 2.5245  Validation loss = 2.3309  \n",
      "\n",
      "Fold: 7  Epoch: 636  Training loss = 2.5244  Validation loss = 2.3308  \n",
      "\n",
      "Fold: 7  Epoch: 637  Training loss = 2.5242  Validation loss = 2.3306  \n",
      "\n",
      "Fold: 7  Epoch: 638  Training loss = 2.5241  Validation loss = 2.3304  \n",
      "\n",
      "Fold: 7  Epoch: 639  Training loss = 2.5239  Validation loss = 2.3303  \n",
      "\n",
      "Fold: 7  Epoch: 640  Training loss = 2.5238  Validation loss = 2.3301  \n",
      "\n",
      "Fold: 7  Epoch: 641  Training loss = 2.5237  Validation loss = 2.3300  \n",
      "\n",
      "Fold: 7  Epoch: 642  Training loss = 2.5236  Validation loss = 2.3299  \n",
      "\n",
      "Fold: 7  Epoch: 643  Training loss = 2.5234  Validation loss = 2.3297  \n",
      "\n",
      "Fold: 7  Epoch: 644  Training loss = 2.5233  Validation loss = 2.3295  \n",
      "\n",
      "Fold: 7  Epoch: 645  Training loss = 2.5232  Validation loss = 2.3294  \n",
      "\n",
      "Fold: 7  Epoch: 646  Training loss = 2.5231  Validation loss = 2.3292  \n",
      "\n",
      "Fold: 7  Epoch: 647  Training loss = 2.5229  Validation loss = 2.3291  \n",
      "\n",
      "Fold: 7  Epoch: 648  Training loss = 2.5228  Validation loss = 2.3290  \n",
      "\n",
      "Fold: 7  Epoch: 649  Training loss = 2.5227  Validation loss = 2.3288  \n",
      "\n",
      "Fold: 7  Epoch: 650  Training loss = 2.5226  Validation loss = 2.3287  \n",
      "\n",
      "Fold: 7  Epoch: 651  Training loss = 2.5224  Validation loss = 2.3285  \n",
      "\n",
      "Fold: 7  Epoch: 652  Training loss = 2.5223  Validation loss = 2.3284  \n",
      "\n",
      "Fold: 7  Epoch: 653  Training loss = 2.5222  Validation loss = 2.3282  \n",
      "\n",
      "Fold: 7  Epoch: 654  Training loss = 2.5221  Validation loss = 2.3280  \n",
      "\n",
      "Fold: 7  Epoch: 655  Training loss = 2.5219  Validation loss = 2.3279  \n",
      "\n",
      "Fold: 7  Epoch: 656  Training loss = 2.5218  Validation loss = 2.3278  \n",
      "\n",
      "Fold: 7  Epoch: 657  Training loss = 2.5217  Validation loss = 2.3276  \n",
      "\n",
      "Fold: 7  Epoch: 658  Training loss = 2.5216  Validation loss = 2.3275  \n",
      "\n",
      "Fold: 7  Epoch: 659  Training loss = 2.5215  Validation loss = 2.3274  \n",
      "\n",
      "Fold: 7  Epoch: 660  Training loss = 2.5214  Validation loss = 2.3272  \n",
      "\n",
      "Fold: 7  Epoch: 661  Training loss = 2.5213  Validation loss = 2.3271  \n",
      "\n",
      "Fold: 7  Epoch: 662  Training loss = 2.5211  Validation loss = 2.3269  \n",
      "\n",
      "Fold: 7  Epoch: 663  Training loss = 2.5210  Validation loss = 2.3268  \n",
      "\n",
      "Fold: 7  Epoch: 664  Training loss = 2.5209  Validation loss = 2.3266  \n",
      "\n",
      "Fold: 7  Epoch: 665  Training loss = 2.5208  Validation loss = 2.3265  \n",
      "\n",
      "Fold: 7  Epoch: 666  Training loss = 2.5206  Validation loss = 2.3263  \n",
      "\n",
      "Fold: 7  Epoch: 667  Training loss = 2.5205  Validation loss = 2.3262  \n",
      "\n",
      "Fold: 7  Epoch: 668  Training loss = 2.5204  Validation loss = 2.3260  \n",
      "\n",
      "Fold: 7  Epoch: 669  Training loss = 2.5202  Validation loss = 2.3259  \n",
      "\n",
      "Fold: 7  Epoch: 670  Training loss = 2.5201  Validation loss = 2.3257  \n",
      "\n",
      "Fold: 7  Epoch: 671  Training loss = 2.5200  Validation loss = 2.3256  \n",
      "\n",
      "Fold: 7  Epoch: 672  Training loss = 2.5199  Validation loss = 2.3254  \n",
      "\n",
      "Fold: 7  Epoch: 673  Training loss = 2.5198  Validation loss = 2.3253  \n",
      "\n",
      "Fold: 7  Epoch: 674  Training loss = 2.5197  Validation loss = 2.3252  \n",
      "\n",
      "Fold: 7  Epoch: 675  Training loss = 2.5196  Validation loss = 2.3250  \n",
      "\n",
      "Fold: 7  Epoch: 676  Training loss = 2.5194  Validation loss = 2.3248  \n",
      "\n",
      "Fold: 7  Epoch: 677  Training loss = 2.5193  Validation loss = 2.3247  \n",
      "\n",
      "Fold: 7  Epoch: 678  Training loss = 2.5192  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 7  Epoch: 679  Training loss = 2.5191  Validation loss = 2.3244  \n",
      "\n",
      "Fold: 7  Epoch: 680  Training loss = 2.5190  Validation loss = 2.3243  \n",
      "\n",
      "Fold: 7  Epoch: 681  Training loss = 2.5189  Validation loss = 2.3241  \n",
      "\n",
      "Fold: 7  Epoch: 682  Training loss = 2.5187  Validation loss = 2.3240  \n",
      "\n",
      "Fold: 7  Epoch: 683  Training loss = 2.5187  Validation loss = 2.3239  \n",
      "\n",
      "Fold: 7  Epoch: 684  Training loss = 2.5185  Validation loss = 2.3237  \n",
      "\n",
      "Fold: 7  Epoch: 685  Training loss = 2.5184  Validation loss = 2.3236  \n",
      "\n",
      "Fold: 7  Epoch: 686  Training loss = 2.5183  Validation loss = 2.3234  \n",
      "\n",
      "Fold: 7  Epoch: 687  Training loss = 2.5182  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 7  Epoch: 688  Training loss = 2.5180  Validation loss = 2.3231  \n",
      "\n",
      "Fold: 7  Epoch: 689  Training loss = 2.5179  Validation loss = 2.3230  \n",
      "\n",
      "Fold: 7  Epoch: 690  Training loss = 2.5178  Validation loss = 2.3228  \n",
      "\n",
      "Fold: 7  Epoch: 691  Training loss = 2.5177  Validation loss = 2.3227  \n",
      "\n",
      "Fold: 7  Epoch: 692  Training loss = 2.5176  Validation loss = 2.3226  \n",
      "\n",
      "Fold: 7  Epoch: 693  Training loss = 2.5175  Validation loss = 2.3224  \n",
      "\n",
      "Fold: 7  Epoch: 694  Training loss = 2.5174  Validation loss = 2.3223  \n",
      "\n",
      "Fold: 7  Epoch: 695  Training loss = 2.5172  Validation loss = 2.3221  \n",
      "\n",
      "Fold: 7  Epoch: 696  Training loss = 2.5171  Validation loss = 2.3220  \n",
      "\n",
      "Fold: 7  Epoch: 697  Training loss = 2.5170  Validation loss = 2.3218  \n",
      "\n",
      "Fold: 7  Epoch: 698  Training loss = 2.5169  Validation loss = 2.3217  \n",
      "\n",
      "Fold: 7  Epoch: 699  Training loss = 2.5167  Validation loss = 2.3215  \n",
      "\n",
      "Fold: 7  Epoch: 700  Training loss = 2.5166  Validation loss = 2.3214  \n",
      "\n",
      "Fold: 7  Epoch: 701  Training loss = 2.5165  Validation loss = 2.3212  \n",
      "\n",
      "Fold: 7  Epoch: 702  Training loss = 2.5164  Validation loss = 2.3211  \n",
      "\n",
      "Fold: 7  Epoch: 703  Training loss = 2.5162  Validation loss = 2.3209  \n",
      "\n",
      "Fold: 7  Epoch: 704  Training loss = 2.5161  Validation loss = 2.3208  \n",
      "\n",
      "Fold: 7  Epoch: 705  Training loss = 2.5160  Validation loss = 2.3206  \n",
      "\n",
      "Fold: 7  Epoch: 706  Training loss = 2.5158  Validation loss = 2.3205  \n",
      "\n",
      "Fold: 7  Epoch: 707  Training loss = 2.5157  Validation loss = 2.3203  \n",
      "\n",
      "Fold: 7  Epoch: 708  Training loss = 2.5156  Validation loss = 2.3202  \n",
      "\n",
      "Fold: 7  Epoch: 709  Training loss = 2.5155  Validation loss = 2.3200  \n",
      "\n",
      "Fold: 7  Epoch: 710  Training loss = 2.5154  Validation loss = 2.3199  \n",
      "\n",
      "Fold: 7  Epoch: 711  Training loss = 2.5152  Validation loss = 2.3197  \n",
      "\n",
      "Fold: 7  Epoch: 712  Training loss = 2.5151  Validation loss = 2.3196  \n",
      "\n",
      "Fold: 7  Epoch: 713  Training loss = 2.5150  Validation loss = 2.3194  \n",
      "\n",
      "Fold: 7  Epoch: 714  Training loss = 2.5149  Validation loss = 2.3193  \n",
      "\n",
      "Fold: 7  Epoch: 715  Training loss = 2.5147  Validation loss = 2.3191  \n",
      "\n",
      "Fold: 7  Epoch: 716  Training loss = 2.5146  Validation loss = 2.3190  \n",
      "\n",
      "Fold: 7  Epoch: 717  Training loss = 2.5145  Validation loss = 2.3188  \n",
      "\n",
      "Fold: 7  Epoch: 718  Training loss = 2.5144  Validation loss = 2.3187  \n",
      "\n",
      "Fold: 7  Epoch: 719  Training loss = 2.5143  Validation loss = 2.3185  \n",
      "\n",
      "Fold: 7  Epoch: 720  Training loss = 2.5141  Validation loss = 2.3184  \n",
      "\n",
      "Fold: 7  Epoch: 721  Training loss = 2.5140  Validation loss = 2.3182  \n",
      "\n",
      "Fold: 7  Epoch: 722  Training loss = 2.5139  Validation loss = 2.3181  \n",
      "\n",
      "Fold: 7  Epoch: 723  Training loss = 2.5137  Validation loss = 2.3179  \n",
      "\n",
      "Fold: 7  Epoch: 724  Training loss = 2.5136  Validation loss = 2.3177  \n",
      "\n",
      "Fold: 7  Epoch: 725  Training loss = 2.5135  Validation loss = 2.3176  \n",
      "\n",
      "Fold: 7  Epoch: 726  Training loss = 2.5134  Validation loss = 2.3175  \n",
      "\n",
      "Fold: 7  Epoch: 727  Training loss = 2.5133  Validation loss = 2.3173  \n",
      "\n",
      "Fold: 7  Epoch: 728  Training loss = 2.5131  Validation loss = 2.3171  \n",
      "\n",
      "Fold: 7  Epoch: 729  Training loss = 2.5130  Validation loss = 2.3170  \n",
      "\n",
      "Fold: 7  Epoch: 730  Training loss = 2.5129  Validation loss = 2.3169  \n",
      "\n",
      "Fold: 7  Epoch: 731  Training loss = 2.5128  Validation loss = 2.3167  \n",
      "\n",
      "Fold: 7  Epoch: 732  Training loss = 2.5127  Validation loss = 2.3166  \n",
      "\n",
      "Fold: 7  Epoch: 733  Training loss = 2.5125  Validation loss = 2.3164  \n",
      "\n",
      "Fold: 7  Epoch: 734  Training loss = 2.5124  Validation loss = 2.3162  \n",
      "\n",
      "Fold: 7  Epoch: 735  Training loss = 2.5122  Validation loss = 2.3161  \n",
      "\n",
      "Fold: 7  Epoch: 736  Training loss = 2.5121  Validation loss = 2.3159  \n",
      "\n",
      "Fold: 7  Epoch: 737  Training loss = 2.5120  Validation loss = 2.3158  \n",
      "\n",
      "Fold: 7  Epoch: 738  Training loss = 2.5119  Validation loss = 2.3157  \n",
      "\n",
      "Fold: 7  Epoch: 739  Training loss = 2.5118  Validation loss = 2.3155  \n",
      "\n",
      "Fold: 7  Epoch: 740  Training loss = 2.5116  Validation loss = 2.3153  \n",
      "\n",
      "Fold: 7  Epoch: 741  Training loss = 2.5115  Validation loss = 2.3152  \n",
      "\n",
      "Fold: 7  Epoch: 742  Training loss = 2.5114  Validation loss = 2.3150  \n",
      "\n",
      "Fold: 7  Epoch: 743  Training loss = 2.5113  Validation loss = 2.3149  \n",
      "\n",
      "Fold: 7  Epoch: 744  Training loss = 2.5112  Validation loss = 2.3147  \n",
      "\n",
      "Fold: 7  Epoch: 745  Training loss = 2.5110  Validation loss = 2.3146  \n",
      "\n",
      "Fold: 7  Epoch: 746  Training loss = 2.5109  Validation loss = 2.3144  \n",
      "\n",
      "Fold: 7  Epoch: 747  Training loss = 2.5108  Validation loss = 2.3142  \n",
      "\n",
      "Fold: 7  Epoch: 748  Training loss = 2.5106  Validation loss = 2.3141  \n",
      "\n",
      "Fold: 7  Epoch: 749  Training loss = 2.5105  Validation loss = 2.3139  \n",
      "\n",
      "Fold: 7  Epoch: 750  Training loss = 2.5103  Validation loss = 2.3137  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 750  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.5233  Validation loss = 7.4741  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.5232  Validation loss = 7.4739  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.5231  Validation loss = 7.4738  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.5229  Validation loss = 7.4736  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.5228  Validation loss = 7.4734  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.5226  Validation loss = 7.4733  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.5225  Validation loss = 7.4731  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.5224  Validation loss = 7.4730  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.5223  Validation loss = 7.4728  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.5221  Validation loss = 7.4727  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.5220  Validation loss = 7.4725  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.5218  Validation loss = 7.4724  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.5217  Validation loss = 7.4722  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.5216  Validation loss = 7.4721  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.5215  Validation loss = 7.4719  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.5214  Validation loss = 7.4718  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.5212  Validation loss = 7.4716  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.5211  Validation loss = 7.4715  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.5209  Validation loss = 7.4713  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.5208  Validation loss = 7.4712  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.5207  Validation loss = 7.4710  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.5206  Validation loss = 7.4709  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.5204  Validation loss = 7.4707  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.5203  Validation loss = 7.4706  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.5202  Validation loss = 7.4704  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.5200  Validation loss = 7.4702  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.5199  Validation loss = 7.4701  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.5198  Validation loss = 7.4699  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.5197  Validation loss = 7.4698  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.5196  Validation loss = 7.4697  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.5195  Validation loss = 7.4695  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.5193  Validation loss = 7.4694  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.5192  Validation loss = 7.4693  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.5191  Validation loss = 7.4691  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.5190  Validation loss = 7.4690  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.5189  Validation loss = 7.4689  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.5187  Validation loss = 7.4687  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.5186  Validation loss = 7.4685  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.5185  Validation loss = 7.4684  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.5183  Validation loss = 7.4682  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.5182  Validation loss = 7.4681  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.5180  Validation loss = 7.4679  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.5179  Validation loss = 7.4677  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.5177  Validation loss = 7.4676  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.5176  Validation loss = 7.4674  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.5175  Validation loss = 7.4673  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.5173  Validation loss = 7.4671  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.5172  Validation loss = 7.4670  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.5171  Validation loss = 7.4668  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.5170  Validation loss = 7.4667  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.5169  Validation loss = 7.4665  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.5167  Validation loss = 7.4663  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.5166  Validation loss = 7.4662  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.5165  Validation loss = 7.4661  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.5163  Validation loss = 7.4659  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.5162  Validation loss = 7.4658  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.5160  Validation loss = 7.4656  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.5159  Validation loss = 7.4654  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.5158  Validation loss = 7.4653  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.5156  Validation loss = 7.4651  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.5155  Validation loss = 7.4650  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.5154  Validation loss = 7.4648  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.5153  Validation loss = 7.4647  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.5151  Validation loss = 7.4645  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.5150  Validation loss = 7.4644  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.5149  Validation loss = 7.4642  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.5147  Validation loss = 7.4641  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.5146  Validation loss = 7.4640  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.5145  Validation loss = 7.4638  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.5143  Validation loss = 7.4636  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.5142  Validation loss = 7.4635  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.5141  Validation loss = 7.4633  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.5139  Validation loss = 7.4632  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.5138  Validation loss = 7.4630  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.5137  Validation loss = 7.4628  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.5135  Validation loss = 7.4627  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.5134  Validation loss = 7.4626  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.5133  Validation loss = 7.4624  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.5132  Validation loss = 7.4622  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.5130  Validation loss = 7.4621  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.5129  Validation loss = 7.4619  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.5128  Validation loss = 7.4618  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.5126  Validation loss = 7.4616  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.5125  Validation loss = 7.4614  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.5123  Validation loss = 7.4613  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.5122  Validation loss = 7.4611  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.5121  Validation loss = 7.4610  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.5119  Validation loss = 7.4608  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.5118  Validation loss = 7.4607  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.5117  Validation loss = 7.4605  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.5116  Validation loss = 7.4604  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.5114  Validation loss = 7.4602  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.5113  Validation loss = 7.4601  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.5112  Validation loss = 7.4600  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.5111  Validation loss = 7.4598  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.5110  Validation loss = 7.4597  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.5108  Validation loss = 7.4595  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.5106  Validation loss = 7.4593  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.5105  Validation loss = 7.4592  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.5103  Validation loss = 7.4590  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.5102  Validation loss = 7.4588  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.5101  Validation loss = 7.4587  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.5099  Validation loss = 7.4585  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.5098  Validation loss = 7.4584  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.5097  Validation loss = 7.4583  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.5096  Validation loss = 7.4581  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.5095  Validation loss = 7.4580  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.5093  Validation loss = 7.4578  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.5092  Validation loss = 7.4576  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.5091  Validation loss = 7.4575  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.5090  Validation loss = 7.4574  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.5088  Validation loss = 7.4572  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.5087  Validation loss = 7.4571  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.5085  Validation loss = 7.4569  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.5084  Validation loss = 7.4567  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.5083  Validation loss = 7.4566  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.5082  Validation loss = 7.4565  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.5080  Validation loss = 7.4563  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.5079  Validation loss = 7.4561  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.5077  Validation loss = 7.4560  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.5076  Validation loss = 7.4558  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.5075  Validation loss = 7.4557  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.5074  Validation loss = 7.4555  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.5072  Validation loss = 7.4554  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.5071  Validation loss = 7.4552  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.5070  Validation loss = 7.4551  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.5069  Validation loss = 7.4550  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.5068  Validation loss = 7.4548  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.5067  Validation loss = 7.4547  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.5065  Validation loss = 7.4546  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.5064  Validation loss = 7.4544  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.5063  Validation loss = 7.4543  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.5062  Validation loss = 7.4541  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.5061  Validation loss = 7.4540  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.5059  Validation loss = 7.4538  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.5058  Validation loss = 7.4537  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.5057  Validation loss = 7.4536  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.5055  Validation loss = 7.4534  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.5054  Validation loss = 7.4533  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.5053  Validation loss = 7.4531  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.5052  Validation loss = 7.4530  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.5051  Validation loss = 7.4529  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.5049  Validation loss = 7.4527  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.5048  Validation loss = 7.4525  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.5047  Validation loss = 7.4524  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.5046  Validation loss = 7.4523  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.5045  Validation loss = 7.4521  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.5043  Validation loss = 7.4520  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.5042  Validation loss = 7.4518  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.5041  Validation loss = 7.4517  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.5039  Validation loss = 7.4515  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.5038  Validation loss = 7.4514  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.5037  Validation loss = 7.4513  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.5035  Validation loss = 7.4511  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.5034  Validation loss = 7.4509  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.5033  Validation loss = 7.4508  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.5032  Validation loss = 7.4506  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.5031  Validation loss = 7.4505  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.5029  Validation loss = 7.4504  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.5028  Validation loss = 7.4502  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.5027  Validation loss = 7.4501  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.5025  Validation loss = 7.4499  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.5024  Validation loss = 7.4497  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.5023  Validation loss = 7.4496  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.5021  Validation loss = 7.4494  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.5020  Validation loss = 7.4493  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.5019  Validation loss = 7.4491  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.5017  Validation loss = 7.4490  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.5016  Validation loss = 7.4489  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.5015  Validation loss = 7.4487  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.5013  Validation loss = 7.4485  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.5012  Validation loss = 7.4484  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.5011  Validation loss = 7.4482  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.5010  Validation loss = 7.4481  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.5009  Validation loss = 7.4480  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.5007  Validation loss = 7.4478  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.5005  Validation loss = 7.4476  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.5004  Validation loss = 7.4474  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.5002  Validation loss = 7.4473  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.5001  Validation loss = 7.4471  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.5000  Validation loss = 7.4470  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.4999  Validation loss = 7.4468  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.4997  Validation loss = 7.4467  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.4996  Validation loss = 7.4465  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.4994  Validation loss = 7.4464  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.4993  Validation loss = 7.4462  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.4991  Validation loss = 7.4460  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.4990  Validation loss = 7.4459  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.4989  Validation loss = 7.4458  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.4988  Validation loss = 7.4456  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.4986  Validation loss = 7.4455  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.4985  Validation loss = 7.4454  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.4984  Validation loss = 7.4452  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.4983  Validation loss = 7.4451  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.4982  Validation loss = 7.4449  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.4981  Validation loss = 7.4448  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.4980  Validation loss = 7.4447  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.4978  Validation loss = 7.4445  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.4977  Validation loss = 7.4444  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.4976  Validation loss = 7.4442  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.4974  Validation loss = 7.4441  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.4973  Validation loss = 7.4439  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.4971  Validation loss = 7.4437  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.4970  Validation loss = 7.4436  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.4969  Validation loss = 7.4434  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.4967  Validation loss = 7.4433  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.4966  Validation loss = 7.4431  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.4965  Validation loss = 7.4430  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.4964  Validation loss = 7.4428  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.4962  Validation loss = 7.4427  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.4961  Validation loss = 7.4425  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.4959  Validation loss = 7.4423  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.4958  Validation loss = 7.4422  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.4957  Validation loss = 7.4421  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.4955  Validation loss = 7.4419  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.4954  Validation loss = 7.4417  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.4953  Validation loss = 7.4416  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.4952  Validation loss = 7.4415  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.4950  Validation loss = 7.4413  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.4949  Validation loss = 7.4411  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.4947  Validation loss = 7.4410  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.4946  Validation loss = 7.4408  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.4945  Validation loss = 7.4407  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.4944  Validation loss = 7.4405  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.4942  Validation loss = 7.4404  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.4941  Validation loss = 7.4402  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.4940  Validation loss = 7.4401  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.4939  Validation loss = 7.4400  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.4938  Validation loss = 7.4398  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.4937  Validation loss = 7.4397  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.4935  Validation loss = 7.4395  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.4934  Validation loss = 7.4393  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.4933  Validation loss = 7.4392  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.4932  Validation loss = 7.4391  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.4930  Validation loss = 7.4389  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.4929  Validation loss = 7.4388  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.4928  Validation loss = 7.4386  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.4927  Validation loss = 7.4385  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.4925  Validation loss = 7.4383  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.4924  Validation loss = 7.4382  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.4922  Validation loss = 7.4380  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.4921  Validation loss = 7.4379  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.4920  Validation loss = 7.4377  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.4918  Validation loss = 7.4375  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.4917  Validation loss = 7.4374  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.4916  Validation loss = 7.4373  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.4915  Validation loss = 7.4372  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.4914  Validation loss = 7.4370  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.4913  Validation loss = 7.4369  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.4911  Validation loss = 7.4367  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.4910  Validation loss = 7.4366  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.4909  Validation loss = 7.4364  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.4907  Validation loss = 7.4362  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.4906  Validation loss = 7.4361  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.4904  Validation loss = 7.4359  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.4903  Validation loss = 7.4358  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.4901  Validation loss = 7.4356  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.4900  Validation loss = 7.4354  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.4899  Validation loss = 7.4353  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.4897  Validation loss = 7.4352  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.4896  Validation loss = 7.4350  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.4895  Validation loss = 7.4349  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.4893  Validation loss = 7.4347  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.4892  Validation loss = 7.4345  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.4890  Validation loss = 7.4344  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.4889  Validation loss = 7.4342  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.4887  Validation loss = 7.4340  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.4886  Validation loss = 7.4339  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.4885  Validation loss = 7.4338  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.4884  Validation loss = 7.4336  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.4882  Validation loss = 7.4334  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.4881  Validation loss = 7.4333  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.4880  Validation loss = 7.4331  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.4878  Validation loss = 7.4330  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.4877  Validation loss = 7.4328  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.4876  Validation loss = 7.4327  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.4875  Validation loss = 7.4325  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.4873  Validation loss = 7.4324  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.4872  Validation loss = 7.4323  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.4871  Validation loss = 7.4321  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.4869  Validation loss = 7.4319  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.4868  Validation loss = 7.4318  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.4867  Validation loss = 7.4317  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.4865  Validation loss = 7.4315  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.4864  Validation loss = 7.4313  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.4863  Validation loss = 7.4311  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.4861  Validation loss = 7.4310  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.4860  Validation loss = 7.4308  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.4859  Validation loss = 7.4307  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.4858  Validation loss = 7.4306  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.4856  Validation loss = 7.4304  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.4856  Validation loss = 7.4303  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.4854  Validation loss = 7.4301  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.4853  Validation loss = 7.4299  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.4852  Validation loss = 7.4298  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.4851  Validation loss = 7.4297  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.4849  Validation loss = 7.4295  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.4848  Validation loss = 7.4294  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.4847  Validation loss = 7.4292  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.4846  Validation loss = 7.4291  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.4844  Validation loss = 7.4289  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.4843  Validation loss = 7.4288  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.4842  Validation loss = 7.4287  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.4841  Validation loss = 7.4285  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.4840  Validation loss = 7.4284  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.4838  Validation loss = 7.4283  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.4837  Validation loss = 7.4281  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.4836  Validation loss = 7.4279  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.4835  Validation loss = 7.4278  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.4833  Validation loss = 7.4276  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.4832  Validation loss = 7.4275  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.4831  Validation loss = 7.4273  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.4830  Validation loss = 7.4272  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.4829  Validation loss = 7.4271  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.4827  Validation loss = 7.4269  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.4826  Validation loss = 7.4268  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.4825  Validation loss = 7.4266  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.4823  Validation loss = 7.4264  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.4822  Validation loss = 7.4263  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.4821  Validation loss = 7.4262  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.4819  Validation loss = 7.4260  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.4818  Validation loss = 7.4259  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.4817  Validation loss = 7.4257  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.4816  Validation loss = 7.4256  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.4815  Validation loss = 7.4254  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.4813  Validation loss = 7.4253  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.4812  Validation loss = 7.4251  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.4811  Validation loss = 7.4250  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.4809  Validation loss = 7.4248  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.4808  Validation loss = 7.4247  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.4807  Validation loss = 7.4245  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.4806  Validation loss = 7.4244  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.4805  Validation loss = 7.4242  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.4803  Validation loss = 7.4241  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.4802  Validation loss = 7.4239  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.4801  Validation loss = 7.4237  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.4799  Validation loss = 7.4236  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.4798  Validation loss = 7.4234  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.4797  Validation loss = 7.4233  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.4795  Validation loss = 7.4231  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.4794  Validation loss = 7.4230  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.4793  Validation loss = 7.4228  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.4792  Validation loss = 7.4227  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.4790  Validation loss = 7.4225  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.4789  Validation loss = 7.4224  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.4788  Validation loss = 7.4223  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.4787  Validation loss = 7.4221  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.4786  Validation loss = 7.4220  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.4784  Validation loss = 7.4218  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.4783  Validation loss = 7.4216  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.4782  Validation loss = 7.4215  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.4780  Validation loss = 7.4214  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.4779  Validation loss = 7.4212  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.4778  Validation loss = 7.4211  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.4777  Validation loss = 7.4209  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.4775  Validation loss = 7.4207  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.4774  Validation loss = 7.4206  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.4773  Validation loss = 7.4204  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.4772  Validation loss = 7.4203  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.4770  Validation loss = 7.4201  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.4769  Validation loss = 7.4200  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.4768  Validation loss = 7.4198  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.4766  Validation loss = 7.4197  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.4765  Validation loss = 7.4195  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.4763  Validation loss = 7.4193  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.4762  Validation loss = 7.4192  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.4761  Validation loss = 7.4191  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.4760  Validation loss = 7.4189  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.4758  Validation loss = 7.4187  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.4757  Validation loss = 7.4186  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.4756  Validation loss = 7.4185  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.4755  Validation loss = 7.4183  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.4754  Validation loss = 7.4182  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.4752  Validation loss = 7.4180  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.4751  Validation loss = 7.4179  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.4750  Validation loss = 7.4178  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.4749  Validation loss = 7.4177  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.4748  Validation loss = 7.4175  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.4746  Validation loss = 7.4173  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.4745  Validation loss = 7.4171  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.4743  Validation loss = 7.4170  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.4742  Validation loss = 7.4168  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.4741  Validation loss = 7.4167  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.4740  Validation loss = 7.4165  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.4739  Validation loss = 7.4164  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.4737  Validation loss = 7.4163  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.4736  Validation loss = 7.4161  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.4734  Validation loss = 7.4159  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 2.4733  Validation loss = 7.4158  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 2.4731  Validation loss = 7.4156  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 2.4730  Validation loss = 7.4154  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 2.4729  Validation loss = 7.4153  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 2.4728  Validation loss = 7.4151  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 2.4726  Validation loss = 7.4150  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 2.4725  Validation loss = 7.4148  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 2.4724  Validation loss = 7.4147  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 2.4722  Validation loss = 7.4145  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 2.4721  Validation loss = 7.4144  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 2.4720  Validation loss = 7.4143  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 2.4719  Validation loss = 7.4142  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 2.4718  Validation loss = 7.4140  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 2.4717  Validation loss = 7.4139  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 2.4715  Validation loss = 7.4137  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 2.4714  Validation loss = 7.4135  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 2.4712  Validation loss = 7.4134  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 2.4711  Validation loss = 7.4132  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 2.4710  Validation loss = 7.4131  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 2.4709  Validation loss = 7.4130  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 2.4707  Validation loss = 7.4128  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 2.4706  Validation loss = 7.4126  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 2.4704  Validation loss = 7.4125  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 2.4703  Validation loss = 7.4123  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 2.4702  Validation loss = 7.4122  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 2.4701  Validation loss = 7.4121  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 2.4700  Validation loss = 7.4119  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 2.4699  Validation loss = 7.4118  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 2.4698  Validation loss = 7.4117  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 2.4697  Validation loss = 7.4116  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 2.4696  Validation loss = 7.4114  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 2.4695  Validation loss = 7.4113  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 2.4694  Validation loss = 7.4111  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 2.4692  Validation loss = 7.4110  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 2.4691  Validation loss = 7.4109  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 2.4690  Validation loss = 7.4107  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 2.4688  Validation loss = 7.4106  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 2.4687  Validation loss = 7.4104  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 2.4686  Validation loss = 7.4103  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 2.4685  Validation loss = 7.4101  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 2.4684  Validation loss = 7.4100  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 2.4682  Validation loss = 7.4099  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 2.4681  Validation loss = 7.4097  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 2.4680  Validation loss = 7.4096  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 2.4678  Validation loss = 7.4094  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 2.4677  Validation loss = 7.4092  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 2.4676  Validation loss = 7.4091  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 2.4674  Validation loss = 7.4089  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 2.4673  Validation loss = 7.4087  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 2.4672  Validation loss = 7.4086  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 2.4670  Validation loss = 7.4084  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 2.4669  Validation loss = 7.4083  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 2.4668  Validation loss = 7.4081  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 2.4667  Validation loss = 7.4080  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 2.4665  Validation loss = 7.4078  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 2.4664  Validation loss = 7.4077  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 2.4663  Validation loss = 7.4075  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 2.4661  Validation loss = 7.4073  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 2.4660  Validation loss = 7.4072  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 2.4659  Validation loss = 7.4070  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 2.4657  Validation loss = 7.4069  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 2.4656  Validation loss = 7.4067  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 2.4654  Validation loss = 7.4065  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 2.4653  Validation loss = 7.4064  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 2.4652  Validation loss = 7.4063  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 2.4651  Validation loss = 7.4061  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 2.4649  Validation loss = 7.4059  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 2.4648  Validation loss = 7.4058  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 2.4647  Validation loss = 7.4057  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 2.4646  Validation loss = 7.4055  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 2.4644  Validation loss = 7.4054  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 2.4643  Validation loss = 7.4053  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 2.4642  Validation loss = 7.4051  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 2.4641  Validation loss = 7.4050  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 2.4640  Validation loss = 7.4048  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 2.4639  Validation loss = 7.4047  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 2.4638  Validation loss = 7.4045  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 2.4636  Validation loss = 7.4043  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 2.4635  Validation loss = 7.4042  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 2.4634  Validation loss = 7.4040  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 2.4632  Validation loss = 7.4039  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 2.4631  Validation loss = 7.4038  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 2.4630  Validation loss = 7.4037  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 2.4629  Validation loss = 7.4035  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 2.4628  Validation loss = 7.4033  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 2.4626  Validation loss = 7.4032  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 2.4625  Validation loss = 7.4031  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 2.4624  Validation loss = 7.4029  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 2.4623  Validation loss = 7.4028  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 2.4622  Validation loss = 7.4027  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 2.4621  Validation loss = 7.4026  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 2.4620  Validation loss = 7.4024  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 2.4619  Validation loss = 7.4023  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 2.4617  Validation loss = 7.4021  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 2.4616  Validation loss = 7.4020  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 2.4615  Validation loss = 7.4018  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 2.4614  Validation loss = 7.4017  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 2.4612  Validation loss = 7.4015  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 2.4611  Validation loss = 7.4014  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 2.4610  Validation loss = 7.4012  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 2.4609  Validation loss = 7.4011  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 2.4608  Validation loss = 7.4010  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 2.4607  Validation loss = 7.4009  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 2.4605  Validation loss = 7.4007  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 2.4604  Validation loss = 7.4005  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 2.4602  Validation loss = 7.4004  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 2.4600  Validation loss = 7.4002  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 2.4599  Validation loss = 7.4001  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 2.4598  Validation loss = 7.3999  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 2.4597  Validation loss = 7.3998  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 2.4596  Validation loss = 7.3996  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 2.4594  Validation loss = 7.3995  \n",
      "\n",
      "Fold: 8  Epoch: 501  Training loss = 2.4593  Validation loss = 7.3993  \n",
      "\n",
      "Fold: 8  Epoch: 502  Training loss = 2.4591  Validation loss = 7.3991  \n",
      "\n",
      "Fold: 8  Epoch: 503  Training loss = 2.4590  Validation loss = 7.3990  \n",
      "\n",
      "Fold: 8  Epoch: 504  Training loss = 2.4589  Validation loss = 7.3989  \n",
      "\n",
      "Fold: 8  Epoch: 505  Training loss = 2.4587  Validation loss = 7.3987  \n",
      "\n",
      "Fold: 8  Epoch: 506  Training loss = 2.4586  Validation loss = 7.3985  \n",
      "\n",
      "Fold: 8  Epoch: 507  Training loss = 2.4585  Validation loss = 7.3984  \n",
      "\n",
      "Fold: 8  Epoch: 508  Training loss = 2.4583  Validation loss = 7.3982  \n",
      "\n",
      "Fold: 8  Epoch: 509  Training loss = 2.4582  Validation loss = 7.3980  \n",
      "\n",
      "Fold: 8  Epoch: 510  Training loss = 2.4581  Validation loss = 7.3979  \n",
      "\n",
      "Fold: 8  Epoch: 511  Training loss = 2.4580  Validation loss = 7.3978  \n",
      "\n",
      "Fold: 8  Epoch: 512  Training loss = 2.4578  Validation loss = 7.3976  \n",
      "\n",
      "Fold: 8  Epoch: 513  Training loss = 2.4577  Validation loss = 7.3975  \n",
      "\n",
      "Fold: 8  Epoch: 514  Training loss = 2.4576  Validation loss = 7.3973  \n",
      "\n",
      "Fold: 8  Epoch: 515  Training loss = 2.4574  Validation loss = 7.3971  \n",
      "\n",
      "Fold: 8  Epoch: 516  Training loss = 2.4573  Validation loss = 7.3969  \n",
      "\n",
      "Fold: 8  Epoch: 517  Training loss = 2.4571  Validation loss = 7.3968  \n",
      "\n",
      "Fold: 8  Epoch: 518  Training loss = 2.4570  Validation loss = 7.3966  \n",
      "\n",
      "Fold: 8  Epoch: 519  Training loss = 2.4569  Validation loss = 7.3965  \n",
      "\n",
      "Fold: 8  Epoch: 520  Training loss = 2.4568  Validation loss = 7.3963  \n",
      "\n",
      "Fold: 8  Epoch: 521  Training loss = 2.4567  Validation loss = 7.3962  \n",
      "\n",
      "Fold: 8  Epoch: 522  Training loss = 2.4565  Validation loss = 7.3961  \n",
      "\n",
      "Fold: 8  Epoch: 523  Training loss = 2.4565  Validation loss = 7.3960  \n",
      "\n",
      "Fold: 8  Epoch: 524  Training loss = 2.4564  Validation loss = 7.3959  \n",
      "\n",
      "Fold: 8  Epoch: 525  Training loss = 2.4562  Validation loss = 7.3957  \n",
      "\n",
      "Fold: 8  Epoch: 526  Training loss = 2.4561  Validation loss = 7.3956  \n",
      "\n",
      "Fold: 8  Epoch: 527  Training loss = 2.4560  Validation loss = 7.3954  \n",
      "\n",
      "Fold: 8  Epoch: 528  Training loss = 2.4559  Validation loss = 7.3953  \n",
      "\n",
      "Fold: 8  Epoch: 529  Training loss = 2.4557  Validation loss = 7.3951  \n",
      "\n",
      "Fold: 8  Epoch: 530  Training loss = 2.4556  Validation loss = 7.3949  \n",
      "\n",
      "Fold: 8  Epoch: 531  Training loss = 2.4555  Validation loss = 7.3948  \n",
      "\n",
      "Fold: 8  Epoch: 532  Training loss = 2.4553  Validation loss = 7.3946  \n",
      "\n",
      "Fold: 8  Epoch: 533  Training loss = 2.4552  Validation loss = 7.3945  \n",
      "\n",
      "Fold: 8  Epoch: 534  Training loss = 2.4551  Validation loss = 7.3943  \n",
      "\n",
      "Fold: 8  Epoch: 535  Training loss = 2.4549  Validation loss = 7.3942  \n",
      "\n",
      "Fold: 8  Epoch: 536  Training loss = 2.4548  Validation loss = 7.3940  \n",
      "\n",
      "Fold: 8  Epoch: 537  Training loss = 2.4547  Validation loss = 7.3939  \n",
      "\n",
      "Fold: 8  Epoch: 538  Training loss = 2.4545  Validation loss = 7.3938  \n",
      "\n",
      "Fold: 8  Epoch: 539  Training loss = 2.4544  Validation loss = 7.3936  \n",
      "\n",
      "Fold: 8  Epoch: 540  Training loss = 2.4543  Validation loss = 7.3934  \n",
      "\n",
      "Fold: 8  Epoch: 541  Training loss = 2.4542  Validation loss = 7.3933  \n",
      "\n",
      "Fold: 8  Epoch: 542  Training loss = 2.4541  Validation loss = 7.3932  \n",
      "\n",
      "Fold: 8  Epoch: 543  Training loss = 2.4540  Validation loss = 7.3930  \n",
      "\n",
      "Fold: 8  Epoch: 544  Training loss = 2.4538  Validation loss = 7.3929  \n",
      "\n",
      "Fold: 8  Epoch: 545  Training loss = 2.4537  Validation loss = 7.3927  \n",
      "\n",
      "Fold: 8  Epoch: 546  Training loss = 2.4536  Validation loss = 7.3926  \n",
      "\n",
      "Fold: 8  Epoch: 547  Training loss = 2.4534  Validation loss = 7.3924  \n",
      "\n",
      "Fold: 8  Epoch: 548  Training loss = 2.4533  Validation loss = 7.3922  \n",
      "\n",
      "Fold: 8  Epoch: 549  Training loss = 2.4532  Validation loss = 7.3921  \n",
      "\n",
      "Fold: 8  Epoch: 550  Training loss = 2.4531  Validation loss = 7.3919  \n",
      "\n",
      "Fold: 8  Epoch: 551  Training loss = 2.4529  Validation loss = 7.3918  \n",
      "\n",
      "Fold: 8  Epoch: 552  Training loss = 2.4528  Validation loss = 7.3916  \n",
      "\n",
      "Fold: 8  Epoch: 553  Training loss = 2.4527  Validation loss = 7.3915  \n",
      "\n",
      "Fold: 8  Epoch: 554  Training loss = 2.4526  Validation loss = 7.3914  \n",
      "\n",
      "Fold: 8  Epoch: 555  Training loss = 2.4524  Validation loss = 7.3912  \n",
      "\n",
      "Fold: 8  Epoch: 556  Training loss = 2.4523  Validation loss = 7.3910  \n",
      "\n",
      "Fold: 8  Epoch: 557  Training loss = 2.4521  Validation loss = 7.3909  \n",
      "\n",
      "Fold: 8  Epoch: 558  Training loss = 2.4520  Validation loss = 7.3907  \n",
      "\n",
      "Fold: 8  Epoch: 559  Training loss = 2.4519  Validation loss = 7.3906  \n",
      "\n",
      "Fold: 8  Epoch: 560  Training loss = 2.4518  Validation loss = 7.3904  \n",
      "\n",
      "Fold: 8  Epoch: 561  Training loss = 2.4516  Validation loss = 7.3902  \n",
      "\n",
      "Fold: 8  Epoch: 562  Training loss = 2.4515  Validation loss = 7.3900  \n",
      "\n",
      "Fold: 8  Epoch: 563  Training loss = 2.4514  Validation loss = 7.3899  \n",
      "\n",
      "Fold: 8  Epoch: 564  Training loss = 2.4513  Validation loss = 7.3898  \n",
      "\n",
      "Fold: 8  Epoch: 565  Training loss = 2.4511  Validation loss = 7.3896  \n",
      "\n",
      "Fold: 8  Epoch: 566  Training loss = 2.4510  Validation loss = 7.3895  \n",
      "\n",
      "Fold: 8  Epoch: 567  Training loss = 2.4509  Validation loss = 7.3893  \n",
      "\n",
      "Fold: 8  Epoch: 568  Training loss = 2.4507  Validation loss = 7.3891  \n",
      "\n",
      "Fold: 8  Epoch: 569  Training loss = 2.4506  Validation loss = 7.3890  \n",
      "\n",
      "Fold: 8  Epoch: 570  Training loss = 2.4505  Validation loss = 7.3888  \n",
      "\n",
      "Fold: 8  Epoch: 571  Training loss = 2.4504  Validation loss = 7.3887  \n",
      "\n",
      "Fold: 8  Epoch: 572  Training loss = 2.4502  Validation loss = 7.3885  \n",
      "\n",
      "Fold: 8  Epoch: 573  Training loss = 2.4501  Validation loss = 7.3884  \n",
      "\n",
      "Fold: 8  Epoch: 574  Training loss = 2.4500  Validation loss = 7.3883  \n",
      "\n",
      "Fold: 8  Epoch: 575  Training loss = 2.4498  Validation loss = 7.3881  \n",
      "\n",
      "Fold: 8  Epoch: 576  Training loss = 2.4497  Validation loss = 7.3880  \n",
      "\n",
      "Fold: 8  Epoch: 577  Training loss = 2.4496  Validation loss = 7.3878  \n",
      "\n",
      "Fold: 8  Epoch: 578  Training loss = 2.4494  Validation loss = 7.3877  \n",
      "\n",
      "Fold: 8  Epoch: 579  Training loss = 2.4493  Validation loss = 7.3875  \n",
      "\n",
      "Fold: 8  Epoch: 580  Training loss = 2.4492  Validation loss = 7.3874  \n",
      "\n",
      "Fold: 8  Epoch: 581  Training loss = 2.4491  Validation loss = 7.3872  \n",
      "\n",
      "Fold: 8  Epoch: 582  Training loss = 2.4490  Validation loss = 7.3871  \n",
      "\n",
      "Fold: 8  Epoch: 583  Training loss = 2.4489  Validation loss = 7.3869  \n",
      "\n",
      "Fold: 8  Epoch: 584  Training loss = 2.4487  Validation loss = 7.3868  \n",
      "\n",
      "Fold: 8  Epoch: 585  Training loss = 2.4486  Validation loss = 7.3866  \n",
      "\n",
      "Fold: 8  Epoch: 586  Training loss = 2.4485  Validation loss = 7.3865  \n",
      "\n",
      "Fold: 8  Epoch: 587  Training loss = 2.4484  Validation loss = 7.3864  \n",
      "\n",
      "Fold: 8  Epoch: 588  Training loss = 2.4483  Validation loss = 7.3862  \n",
      "\n",
      "Fold: 8  Epoch: 589  Training loss = 2.4481  Validation loss = 7.3861  \n",
      "\n",
      "Fold: 8  Epoch: 590  Training loss = 2.4480  Validation loss = 7.3859  \n",
      "\n",
      "Fold: 8  Epoch: 591  Training loss = 2.4479  Validation loss = 7.3858  \n",
      "\n",
      "Fold: 8  Epoch: 592  Training loss = 2.4477  Validation loss = 7.3856  \n",
      "\n",
      "Fold: 8  Epoch: 593  Training loss = 2.4476  Validation loss = 7.3855  \n",
      "\n",
      "Fold: 8  Epoch: 594  Training loss = 2.4474  Validation loss = 7.3853  \n",
      "\n",
      "Fold: 8  Epoch: 595  Training loss = 2.4473  Validation loss = 7.3852  \n",
      "\n",
      "Fold: 8  Epoch: 596  Training loss = 2.4472  Validation loss = 7.3850  \n",
      "\n",
      "Fold: 8  Epoch: 597  Training loss = 2.4471  Validation loss = 7.3849  \n",
      "\n",
      "Fold: 8  Epoch: 598  Training loss = 2.4470  Validation loss = 7.3848  \n",
      "\n",
      "Fold: 8  Epoch: 599  Training loss = 2.4468  Validation loss = 7.3846  \n",
      "\n",
      "Fold: 8  Epoch: 600  Training loss = 2.4467  Validation loss = 7.3844  \n",
      "\n",
      "Fold: 8  Epoch: 601  Training loss = 2.4465  Validation loss = 7.3843  \n",
      "\n",
      "Fold: 8  Epoch: 602  Training loss = 2.4464  Validation loss = 7.3841  \n",
      "\n",
      "Fold: 8  Epoch: 603  Training loss = 2.4463  Validation loss = 7.3840  \n",
      "\n",
      "Fold: 8  Epoch: 604  Training loss = 2.4461  Validation loss = 7.3838  \n",
      "\n",
      "Fold: 8  Epoch: 605  Training loss = 2.4460  Validation loss = 7.3837  \n",
      "\n",
      "Fold: 8  Epoch: 606  Training loss = 2.4459  Validation loss = 7.3836  \n",
      "\n",
      "Fold: 8  Epoch: 607  Training loss = 2.4458  Validation loss = 7.3834  \n",
      "\n",
      "Fold: 8  Epoch: 608  Training loss = 2.4457  Validation loss = 7.3833  \n",
      "\n",
      "Fold: 8  Epoch: 609  Training loss = 2.4455  Validation loss = 7.3831  \n",
      "\n",
      "Fold: 8  Epoch: 610  Training loss = 2.4454  Validation loss = 7.3829  \n",
      "\n",
      "Fold: 8  Epoch: 611  Training loss = 2.4452  Validation loss = 7.3828  \n",
      "\n",
      "Fold: 8  Epoch: 612  Training loss = 2.4451  Validation loss = 7.3826  \n",
      "\n",
      "Fold: 8  Epoch: 613  Training loss = 2.4450  Validation loss = 7.3824  \n",
      "\n",
      "Fold: 8  Epoch: 614  Training loss = 2.4449  Validation loss = 7.3823  \n",
      "\n",
      "Fold: 8  Epoch: 615  Training loss = 2.4447  Validation loss = 7.3821  \n",
      "\n",
      "Fold: 8  Epoch: 616  Training loss = 2.4446  Validation loss = 7.3820  \n",
      "\n",
      "Fold: 8  Epoch: 617  Training loss = 2.4445  Validation loss = 7.3819  \n",
      "\n",
      "Fold: 8  Epoch: 618  Training loss = 2.4444  Validation loss = 7.3817  \n",
      "\n",
      "Fold: 8  Epoch: 619  Training loss = 2.4443  Validation loss = 7.3816  \n",
      "\n",
      "Fold: 8  Epoch: 620  Training loss = 2.4441  Validation loss = 7.3814  \n",
      "\n",
      "Fold: 8  Epoch: 621  Training loss = 2.4440  Validation loss = 7.3813  \n",
      "\n",
      "Fold: 8  Epoch: 622  Training loss = 2.4439  Validation loss = 7.3811  \n",
      "\n",
      "Fold: 8  Epoch: 623  Training loss = 2.4438  Validation loss = 7.3810  \n",
      "\n",
      "Fold: 8  Epoch: 624  Training loss = 2.4436  Validation loss = 7.3808  \n",
      "\n",
      "Fold: 8  Epoch: 625  Training loss = 2.4435  Validation loss = 7.3807  \n",
      "\n",
      "Fold: 8  Epoch: 626  Training loss = 2.4434  Validation loss = 7.3805  \n",
      "\n",
      "Fold: 8  Epoch: 627  Training loss = 2.4433  Validation loss = 7.3804  \n",
      "\n",
      "Fold: 8  Epoch: 628  Training loss = 2.4431  Validation loss = 7.3802  \n",
      "\n",
      "Fold: 8  Epoch: 629  Training loss = 2.4430  Validation loss = 7.3801  \n",
      "\n",
      "Fold: 8  Epoch: 630  Training loss = 2.4429  Validation loss = 7.3799  \n",
      "\n",
      "Fold: 8  Epoch: 631  Training loss = 2.4428  Validation loss = 7.3798  \n",
      "\n",
      "Fold: 8  Epoch: 632  Training loss = 2.4427  Validation loss = 7.3797  \n",
      "\n",
      "Fold: 8  Epoch: 633  Training loss = 2.4425  Validation loss = 7.3795  \n",
      "\n",
      "Fold: 8  Epoch: 634  Training loss = 2.4424  Validation loss = 7.3794  \n",
      "\n",
      "Fold: 8  Epoch: 635  Training loss = 2.4423  Validation loss = 7.3792  \n",
      "\n",
      "Fold: 8  Epoch: 636  Training loss = 2.4422  Validation loss = 7.3791  \n",
      "\n",
      "Fold: 8  Epoch: 637  Training loss = 2.4420  Validation loss = 7.3789  \n",
      "\n",
      "Fold: 8  Epoch: 638  Training loss = 2.4419  Validation loss = 7.3788  \n",
      "\n",
      "Fold: 8  Epoch: 639  Training loss = 2.4418  Validation loss = 7.3786  \n",
      "\n",
      "Fold: 8  Epoch: 640  Training loss = 2.4417  Validation loss = 7.3785  \n",
      "\n",
      "Fold: 8  Epoch: 641  Training loss = 2.4416  Validation loss = 7.3784  \n",
      "\n",
      "Fold: 8  Epoch: 642  Training loss = 2.4414  Validation loss = 7.3782  \n",
      "\n",
      "Fold: 8  Epoch: 643  Training loss = 2.4413  Validation loss = 7.3780  \n",
      "\n",
      "Fold: 8  Epoch: 644  Training loss = 2.4412  Validation loss = 7.3779  \n",
      "\n",
      "Fold: 8  Epoch: 645  Training loss = 2.4411  Validation loss = 7.3777  \n",
      "\n",
      "Fold: 8  Epoch: 646  Training loss = 2.4410  Validation loss = 7.3776  \n",
      "\n",
      "Fold: 8  Epoch: 647  Training loss = 2.4409  Validation loss = 7.3775  \n",
      "\n",
      "Fold: 8  Epoch: 648  Training loss = 2.4408  Validation loss = 7.3774  \n",
      "\n",
      "Fold: 8  Epoch: 649  Training loss = 2.4406  Validation loss = 7.3772  \n",
      "\n",
      "Fold: 8  Epoch: 650  Training loss = 2.4405  Validation loss = 7.3771  \n",
      "\n",
      "Fold: 8  Epoch: 651  Training loss = 2.4404  Validation loss = 7.3769  \n",
      "\n",
      "Fold: 8  Epoch: 652  Training loss = 2.4403  Validation loss = 7.3768  \n",
      "\n",
      "Fold: 8  Epoch: 653  Training loss = 2.4401  Validation loss = 7.3766  \n",
      "\n",
      "Fold: 8  Epoch: 654  Training loss = 2.4400  Validation loss = 7.3764  \n",
      "\n",
      "Fold: 8  Epoch: 655  Training loss = 2.4399  Validation loss = 7.3763  \n",
      "\n",
      "Fold: 8  Epoch: 656  Training loss = 2.4398  Validation loss = 7.3761  \n",
      "\n",
      "Fold: 8  Epoch: 657  Training loss = 2.4396  Validation loss = 7.3760  \n",
      "\n",
      "Fold: 8  Epoch: 658  Training loss = 2.4395  Validation loss = 7.3758  \n",
      "\n",
      "Fold: 8  Epoch: 659  Training loss = 2.4394  Validation loss = 7.3757  \n",
      "\n",
      "Fold: 8  Epoch: 660  Training loss = 2.4393  Validation loss = 7.3756  \n",
      "\n",
      "Fold: 8  Epoch: 661  Training loss = 2.4391  Validation loss = 7.3754  \n",
      "\n",
      "Fold: 8  Epoch: 662  Training loss = 2.4390  Validation loss = 7.3752  \n",
      "\n",
      "Fold: 8  Epoch: 663  Training loss = 2.4389  Validation loss = 7.3751  \n",
      "\n",
      "Fold: 8  Epoch: 664  Training loss = 2.4388  Validation loss = 7.3749  \n",
      "\n",
      "Fold: 8  Epoch: 665  Training loss = 2.4386  Validation loss = 7.3747  \n",
      "\n",
      "Fold: 8  Epoch: 666  Training loss = 2.4385  Validation loss = 7.3746  \n",
      "\n",
      "Fold: 8  Epoch: 667  Training loss = 2.4383  Validation loss = 7.3745  \n",
      "\n",
      "Fold: 8  Epoch: 668  Training loss = 2.4382  Validation loss = 7.3743  \n",
      "\n",
      "Fold: 8  Epoch: 669  Training loss = 2.4381  Validation loss = 7.3741  \n",
      "\n",
      "Fold: 8  Epoch: 670  Training loss = 2.4379  Validation loss = 7.3740  \n",
      "\n",
      "Fold: 8  Epoch: 671  Training loss = 2.4378  Validation loss = 7.3738  \n",
      "\n",
      "Fold: 8  Epoch: 672  Training loss = 2.4377  Validation loss = 7.3737  \n",
      "\n",
      "Fold: 8  Epoch: 673  Training loss = 2.4376  Validation loss = 7.3736  \n",
      "\n",
      "Fold: 8  Epoch: 674  Training loss = 2.4375  Validation loss = 7.3734  \n",
      "\n",
      "Fold: 8  Epoch: 675  Training loss = 2.4374  Validation loss = 7.3733  \n",
      "\n",
      "Fold: 8  Epoch: 676  Training loss = 2.4373  Validation loss = 7.3731  \n",
      "\n",
      "Fold: 8  Epoch: 677  Training loss = 2.4371  Validation loss = 7.3730  \n",
      "\n",
      "Fold: 8  Epoch: 678  Training loss = 2.4370  Validation loss = 7.3728  \n",
      "\n",
      "Fold: 8  Epoch: 679  Training loss = 2.4369  Validation loss = 7.3727  \n",
      "\n",
      "Fold: 8  Epoch: 680  Training loss = 2.4367  Validation loss = 7.3725  \n",
      "\n",
      "Fold: 8  Epoch: 681  Training loss = 2.4366  Validation loss = 7.3723  \n",
      "\n",
      "Fold: 8  Epoch: 682  Training loss = 2.4365  Validation loss = 7.3722  \n",
      "\n",
      "Fold: 8  Epoch: 683  Training loss = 2.4363  Validation loss = 7.3720  \n",
      "\n",
      "Fold: 8  Epoch: 684  Training loss = 2.4362  Validation loss = 7.3719  \n",
      "\n",
      "Fold: 8  Epoch: 685  Training loss = 2.4361  Validation loss = 7.3718  \n",
      "\n",
      "Fold: 8  Epoch: 686  Training loss = 2.4360  Validation loss = 7.3716  \n",
      "\n",
      "Fold: 8  Epoch: 687  Training loss = 2.4359  Validation loss = 7.3715  \n",
      "\n",
      "Fold: 8  Epoch: 688  Training loss = 2.4358  Validation loss = 7.3714  \n",
      "\n",
      "Fold: 8  Epoch: 689  Training loss = 2.4357  Validation loss = 7.3712  \n",
      "\n",
      "Fold: 8  Epoch: 690  Training loss = 2.4356  Validation loss = 7.3711  \n",
      "\n",
      "Fold: 8  Epoch: 691  Training loss = 2.4354  Validation loss = 7.3709  \n",
      "\n",
      "Fold: 8  Epoch: 692  Training loss = 2.4353  Validation loss = 7.3707  \n",
      "\n",
      "Fold: 8  Epoch: 693  Training loss = 2.4351  Validation loss = 7.3706  \n",
      "\n",
      "Fold: 8  Epoch: 694  Training loss = 2.4350  Validation loss = 7.3704  \n",
      "\n",
      "Fold: 8  Epoch: 695  Training loss = 2.4349  Validation loss = 7.3703  \n",
      "\n",
      "Fold: 8  Epoch: 696  Training loss = 2.4348  Validation loss = 7.3701  \n",
      "\n",
      "Fold: 8  Epoch: 697  Training loss = 2.4346  Validation loss = 7.3699  \n",
      "\n",
      "Fold: 8  Epoch: 698  Training loss = 2.4345  Validation loss = 7.3697  \n",
      "\n",
      "Fold: 8  Epoch: 699  Training loss = 2.4343  Validation loss = 7.3696  \n",
      "\n",
      "Fold: 8  Epoch: 700  Training loss = 2.4342  Validation loss = 7.3695  \n",
      "\n",
      "Fold: 8  Epoch: 701  Training loss = 2.4341  Validation loss = 7.3693  \n",
      "\n",
      "Fold: 8  Epoch: 702  Training loss = 2.4340  Validation loss = 7.3691  \n",
      "\n",
      "Fold: 8  Epoch: 703  Training loss = 2.4338  Validation loss = 7.3690  \n",
      "\n",
      "Fold: 8  Epoch: 704  Training loss = 2.4337  Validation loss = 7.3688  \n",
      "\n",
      "Fold: 8  Epoch: 705  Training loss = 2.4336  Validation loss = 7.3687  \n",
      "\n",
      "Fold: 8  Epoch: 706  Training loss = 2.4334  Validation loss = 7.3685  \n",
      "\n",
      "Fold: 8  Epoch: 707  Training loss = 2.4333  Validation loss = 7.3683  \n",
      "\n",
      "Fold: 8  Epoch: 708  Training loss = 2.4332  Validation loss = 7.3682  \n",
      "\n",
      "Fold: 8  Epoch: 709  Training loss = 2.4330  Validation loss = 7.3680  \n",
      "\n",
      "Fold: 8  Epoch: 710  Training loss = 2.4329  Validation loss = 7.3679  \n",
      "\n",
      "Fold: 8  Epoch: 711  Training loss = 2.4328  Validation loss = 7.3677  \n",
      "\n",
      "Fold: 8  Epoch: 712  Training loss = 2.4327  Validation loss = 7.3676  \n",
      "\n",
      "Fold: 8  Epoch: 713  Training loss = 2.4325  Validation loss = 7.3675  \n",
      "\n",
      "Fold: 8  Epoch: 714  Training loss = 2.4325  Validation loss = 7.3673  \n",
      "\n",
      "Fold: 8  Epoch: 715  Training loss = 2.4323  Validation loss = 7.3672  \n",
      "\n",
      "Fold: 8  Epoch: 716  Training loss = 2.4322  Validation loss = 7.3670  \n",
      "\n",
      "Fold: 8  Epoch: 717  Training loss = 2.4321  Validation loss = 7.3669  \n",
      "\n",
      "Fold: 8  Epoch: 718  Training loss = 2.4320  Validation loss = 7.3667  \n",
      "\n",
      "Fold: 8  Epoch: 719  Training loss = 2.4318  Validation loss = 7.3666  \n",
      "\n",
      "Fold: 8  Epoch: 720  Training loss = 2.4317  Validation loss = 7.3664  \n",
      "\n",
      "Fold: 8  Epoch: 721  Training loss = 2.4316  Validation loss = 7.3663  \n",
      "\n",
      "Fold: 8  Epoch: 722  Training loss = 2.4314  Validation loss = 7.3661  \n",
      "\n",
      "Fold: 8  Epoch: 723  Training loss = 2.4313  Validation loss = 7.3659  \n",
      "\n",
      "Fold: 8  Epoch: 724  Training loss = 2.4312  Validation loss = 7.3658  \n",
      "\n",
      "Fold: 8  Epoch: 725  Training loss = 2.4310  Validation loss = 7.3657  \n",
      "\n",
      "Fold: 8  Epoch: 726  Training loss = 2.4309  Validation loss = 7.3655  \n",
      "\n",
      "Fold: 8  Epoch: 727  Training loss = 2.4308  Validation loss = 7.3653  \n",
      "\n",
      "Fold: 8  Epoch: 728  Training loss = 2.4306  Validation loss = 7.3651  \n",
      "\n",
      "Fold: 8  Epoch: 729  Training loss = 2.4305  Validation loss = 7.3650  \n",
      "\n",
      "Fold: 8  Epoch: 730  Training loss = 2.4304  Validation loss = 7.3649  \n",
      "\n",
      "Fold: 8  Epoch: 731  Training loss = 2.4303  Validation loss = 7.3647  \n",
      "\n",
      "Fold: 8  Epoch: 732  Training loss = 2.4301  Validation loss = 7.3646  \n",
      "\n",
      "Fold: 8  Epoch: 733  Training loss = 2.4300  Validation loss = 7.3645  \n",
      "\n",
      "Fold: 8  Epoch: 734  Training loss = 2.4299  Validation loss = 7.3643  \n",
      "\n",
      "Fold: 8  Epoch: 735  Training loss = 2.4297  Validation loss = 7.3641  \n",
      "\n",
      "Fold: 8  Epoch: 736  Training loss = 2.4296  Validation loss = 7.3639  \n",
      "\n",
      "Fold: 8  Epoch: 737  Training loss = 2.4295  Validation loss = 7.3638  \n",
      "\n",
      "Fold: 8  Epoch: 738  Training loss = 2.4293  Validation loss = 7.3636  \n",
      "\n",
      "Fold: 8  Epoch: 739  Training loss = 2.4292  Validation loss = 7.3635  \n",
      "\n",
      "Fold: 8  Epoch: 740  Training loss = 2.4291  Validation loss = 7.3633  \n",
      "\n",
      "Fold: 8  Epoch: 741  Training loss = 2.4290  Validation loss = 7.3632  \n",
      "\n",
      "Fold: 8  Epoch: 742  Training loss = 2.4289  Validation loss = 7.3631  \n",
      "\n",
      "Fold: 8  Epoch: 743  Training loss = 2.4287  Validation loss = 7.3630  \n",
      "\n",
      "Fold: 8  Epoch: 744  Training loss = 2.4286  Validation loss = 7.3628  \n",
      "\n",
      "Fold: 8  Epoch: 745  Training loss = 2.4285  Validation loss = 7.3627  \n",
      "\n",
      "Fold: 8  Epoch: 746  Training loss = 2.4284  Validation loss = 7.3625  \n",
      "\n",
      "Fold: 8  Epoch: 747  Training loss = 2.4283  Validation loss = 7.3624  \n",
      "\n",
      "Fold: 8  Epoch: 748  Training loss = 2.4281  Validation loss = 7.3622  \n",
      "\n",
      "Fold: 8  Epoch: 749  Training loss = 2.4280  Validation loss = 7.3621  \n",
      "\n",
      "Fold: 8  Epoch: 750  Training loss = 2.4279  Validation loss = 7.3619  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 750  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.9747  Validation loss = 11.6372  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.9746  Validation loss = 11.6371  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.9744  Validation loss = 11.6369  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.9743  Validation loss = 11.6369  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.9742  Validation loss = 11.6368  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.9740  Validation loss = 11.6367  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.9739  Validation loss = 11.6365  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.9737  Validation loss = 11.6364  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.9736  Validation loss = 11.6363  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.9734  Validation loss = 11.6361  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.9733  Validation loss = 11.6360  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.9731  Validation loss = 11.6359  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.9730  Validation loss = 11.6358  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.9729  Validation loss = 11.6357  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.9727  Validation loss = 11.6356  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.9726  Validation loss = 11.6355  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.9725  Validation loss = 11.6354  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.9724  Validation loss = 11.6353  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.9722  Validation loss = 11.6352  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.9721  Validation loss = 11.6351  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.9720  Validation loss = 11.6350  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.9718  Validation loss = 11.6349  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.9717  Validation loss = 11.6348  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.9715  Validation loss = 11.6347  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.9714  Validation loss = 11.6345  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.9713  Validation loss = 11.6344  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.9711  Validation loss = 11.6343  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.9710  Validation loss = 11.6342  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.9709  Validation loss = 11.6341  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.9708  Validation loss = 11.6340  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.9707  Validation loss = 11.6340  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.9706  Validation loss = 11.6339  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.9705  Validation loss = 11.6338  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.9703  Validation loss = 11.6337  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.9701  Validation loss = 11.6335  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.9700  Validation loss = 11.6334  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.9699  Validation loss = 11.6334  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.9698  Validation loss = 11.6333  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.9697  Validation loss = 11.6332  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.9695  Validation loss = 11.6330  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.9694  Validation loss = 11.6329  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.9693  Validation loss = 11.6328  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.9691  Validation loss = 11.6327  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.9690  Validation loss = 11.6326  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.9688  Validation loss = 11.6325  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.9686  Validation loss = 11.6323  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.9685  Validation loss = 11.6323  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.9684  Validation loss = 11.6321  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.9683  Validation loss = 11.6320  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.9682  Validation loss = 11.6320  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.9680  Validation loss = 11.6319  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.9679  Validation loss = 11.6318  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.9677  Validation loss = 11.6316  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.9676  Validation loss = 11.6315  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.9675  Validation loss = 11.6315  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.9674  Validation loss = 11.6314  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.9673  Validation loss = 11.6313  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.9671  Validation loss = 11.6311  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.9670  Validation loss = 11.6310  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.9669  Validation loss = 11.6309  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.9667  Validation loss = 11.6308  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.9666  Validation loss = 11.6307  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.9664  Validation loss = 11.6306  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.9663  Validation loss = 11.6305  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.9662  Validation loss = 11.6304  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.9660  Validation loss = 11.6303  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.9659  Validation loss = 11.6301  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.9657  Validation loss = 11.6300  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.9656  Validation loss = 11.6299  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.9654  Validation loss = 11.6298  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.9653  Validation loss = 11.6297  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.9652  Validation loss = 11.6296  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.9651  Validation loss = 11.6295  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.9649  Validation loss = 11.6294  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.9648  Validation loss = 11.6293  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.9647  Validation loss = 11.6292  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.9645  Validation loss = 11.6291  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.9644  Validation loss = 11.6290  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.9642  Validation loss = 11.6288  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.9641  Validation loss = 11.6287  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.9639  Validation loss = 11.6286  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.9638  Validation loss = 11.6285  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.9637  Validation loss = 11.6284  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.9636  Validation loss = 11.6284  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.9635  Validation loss = 11.6283  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.9633  Validation loss = 11.6281  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.9633  Validation loss = 11.6281  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.9631  Validation loss = 11.6279  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.9630  Validation loss = 11.6278  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.9628  Validation loss = 11.6277  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.9627  Validation loss = 11.6276  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.9625  Validation loss = 11.6275  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.9624  Validation loss = 11.6274  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.9623  Validation loss = 11.6273  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.9621  Validation loss = 11.6272  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.9620  Validation loss = 11.6270  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.9618  Validation loss = 11.6269  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.9617  Validation loss = 11.6268  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.9616  Validation loss = 11.6267  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.9614  Validation loss = 11.6266  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.9613  Validation loss = 11.6265  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.9612  Validation loss = 11.6264  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.9610  Validation loss = 11.6263  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.9609  Validation loss = 11.6262  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.9608  Validation loss = 11.6261  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.9607  Validation loss = 11.6260  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.9605  Validation loss = 11.6259  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.9604  Validation loss = 11.6258  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.9603  Validation loss = 11.6256  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.9601  Validation loss = 11.6256  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.9600  Validation loss = 11.6254  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.9598  Validation loss = 11.6253  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.9597  Validation loss = 11.6252  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.9596  Validation loss = 11.6251  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.9594  Validation loss = 11.6250  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.9593  Validation loss = 11.6249  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.9592  Validation loss = 11.6248  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.9590  Validation loss = 11.6247  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.9589  Validation loss = 11.6245  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.9587  Validation loss = 11.6244  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.9586  Validation loss = 11.6243  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.9585  Validation loss = 11.6242  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.9584  Validation loss = 11.6241  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.9582  Validation loss = 11.6240  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.9581  Validation loss = 11.6239  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.9580  Validation loss = 11.6238  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.9579  Validation loss = 11.6237  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.9577  Validation loss = 11.6236  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.9576  Validation loss = 11.6235  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.9575  Validation loss = 11.6234  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.9574  Validation loss = 11.6233  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.9572  Validation loss = 11.6232  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.9571  Validation loss = 11.6231  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.9569  Validation loss = 11.6230  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.9568  Validation loss = 11.6229  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.9567  Validation loss = 11.6228  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.9566  Validation loss = 11.6227  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.9564  Validation loss = 11.6226  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.9563  Validation loss = 11.6225  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.9562  Validation loss = 11.6224  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.9561  Validation loss = 11.6223  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.9559  Validation loss = 11.6222  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.9558  Validation loss = 11.6221  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.9557  Validation loss = 11.6220  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.9556  Validation loss = 11.6219  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.9555  Validation loss = 11.6218  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.9553  Validation loss = 11.6217  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.9552  Validation loss = 11.6216  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.9550  Validation loss = 11.6214  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.9549  Validation loss = 11.6213  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.9548  Validation loss = 11.6212  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.9547  Validation loss = 11.6212  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.9545  Validation loss = 11.6211  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.9544  Validation loss = 11.6209  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.9542  Validation loss = 11.6208  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.9541  Validation loss = 11.6207  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.9540  Validation loss = 11.6207  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.9539  Validation loss = 11.6206  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.9538  Validation loss = 11.6205  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.9536  Validation loss = 11.6203  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.9535  Validation loss = 11.6203  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.9534  Validation loss = 11.6202  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.9533  Validation loss = 11.6201  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.9532  Validation loss = 11.6199  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.9530  Validation loss = 11.6198  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.9529  Validation loss = 11.6197  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.9528  Validation loss = 11.6196  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.9527  Validation loss = 11.6195  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.9526  Validation loss = 11.6194  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.9524  Validation loss = 11.6193  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.9523  Validation loss = 11.6192  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.9522  Validation loss = 11.6191  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.9521  Validation loss = 11.6190  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.9519  Validation loss = 11.6189  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.9518  Validation loss = 11.6188  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.9516  Validation loss = 11.6187  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.9515  Validation loss = 11.6186  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.9514  Validation loss = 11.6185  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.9513  Validation loss = 11.6184  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.9511  Validation loss = 11.6183  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.9510  Validation loss = 11.6182  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.9509  Validation loss = 11.6181  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.9507  Validation loss = 11.6180  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.9506  Validation loss = 11.6179  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.9505  Validation loss = 11.6178  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.9504  Validation loss = 11.6177  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.9502  Validation loss = 11.6176  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.9501  Validation loss = 11.6175  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.9500  Validation loss = 11.6174  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.9499  Validation loss = 11.6173  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.9497  Validation loss = 11.6171  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.9496  Validation loss = 11.6170  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.9495  Validation loss = 11.6169  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.9493  Validation loss = 11.6168  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.9492  Validation loss = 11.6167  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.9490  Validation loss = 11.6166  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.9489  Validation loss = 11.6165  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.9488  Validation loss = 11.6164  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.9487  Validation loss = 11.6163  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.9485  Validation loss = 11.6162  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.9484  Validation loss = 11.6161  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.9483  Validation loss = 11.6160  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.9481  Validation loss = 11.6159  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.9480  Validation loss = 11.6158  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.9478  Validation loss = 11.6156  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.9477  Validation loss = 11.6155  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.9476  Validation loss = 11.6154  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.9475  Validation loss = 11.6153  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.9473  Validation loss = 11.6152  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.9472  Validation loss = 11.6151  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.9471  Validation loss = 11.6150  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.9469  Validation loss = 11.6149  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.9468  Validation loss = 11.6148  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.9467  Validation loss = 11.6147  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.9466  Validation loss = 11.6146  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.9464  Validation loss = 11.6144  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.9463  Validation loss = 11.6143  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.9461  Validation loss = 11.6142  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.9460  Validation loss = 11.6141  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.9458  Validation loss = 11.6140  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.9457  Validation loss = 11.6139  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.9455  Validation loss = 11.6138  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.9454  Validation loss = 11.6137  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.9453  Validation loss = 11.6135  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.9452  Validation loss = 11.6134  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.9450  Validation loss = 11.6133  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.9449  Validation loss = 11.6132  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.9448  Validation loss = 11.6131  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.9447  Validation loss = 11.6130  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.9445  Validation loss = 11.6129  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.9444  Validation loss = 11.6128  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.9443  Validation loss = 11.6127  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.9441  Validation loss = 11.6126  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.9440  Validation loss = 11.6125  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.9439  Validation loss = 11.6124  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.9438  Validation loss = 11.6123  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.9436  Validation loss = 11.6121  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.9435  Validation loss = 11.6120  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.9433  Validation loss = 11.6119  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.9432  Validation loss = 11.6118  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.9431  Validation loss = 11.6117  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.9430  Validation loss = 11.6116  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.9428  Validation loss = 11.6115  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.9427  Validation loss = 11.6114  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.9426  Validation loss = 11.6113  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.9425  Validation loss = 11.6112  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.9423  Validation loss = 11.6111  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.9422  Validation loss = 11.6110  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.9421  Validation loss = 11.6109  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.9420  Validation loss = 11.6108  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.9419  Validation loss = 11.6107  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.9417  Validation loss = 11.6106  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.9416  Validation loss = 11.6104  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.9415  Validation loss = 11.6103  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.9413  Validation loss = 11.6102  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.9412  Validation loss = 11.6101  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.9410  Validation loss = 11.6100  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 2.9409  Validation loss = 11.6098  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 2.9407  Validation loss = 11.6097  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 2.9406  Validation loss = 11.6096  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 2.9405  Validation loss = 11.6095  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 2.9404  Validation loss = 11.6094  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 2.9403  Validation loss = 11.6093  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 2.9401  Validation loss = 11.6092  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 2.9400  Validation loss = 11.6091  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 2.9398  Validation loss = 11.6090  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 2.9397  Validation loss = 11.6089  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 2.9396  Validation loss = 11.6088  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 2.9395  Validation loss = 11.6087  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 2.9393  Validation loss = 11.6086  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 2.9392  Validation loss = 11.6085  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 2.9391  Validation loss = 11.6084  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 2.9389  Validation loss = 11.6082  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 2.9388  Validation loss = 11.6081  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 2.9387  Validation loss = 11.6080  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 2.9385  Validation loss = 11.6079  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 2.9384  Validation loss = 11.6078  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 2.9383  Validation loss = 11.6077  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 2.9382  Validation loss = 11.6076  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 2.9381  Validation loss = 11.6075  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 2.9380  Validation loss = 11.6074  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 2.9378  Validation loss = 11.6073  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 2.9377  Validation loss = 11.6072  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 2.9376  Validation loss = 11.6070  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 2.9374  Validation loss = 11.6069  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 2.9373  Validation loss = 11.6068  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 2.9372  Validation loss = 11.6067  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 2.9371  Validation loss = 11.6066  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 2.9369  Validation loss = 11.6065  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 2.9368  Validation loss = 11.6064  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 2.9367  Validation loss = 11.6063  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 2.9365  Validation loss = 11.6062  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 2.9364  Validation loss = 11.6061  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 2.9363  Validation loss = 11.6060  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 2.9362  Validation loss = 11.6059  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 2.9361  Validation loss = 11.6058  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 2.9360  Validation loss = 11.6057  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 2.9359  Validation loss = 11.6056  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 2.9357  Validation loss = 11.6055  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 2.9356  Validation loss = 11.6054  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 2.9355  Validation loss = 11.6053  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 2.9354  Validation loss = 11.6052  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 2.9352  Validation loss = 11.6051  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 2.9351  Validation loss = 11.6050  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 2.9350  Validation loss = 11.6049  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 2.9349  Validation loss = 11.6048  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 2.9348  Validation loss = 11.6047  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 2.9347  Validation loss = 11.6046  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 2.9346  Validation loss = 11.6045  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 2.9345  Validation loss = 11.6044  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 2.9344  Validation loss = 11.6043  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 2.9342  Validation loss = 11.6042  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 2.9341  Validation loss = 11.6041  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 2.9340  Validation loss = 11.6040  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 2.9338  Validation loss = 11.6039  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 2.9337  Validation loss = 11.6038  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 2.9335  Validation loss = 11.6037  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 2.9334  Validation loss = 11.6035  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 2.9333  Validation loss = 11.6034  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 2.9332  Validation loss = 11.6033  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 2.9330  Validation loss = 11.6032  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 2.9329  Validation loss = 11.6031  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 2.9328  Validation loss = 11.6030  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 2.9327  Validation loss = 11.6029  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 2.9325  Validation loss = 11.6028  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 2.9324  Validation loss = 11.6027  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 2.9323  Validation loss = 11.6026  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 2.9321  Validation loss = 11.6025  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 2.9320  Validation loss = 11.6024  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 2.9319  Validation loss = 11.6023  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 2.9318  Validation loss = 11.6022  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 2.9316  Validation loss = 11.6020  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 2.9315  Validation loss = 11.6019  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 2.9314  Validation loss = 11.6018  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 2.9312  Validation loss = 11.6017  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 2.9311  Validation loss = 11.6016  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 2.9310  Validation loss = 11.6014  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 2.9308  Validation loss = 11.6013  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 2.9307  Validation loss = 11.6012  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 2.9305  Validation loss = 11.6011  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 2.9304  Validation loss = 11.6010  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 2.9302  Validation loss = 11.6008  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 2.9300  Validation loss = 11.6007  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 2.9299  Validation loss = 11.6006  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 2.9298  Validation loss = 11.6004  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 2.9296  Validation loss = 11.6003  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 2.9295  Validation loss = 11.6002  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 2.9294  Validation loss = 11.6001  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 2.9293  Validation loss = 11.6000  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 2.9291  Validation loss = 11.5999  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 2.9290  Validation loss = 11.5998  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 2.9289  Validation loss = 11.5997  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 2.9288  Validation loss = 11.5996  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 2.9287  Validation loss = 11.5995  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 2.9285  Validation loss = 11.5993  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 2.9283  Validation loss = 11.5992  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 2.9282  Validation loss = 11.5991  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 2.9281  Validation loss = 11.5990  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 2.9279  Validation loss = 11.5989  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 2.9278  Validation loss = 11.5988  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 2.9277  Validation loss = 11.5987  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 2.9276  Validation loss = 11.5986  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 2.9274  Validation loss = 11.5985  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 2.9273  Validation loss = 11.5983  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 2.9272  Validation loss = 11.5982  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 2.9270  Validation loss = 11.5981  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 2.9269  Validation loss = 11.5980  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 2.9268  Validation loss = 11.5979  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 2.9267  Validation loss = 11.5978  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 2.9265  Validation loss = 11.5977  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 2.9264  Validation loss = 11.5976  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 2.9263  Validation loss = 11.5975  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 2.9262  Validation loss = 11.5974  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 2.9260  Validation loss = 11.5972  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 2.9259  Validation loss = 11.5971  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 2.9257  Validation loss = 11.5970  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 2.9256  Validation loss = 11.5969  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 2.9255  Validation loss = 11.5968  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 2.9254  Validation loss = 11.5967  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 2.9252  Validation loss = 11.5965  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 2.9251  Validation loss = 11.5964  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 2.9250  Validation loss = 11.5964  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 2.9248  Validation loss = 11.5962  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 2.9247  Validation loss = 11.5961  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 2.9246  Validation loss = 11.5960  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 2.9245  Validation loss = 11.5959  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 2.9243  Validation loss = 11.5958  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 2.9242  Validation loss = 11.5957  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 2.9241  Validation loss = 11.5956  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 2.9239  Validation loss = 11.5955  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 2.9238  Validation loss = 11.5954  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 2.9236  Validation loss = 11.5952  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 2.9235  Validation loss = 11.5951  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 2.9234  Validation loss = 11.5950  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 2.9232  Validation loss = 11.5949  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 2.9231  Validation loss = 11.5948  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 2.9230  Validation loss = 11.5947  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 2.9229  Validation loss = 11.5946  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 2.9228  Validation loss = 11.5945  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 2.9226  Validation loss = 11.5944  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 2.9225  Validation loss = 11.5943  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 2.9224  Validation loss = 11.5942  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 2.9223  Validation loss = 11.5941  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 2.9222  Validation loss = 11.5940  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 2.9220  Validation loss = 11.5939  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 2.9219  Validation loss = 11.5937  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 2.9217  Validation loss = 11.5936  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 2.9216  Validation loss = 11.5935  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 2.9215  Validation loss = 11.5934  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 2.9213  Validation loss = 11.5933  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 2.9212  Validation loss = 11.5932  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 2.9211  Validation loss = 11.5931  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 2.9209  Validation loss = 11.5929  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 2.9208  Validation loss = 11.5928  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 2.9206  Validation loss = 11.5927  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 2.9205  Validation loss = 11.5925  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 2.9204  Validation loss = 11.5924  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 2.9202  Validation loss = 11.5923  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 2.9201  Validation loss = 11.5922  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 2.9200  Validation loss = 11.5921  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 2.9198  Validation loss = 11.5920  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 2.9197  Validation loss = 11.5919  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 2.9196  Validation loss = 11.5918  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 2.9194  Validation loss = 11.5916  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 2.9193  Validation loss = 11.5915  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 2.9192  Validation loss = 11.5914  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 2.9190  Validation loss = 11.5913  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 2.9189  Validation loss = 11.5912  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 2.9188  Validation loss = 11.5910  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 2.9187  Validation loss = 11.5910  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 2.9186  Validation loss = 11.5909  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 2.9184  Validation loss = 11.5908  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 2.9183  Validation loss = 11.5907  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 2.9182  Validation loss = 11.5906  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 2.9181  Validation loss = 11.5905  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 2.9179  Validation loss = 11.5903  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 2.9178  Validation loss = 11.5902  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 2.9177  Validation loss = 11.5901  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 2.9175  Validation loss = 11.5899  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 2.9174  Validation loss = 11.5898  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 2.9173  Validation loss = 11.5897  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 2.9171  Validation loss = 11.5896  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 2.9170  Validation loss = 11.5895  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 2.9169  Validation loss = 11.5894  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 2.9167  Validation loss = 11.5893  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 2.9166  Validation loss = 11.5891  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 2.9164  Validation loss = 11.5890  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 2.9163  Validation loss = 11.5889  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 2.9162  Validation loss = 11.5888  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 2.9161  Validation loss = 11.5887  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 2.9160  Validation loss = 11.5886  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 2.9158  Validation loss = 11.5885  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 2.9157  Validation loss = 11.5884  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 2.9156  Validation loss = 11.5883  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 2.9154  Validation loss = 11.5882  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 2.9153  Validation loss = 11.5880  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 2.9152  Validation loss = 11.5879  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 2.9151  Validation loss = 11.5879  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 2.9150  Validation loss = 11.5878  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 2.9148  Validation loss = 11.5876  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 2.9147  Validation loss = 11.5875  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 2.9145  Validation loss = 11.5873  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 2.9144  Validation loss = 11.5872  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 2.9143  Validation loss = 11.5872  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 2.9142  Validation loss = 11.5870  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 2.9141  Validation loss = 11.5869  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 2.9139  Validation loss = 11.5868  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 2.9138  Validation loss = 11.5867  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 2.9137  Validation loss = 11.5866  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 2.9136  Validation loss = 11.5865  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 2.9135  Validation loss = 11.5864  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 2.9133  Validation loss = 11.5863  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 2.9132  Validation loss = 11.5861  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 2.9131  Validation loss = 11.5860  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 2.9129  Validation loss = 11.5859  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 2.9128  Validation loss = 11.5858  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 2.9127  Validation loss = 11.5857  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 2.9126  Validation loss = 11.5856  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 2.9124  Validation loss = 11.5855  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 2.9123  Validation loss = 11.5854  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 2.9122  Validation loss = 11.5853  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 2.9120  Validation loss = 11.5851  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 2.9119  Validation loss = 11.5850  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 2.9118  Validation loss = 11.5849  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 2.9116  Validation loss = 11.5848  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 2.9115  Validation loss = 11.5847  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 2.9114  Validation loss = 11.5846  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 2.9113  Validation loss = 11.5845  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 2.9111  Validation loss = 11.5844  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 2.9110  Validation loss = 11.5843  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 2.9109  Validation loss = 11.5842  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 2.9108  Validation loss = 11.5840  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 2.9106  Validation loss = 11.5839  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 2.9105  Validation loss = 11.5838  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 2.9104  Validation loss = 11.5837  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 2.9102  Validation loss = 11.5835  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 2.9101  Validation loss = 11.5834  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 2.9100  Validation loss = 11.5833  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 2.9099  Validation loss = 11.5832  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 2.9097  Validation loss = 11.5830  \n",
      "\n",
      "Fold: 9  Epoch: 501  Training loss = 2.9096  Validation loss = 11.5829  \n",
      "\n",
      "Fold: 9  Epoch: 502  Training loss = 2.9094  Validation loss = 11.5828  \n",
      "\n",
      "Fold: 9  Epoch: 503  Training loss = 2.9093  Validation loss = 11.5827  \n",
      "\n",
      "Fold: 9  Epoch: 504  Training loss = 2.9092  Validation loss = 11.5826  \n",
      "\n",
      "Fold: 9  Epoch: 505  Training loss = 2.9090  Validation loss = 11.5825  \n",
      "\n",
      "Fold: 9  Epoch: 506  Training loss = 2.9089  Validation loss = 11.5824  \n",
      "\n",
      "Fold: 9  Epoch: 507  Training loss = 2.9088  Validation loss = 11.5823  \n",
      "\n",
      "Fold: 9  Epoch: 508  Training loss = 2.9087  Validation loss = 11.5821  \n",
      "\n",
      "Fold: 9  Epoch: 509  Training loss = 2.9085  Validation loss = 11.5820  \n",
      "\n",
      "Fold: 9  Epoch: 510  Training loss = 2.9084  Validation loss = 11.5819  \n",
      "\n",
      "Fold: 9  Epoch: 511  Training loss = 2.9083  Validation loss = 11.5818  \n",
      "\n",
      "Fold: 9  Epoch: 512  Training loss = 2.9082  Validation loss = 11.5817  \n",
      "\n",
      "Fold: 9  Epoch: 513  Training loss = 2.9081  Validation loss = 11.5816  \n",
      "\n",
      "Fold: 9  Epoch: 514  Training loss = 2.9079  Validation loss = 11.5815  \n",
      "\n",
      "Fold: 9  Epoch: 515  Training loss = 2.9078  Validation loss = 11.5813  \n",
      "\n",
      "Fold: 9  Epoch: 516  Training loss = 2.9077  Validation loss = 11.5812  \n",
      "\n",
      "Fold: 9  Epoch: 517  Training loss = 2.9075  Validation loss = 11.5811  \n",
      "\n",
      "Fold: 9  Epoch: 518  Training loss = 2.9074  Validation loss = 11.5810  \n",
      "\n",
      "Fold: 9  Epoch: 519  Training loss = 2.9072  Validation loss = 11.5809  \n",
      "\n",
      "Fold: 9  Epoch: 520  Training loss = 2.9071  Validation loss = 11.5807  \n",
      "\n",
      "Fold: 9  Epoch: 521  Training loss = 2.9070  Validation loss = 11.5806  \n",
      "\n",
      "Fold: 9  Epoch: 522  Training loss = 2.9068  Validation loss = 11.5805  \n",
      "\n",
      "Fold: 9  Epoch: 523  Training loss = 2.9067  Validation loss = 11.5803  \n",
      "\n",
      "Fold: 9  Epoch: 524  Training loss = 2.9065  Validation loss = 11.5802  \n",
      "\n",
      "Fold: 9  Epoch: 525  Training loss = 2.9064  Validation loss = 11.5801  \n",
      "\n",
      "Fold: 9  Epoch: 526  Training loss = 2.9063  Validation loss = 11.5800  \n",
      "\n",
      "Fold: 9  Epoch: 527  Training loss = 2.9062  Validation loss = 11.5799  \n",
      "\n",
      "Fold: 9  Epoch: 528  Training loss = 2.9060  Validation loss = 11.5798  \n",
      "\n",
      "Fold: 9  Epoch: 529  Training loss = 2.9059  Validation loss = 11.5797  \n",
      "\n",
      "Fold: 9  Epoch: 530  Training loss = 2.9058  Validation loss = 11.5795  \n",
      "\n",
      "Fold: 9  Epoch: 531  Training loss = 2.9057  Validation loss = 11.5794  \n",
      "\n",
      "Fold: 9  Epoch: 532  Training loss = 2.9055  Validation loss = 11.5793  \n",
      "\n",
      "Fold: 9  Epoch: 533  Training loss = 2.9054  Validation loss = 11.5792  \n",
      "\n",
      "Fold: 9  Epoch: 534  Training loss = 2.9053  Validation loss = 11.5791  \n",
      "\n",
      "Fold: 9  Epoch: 535  Training loss = 2.9052  Validation loss = 11.5790  \n",
      "\n",
      "Fold: 9  Epoch: 536  Training loss = 2.9050  Validation loss = 11.5788  \n",
      "\n",
      "Fold: 9  Epoch: 537  Training loss = 2.9049  Validation loss = 11.5787  \n",
      "\n",
      "Fold: 9  Epoch: 538  Training loss = 2.9048  Validation loss = 11.5786  \n",
      "\n",
      "Fold: 9  Epoch: 539  Training loss = 2.9047  Validation loss = 11.5785  \n",
      "\n",
      "Fold: 9  Epoch: 540  Training loss = 2.9045  Validation loss = 11.5784  \n",
      "\n",
      "Fold: 9  Epoch: 541  Training loss = 2.9044  Validation loss = 11.5783  \n",
      "\n",
      "Fold: 9  Epoch: 542  Training loss = 2.9042  Validation loss = 11.5781  \n",
      "\n",
      "Fold: 9  Epoch: 543  Training loss = 2.9041  Validation loss = 11.5780  \n",
      "\n",
      "Fold: 9  Epoch: 544  Training loss = 2.9040  Validation loss = 11.5779  \n",
      "\n",
      "Fold: 9  Epoch: 545  Training loss = 2.9039  Validation loss = 11.5778  \n",
      "\n",
      "Fold: 9  Epoch: 546  Training loss = 2.9037  Validation loss = 11.5777  \n",
      "\n",
      "Fold: 9  Epoch: 547  Training loss = 2.9036  Validation loss = 11.5776  \n",
      "\n",
      "Fold: 9  Epoch: 548  Training loss = 2.9035  Validation loss = 11.5775  \n",
      "\n",
      "Fold: 9  Epoch: 549  Training loss = 2.9034  Validation loss = 11.5774  \n",
      "\n",
      "Fold: 9  Epoch: 550  Training loss = 2.9033  Validation loss = 11.5773  \n",
      "\n",
      "Fold: 9  Epoch: 551  Training loss = 2.9032  Validation loss = 11.5771  \n",
      "\n",
      "Fold: 9  Epoch: 552  Training loss = 2.9030  Validation loss = 11.5770  \n",
      "\n",
      "Fold: 9  Epoch: 553  Training loss = 2.9029  Validation loss = 11.5769  \n",
      "\n",
      "Fold: 9  Epoch: 554  Training loss = 2.9027  Validation loss = 11.5768  \n",
      "\n",
      "Fold: 9  Epoch: 555  Training loss = 2.9026  Validation loss = 11.5766  \n",
      "\n",
      "Fold: 9  Epoch: 556  Training loss = 2.9025  Validation loss = 11.5765  \n",
      "\n",
      "Fold: 9  Epoch: 557  Training loss = 2.9023  Validation loss = 11.5764  \n",
      "\n",
      "Fold: 9  Epoch: 558  Training loss = 2.9022  Validation loss = 11.5763  \n",
      "\n",
      "Fold: 9  Epoch: 559  Training loss = 2.9020  Validation loss = 11.5761  \n",
      "\n",
      "Fold: 9  Epoch: 560  Training loss = 2.9019  Validation loss = 11.5760  \n",
      "\n",
      "Fold: 9  Epoch: 561  Training loss = 2.9018  Validation loss = 11.5759  \n",
      "\n",
      "Fold: 9  Epoch: 562  Training loss = 2.9017  Validation loss = 11.5758  \n",
      "\n",
      "Fold: 9  Epoch: 563  Training loss = 2.9015  Validation loss = 11.5756  \n",
      "\n",
      "Fold: 9  Epoch: 564  Training loss = 2.9014  Validation loss = 11.5755  \n",
      "\n",
      "Fold: 9  Epoch: 565  Training loss = 2.9013  Validation loss = 11.5754  \n",
      "\n",
      "Fold: 9  Epoch: 566  Training loss = 2.9011  Validation loss = 11.5753  \n",
      "\n",
      "Fold: 9  Epoch: 567  Training loss = 2.9010  Validation loss = 11.5752  \n",
      "\n",
      "Fold: 9  Epoch: 568  Training loss = 2.9009  Validation loss = 11.5750  \n",
      "\n",
      "Fold: 9  Epoch: 569  Training loss = 2.9007  Validation loss = 11.5749  \n",
      "\n",
      "Fold: 9  Epoch: 570  Training loss = 2.9006  Validation loss = 11.5748  \n",
      "\n",
      "Fold: 9  Epoch: 571  Training loss = 2.9005  Validation loss = 11.5747  \n",
      "\n",
      "Fold: 9  Epoch: 572  Training loss = 2.9004  Validation loss = 11.5746  \n",
      "\n",
      "Fold: 9  Epoch: 573  Training loss = 2.9002  Validation loss = 11.5744  \n",
      "\n",
      "Fold: 9  Epoch: 574  Training loss = 2.9001  Validation loss = 11.5743  \n",
      "\n",
      "Fold: 9  Epoch: 575  Training loss = 2.9000  Validation loss = 11.5742  \n",
      "\n",
      "Fold: 9  Epoch: 576  Training loss = 2.8999  Validation loss = 11.5741  \n",
      "\n",
      "Fold: 9  Epoch: 577  Training loss = 2.8997  Validation loss = 11.5739  \n",
      "\n",
      "Fold: 9  Epoch: 578  Training loss = 2.8996  Validation loss = 11.5738  \n",
      "\n",
      "Fold: 9  Epoch: 579  Training loss = 2.8995  Validation loss = 11.5737  \n",
      "\n",
      "Fold: 9  Epoch: 580  Training loss = 2.8994  Validation loss = 11.5736  \n",
      "\n",
      "Fold: 9  Epoch: 581  Training loss = 2.8993  Validation loss = 11.5735  \n",
      "\n",
      "Fold: 9  Epoch: 582  Training loss = 2.8991  Validation loss = 11.5733  \n",
      "\n",
      "Fold: 9  Epoch: 583  Training loss = 2.8990  Validation loss = 11.5732  \n",
      "\n",
      "Fold: 9  Epoch: 584  Training loss = 2.8989  Validation loss = 11.5731  \n",
      "\n",
      "Fold: 9  Epoch: 585  Training loss = 2.8988  Validation loss = 11.5730  \n",
      "\n",
      "Fold: 9  Epoch: 586  Training loss = 2.8986  Validation loss = 11.5729  \n",
      "\n",
      "Fold: 9  Epoch: 587  Training loss = 2.8985  Validation loss = 11.5728  \n",
      "\n",
      "Fold: 9  Epoch: 588  Training loss = 2.8984  Validation loss = 11.5726  \n",
      "\n",
      "Fold: 9  Epoch: 589  Training loss = 2.8983  Validation loss = 11.5725  \n",
      "\n",
      "Fold: 9  Epoch: 590  Training loss = 2.8982  Validation loss = 11.5724  \n",
      "\n",
      "Fold: 9  Epoch: 591  Training loss = 2.8980  Validation loss = 11.5723  \n",
      "\n",
      "Fold: 9  Epoch: 592  Training loss = 2.8979  Validation loss = 11.5722  \n",
      "\n",
      "Fold: 9  Epoch: 593  Training loss = 2.8978  Validation loss = 11.5721  \n",
      "\n",
      "Fold: 9  Epoch: 594  Training loss = 2.8977  Validation loss = 11.5720  \n",
      "\n",
      "Fold: 9  Epoch: 595  Training loss = 2.8976  Validation loss = 11.5719  \n",
      "\n",
      "Fold: 9  Epoch: 596  Training loss = 2.8975  Validation loss = 11.5718  \n",
      "\n",
      "Fold: 9  Epoch: 597  Training loss = 2.8973  Validation loss = 11.5716  \n",
      "\n",
      "Fold: 9  Epoch: 598  Training loss = 2.8972  Validation loss = 11.5715  \n",
      "\n",
      "Fold: 9  Epoch: 599  Training loss = 2.8970  Validation loss = 11.5713  \n",
      "\n",
      "Fold: 9  Epoch: 600  Training loss = 2.8969  Validation loss = 11.5712  \n",
      "\n",
      "Fold: 9  Epoch: 601  Training loss = 2.8968  Validation loss = 11.5711  \n",
      "\n",
      "Fold: 9  Epoch: 602  Training loss = 2.8967  Validation loss = 11.5710  \n",
      "\n",
      "Fold: 9  Epoch: 603  Training loss = 2.8966  Validation loss = 11.5709  \n",
      "\n",
      "Fold: 9  Epoch: 604  Training loss = 2.8965  Validation loss = 11.5708  \n",
      "\n",
      "Fold: 9  Epoch: 605  Training loss = 2.8964  Validation loss = 11.5707  \n",
      "\n",
      "Fold: 9  Epoch: 606  Training loss = 2.8962  Validation loss = 11.5706  \n",
      "\n",
      "Fold: 9  Epoch: 607  Training loss = 2.8961  Validation loss = 11.5704  \n",
      "\n",
      "Fold: 9  Epoch: 608  Training loss = 2.8960  Validation loss = 11.5703  \n",
      "\n",
      "Fold: 9  Epoch: 609  Training loss = 2.8959  Validation loss = 11.5702  \n",
      "\n",
      "Fold: 9  Epoch: 610  Training loss = 2.8957  Validation loss = 11.5700  \n",
      "\n",
      "Fold: 9  Epoch: 611  Training loss = 2.8956  Validation loss = 11.5699  \n",
      "\n",
      "Fold: 9  Epoch: 612  Training loss = 2.8955  Validation loss = 11.5698  \n",
      "\n",
      "Fold: 9  Epoch: 613  Training loss = 2.8954  Validation loss = 11.5697  \n",
      "\n",
      "Fold: 9  Epoch: 614  Training loss = 2.8952  Validation loss = 11.5696  \n",
      "\n",
      "Fold: 9  Epoch: 615  Training loss = 2.8951  Validation loss = 11.5694  \n",
      "\n",
      "Fold: 9  Epoch: 616  Training loss = 2.8950  Validation loss = 11.5693  \n",
      "\n",
      "Fold: 9  Epoch: 617  Training loss = 2.8949  Validation loss = 11.5692  \n",
      "\n",
      "Fold: 9  Epoch: 618  Training loss = 2.8947  Validation loss = 11.5690  \n",
      "\n",
      "Fold: 9  Epoch: 619  Training loss = 2.8946  Validation loss = 11.5689  \n",
      "\n",
      "Fold: 9  Epoch: 620  Training loss = 2.8944  Validation loss = 11.5688  \n",
      "\n",
      "Fold: 9  Epoch: 621  Training loss = 2.8943  Validation loss = 11.5687  \n",
      "\n",
      "Fold: 9  Epoch: 622  Training loss = 2.8942  Validation loss = 11.5686  \n",
      "\n",
      "Fold: 9  Epoch: 623  Training loss = 2.8941  Validation loss = 11.5685  \n",
      "\n",
      "Fold: 9  Epoch: 624  Training loss = 2.8940  Validation loss = 11.5684  \n",
      "\n",
      "Fold: 9  Epoch: 625  Training loss = 2.8939  Validation loss = 11.5683  \n",
      "\n",
      "Fold: 9  Epoch: 626  Training loss = 2.8938  Validation loss = 11.5682  \n",
      "\n",
      "Fold: 9  Epoch: 627  Training loss = 2.8937  Validation loss = 11.5681  \n",
      "\n",
      "Fold: 9  Epoch: 628  Training loss = 2.8936  Validation loss = 11.5679  \n",
      "\n",
      "Fold: 9  Epoch: 629  Training loss = 2.8934  Validation loss = 11.5678  \n",
      "\n",
      "Fold: 9  Epoch: 630  Training loss = 2.8933  Validation loss = 11.5677  \n",
      "\n",
      "Fold: 9  Epoch: 631  Training loss = 2.8932  Validation loss = 11.5676  \n",
      "\n",
      "Fold: 9  Epoch: 632  Training loss = 2.8931  Validation loss = 11.5674  \n",
      "\n",
      "Fold: 9  Epoch: 633  Training loss = 2.8929  Validation loss = 11.5673  \n",
      "\n",
      "Fold: 9  Epoch: 634  Training loss = 2.8928  Validation loss = 11.5672  \n",
      "\n",
      "Fold: 9  Epoch: 635  Training loss = 2.8926  Validation loss = 11.5670  \n",
      "\n",
      "Fold: 9  Epoch: 636  Training loss = 2.8925  Validation loss = 11.5669  \n",
      "\n",
      "Fold: 9  Epoch: 637  Training loss = 2.8924  Validation loss = 11.5668  \n",
      "\n",
      "Fold: 9  Epoch: 638  Training loss = 2.8923  Validation loss = 11.5667  \n",
      "\n",
      "Fold: 9  Epoch: 639  Training loss = 2.8922  Validation loss = 11.5666  \n",
      "\n",
      "Fold: 9  Epoch: 640  Training loss = 2.8920  Validation loss = 11.5665  \n",
      "\n",
      "Fold: 9  Epoch: 641  Training loss = 2.8919  Validation loss = 11.5663  \n",
      "\n",
      "Fold: 9  Epoch: 642  Training loss = 2.8918  Validation loss = 11.5662  \n",
      "\n",
      "Fold: 9  Epoch: 643  Training loss = 2.8916  Validation loss = 11.5660  \n",
      "\n",
      "Fold: 9  Epoch: 644  Training loss = 2.8915  Validation loss = 11.5659  \n",
      "\n",
      "Fold: 9  Epoch: 645  Training loss = 2.8914  Validation loss = 11.5658  \n",
      "\n",
      "Fold: 9  Epoch: 646  Training loss = 2.8913  Validation loss = 11.5657  \n",
      "\n",
      "Fold: 9  Epoch: 647  Training loss = 2.8911  Validation loss = 11.5655  \n",
      "\n",
      "Fold: 9  Epoch: 648  Training loss = 2.8910  Validation loss = 11.5654  \n",
      "\n",
      "Fold: 9  Epoch: 649  Training loss = 2.8909  Validation loss = 11.5652  \n",
      "\n",
      "Fold: 9  Epoch: 650  Training loss = 2.8907  Validation loss = 11.5651  \n",
      "\n",
      "Fold: 9  Epoch: 651  Training loss = 2.8906  Validation loss = 11.5650  \n",
      "\n",
      "Fold: 9  Epoch: 652  Training loss = 2.8905  Validation loss = 11.5649  \n",
      "\n",
      "Fold: 9  Epoch: 653  Training loss = 2.8903  Validation loss = 11.5647  \n",
      "\n",
      "Fold: 9  Epoch: 654  Training loss = 2.8902  Validation loss = 11.5646  \n",
      "\n",
      "Fold: 9  Epoch: 655  Training loss = 2.8900  Validation loss = 11.5644  \n",
      "\n",
      "Fold: 9  Epoch: 656  Training loss = 2.8899  Validation loss = 11.5643  \n",
      "\n",
      "Fold: 9  Epoch: 657  Training loss = 2.8898  Validation loss = 11.5641  \n",
      "\n",
      "Fold: 9  Epoch: 658  Training loss = 2.8897  Validation loss = 11.5641  \n",
      "\n",
      "Fold: 9  Epoch: 659  Training loss = 2.8896  Validation loss = 11.5639  \n",
      "\n",
      "Fold: 9  Epoch: 660  Training loss = 2.8895  Validation loss = 11.5638  \n",
      "\n",
      "Fold: 9  Epoch: 661  Training loss = 2.8893  Validation loss = 11.5636  \n",
      "\n",
      "Fold: 9  Epoch: 662  Training loss = 2.8892  Validation loss = 11.5635  \n",
      "\n",
      "Fold: 9  Epoch: 663  Training loss = 2.8891  Validation loss = 11.5634  \n",
      "\n",
      "Fold: 9  Epoch: 664  Training loss = 2.8890  Validation loss = 11.5633  \n",
      "\n",
      "Fold: 9  Epoch: 665  Training loss = 2.8889  Validation loss = 11.5632  \n",
      "\n",
      "Fold: 9  Epoch: 666  Training loss = 2.8888  Validation loss = 11.5631  \n",
      "\n",
      "Fold: 9  Epoch: 667  Training loss = 2.8887  Validation loss = 11.5630  \n",
      "\n",
      "Fold: 9  Epoch: 668  Training loss = 2.8886  Validation loss = 11.5629  \n",
      "\n",
      "Fold: 9  Epoch: 669  Training loss = 2.8885  Validation loss = 11.5627  \n",
      "\n",
      "Fold: 9  Epoch: 670  Training loss = 2.8884  Validation loss = 11.5626  \n",
      "\n",
      "Fold: 9  Epoch: 671  Training loss = 2.8882  Validation loss = 11.5625  \n",
      "\n",
      "Fold: 9  Epoch: 672  Training loss = 2.8881  Validation loss = 11.5624  \n",
      "\n",
      "Fold: 9  Epoch: 673  Training loss = 2.8880  Validation loss = 11.5623  \n",
      "\n",
      "Fold: 9  Epoch: 674  Training loss = 2.8879  Validation loss = 11.5621  \n",
      "\n",
      "Fold: 9  Epoch: 675  Training loss = 2.8877  Validation loss = 11.5620  \n",
      "\n",
      "Fold: 9  Epoch: 676  Training loss = 2.8876  Validation loss = 11.5618  \n",
      "\n",
      "Fold: 9  Epoch: 677  Training loss = 2.8874  Validation loss = 11.5616  \n",
      "\n",
      "Fold: 9  Epoch: 678  Training loss = 2.8873  Validation loss = 11.5615  \n",
      "\n",
      "Fold: 9  Epoch: 679  Training loss = 2.8871  Validation loss = 11.5613  \n",
      "\n",
      "Fold: 9  Epoch: 680  Training loss = 2.8870  Validation loss = 11.5612  \n",
      "\n",
      "Fold: 9  Epoch: 681  Training loss = 2.8869  Validation loss = 11.5611  \n",
      "\n",
      "Fold: 9  Epoch: 682  Training loss = 2.8868  Validation loss = 11.5609  \n",
      "\n",
      "Fold: 9  Epoch: 683  Training loss = 2.8866  Validation loss = 11.5608  \n",
      "\n",
      "Fold: 9  Epoch: 684  Training loss = 2.8865  Validation loss = 11.5607  \n",
      "\n",
      "Fold: 9  Epoch: 685  Training loss = 2.8864  Validation loss = 11.5606  \n",
      "\n",
      "Fold: 9  Epoch: 686  Training loss = 2.8863  Validation loss = 11.5604  \n",
      "\n",
      "Fold: 9  Epoch: 687  Training loss = 2.8861  Validation loss = 11.5603  \n",
      "\n",
      "Fold: 9  Epoch: 688  Training loss = 2.8860  Validation loss = 11.5601  \n",
      "\n",
      "Fold: 9  Epoch: 689  Training loss = 2.8859  Validation loss = 11.5600  \n",
      "\n",
      "Fold: 9  Epoch: 690  Training loss = 2.8858  Validation loss = 11.5599  \n",
      "\n",
      "Fold: 9  Epoch: 691  Training loss = 2.8857  Validation loss = 11.5598  \n",
      "\n",
      "Fold: 9  Epoch: 692  Training loss = 2.8855  Validation loss = 11.5596  \n",
      "\n",
      "Fold: 9  Epoch: 693  Training loss = 2.8854  Validation loss = 11.5595  \n",
      "\n",
      "Fold: 9  Epoch: 694  Training loss = 2.8853  Validation loss = 11.5593  \n",
      "\n",
      "Fold: 9  Epoch: 695  Training loss = 2.8852  Validation loss = 11.5592  \n",
      "\n",
      "Fold: 9  Epoch: 696  Training loss = 2.8850  Validation loss = 11.5591  \n",
      "\n",
      "Fold: 9  Epoch: 697  Training loss = 2.8849  Validation loss = 11.5589  \n",
      "\n",
      "Fold: 9  Epoch: 698  Training loss = 2.8848  Validation loss = 11.5587  \n",
      "\n",
      "Fold: 9  Epoch: 699  Training loss = 2.8846  Validation loss = 11.5586  \n",
      "\n",
      "Fold: 9  Epoch: 700  Training loss = 2.8845  Validation loss = 11.5584  \n",
      "\n",
      "Fold: 9  Epoch: 701  Training loss = 2.8844  Validation loss = 11.5583  \n",
      "\n",
      "Fold: 9  Epoch: 702  Training loss = 2.8842  Validation loss = 11.5582  \n",
      "\n",
      "Fold: 9  Epoch: 703  Training loss = 2.8841  Validation loss = 11.5580  \n",
      "\n",
      "Fold: 9  Epoch: 704  Training loss = 2.8840  Validation loss = 11.5578  \n",
      "\n",
      "Fold: 9  Epoch: 705  Training loss = 2.8838  Validation loss = 11.5577  \n",
      "\n",
      "Fold: 9  Epoch: 706  Training loss = 2.8837  Validation loss = 11.5575  \n",
      "\n",
      "Fold: 9  Epoch: 707  Training loss = 2.8836  Validation loss = 11.5574  \n",
      "\n",
      "Fold: 9  Epoch: 708  Training loss = 2.8834  Validation loss = 11.5572  \n",
      "\n",
      "Fold: 9  Epoch: 709  Training loss = 2.8833  Validation loss = 11.5571  \n",
      "\n",
      "Fold: 9  Epoch: 710  Training loss = 2.8832  Validation loss = 11.5570  \n",
      "\n",
      "Fold: 9  Epoch: 711  Training loss = 2.8831  Validation loss = 11.5568  \n",
      "\n",
      "Fold: 9  Epoch: 712  Training loss = 2.8830  Validation loss = 11.5567  \n",
      "\n",
      "Fold: 9  Epoch: 713  Training loss = 2.8829  Validation loss = 11.5565  \n",
      "\n",
      "Fold: 9  Epoch: 714  Training loss = 2.8828  Validation loss = 11.5564  \n",
      "\n",
      "Fold: 9  Epoch: 715  Training loss = 2.8826  Validation loss = 11.5562  \n",
      "\n",
      "Fold: 9  Epoch: 716  Training loss = 2.8825  Validation loss = 11.5561  \n",
      "\n",
      "Fold: 9  Epoch: 717  Training loss = 2.8824  Validation loss = 11.5559  \n",
      "\n",
      "Fold: 9  Epoch: 718  Training loss = 2.8822  Validation loss = 11.5558  \n",
      "\n",
      "Fold: 9  Epoch: 719  Training loss = 2.8821  Validation loss = 11.5556  \n",
      "\n",
      "Fold: 9  Epoch: 720  Training loss = 2.8819  Validation loss = 11.5554  \n",
      "\n",
      "Fold: 9  Epoch: 721  Training loss = 2.8818  Validation loss = 11.5553  \n",
      "\n",
      "Fold: 9  Epoch: 722  Training loss = 2.8817  Validation loss = 11.5551  \n",
      "\n",
      "Fold: 9  Epoch: 723  Training loss = 2.8816  Validation loss = 11.5550  \n",
      "\n",
      "Fold: 9  Epoch: 724  Training loss = 2.8815  Validation loss = 11.5548  \n",
      "\n",
      "Fold: 9  Epoch: 725  Training loss = 2.8813  Validation loss = 11.5546  \n",
      "\n",
      "Fold: 9  Epoch: 726  Training loss = 2.8812  Validation loss = 11.5545  \n",
      "\n",
      "Fold: 9  Epoch: 727  Training loss = 2.8811  Validation loss = 11.5543  \n",
      "\n",
      "Fold: 9  Epoch: 728  Training loss = 2.8809  Validation loss = 11.5542  \n",
      "\n",
      "Fold: 9  Epoch: 729  Training loss = 2.8808  Validation loss = 11.5541  \n",
      "\n",
      "Fold: 9  Epoch: 730  Training loss = 2.8808  Validation loss = 11.5539  \n",
      "\n",
      "Fold: 9  Epoch: 731  Training loss = 2.8806  Validation loss = 11.5538  \n",
      "\n",
      "Fold: 9  Epoch: 732  Training loss = 2.8805  Validation loss = 11.5536  \n",
      "\n",
      "Fold: 9  Epoch: 733  Training loss = 2.8804  Validation loss = 11.5535  \n",
      "\n",
      "Fold: 9  Epoch: 734  Training loss = 2.8802  Validation loss = 11.5533  \n",
      "\n",
      "Fold: 9  Epoch: 735  Training loss = 2.8801  Validation loss = 11.5531  \n",
      "\n",
      "Fold: 9  Epoch: 736  Training loss = 2.8800  Validation loss = 11.5530  \n",
      "\n",
      "Fold: 9  Epoch: 737  Training loss = 2.8799  Validation loss = 11.5527  \n",
      "\n",
      "Fold: 9  Epoch: 738  Training loss = 2.8798  Validation loss = 11.5526  \n",
      "\n",
      "Fold: 9  Epoch: 739  Training loss = 2.8796  Validation loss = 11.5524  \n",
      "\n",
      "Fold: 9  Epoch: 740  Training loss = 2.8795  Validation loss = 11.5523  \n",
      "\n",
      "Fold: 9  Epoch: 741  Training loss = 2.8794  Validation loss = 11.5522  \n",
      "\n",
      "Fold: 9  Epoch: 742  Training loss = 2.8793  Validation loss = 11.5520  \n",
      "\n",
      "Fold: 9  Epoch: 743  Training loss = 2.8792  Validation loss = 11.5519  \n",
      "\n",
      "Fold: 9  Epoch: 744  Training loss = 2.8791  Validation loss = 11.5517  \n",
      "\n",
      "Fold: 9  Epoch: 745  Training loss = 2.8790  Validation loss = 11.5515  \n",
      "\n",
      "Fold: 9  Epoch: 746  Training loss = 2.8788  Validation loss = 11.5513  \n",
      "\n",
      "Fold: 9  Epoch: 747  Training loss = 2.8787  Validation loss = 11.5511  \n",
      "\n",
      "Fold: 9  Epoch: 748  Training loss = 2.8786  Validation loss = 11.5509  \n",
      "\n",
      "Fold: 9  Epoch: 749  Training loss = 2.8784  Validation loss = 11.5508  \n",
      "\n",
      "Fold: 9  Epoch: 750  Training loss = 2.8783  Validation loss = 11.5506  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 750  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 4.0042  Validation loss = 6.4292  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 4.0041  Validation loss = 6.4290  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 4.0040  Validation loss = 6.4289  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 4.0038  Validation loss = 6.4287  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 4.0037  Validation loss = 6.4285  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 4.0036  Validation loss = 6.4283  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 4.0034  Validation loss = 6.4280  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 4.0033  Validation loss = 6.4278  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 4.0031  Validation loss = 6.4276  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 4.0030  Validation loss = 6.4274  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 4.0029  Validation loss = 6.4272  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 4.0027  Validation loss = 6.4270  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 4.0026  Validation loss = 6.4268  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 4.0025  Validation loss = 6.4266  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 4.0023  Validation loss = 6.4264  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 4.0022  Validation loss = 6.4262  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 4.0021  Validation loss = 6.4261  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 4.0020  Validation loss = 6.4259  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 4.0019  Validation loss = 6.4257  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 4.0017  Validation loss = 6.4255  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 4.0016  Validation loss = 6.4253  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 4.0015  Validation loss = 6.4251  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 4.0014  Validation loss = 6.4249  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 4.0012  Validation loss = 6.4248  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 4.0011  Validation loss = 6.4245  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 4.0009  Validation loss = 6.4243  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 4.0008  Validation loss = 6.4242  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 4.0007  Validation loss = 6.4239  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 4.0005  Validation loss = 6.4237  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 4.0004  Validation loss = 6.4235  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 4.0003  Validation loss = 6.4234  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 4.0002  Validation loss = 6.4232  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 4.0001  Validation loss = 6.4230  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 3.9999  Validation loss = 6.4228  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 3.9998  Validation loss = 6.4226  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 3.9997  Validation loss = 6.4224  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 3.9995  Validation loss = 6.4222  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 3.9994  Validation loss = 6.4220  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 3.9992  Validation loss = 6.4218  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 3.9991  Validation loss = 6.4216  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 3.9990  Validation loss = 6.4214  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 3.9989  Validation loss = 6.4212  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 3.9987  Validation loss = 6.4210  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 3.9987  Validation loss = 6.4209  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 3.9985  Validation loss = 6.4207  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 3.9983  Validation loss = 6.4204  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 3.9982  Validation loss = 6.4202  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 3.9981  Validation loss = 6.4201  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 3.9980  Validation loss = 6.4199  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 3.9978  Validation loss = 6.4197  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 3.9977  Validation loss = 6.4194  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 3.9975  Validation loss = 6.4192  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 3.9974  Validation loss = 6.4190  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 3.9973  Validation loss = 6.4188  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 3.9972  Validation loss = 6.4187  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 3.9971  Validation loss = 6.4185  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 3.9970  Validation loss = 6.4183  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 3.9968  Validation loss = 6.4182  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 3.9967  Validation loss = 6.4180  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 3.9966  Validation loss = 6.4178  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 3.9965  Validation loss = 6.4176  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 3.9963  Validation loss = 6.4174  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 3.9962  Validation loss = 6.4171  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 3.9960  Validation loss = 6.4169  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 3.9959  Validation loss = 6.4168  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 3.9958  Validation loss = 6.4166  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 3.9956  Validation loss = 6.4163  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 3.9955  Validation loss = 6.4161  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 3.9954  Validation loss = 6.4159  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 3.9952  Validation loss = 6.4157  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 3.9951  Validation loss = 6.4155  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 3.9950  Validation loss = 6.4153  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 3.9948  Validation loss = 6.4151  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 3.9947  Validation loss = 6.4149  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 3.9945  Validation loss = 6.4146  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 3.9944  Validation loss = 6.4144  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 3.9943  Validation loss = 6.4142  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 3.9941  Validation loss = 6.4140  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 3.9940  Validation loss = 6.4138  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 3.9938  Validation loss = 6.4135  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 3.9937  Validation loss = 6.4133  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 3.9936  Validation loss = 6.4131  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 3.9934  Validation loss = 6.4130  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 3.9933  Validation loss = 6.4127  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 3.9932  Validation loss = 6.4126  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 3.9930  Validation loss = 6.4123  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 3.9929  Validation loss = 6.4121  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 3.9928  Validation loss = 6.4120  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 3.9926  Validation loss = 6.4118  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 3.9925  Validation loss = 6.4116  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 3.9924  Validation loss = 6.4113  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 3.9922  Validation loss = 6.4111  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 3.9921  Validation loss = 6.4109  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 3.9919  Validation loss = 6.4107  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 3.9918  Validation loss = 6.4105  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 3.9917  Validation loss = 6.4104  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 3.9916  Validation loss = 6.4102  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 3.9915  Validation loss = 6.4100  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 3.9914  Validation loss = 6.4098  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 3.9913  Validation loss = 6.4097  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 3.9911  Validation loss = 6.4094  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 3.9909  Validation loss = 6.4091  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 3.9908  Validation loss = 6.4089  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 3.9906  Validation loss = 6.4087  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 3.9905  Validation loss = 6.4085  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 3.9904  Validation loss = 6.4083  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 3.9903  Validation loss = 6.4082  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 3.9901  Validation loss = 6.4080  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 3.9900  Validation loss = 6.4078  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 3.9899  Validation loss = 6.4077  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 3.9898  Validation loss = 6.4075  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 3.9897  Validation loss = 6.4073  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 3.9896  Validation loss = 6.4071  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 3.9894  Validation loss = 6.4069  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 3.9893  Validation loss = 6.4066  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 3.9891  Validation loss = 6.4064  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 3.9890  Validation loss = 6.4063  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 3.9889  Validation loss = 6.4061  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 3.9888  Validation loss = 6.4059  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 3.9887  Validation loss = 6.4057  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 3.9886  Validation loss = 6.4056  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 3.9884  Validation loss = 6.4054  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 3.9883  Validation loss = 6.4053  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 3.9882  Validation loss = 6.4051  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 3.9881  Validation loss = 6.4048  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 3.9879  Validation loss = 6.4046  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 3.9878  Validation loss = 6.4044  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 3.9877  Validation loss = 6.4042  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 3.9875  Validation loss = 6.4040  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 3.9874  Validation loss = 6.4038  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 3.9873  Validation loss = 6.4037  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 3.9871  Validation loss = 6.4034  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 3.9870  Validation loss = 6.4032  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 3.9869  Validation loss = 6.4030  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 3.9868  Validation loss = 6.4029  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 3.9866  Validation loss = 6.4026  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 3.9865  Validation loss = 6.4024  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 3.9863  Validation loss = 6.4022  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 3.9862  Validation loss = 6.4021  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 3.9861  Validation loss = 6.4019  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 3.9860  Validation loss = 6.4017  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 3.9858  Validation loss = 6.4014  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 3.9857  Validation loss = 6.4012  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 3.9856  Validation loss = 6.4011  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 3.9854  Validation loss = 6.4009  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 3.9853  Validation loss = 6.4007  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 3.9851  Validation loss = 6.4005  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 3.9850  Validation loss = 6.4003  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 3.9849  Validation loss = 6.4001  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 3.9848  Validation loss = 6.3999  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 3.9847  Validation loss = 6.3998  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 3.9846  Validation loss = 6.3996  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 3.9844  Validation loss = 6.3993  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 3.9842  Validation loss = 6.3991  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 3.9841  Validation loss = 6.3989  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 3.9840  Validation loss = 6.3987  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 3.9838  Validation loss = 6.3985  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 3.9837  Validation loss = 6.3983  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 3.9836  Validation loss = 6.3981  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 3.9834  Validation loss = 6.3979  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 3.9833  Validation loss = 6.3977  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 3.9831  Validation loss = 6.3974  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 3.9830  Validation loss = 6.3972  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 3.9828  Validation loss = 6.3970  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 3.9827  Validation loss = 6.3968  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 3.9826  Validation loss = 6.3966  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 3.9824  Validation loss = 6.3964  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 3.9823  Validation loss = 6.3962  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 3.9822  Validation loss = 6.3960  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 3.9820  Validation loss = 6.3958  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 3.9819  Validation loss = 6.3956  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 3.9817  Validation loss = 6.3953  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 3.9816  Validation loss = 6.3952  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 3.9815  Validation loss = 6.3950  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 3.9814  Validation loss = 6.3948  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 3.9812  Validation loss = 6.3946  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 3.9811  Validation loss = 6.3945  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 3.9810  Validation loss = 6.3943  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 3.9809  Validation loss = 6.3940  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 3.9807  Validation loss = 6.3938  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 3.9805  Validation loss = 6.3935  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 3.9804  Validation loss = 6.3934  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 3.9803  Validation loss = 6.3932  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 3.9802  Validation loss = 6.3930  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 3.9801  Validation loss = 6.3929  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 3.9799  Validation loss = 6.3926  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 3.9797  Validation loss = 6.3923  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 3.9796  Validation loss = 6.3921  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 3.9795  Validation loss = 6.3919  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 3.9793  Validation loss = 6.3917  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 3.9792  Validation loss = 6.3915  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 3.9791  Validation loss = 6.3913  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 3.9789  Validation loss = 6.3910  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 3.9788  Validation loss = 6.3909  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 3.9787  Validation loss = 6.3907  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 3.9785  Validation loss = 6.3904  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 3.9784  Validation loss = 6.3903  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 3.9783  Validation loss = 6.3901  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 3.9782  Validation loss = 6.3899  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 3.9780  Validation loss = 6.3897  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 3.9779  Validation loss = 6.3895  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 3.9777  Validation loss = 6.3893  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 3.9776  Validation loss = 6.3891  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 3.9775  Validation loss = 6.3889  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 3.9774  Validation loss = 6.3887  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 3.9773  Validation loss = 6.3885  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 3.9771  Validation loss = 6.3883  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 3.9770  Validation loss = 6.3881  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 3.9768  Validation loss = 6.3879  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 3.9767  Validation loss = 6.3877  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 3.9766  Validation loss = 6.3875  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 3.9764  Validation loss = 6.3873  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 3.9763  Validation loss = 6.3872  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 3.9762  Validation loss = 6.3870  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 3.9761  Validation loss = 6.3868  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 3.9760  Validation loss = 6.3866  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 3.9758  Validation loss = 6.3864  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 3.9757  Validation loss = 6.3862  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 3.9756  Validation loss = 6.3861  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 3.9755  Validation loss = 6.3859  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 3.9754  Validation loss = 6.3857  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 3.9752  Validation loss = 6.3855  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 3.9751  Validation loss = 6.3854  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 3.9750  Validation loss = 6.3852  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 3.9748  Validation loss = 6.3850  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 3.9747  Validation loss = 6.3847  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 3.9746  Validation loss = 6.3846  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 3.9745  Validation loss = 6.3845  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 3.9744  Validation loss = 6.3843  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 3.9743  Validation loss = 6.3841  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 3.9742  Validation loss = 6.3840  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 3.9740  Validation loss = 6.3837  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 3.9739  Validation loss = 6.3835  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 3.9738  Validation loss = 6.3833  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 3.9736  Validation loss = 6.3831  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 3.9735  Validation loss = 6.3829  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 3.9733  Validation loss = 6.3826  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 3.9731  Validation loss = 6.3824  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 3.9730  Validation loss = 6.3822  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 3.9729  Validation loss = 6.3820  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 3.9727  Validation loss = 6.3818  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 3.9726  Validation loss = 6.3816  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 3.9724  Validation loss = 6.3814  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 3.9723  Validation loss = 6.3811  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 3.9722  Validation loss = 6.3809  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 3.9721  Validation loss = 6.3808  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 3.9719  Validation loss = 6.3806  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 3.9718  Validation loss = 6.3803  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 3.9716  Validation loss = 6.3800  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 3.9715  Validation loss = 6.3799  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 3.9714  Validation loss = 6.3797  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 3.9712  Validation loss = 6.3795  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 3.9711  Validation loss = 6.3793  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 3.9709  Validation loss = 6.3790  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 3.9708  Validation loss = 6.3788  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 3.9707  Validation loss = 6.3787  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 3.9706  Validation loss = 6.3784  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 3.9704  Validation loss = 6.3782  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 3.9702  Validation loss = 6.3779  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 3.9701  Validation loss = 6.3777  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 3.9699  Validation loss = 6.3775  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 3.9698  Validation loss = 6.3773  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 3.9696  Validation loss = 6.3771  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 3.9695  Validation loss = 6.3769  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 3.9694  Validation loss = 6.3767  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 3.9693  Validation loss = 6.3765  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 3.9691  Validation loss = 6.3762  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 3.9689  Validation loss = 6.3760  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 3.9688  Validation loss = 6.3758  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 3.9687  Validation loss = 6.3756  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 3.9685  Validation loss = 6.3753  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 3.9684  Validation loss = 6.3751  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 3.9683  Validation loss = 6.3750  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 3.9681  Validation loss = 6.3747  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 3.9679  Validation loss = 6.3745  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 3.9678  Validation loss = 6.3743  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 3.9677  Validation loss = 6.3741  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 3.9675  Validation loss = 6.3739  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 3.9674  Validation loss = 6.3737  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 3.9673  Validation loss = 6.3736  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 3.9672  Validation loss = 6.3734  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 3.9671  Validation loss = 6.3732  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 3.9669  Validation loss = 6.3729  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 3.9668  Validation loss = 6.3728  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 3.9666  Validation loss = 6.3725  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 3.9665  Validation loss = 6.3723  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 3.9663  Validation loss = 6.3721  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 3.9663  Validation loss = 6.3719  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 3.9661  Validation loss = 6.3718  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 3.9660  Validation loss = 6.3716  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 3.9659  Validation loss = 6.3714  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 3.9658  Validation loss = 6.3712  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 3.9656  Validation loss = 6.3710  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 3.9655  Validation loss = 6.3708  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 3.9653  Validation loss = 6.3705  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 3.9652  Validation loss = 6.3703  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 3.9650  Validation loss = 6.3701  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 3.9649  Validation loss = 6.3699  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 3.9647  Validation loss = 6.3697  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 3.9646  Validation loss = 6.3695  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 3.9645  Validation loss = 6.3693  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 3.9644  Validation loss = 6.3691  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 3.9642  Validation loss = 6.3689  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 3.9641  Validation loss = 6.3687  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 3.9640  Validation loss = 6.3685  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 3.9638  Validation loss = 6.3683  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 3.9637  Validation loss = 6.3681  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 3.9636  Validation loss = 6.3679  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 3.9635  Validation loss = 6.3677  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 3.9633  Validation loss = 6.3675  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 3.9632  Validation loss = 6.3673  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 3.9630  Validation loss = 6.3671  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 3.9629  Validation loss = 6.3669  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 3.9628  Validation loss = 6.3667  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 3.9627  Validation loss = 6.3665  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 3.9626  Validation loss = 6.3664  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 3.9624  Validation loss = 6.3662  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 3.9623  Validation loss = 6.3659  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 3.9621  Validation loss = 6.3657  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 3.9620  Validation loss = 6.3655  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 3.9619  Validation loss = 6.3653  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 3.9617  Validation loss = 6.3651  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 3.9616  Validation loss = 6.3649  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 3.9615  Validation loss = 6.3646  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 3.9613  Validation loss = 6.3644  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 3.9612  Validation loss = 6.3642  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 3.9611  Validation loss = 6.3641  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 3.9609  Validation loss = 6.3638  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 3.9608  Validation loss = 6.3636  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 3.9607  Validation loss = 6.3635  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 3.9605  Validation loss = 6.3633  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 3.9604  Validation loss = 6.3630  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 3.9602  Validation loss = 6.3628  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 3.9601  Validation loss = 6.3626  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 3.9600  Validation loss = 6.3624  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 3.9599  Validation loss = 6.3623  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 3.9598  Validation loss = 6.3621  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 3.9596  Validation loss = 6.3619  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 3.9595  Validation loss = 6.3617  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 3.9594  Validation loss = 6.3615  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 3.9593  Validation loss = 6.3613  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 3.9591  Validation loss = 6.3610  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 3.9590  Validation loss = 6.3608  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 3.9588  Validation loss = 6.3606  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 3.9587  Validation loss = 6.3604  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 3.9585  Validation loss = 6.3602  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 3.9585  Validation loss = 6.3601  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 3.9583  Validation loss = 6.3599  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 3.9582  Validation loss = 6.3597  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 3.9581  Validation loss = 6.3595  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 3.9580  Validation loss = 6.3594  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 3.9578  Validation loss = 6.3592  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 3.9577  Validation loss = 6.3590  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 3.9576  Validation loss = 6.3589  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 3.9575  Validation loss = 6.3586  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 3.9574  Validation loss = 6.3585  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 3.9572  Validation loss = 6.3583  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 3.9571  Validation loss = 6.3581  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 3.9570  Validation loss = 6.3578  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 3.9568  Validation loss = 6.3576  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 3.9567  Validation loss = 6.3574  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 3.9565  Validation loss = 6.3572  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 3.9564  Validation loss = 6.3569  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 3.9563  Validation loss = 6.3568  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 3.9561  Validation loss = 6.3565  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 3.9560  Validation loss = 6.3563  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 3.9559  Validation loss = 6.3561  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 3.9557  Validation loss = 6.3559  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 3.9556  Validation loss = 6.3557  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 3.9555  Validation loss = 6.3556  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 3.9554  Validation loss = 6.3553  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 3.9552  Validation loss = 6.3551  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 3.9551  Validation loss = 6.3549  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 3.9549  Validation loss = 6.3547  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 3.9548  Validation loss = 6.3545  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 3.9547  Validation loss = 6.3542  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 3.9545  Validation loss = 6.3541  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 3.9544  Validation loss = 6.3539  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 3.9543  Validation loss = 6.3537  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 3.9541  Validation loss = 6.3535  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 3.9540  Validation loss = 6.3533  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 3.9539  Validation loss = 6.3531  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 3.9538  Validation loss = 6.3529  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 3.9536  Validation loss = 6.3527  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 3.9535  Validation loss = 6.3525  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 3.9533  Validation loss = 6.3523  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 3.9532  Validation loss = 6.3521  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 3.9531  Validation loss = 6.3519  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 3.9530  Validation loss = 6.3517  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 3.9529  Validation loss = 6.3516  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 3.9527  Validation loss = 6.3514  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 3.9526  Validation loss = 6.3512  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 3.9525  Validation loss = 6.3511  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 3.9524  Validation loss = 6.3509  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 3.9523  Validation loss = 6.3507  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 3.9521  Validation loss = 6.3505  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 3.9520  Validation loss = 6.3503  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 3.9519  Validation loss = 6.3501  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 3.9517  Validation loss = 6.3499  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 3.9516  Validation loss = 6.3497  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 3.9515  Validation loss = 6.3495  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 3.9514  Validation loss = 6.3493  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 3.9513  Validation loss = 6.3491  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 3.9511  Validation loss = 6.3489  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 3.9510  Validation loss = 6.3488  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 3.9508  Validation loss = 6.3485  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 3.9507  Validation loss = 6.3483  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 3.9505  Validation loss = 6.3481  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 3.9504  Validation loss = 6.3479  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 3.9503  Validation loss = 6.3477  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 3.9502  Validation loss = 6.3476  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 3.9501  Validation loss = 6.3474  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 3.9499  Validation loss = 6.3472  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 3.9498  Validation loss = 6.3470  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 3.9497  Validation loss = 6.3468  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 3.9496  Validation loss = 6.3466  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 3.9494  Validation loss = 6.3463  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 3.9493  Validation loss = 6.3461  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 3.9491  Validation loss = 6.3459  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 3.9490  Validation loss = 6.3457  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 3.9489  Validation loss = 6.3455  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 3.9487  Validation loss = 6.3453  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 3.9486  Validation loss = 6.3450  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 3.9484  Validation loss = 6.3448  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 3.9483  Validation loss = 6.3447  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 3.9482  Validation loss = 6.3445  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 3.9481  Validation loss = 6.3443  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 3.9480  Validation loss = 6.3441  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 3.9478  Validation loss = 6.3439  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 3.9477  Validation loss = 6.3438  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 3.9476  Validation loss = 6.3435  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 3.9474  Validation loss = 6.3433  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 3.9473  Validation loss = 6.3431  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 3.9471  Validation loss = 6.3428  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 3.9470  Validation loss = 6.3426  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 3.9469  Validation loss = 6.3424  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 3.9468  Validation loss = 6.3423  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 3.9466  Validation loss = 6.3420  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 3.9465  Validation loss = 6.3418  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 3.9463  Validation loss = 6.3416  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 3.9462  Validation loss = 6.3414  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 3.9461  Validation loss = 6.3413  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 3.9460  Validation loss = 6.3411  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 3.9459  Validation loss = 6.3409  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 3.9458  Validation loss = 6.3408  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 3.9457  Validation loss = 6.3406  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 3.9455  Validation loss = 6.3404  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 3.9454  Validation loss = 6.3402  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 3.9452  Validation loss = 6.3400  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 3.9451  Validation loss = 6.3398  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 3.9450  Validation loss = 6.3396  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 3.9449  Validation loss = 6.3394  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 3.9448  Validation loss = 6.3392  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 3.9446  Validation loss = 6.3390  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 3.9445  Validation loss = 6.3388  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 3.9443  Validation loss = 6.3386  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 3.9442  Validation loss = 6.3383  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 3.9441  Validation loss = 6.3382  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 3.9439  Validation loss = 6.3379  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 3.9438  Validation loss = 6.3377  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 3.9437  Validation loss = 6.3376  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 3.9435  Validation loss = 6.3373  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 3.9434  Validation loss = 6.3372  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 3.9433  Validation loss = 6.3370  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 3.9431  Validation loss = 6.3368  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 3.9430  Validation loss = 6.3365  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 3.9429  Validation loss = 6.3364  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 3.9428  Validation loss = 6.3362  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 3.9427  Validation loss = 6.3360  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 3.9425  Validation loss = 6.3359  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 3.9424  Validation loss = 6.3356  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 3.9423  Validation loss = 6.3355  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 3.9421  Validation loss = 6.3352  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 3.9420  Validation loss = 6.3350  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 3.9418  Validation loss = 6.3348  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 3.9417  Validation loss = 6.3346  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 3.9416  Validation loss = 6.3344  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 3.9414  Validation loss = 6.3342  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 3.9413  Validation loss = 6.3340  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 3.9412  Validation loss = 6.3338  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 3.9410  Validation loss = 6.3336  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 3.9409  Validation loss = 6.3334  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 3.9407  Validation loss = 6.3331  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 3.9406  Validation loss = 6.3330  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 3.9405  Validation loss = 6.3327  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 3.9403  Validation loss = 6.3325  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 3.9402  Validation loss = 6.3323  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 3.9400  Validation loss = 6.3320  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 3.9398  Validation loss = 6.3318  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 3.9397  Validation loss = 6.3315  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 3.9395  Validation loss = 6.3313  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 3.9394  Validation loss = 6.3311  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 3.9393  Validation loss = 6.3309  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 3.9391  Validation loss = 6.3306  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 3.9390  Validation loss = 6.3304  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 3.9388  Validation loss = 6.3303  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 3.9387  Validation loss = 6.3301  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 3.9386  Validation loss = 6.3299  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 3.9385  Validation loss = 6.3297  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 3.9384  Validation loss = 6.3296  \n",
      "\n",
      "Fold: 10  Epoch: 501  Training loss = 3.9382  Validation loss = 6.3293  \n",
      "\n",
      "Fold: 10  Epoch: 502  Training loss = 3.9380  Validation loss = 6.3290  \n",
      "\n",
      "Fold: 10  Epoch: 503  Training loss = 3.9379  Validation loss = 6.3289  \n",
      "\n",
      "Fold: 10  Epoch: 504  Training loss = 3.9378  Validation loss = 6.3287  \n",
      "\n",
      "Fold: 10  Epoch: 505  Training loss = 3.9377  Validation loss = 6.3286  \n",
      "\n",
      "Fold: 10  Epoch: 506  Training loss = 3.9376  Validation loss = 6.3284  \n",
      "\n",
      "Fold: 10  Epoch: 507  Training loss = 3.9374  Validation loss = 6.3282  \n",
      "\n",
      "Fold: 10  Epoch: 508  Training loss = 3.9373  Validation loss = 6.3280  \n",
      "\n",
      "Fold: 10  Epoch: 509  Training loss = 3.9372  Validation loss = 6.3277  \n",
      "\n",
      "Fold: 10  Epoch: 510  Training loss = 3.9370  Validation loss = 6.3275  \n",
      "\n",
      "Fold: 10  Epoch: 511  Training loss = 3.9369  Validation loss = 6.3273  \n",
      "\n",
      "Fold: 10  Epoch: 512  Training loss = 3.9367  Validation loss = 6.3271  \n",
      "\n",
      "Fold: 10  Epoch: 513  Training loss = 3.9366  Validation loss = 6.3268  \n",
      "\n",
      "Fold: 10  Epoch: 514  Training loss = 3.9364  Validation loss = 6.3266  \n",
      "\n",
      "Fold: 10  Epoch: 515  Training loss = 3.9363  Validation loss = 6.3265  \n",
      "\n",
      "Fold: 10  Epoch: 516  Training loss = 3.9361  Validation loss = 6.3262  \n",
      "\n",
      "Fold: 10  Epoch: 517  Training loss = 3.9360  Validation loss = 6.3260  \n",
      "\n",
      "Fold: 10  Epoch: 518  Training loss = 3.9359  Validation loss = 6.3258  \n",
      "\n",
      "Fold: 10  Epoch: 519  Training loss = 3.9358  Validation loss = 6.3257  \n",
      "\n",
      "Fold: 10  Epoch: 520  Training loss = 3.9356  Validation loss = 6.3254  \n",
      "\n",
      "Fold: 10  Epoch: 521  Training loss = 3.9354  Validation loss = 6.3252  \n",
      "\n",
      "Fold: 10  Epoch: 522  Training loss = 3.9353  Validation loss = 6.3249  \n",
      "\n",
      "Fold: 10  Epoch: 523  Training loss = 3.9351  Validation loss = 6.3248  \n",
      "\n",
      "Fold: 10  Epoch: 524  Training loss = 3.9351  Validation loss = 6.3246  \n",
      "\n",
      "Fold: 10  Epoch: 525  Training loss = 3.9349  Validation loss = 6.3244  \n",
      "\n",
      "Fold: 10  Epoch: 526  Training loss = 3.9348  Validation loss = 6.3243  \n",
      "\n",
      "Fold: 10  Epoch: 527  Training loss = 3.9347  Validation loss = 6.3241  \n",
      "\n",
      "Fold: 10  Epoch: 528  Training loss = 3.9346  Validation loss = 6.3239  \n",
      "\n",
      "Fold: 10  Epoch: 529  Training loss = 3.9345  Validation loss = 6.3237  \n",
      "\n",
      "Fold: 10  Epoch: 530  Training loss = 3.9343  Validation loss = 6.3235  \n",
      "\n",
      "Fold: 10  Epoch: 531  Training loss = 3.9342  Validation loss = 6.3233  \n",
      "\n",
      "Fold: 10  Epoch: 532  Training loss = 3.9341  Validation loss = 6.3232  \n",
      "\n",
      "Fold: 10  Epoch: 533  Training loss = 3.9340  Validation loss = 6.3230  \n",
      "\n",
      "Fold: 10  Epoch: 534  Training loss = 3.9338  Validation loss = 6.3228  \n",
      "\n",
      "Fold: 10  Epoch: 535  Training loss = 3.9337  Validation loss = 6.3226  \n",
      "\n",
      "Fold: 10  Epoch: 536  Training loss = 3.9335  Validation loss = 6.3224  \n",
      "\n",
      "Fold: 10  Epoch: 537  Training loss = 3.9334  Validation loss = 6.3222  \n",
      "\n",
      "Fold: 10  Epoch: 538  Training loss = 3.9333  Validation loss = 6.3220  \n",
      "\n",
      "Fold: 10  Epoch: 539  Training loss = 3.9332  Validation loss = 6.3218  \n",
      "\n",
      "Fold: 10  Epoch: 540  Training loss = 3.9331  Validation loss = 6.3217  \n",
      "\n",
      "Fold: 10  Epoch: 541  Training loss = 3.9329  Validation loss = 6.3214  \n",
      "\n",
      "Fold: 10  Epoch: 542  Training loss = 3.9328  Validation loss = 6.3213  \n",
      "\n",
      "Fold: 10  Epoch: 543  Training loss = 3.9327  Validation loss = 6.3211  \n",
      "\n",
      "Fold: 10  Epoch: 544  Training loss = 3.9325  Validation loss = 6.3208  \n",
      "\n",
      "Fold: 10  Epoch: 545  Training loss = 3.9324  Validation loss = 6.3207  \n",
      "\n",
      "Fold: 10  Epoch: 546  Training loss = 3.9323  Validation loss = 6.3204  \n",
      "\n",
      "Fold: 10  Epoch: 547  Training loss = 3.9321  Validation loss = 6.3202  \n",
      "\n",
      "Fold: 10  Epoch: 548  Training loss = 3.9320  Validation loss = 6.3201  \n",
      "\n",
      "Fold: 10  Epoch: 549  Training loss = 3.9319  Validation loss = 6.3199  \n",
      "\n",
      "Fold: 10  Epoch: 550  Training loss = 3.9318  Validation loss = 6.3197  \n",
      "\n",
      "Fold: 10  Epoch: 551  Training loss = 3.9316  Validation loss = 6.3195  \n",
      "\n",
      "Fold: 10  Epoch: 552  Training loss = 3.9315  Validation loss = 6.3192  \n",
      "\n",
      "Fold: 10  Epoch: 553  Training loss = 3.9313  Validation loss = 6.3190  \n",
      "\n",
      "Fold: 10  Epoch: 554  Training loss = 3.9312  Validation loss = 6.3187  \n",
      "\n",
      "Fold: 10  Epoch: 555  Training loss = 3.9310  Validation loss = 6.3185  \n",
      "\n",
      "Fold: 10  Epoch: 556  Training loss = 3.9310  Validation loss = 6.3184  \n",
      "\n",
      "Fold: 10  Epoch: 557  Training loss = 3.9308  Validation loss = 6.3182  \n",
      "\n",
      "Fold: 10  Epoch: 558  Training loss = 3.9307  Validation loss = 6.3180  \n",
      "\n",
      "Fold: 10  Epoch: 559  Training loss = 3.9306  Validation loss = 6.3178  \n",
      "\n",
      "Fold: 10  Epoch: 560  Training loss = 3.9304  Validation loss = 6.3176  \n",
      "\n",
      "Fold: 10  Epoch: 561  Training loss = 3.9303  Validation loss = 6.3174  \n",
      "\n",
      "Fold: 10  Epoch: 562  Training loss = 3.9302  Validation loss = 6.3172  \n",
      "\n",
      "Fold: 10  Epoch: 563  Training loss = 3.9300  Validation loss = 6.3170  \n",
      "\n",
      "Fold: 10  Epoch: 564  Training loss = 3.9299  Validation loss = 6.3168  \n",
      "\n",
      "Fold: 10  Epoch: 565  Training loss = 3.9298  Validation loss = 6.3166  \n",
      "\n",
      "Fold: 10  Epoch: 566  Training loss = 3.9296  Validation loss = 6.3164  \n",
      "\n",
      "Fold: 10  Epoch: 567  Training loss = 3.9295  Validation loss = 6.3162  \n",
      "\n",
      "Fold: 10  Epoch: 568  Training loss = 3.9293  Validation loss = 6.3159  \n",
      "\n",
      "Fold: 10  Epoch: 569  Training loss = 3.9292  Validation loss = 6.3157  \n",
      "\n",
      "Fold: 10  Epoch: 570  Training loss = 3.9291  Validation loss = 6.3155  \n",
      "\n",
      "Fold: 10  Epoch: 571  Training loss = 3.9289  Validation loss = 6.3153  \n",
      "\n",
      "Fold: 10  Epoch: 572  Training loss = 3.9289  Validation loss = 6.3152  \n",
      "\n",
      "Fold: 10  Epoch: 573  Training loss = 3.9288  Validation loss = 6.3150  \n",
      "\n",
      "Fold: 10  Epoch: 574  Training loss = 3.9286  Validation loss = 6.3148  \n",
      "\n",
      "Fold: 10  Epoch: 575  Training loss = 3.9285  Validation loss = 6.3146  \n",
      "\n",
      "Fold: 10  Epoch: 576  Training loss = 3.9284  Validation loss = 6.3144  \n",
      "\n",
      "Fold: 10  Epoch: 577  Training loss = 3.9282  Validation loss = 6.3141  \n",
      "\n",
      "Fold: 10  Epoch: 578  Training loss = 3.9280  Validation loss = 6.3138  \n",
      "\n",
      "Fold: 10  Epoch: 579  Training loss = 3.9278  Validation loss = 6.3136  \n",
      "\n",
      "Fold: 10  Epoch: 580  Training loss = 3.9277  Validation loss = 6.3133  \n",
      "\n",
      "Fold: 10  Epoch: 581  Training loss = 3.9275  Validation loss = 6.3131  \n",
      "\n",
      "Fold: 10  Epoch: 582  Training loss = 3.9274  Validation loss = 6.3130  \n",
      "\n",
      "Fold: 10  Epoch: 583  Training loss = 3.9273  Validation loss = 6.3128  \n",
      "\n",
      "Fold: 10  Epoch: 584  Training loss = 3.9272  Validation loss = 6.3126  \n",
      "\n",
      "Fold: 10  Epoch: 585  Training loss = 3.9270  Validation loss = 6.3124  \n",
      "\n",
      "Fold: 10  Epoch: 586  Training loss = 3.9269  Validation loss = 6.3122  \n",
      "\n",
      "Fold: 10  Epoch: 587  Training loss = 3.9268  Validation loss = 6.3120  \n",
      "\n",
      "Fold: 10  Epoch: 588  Training loss = 3.9266  Validation loss = 6.3118  \n",
      "\n",
      "Fold: 10  Epoch: 589  Training loss = 3.9265  Validation loss = 6.3116  \n",
      "\n",
      "Fold: 10  Epoch: 590  Training loss = 3.9263  Validation loss = 6.3114  \n",
      "\n",
      "Fold: 10  Epoch: 591  Training loss = 3.9262  Validation loss = 6.3112  \n",
      "\n",
      "Fold: 10  Epoch: 592  Training loss = 3.9261  Validation loss = 6.3109  \n",
      "\n",
      "Fold: 10  Epoch: 593  Training loss = 3.9259  Validation loss = 6.3107  \n",
      "\n",
      "Fold: 10  Epoch: 594  Training loss = 3.9258  Validation loss = 6.3105  \n",
      "\n",
      "Fold: 10  Epoch: 595  Training loss = 3.9257  Validation loss = 6.3103  \n",
      "\n",
      "Fold: 10  Epoch: 596  Training loss = 3.9255  Validation loss = 6.3102  \n",
      "\n",
      "Fold: 10  Epoch: 597  Training loss = 3.9254  Validation loss = 6.3101  \n",
      "\n",
      "Fold: 10  Epoch: 598  Training loss = 3.9253  Validation loss = 6.3098  \n",
      "\n",
      "Fold: 10  Epoch: 599  Training loss = 3.9252  Validation loss = 6.3096  \n",
      "\n",
      "Fold: 10  Epoch: 600  Training loss = 3.9251  Validation loss = 6.3095  \n",
      "\n",
      "Fold: 10  Epoch: 601  Training loss = 3.9249  Validation loss = 6.3093  \n",
      "\n",
      "Fold: 10  Epoch: 602  Training loss = 3.9248  Validation loss = 6.3091  \n",
      "\n",
      "Fold: 10  Epoch: 603  Training loss = 3.9247  Validation loss = 6.3089  \n",
      "\n",
      "Fold: 10  Epoch: 604  Training loss = 3.9245  Validation loss = 6.3086  \n",
      "\n",
      "Fold: 10  Epoch: 605  Training loss = 3.9244  Validation loss = 6.3085  \n",
      "\n",
      "Fold: 10  Epoch: 606  Training loss = 3.9243  Validation loss = 6.3083  \n",
      "\n",
      "Fold: 10  Epoch: 607  Training loss = 3.9241  Validation loss = 6.3081  \n",
      "\n",
      "Fold: 10  Epoch: 608  Training loss = 3.9240  Validation loss = 6.3079  \n",
      "\n",
      "Fold: 10  Epoch: 609  Training loss = 3.9239  Validation loss = 6.3077  \n",
      "\n",
      "Fold: 10  Epoch: 610  Training loss = 3.9237  Validation loss = 6.3075  \n",
      "\n",
      "Fold: 10  Epoch: 611  Training loss = 3.9236  Validation loss = 6.3073  \n",
      "\n",
      "Fold: 10  Epoch: 612  Training loss = 3.9235  Validation loss = 6.3071  \n",
      "\n",
      "Fold: 10  Epoch: 613  Training loss = 3.9233  Validation loss = 6.3069  \n",
      "\n",
      "Fold: 10  Epoch: 614  Training loss = 3.9232  Validation loss = 6.3067  \n",
      "\n",
      "Fold: 10  Epoch: 615  Training loss = 3.9230  Validation loss = 6.3065  \n",
      "\n",
      "Fold: 10  Epoch: 616  Training loss = 3.9229  Validation loss = 6.3062  \n",
      "\n",
      "Fold: 10  Epoch: 617  Training loss = 3.9227  Validation loss = 6.3060  \n",
      "\n",
      "Fold: 10  Epoch: 618  Training loss = 3.9226  Validation loss = 6.3058  \n",
      "\n",
      "Fold: 10  Epoch: 619  Training loss = 3.9225  Validation loss = 6.3056  \n",
      "\n",
      "Fold: 10  Epoch: 620  Training loss = 3.9223  Validation loss = 6.3054  \n",
      "\n",
      "Fold: 10  Epoch: 621  Training loss = 3.9222  Validation loss = 6.3052  \n",
      "\n",
      "Fold: 10  Epoch: 622  Training loss = 3.9221  Validation loss = 6.3050  \n",
      "\n",
      "Fold: 10  Epoch: 623  Training loss = 3.9219  Validation loss = 6.3048  \n",
      "\n",
      "Fold: 10  Epoch: 624  Training loss = 3.9218  Validation loss = 6.3046  \n",
      "\n",
      "Fold: 10  Epoch: 625  Training loss = 3.9217  Validation loss = 6.3044  \n",
      "\n",
      "Fold: 10  Epoch: 626  Training loss = 3.9215  Validation loss = 6.3042  \n",
      "\n",
      "Fold: 10  Epoch: 627  Training loss = 3.9214  Validation loss = 6.3040  \n",
      "\n",
      "Fold: 10  Epoch: 628  Training loss = 3.9212  Validation loss = 6.3037  \n",
      "\n",
      "Fold: 10  Epoch: 629  Training loss = 3.9211  Validation loss = 6.3036  \n",
      "\n",
      "Fold: 10  Epoch: 630  Training loss = 3.9209  Validation loss = 6.3033  \n",
      "\n",
      "Fold: 10  Epoch: 631  Training loss = 3.9208  Validation loss = 6.3031  \n",
      "\n",
      "Fold: 10  Epoch: 632  Training loss = 3.9207  Validation loss = 6.3029  \n",
      "\n",
      "Fold: 10  Epoch: 633  Training loss = 3.9205  Validation loss = 6.3027  \n",
      "\n",
      "Fold: 10  Epoch: 634  Training loss = 3.9204  Validation loss = 6.3024  \n",
      "\n",
      "Fold: 10  Epoch: 635  Training loss = 3.9202  Validation loss = 6.3022  \n",
      "\n",
      "Fold: 10  Epoch: 636  Training loss = 3.9201  Validation loss = 6.3020  \n",
      "\n",
      "Fold: 10  Epoch: 637  Training loss = 3.9199  Validation loss = 6.3018  \n",
      "\n",
      "Fold: 10  Epoch: 638  Training loss = 3.9198  Validation loss = 6.3015  \n",
      "\n",
      "Fold: 10  Epoch: 639  Training loss = 3.9197  Validation loss = 6.3013  \n",
      "\n",
      "Fold: 10  Epoch: 640  Training loss = 3.9195  Validation loss = 6.3012  \n",
      "\n",
      "Fold: 10  Epoch: 641  Training loss = 3.9194  Validation loss = 6.3010  \n",
      "\n",
      "Fold: 10  Epoch: 642  Training loss = 3.9192  Validation loss = 6.3007  \n",
      "\n",
      "Fold: 10  Epoch: 643  Training loss = 3.9191  Validation loss = 6.3006  \n",
      "\n",
      "Fold: 10  Epoch: 644  Training loss = 3.9190  Validation loss = 6.3004  \n",
      "\n",
      "Fold: 10  Epoch: 645  Training loss = 3.9189  Validation loss = 6.3002  \n",
      "\n",
      "Fold: 10  Epoch: 646  Training loss = 3.9188  Validation loss = 6.3001  \n",
      "\n",
      "Fold: 10  Epoch: 647  Training loss = 3.9186  Validation loss = 6.2998  \n",
      "\n",
      "Fold: 10  Epoch: 648  Training loss = 3.9185  Validation loss = 6.2996  \n",
      "\n",
      "Fold: 10  Epoch: 649  Training loss = 3.9183  Validation loss = 6.2993  \n",
      "\n",
      "Fold: 10  Epoch: 650  Training loss = 3.9182  Validation loss = 6.2992  \n",
      "\n",
      "Fold: 10  Epoch: 651  Training loss = 3.9181  Validation loss = 6.2990  \n",
      "\n",
      "Fold: 10  Epoch: 652  Training loss = 3.9179  Validation loss = 6.2988  \n",
      "\n",
      "Fold: 10  Epoch: 653  Training loss = 3.9178  Validation loss = 6.2986  \n",
      "\n",
      "Fold: 10  Epoch: 654  Training loss = 3.9177  Validation loss = 6.2984  \n",
      "\n",
      "Fold: 10  Epoch: 655  Training loss = 3.9176  Validation loss = 6.2983  \n",
      "\n",
      "Fold: 10  Epoch: 656  Training loss = 3.9175  Validation loss = 6.2981  \n",
      "\n",
      "Fold: 10  Epoch: 657  Training loss = 3.9173  Validation loss = 6.2979  \n",
      "\n",
      "Fold: 10  Epoch: 658  Training loss = 3.9172  Validation loss = 6.2977  \n",
      "\n",
      "Fold: 10  Epoch: 659  Training loss = 3.9171  Validation loss = 6.2975  \n",
      "\n",
      "Fold: 10  Epoch: 660  Training loss = 3.9169  Validation loss = 6.2973  \n",
      "\n",
      "Fold: 10  Epoch: 661  Training loss = 3.9168  Validation loss = 6.2971  \n",
      "\n",
      "Fold: 10  Epoch: 662  Training loss = 3.9166  Validation loss = 6.2969  \n",
      "\n",
      "Fold: 10  Epoch: 663  Training loss = 3.9165  Validation loss = 6.2967  \n",
      "\n",
      "Fold: 10  Epoch: 664  Training loss = 3.9164  Validation loss = 6.2965  \n",
      "\n",
      "Fold: 10  Epoch: 665  Training loss = 3.9162  Validation loss = 6.2963  \n",
      "\n",
      "Fold: 10  Epoch: 666  Training loss = 3.9161  Validation loss = 6.2961  \n",
      "\n",
      "Fold: 10  Epoch: 667  Training loss = 3.9159  Validation loss = 6.2958  \n",
      "\n",
      "Fold: 10  Epoch: 668  Training loss = 3.9158  Validation loss = 6.2956  \n",
      "\n",
      "Fold: 10  Epoch: 669  Training loss = 3.9156  Validation loss = 6.2954  \n",
      "\n",
      "Fold: 10  Epoch: 670  Training loss = 3.9155  Validation loss = 6.2951  \n",
      "\n",
      "Fold: 10  Epoch: 671  Training loss = 3.9153  Validation loss = 6.2949  \n",
      "\n",
      "Fold: 10  Epoch: 672  Training loss = 3.9152  Validation loss = 6.2947  \n",
      "\n",
      "Fold: 10  Epoch: 673  Training loss = 3.9151  Validation loss = 6.2946  \n",
      "\n",
      "Fold: 10  Epoch: 674  Training loss = 3.9150  Validation loss = 6.2943  \n",
      "\n",
      "Fold: 10  Epoch: 675  Training loss = 3.9148  Validation loss = 6.2942  \n",
      "\n",
      "Fold: 10  Epoch: 676  Training loss = 3.9147  Validation loss = 6.2940  \n",
      "\n",
      "Fold: 10  Epoch: 677  Training loss = 3.9146  Validation loss = 6.2937  \n",
      "\n",
      "Fold: 10  Epoch: 678  Training loss = 3.9144  Validation loss = 6.2935  \n",
      "\n",
      "Fold: 10  Epoch: 679  Training loss = 3.9143  Validation loss = 6.2933  \n",
      "\n",
      "Fold: 10  Epoch: 680  Training loss = 3.9142  Validation loss = 6.2931  \n",
      "\n",
      "Fold: 10  Epoch: 681  Training loss = 3.9140  Validation loss = 6.2929  \n",
      "\n",
      "Fold: 10  Epoch: 682  Training loss = 3.9139  Validation loss = 6.2927  \n",
      "\n",
      "Fold: 10  Epoch: 683  Training loss = 3.9137  Validation loss = 6.2925  \n",
      "\n",
      "Fold: 10  Epoch: 684  Training loss = 3.9136  Validation loss = 6.2922  \n",
      "\n",
      "Fold: 10  Epoch: 685  Training loss = 3.9134  Validation loss = 6.2920  \n",
      "\n",
      "Fold: 10  Epoch: 686  Training loss = 3.9133  Validation loss = 6.2918  \n",
      "\n",
      "Fold: 10  Epoch: 687  Training loss = 3.9131  Validation loss = 6.2915  \n",
      "\n",
      "Fold: 10  Epoch: 688  Training loss = 3.9130  Validation loss = 6.2913  \n",
      "\n",
      "Fold: 10  Epoch: 689  Training loss = 3.9129  Validation loss = 6.2912  \n",
      "\n",
      "Fold: 10  Epoch: 690  Training loss = 3.9127  Validation loss = 6.2909  \n",
      "\n",
      "Fold: 10  Epoch: 691  Training loss = 3.9126  Validation loss = 6.2907  \n",
      "\n",
      "Fold: 10  Epoch: 692  Training loss = 3.9125  Validation loss = 6.2906  \n",
      "\n",
      "Fold: 10  Epoch: 693  Training loss = 3.9123  Validation loss = 6.2903  \n",
      "\n",
      "Fold: 10  Epoch: 694  Training loss = 3.9122  Validation loss = 6.2901  \n",
      "\n",
      "Fold: 10  Epoch: 695  Training loss = 3.9120  Validation loss = 6.2899  \n",
      "\n",
      "Fold: 10  Epoch: 696  Training loss = 3.9119  Validation loss = 6.2897  \n",
      "\n",
      "Fold: 10  Epoch: 697  Training loss = 3.9118  Validation loss = 6.2895  \n",
      "\n",
      "Fold: 10  Epoch: 698  Training loss = 3.9116  Validation loss = 6.2893  \n",
      "\n",
      "Fold: 10  Epoch: 699  Training loss = 3.9115  Validation loss = 6.2891  \n",
      "\n",
      "Fold: 10  Epoch: 700  Training loss = 3.9113  Validation loss = 6.2889  \n",
      "\n",
      "Fold: 10  Epoch: 701  Training loss = 3.9112  Validation loss = 6.2887  \n",
      "\n",
      "Fold: 10  Epoch: 702  Training loss = 3.9111  Validation loss = 6.2885  \n",
      "\n",
      "Fold: 10  Epoch: 703  Training loss = 3.9109  Validation loss = 6.2883  \n",
      "\n",
      "Fold: 10  Epoch: 704  Training loss = 3.9108  Validation loss = 6.2881  \n",
      "\n",
      "Fold: 10  Epoch: 705  Training loss = 3.9106  Validation loss = 6.2879  \n",
      "\n",
      "Fold: 10  Epoch: 706  Training loss = 3.9105  Validation loss = 6.2877  \n",
      "\n",
      "Fold: 10  Epoch: 707  Training loss = 3.9103  Validation loss = 6.2874  \n",
      "\n",
      "Fold: 10  Epoch: 708  Training loss = 3.9102  Validation loss = 6.2873  \n",
      "\n",
      "Fold: 10  Epoch: 709  Training loss = 3.9101  Validation loss = 6.2871  \n",
      "\n",
      "Fold: 10  Epoch: 710  Training loss = 3.9100  Validation loss = 6.2869  \n",
      "\n",
      "Fold: 10  Epoch: 711  Training loss = 3.9098  Validation loss = 6.2867  \n",
      "\n",
      "Fold: 10  Epoch: 712  Training loss = 3.9097  Validation loss = 6.2865  \n",
      "\n",
      "Fold: 10  Epoch: 713  Training loss = 3.9096  Validation loss = 6.2863  \n",
      "\n",
      "Fold: 10  Epoch: 714  Training loss = 3.9095  Validation loss = 6.2861  \n",
      "\n",
      "Fold: 10  Epoch: 715  Training loss = 3.9093  Validation loss = 6.2859  \n",
      "\n",
      "Fold: 10  Epoch: 716  Training loss = 3.9092  Validation loss = 6.2857  \n",
      "\n",
      "Fold: 10  Epoch: 717  Training loss = 3.9091  Validation loss = 6.2856  \n",
      "\n",
      "Fold: 10  Epoch: 718  Training loss = 3.9090  Validation loss = 6.2854  \n",
      "\n",
      "Fold: 10  Epoch: 719  Training loss = 3.9088  Validation loss = 6.2852  \n",
      "\n",
      "Fold: 10  Epoch: 720  Training loss = 3.9087  Validation loss = 6.2851  \n",
      "\n",
      "Fold: 10  Epoch: 721  Training loss = 3.9086  Validation loss = 6.2849  \n",
      "\n",
      "Fold: 10  Epoch: 722  Training loss = 3.9085  Validation loss = 6.2847  \n",
      "\n",
      "Fold: 10  Epoch: 723  Training loss = 3.9083  Validation loss = 6.2845  \n",
      "\n",
      "Fold: 10  Epoch: 724  Training loss = 3.9082  Validation loss = 6.2843  \n",
      "\n",
      "Fold: 10  Epoch: 725  Training loss = 3.9080  Validation loss = 6.2841  \n",
      "\n",
      "Fold: 10  Epoch: 726  Training loss = 3.9079  Validation loss = 6.2839  \n",
      "\n",
      "Fold: 10  Epoch: 727  Training loss = 3.9078  Validation loss = 6.2838  \n",
      "\n",
      "Fold: 10  Epoch: 728  Training loss = 3.9077  Validation loss = 6.2835  \n",
      "\n",
      "Fold: 10  Epoch: 729  Training loss = 3.9075  Validation loss = 6.2833  \n",
      "\n",
      "Fold: 10  Epoch: 730  Training loss = 3.9074  Validation loss = 6.2831  \n",
      "\n",
      "Fold: 10  Epoch: 731  Training loss = 3.9072  Validation loss = 6.2829  \n",
      "\n",
      "Fold: 10  Epoch: 732  Training loss = 3.9071  Validation loss = 6.2827  \n",
      "\n",
      "Fold: 10  Epoch: 733  Training loss = 3.9069  Validation loss = 6.2825  \n",
      "\n",
      "Fold: 10  Epoch: 734  Training loss = 3.9068  Validation loss = 6.2823  \n",
      "\n",
      "Fold: 10  Epoch: 735  Training loss = 3.9067  Validation loss = 6.2821  \n",
      "\n",
      "Fold: 10  Epoch: 736  Training loss = 3.9066  Validation loss = 6.2819  \n",
      "\n",
      "Fold: 10  Epoch: 737  Training loss = 3.9064  Validation loss = 6.2817  \n",
      "\n",
      "Fold: 10  Epoch: 738  Training loss = 3.9063  Validation loss = 6.2815  \n",
      "\n",
      "Fold: 10  Epoch: 739  Training loss = 3.9061  Validation loss = 6.2812  \n",
      "\n",
      "Fold: 10  Epoch: 740  Training loss = 3.9060  Validation loss = 6.2810  \n",
      "\n",
      "Fold: 10  Epoch: 741  Training loss = 3.9058  Validation loss = 6.2808  \n",
      "\n",
      "Fold: 10  Epoch: 742  Training loss = 3.9057  Validation loss = 6.2806  \n",
      "\n",
      "Fold: 10  Epoch: 743  Training loss = 3.9055  Validation loss = 6.2803  \n",
      "\n",
      "Fold: 10  Epoch: 744  Training loss = 3.9054  Validation loss = 6.2801  \n",
      "\n",
      "Fold: 10  Epoch: 745  Training loss = 3.9052  Validation loss = 6.2799  \n",
      "\n",
      "Fold: 10  Epoch: 746  Training loss = 3.9051  Validation loss = 6.2797  \n",
      "\n",
      "Fold: 10  Epoch: 747  Training loss = 3.9050  Validation loss = 6.2796  \n",
      "\n",
      "Fold: 10  Epoch: 748  Training loss = 3.9049  Validation loss = 6.2794  \n",
      "\n",
      "Fold: 10  Epoch: 749  Training loss = 3.9047  Validation loss = 6.2792  \n",
      "\n",
      "Fold: 10  Epoch: 750  Training loss = 3.9046  Validation loss = 6.2790  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 750  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 4.1950  Validation loss = 3.7850  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 4.1948  Validation loss = 3.7846  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 4.1946  Validation loss = 3.7843  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 4.1944  Validation loss = 3.7840  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 4.1942  Validation loss = 3.7836  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 4.1941  Validation loss = 3.7833  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 4.1939  Validation loss = 3.7830  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 4.1937  Validation loss = 3.7827  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 4.1936  Validation loss = 3.7824  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 4.1934  Validation loss = 3.7821  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 4.1932  Validation loss = 3.7818  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 4.1931  Validation loss = 3.7815  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 4.1929  Validation loss = 3.7811  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 4.1927  Validation loss = 3.7809  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 4.1926  Validation loss = 3.7805  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 4.1924  Validation loss = 3.7802  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 4.1922  Validation loss = 3.7799  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 4.1920  Validation loss = 3.7796  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 4.1918  Validation loss = 3.7792  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 4.1916  Validation loss = 3.7788  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 4.1914  Validation loss = 3.7784  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 4.1912  Validation loss = 3.7780  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 4.1911  Validation loss = 3.7778  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 4.1909  Validation loss = 3.7774  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 4.1908  Validation loss = 3.7772  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 4.1906  Validation loss = 3.7769  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 4.1905  Validation loss = 3.7766  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 4.1903  Validation loss = 3.7763  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 4.1901  Validation loss = 3.7760  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 4.1899  Validation loss = 3.7756  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 4.1898  Validation loss = 3.7753  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 4.1896  Validation loss = 3.7751  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 4.1894  Validation loss = 3.7747  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 4.1893  Validation loss = 3.7745  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 4.1892  Validation loss = 3.7743  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 4.1890  Validation loss = 3.7739  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 4.1889  Validation loss = 3.7738  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 4.1887  Validation loss = 3.7735  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 4.1886  Validation loss = 3.7732  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 4.1884  Validation loss = 3.7729  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 4.1882  Validation loss = 3.7725  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 4.1881  Validation loss = 3.7723  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 4.1878  Validation loss = 3.7718  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 4.1876  Validation loss = 3.7714  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 4.1875  Validation loss = 3.7711  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 4.1873  Validation loss = 3.7708  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 4.1871  Validation loss = 3.7704  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 4.1869  Validation loss = 3.7701  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 4.1867  Validation loss = 3.7698  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 4.1865  Validation loss = 3.7694  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 4.1863  Validation loss = 3.7691  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 4.1862  Validation loss = 3.7688  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 4.1860  Validation loss = 3.7686  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 4.1858  Validation loss = 3.7682  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 4.1857  Validation loss = 3.7679  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 4.1854  Validation loss = 3.7676  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 4.1853  Validation loss = 3.7673  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 4.1852  Validation loss = 3.7671  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 4.1849  Validation loss = 3.7667  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 4.1848  Validation loss = 3.7663  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 4.1846  Validation loss = 3.7659  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 4.1844  Validation loss = 3.7657  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 4.1842  Validation loss = 3.7654  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 4.1840  Validation loss = 3.7650  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 4.1839  Validation loss = 3.7648  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 4.1837  Validation loss = 3.7645  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 4.1836  Validation loss = 3.7642  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 4.1834  Validation loss = 3.7638  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 4.1832  Validation loss = 3.7635  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 4.1831  Validation loss = 3.7633  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 4.1828  Validation loss = 3.7629  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 4.1827  Validation loss = 3.7627  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 4.1825  Validation loss = 3.7624  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 4.1824  Validation loss = 3.7621  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 4.1822  Validation loss = 3.7619  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 4.1821  Validation loss = 3.7616  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 4.1819  Validation loss = 3.7613  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 4.1817  Validation loss = 3.7609  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 4.1816  Validation loss = 3.7607  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 4.1814  Validation loss = 3.7603  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 4.1812  Validation loss = 3.7600  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 4.1811  Validation loss = 3.7598  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 4.1809  Validation loss = 3.7595  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 4.1807  Validation loss = 3.7591  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 4.1805  Validation loss = 3.7588  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 4.1804  Validation loss = 3.7586  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 4.1802  Validation loss = 3.7583  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 4.1801  Validation loss = 3.7581  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 4.1799  Validation loss = 3.7578  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 4.1797  Validation loss = 3.7574  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 4.1796  Validation loss = 3.7572  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 4.1794  Validation loss = 3.7569  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 4.1793  Validation loss = 3.7567  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 4.1792  Validation loss = 3.7565  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 4.1789  Validation loss = 3.7561  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 4.1787  Validation loss = 3.7557  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 4.1785  Validation loss = 3.7553  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 4.1783  Validation loss = 3.7550  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 4.1782  Validation loss = 3.7548  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 4.1780  Validation loss = 3.7544  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 4.1778  Validation loss = 3.7542  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 4.1777  Validation loss = 3.7539  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 4.1775  Validation loss = 3.7536  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 4.1773  Validation loss = 3.7532  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 4.1771  Validation loss = 3.7529  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 4.1769  Validation loss = 3.7525  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 4.1768  Validation loss = 3.7523  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 4.1766  Validation loss = 3.7520  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 4.1764  Validation loss = 3.7517  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 4.1763  Validation loss = 3.7514  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 4.1761  Validation loss = 3.7512  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 4.1759  Validation loss = 3.7508  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 4.1758  Validation loss = 3.7505  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 4.1756  Validation loss = 3.7503  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 4.1755  Validation loss = 3.7500  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 4.1753  Validation loss = 3.7497  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 4.1752  Validation loss = 3.7495  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 4.1750  Validation loss = 3.7492  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 4.1748  Validation loss = 3.7489  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 4.1746  Validation loss = 3.7485  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 4.1745  Validation loss = 3.7482  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 4.1743  Validation loss = 3.7480  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 4.1741  Validation loss = 3.7477  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 4.1740  Validation loss = 3.7474  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 4.1738  Validation loss = 3.7471  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 4.1736  Validation loss = 3.7468  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 4.1734  Validation loss = 3.7464  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 4.1733  Validation loss = 3.7462  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 4.1730  Validation loss = 3.7458  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 4.1728  Validation loss = 3.7455  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 4.1726  Validation loss = 3.7451  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 4.1725  Validation loss = 3.7448  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 4.1723  Validation loss = 3.7445  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 4.1721  Validation loss = 3.7442  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 4.1719  Validation loss = 3.7438  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 4.1717  Validation loss = 3.7435  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 4.1715  Validation loss = 3.7433  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 4.1713  Validation loss = 3.7429  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 4.1711  Validation loss = 3.7426  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 4.1709  Validation loss = 3.7422  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 4.1708  Validation loss = 3.7420  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 4.1705  Validation loss = 3.7416  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 4.1703  Validation loss = 3.7412  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 4.1701  Validation loss = 3.7408  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 4.1699  Validation loss = 3.7404  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 4.1696  Validation loss = 3.7400  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 4.1695  Validation loss = 3.7397  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 4.1693  Validation loss = 3.7395  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 4.1691  Validation loss = 3.7392  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 4.1689  Validation loss = 3.7387  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 4.1687  Validation loss = 3.7385  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 4.1685  Validation loss = 3.7382  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 4.1683  Validation loss = 3.7378  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 4.1680  Validation loss = 3.7374  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 4.1678  Validation loss = 3.7369  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 4.1676  Validation loss = 3.7367  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 4.1674  Validation loss = 3.7364  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 4.1673  Validation loss = 3.7361  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 4.1671  Validation loss = 3.7358  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 4.1669  Validation loss = 3.7355  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 4.1668  Validation loss = 3.7352  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 4.1665  Validation loss = 3.7349  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 4.1663  Validation loss = 3.7345  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 4.1661  Validation loss = 3.7342  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 4.1659  Validation loss = 3.7339  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 4.1657  Validation loss = 3.7336  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 4.1656  Validation loss = 3.7333  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 4.1655  Validation loss = 3.7331  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 4.1653  Validation loss = 3.7328  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 4.1651  Validation loss = 3.7325  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 4.1649  Validation loss = 3.7321  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 4.1647  Validation loss = 3.7317  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 4.1645  Validation loss = 3.7314  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 4.1644  Validation loss = 3.7312  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 4.1642  Validation loss = 3.7309  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 4.1639  Validation loss = 3.7305  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 4.1636  Validation loss = 3.7301  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 4.1634  Validation loss = 3.7297  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 4.1632  Validation loss = 3.7294  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 4.1630  Validation loss = 3.7291  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 4.1628  Validation loss = 3.7287  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 4.1626  Validation loss = 3.7284  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 4.1625  Validation loss = 3.7282  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 4.1623  Validation loss = 3.7279  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 4.1621  Validation loss = 3.7276  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 4.1620  Validation loss = 3.7273  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 4.1617  Validation loss = 3.7270  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 4.1615  Validation loss = 3.7266  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 4.1613  Validation loss = 3.7263  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 4.1611  Validation loss = 3.7260  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 4.1609  Validation loss = 3.7257  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 4.1607  Validation loss = 3.7254  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 4.1605  Validation loss = 3.7251  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 4.1603  Validation loss = 3.7247  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 4.1602  Validation loss = 3.7245  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 4.1600  Validation loss = 3.7242  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 4.1599  Validation loss = 3.7240  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 4.1597  Validation loss = 3.7237  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 4.1596  Validation loss = 3.7235  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 4.1594  Validation loss = 3.7232  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 4.1592  Validation loss = 3.7229  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 4.1591  Validation loss = 3.7227  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 4.1589  Validation loss = 3.7225  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 4.1587  Validation loss = 3.7222  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 4.1585  Validation loss = 3.7218  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 4.1584  Validation loss = 3.7216  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 4.1581  Validation loss = 3.7213  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 4.1579  Validation loss = 3.7210  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 4.1578  Validation loss = 3.7207  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 4.1576  Validation loss = 3.7204  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 4.1575  Validation loss = 3.7202  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 4.1573  Validation loss = 3.7199  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 4.1572  Validation loss = 3.7197  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 4.1570  Validation loss = 3.7194  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 4.1569  Validation loss = 3.7192  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 4.1567  Validation loss = 3.7189  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 4.1565  Validation loss = 3.7186  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 4.1563  Validation loss = 3.7184  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 4.1562  Validation loss = 3.7181  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 4.1560  Validation loss = 3.7179  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 4.1559  Validation loss = 3.7176  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 4.1557  Validation loss = 3.7174  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 4.1555  Validation loss = 3.7171  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 4.1553  Validation loss = 3.7167  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 4.1551  Validation loss = 3.7164  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 4.1549  Validation loss = 3.7161  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 4.1547  Validation loss = 3.7157  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 4.1544  Validation loss = 3.7154  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 4.1543  Validation loss = 3.7152  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 4.1542  Validation loss = 3.7149  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 4.1540  Validation loss = 3.7146  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 4.1537  Validation loss = 3.7143  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 4.1535  Validation loss = 3.7139  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 4.1533  Validation loss = 3.7135  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 4.1531  Validation loss = 3.7132  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 4.1529  Validation loss = 3.7130  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 4.1527  Validation loss = 3.7127  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 4.1526  Validation loss = 3.7125  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 4.1523  Validation loss = 3.7121  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 4.1521  Validation loss = 3.7118  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 4.1519  Validation loss = 3.7115  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 4.1517  Validation loss = 3.7111  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 4.1515  Validation loss = 3.7108  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 4.1513  Validation loss = 3.7105  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 4.1511  Validation loss = 3.7102  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 4.1509  Validation loss = 3.7099  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 4.1507  Validation loss = 3.7096  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 4.1506  Validation loss = 3.7094  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 4.1504  Validation loss = 3.7092  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 4.1502  Validation loss = 3.7089  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 4.1500  Validation loss = 3.7085  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 4.1498  Validation loss = 3.7082  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 4.1496  Validation loss = 3.7079  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 4.1494  Validation loss = 3.7076  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 4.1492  Validation loss = 3.7073  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 4.1490  Validation loss = 3.7070  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 4.1488  Validation loss = 3.7067  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 4.1486  Validation loss = 3.7064  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 4.1484  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 4.1482  Validation loss = 3.7058  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 4.1480  Validation loss = 3.7055  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 4.1478  Validation loss = 3.7052  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 4.1476  Validation loss = 3.7049  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 4.1474  Validation loss = 3.7046  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 4.1471  Validation loss = 3.7042  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 4.1469  Validation loss = 3.7039  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 4.1468  Validation loss = 3.7037  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 4.1466  Validation loss = 3.7034  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 4.1464  Validation loss = 3.7032  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 4.1463  Validation loss = 3.7029  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 4.1461  Validation loss = 3.7026  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 4.1459  Validation loss = 3.7024  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 4.1457  Validation loss = 3.7021  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 4.1455  Validation loss = 3.7018  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 4.1453  Validation loss = 3.7015  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 4.1450  Validation loss = 3.7012  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 4.1448  Validation loss = 3.7009  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 4.1446  Validation loss = 3.7005  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 4.1444  Validation loss = 3.7003  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 4.1442  Validation loss = 3.6999  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 4.1440  Validation loss = 3.6997  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 4.1438  Validation loss = 3.6994  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 4.1435  Validation loss = 3.6991  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 4.1433  Validation loss = 3.6988  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 4.1432  Validation loss = 3.6986  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 4.1429  Validation loss = 3.6983  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 4.1427  Validation loss = 3.6979  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 4.1425  Validation loss = 3.6976  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 4.1423  Validation loss = 3.6973  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 4.1421  Validation loss = 3.6971  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 4.1419  Validation loss = 3.6968  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 4.1417  Validation loss = 3.6965  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 4.1415  Validation loss = 3.6961  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 4.1412  Validation loss = 3.6958  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 4.1410  Validation loss = 3.6954  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 4.1407  Validation loss = 3.6951  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 4.1405  Validation loss = 3.6948  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 4.1403  Validation loss = 3.6945  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 4.1401  Validation loss = 3.6943  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 4.1399  Validation loss = 3.6940  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 4.1396  Validation loss = 3.6936  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 4.1393  Validation loss = 3.6932  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 4.1391  Validation loss = 3.6930  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 4.1389  Validation loss = 3.6927  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 4.1388  Validation loss = 3.6924  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 4.1387  Validation loss = 3.6922  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 4.1385  Validation loss = 3.6920  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 4.1383  Validation loss = 3.6917  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 4.1381  Validation loss = 3.6914  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 4.1379  Validation loss = 3.6912  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 4.1377  Validation loss = 3.6909  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 4.1375  Validation loss = 3.6906  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 4.1373  Validation loss = 3.6903  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 4.1371  Validation loss = 3.6900  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 4.1368  Validation loss = 3.6897  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 4.1367  Validation loss = 3.6895  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 4.1365  Validation loss = 3.6892  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 4.1364  Validation loss = 3.6890  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 4.1362  Validation loss = 3.6887  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 4.1360  Validation loss = 3.6885  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 4.1358  Validation loss = 3.6882  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 4.1356  Validation loss = 3.6879  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 4.1355  Validation loss = 3.6877  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 4.1352  Validation loss = 3.6874  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 4.1350  Validation loss = 3.6870  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 4.1348  Validation loss = 3.6868  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 4.1346  Validation loss = 3.6865  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 4.1344  Validation loss = 3.6862  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 4.1342  Validation loss = 3.6860  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 4.1340  Validation loss = 3.6857  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 4.1339  Validation loss = 3.6854  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 4.1336  Validation loss = 3.6851  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 4.1334  Validation loss = 3.6848  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 4.1331  Validation loss = 3.6845  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 4.1329  Validation loss = 3.6842  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 4.1327  Validation loss = 3.6839  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 4.1325  Validation loss = 3.6836  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 4.1323  Validation loss = 3.6833  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 4.1320  Validation loss = 3.6830  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 4.1319  Validation loss = 3.6828  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 4.1316  Validation loss = 3.6825  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 4.1315  Validation loss = 3.6823  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 4.1313  Validation loss = 3.6820  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 4.1312  Validation loss = 3.6818  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 4.1309  Validation loss = 3.6815  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 4.1307  Validation loss = 3.6812  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 4.1305  Validation loss = 3.6810  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 4.1304  Validation loss = 3.6807  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 4.1302  Validation loss = 3.6805  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 4.1299  Validation loss = 3.6802  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 4.1296  Validation loss = 3.6798  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 4.1294  Validation loss = 3.6795  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 4.1292  Validation loss = 3.6792  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 4.1289  Validation loss = 3.6789  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 4.1286  Validation loss = 3.6785  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 4.1284  Validation loss = 3.6782  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 4.1282  Validation loss = 3.6780  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 4.1279  Validation loss = 3.6776  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 4.1277  Validation loss = 3.6774  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 4.1273  Validation loss = 3.6770  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 4.1269  Validation loss = 3.6766  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 4.1266  Validation loss = 3.6762  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 4.1264  Validation loss = 3.6760  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 4.1262  Validation loss = 3.6757  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 4.1260  Validation loss = 3.6754  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 4.1257  Validation loss = 3.6751  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 4.1255  Validation loss = 3.6748  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 4.1251  Validation loss = 3.6744  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 4.1248  Validation loss = 3.6740  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 4.1245  Validation loss = 3.6737  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 4.1242  Validation loss = 3.6733  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 4.1239  Validation loss = 3.6730  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 4.1237  Validation loss = 3.6728  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 4.1235  Validation loss = 3.6725  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 4.1233  Validation loss = 3.6722  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 4.1230  Validation loss = 3.6719  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 4.1228  Validation loss = 3.6716  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 4.1224  Validation loss = 3.6712  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 4.1221  Validation loss = 3.6708  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 4.1220  Validation loss = 3.6706  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 4.1218  Validation loss = 3.6703  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 4.1216  Validation loss = 3.6701  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 4.1213  Validation loss = 3.6698  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 4.1211  Validation loss = 3.6695  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 4.1208  Validation loss = 3.6692  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 4.1207  Validation loss = 3.6690  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 4.1205  Validation loss = 3.6688  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 4.1203  Validation loss = 3.6685  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 4.1201  Validation loss = 3.6683  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 4.1199  Validation loss = 3.6680  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 4.1196  Validation loss = 3.6677  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 4.1194  Validation loss = 3.6674  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 4.1191  Validation loss = 3.6671  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 4.1188  Validation loss = 3.6668  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 4.1187  Validation loss = 3.6666  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 4.1184  Validation loss = 3.6663  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 4.1183  Validation loss = 3.6661  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 4.1181  Validation loss = 3.6659  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 4.1178  Validation loss = 3.6655  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 4.1176  Validation loss = 3.6653  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 4.1174  Validation loss = 3.6650  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 4.1171  Validation loss = 3.6647  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 4.1169  Validation loss = 3.6644  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 4.1167  Validation loss = 3.6642  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 4.1165  Validation loss = 3.6639  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 4.1163  Validation loss = 3.6637  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 4.1161  Validation loss = 3.6634  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 4.1158  Validation loss = 3.6631  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 4.1155  Validation loss = 3.6628  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 4.1152  Validation loss = 3.6625  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 4.1149  Validation loss = 3.6622  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 4.1147  Validation loss = 3.6618  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 4.1144  Validation loss = 3.6615  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 4.1141  Validation loss = 3.6613  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 4.1139  Validation loss = 3.6610  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 4.1137  Validation loss = 3.6607  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 4.1133  Validation loss = 3.6604  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 4.1131  Validation loss = 3.6602  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 4.1129  Validation loss = 3.6599  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 4.1126  Validation loss = 3.6596  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 4.1124  Validation loss = 3.6594  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 4.1122  Validation loss = 3.6591  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 4.1119  Validation loss = 3.6588  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 4.1116  Validation loss = 3.6585  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 4.1114  Validation loss = 3.6582  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 4.1112  Validation loss = 3.6579  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 4.1110  Validation loss = 3.6577  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 4.1108  Validation loss = 3.6575  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 4.1106  Validation loss = 3.6572  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 4.1104  Validation loss = 3.6570  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 4.1099  Validation loss = 3.6565  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 4.1096  Validation loss = 3.6562  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 4.1093  Validation loss = 3.6559  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 4.1092  Validation loss = 3.6557  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 4.1090  Validation loss = 3.6554  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 4.1087  Validation loss = 3.6552  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 4.1085  Validation loss = 3.6549  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 4.1083  Validation loss = 3.6546  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 4.1080  Validation loss = 3.6544  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 4.1078  Validation loss = 3.6541  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 4.1075  Validation loss = 3.6538  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 4.1072  Validation loss = 3.6535  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 4.1070  Validation loss = 3.6533  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 4.1069  Validation loss = 3.6530  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 4.1066  Validation loss = 3.6527  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 4.1062  Validation loss = 3.6524  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 4.1060  Validation loss = 3.6522  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 4.1059  Validation loss = 3.6519  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 4.1055  Validation loss = 3.6516  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 4.1053  Validation loss = 3.6513  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 4.1050  Validation loss = 3.6510  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 4.1047  Validation loss = 3.6507  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 4.1045  Validation loss = 3.6505  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 4.1042  Validation loss = 3.6502  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 4.1040  Validation loss = 3.6500  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 4.1037  Validation loss = 3.6497  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 4.1033  Validation loss = 3.6494  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 4.1031  Validation loss = 3.6491  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 4.1028  Validation loss = 3.6488  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 4.1026  Validation loss = 3.6485  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 4.1023  Validation loss = 3.6482  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 4.1020  Validation loss = 3.6479  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 4.1018  Validation loss = 3.6477  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 4.1015  Validation loss = 3.6474  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 4.1012  Validation loss = 3.6471  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 4.1010  Validation loss = 3.6469  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 4.1008  Validation loss = 3.6467  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 4.1006  Validation loss = 3.6465  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 4.1003  Validation loss = 3.6462  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 4.0999  Validation loss = 3.6459  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 4.0996  Validation loss = 3.6456  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 4.0994  Validation loss = 3.6454  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 4.0992  Validation loss = 3.6452  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 4.0990  Validation loss = 3.6450  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 4.0988  Validation loss = 3.6447  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 4.0986  Validation loss = 3.6444  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 4.0982  Validation loss = 3.6442  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 4.0980  Validation loss = 3.6439  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 4.0978  Validation loss = 3.6437  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 4.0976  Validation loss = 3.6434  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 4.0974  Validation loss = 3.6432  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 4.0971  Validation loss = 3.6428  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 4.0968  Validation loss = 3.6425  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 4.0963  Validation loss = 3.6422  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 4.0962  Validation loss = 3.6420  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 4.0960  Validation loss = 3.6418  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 4.0956  Validation loss = 3.6414  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 4.0955  Validation loss = 3.6413  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 4.0952  Validation loss = 3.6410  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 4.0950  Validation loss = 3.6408  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 4.0946  Validation loss = 3.6405  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 4.0943  Validation loss = 3.6402  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 4.0940  Validation loss = 3.6399  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 4.0939  Validation loss = 3.6397  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 4.0936  Validation loss = 3.6395  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 4.0933  Validation loss = 3.6392  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 4.0930  Validation loss = 3.6389  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 4.0926  Validation loss = 3.6386  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 4.0923  Validation loss = 3.6383  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 4.0920  Validation loss = 3.6380  \n",
      "\n",
      "Fold: 11  Epoch: 501  Training loss = 4.0918  Validation loss = 3.6378  \n",
      "\n",
      "Fold: 11  Epoch: 502  Training loss = 4.0917  Validation loss = 3.6376  \n",
      "\n",
      "Fold: 11  Epoch: 503  Training loss = 4.0913  Validation loss = 3.6372  \n",
      "\n",
      "Fold: 11  Epoch: 504  Training loss = 4.0909  Validation loss = 3.6369  \n",
      "\n",
      "Fold: 11  Epoch: 505  Training loss = 4.0906  Validation loss = 3.6367  \n",
      "\n",
      "Fold: 11  Epoch: 506  Training loss = 4.0901  Validation loss = 3.6363  \n",
      "\n",
      "Fold: 11  Epoch: 507  Training loss = 4.0899  Validation loss = 3.6361  \n",
      "\n",
      "Fold: 11  Epoch: 508  Training loss = 4.0895  Validation loss = 3.6359  \n",
      "\n",
      "Fold: 11  Epoch: 509  Training loss = 4.0892  Validation loss = 3.6356  \n",
      "\n",
      "Fold: 11  Epoch: 510  Training loss = 4.0891  Validation loss = 3.6354  \n",
      "\n",
      "Fold: 11  Epoch: 511  Training loss = 4.0888  Validation loss = 3.6351  \n",
      "\n",
      "Fold: 11  Epoch: 512  Training loss = 4.0884  Validation loss = 3.6347  \n",
      "\n",
      "Fold: 11  Epoch: 513  Training loss = 4.0882  Validation loss = 3.6345  \n",
      "\n",
      "Fold: 11  Epoch: 514  Training loss = 4.0879  Validation loss = 3.6342  \n",
      "\n",
      "Fold: 11  Epoch: 515  Training loss = 4.0876  Validation loss = 3.6339  \n",
      "\n",
      "Fold: 11  Epoch: 516  Training loss = 4.0874  Validation loss = 3.6337  \n",
      "\n",
      "Fold: 11  Epoch: 517  Training loss = 4.0871  Validation loss = 3.6334  \n",
      "\n",
      "Fold: 11  Epoch: 518  Training loss = 4.0867  Validation loss = 3.6331  \n",
      "\n",
      "Fold: 11  Epoch: 519  Training loss = 4.0864  Validation loss = 3.6328  \n",
      "\n",
      "Fold: 11  Epoch: 520  Training loss = 4.0861  Validation loss = 3.6326  \n",
      "\n",
      "Fold: 11  Epoch: 521  Training loss = 4.0859  Validation loss = 3.6324  \n",
      "\n",
      "Fold: 11  Epoch: 522  Training loss = 4.0857  Validation loss = 3.6322  \n",
      "\n",
      "Fold: 11  Epoch: 523  Training loss = 4.0853  Validation loss = 3.6318  \n",
      "\n",
      "Fold: 11  Epoch: 524  Training loss = 4.0849  Validation loss = 3.6315  \n",
      "\n",
      "Fold: 11  Epoch: 525  Training loss = 4.0846  Validation loss = 3.6312  \n",
      "\n",
      "Fold: 11  Epoch: 526  Training loss = 4.0843  Validation loss = 3.6309  \n",
      "\n",
      "Fold: 11  Epoch: 527  Training loss = 4.0840  Validation loss = 3.6307  \n",
      "\n",
      "Fold: 11  Epoch: 528  Training loss = 4.0837  Validation loss = 3.6304  \n",
      "\n",
      "Fold: 11  Epoch: 529  Training loss = 4.0836  Validation loss = 3.6301  \n",
      "\n",
      "Fold: 11  Epoch: 530  Training loss = 4.0834  Validation loss = 3.6298  \n",
      "\n",
      "Fold: 11  Epoch: 531  Training loss = 4.0830  Validation loss = 3.6295  \n",
      "\n",
      "Fold: 11  Epoch: 532  Training loss = 4.0828  Validation loss = 3.6293  \n",
      "\n",
      "Fold: 11  Epoch: 533  Training loss = 4.0823  Validation loss = 3.6289  \n",
      "\n",
      "Fold: 11  Epoch: 534  Training loss = 4.0821  Validation loss = 3.6287  \n",
      "\n",
      "Fold: 11  Epoch: 535  Training loss = 4.0816  Validation loss = 3.6283  \n",
      "\n",
      "Fold: 11  Epoch: 536  Training loss = 4.0813  Validation loss = 3.6280  \n",
      "\n",
      "Fold: 11  Epoch: 537  Training loss = 4.0811  Validation loss = 3.6278  \n",
      "\n",
      "Fold: 11  Epoch: 538  Training loss = 4.0808  Validation loss = 3.6275  \n",
      "\n",
      "Fold: 11  Epoch: 539  Training loss = 4.0805  Validation loss = 3.6272  \n",
      "\n",
      "Fold: 11  Epoch: 540  Training loss = 4.0802  Validation loss = 3.6270  \n",
      "\n",
      "Fold: 11  Epoch: 541  Training loss = 4.0800  Validation loss = 3.6268  \n",
      "\n",
      "Fold: 11  Epoch: 542  Training loss = 4.0796  Validation loss = 3.6265  \n",
      "\n",
      "Fold: 11  Epoch: 543  Training loss = 4.0793  Validation loss = 3.6262  \n",
      "\n",
      "Fold: 11  Epoch: 544  Training loss = 4.0790  Validation loss = 3.6259  \n",
      "\n",
      "Fold: 11  Epoch: 545  Training loss = 4.0787  Validation loss = 3.6256  \n",
      "\n",
      "Fold: 11  Epoch: 546  Training loss = 4.0785  Validation loss = 3.6254  \n",
      "\n",
      "Fold: 11  Epoch: 547  Training loss = 4.0782  Validation loss = 3.6251  \n",
      "\n",
      "Fold: 11  Epoch: 548  Training loss = 4.0779  Validation loss = 3.6248  \n",
      "\n",
      "Fold: 11  Epoch: 549  Training loss = 4.0775  Validation loss = 3.6245  \n",
      "\n",
      "Fold: 11  Epoch: 550  Training loss = 4.0772  Validation loss = 3.6243  \n",
      "\n",
      "Fold: 11  Epoch: 551  Training loss = 4.0770  Validation loss = 3.6241  \n",
      "\n",
      "Fold: 11  Epoch: 552  Training loss = 4.0767  Validation loss = 3.6238  \n",
      "\n",
      "Fold: 11  Epoch: 553  Training loss = 4.0762  Validation loss = 3.6235  \n",
      "\n",
      "Fold: 11  Epoch: 554  Training loss = 4.0759  Validation loss = 3.6232  \n",
      "\n",
      "Fold: 11  Epoch: 555  Training loss = 4.0756  Validation loss = 3.6229  \n",
      "\n",
      "Fold: 11  Epoch: 556  Training loss = 4.0753  Validation loss = 3.6226  \n",
      "\n",
      "Fold: 11  Epoch: 557  Training loss = 4.0747  Validation loss = 3.6223  \n",
      "\n",
      "Fold: 11  Epoch: 558  Training loss = 4.0745  Validation loss = 3.6221  \n",
      "\n",
      "Fold: 11  Epoch: 559  Training loss = 4.0742  Validation loss = 3.6218  \n",
      "\n",
      "Fold: 11  Epoch: 560  Training loss = 4.0738  Validation loss = 3.6215  \n",
      "\n",
      "Fold: 11  Epoch: 561  Training loss = 4.0736  Validation loss = 3.6213  \n",
      "\n",
      "Fold: 11  Epoch: 562  Training loss = 4.0733  Validation loss = 3.6210  \n",
      "\n",
      "Fold: 11  Epoch: 563  Training loss = 4.0730  Validation loss = 3.6208  \n",
      "\n",
      "Fold: 11  Epoch: 564  Training loss = 4.0727  Validation loss = 3.6205  \n",
      "\n",
      "Fold: 11  Epoch: 565  Training loss = 4.0725  Validation loss = 3.6203  \n",
      "\n",
      "Fold: 11  Epoch: 566  Training loss = 4.0722  Validation loss = 3.6200  \n",
      "\n",
      "Fold: 11  Epoch: 567  Training loss = 4.0720  Validation loss = 3.6198  \n",
      "\n",
      "Fold: 11  Epoch: 568  Training loss = 4.0717  Validation loss = 3.6196  \n",
      "\n",
      "Fold: 11  Epoch: 569  Training loss = 4.0715  Validation loss = 3.6193  \n",
      "\n",
      "Fold: 11  Epoch: 570  Training loss = 4.0712  Validation loss = 3.6190  \n",
      "\n",
      "Fold: 11  Epoch: 571  Training loss = 4.0709  Validation loss = 3.6188  \n",
      "\n",
      "Fold: 11  Epoch: 572  Training loss = 4.0707  Validation loss = 3.6186  \n",
      "\n",
      "Fold: 11  Epoch: 573  Training loss = 4.0704  Validation loss = 3.6183  \n",
      "\n",
      "Fold: 11  Epoch: 574  Training loss = 4.0701  Validation loss = 3.6181  \n",
      "\n",
      "Fold: 11  Epoch: 575  Training loss = 4.0698  Validation loss = 3.6179  \n",
      "\n",
      "Fold: 11  Epoch: 576  Training loss = 4.0695  Validation loss = 3.6176  \n",
      "\n",
      "Fold: 11  Epoch: 577  Training loss = 4.0690  Validation loss = 3.6172  \n",
      "\n",
      "Fold: 11  Epoch: 578  Training loss = 4.0689  Validation loss = 3.6170  \n",
      "\n",
      "Fold: 11  Epoch: 579  Training loss = 4.0684  Validation loss = 3.6167  \n",
      "\n",
      "Fold: 11  Epoch: 580  Training loss = 4.0682  Validation loss = 3.6165  \n",
      "\n",
      "Fold: 11  Epoch: 581  Training loss = 4.0679  Validation loss = 3.6162  \n",
      "\n",
      "Fold: 11  Epoch: 582  Training loss = 4.0674  Validation loss = 3.6158  \n",
      "\n",
      "Fold: 11  Epoch: 583  Training loss = 4.0672  Validation loss = 3.6156  \n",
      "\n",
      "Fold: 11  Epoch: 584  Training loss = 4.0668  Validation loss = 3.6153  \n",
      "\n",
      "Fold: 11  Epoch: 585  Training loss = 4.0664  Validation loss = 3.6151  \n",
      "\n",
      "Fold: 11  Epoch: 586  Training loss = 4.0661  Validation loss = 3.6148  \n",
      "\n",
      "Fold: 11  Epoch: 587  Training loss = 4.0657  Validation loss = 3.6145  \n",
      "\n",
      "Fold: 11  Epoch: 588  Training loss = 4.0654  Validation loss = 3.6142  \n",
      "\n",
      "Fold: 11  Epoch: 589  Training loss = 4.0652  Validation loss = 3.6139  \n",
      "\n",
      "Fold: 11  Epoch: 590  Training loss = 4.0650  Validation loss = 3.6138  \n",
      "\n",
      "Fold: 11  Epoch: 591  Training loss = 4.0648  Validation loss = 3.6135  \n",
      "\n",
      "Fold: 11  Epoch: 592  Training loss = 4.0646  Validation loss = 3.6133  \n",
      "\n",
      "Fold: 11  Epoch: 593  Training loss = 4.0642  Validation loss = 3.6129  \n",
      "\n",
      "Fold: 11  Epoch: 594  Training loss = 4.0639  Validation loss = 3.6127  \n",
      "\n",
      "Fold: 11  Epoch: 595  Training loss = 4.0637  Validation loss = 3.6125  \n",
      "\n",
      "Fold: 11  Epoch: 596  Training loss = 4.0634  Validation loss = 3.6122  \n",
      "\n",
      "Fold: 11  Epoch: 597  Training loss = 4.0633  Validation loss = 3.6120  \n",
      "\n",
      "Fold: 11  Epoch: 598  Training loss = 4.0629  Validation loss = 3.6117  \n",
      "\n",
      "Fold: 11  Epoch: 599  Training loss = 4.0626  Validation loss = 3.6114  \n",
      "\n",
      "Fold: 11  Epoch: 600  Training loss = 4.0624  Validation loss = 3.6112  \n",
      "\n",
      "Fold: 11  Epoch: 601  Training loss = 4.0621  Validation loss = 3.6109  \n",
      "\n",
      "Fold: 11  Epoch: 602  Training loss = 4.0618  Validation loss = 3.6107  \n",
      "\n",
      "Fold: 11  Epoch: 603  Training loss = 4.0616  Validation loss = 3.6105  \n",
      "\n",
      "Fold: 11  Epoch: 604  Training loss = 4.0614  Validation loss = 3.6102  \n",
      "\n",
      "Fold: 11  Epoch: 605  Training loss = 4.0610  Validation loss = 3.6099  \n",
      "\n",
      "Fold: 11  Epoch: 606  Training loss = 4.0607  Validation loss = 3.6097  \n",
      "\n",
      "Fold: 11  Epoch: 607  Training loss = 4.0604  Validation loss = 3.6094  \n",
      "\n",
      "Fold: 11  Epoch: 608  Training loss = 4.0601  Validation loss = 3.6092  \n",
      "\n",
      "Fold: 11  Epoch: 609  Training loss = 4.0598  Validation loss = 3.6088  \n",
      "\n",
      "Fold: 11  Epoch: 610  Training loss = 4.0594  Validation loss = 3.6085  \n",
      "\n",
      "Fold: 11  Epoch: 611  Training loss = 4.0591  Validation loss = 3.6083  \n",
      "\n",
      "Fold: 11  Epoch: 612  Training loss = 4.0588  Validation loss = 3.6080  \n",
      "\n",
      "Fold: 11  Epoch: 613  Training loss = 4.0585  Validation loss = 3.6078  \n",
      "\n",
      "Fold: 11  Epoch: 614  Training loss = 4.0582  Validation loss = 3.6075  \n",
      "\n",
      "Fold: 11  Epoch: 615  Training loss = 4.0579  Validation loss = 3.6072  \n",
      "\n",
      "Fold: 11  Epoch: 616  Training loss = 4.0575  Validation loss = 3.6070  \n",
      "\n",
      "Fold: 11  Epoch: 617  Training loss = 4.0572  Validation loss = 3.6067  \n",
      "\n",
      "Fold: 11  Epoch: 618  Training loss = 4.0568  Validation loss = 3.6064  \n",
      "\n",
      "Fold: 11  Epoch: 619  Training loss = 4.0565  Validation loss = 3.6061  \n",
      "\n",
      "Fold: 11  Epoch: 620  Training loss = 4.0561  Validation loss = 3.6058  \n",
      "\n",
      "Fold: 11  Epoch: 621  Training loss = 4.0558  Validation loss = 3.6055  \n",
      "\n",
      "Fold: 11  Epoch: 622  Training loss = 4.0555  Validation loss = 3.6053  \n",
      "\n",
      "Fold: 11  Epoch: 623  Training loss = 4.0550  Validation loss = 3.6050  \n",
      "\n",
      "Fold: 11  Epoch: 624  Training loss = 4.0547  Validation loss = 3.6047  \n",
      "\n",
      "Fold: 11  Epoch: 625  Training loss = 4.0545  Validation loss = 3.6045  \n",
      "\n",
      "Fold: 11  Epoch: 626  Training loss = 4.0542  Validation loss = 3.6042  \n",
      "\n",
      "Fold: 11  Epoch: 627  Training loss = 4.0540  Validation loss = 3.6040  \n",
      "\n",
      "Fold: 11  Epoch: 628  Training loss = 4.0536  Validation loss = 3.6037  \n",
      "\n",
      "Fold: 11  Epoch: 629  Training loss = 4.0532  Validation loss = 3.6034  \n",
      "\n",
      "Fold: 11  Epoch: 630  Training loss = 4.0530  Validation loss = 3.6031  \n",
      "\n",
      "Fold: 11  Epoch: 631  Training loss = 4.0527  Validation loss = 3.6029  \n",
      "\n",
      "Fold: 11  Epoch: 632  Training loss = 4.0524  Validation loss = 3.6027  \n",
      "\n",
      "Fold: 11  Epoch: 633  Training loss = 4.0522  Validation loss = 3.6024  \n",
      "\n",
      "Fold: 11  Epoch: 634  Training loss = 4.0518  Validation loss = 3.6022  \n",
      "\n",
      "Fold: 11  Epoch: 635  Training loss = 4.0515  Validation loss = 3.6019  \n",
      "\n",
      "Fold: 11  Epoch: 636  Training loss = 4.0510  Validation loss = 3.6015  \n",
      "\n",
      "Fold: 11  Epoch: 637  Training loss = 4.0508  Validation loss = 3.6013  \n",
      "\n",
      "Fold: 11  Epoch: 638  Training loss = 4.0505  Validation loss = 3.6010  \n",
      "\n",
      "Fold: 11  Epoch: 639  Training loss = 4.0503  Validation loss = 3.6008  \n",
      "\n",
      "Fold: 11  Epoch: 640  Training loss = 4.0500  Validation loss = 3.6006  \n",
      "\n",
      "Fold: 11  Epoch: 641  Training loss = 4.0496  Validation loss = 3.6003  \n",
      "\n",
      "Fold: 11  Epoch: 642  Training loss = 4.0493  Validation loss = 3.6001  \n",
      "\n",
      "Fold: 11  Epoch: 643  Training loss = 4.0489  Validation loss = 3.5998  \n",
      "\n",
      "Fold: 11  Epoch: 644  Training loss = 4.0486  Validation loss = 3.5996  \n",
      "\n",
      "Fold: 11  Epoch: 645  Training loss = 4.0482  Validation loss = 3.5993  \n",
      "\n",
      "Fold: 11  Epoch: 646  Training loss = 4.0479  Validation loss = 3.5991  \n",
      "\n",
      "Fold: 11  Epoch: 647  Training loss = 4.0474  Validation loss = 3.5988  \n",
      "\n",
      "Fold: 11  Epoch: 648  Training loss = 4.0473  Validation loss = 3.5986  \n",
      "\n",
      "Fold: 11  Epoch: 649  Training loss = 4.0470  Validation loss = 3.5984  \n",
      "\n",
      "Fold: 11  Epoch: 650  Training loss = 4.0467  Validation loss = 3.5981  \n",
      "\n",
      "Fold: 11  Epoch: 651  Training loss = 4.0464  Validation loss = 3.5978  \n",
      "\n",
      "Fold: 11  Epoch: 652  Training loss = 4.0461  Validation loss = 3.5976  \n",
      "\n",
      "Fold: 11  Epoch: 653  Training loss = 4.0458  Validation loss = 3.5973  \n",
      "\n",
      "Fold: 11  Epoch: 654  Training loss = 4.0454  Validation loss = 3.5971  \n",
      "\n",
      "Fold: 11  Epoch: 655  Training loss = 4.0451  Validation loss = 3.5968  \n",
      "\n",
      "Fold: 11  Epoch: 656  Training loss = 4.0448  Validation loss = 3.5965  \n",
      "\n",
      "Fold: 11  Epoch: 657  Training loss = 4.0446  Validation loss = 3.5963  \n",
      "\n",
      "Fold: 11  Epoch: 658  Training loss = 4.0441  Validation loss = 3.5960  \n",
      "\n",
      "Fold: 11  Epoch: 659  Training loss = 4.0437  Validation loss = 3.5957  \n",
      "\n",
      "Fold: 11  Epoch: 660  Training loss = 4.0435  Validation loss = 3.5955  \n",
      "\n",
      "Fold: 11  Epoch: 661  Training loss = 4.0431  Validation loss = 3.5952  \n",
      "\n",
      "Fold: 11  Epoch: 662  Training loss = 4.0427  Validation loss = 3.5950  \n",
      "\n",
      "Fold: 11  Epoch: 663  Training loss = 4.0425  Validation loss = 3.5947  \n",
      "\n",
      "Fold: 11  Epoch: 664  Training loss = 4.0422  Validation loss = 3.5945  \n",
      "\n",
      "Fold: 11  Epoch: 665  Training loss = 4.0418  Validation loss = 3.5942  \n",
      "\n",
      "Fold: 11  Epoch: 666  Training loss = 4.0414  Validation loss = 3.5938  \n",
      "\n",
      "Fold: 11  Epoch: 667  Training loss = 4.0411  Validation loss = 3.5936  \n",
      "\n",
      "Fold: 11  Epoch: 668  Training loss = 4.0409  Validation loss = 3.5933  \n",
      "\n",
      "Fold: 11  Epoch: 669  Training loss = 4.0405  Validation loss = 3.5931  \n",
      "\n",
      "Fold: 11  Epoch: 670  Training loss = 4.0401  Validation loss = 3.5928  \n",
      "\n",
      "Fold: 11  Epoch: 671  Training loss = 4.0397  Validation loss = 3.5925  \n",
      "\n",
      "Fold: 11  Epoch: 672  Training loss = 4.0395  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 11  Epoch: 673  Training loss = 4.0392  Validation loss = 3.5921  \n",
      "\n",
      "Fold: 11  Epoch: 674  Training loss = 4.0389  Validation loss = 3.5918  \n",
      "\n",
      "Fold: 11  Epoch: 675  Training loss = 4.0386  Validation loss = 3.5916  \n",
      "\n",
      "Fold: 11  Epoch: 676  Training loss = 4.0383  Validation loss = 3.5913  \n",
      "\n",
      "Fold: 11  Epoch: 677  Training loss = 4.0379  Validation loss = 3.5911  \n",
      "\n",
      "Fold: 11  Epoch: 678  Training loss = 4.0377  Validation loss = 3.5908  \n",
      "\n",
      "Fold: 11  Epoch: 679  Training loss = 4.0374  Validation loss = 3.5906  \n",
      "\n",
      "Fold: 11  Epoch: 680  Training loss = 4.0369  Validation loss = 3.5902  \n",
      "\n",
      "Fold: 11  Epoch: 681  Training loss = 4.0366  Validation loss = 3.5900  \n",
      "\n",
      "Fold: 11  Epoch: 682  Training loss = 4.0362  Validation loss = 3.5897  \n",
      "\n",
      "Fold: 11  Epoch: 683  Training loss = 4.0360  Validation loss = 3.5895  \n",
      "\n",
      "Fold: 11  Epoch: 684  Training loss = 4.0357  Validation loss = 3.5893  \n",
      "\n",
      "Fold: 11  Epoch: 685  Training loss = 4.0356  Validation loss = 3.5891  \n",
      "\n",
      "Fold: 11  Epoch: 686  Training loss = 4.0354  Validation loss = 3.5889  \n",
      "\n",
      "Fold: 11  Epoch: 687  Training loss = 4.0350  Validation loss = 3.5886  \n",
      "\n",
      "Fold: 11  Epoch: 688  Training loss = 4.0346  Validation loss = 3.5883  \n",
      "\n",
      "Fold: 11  Epoch: 689  Training loss = 4.0343  Validation loss = 3.5881  \n",
      "\n",
      "Fold: 11  Epoch: 690  Training loss = 4.0340  Validation loss = 3.5878  \n",
      "\n",
      "Fold: 11  Epoch: 691  Training loss = 4.0337  Validation loss = 3.5876  \n",
      "\n",
      "Fold: 11  Epoch: 692  Training loss = 4.0334  Validation loss = 3.5874  \n",
      "\n",
      "Fold: 11  Epoch: 693  Training loss = 4.0329  Validation loss = 3.5871  \n",
      "\n",
      "Fold: 11  Epoch: 694  Training loss = 4.0325  Validation loss = 3.5869  \n",
      "\n",
      "Fold: 11  Epoch: 695  Training loss = 4.0322  Validation loss = 3.5866  \n",
      "\n",
      "Fold: 11  Epoch: 696  Training loss = 4.0318  Validation loss = 3.5863  \n",
      "\n",
      "Fold: 11  Epoch: 697  Training loss = 4.0315  Validation loss = 3.5860  \n",
      "\n",
      "Fold: 11  Epoch: 698  Training loss = 4.0311  Validation loss = 3.5857  \n",
      "\n",
      "Fold: 11  Epoch: 699  Training loss = 4.0308  Validation loss = 3.5855  \n",
      "\n",
      "Fold: 11  Epoch: 700  Training loss = 4.0304  Validation loss = 3.5852  \n",
      "\n",
      "Fold: 11  Epoch: 701  Training loss = 4.0299  Validation loss = 3.5849  \n",
      "\n",
      "Fold: 11  Epoch: 702  Training loss = 4.0294  Validation loss = 3.5846  \n",
      "\n",
      "Fold: 11  Epoch: 703  Training loss = 4.0289  Validation loss = 3.5843  \n",
      "\n",
      "Fold: 11  Epoch: 704  Training loss = 4.0286  Validation loss = 3.5840  \n",
      "\n",
      "Fold: 11  Epoch: 705  Training loss = 4.0283  Validation loss = 3.5838  \n",
      "\n",
      "Fold: 11  Epoch: 706  Training loss = 4.0280  Validation loss = 3.5835  \n",
      "\n",
      "Fold: 11  Epoch: 707  Training loss = 4.0276  Validation loss = 3.5833  \n",
      "\n",
      "Fold: 11  Epoch: 708  Training loss = 4.0274  Validation loss = 3.5831  \n",
      "\n",
      "Fold: 11  Epoch: 709  Training loss = 4.0271  Validation loss = 3.5828  \n",
      "\n",
      "Fold: 11  Epoch: 710  Training loss = 4.0268  Validation loss = 3.5826  \n",
      "\n",
      "Fold: 11  Epoch: 711  Training loss = 4.0264  Validation loss = 3.5823  \n",
      "\n",
      "Fold: 11  Epoch: 712  Training loss = 4.0261  Validation loss = 3.5821  \n",
      "\n",
      "Fold: 11  Epoch: 713  Training loss = 4.0258  Validation loss = 3.5818  \n",
      "\n",
      "Fold: 11  Epoch: 714  Training loss = 4.0253  Validation loss = 3.5816  \n",
      "\n",
      "Fold: 11  Epoch: 715  Training loss = 4.0250  Validation loss = 3.5813  \n",
      "\n",
      "Fold: 11  Epoch: 716  Training loss = 4.0244  Validation loss = 3.5810  \n",
      "\n",
      "Fold: 11  Epoch: 717  Training loss = 4.0241  Validation loss = 3.5807  \n",
      "\n",
      "Fold: 11  Epoch: 718  Training loss = 4.0238  Validation loss = 3.5805  \n",
      "\n",
      "Fold: 11  Epoch: 719  Training loss = 4.0234  Validation loss = 3.5802  \n",
      "\n",
      "Fold: 11  Epoch: 720  Training loss = 4.0229  Validation loss = 3.5799  \n",
      "\n",
      "Fold: 11  Epoch: 721  Training loss = 4.0227  Validation loss = 3.5797  \n",
      "\n",
      "Fold: 11  Epoch: 722  Training loss = 4.0224  Validation loss = 3.5794  \n",
      "\n",
      "Fold: 11  Epoch: 723  Training loss = 4.0220  Validation loss = 3.5792  \n",
      "\n",
      "Fold: 11  Epoch: 724  Training loss = 4.0216  Validation loss = 3.5789  \n",
      "\n",
      "Fold: 11  Epoch: 725  Training loss = 4.0213  Validation loss = 3.5786  \n",
      "\n",
      "Fold: 11  Epoch: 726  Training loss = 4.0209  Validation loss = 3.5784  \n",
      "\n",
      "Fold: 11  Epoch: 727  Training loss = 4.0206  Validation loss = 3.5782  \n",
      "\n",
      "Fold: 11  Epoch: 728  Training loss = 4.0202  Validation loss = 3.5779  \n",
      "\n",
      "Fold: 11  Epoch: 729  Training loss = 4.0197  Validation loss = 3.5776  \n",
      "\n",
      "Fold: 11  Epoch: 730  Training loss = 4.0194  Validation loss = 3.5773  \n",
      "\n",
      "Fold: 11  Epoch: 731  Training loss = 4.0189  Validation loss = 3.5771  \n",
      "\n",
      "Fold: 11  Epoch: 732  Training loss = 4.0186  Validation loss = 3.5768  \n",
      "\n",
      "Fold: 11  Epoch: 733  Training loss = 4.0184  Validation loss = 3.5766  \n",
      "\n",
      "Fold: 11  Epoch: 734  Training loss = 4.0181  Validation loss = 3.5764  \n",
      "\n",
      "Fold: 11  Epoch: 735  Training loss = 4.0176  Validation loss = 3.5761  \n",
      "\n",
      "Fold: 11  Epoch: 736  Training loss = 4.0174  Validation loss = 3.5759  \n",
      "\n",
      "Fold: 11  Epoch: 737  Training loss = 4.0168  Validation loss = 3.5755  \n",
      "\n",
      "Fold: 11  Epoch: 738  Training loss = 4.0163  Validation loss = 3.5753  \n",
      "\n",
      "Fold: 11  Epoch: 739  Training loss = 4.0160  Validation loss = 3.5750  \n",
      "\n",
      "Fold: 11  Epoch: 740  Training loss = 4.0156  Validation loss = 3.5748  \n",
      "\n",
      "Fold: 11  Epoch: 741  Training loss = 4.0153  Validation loss = 3.5745  \n",
      "\n",
      "Fold: 11  Epoch: 742  Training loss = 4.0150  Validation loss = 3.5742  \n",
      "\n",
      "Fold: 11  Epoch: 743  Training loss = 4.0146  Validation loss = 3.5739  \n",
      "\n",
      "Fold: 11  Epoch: 744  Training loss = 4.0142  Validation loss = 3.5736  \n",
      "\n",
      "Fold: 11  Epoch: 745  Training loss = 4.0139  Validation loss = 3.5734  \n",
      "\n",
      "Fold: 11  Epoch: 746  Training loss = 4.0136  Validation loss = 3.5731  \n",
      "\n",
      "Fold: 11  Epoch: 747  Training loss = 4.0134  Validation loss = 3.5729  \n",
      "\n",
      "Fold: 11  Epoch: 748  Training loss = 4.0130  Validation loss = 3.5727  \n",
      "\n",
      "Fold: 11  Epoch: 749  Training loss = 4.0127  Validation loss = 3.5724  \n",
      "\n",
      "Fold: 11  Epoch: 750  Training loss = 4.0124  Validation loss = 3.5721  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 750  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 4.0995  Validation loss = 5.0927  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 4.0992  Validation loss = 5.0923  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 4.0988  Validation loss = 5.0919  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 4.0985  Validation loss = 5.0915  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 4.0980  Validation loss = 5.0909  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 4.0977  Validation loss = 5.0906  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 4.0974  Validation loss = 5.0901  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 4.0970  Validation loss = 5.0897  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 4.0966  Validation loss = 5.0891  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 4.0961  Validation loss = 5.0885  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 4.0957  Validation loss = 5.0881  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 4.0952  Validation loss = 5.0875  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 4.0947  Validation loss = 5.0868  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 4.0945  Validation loss = 5.0865  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 4.0940  Validation loss = 5.0860  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 4.0938  Validation loss = 5.0858  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 4.0933  Validation loss = 5.0852  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 4.0928  Validation loss = 5.0845  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 4.0924  Validation loss = 5.0840  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 4.0920  Validation loss = 5.0836  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 4.0916  Validation loss = 5.0831  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 4.0912  Validation loss = 5.0827  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 4.0909  Validation loss = 5.0823  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 4.0906  Validation loss = 5.0820  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 4.0903  Validation loss = 5.0816  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 4.0898  Validation loss = 5.0811  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 4.0896  Validation loss = 5.0808  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 4.0893  Validation loss = 5.0805  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 4.0889  Validation loss = 5.0801  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 4.0886  Validation loss = 5.0797  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 4.0884  Validation loss = 5.0795  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 4.0881  Validation loss = 5.0791  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 4.0877  Validation loss = 5.0786  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 4.0873  Validation loss = 5.0781  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 4.0870  Validation loss = 5.0777  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 4.0866  Validation loss = 5.0774  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 4.0863  Validation loss = 5.0770  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 4.0860  Validation loss = 5.0766  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 4.0855  Validation loss = 5.0761  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 4.0852  Validation loss = 5.0758  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 4.0850  Validation loss = 5.0755  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 4.0848  Validation loss = 5.0752  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 4.0844  Validation loss = 5.0748  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 4.0840  Validation loss = 5.0744  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 4.0839  Validation loss = 5.0742  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 4.0835  Validation loss = 5.0737  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 4.0833  Validation loss = 5.0734  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 4.0829  Validation loss = 5.0730  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 4.0826  Validation loss = 5.0726  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 4.0823  Validation loss = 5.0722  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 4.0820  Validation loss = 5.0718  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 4.0816  Validation loss = 5.0714  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 4.0812  Validation loss = 5.0709  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 4.0807  Validation loss = 5.0704  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 4.0805  Validation loss = 5.0701  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 4.0801  Validation loss = 5.0696  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 4.0797  Validation loss = 5.0692  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 4.0793  Validation loss = 5.0688  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 4.0790  Validation loss = 5.0684  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 4.0785  Validation loss = 5.0679  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 4.0782  Validation loss = 5.0675  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 4.0778  Validation loss = 5.0671  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 4.0775  Validation loss = 5.0667  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 4.0772  Validation loss = 5.0663  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 4.0768  Validation loss = 5.0658  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 4.0765  Validation loss = 5.0655  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 4.0761  Validation loss = 5.0650  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 4.0759  Validation loss = 5.0648  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 4.0755  Validation loss = 5.0644  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 4.0752  Validation loss = 5.0641  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 4.0749  Validation loss = 5.0636  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 4.0745  Validation loss = 5.0632  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 4.0742  Validation loss = 5.0628  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 4.0738  Validation loss = 5.0623  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 4.0735  Validation loss = 5.0619  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 4.0732  Validation loss = 5.0615  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 4.0730  Validation loss = 5.0612  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 4.0728  Validation loss = 5.0610  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 4.0725  Validation loss = 5.0607  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 4.0723  Validation loss = 5.0604  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 4.0720  Validation loss = 5.0600  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 4.0716  Validation loss = 5.0595  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 4.0714  Validation loss = 5.0592  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 4.0710  Validation loss = 5.0588  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 4.0707  Validation loss = 5.0584  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 4.0704  Validation loss = 5.0580  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 4.0700  Validation loss = 5.0576  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 4.0698  Validation loss = 5.0573  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 4.0694  Validation loss = 5.0569  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 4.0693  Validation loss = 5.0567  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 4.0689  Validation loss = 5.0563  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 4.0686  Validation loss = 5.0559  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 4.0684  Validation loss = 5.0556  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 4.0680  Validation loss = 5.0553  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 4.0678  Validation loss = 5.0549  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 4.0675  Validation loss = 5.0546  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 4.0671  Validation loss = 5.0542  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 4.0669  Validation loss = 5.0538  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 4.0667  Validation loss = 5.0535  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 4.0664  Validation loss = 5.0532  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 4.0659  Validation loss = 5.0527  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 4.0657  Validation loss = 5.0523  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 4.0653  Validation loss = 5.0519  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 4.0650  Validation loss = 5.0515  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 4.0648  Validation loss = 5.0512  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 4.0646  Validation loss = 5.0509  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 4.0644  Validation loss = 5.0507  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 4.0640  Validation loss = 5.0502  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 4.0637  Validation loss = 5.0499  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 4.0633  Validation loss = 5.0495  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 4.0629  Validation loss = 5.0490  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 4.0627  Validation loss = 5.0486  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 4.0624  Validation loss = 5.0482  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 4.0621  Validation loss = 5.0479  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 4.0618  Validation loss = 5.0476  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 4.0616  Validation loss = 5.0473  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 4.0613  Validation loss = 5.0469  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 4.0610  Validation loss = 5.0466  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 4.0608  Validation loss = 5.0463  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 4.0605  Validation loss = 5.0460  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 4.0603  Validation loss = 5.0458  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 4.0601  Validation loss = 5.0455  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 4.0598  Validation loss = 5.0452  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 4.0595  Validation loss = 5.0448  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 4.0593  Validation loss = 5.0445  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 4.0590  Validation loss = 5.0441  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 4.0588  Validation loss = 5.0438  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 4.0586  Validation loss = 5.0436  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 4.0583  Validation loss = 5.0433  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 4.0580  Validation loss = 5.0429  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 4.0578  Validation loss = 5.0426  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 4.0574  Validation loss = 5.0421  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 4.0572  Validation loss = 5.0418  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 4.0568  Validation loss = 5.0414  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 4.0566  Validation loss = 5.0411  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 4.0562  Validation loss = 5.0407  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 4.0559  Validation loss = 5.0403  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 4.0557  Validation loss = 5.0401  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 4.0555  Validation loss = 5.0398  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 4.0553  Validation loss = 5.0395  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 4.0550  Validation loss = 5.0391  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 4.0547  Validation loss = 5.0388  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 4.0545  Validation loss = 5.0385  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 4.0542  Validation loss = 5.0381  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 4.0540  Validation loss = 5.0378  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 4.0538  Validation loss = 5.0375  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 4.0535  Validation loss = 5.0371  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 4.0532  Validation loss = 5.0368  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 4.0529  Validation loss = 5.0365  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 4.0526  Validation loss = 5.0361  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 4.0524  Validation loss = 5.0358  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 4.0521  Validation loss = 5.0354  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 4.0519  Validation loss = 5.0350  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 4.0516  Validation loss = 5.0347  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 4.0514  Validation loss = 5.0345  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 4.0510  Validation loss = 5.0340  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 4.0509  Validation loss = 5.0338  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 4.0506  Validation loss = 5.0335  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 4.0503  Validation loss = 5.0332  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 4.0501  Validation loss = 5.0329  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 4.0498  Validation loss = 5.0325  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 4.0495  Validation loss = 5.0322  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 4.0492  Validation loss = 5.0318  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 4.0490  Validation loss = 5.0315  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 4.0487  Validation loss = 5.0311  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 4.0485  Validation loss = 5.0308  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 4.0482  Validation loss = 5.0304  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 4.0480  Validation loss = 5.0301  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 4.0477  Validation loss = 5.0297  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 4.0474  Validation loss = 5.0292  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 4.0472  Validation loss = 5.0289  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 4.0469  Validation loss = 5.0286  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 4.0467  Validation loss = 5.0282  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 4.0464  Validation loss = 5.0279  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 4.0462  Validation loss = 5.0275  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 4.0460  Validation loss = 5.0273  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 4.0457  Validation loss = 5.0270  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 4.0455  Validation loss = 5.0267  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 4.0452  Validation loss = 5.0263  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 4.0450  Validation loss = 5.0260  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 4.0448  Validation loss = 5.0258  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 4.0447  Validation loss = 5.0256  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 4.0444  Validation loss = 5.0251  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 4.0441  Validation loss = 5.0248  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 4.0439  Validation loss = 5.0245  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 4.0436  Validation loss = 5.0241  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 4.0434  Validation loss = 5.0238  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 4.0431  Validation loss = 5.0234  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 4.0428  Validation loss = 5.0231  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 4.0426  Validation loss = 5.0228  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 4.0423  Validation loss = 5.0224  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 4.0421  Validation loss = 5.0221  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 4.0419  Validation loss = 5.0218  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 4.0417  Validation loss = 5.0216  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 4.0415  Validation loss = 5.0212  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 4.0412  Validation loss = 5.0209  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 4.0410  Validation loss = 5.0207  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 4.0408  Validation loss = 5.0203  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 4.0405  Validation loss = 5.0200  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 4.0403  Validation loss = 5.0197  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 4.0400  Validation loss = 5.0193  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 4.0397  Validation loss = 5.0189  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 4.0395  Validation loss = 5.0186  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 4.0393  Validation loss = 5.0183  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 4.0390  Validation loss = 5.0180  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 4.0387  Validation loss = 5.0176  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 4.0385  Validation loss = 5.0173  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 4.0383  Validation loss = 5.0170  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 4.0381  Validation loss = 5.0167  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 4.0378  Validation loss = 5.0164  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 4.0376  Validation loss = 5.0162  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 4.0374  Validation loss = 5.0159  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 4.0371  Validation loss = 5.0155  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 4.0369  Validation loss = 5.0152  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 4.0367  Validation loss = 5.0149  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 4.0364  Validation loss = 5.0145  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 4.0363  Validation loss = 5.0143  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 4.0360  Validation loss = 5.0140  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 4.0359  Validation loss = 5.0137  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 4.0357  Validation loss = 5.0135  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 4.0354  Validation loss = 5.0131  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 4.0351  Validation loss = 5.0127  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 4.0348  Validation loss = 5.0123  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 4.0346  Validation loss = 5.0121  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 4.0345  Validation loss = 5.0119  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 4.0342  Validation loss = 5.0115  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 4.0341  Validation loss = 5.0113  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 4.0339  Validation loss = 5.0110  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 4.0336  Validation loss = 5.0105  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 4.0334  Validation loss = 5.0103  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 4.0332  Validation loss = 5.0100  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 4.0329  Validation loss = 5.0097  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 4.0327  Validation loss = 5.0094  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 4.0324  Validation loss = 5.0089  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 4.0323  Validation loss = 5.0087  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 4.0320  Validation loss = 5.0083  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 4.0318  Validation loss = 5.0081  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 4.0316  Validation loss = 5.0078  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 4.0313  Validation loss = 5.0075  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 4.0311  Validation loss = 5.0072  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 4.0309  Validation loss = 5.0068  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 4.0307  Validation loss = 5.0065  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 4.0305  Validation loss = 5.0063  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 4.0301  Validation loss = 5.0057  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 4.0299  Validation loss = 5.0054  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 4.0297  Validation loss = 5.0052  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 4.0295  Validation loss = 5.0048  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 4.0293  Validation loss = 5.0045  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 4.0291  Validation loss = 5.0043  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 4.0288  Validation loss = 5.0039  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 4.0286  Validation loss = 5.0036  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 4.0284  Validation loss = 5.0033  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 4.0282  Validation loss = 5.0030  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 4.0279  Validation loss = 5.0027  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 4.0277  Validation loss = 5.0023  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 4.0275  Validation loss = 5.0020  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 4.0273  Validation loss = 5.0018  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 4.0270  Validation loss = 5.0014  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 4.0268  Validation loss = 5.0012  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 4.0266  Validation loss = 5.0009  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 4.0264  Validation loss = 5.0006  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 4.0261  Validation loss = 5.0001  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 4.0258  Validation loss = 4.9998  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 4.0256  Validation loss = 4.9994  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 4.0254  Validation loss = 4.9992  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 4.0252  Validation loss = 4.9988  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 4.0250  Validation loss = 4.9985  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 4.0247  Validation loss = 4.9981  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 4.0245  Validation loss = 4.9977  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 4.0242  Validation loss = 4.9973  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 4.0240  Validation loss = 4.9971  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 4.0237  Validation loss = 4.9967  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 4.0235  Validation loss = 4.9963  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 4.0232  Validation loss = 4.9958  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 4.0230  Validation loss = 4.9956  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 4.0227  Validation loss = 4.9952  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 4.0225  Validation loss = 4.9949  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 4.0223  Validation loss = 4.9945  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 4.0221  Validation loss = 4.9942  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 4.0219  Validation loss = 4.9939  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 4.0217  Validation loss = 4.9938  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 4.0215  Validation loss = 4.9935  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 4.0213  Validation loss = 4.9932  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 4.0211  Validation loss = 4.9929  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 4.0208  Validation loss = 4.9926  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 4.0206  Validation loss = 4.9923  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 4.0205  Validation loss = 4.9921  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 4.0202  Validation loss = 4.9918  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 4.0200  Validation loss = 4.9915  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 4.0198  Validation loss = 4.9910  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 4.0196  Validation loss = 4.9908  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 4.0194  Validation loss = 4.9905  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 4.0192  Validation loss = 4.9901  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 4.0189  Validation loss = 4.9898  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 4.0187  Validation loss = 4.9894  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 4.0185  Validation loss = 4.9891  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 4.0182  Validation loss = 4.9887  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 4.0180  Validation loss = 4.9885  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 4.0179  Validation loss = 4.9883  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 4.0177  Validation loss = 4.9880  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 4.0175  Validation loss = 4.9876  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 4.0172  Validation loss = 4.9872  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 4.0170  Validation loss = 4.9869  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 4.0168  Validation loss = 4.9866  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 4.0165  Validation loss = 4.9863  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 4.0163  Validation loss = 4.9859  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 4.0160  Validation loss = 4.9855  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 4.0157  Validation loss = 4.9850  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 4.0155  Validation loss = 4.9847  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 4.0153  Validation loss = 4.9844  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 4.0151  Validation loss = 4.9840  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 4.0148  Validation loss = 4.9837  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 4.0147  Validation loss = 4.9835  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 4.0145  Validation loss = 4.9832  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 4.0143  Validation loss = 4.9829  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 4.0141  Validation loss = 4.9826  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 4.0138  Validation loss = 4.9823  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 4.0137  Validation loss = 4.9821  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 4.0134  Validation loss = 4.9817  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 4.0132  Validation loss = 4.9815  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 4.0130  Validation loss = 4.9811  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 4.0128  Validation loss = 4.9808  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 4.0126  Validation loss = 4.9805  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 4.0123  Validation loss = 4.9802  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 4.0122  Validation loss = 4.9800  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 4.0120  Validation loss = 4.9796  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 4.0117  Validation loss = 4.9793  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 4.0115  Validation loss = 4.9790  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 4.0113  Validation loss = 4.9785  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 4.0110  Validation loss = 4.9782  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 4.0108  Validation loss = 4.9778  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 4.0106  Validation loss = 4.9775  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 4.0103  Validation loss = 4.9771  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 4.0101  Validation loss = 4.9769  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 4.0099  Validation loss = 4.9765  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 4.0097  Validation loss = 4.9762  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 4.0095  Validation loss = 4.9759  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 4.0093  Validation loss = 4.9757  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 4.0091  Validation loss = 4.9754  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 4.0089  Validation loss = 4.9751  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 4.0087  Validation loss = 4.9748  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 4.0085  Validation loss = 4.9745  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 4.0083  Validation loss = 4.9743  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 4.0081  Validation loss = 4.9740  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 4.0079  Validation loss = 4.9737  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 4.0077  Validation loss = 4.9734  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 4.0075  Validation loss = 4.9731  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 4.0073  Validation loss = 4.9728  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 4.0071  Validation loss = 4.9725  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 4.0069  Validation loss = 4.9721  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 4.0067  Validation loss = 4.9719  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 4.0064  Validation loss = 4.9716  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 4.0062  Validation loss = 4.9714  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 4.0061  Validation loss = 4.9712  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 4.0058  Validation loss = 4.9708  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 4.0056  Validation loss = 4.9703  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 4.0053  Validation loss = 4.9700  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 4.0051  Validation loss = 4.9696  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 4.0048  Validation loss = 4.9692  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 4.0046  Validation loss = 4.9689  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 4.0044  Validation loss = 4.9686  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 4.0042  Validation loss = 4.9684  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 4.0039  Validation loss = 4.9680  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 4.0038  Validation loss = 4.9677  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 4.0035  Validation loss = 4.9673  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 4.0033  Validation loss = 4.9670  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 4.0031  Validation loss = 4.9667  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 4.0028  Validation loss = 4.9663  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 4.0026  Validation loss = 4.9659  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 4.0024  Validation loss = 4.9656  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 4.0021  Validation loss = 4.9651  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 4.0018  Validation loss = 4.9647  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 4.0016  Validation loss = 4.9645  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 4.0014  Validation loss = 4.9642  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 4.0012  Validation loss = 4.9637  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 4.0009  Validation loss = 4.9633  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 4.0008  Validation loss = 4.9631  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 4.0005  Validation loss = 4.9628  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 4.0003  Validation loss = 4.9624  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 4.0002  Validation loss = 4.9623  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 4.0000  Validation loss = 4.9619  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 3.9997  Validation loss = 4.9616  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 3.9995  Validation loss = 4.9613  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 3.9994  Validation loss = 4.9612  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 3.9992  Validation loss = 4.9608  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 3.9989  Validation loss = 4.9604  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 3.9988  Validation loss = 4.9602  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 3.9986  Validation loss = 4.9599  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 3.9983  Validation loss = 4.9594  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 3.9981  Validation loss = 4.9591  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 3.9978  Validation loss = 4.9586  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 3.9976  Validation loss = 4.9583  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 3.9974  Validation loss = 4.9580  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 3.9972  Validation loss = 4.9578  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 3.9969  Validation loss = 4.9574  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 3.9967  Validation loss = 4.9570  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 3.9966  Validation loss = 4.9569  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 3.9964  Validation loss = 4.9567  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 3.9961  Validation loss = 4.9562  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 3.9959  Validation loss = 4.9560  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 3.9956  Validation loss = 4.9557  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 3.9954  Validation loss = 4.9554  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 3.9952  Validation loss = 4.9552  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 3.9950  Validation loss = 4.9549  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 3.9949  Validation loss = 4.9547  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 3.9947  Validation loss = 4.9545  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 3.9945  Validation loss = 4.9542  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 3.9943  Validation loss = 4.9538  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 3.9941  Validation loss = 4.9536  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 3.9939  Validation loss = 4.9532  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 3.9937  Validation loss = 4.9529  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 3.9935  Validation loss = 4.9527  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 3.9933  Validation loss = 4.9524  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 3.9932  Validation loss = 4.9522  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 3.9929  Validation loss = 4.9518  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 3.9927  Validation loss = 4.9515  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 3.9925  Validation loss = 4.9513  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 3.9923  Validation loss = 4.9508  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 3.9920  Validation loss = 4.9504  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 3.9918  Validation loss = 4.9501  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 3.9916  Validation loss = 4.9498  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 3.9914  Validation loss = 4.9496  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 3.9912  Validation loss = 4.9493  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 3.9910  Validation loss = 4.9490  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 3.9908  Validation loss = 4.9487  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 3.9906  Validation loss = 4.9484  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 3.9904  Validation loss = 4.9480  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 3.9902  Validation loss = 4.9477  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 3.9900  Validation loss = 4.9474  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 3.9898  Validation loss = 4.9471  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 3.9895  Validation loss = 4.9467  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 3.9894  Validation loss = 4.9465  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 3.9892  Validation loss = 4.9463  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 3.9891  Validation loss = 4.9461  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 3.9889  Validation loss = 4.9459  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 3.9887  Validation loss = 4.9455  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 3.9884  Validation loss = 4.9452  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 3.9882  Validation loss = 4.9448  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 3.9879  Validation loss = 4.9445  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 3.9877  Validation loss = 4.9442  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 3.9875  Validation loss = 4.9437  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 3.9872  Validation loss = 4.9434  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 3.9870  Validation loss = 4.9432  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 3.9868  Validation loss = 4.9428  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 3.9867  Validation loss = 4.9426  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 3.9864  Validation loss = 4.9421  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 3.9861  Validation loss = 4.9417  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 3.9859  Validation loss = 4.9414  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 3.9857  Validation loss = 4.9411  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 3.9855  Validation loss = 4.9408  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 3.9852  Validation loss = 4.9404  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 3.9851  Validation loss = 4.9402  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 3.9848  Validation loss = 4.9400  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 3.9847  Validation loss = 4.9397  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 3.9845  Validation loss = 4.9394  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 3.9843  Validation loss = 4.9392  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 3.9841  Validation loss = 4.9389  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 3.9838  Validation loss = 4.9385  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 3.9836  Validation loss = 4.9381  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 3.9834  Validation loss = 4.9378  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 3.9832  Validation loss = 4.9376  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 3.9830  Validation loss = 4.9372  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 3.9827  Validation loss = 4.9368  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 3.9824  Validation loss = 4.9364  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 3.9823  Validation loss = 4.9362  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 3.9821  Validation loss = 4.9359  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 3.9819  Validation loss = 4.9356  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 3.9817  Validation loss = 4.9354  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 3.9815  Validation loss = 4.9351  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 3.9813  Validation loss = 4.9349  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 3.9811  Validation loss = 4.9346  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 3.9809  Validation loss = 4.9342  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 3.9807  Validation loss = 4.9339  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 3.9804  Validation loss = 4.9335  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 3.9802  Validation loss = 4.9331  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 3.9800  Validation loss = 4.9329  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 3.9798  Validation loss = 4.9327  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 3.9796  Validation loss = 4.9323  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 3.9794  Validation loss = 4.9320  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 3.9792  Validation loss = 4.9317  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 3.9789  Validation loss = 4.9313  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 3.9787  Validation loss = 4.9309  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 3.9784  Validation loss = 4.9305  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 3.9782  Validation loss = 4.9302  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 3.9780  Validation loss = 4.9299  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 3.9777  Validation loss = 4.9295  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 3.9775  Validation loss = 4.9291  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 3.9773  Validation loss = 4.9288  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 3.9771  Validation loss = 4.9285  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 3.9768  Validation loss = 4.9281  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 3.9766  Validation loss = 4.9277  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 3.9763  Validation loss = 4.9272  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 3.9762  Validation loss = 4.9270  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 3.9760  Validation loss = 4.9267  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 3.9758  Validation loss = 4.9264  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 3.9755  Validation loss = 4.9261  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 3.9752  Validation loss = 4.9255  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 3.9750  Validation loss = 4.9252  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 3.9748  Validation loss = 4.9249  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 3.9745  Validation loss = 4.9245  \n",
      "\n",
      "Fold: 12  Epoch: 501  Training loss = 3.9743  Validation loss = 4.9242  \n",
      "\n",
      "Fold: 12  Epoch: 502  Training loss = 3.9741  Validation loss = 4.9238  \n",
      "\n",
      "Fold: 12  Epoch: 503  Training loss = 3.9738  Validation loss = 4.9235  \n",
      "\n",
      "Fold: 12  Epoch: 504  Training loss = 3.9736  Validation loss = 4.9231  \n",
      "\n",
      "Fold: 12  Epoch: 505  Training loss = 3.9733  Validation loss = 4.9227  \n",
      "\n",
      "Fold: 12  Epoch: 506  Training loss = 3.9730  Validation loss = 4.9222  \n",
      "\n",
      "Fold: 12  Epoch: 507  Training loss = 3.9727  Validation loss = 4.9217  \n",
      "\n",
      "Fold: 12  Epoch: 508  Training loss = 3.9725  Validation loss = 4.9213  \n",
      "\n",
      "Fold: 12  Epoch: 509  Training loss = 3.9722  Validation loss = 4.9210  \n",
      "\n",
      "Fold: 12  Epoch: 510  Training loss = 3.9720  Validation loss = 4.9206  \n",
      "\n",
      "Fold: 12  Epoch: 511  Training loss = 3.9718  Validation loss = 4.9203  \n",
      "\n",
      "Fold: 12  Epoch: 512  Training loss = 3.9716  Validation loss = 4.9201  \n",
      "\n",
      "Fold: 12  Epoch: 513  Training loss = 3.9714  Validation loss = 4.9198  \n",
      "\n",
      "Fold: 12  Epoch: 514  Training loss = 3.9712  Validation loss = 4.9195  \n",
      "\n",
      "Fold: 12  Epoch: 515  Training loss = 3.9709  Validation loss = 4.9191  \n",
      "\n",
      "Fold: 12  Epoch: 516  Training loss = 3.9707  Validation loss = 4.9187  \n",
      "\n",
      "Fold: 12  Epoch: 517  Training loss = 3.9705  Validation loss = 4.9185  \n",
      "\n",
      "Fold: 12  Epoch: 518  Training loss = 3.9702  Validation loss = 4.9180  \n",
      "\n",
      "Fold: 12  Epoch: 519  Training loss = 3.9699  Validation loss = 4.9177  \n",
      "\n",
      "Fold: 12  Epoch: 520  Training loss = 3.9697  Validation loss = 4.9173  \n",
      "\n",
      "Fold: 12  Epoch: 521  Training loss = 3.9695  Validation loss = 4.9170  \n",
      "\n",
      "Fold: 12  Epoch: 522  Training loss = 3.9693  Validation loss = 4.9167  \n",
      "\n",
      "Fold: 12  Epoch: 523  Training loss = 3.9690  Validation loss = 4.9163  \n",
      "\n",
      "Fold: 12  Epoch: 524  Training loss = 3.9688  Validation loss = 4.9160  \n",
      "\n",
      "Fold: 12  Epoch: 525  Training loss = 3.9685  Validation loss = 4.9155  \n",
      "\n",
      "Fold: 12  Epoch: 526  Training loss = 3.9682  Validation loss = 4.9151  \n",
      "\n",
      "Fold: 12  Epoch: 527  Training loss = 3.9680  Validation loss = 4.9147  \n",
      "\n",
      "Fold: 12  Epoch: 528  Training loss = 3.9678  Validation loss = 4.9145  \n",
      "\n",
      "Fold: 12  Epoch: 529  Training loss = 3.9676  Validation loss = 4.9142  \n",
      "\n",
      "Fold: 12  Epoch: 530  Training loss = 3.9674  Validation loss = 4.9139  \n",
      "\n",
      "Fold: 12  Epoch: 531  Training loss = 3.9672  Validation loss = 4.9135  \n",
      "\n",
      "Fold: 12  Epoch: 532  Training loss = 3.9670  Validation loss = 4.9132  \n",
      "\n",
      "Fold: 12  Epoch: 533  Training loss = 3.9668  Validation loss = 4.9129  \n",
      "\n",
      "Fold: 12  Epoch: 534  Training loss = 3.9666  Validation loss = 4.9125  \n",
      "\n",
      "Fold: 12  Epoch: 535  Training loss = 3.9663  Validation loss = 4.9122  \n",
      "\n",
      "Fold: 12  Epoch: 536  Training loss = 3.9660  Validation loss = 4.9118  \n",
      "\n",
      "Fold: 12  Epoch: 537  Training loss = 3.9658  Validation loss = 4.9114  \n",
      "\n",
      "Fold: 12  Epoch: 538  Training loss = 3.9656  Validation loss = 4.9112  \n",
      "\n",
      "Fold: 12  Epoch: 539  Training loss = 3.9653  Validation loss = 4.9107  \n",
      "\n",
      "Fold: 12  Epoch: 540  Training loss = 3.9651  Validation loss = 4.9104  \n",
      "\n",
      "Fold: 12  Epoch: 541  Training loss = 3.9648  Validation loss = 4.9100  \n",
      "\n",
      "Fold: 12  Epoch: 542  Training loss = 3.9646  Validation loss = 4.9098  \n",
      "\n",
      "Fold: 12  Epoch: 543  Training loss = 3.9644  Validation loss = 4.9095  \n",
      "\n",
      "Fold: 12  Epoch: 544  Training loss = 3.9642  Validation loss = 4.9091  \n",
      "\n",
      "Fold: 12  Epoch: 545  Training loss = 3.9640  Validation loss = 4.9089  \n",
      "\n",
      "Fold: 12  Epoch: 546  Training loss = 3.9638  Validation loss = 4.9086  \n",
      "\n",
      "Fold: 12  Epoch: 547  Training loss = 3.9636  Validation loss = 4.9083  \n",
      "\n",
      "Fold: 12  Epoch: 548  Training loss = 3.9634  Validation loss = 4.9080  \n",
      "\n",
      "Fold: 12  Epoch: 549  Training loss = 3.9631  Validation loss = 4.9077  \n",
      "\n",
      "Fold: 12  Epoch: 550  Training loss = 3.9629  Validation loss = 4.9075  \n",
      "\n",
      "Fold: 12  Epoch: 551  Training loss = 3.9627  Validation loss = 4.9072  \n",
      "\n",
      "Fold: 12  Epoch: 552  Training loss = 3.9625  Validation loss = 4.9069  \n",
      "\n",
      "Fold: 12  Epoch: 553  Training loss = 3.9623  Validation loss = 4.9067  \n",
      "\n",
      "Fold: 12  Epoch: 554  Training loss = 3.9621  Validation loss = 4.9063  \n",
      "\n",
      "Fold: 12  Epoch: 555  Training loss = 3.9618  Validation loss = 4.9060  \n",
      "\n",
      "Fold: 12  Epoch: 556  Training loss = 3.9616  Validation loss = 4.9056  \n",
      "\n",
      "Fold: 12  Epoch: 557  Training loss = 3.9613  Validation loss = 4.9052  \n",
      "\n",
      "Fold: 12  Epoch: 558  Training loss = 3.9611  Validation loss = 4.9049  \n",
      "\n",
      "Fold: 12  Epoch: 559  Training loss = 3.9609  Validation loss = 4.9046  \n",
      "\n",
      "Fold: 12  Epoch: 560  Training loss = 3.9607  Validation loss = 4.9044  \n",
      "\n",
      "Fold: 12  Epoch: 561  Training loss = 3.9605  Validation loss = 4.9041  \n",
      "\n",
      "Fold: 12  Epoch: 562  Training loss = 3.9603  Validation loss = 4.9038  \n",
      "\n",
      "Fold: 12  Epoch: 563  Training loss = 3.9600  Validation loss = 4.9034  \n",
      "\n",
      "Fold: 12  Epoch: 564  Training loss = 3.9597  Validation loss = 4.9030  \n",
      "\n",
      "Fold: 12  Epoch: 565  Training loss = 3.9596  Validation loss = 4.9028  \n",
      "\n",
      "Fold: 12  Epoch: 566  Training loss = 3.9594  Validation loss = 4.9025  \n",
      "\n",
      "Fold: 12  Epoch: 567  Training loss = 3.9592  Validation loss = 4.9023  \n",
      "\n",
      "Fold: 12  Epoch: 568  Training loss = 3.9590  Validation loss = 4.9020  \n",
      "\n",
      "Fold: 12  Epoch: 569  Training loss = 3.9587  Validation loss = 4.9016  \n",
      "\n",
      "Fold: 12  Epoch: 570  Training loss = 3.9585  Validation loss = 4.9014  \n",
      "\n",
      "Fold: 12  Epoch: 571  Training loss = 3.9583  Validation loss = 4.9011  \n",
      "\n",
      "Fold: 12  Epoch: 572  Training loss = 3.9580  Validation loss = 4.9007  \n",
      "\n",
      "Fold: 12  Epoch: 573  Training loss = 3.9579  Validation loss = 4.9005  \n",
      "\n",
      "Fold: 12  Epoch: 574  Training loss = 3.9576  Validation loss = 4.9000  \n",
      "\n",
      "Fold: 12  Epoch: 575  Training loss = 3.9573  Validation loss = 4.8997  \n",
      "\n",
      "Fold: 12  Epoch: 576  Training loss = 3.9572  Validation loss = 4.8995  \n",
      "\n",
      "Fold: 12  Epoch: 577  Training loss = 3.9569  Validation loss = 4.8990  \n",
      "\n",
      "Fold: 12  Epoch: 578  Training loss = 3.9567  Validation loss = 4.8987  \n",
      "\n",
      "Fold: 12  Epoch: 579  Training loss = 3.9564  Validation loss = 4.8984  \n",
      "\n",
      "Fold: 12  Epoch: 580  Training loss = 3.9563  Validation loss = 4.8982  \n",
      "\n",
      "Fold: 12  Epoch: 581  Training loss = 3.9561  Validation loss = 4.8980  \n",
      "\n",
      "Fold: 12  Epoch: 582  Training loss = 3.9558  Validation loss = 4.8977  \n",
      "\n",
      "Fold: 12  Epoch: 583  Training loss = 3.9557  Validation loss = 4.8974  \n",
      "\n",
      "Fold: 12  Epoch: 584  Training loss = 3.9554  Validation loss = 4.8971  \n",
      "\n",
      "Fold: 12  Epoch: 585  Training loss = 3.9552  Validation loss = 4.8968  \n",
      "\n",
      "Fold: 12  Epoch: 586  Training loss = 3.9550  Validation loss = 4.8966  \n",
      "\n",
      "Fold: 12  Epoch: 587  Training loss = 3.9548  Validation loss = 4.8963  \n",
      "\n",
      "Fold: 12  Epoch: 588  Training loss = 3.9546  Validation loss = 4.8959  \n",
      "\n",
      "Fold: 12  Epoch: 589  Training loss = 3.9543  Validation loss = 4.8956  \n",
      "\n",
      "Fold: 12  Epoch: 590  Training loss = 3.9541  Validation loss = 4.8953  \n",
      "\n",
      "Fold: 12  Epoch: 591  Training loss = 3.9539  Validation loss = 4.8950  \n",
      "\n",
      "Fold: 12  Epoch: 592  Training loss = 3.9537  Validation loss = 4.8947  \n",
      "\n",
      "Fold: 12  Epoch: 593  Training loss = 3.9534  Validation loss = 4.8942  \n",
      "\n",
      "Fold: 12  Epoch: 594  Training loss = 3.9531  Validation loss = 4.8939  \n",
      "\n",
      "Fold: 12  Epoch: 595  Training loss = 3.9528  Validation loss = 4.8933  \n",
      "\n",
      "Fold: 12  Epoch: 596  Training loss = 3.9526  Validation loss = 4.8930  \n",
      "\n",
      "Fold: 12  Epoch: 597  Training loss = 3.9522  Validation loss = 4.8926  \n",
      "\n",
      "Fold: 12  Epoch: 598  Training loss = 3.9520  Validation loss = 4.8924  \n",
      "\n",
      "Fold: 12  Epoch: 599  Training loss = 3.9518  Validation loss = 4.8920  \n",
      "\n",
      "Fold: 12  Epoch: 600  Training loss = 3.9516  Validation loss = 4.8919  \n",
      "\n",
      "Fold: 12  Epoch: 601  Training loss = 3.9514  Validation loss = 4.8915  \n",
      "\n",
      "Fold: 12  Epoch: 602  Training loss = 3.9511  Validation loss = 4.8911  \n",
      "\n",
      "Fold: 12  Epoch: 603  Training loss = 3.9509  Validation loss = 4.8909  \n",
      "\n",
      "Fold: 12  Epoch: 604  Training loss = 3.9506  Validation loss = 4.8905  \n",
      "\n",
      "Fold: 12  Epoch: 605  Training loss = 3.9504  Validation loss = 4.8902  \n",
      "\n",
      "Fold: 12  Epoch: 606  Training loss = 3.9502  Validation loss = 4.8900  \n",
      "\n",
      "Fold: 12  Epoch: 607  Training loss = 3.9498  Validation loss = 4.8893  \n",
      "\n",
      "Fold: 12  Epoch: 608  Training loss = 3.9496  Validation loss = 4.8891  \n",
      "\n",
      "Fold: 12  Epoch: 609  Training loss = 3.9494  Validation loss = 4.8888  \n",
      "\n",
      "Fold: 12  Epoch: 610  Training loss = 3.9492  Validation loss = 4.8885  \n",
      "\n",
      "Fold: 12  Epoch: 611  Training loss = 3.9490  Validation loss = 4.8883  \n",
      "\n",
      "Fold: 12  Epoch: 612  Training loss = 3.9487  Validation loss = 4.8879  \n",
      "\n",
      "Fold: 12  Epoch: 613  Training loss = 3.9485  Validation loss = 4.8876  \n",
      "\n",
      "Fold: 12  Epoch: 614  Training loss = 3.9482  Validation loss = 4.8872  \n",
      "\n",
      "Fold: 12  Epoch: 615  Training loss = 3.9479  Validation loss = 4.8868  \n",
      "\n",
      "Fold: 12  Epoch: 616  Training loss = 3.9476  Validation loss = 4.8865  \n",
      "\n",
      "Fold: 12  Epoch: 617  Training loss = 3.9474  Validation loss = 4.8861  \n",
      "\n",
      "Fold: 12  Epoch: 618  Training loss = 3.9470  Validation loss = 4.8858  \n",
      "\n",
      "Fold: 12  Epoch: 619  Training loss = 3.9467  Validation loss = 4.8854  \n",
      "\n",
      "Fold: 12  Epoch: 620  Training loss = 3.9465  Validation loss = 4.8851  \n",
      "\n",
      "Fold: 12  Epoch: 621  Training loss = 3.9462  Validation loss = 4.8847  \n",
      "\n",
      "Fold: 12  Epoch: 622  Training loss = 3.9458  Validation loss = 4.8844  \n",
      "\n",
      "Fold: 12  Epoch: 623  Training loss = 3.9456  Validation loss = 4.8841  \n",
      "\n",
      "Fold: 12  Epoch: 624  Training loss = 3.9453  Validation loss = 4.8837  \n",
      "\n",
      "Fold: 12  Epoch: 625  Training loss = 3.9451  Validation loss = 4.8834  \n",
      "\n",
      "Fold: 12  Epoch: 626  Training loss = 3.9449  Validation loss = 4.8830  \n",
      "\n",
      "Fold: 12  Epoch: 627  Training loss = 3.9446  Validation loss = 4.8827  \n",
      "\n",
      "Fold: 12  Epoch: 628  Training loss = 3.9443  Validation loss = 4.8824  \n",
      "\n",
      "Fold: 12  Epoch: 629  Training loss = 3.9440  Validation loss = 4.8821  \n",
      "\n",
      "Fold: 12  Epoch: 630  Training loss = 3.9438  Validation loss = 4.8818  \n",
      "\n",
      "Fold: 12  Epoch: 631  Training loss = 3.9436  Validation loss = 4.8815  \n",
      "\n",
      "Fold: 12  Epoch: 632  Training loss = 3.9434  Validation loss = 4.8812  \n",
      "\n",
      "Fold: 12  Epoch: 633  Training loss = 3.9432  Validation loss = 4.8810  \n",
      "\n",
      "Fold: 12  Epoch: 634  Training loss = 3.9430  Validation loss = 4.8807  \n",
      "\n",
      "Fold: 12  Epoch: 635  Training loss = 3.9428  Validation loss = 4.8805  \n",
      "\n",
      "Fold: 12  Epoch: 636  Training loss = 3.9426  Validation loss = 4.8803  \n",
      "\n",
      "Fold: 12  Epoch: 637  Training loss = 3.9423  Validation loss = 4.8799  \n",
      "\n",
      "Fold: 12  Epoch: 638  Training loss = 3.9422  Validation loss = 4.8798  \n",
      "\n",
      "Fold: 12  Epoch: 639  Training loss = 3.9420  Validation loss = 4.8795  \n",
      "\n",
      "Fold: 12  Epoch: 640  Training loss = 3.9418  Validation loss = 4.8792  \n",
      "\n",
      "Fold: 12  Epoch: 641  Training loss = 3.9415  Validation loss = 4.8789  \n",
      "\n",
      "Fold: 12  Epoch: 642  Training loss = 3.9412  Validation loss = 4.8786  \n",
      "\n",
      "Fold: 12  Epoch: 643  Training loss = 3.9410  Validation loss = 4.8782  \n",
      "\n",
      "Fold: 12  Epoch: 644  Training loss = 3.9407  Validation loss = 4.8778  \n",
      "\n",
      "Fold: 12  Epoch: 645  Training loss = 3.9403  Validation loss = 4.8774  \n",
      "\n",
      "Fold: 12  Epoch: 646  Training loss = 3.9400  Validation loss = 4.8771  \n",
      "\n",
      "Fold: 12  Epoch: 647  Training loss = 3.9397  Validation loss = 4.8768  \n",
      "\n",
      "Fold: 12  Epoch: 648  Training loss = 3.9393  Validation loss = 4.8764  \n",
      "\n",
      "Fold: 12  Epoch: 649  Training loss = 3.9391  Validation loss = 4.8761  \n",
      "\n",
      "Fold: 12  Epoch: 650  Training loss = 3.9388  Validation loss = 4.8757  \n",
      "\n",
      "Fold: 12  Epoch: 651  Training loss = 3.9386  Validation loss = 4.8754  \n",
      "\n",
      "Fold: 12  Epoch: 652  Training loss = 3.9384  Validation loss = 4.8751  \n",
      "\n",
      "Fold: 12  Epoch: 653  Training loss = 3.9381  Validation loss = 4.8747  \n",
      "\n",
      "Fold: 12  Epoch: 654  Training loss = 3.9378  Validation loss = 4.8745  \n",
      "\n",
      "Fold: 12  Epoch: 655  Training loss = 3.9376  Validation loss = 4.8743  \n",
      "\n",
      "Fold: 12  Epoch: 656  Training loss = 3.9374  Validation loss = 4.8740  \n",
      "\n",
      "Fold: 12  Epoch: 657  Training loss = 3.9370  Validation loss = 4.8736  \n",
      "\n",
      "Fold: 12  Epoch: 658  Training loss = 3.9369  Validation loss = 4.8735  \n",
      "\n",
      "Fold: 12  Epoch: 659  Training loss = 3.9366  Validation loss = 4.8731  \n",
      "\n",
      "Fold: 12  Epoch: 660  Training loss = 3.9363  Validation loss = 4.8728  \n",
      "\n",
      "Fold: 12  Epoch: 661  Training loss = 3.9360  Validation loss = 4.8724  \n",
      "\n",
      "Fold: 12  Epoch: 662  Training loss = 3.9357  Validation loss = 4.8721  \n",
      "\n",
      "Fold: 12  Epoch: 663  Training loss = 3.9352  Validation loss = 4.8717  \n",
      "\n",
      "Fold: 12  Epoch: 664  Training loss = 3.9350  Validation loss = 4.8715  \n",
      "\n",
      "Fold: 12  Epoch: 665  Training loss = 3.9346  Validation loss = 4.8711  \n",
      "\n",
      "Fold: 12  Epoch: 666  Training loss = 3.9344  Validation loss = 4.8709  \n",
      "\n",
      "Fold: 12  Epoch: 667  Training loss = 3.9341  Validation loss = 4.8706  \n",
      "\n",
      "Fold: 12  Epoch: 668  Training loss = 3.9338  Validation loss = 4.8702  \n",
      "\n",
      "Fold: 12  Epoch: 669  Training loss = 3.9336  Validation loss = 4.8700  \n",
      "\n",
      "Fold: 12  Epoch: 670  Training loss = 3.9333  Validation loss = 4.8696  \n",
      "\n",
      "Fold: 12  Epoch: 671  Training loss = 3.9329  Validation loss = 4.8693  \n",
      "\n",
      "Fold: 12  Epoch: 672  Training loss = 3.9324  Validation loss = 4.8688  \n",
      "\n",
      "Fold: 12  Epoch: 673  Training loss = 3.9319  Validation loss = 4.8684  \n",
      "\n",
      "Fold: 12  Epoch: 674  Training loss = 3.9316  Validation loss = 4.8680  \n",
      "\n",
      "Fold: 12  Epoch: 675  Training loss = 3.9313  Validation loss = 4.8678  \n",
      "\n",
      "Fold: 12  Epoch: 676  Training loss = 3.9309  Validation loss = 4.8674  \n",
      "\n",
      "Fold: 12  Epoch: 677  Training loss = 3.9303  Validation loss = 4.8669  \n",
      "\n",
      "Fold: 12  Epoch: 678  Training loss = 3.9300  Validation loss = 4.8667  \n",
      "\n",
      "Fold: 12  Epoch: 679  Training loss = 3.9297  Validation loss = 4.8664  \n",
      "\n",
      "Fold: 12  Epoch: 680  Training loss = 3.9293  Validation loss = 4.8660  \n",
      "\n",
      "Fold: 12  Epoch: 681  Training loss = 3.9289  Validation loss = 4.8656  \n",
      "\n",
      "Fold: 12  Epoch: 682  Training loss = 3.9285  Validation loss = 4.8652  \n",
      "\n",
      "Fold: 12  Epoch: 683  Training loss = 3.9281  Validation loss = 4.8649  \n",
      "\n",
      "Fold: 12  Epoch: 684  Training loss = 3.9280  Validation loss = 4.8647  \n",
      "\n",
      "Fold: 12  Epoch: 685  Training loss = 3.9277  Validation loss = 4.8645  \n",
      "\n",
      "Fold: 12  Epoch: 686  Training loss = 3.9272  Validation loss = 4.8641  \n",
      "\n",
      "Fold: 12  Epoch: 687  Training loss = 3.9270  Validation loss = 4.8638  \n",
      "\n",
      "Fold: 12  Epoch: 688  Training loss = 3.9266  Validation loss = 4.8634  \n",
      "\n",
      "Fold: 12  Epoch: 689  Training loss = 3.9263  Validation loss = 4.8632  \n",
      "\n",
      "Fold: 12  Epoch: 690  Training loss = 3.9261  Validation loss = 4.8629  \n",
      "\n",
      "Fold: 12  Epoch: 691  Training loss = 3.9258  Validation loss = 4.8626  \n",
      "\n",
      "Fold: 12  Epoch: 692  Training loss = 3.9254  Validation loss = 4.8623  \n",
      "\n",
      "Fold: 12  Epoch: 693  Training loss = 3.9250  Validation loss = 4.8620  \n",
      "\n",
      "Fold: 12  Epoch: 694  Training loss = 3.9247  Validation loss = 4.8618  \n",
      "\n",
      "Fold: 12  Epoch: 695  Training loss = 3.9244  Validation loss = 4.8615  \n",
      "\n",
      "Fold: 12  Epoch: 696  Training loss = 3.9238  Validation loss = 4.8611  \n",
      "\n",
      "Fold: 12  Epoch: 697  Training loss = 3.9234  Validation loss = 4.8607  \n",
      "\n",
      "Fold: 12  Epoch: 698  Training loss = 3.9228  Validation loss = 4.8604  \n",
      "\n",
      "Fold: 12  Epoch: 699  Training loss = 3.9225  Validation loss = 4.8600  \n",
      "\n",
      "Fold: 12  Epoch: 700  Training loss = 3.9222  Validation loss = 4.8597  \n",
      "\n",
      "Fold: 12  Epoch: 701  Training loss = 3.9216  Validation loss = 4.8593  \n",
      "\n",
      "Fold: 12  Epoch: 702  Training loss = 3.9213  Validation loss = 4.8591  \n",
      "\n",
      "Fold: 12  Epoch: 703  Training loss = 3.9208  Validation loss = 4.8588  \n",
      "\n",
      "Fold: 12  Epoch: 704  Training loss = 3.9203  Validation loss = 4.8584  \n",
      "\n",
      "Fold: 12  Epoch: 705  Training loss = 3.9198  Validation loss = 4.8582  \n",
      "\n",
      "Fold: 12  Epoch: 706  Training loss = 3.9192  Validation loss = 4.8577  \n",
      "\n",
      "Fold: 12  Epoch: 707  Training loss = 3.9189  Validation loss = 4.8575  \n",
      "\n",
      "Fold: 12  Epoch: 708  Training loss = 3.9183  Validation loss = 4.8571  \n",
      "\n",
      "Fold: 12  Epoch: 709  Training loss = 3.9178  Validation loss = 4.8568  \n",
      "\n",
      "Fold: 12  Epoch: 710  Training loss = 3.9175  Validation loss = 4.8565  \n",
      "\n",
      "Fold: 12  Epoch: 711  Training loss = 3.9173  Validation loss = 4.8563  \n",
      "\n",
      "Fold: 12  Epoch: 712  Training loss = 3.9166  Validation loss = 4.8559  \n",
      "\n",
      "Fold: 12  Epoch: 713  Training loss = 3.9162  Validation loss = 4.8557  \n",
      "\n",
      "Fold: 12  Epoch: 714  Training loss = 3.9161  Validation loss = 4.8555  \n",
      "\n",
      "Fold: 12  Epoch: 715  Training loss = 3.9157  Validation loss = 4.8552  \n",
      "\n",
      "Fold: 12  Epoch: 716  Training loss = 3.9152  Validation loss = 4.8547  \n",
      "\n",
      "Fold: 12  Epoch: 717  Training loss = 3.9148  Validation loss = 4.8545  \n",
      "\n",
      "Fold: 12  Epoch: 718  Training loss = 3.9143  Validation loss = 4.8542  \n",
      "\n",
      "Fold: 12  Epoch: 719  Training loss = 3.9142  Validation loss = 4.8540  \n",
      "\n",
      "Fold: 12  Epoch: 720  Training loss = 3.9135  Validation loss = 4.8536  \n",
      "\n",
      "Fold: 12  Epoch: 721  Training loss = 3.9127  Validation loss = 4.8532  \n",
      "\n",
      "Fold: 12  Epoch: 722  Training loss = 3.9121  Validation loss = 4.8529  \n",
      "\n",
      "Fold: 12  Epoch: 723  Training loss = 3.9117  Validation loss = 4.8526  \n",
      "\n",
      "Fold: 12  Epoch: 724  Training loss = 3.9114  Validation loss = 4.8523  \n",
      "\n",
      "Fold: 12  Epoch: 725  Training loss = 3.9108  Validation loss = 4.8519  \n",
      "\n",
      "Fold: 12  Epoch: 726  Training loss = 3.9104  Validation loss = 4.8517  \n",
      "\n",
      "Fold: 12  Epoch: 727  Training loss = 3.9101  Validation loss = 4.8514  \n",
      "\n",
      "Fold: 12  Epoch: 728  Training loss = 3.9098  Validation loss = 4.8512  \n",
      "\n",
      "Fold: 12  Epoch: 729  Training loss = 3.9094  Validation loss = 4.8509  \n",
      "\n",
      "Fold: 12  Epoch: 730  Training loss = 3.9088  Validation loss = 4.8505  \n",
      "\n",
      "Fold: 12  Epoch: 731  Training loss = 3.9083  Validation loss = 4.8502  \n",
      "\n",
      "Fold: 12  Epoch: 732  Training loss = 3.9077  Validation loss = 4.8497  \n",
      "\n",
      "Fold: 12  Epoch: 733  Training loss = 3.9073  Validation loss = 4.8494  \n",
      "\n",
      "Fold: 12  Epoch: 734  Training loss = 3.9068  Validation loss = 4.8491  \n",
      "\n",
      "Fold: 12  Epoch: 735  Training loss = 3.9057  Validation loss = 4.8486  \n",
      "\n",
      "Fold: 12  Epoch: 736  Training loss = 3.9051  Validation loss = 4.8484  \n",
      "\n",
      "Fold: 12  Epoch: 737  Training loss = 3.9043  Validation loss = 4.8480  \n",
      "\n",
      "Fold: 12  Epoch: 738  Training loss = 3.9034  Validation loss = 4.8476  \n",
      "\n",
      "Fold: 12  Epoch: 739  Training loss = 3.9032  Validation loss = 4.8474  \n",
      "\n",
      "Fold: 12  Epoch: 740  Training loss = 3.9022  Validation loss = 4.8470  \n",
      "\n",
      "Fold: 12  Epoch: 741  Training loss = 3.9019  Validation loss = 4.8468  \n",
      "\n",
      "Fold: 12  Epoch: 742  Training loss = 3.9009  Validation loss = 4.8463  \n",
      "\n",
      "Fold: 12  Epoch: 743  Training loss = 3.9002  Validation loss = 4.8459  \n",
      "\n",
      "Fold: 12  Epoch: 744  Training loss = 3.8998  Validation loss = 4.8457  \n",
      "\n",
      "Fold: 12  Epoch: 745  Training loss = 3.8995  Validation loss = 4.8453  \n",
      "\n",
      "Fold: 12  Epoch: 746  Training loss = 3.8989  Validation loss = 4.8450  \n",
      "\n",
      "Fold: 12  Epoch: 747  Training loss = 3.8987  Validation loss = 4.8447  \n",
      "\n",
      "Fold: 12  Epoch: 748  Training loss = 3.8980  Validation loss = 4.8443  \n",
      "\n",
      "Fold: 12  Epoch: 749  Training loss = 3.8975  Validation loss = 4.8440  \n",
      "\n",
      "Fold: 12  Epoch: 750  Training loss = 3.8969  Validation loss = 4.8437  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 750  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 4.0651  Validation loss = 6.9260  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 4.0648  Validation loss = 6.9257  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 4.0644  Validation loss = 6.9254  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 4.0640  Validation loss = 6.9251  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 4.0633  Validation loss = 6.9247  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 4.0626  Validation loss = 6.9243  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 4.0617  Validation loss = 6.9238  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 4.0614  Validation loss = 6.9235  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 4.0611  Validation loss = 6.9230  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 4.0604  Validation loss = 6.9226  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 4.0600  Validation loss = 6.9221  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 4.0595  Validation loss = 6.9218  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 4.0592  Validation loss = 6.9214  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 4.0587  Validation loss = 6.9210  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 4.0584  Validation loss = 6.9206  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 4.0581  Validation loss = 6.9204  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 4.0575  Validation loss = 6.9200  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 4.0572  Validation loss = 6.9196  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 4.0565  Validation loss = 6.9191  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 4.0559  Validation loss = 6.9186  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 4.0555  Validation loss = 6.9183  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 4.0551  Validation loss = 6.9180  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 4.0548  Validation loss = 6.9176  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 4.0544  Validation loss = 6.9172  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 4.0540  Validation loss = 6.9168  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 4.0537  Validation loss = 6.9165  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 4.0535  Validation loss = 6.9162  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 4.0533  Validation loss = 6.9158  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 4.0528  Validation loss = 6.9154  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 4.0524  Validation loss = 6.9150  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 4.0519  Validation loss = 6.9146  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 4.0517  Validation loss = 6.9143  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 4.0515  Validation loss = 6.9140  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 4.0511  Validation loss = 6.9137  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 4.0507  Validation loss = 6.9134  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 4.0505  Validation loss = 6.9131  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 4.0502  Validation loss = 6.9127  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 4.0497  Validation loss = 6.9123  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 4.0494  Validation loss = 6.9118  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 4.0490  Validation loss = 6.9114  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 4.0488  Validation loss = 6.9111  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 4.0485  Validation loss = 6.9107  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 4.0480  Validation loss = 6.9103  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 4.0473  Validation loss = 6.9098  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 4.0470  Validation loss = 6.9094  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 4.0466  Validation loss = 6.9091  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 4.0463  Validation loss = 6.9087  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 4.0461  Validation loss = 6.9084  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 4.0458  Validation loss = 6.9081  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 4.0454  Validation loss = 6.9077  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 4.0450  Validation loss = 6.9072  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 4.0445  Validation loss = 6.9068  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 4.0443  Validation loss = 6.9065  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 4.0439  Validation loss = 6.9060  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 4.0435  Validation loss = 6.9056  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 4.0430  Validation loss = 6.9051  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 4.0427  Validation loss = 6.9048  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 4.0425  Validation loss = 6.9044  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 4.0423  Validation loss = 6.9041  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 4.0419  Validation loss = 6.9036  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 4.0415  Validation loss = 6.9032  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 4.0412  Validation loss = 6.9028  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 4.0409  Validation loss = 6.9025  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 4.0406  Validation loss = 6.9021  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 4.0404  Validation loss = 6.9018  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 4.0401  Validation loss = 6.9015  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 4.0398  Validation loss = 6.9011  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 4.0394  Validation loss = 6.9007  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 4.0392  Validation loss = 6.9003  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 4.0388  Validation loss = 6.8999  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 4.0385  Validation loss = 6.8995  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 4.0382  Validation loss = 6.8991  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 4.0380  Validation loss = 6.8989  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 4.0377  Validation loss = 6.8985  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 4.0375  Validation loss = 6.8981  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 4.0372  Validation loss = 6.8978  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 4.0369  Validation loss = 6.8974  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 4.0365  Validation loss = 6.8970  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 4.0363  Validation loss = 6.8966  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 4.0359  Validation loss = 6.8961  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 4.0356  Validation loss = 6.8957  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 4.0352  Validation loss = 6.8953  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 4.0349  Validation loss = 6.8949  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 4.0347  Validation loss = 6.8946  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 4.0344  Validation loss = 6.8942  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 4.0341  Validation loss = 6.8938  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 4.0339  Validation loss = 6.8935  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 4.0336  Validation loss = 6.8930  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 4.0334  Validation loss = 6.8927  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 4.0331  Validation loss = 6.8923  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 4.0328  Validation loss = 6.8919  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 4.0326  Validation loss = 6.8916  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 4.0324  Validation loss = 6.8913  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 4.0322  Validation loss = 6.8909  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 4.0319  Validation loss = 6.8905  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 4.0316  Validation loss = 6.8902  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 4.0313  Validation loss = 6.8898  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 4.0310  Validation loss = 6.8894  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 4.0308  Validation loss = 6.8891  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 4.0305  Validation loss = 6.8887  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 4.0303  Validation loss = 6.8883  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 4.0300  Validation loss = 6.8880  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 4.0298  Validation loss = 6.8877  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 4.0295  Validation loss = 6.8873  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 4.0292  Validation loss = 6.8868  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 4.0289  Validation loss = 6.8865  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 4.0287  Validation loss = 6.8861  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 4.0283  Validation loss = 6.8856  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 4.0280  Validation loss = 6.8852  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 4.0277  Validation loss = 6.8848  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 4.0275  Validation loss = 6.8845  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 4.0272  Validation loss = 6.8840  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 4.0270  Validation loss = 6.8837  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 4.0267  Validation loss = 6.8834  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 4.0264  Validation loss = 6.8829  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 4.0262  Validation loss = 6.8826  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 4.0259  Validation loss = 6.8822  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 4.0256  Validation loss = 6.8817  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 4.0253  Validation loss = 6.8814  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 4.0249  Validation loss = 6.8808  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 4.0246  Validation loss = 6.8804  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 4.0244  Validation loss = 6.8800  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 4.0241  Validation loss = 6.8797  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 4.0238  Validation loss = 6.8792  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 4.0235  Validation loss = 6.8788  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 4.0233  Validation loss = 6.8785  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 4.0230  Validation loss = 6.8780  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 4.0227  Validation loss = 6.8776  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 4.0224  Validation loss = 6.8772  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 4.0221  Validation loss = 6.8767  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 4.0219  Validation loss = 6.8764  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 4.0215  Validation loss = 6.8760  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 4.0212  Validation loss = 6.8755  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 4.0210  Validation loss = 6.8752  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 4.0208  Validation loss = 6.8748  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 4.0205  Validation loss = 6.8744  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 4.0203  Validation loss = 6.8741  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 4.0199  Validation loss = 6.8736  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 4.0197  Validation loss = 6.8732  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 4.0194  Validation loss = 6.8729  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 4.0192  Validation loss = 6.8726  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 4.0191  Validation loss = 6.8723  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 4.0188  Validation loss = 6.8719  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 4.0185  Validation loss = 6.8715  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 4.0182  Validation loss = 6.8711  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 4.0179  Validation loss = 6.8707  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 4.0177  Validation loss = 6.8703  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 4.0174  Validation loss = 6.8699  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 4.0172  Validation loss = 6.8696  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 4.0169  Validation loss = 6.8691  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 4.0166  Validation loss = 6.8687  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 4.0164  Validation loss = 6.8684  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 4.0162  Validation loss = 6.8679  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 4.0158  Validation loss = 6.8675  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 4.0156  Validation loss = 6.8670  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 4.0153  Validation loss = 6.8666  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 4.0150  Validation loss = 6.8662  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 4.0147  Validation loss = 6.8658  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 4.0144  Validation loss = 6.8654  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 4.0142  Validation loss = 6.8650  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 4.0140  Validation loss = 6.8647  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 4.0137  Validation loss = 6.8643  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 4.0134  Validation loss = 6.8638  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 4.0131  Validation loss = 6.8634  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 4.0129  Validation loss = 6.8631  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 4.0127  Validation loss = 6.8628  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 4.0124  Validation loss = 6.8624  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 4.0122  Validation loss = 6.8620  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 4.0119  Validation loss = 6.8615  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 4.0116  Validation loss = 6.8611  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 4.0114  Validation loss = 6.8608  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 4.0111  Validation loss = 6.8604  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 4.0109  Validation loss = 6.8600  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 4.0106  Validation loss = 6.8596  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 4.0104  Validation loss = 6.8593  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 4.0102  Validation loss = 6.8589  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 4.0099  Validation loss = 6.8585  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 4.0097  Validation loss = 6.8581  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 4.0094  Validation loss = 6.8577  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 4.0092  Validation loss = 6.8574  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 4.0088  Validation loss = 6.8569  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 4.0086  Validation loss = 6.8566  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 4.0083  Validation loss = 6.8562  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 4.0081  Validation loss = 6.8559  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 4.0079  Validation loss = 6.8555  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 4.0076  Validation loss = 6.8552  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 4.0074  Validation loss = 6.8548  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 4.0072  Validation loss = 6.8544  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 4.0069  Validation loss = 6.8540  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 4.0066  Validation loss = 6.8536  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 4.0064  Validation loss = 6.8532  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 4.0061  Validation loss = 6.8528  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 4.0059  Validation loss = 6.8525  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 4.0057  Validation loss = 6.8521  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 4.0054  Validation loss = 6.8517  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 4.0051  Validation loss = 6.8513  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 4.0048  Validation loss = 6.8508  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 4.0046  Validation loss = 6.8505  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 4.0044  Validation loss = 6.8501  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 4.0041  Validation loss = 6.8497  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 4.0038  Validation loss = 6.8493  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 4.0035  Validation loss = 6.8489  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 4.0032  Validation loss = 6.8485  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 4.0030  Validation loss = 6.8481  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 4.0027  Validation loss = 6.8478  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 4.0025  Validation loss = 6.8474  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 4.0023  Validation loss = 6.8470  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 4.0020  Validation loss = 6.8466  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 4.0018  Validation loss = 6.8462  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 4.0015  Validation loss = 6.8458  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 4.0012  Validation loss = 6.8454  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 4.0010  Validation loss = 6.8451  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 4.0008  Validation loss = 6.8447  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 4.0005  Validation loss = 6.8443  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 4.0004  Validation loss = 6.8440  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 4.0001  Validation loss = 6.8436  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 3.9999  Validation loss = 6.8433  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 3.9996  Validation loss = 6.8429  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 3.9994  Validation loss = 6.8425  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 3.9991  Validation loss = 6.8422  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 3.9989  Validation loss = 6.8418  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 3.9987  Validation loss = 6.8415  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 3.9985  Validation loss = 6.8412  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 3.9983  Validation loss = 6.8408  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 3.9981  Validation loss = 6.8406  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 3.9978  Validation loss = 6.8402  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 3.9976  Validation loss = 6.8399  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 3.9974  Validation loss = 6.8394  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 3.9971  Validation loss = 6.8390  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 3.9968  Validation loss = 6.8386  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 3.9966  Validation loss = 6.8382  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 3.9963  Validation loss = 6.8378  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 3.9960  Validation loss = 6.8374  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 3.9958  Validation loss = 6.8370  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 3.9955  Validation loss = 6.8366  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 3.9953  Validation loss = 6.8363  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 3.9951  Validation loss = 6.8359  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 3.9947  Validation loss = 6.8354  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 3.9945  Validation loss = 6.8351  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 3.9943  Validation loss = 6.8347  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 3.9941  Validation loss = 6.8344  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 3.9938  Validation loss = 6.8340  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 3.9936  Validation loss = 6.8337  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 3.9933  Validation loss = 6.8333  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 3.9930  Validation loss = 6.8328  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 3.9928  Validation loss = 6.8325  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 3.9926  Validation loss = 6.8321  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 3.9924  Validation loss = 6.8318  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 3.9921  Validation loss = 6.8314  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 3.9919  Validation loss = 6.8311  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 3.9917  Validation loss = 6.8307  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 3.9914  Validation loss = 6.8303  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 3.9911  Validation loss = 6.8298  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 3.9908  Validation loss = 6.8295  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 3.9906  Validation loss = 6.8291  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 3.9903  Validation loss = 6.8287  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 3.9901  Validation loss = 6.8283  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 3.9898  Validation loss = 6.8278  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 3.9896  Validation loss = 6.8275  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 3.9893  Validation loss = 6.8271  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 3.9891  Validation loss = 6.8267  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 3.9888  Validation loss = 6.8263  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 3.9886  Validation loss = 6.8260  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 3.9884  Validation loss = 6.8257  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 3.9882  Validation loss = 6.8253  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 3.9878  Validation loss = 6.8248  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 3.9876  Validation loss = 6.8244  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 3.9874  Validation loss = 6.8240  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 3.9871  Validation loss = 6.8237  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 3.9869  Validation loss = 6.8233  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 3.9866  Validation loss = 6.8229  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 3.9863  Validation loss = 6.8225  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 3.9861  Validation loss = 6.8221  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 3.9858  Validation loss = 6.8217  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 3.9856  Validation loss = 6.8214  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 3.9853  Validation loss = 6.8210  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 3.9851  Validation loss = 6.8206  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 3.9848  Validation loss = 6.8202  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 3.9846  Validation loss = 6.8199  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 3.9844  Validation loss = 6.8196  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 3.9842  Validation loss = 6.8192  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 3.9839  Validation loss = 6.8188  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 3.9836  Validation loss = 6.8183  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 3.9834  Validation loss = 6.8179  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 3.9832  Validation loss = 6.8177  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 3.9830  Validation loss = 6.8173  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 3.9828  Validation loss = 6.8170  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 3.9826  Validation loss = 6.8167  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 3.9823  Validation loss = 6.8162  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 3.9821  Validation loss = 6.8159  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 3.9818  Validation loss = 6.8155  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 3.9816  Validation loss = 6.8151  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 3.9813  Validation loss = 6.8148  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 3.9811  Validation loss = 6.8144  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 3.9809  Validation loss = 6.8141  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 3.9807  Validation loss = 6.8138  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 3.9805  Validation loss = 6.8134  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 3.9802  Validation loss = 6.8130  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 3.9800  Validation loss = 6.8127  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 3.9797  Validation loss = 6.8122  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 3.9795  Validation loss = 6.8119  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 3.9793  Validation loss = 6.8115  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 3.9791  Validation loss = 6.8112  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 3.9788  Validation loss = 6.8109  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 3.9786  Validation loss = 6.8105  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 3.9784  Validation loss = 6.8101  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 3.9781  Validation loss = 6.8097  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 3.9778  Validation loss = 6.8093  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 3.9777  Validation loss = 6.8090  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 3.9774  Validation loss = 6.8086  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 3.9771  Validation loss = 6.8082  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 3.9769  Validation loss = 6.8078  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 3.9767  Validation loss = 6.8074  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 3.9764  Validation loss = 6.8070  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 3.9761  Validation loss = 6.8066  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 3.9759  Validation loss = 6.8062  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 3.9757  Validation loss = 6.8058  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 3.9754  Validation loss = 6.8054  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 3.9752  Validation loss = 6.8051  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 3.9750  Validation loss = 6.8048  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 3.9747  Validation loss = 6.8043  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 3.9744  Validation loss = 6.8039  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 3.9742  Validation loss = 6.8036  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 3.9739  Validation loss = 6.8031  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 3.9737  Validation loss = 6.8028  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 3.9735  Validation loss = 6.8025  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 3.9733  Validation loss = 6.8021  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 3.9730  Validation loss = 6.8017  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 3.9728  Validation loss = 6.8014  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 3.9726  Validation loss = 6.8010  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 3.9723  Validation loss = 6.8006  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 3.9721  Validation loss = 6.8002  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 3.9718  Validation loss = 6.7998  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 3.9716  Validation loss = 6.7995  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 3.9714  Validation loss = 6.7991  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 3.9711  Validation loss = 6.7987  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 3.9710  Validation loss = 6.7985  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 3.9707  Validation loss = 6.7980  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 3.9705  Validation loss = 6.7977  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 3.9702  Validation loss = 6.7973  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 3.9700  Validation loss = 6.7970  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 3.9698  Validation loss = 6.7966  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 3.9695  Validation loss = 6.7962  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 3.9693  Validation loss = 6.7959  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 3.9691  Validation loss = 6.7955  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 3.9688  Validation loss = 6.7951  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 3.9685  Validation loss = 6.7947  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 3.9683  Validation loss = 6.7943  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 3.9680  Validation loss = 6.7939  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 3.9678  Validation loss = 6.7935  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 3.9676  Validation loss = 6.7931  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 3.9673  Validation loss = 6.7927  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 3.9671  Validation loss = 6.7923  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 3.9668  Validation loss = 6.7919  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 3.9666  Validation loss = 6.7916  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 3.9663  Validation loss = 6.7912  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 3.9661  Validation loss = 6.7908  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 3.9658  Validation loss = 6.7903  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 3.9655  Validation loss = 6.7899  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 3.9653  Validation loss = 6.7896  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 3.9650  Validation loss = 6.7892  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 3.9648  Validation loss = 6.7888  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 3.9645  Validation loss = 6.7884  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 3.9643  Validation loss = 6.7880  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 3.9641  Validation loss = 6.7876  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 3.9638  Validation loss = 6.7873  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 3.9636  Validation loss = 6.7869  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 3.9633  Validation loss = 6.7865  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 3.9631  Validation loss = 6.7861  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 3.9628  Validation loss = 6.7857  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 3.9626  Validation loss = 6.7853  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 3.9623  Validation loss = 6.7849  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 3.9621  Validation loss = 6.7846  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 3.9619  Validation loss = 6.7843  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 3.9617  Validation loss = 6.7839  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 3.9616  Validation loss = 6.7837  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 3.9613  Validation loss = 6.7833  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 3.9612  Validation loss = 6.7831  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 3.9609  Validation loss = 6.7826  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 3.9606  Validation loss = 6.7821  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 3.9603  Validation loss = 6.7817  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 3.9601  Validation loss = 6.7814  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 3.9599  Validation loss = 6.7810  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 3.9597  Validation loss = 6.7807  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 3.9594  Validation loss = 6.7802  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 3.9592  Validation loss = 6.7799  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 3.9589  Validation loss = 6.7795  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 3.9587  Validation loss = 6.7791  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 3.9585  Validation loss = 6.7787  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 3.9582  Validation loss = 6.7783  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 3.9580  Validation loss = 6.7779  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 3.9577  Validation loss = 6.7775  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 3.9575  Validation loss = 6.7771  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 3.9572  Validation loss = 6.7768  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 3.9570  Validation loss = 6.7764  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 3.9568  Validation loss = 6.7761  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 3.9566  Validation loss = 6.7758  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 3.9563  Validation loss = 6.7753  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 3.9561  Validation loss = 6.7750  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 3.9559  Validation loss = 6.7746  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 3.9557  Validation loss = 6.7743  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 3.9555  Validation loss = 6.7740  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 3.9552  Validation loss = 6.7736  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 3.9550  Validation loss = 6.7732  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 3.9548  Validation loss = 6.7729  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 3.9546  Validation loss = 6.7725  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 3.9543  Validation loss = 6.7721  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 3.9541  Validation loss = 6.7718  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 3.9539  Validation loss = 6.7714  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 3.9536  Validation loss = 6.7710  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 3.9533  Validation loss = 6.7706  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 3.9531  Validation loss = 6.7702  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 3.9529  Validation loss = 6.7698  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 3.9527  Validation loss = 6.7695  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 3.9524  Validation loss = 6.7691  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 3.9522  Validation loss = 6.7688  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 3.9520  Validation loss = 6.7684  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 3.9517  Validation loss = 6.7679  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 3.9514  Validation loss = 6.7674  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 3.9511  Validation loss = 6.7670  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 3.9508  Validation loss = 6.7666  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 3.9506  Validation loss = 6.7662  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 3.9503  Validation loss = 6.7657  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 3.9501  Validation loss = 6.7655  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 3.9499  Validation loss = 6.7651  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 3.9497  Validation loss = 6.7647  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 3.9494  Validation loss = 6.7644  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 3.9492  Validation loss = 6.7640  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 3.9490  Validation loss = 6.7636  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 3.9488  Validation loss = 6.7632  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 3.9485  Validation loss = 6.7628  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 3.9482  Validation loss = 6.7624  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 3.9480  Validation loss = 6.7621  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 3.9478  Validation loss = 6.7617  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 3.9475  Validation loss = 6.7613  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 3.9473  Validation loss = 6.7609  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 3.9470  Validation loss = 6.7605  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 3.9468  Validation loss = 6.7602  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 3.9466  Validation loss = 6.7598  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 3.9463  Validation loss = 6.7594  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 3.9461  Validation loss = 6.7590  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 3.9460  Validation loss = 6.7588  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 3.9457  Validation loss = 6.7584  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 3.9454  Validation loss = 6.7579  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 3.9452  Validation loss = 6.7575  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 3.9449  Validation loss = 6.7571  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 3.9446  Validation loss = 6.7567  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 3.9445  Validation loss = 6.7564  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 3.9442  Validation loss = 6.7561  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 3.9439  Validation loss = 6.7556  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 3.9437  Validation loss = 6.7552  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 3.9435  Validation loss = 6.7549  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 3.9432  Validation loss = 6.7544  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 3.9430  Validation loss = 6.7540  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 3.9427  Validation loss = 6.7536  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 3.9425  Validation loss = 6.7533  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 3.9422  Validation loss = 6.7528  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 3.9420  Validation loss = 6.7525  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 3.9417  Validation loss = 6.7521  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 3.9415  Validation loss = 6.7518  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 3.9413  Validation loss = 6.7513  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 3.9410  Validation loss = 6.7509  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 3.9408  Validation loss = 6.7506  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 3.9406  Validation loss = 6.7503  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 3.9404  Validation loss = 6.7499  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 3.9402  Validation loss = 6.7496  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 3.9399  Validation loss = 6.7492  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 3.9397  Validation loss = 6.7488  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 3.9394  Validation loss = 6.7484  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 3.9392  Validation loss = 6.7480  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 3.9389  Validation loss = 6.7476  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 3.9387  Validation loss = 6.7473  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 3.9384  Validation loss = 6.7469  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 3.9381  Validation loss = 6.7464  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 3.9379  Validation loss = 6.7460  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 3.9377  Validation loss = 6.7456  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 3.9374  Validation loss = 6.7453  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 3.9373  Validation loss = 6.7450  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 3.9370  Validation loss = 6.7446  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 3.9368  Validation loss = 6.7442  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 3.9365  Validation loss = 6.7437  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 3.9362  Validation loss = 6.7433  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 3.9360  Validation loss = 6.7430  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 3.9358  Validation loss = 6.7427  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 3.9356  Validation loss = 6.7423  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 3.9353  Validation loss = 6.7418  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 3.9350  Validation loss = 6.7414  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 3.9348  Validation loss = 6.7410  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 3.9345  Validation loss = 6.7406  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 3.9343  Validation loss = 6.7402  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 3.9341  Validation loss = 6.7399  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 3.9339  Validation loss = 6.7395  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 3.9337  Validation loss = 6.7392  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 3.9334  Validation loss = 6.7389  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 3.9332  Validation loss = 6.7385  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 3.9330  Validation loss = 6.7381  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 3.9327  Validation loss = 6.7377  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 3.9325  Validation loss = 6.7373  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 3.9323  Validation loss = 6.7370  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 3.9320  Validation loss = 6.7366  \n",
      "\n",
      "Fold: 13  Epoch: 501  Training loss = 3.9318  Validation loss = 6.7362  \n",
      "\n",
      "Fold: 13  Epoch: 502  Training loss = 3.9316  Validation loss = 6.7360  \n",
      "\n",
      "Fold: 13  Epoch: 503  Training loss = 3.9313  Validation loss = 6.7355  \n",
      "\n",
      "Fold: 13  Epoch: 504  Training loss = 3.9312  Validation loss = 6.7352  \n",
      "\n",
      "Fold: 13  Epoch: 505  Training loss = 3.9310  Validation loss = 6.7349  \n",
      "\n",
      "Fold: 13  Epoch: 506  Training loss = 3.9307  Validation loss = 6.7345  \n",
      "\n",
      "Fold: 13  Epoch: 507  Training loss = 3.9305  Validation loss = 6.7342  \n",
      "\n",
      "Fold: 13  Epoch: 508  Training loss = 3.9302  Validation loss = 6.7338  \n",
      "\n",
      "Fold: 13  Epoch: 509  Training loss = 3.9300  Validation loss = 6.7334  \n",
      "\n",
      "Fold: 13  Epoch: 510  Training loss = 3.9298  Validation loss = 6.7331  \n",
      "\n",
      "Fold: 13  Epoch: 511  Training loss = 3.9296  Validation loss = 6.7327  \n",
      "\n",
      "Fold: 13  Epoch: 512  Training loss = 3.9294  Validation loss = 6.7324  \n",
      "\n",
      "Fold: 13  Epoch: 513  Training loss = 3.9292  Validation loss = 6.7320  \n",
      "\n",
      "Fold: 13  Epoch: 514  Training loss = 3.9289  Validation loss = 6.7316  \n",
      "\n",
      "Fold: 13  Epoch: 515  Training loss = 3.9286  Validation loss = 6.7312  \n",
      "\n",
      "Fold: 13  Epoch: 516  Training loss = 3.9284  Validation loss = 6.7308  \n",
      "\n",
      "Fold: 13  Epoch: 517  Training loss = 3.9282  Validation loss = 6.7305  \n",
      "\n",
      "Fold: 13  Epoch: 518  Training loss = 3.9280  Validation loss = 6.7301  \n",
      "\n",
      "Fold: 13  Epoch: 519  Training loss = 3.9277  Validation loss = 6.7298  \n",
      "\n",
      "Fold: 13  Epoch: 520  Training loss = 3.9275  Validation loss = 6.7294  \n",
      "\n",
      "Fold: 13  Epoch: 521  Training loss = 3.9273  Validation loss = 6.7291  \n",
      "\n",
      "Fold: 13  Epoch: 522  Training loss = 3.9271  Validation loss = 6.7287  \n",
      "\n",
      "Fold: 13  Epoch: 523  Training loss = 3.9268  Validation loss = 6.7284  \n",
      "\n",
      "Fold: 13  Epoch: 524  Training loss = 3.9266  Validation loss = 6.7280  \n",
      "\n",
      "Fold: 13  Epoch: 525  Training loss = 3.9263  Validation loss = 6.7275  \n",
      "\n",
      "Fold: 13  Epoch: 526  Training loss = 3.9261  Validation loss = 6.7272  \n",
      "\n",
      "Fold: 13  Epoch: 527  Training loss = 3.9258  Validation loss = 6.7267  \n",
      "\n",
      "Fold: 13  Epoch: 528  Training loss = 3.9255  Validation loss = 6.7264  \n",
      "\n",
      "Fold: 13  Epoch: 529  Training loss = 3.9254  Validation loss = 6.7261  \n",
      "\n",
      "Fold: 13  Epoch: 530  Training loss = 3.9251  Validation loss = 6.7258  \n",
      "\n",
      "Fold: 13  Epoch: 531  Training loss = 3.9249  Validation loss = 6.7254  \n",
      "\n",
      "Fold: 13  Epoch: 532  Training loss = 3.9245  Validation loss = 6.7250  \n",
      "\n",
      "Fold: 13  Epoch: 533  Training loss = 3.9242  Validation loss = 6.7247  \n",
      "\n",
      "Fold: 13  Epoch: 534  Training loss = 3.9239  Validation loss = 6.7242  \n",
      "\n",
      "Fold: 13  Epoch: 535  Training loss = 3.9235  Validation loss = 6.7239  \n",
      "\n",
      "Fold: 13  Epoch: 536  Training loss = 3.9234  Validation loss = 6.7236  \n",
      "\n",
      "Fold: 13  Epoch: 537  Training loss = 3.9223  Validation loss = 6.7232  \n",
      "\n",
      "Fold: 13  Epoch: 538  Training loss = 3.9215  Validation loss = 6.7228  \n",
      "\n",
      "Fold: 13  Epoch: 539  Training loss = 3.9207  Validation loss = 6.7224  \n",
      "\n",
      "Fold: 13  Epoch: 540  Training loss = 3.9203  Validation loss = 6.7220  \n",
      "\n",
      "Fold: 13  Epoch: 541  Training loss = 3.9199  Validation loss = 6.7217  \n",
      "\n",
      "Fold: 13  Epoch: 542  Training loss = 3.9196  Validation loss = 6.7213  \n",
      "\n",
      "Fold: 13  Epoch: 543  Training loss = 3.9193  Validation loss = 6.7209  \n",
      "\n",
      "Fold: 13  Epoch: 544  Training loss = 3.9190  Validation loss = 6.7205  \n",
      "\n",
      "Fold: 13  Epoch: 545  Training loss = 3.9188  Validation loss = 6.7202  \n",
      "\n",
      "Fold: 13  Epoch: 546  Training loss = 3.9186  Validation loss = 6.7198  \n",
      "\n",
      "Fold: 13  Epoch: 547  Training loss = 3.9183  Validation loss = 6.7195  \n",
      "\n",
      "Fold: 13  Epoch: 548  Training loss = 3.9181  Validation loss = 6.7192  \n",
      "\n",
      "Fold: 13  Epoch: 549  Training loss = 3.9179  Validation loss = 6.7188  \n",
      "\n",
      "Fold: 13  Epoch: 550  Training loss = 3.9176  Validation loss = 6.7184  \n",
      "\n",
      "Fold: 13  Epoch: 551  Training loss = 3.9174  Validation loss = 6.7180  \n",
      "\n",
      "Fold: 13  Epoch: 552  Training loss = 3.9172  Validation loss = 6.7177  \n",
      "\n",
      "Fold: 13  Epoch: 553  Training loss = 3.9170  Validation loss = 6.7174  \n",
      "\n",
      "Fold: 13  Epoch: 554  Training loss = 3.9168  Validation loss = 6.7171  \n",
      "\n",
      "Fold: 13  Epoch: 555  Training loss = 3.9165  Validation loss = 6.7166  \n",
      "\n",
      "Fold: 13  Epoch: 556  Training loss = 3.9163  Validation loss = 6.7163  \n",
      "\n",
      "Fold: 13  Epoch: 557  Training loss = 3.9161  Validation loss = 6.7159  \n",
      "\n",
      "Fold: 13  Epoch: 558  Training loss = 3.9159  Validation loss = 6.7155  \n",
      "\n",
      "Fold: 13  Epoch: 559  Training loss = 3.9157  Validation loss = 6.7152  \n",
      "\n",
      "Fold: 13  Epoch: 560  Training loss = 3.9155  Validation loss = 6.7149  \n",
      "\n",
      "Fold: 13  Epoch: 561  Training loss = 3.9152  Validation loss = 6.7145  \n",
      "\n",
      "Fold: 13  Epoch: 562  Training loss = 3.9150  Validation loss = 6.7142  \n",
      "\n",
      "Fold: 13  Epoch: 563  Training loss = 3.9147  Validation loss = 6.7137  \n",
      "\n",
      "Fold: 13  Epoch: 564  Training loss = 3.9144  Validation loss = 6.7133  \n",
      "\n",
      "Fold: 13  Epoch: 565  Training loss = 3.9142  Validation loss = 6.7129  \n",
      "\n",
      "Fold: 13  Epoch: 566  Training loss = 3.9140  Validation loss = 6.7126  \n",
      "\n",
      "Fold: 13  Epoch: 567  Training loss = 3.9138  Validation loss = 6.7122  \n",
      "\n",
      "Fold: 13  Epoch: 568  Training loss = 3.9136  Validation loss = 6.7119  \n",
      "\n",
      "Fold: 13  Epoch: 569  Training loss = 3.9134  Validation loss = 6.7115  \n",
      "\n",
      "Fold: 13  Epoch: 570  Training loss = 3.9131  Validation loss = 6.7112  \n",
      "\n",
      "Fold: 13  Epoch: 571  Training loss = 3.9129  Validation loss = 6.7109  \n",
      "\n",
      "Fold: 13  Epoch: 572  Training loss = 3.9127  Validation loss = 6.7104  \n",
      "\n",
      "Fold: 13  Epoch: 573  Training loss = 3.9125  Validation loss = 6.7101  \n",
      "\n",
      "Fold: 13  Epoch: 574  Training loss = 3.9123  Validation loss = 6.7098  \n",
      "\n",
      "Fold: 13  Epoch: 575  Training loss = 3.9121  Validation loss = 6.7095  \n",
      "\n",
      "Fold: 13  Epoch: 576  Training loss = 3.9119  Validation loss = 6.7091  \n",
      "\n",
      "Fold: 13  Epoch: 577  Training loss = 3.9117  Validation loss = 6.7088  \n",
      "\n",
      "Fold: 13  Epoch: 578  Training loss = 3.9115  Validation loss = 6.7085  \n",
      "\n",
      "Fold: 13  Epoch: 579  Training loss = 3.9113  Validation loss = 6.7082  \n",
      "\n",
      "Fold: 13  Epoch: 580  Training loss = 3.9111  Validation loss = 6.7079  \n",
      "\n",
      "Fold: 13  Epoch: 581  Training loss = 3.9110  Validation loss = 6.7076  \n",
      "\n",
      "Fold: 13  Epoch: 582  Training loss = 3.9108  Validation loss = 6.7073  \n",
      "\n",
      "Fold: 13  Epoch: 583  Training loss = 3.9105  Validation loss = 6.7070  \n",
      "\n",
      "Fold: 13  Epoch: 584  Training loss = 3.9103  Validation loss = 6.7066  \n",
      "\n",
      "Fold: 13  Epoch: 585  Training loss = 3.9101  Validation loss = 6.7063  \n",
      "\n",
      "Fold: 13  Epoch: 586  Training loss = 3.9098  Validation loss = 6.7058  \n",
      "\n",
      "Fold: 13  Epoch: 587  Training loss = 3.9097  Validation loss = 6.7055  \n",
      "\n",
      "Fold: 13  Epoch: 588  Training loss = 3.9094  Validation loss = 6.7052  \n",
      "\n",
      "Fold: 13  Epoch: 589  Training loss = 3.9092  Validation loss = 6.7048  \n",
      "\n",
      "Fold: 13  Epoch: 590  Training loss = 3.9090  Validation loss = 6.7044  \n",
      "\n",
      "Fold: 13  Epoch: 591  Training loss = 3.9087  Validation loss = 6.7041  \n",
      "\n",
      "Fold: 13  Epoch: 592  Training loss = 3.9085  Validation loss = 6.7038  \n",
      "\n",
      "Fold: 13  Epoch: 593  Training loss = 3.9083  Validation loss = 6.7034  \n",
      "\n",
      "Fold: 13  Epoch: 594  Training loss = 3.9081  Validation loss = 6.7030  \n",
      "\n",
      "Fold: 13  Epoch: 595  Training loss = 3.9079  Validation loss = 6.7028  \n",
      "\n",
      "Fold: 13  Epoch: 596  Training loss = 3.9077  Validation loss = 6.7024  \n",
      "\n",
      "Fold: 13  Epoch: 597  Training loss = 3.9074  Validation loss = 6.7020  \n",
      "\n",
      "Fold: 13  Epoch: 598  Training loss = 3.9072  Validation loss = 6.7015  \n",
      "\n",
      "Fold: 13  Epoch: 599  Training loss = 3.9069  Validation loss = 6.7011  \n",
      "\n",
      "Fold: 13  Epoch: 600  Training loss = 3.9067  Validation loss = 6.7007  \n",
      "\n",
      "Fold: 13  Epoch: 601  Training loss = 3.9064  Validation loss = 6.7004  \n",
      "\n",
      "Fold: 13  Epoch: 602  Training loss = 3.9062  Validation loss = 6.7000  \n",
      "\n",
      "Fold: 13  Epoch: 603  Training loss = 3.9060  Validation loss = 6.6996  \n",
      "\n",
      "Fold: 13  Epoch: 604  Training loss = 3.9058  Validation loss = 6.6993  \n",
      "\n",
      "Fold: 13  Epoch: 605  Training loss = 3.9056  Validation loss = 6.6990  \n",
      "\n",
      "Fold: 13  Epoch: 606  Training loss = 3.9053  Validation loss = 6.6986  \n",
      "\n",
      "Fold: 13  Epoch: 607  Training loss = 3.9052  Validation loss = 6.6983  \n",
      "\n",
      "Fold: 13  Epoch: 608  Training loss = 3.9050  Validation loss = 6.6980  \n",
      "\n",
      "Fold: 13  Epoch: 609  Training loss = 3.9048  Validation loss = 6.6977  \n",
      "\n",
      "Fold: 13  Epoch: 610  Training loss = 3.9046  Validation loss = 6.6973  \n",
      "\n",
      "Fold: 13  Epoch: 611  Training loss = 3.9043  Validation loss = 6.6969  \n",
      "\n",
      "Fold: 13  Epoch: 612  Training loss = 3.9040  Validation loss = 6.6964  \n",
      "\n",
      "Fold: 13  Epoch: 613  Training loss = 3.9038  Validation loss = 6.6961  \n",
      "\n",
      "Fold: 13  Epoch: 614  Training loss = 3.9036  Validation loss = 6.6957  \n",
      "\n",
      "Fold: 13  Epoch: 615  Training loss = 3.9034  Validation loss = 6.6954  \n",
      "\n",
      "Fold: 13  Epoch: 616  Training loss = 3.9032  Validation loss = 6.6950  \n",
      "\n",
      "Fold: 13  Epoch: 617  Training loss = 3.9029  Validation loss = 6.6947  \n",
      "\n",
      "Fold: 13  Epoch: 618  Training loss = 3.9027  Validation loss = 6.6943  \n",
      "\n",
      "Fold: 13  Epoch: 619  Training loss = 3.9025  Validation loss = 6.6939  \n",
      "\n",
      "Fold: 13  Epoch: 620  Training loss = 3.9023  Validation loss = 6.6936  \n",
      "\n",
      "Fold: 13  Epoch: 621  Training loss = 3.9021  Validation loss = 6.6933  \n",
      "\n",
      "Fold: 13  Epoch: 622  Training loss = 3.9019  Validation loss = 6.6929  \n",
      "\n",
      "Fold: 13  Epoch: 623  Training loss = 3.9016  Validation loss = 6.6925  \n",
      "\n",
      "Fold: 13  Epoch: 624  Training loss = 3.9014  Validation loss = 6.6921  \n",
      "\n",
      "Fold: 13  Epoch: 625  Training loss = 3.9012  Validation loss = 6.6918  \n",
      "\n",
      "Fold: 13  Epoch: 626  Training loss = 3.9009  Validation loss = 6.6914  \n",
      "\n",
      "Fold: 13  Epoch: 627  Training loss = 3.9007  Validation loss = 6.6910  \n",
      "\n",
      "Fold: 13  Epoch: 628  Training loss = 3.9005  Validation loss = 6.6906  \n",
      "\n",
      "Fold: 13  Epoch: 629  Training loss = 3.9002  Validation loss = 6.6902  \n",
      "\n",
      "Fold: 13  Epoch: 630  Training loss = 3.9000  Validation loss = 6.6899  \n",
      "\n",
      "Fold: 13  Epoch: 631  Training loss = 3.8997  Validation loss = 6.6894  \n",
      "\n",
      "Fold: 13  Epoch: 632  Training loss = 3.8995  Validation loss = 6.6891  \n",
      "\n",
      "Fold: 13  Epoch: 633  Training loss = 3.8993  Validation loss = 6.6888  \n",
      "\n",
      "Fold: 13  Epoch: 634  Training loss = 3.8991  Validation loss = 6.6884  \n",
      "\n",
      "Fold: 13  Epoch: 635  Training loss = 3.8989  Validation loss = 6.6881  \n",
      "\n",
      "Fold: 13  Epoch: 636  Training loss = 3.8987  Validation loss = 6.6878  \n",
      "\n",
      "Fold: 13  Epoch: 637  Training loss = 3.8986  Validation loss = 6.6875  \n",
      "\n",
      "Fold: 13  Epoch: 638  Training loss = 3.8984  Validation loss = 6.6872  \n",
      "\n",
      "Fold: 13  Epoch: 639  Training loss = 3.8981  Validation loss = 6.6868  \n",
      "\n",
      "Fold: 13  Epoch: 640  Training loss = 3.8979  Validation loss = 6.6864  \n",
      "\n",
      "Fold: 13  Epoch: 641  Training loss = 3.8977  Validation loss = 6.6861  \n",
      "\n",
      "Fold: 13  Epoch: 642  Training loss = 3.8975  Validation loss = 6.6858  \n",
      "\n",
      "Fold: 13  Epoch: 643  Training loss = 3.8972  Validation loss = 6.6854  \n",
      "\n",
      "Fold: 13  Epoch: 644  Training loss = 3.8970  Validation loss = 6.6851  \n",
      "\n",
      "Fold: 13  Epoch: 645  Training loss = 3.8968  Validation loss = 6.6847  \n",
      "\n",
      "Fold: 13  Epoch: 646  Training loss = 3.8965  Validation loss = 6.6843  \n",
      "\n",
      "Fold: 13  Epoch: 647  Training loss = 3.8963  Validation loss = 6.6839  \n",
      "\n",
      "Fold: 13  Epoch: 648  Training loss = 3.8960  Validation loss = 6.6835  \n",
      "\n",
      "Fold: 13  Epoch: 649  Training loss = 3.8958  Validation loss = 6.6832  \n",
      "\n",
      "Fold: 13  Epoch: 650  Training loss = 3.8956  Validation loss = 6.6828  \n",
      "\n",
      "Fold: 13  Epoch: 651  Training loss = 3.8954  Validation loss = 6.6825  \n",
      "\n",
      "Fold: 13  Epoch: 652  Training loss = 3.8952  Validation loss = 6.6821  \n",
      "\n",
      "Fold: 13  Epoch: 653  Training loss = 3.8950  Validation loss = 6.6818  \n",
      "\n",
      "Fold: 13  Epoch: 654  Training loss = 3.8948  Validation loss = 6.6814  \n",
      "\n",
      "Fold: 13  Epoch: 655  Training loss = 3.8946  Validation loss = 6.6811  \n",
      "\n",
      "Fold: 13  Epoch: 656  Training loss = 3.8944  Validation loss = 6.6808  \n",
      "\n",
      "Fold: 13  Epoch: 657  Training loss = 3.8942  Validation loss = 6.6804  \n",
      "\n",
      "Fold: 13  Epoch: 658  Training loss = 3.8940  Validation loss = 6.6801  \n",
      "\n",
      "Fold: 13  Epoch: 659  Training loss = 3.8938  Validation loss = 6.6798  \n",
      "\n",
      "Fold: 13  Epoch: 660  Training loss = 3.8936  Validation loss = 6.6794  \n",
      "\n",
      "Fold: 13  Epoch: 661  Training loss = 3.8934  Validation loss = 6.6791  \n",
      "\n",
      "Fold: 13  Epoch: 662  Training loss = 3.8932  Validation loss = 6.6788  \n",
      "\n",
      "Fold: 13  Epoch: 663  Training loss = 3.8929  Validation loss = 6.6784  \n",
      "\n",
      "Fold: 13  Epoch: 664  Training loss = 3.8928  Validation loss = 6.6782  \n",
      "\n",
      "Fold: 13  Epoch: 665  Training loss = 3.8926  Validation loss = 6.6778  \n",
      "\n",
      "Fold: 13  Epoch: 666  Training loss = 3.8923  Validation loss = 6.6774  \n",
      "\n",
      "Fold: 13  Epoch: 667  Training loss = 3.8920  Validation loss = 6.6769  \n",
      "\n",
      "Fold: 13  Epoch: 668  Training loss = 3.8918  Validation loss = 6.6766  \n",
      "\n",
      "Fold: 13  Epoch: 669  Training loss = 3.8916  Validation loss = 6.6763  \n",
      "\n",
      "Fold: 13  Epoch: 670  Training loss = 3.8914  Validation loss = 6.6759  \n",
      "\n",
      "Fold: 13  Epoch: 671  Training loss = 3.8912  Validation loss = 6.6756  \n",
      "\n",
      "Fold: 13  Epoch: 672  Training loss = 3.8910  Validation loss = 6.6753  \n",
      "\n",
      "Fold: 13  Epoch: 673  Training loss = 3.8908  Validation loss = 6.6750  \n",
      "\n",
      "Fold: 13  Epoch: 674  Training loss = 3.8906  Validation loss = 6.6747  \n",
      "\n",
      "Fold: 13  Epoch: 675  Training loss = 3.8904  Validation loss = 6.6743  \n",
      "\n",
      "Fold: 13  Epoch: 676  Training loss = 3.8902  Validation loss = 6.6739  \n",
      "\n",
      "Fold: 13  Epoch: 677  Training loss = 3.8900  Validation loss = 6.6735  \n",
      "\n",
      "Fold: 13  Epoch: 678  Training loss = 3.8897  Validation loss = 6.6732  \n",
      "\n",
      "Fold: 13  Epoch: 679  Training loss = 3.8895  Validation loss = 6.6728  \n",
      "\n",
      "Fold: 13  Epoch: 680  Training loss = 3.8892  Validation loss = 6.6723  \n",
      "\n",
      "Fold: 13  Epoch: 681  Training loss = 3.8890  Validation loss = 6.6720  \n",
      "\n",
      "Fold: 13  Epoch: 682  Training loss = 3.8887  Validation loss = 6.6716  \n",
      "\n",
      "Fold: 13  Epoch: 683  Training loss = 3.8885  Validation loss = 6.6712  \n",
      "\n",
      "Fold: 13  Epoch: 684  Training loss = 3.8883  Validation loss = 6.6708  \n",
      "\n",
      "Fold: 13  Epoch: 685  Training loss = 3.8880  Validation loss = 6.6704  \n",
      "\n",
      "Fold: 13  Epoch: 686  Training loss = 3.8878  Validation loss = 6.6701  \n",
      "\n",
      "Fold: 13  Epoch: 687  Training loss = 3.8876  Validation loss = 6.6697  \n",
      "\n",
      "Fold: 13  Epoch: 688  Training loss = 3.8874  Validation loss = 6.6694  \n",
      "\n",
      "Fold: 13  Epoch: 689  Training loss = 3.8871  Validation loss = 6.6690  \n",
      "\n",
      "Fold: 13  Epoch: 690  Training loss = 3.8869  Validation loss = 6.6686  \n",
      "\n",
      "Fold: 13  Epoch: 691  Training loss = 3.8867  Validation loss = 6.6683  \n",
      "\n",
      "Fold: 13  Epoch: 692  Training loss = 3.8864  Validation loss = 6.6678  \n",
      "\n",
      "Fold: 13  Epoch: 693  Training loss = 3.8862  Validation loss = 6.6675  \n",
      "\n",
      "Fold: 13  Epoch: 694  Training loss = 3.8860  Validation loss = 6.6671  \n",
      "\n",
      "Fold: 13  Epoch: 695  Training loss = 3.8858  Validation loss = 6.6667  \n",
      "\n",
      "Fold: 13  Epoch: 696  Training loss = 3.8855  Validation loss = 6.6663  \n",
      "\n",
      "Fold: 13  Epoch: 697  Training loss = 3.8853  Validation loss = 6.6660  \n",
      "\n",
      "Fold: 13  Epoch: 698  Training loss = 3.8851  Validation loss = 6.6656  \n",
      "\n",
      "Fold: 13  Epoch: 699  Training loss = 3.8849  Validation loss = 6.6652  \n",
      "\n",
      "Fold: 13  Epoch: 700  Training loss = 3.8846  Validation loss = 6.6648  \n",
      "\n",
      "Fold: 13  Epoch: 701  Training loss = 3.8844  Validation loss = 6.6644  \n",
      "\n",
      "Fold: 13  Epoch: 702  Training loss = 3.8842  Validation loss = 6.6642  \n",
      "\n",
      "Fold: 13  Epoch: 703  Training loss = 3.8840  Validation loss = 6.6639  \n",
      "\n",
      "Fold: 13  Epoch: 704  Training loss = 3.8838  Validation loss = 6.6635  \n",
      "\n",
      "Fold: 13  Epoch: 705  Training loss = 3.8836  Validation loss = 6.6632  \n",
      "\n",
      "Fold: 13  Epoch: 706  Training loss = 3.8835  Validation loss = 6.6630  \n",
      "\n",
      "Fold: 13  Epoch: 707  Training loss = 3.8833  Validation loss = 6.6627  \n",
      "\n",
      "Fold: 13  Epoch: 708  Training loss = 3.8830  Validation loss = 6.6623  \n",
      "\n",
      "Fold: 13  Epoch: 709  Training loss = 3.8828  Validation loss = 6.6619  \n",
      "\n",
      "Fold: 13  Epoch: 710  Training loss = 3.8826  Validation loss = 6.6616  \n",
      "\n",
      "Fold: 13  Epoch: 711  Training loss = 3.8824  Validation loss = 6.6612  \n",
      "\n",
      "Fold: 13  Epoch: 712  Training loss = 3.8821  Validation loss = 6.6607  \n",
      "\n",
      "Fold: 13  Epoch: 713  Training loss = 3.8819  Validation loss = 6.6604  \n",
      "\n",
      "Fold: 13  Epoch: 714  Training loss = 3.8817  Validation loss = 6.6601  \n",
      "\n",
      "Fold: 13  Epoch: 715  Training loss = 3.8815  Validation loss = 6.6598  \n",
      "\n",
      "Fold: 13  Epoch: 716  Training loss = 3.8813  Validation loss = 6.6594  \n",
      "\n",
      "Fold: 13  Epoch: 717  Training loss = 3.8811  Validation loss = 6.6591  \n",
      "\n",
      "Fold: 13  Epoch: 718  Training loss = 3.8808  Validation loss = 6.6587  \n",
      "\n",
      "Fold: 13  Epoch: 719  Training loss = 3.8807  Validation loss = 6.6584  \n",
      "\n",
      "Fold: 13  Epoch: 720  Training loss = 3.8804  Validation loss = 6.6580  \n",
      "\n",
      "Fold: 13  Epoch: 721  Training loss = 3.8802  Validation loss = 6.6576  \n",
      "\n",
      "Fold: 13  Epoch: 722  Training loss = 3.8800  Validation loss = 6.6573  \n",
      "\n",
      "Fold: 13  Epoch: 723  Training loss = 3.8798  Validation loss = 6.6570  \n",
      "\n",
      "Fold: 13  Epoch: 724  Training loss = 3.8796  Validation loss = 6.6566  \n",
      "\n",
      "Fold: 13  Epoch: 725  Training loss = 3.8794  Validation loss = 6.6563  \n",
      "\n",
      "Fold: 13  Epoch: 726  Training loss = 3.8791  Validation loss = 6.6560  \n",
      "\n",
      "Fold: 13  Epoch: 727  Training loss = 3.8790  Validation loss = 6.6556  \n",
      "\n",
      "Fold: 13  Epoch: 728  Training loss = 3.8787  Validation loss = 6.6553  \n",
      "\n",
      "Fold: 13  Epoch: 729  Training loss = 3.8785  Validation loss = 6.6549  \n",
      "\n",
      "Fold: 13  Epoch: 730  Training loss = 3.8783  Validation loss = 6.6545  \n",
      "\n",
      "Fold: 13  Epoch: 731  Training loss = 3.8781  Validation loss = 6.6542  \n",
      "\n",
      "Fold: 13  Epoch: 732  Training loss = 3.8779  Validation loss = 6.6538  \n",
      "\n",
      "Fold: 13  Epoch: 733  Training loss = 3.8776  Validation loss = 6.6535  \n",
      "\n",
      "Fold: 13  Epoch: 734  Training loss = 3.8774  Validation loss = 6.6530  \n",
      "\n",
      "Fold: 13  Epoch: 735  Training loss = 3.8772  Validation loss = 6.6527  \n",
      "\n",
      "Fold: 13  Epoch: 736  Training loss = 3.8770  Validation loss = 6.6524  \n",
      "\n",
      "Fold: 13  Epoch: 737  Training loss = 3.8768  Validation loss = 6.6521  \n",
      "\n",
      "Fold: 13  Epoch: 738  Training loss = 3.8766  Validation loss = 6.6517  \n",
      "\n",
      "Fold: 13  Epoch: 739  Training loss = 3.8764  Validation loss = 6.6514  \n",
      "\n",
      "Fold: 13  Epoch: 740  Training loss = 3.8762  Validation loss = 6.6511  \n",
      "\n",
      "Fold: 13  Epoch: 741  Training loss = 3.8760  Validation loss = 6.6507  \n",
      "\n",
      "Fold: 13  Epoch: 742  Training loss = 3.8757  Validation loss = 6.6503  \n",
      "\n",
      "Fold: 13  Epoch: 743  Training loss = 3.8755  Validation loss = 6.6500  \n",
      "\n",
      "Fold: 13  Epoch: 744  Training loss = 3.8753  Validation loss = 6.6496  \n",
      "\n",
      "Fold: 13  Epoch: 745  Training loss = 3.8751  Validation loss = 6.6493  \n",
      "\n",
      "Fold: 13  Epoch: 746  Training loss = 3.8749  Validation loss = 6.6489  \n",
      "\n",
      "Fold: 13  Epoch: 747  Training loss = 3.8746  Validation loss = 6.6486  \n",
      "\n",
      "Fold: 13  Epoch: 748  Training loss = 3.8744  Validation loss = 6.6482  \n",
      "\n",
      "Fold: 13  Epoch: 749  Training loss = 3.8742  Validation loss = 6.6478  \n",
      "\n",
      "Fold: 13  Epoch: 750  Training loss = 3.8739  Validation loss = 6.6474  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 750  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 4.2064  Validation loss = 10.3649  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 4.2060  Validation loss = 10.3644  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 4.2058  Validation loss = 10.3641  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 4.2056  Validation loss = 10.3638  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 4.2053  Validation loss = 10.3634  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 4.2050  Validation loss = 10.3630  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 4.2047  Validation loss = 10.3625  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 4.2044  Validation loss = 10.3621  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 4.2040  Validation loss = 10.3616  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 4.2038  Validation loss = 10.3613  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 4.2035  Validation loss = 10.3609  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 4.2032  Validation loss = 10.3605  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 4.2030  Validation loss = 10.3601  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 4.2027  Validation loss = 10.3597  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 4.2024  Validation loss = 10.3594  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 4.2022  Validation loss = 10.3590  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 4.2019  Validation loss = 10.3586  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 4.2016  Validation loss = 10.3583  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 4.2013  Validation loss = 10.3578  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 4.2010  Validation loss = 10.3575  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 4.2008  Validation loss = 10.3571  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 4.2004  Validation loss = 10.3566  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 4.2002  Validation loss = 10.3563  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 4.1999  Validation loss = 10.3559  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 4.1997  Validation loss = 10.3556  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 4.1994  Validation loss = 10.3552  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 4.1992  Validation loss = 10.3549  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 4.1990  Validation loss = 10.3545  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 4.1987  Validation loss = 10.3542  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 4.1985  Validation loss = 10.3538  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 4.1982  Validation loss = 10.3535  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 4.1979  Validation loss = 10.3531  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 4.1977  Validation loss = 10.3527  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 4.1974  Validation loss = 10.3523  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 4.1971  Validation loss = 10.3519  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 4.1968  Validation loss = 10.3515  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 4.1965  Validation loss = 10.3511  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 4.1963  Validation loss = 10.3507  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 4.1959  Validation loss = 10.3502  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 4.1957  Validation loss = 10.3499  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 4.1955  Validation loss = 10.3497  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 4.1952  Validation loss = 10.3493  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 4.1949  Validation loss = 10.3489  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 4.1946  Validation loss = 10.3483  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 4.1943  Validation loss = 10.3479  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 4.1940  Validation loss = 10.3475  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 4.1937  Validation loss = 10.3471  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 4.1934  Validation loss = 10.3468  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 4.1932  Validation loss = 10.3464  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 4.1929  Validation loss = 10.3461  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 4.1926  Validation loss = 10.3457  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 4.1924  Validation loss = 10.3453  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 4.1921  Validation loss = 10.3450  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 4.1919  Validation loss = 10.3446  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 4.1916  Validation loss = 10.3442  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 4.1913  Validation loss = 10.3437  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 4.1910  Validation loss = 10.3434  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 4.1908  Validation loss = 10.3431  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 4.1905  Validation loss = 10.3427  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 4.1902  Validation loss = 10.3422  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 4.1899  Validation loss = 10.3418  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 4.1896  Validation loss = 10.3414  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 4.1893  Validation loss = 10.3410  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 4.1890  Validation loss = 10.3406  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 4.1887  Validation loss = 10.3401  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 4.1883  Validation loss = 10.3396  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 4.1880  Validation loss = 10.3392  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 4.1878  Validation loss = 10.3389  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 4.1875  Validation loss = 10.3385  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 4.1872  Validation loss = 10.3380  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 4.1869  Validation loss = 10.3377  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 4.1867  Validation loss = 10.3374  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 4.1864  Validation loss = 10.3369  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 4.1862  Validation loss = 10.3366  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 4.1859  Validation loss = 10.3362  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 4.1856  Validation loss = 10.3358  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 4.1853  Validation loss = 10.3353  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 4.1850  Validation loss = 10.3350  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 4.1848  Validation loss = 10.3346  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 4.1845  Validation loss = 10.3343  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 4.1843  Validation loss = 10.3339  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 4.1840  Validation loss = 10.3335  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 4.1838  Validation loss = 10.3332  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 4.1834  Validation loss = 10.3327  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 4.1832  Validation loss = 10.3324  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 4.1829  Validation loss = 10.3320  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 4.1826  Validation loss = 10.3316  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 4.1824  Validation loss = 10.3313  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 4.1821  Validation loss = 10.3309  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 4.1818  Validation loss = 10.3305  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 4.1815  Validation loss = 10.3301  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 4.1813  Validation loss = 10.3297  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 4.1810  Validation loss = 10.3293  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 4.1807  Validation loss = 10.3290  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 4.1804  Validation loss = 10.3286  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 4.1801  Validation loss = 10.3282  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 4.1798  Validation loss = 10.3278  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 4.1796  Validation loss = 10.3275  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 4.1794  Validation loss = 10.3271  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 4.1791  Validation loss = 10.3267  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 4.1788  Validation loss = 10.3263  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 4.1785  Validation loss = 10.3259  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 4.1783  Validation loss = 10.3255  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 4.1780  Validation loss = 10.3252  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 4.1777  Validation loss = 10.3248  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 4.1775  Validation loss = 10.3244  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 4.1772  Validation loss = 10.3241  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 4.1769  Validation loss = 10.3236  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 4.1767  Validation loss = 10.3233  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 4.1765  Validation loss = 10.3230  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 4.1761  Validation loss = 10.3226  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 4.1759  Validation loss = 10.3222  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 4.1756  Validation loss = 10.3219  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 4.1754  Validation loss = 10.3215  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 4.1751  Validation loss = 10.3211  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 4.1748  Validation loss = 10.3207  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 4.1746  Validation loss = 10.3204  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 4.1743  Validation loss = 10.3200  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 4.1741  Validation loss = 10.3197  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 4.1738  Validation loss = 10.3193  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 4.1735  Validation loss = 10.3189  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 4.1733  Validation loss = 10.3186  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 4.1730  Validation loss = 10.3182  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 4.1728  Validation loss = 10.3179  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 4.1725  Validation loss = 10.3175  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 4.1722  Validation loss = 10.3171  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 4.1720  Validation loss = 10.3168  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 4.1716  Validation loss = 10.3164  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 4.1714  Validation loss = 10.3160  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 4.1711  Validation loss = 10.3157  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 4.1708  Validation loss = 10.3153  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 4.1706  Validation loss = 10.3149  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 4.1703  Validation loss = 10.3146  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 4.1701  Validation loss = 10.3143  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 4.1698  Validation loss = 10.3140  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 4.1694  Validation loss = 10.3135  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 4.1690  Validation loss = 10.3131  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 4.1687  Validation loss = 10.3127  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 4.1685  Validation loss = 10.3124  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 4.1681  Validation loss = 10.3120  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 4.1676  Validation loss = 10.3116  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 4.1672  Validation loss = 10.3112  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 4.1670  Validation loss = 10.3108  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 4.1662  Validation loss = 10.3105  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 4.1659  Validation loss = 10.3100  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 4.1642  Validation loss = 10.3096  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 4.1576  Validation loss = 10.3091  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 4.1570  Validation loss = 10.3088  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 4.1568  Validation loss = 10.3084  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 4.1564  Validation loss = 10.3080  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 4.1561  Validation loss = 10.3076  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 4.1557  Validation loss = 10.3072  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 4.1553  Validation loss = 10.3068  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 4.1550  Validation loss = 10.3064  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 4.1547  Validation loss = 10.3060  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 4.1544  Validation loss = 10.3056  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 4.1541  Validation loss = 10.3051  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 4.1538  Validation loss = 10.3048  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 4.1535  Validation loss = 10.3044  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 4.1532  Validation loss = 10.3040  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 4.1530  Validation loss = 10.3036  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 4.1527  Validation loss = 10.3033  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 4.1525  Validation loss = 10.3030  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 4.1522  Validation loss = 10.3025  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 4.1519  Validation loss = 10.3021  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 4.1516  Validation loss = 10.3017  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 4.1513  Validation loss = 10.3013  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 4.1511  Validation loss = 10.3010  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 4.1508  Validation loss = 10.3005  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 4.1505  Validation loss = 10.3002  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 4.1503  Validation loss = 10.2998  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 4.1500  Validation loss = 10.2994  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 4.1498  Validation loss = 10.2991  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 4.1495  Validation loss = 10.2987  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 4.1492  Validation loss = 10.2983  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 4.1489  Validation loss = 10.2979  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 4.1486  Validation loss = 10.2975  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 4.1484  Validation loss = 10.2972  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 4.1481  Validation loss = 10.2968  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 4.1478  Validation loss = 10.2964  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 4.1476  Validation loss = 10.2960  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 4.1473  Validation loss = 10.2957  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 4.1471  Validation loss = 10.2953  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 4.1468  Validation loss = 10.2949  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 4.1465  Validation loss = 10.2945  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 4.1463  Validation loss = 10.2941  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 4.1460  Validation loss = 10.2937  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 4.1456  Validation loss = 10.2933  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 4.1453  Validation loss = 10.2928  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 4.1450  Validation loss = 10.2924  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 4.1447  Validation loss = 10.2919  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 4.1444  Validation loss = 10.2916  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 4.1442  Validation loss = 10.2912  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 4.1439  Validation loss = 10.2908  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 4.1436  Validation loss = 10.2904  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 4.1433  Validation loss = 10.2900  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 4.1431  Validation loss = 10.2897  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 4.1428  Validation loss = 10.2893  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 4.1425  Validation loss = 10.2888  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 4.1422  Validation loss = 10.2884  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 4.1420  Validation loss = 10.2881  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 4.1418  Validation loss = 10.2877  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 4.1415  Validation loss = 10.2874  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 4.1413  Validation loss = 10.2871  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 4.1410  Validation loss = 10.2866  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 4.1407  Validation loss = 10.2862  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 4.1404  Validation loss = 10.2858  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 4.1401  Validation loss = 10.2853  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 4.1397  Validation loss = 10.2848  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 4.1394  Validation loss = 10.2844  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 4.1392  Validation loss = 10.2840  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 4.1389  Validation loss = 10.2836  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 4.1386  Validation loss = 10.2833  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 4.1384  Validation loss = 10.2829  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 4.1381  Validation loss = 10.2826  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 4.1378  Validation loss = 10.2822  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 4.1376  Validation loss = 10.2818  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 4.1373  Validation loss = 10.2814  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 4.1370  Validation loss = 10.2810  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 4.1368  Validation loss = 10.2807  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 4.1365  Validation loss = 10.2803  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 4.1362  Validation loss = 10.2799  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 4.1360  Validation loss = 10.2796  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 4.1357  Validation loss = 10.2792  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 4.1354  Validation loss = 10.2788  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 4.1351  Validation loss = 10.2783  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 4.1348  Validation loss = 10.2779  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 4.1345  Validation loss = 10.2775  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 4.1343  Validation loss = 10.2771  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 4.1340  Validation loss = 10.2767  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 4.1337  Validation loss = 10.2763  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 4.1334  Validation loss = 10.2759  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 4.1331  Validation loss = 10.2756  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 4.1328  Validation loss = 10.2751  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 4.1325  Validation loss = 10.2747  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 4.1322  Validation loss = 10.2743  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 4.1319  Validation loss = 10.2739  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 4.1316  Validation loss = 10.2734  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 4.1313  Validation loss = 10.2730  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 4.1310  Validation loss = 10.2725  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 4.1307  Validation loss = 10.2721  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 4.1305  Validation loss = 10.2718  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 4.1301  Validation loss = 10.2713  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 4.1298  Validation loss = 10.2709  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 4.1296  Validation loss = 10.2705  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 4.1293  Validation loss = 10.2701  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 4.1290  Validation loss = 10.2697  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 4.1287  Validation loss = 10.2693  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 4.1284  Validation loss = 10.2689  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 4.1281  Validation loss = 10.2685  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 4.1278  Validation loss = 10.2681  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 4.1276  Validation loss = 10.2677  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 4.1273  Validation loss = 10.2673  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 4.1270  Validation loss = 10.2669  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 4.1268  Validation loss = 10.2666  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 4.1264  Validation loss = 10.2661  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 4.1262  Validation loss = 10.2657  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 4.1259  Validation loss = 10.2653  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 4.1256  Validation loss = 10.2649  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 4.1253  Validation loss = 10.2645  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 4.1251  Validation loss = 10.2641  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 4.1248  Validation loss = 10.2637  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 4.1246  Validation loss = 10.2633  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 4.1243  Validation loss = 10.2629  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 4.1240  Validation loss = 10.2625  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 4.1237  Validation loss = 10.2622  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 4.1234  Validation loss = 10.2617  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 4.1232  Validation loss = 10.2614  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 4.1229  Validation loss = 10.2609  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 4.1226  Validation loss = 10.2605  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 4.1222  Validation loss = 10.2601  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 4.1220  Validation loss = 10.2597  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 4.1217  Validation loss = 10.2593  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 4.1214  Validation loss = 10.2590  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 4.1211  Validation loss = 10.2585  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 4.1208  Validation loss = 10.2580  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 4.1205  Validation loss = 10.2577  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 4.1202  Validation loss = 10.2573  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 4.1199  Validation loss = 10.2569  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 4.1197  Validation loss = 10.2564  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 4.1194  Validation loss = 10.2560  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 4.1191  Validation loss = 10.2557  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 4.1188  Validation loss = 10.2552  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 4.1185  Validation loss = 10.2548  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 4.1183  Validation loss = 10.2544  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 4.1180  Validation loss = 10.2540  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 4.1177  Validation loss = 10.2536  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 4.1174  Validation loss = 10.2532  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 4.1172  Validation loss = 10.2529  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 4.1170  Validation loss = 10.2526  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 4.1167  Validation loss = 10.2523  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 4.1165  Validation loss = 10.2519  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 4.1162  Validation loss = 10.2515  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 4.1159  Validation loss = 10.2511  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 4.1157  Validation loss = 10.2508  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 4.1154  Validation loss = 10.2504  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 4.1151  Validation loss = 10.2500  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 4.1149  Validation loss = 10.2496  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 4.1146  Validation loss = 10.2493  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 4.1143  Validation loss = 10.2489  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 4.1142  Validation loss = 10.2486  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 4.1139  Validation loss = 10.2483  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 4.1137  Validation loss = 10.2479  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 4.1134  Validation loss = 10.2475  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 4.1131  Validation loss = 10.2471  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 4.1128  Validation loss = 10.2467  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 4.1126  Validation loss = 10.2463  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 4.1123  Validation loss = 10.2459  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 4.1120  Validation loss = 10.2455  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 4.1118  Validation loss = 10.2452  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 4.1115  Validation loss = 10.2448  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 4.1113  Validation loss = 10.2444  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 4.1110  Validation loss = 10.2441  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 4.1108  Validation loss = 10.2437  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 4.1105  Validation loss = 10.2434  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 4.1103  Validation loss = 10.2431  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 4.1101  Validation loss = 10.2427  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 4.1098  Validation loss = 10.2423  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 4.1095  Validation loss = 10.2419  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 4.1092  Validation loss = 10.2415  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 4.1089  Validation loss = 10.2411  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 4.1087  Validation loss = 10.2407  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 4.1083  Validation loss = 10.2402  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 4.1081  Validation loss = 10.2398  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 4.1078  Validation loss = 10.2395  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 4.1076  Validation loss = 10.2391  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 4.1073  Validation loss = 10.2387  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 4.1070  Validation loss = 10.2383  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 4.1067  Validation loss = 10.2379  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 4.1066  Validation loss = 10.2377  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 4.1063  Validation loss = 10.2373  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 4.1061  Validation loss = 10.2370  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 4.1058  Validation loss = 10.2366  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 4.1055  Validation loss = 10.2362  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 4.1053  Validation loss = 10.2358  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 4.1050  Validation loss = 10.2354  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 4.1047  Validation loss = 10.2350  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 4.1044  Validation loss = 10.2346  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 4.1041  Validation loss = 10.2342  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 4.1039  Validation loss = 10.2339  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 4.1036  Validation loss = 10.2335  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 4.1034  Validation loss = 10.2331  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 4.1031  Validation loss = 10.2328  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 4.1029  Validation loss = 10.2325  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 4.1027  Validation loss = 10.2322  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 4.1024  Validation loss = 10.2318  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 4.1022  Validation loss = 10.2314  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 4.1018  Validation loss = 10.2309  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 4.1015  Validation loss = 10.2305  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 4.1012  Validation loss = 10.2300  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 4.1009  Validation loss = 10.2296  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 4.1007  Validation loss = 10.2293  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 4.1004  Validation loss = 10.2289  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 4.1001  Validation loss = 10.2285  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 4.0998  Validation loss = 10.2281  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 4.0996  Validation loss = 10.2278  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 4.0993  Validation loss = 10.2273  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 4.0990  Validation loss = 10.2270  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 4.0988  Validation loss = 10.2266  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 4.0985  Validation loss = 10.2262  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 4.0983  Validation loss = 10.2258  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 4.0980  Validation loss = 10.2254  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 4.0977  Validation loss = 10.2250  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 4.0974  Validation loss = 10.2246  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 4.0972  Validation loss = 10.2243  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 4.0970  Validation loss = 10.2240  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 4.0967  Validation loss = 10.2236  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 4.0964  Validation loss = 10.2232  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 4.0962  Validation loss = 10.2229  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 4.0960  Validation loss = 10.2225  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 4.0957  Validation loss = 10.2221  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 4.0954  Validation loss = 10.2217  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 4.0952  Validation loss = 10.2214  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 4.0949  Validation loss = 10.2209  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 4.0947  Validation loss = 10.2206  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 4.0944  Validation loss = 10.2203  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 4.0942  Validation loss = 10.2199  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 4.0939  Validation loss = 10.2195  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 4.0937  Validation loss = 10.2192  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 4.0934  Validation loss = 10.2188  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 4.0932  Validation loss = 10.2185  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 4.0929  Validation loss = 10.2181  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 4.0926  Validation loss = 10.2177  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 4.0923  Validation loss = 10.2172  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 4.0920  Validation loss = 10.2167  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 4.0917  Validation loss = 10.2164  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 4.0915  Validation loss = 10.2160  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 4.0912  Validation loss = 10.2156  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 4.0909  Validation loss = 10.2152  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 4.0907  Validation loss = 10.2148  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 4.0904  Validation loss = 10.2145  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 4.0901  Validation loss = 10.2140  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 4.0899  Validation loss = 10.2137  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 4.0897  Validation loss = 10.2134  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 4.0894  Validation loss = 10.2130  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 4.0892  Validation loss = 10.2127  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 4.0890  Validation loss = 10.2124  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 4.0887  Validation loss = 10.2120  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 4.0885  Validation loss = 10.2117  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 4.0882  Validation loss = 10.2113  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 4.0880  Validation loss = 10.2110  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 4.0877  Validation loss = 10.2106  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 4.0874  Validation loss = 10.2102  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 4.0872  Validation loss = 10.2098  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 4.0869  Validation loss = 10.2094  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 4.0867  Validation loss = 10.2091  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 4.0864  Validation loss = 10.2086  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 4.0860  Validation loss = 10.2081  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 4.0857  Validation loss = 10.2077  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 4.0855  Validation loss = 10.2073  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 4.0853  Validation loss = 10.2070  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 4.0850  Validation loss = 10.2067  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 4.0847  Validation loss = 10.2062  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 4.0845  Validation loss = 10.2059  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 4.0842  Validation loss = 10.2055  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 4.0840  Validation loss = 10.2051  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 4.0837  Validation loss = 10.2048  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 4.0835  Validation loss = 10.2044  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 4.0832  Validation loss = 10.2040  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 4.0828  Validation loss = 10.2034  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 4.0825  Validation loss = 10.2031  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 4.0822  Validation loss = 10.2027  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 4.0820  Validation loss = 10.2023  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 4.0817  Validation loss = 10.2018  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 4.0815  Validation loss = 10.2015  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 4.0812  Validation loss = 10.2012  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 4.0810  Validation loss = 10.2008  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 4.0807  Validation loss = 10.2004  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 4.0804  Validation loss = 10.2000  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 4.0802  Validation loss = 10.1996  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 4.0800  Validation loss = 10.1994  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 4.0797  Validation loss = 10.1989  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 4.0794  Validation loss = 10.1986  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 4.0791  Validation loss = 10.1980  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 4.0788  Validation loss = 10.1977  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 4.0785  Validation loss = 10.1972  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 4.0783  Validation loss = 10.1969  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 4.0780  Validation loss = 10.1965  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 4.0778  Validation loss = 10.1962  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 4.0775  Validation loss = 10.1958  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 4.0773  Validation loss = 10.1955  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 4.0770  Validation loss = 10.1951  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 4.0767  Validation loss = 10.1947  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 4.0765  Validation loss = 10.1943  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 4.0763  Validation loss = 10.1940  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 4.0760  Validation loss = 10.1936  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 4.0758  Validation loss = 10.1933  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 4.0756  Validation loss = 10.1929  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 4.0753  Validation loss = 10.1925  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 4.0750  Validation loss = 10.1921  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 4.0747  Validation loss = 10.1917  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 4.0745  Validation loss = 10.1914  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 4.0742  Validation loss = 10.1910  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 4.0739  Validation loss = 10.1905  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 4.0737  Validation loss = 10.1901  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 4.0734  Validation loss = 10.1897  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 4.0731  Validation loss = 10.1893  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 4.0729  Validation loss = 10.1890  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 4.0726  Validation loss = 10.1886  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 4.0723  Validation loss = 10.1882  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 4.0721  Validation loss = 10.1878  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 4.0718  Validation loss = 10.1874  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 4.0715  Validation loss = 10.1870  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 4.0712  Validation loss = 10.1866  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 4.0710  Validation loss = 10.1863  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 4.0707  Validation loss = 10.1859  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 4.0704  Validation loss = 10.1855  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 4.0702  Validation loss = 10.1851  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 4.0698  Validation loss = 10.1846  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 4.0696  Validation loss = 10.1843  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 4.0694  Validation loss = 10.1839  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 4.0691  Validation loss = 10.1836  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 4.0689  Validation loss = 10.1833  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 4.0686  Validation loss = 10.1829  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 4.0684  Validation loss = 10.1825  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 4.0681  Validation loss = 10.1820  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 4.0678  Validation loss = 10.1816  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 4.0676  Validation loss = 10.1813  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 4.0673  Validation loss = 10.1809  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 4.0670  Validation loss = 10.1805  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 4.0668  Validation loss = 10.1802  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 4.0664  Validation loss = 10.1797  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 4.0662  Validation loss = 10.1793  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 4.0659  Validation loss = 10.1789  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 4.0655  Validation loss = 10.1785  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 4.0652  Validation loss = 10.1781  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 4.0649  Validation loss = 10.1777  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 4.0647  Validation loss = 10.1774  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 4.0644  Validation loss = 10.1770  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 4.0641  Validation loss = 10.1767  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 4.0638  Validation loss = 10.1763  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 4.0634  Validation loss = 10.1759  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 4.0630  Validation loss = 10.1756  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 4.0624  Validation loss = 10.1752  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 4.0619  Validation loss = 10.1747  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 4.0616  Validation loss = 10.1744  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 4.0613  Validation loss = 10.1740  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 4.0604  Validation loss = 10.1736  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 4.0601  Validation loss = 10.1733  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 4.0591  Validation loss = 10.1729  \n",
      "\n",
      "Fold: 14  Epoch: 501  Training loss = 4.0582  Validation loss = 10.1725  \n",
      "\n",
      "Fold: 14  Epoch: 502  Training loss = 4.0578  Validation loss = 10.1721  \n",
      "\n",
      "Fold: 14  Epoch: 503  Training loss = 4.0575  Validation loss = 10.1717  \n",
      "\n",
      "Fold: 14  Epoch: 504  Training loss = 4.0572  Validation loss = 10.1714  \n",
      "\n",
      "Fold: 14  Epoch: 505  Training loss = 4.0569  Validation loss = 10.1710  \n",
      "\n",
      "Fold: 14  Epoch: 506  Training loss = 4.0567  Validation loss = 10.1706  \n",
      "\n",
      "Fold: 14  Epoch: 507  Training loss = 4.0564  Validation loss = 10.1703  \n",
      "\n",
      "Fold: 14  Epoch: 508  Training loss = 4.0561  Validation loss = 10.1699  \n",
      "\n",
      "Fold: 14  Epoch: 509  Training loss = 4.0559  Validation loss = 10.1696  \n",
      "\n",
      "Fold: 14  Epoch: 510  Training loss = 4.0556  Validation loss = 10.1692  \n",
      "\n",
      "Fold: 14  Epoch: 511  Training loss = 4.0554  Validation loss = 10.1688  \n",
      "\n",
      "Fold: 14  Epoch: 512  Training loss = 4.0551  Validation loss = 10.1684  \n",
      "\n",
      "Fold: 14  Epoch: 513  Training loss = 4.0549  Validation loss = 10.1681  \n",
      "\n",
      "Fold: 14  Epoch: 514  Training loss = 4.0546  Validation loss = 10.1678  \n",
      "\n",
      "Fold: 14  Epoch: 515  Training loss = 4.0544  Validation loss = 10.1674  \n",
      "\n",
      "Fold: 14  Epoch: 516  Training loss = 4.0541  Validation loss = 10.1670  \n",
      "\n",
      "Fold: 14  Epoch: 517  Training loss = 4.0538  Validation loss = 10.1665  \n",
      "\n",
      "Fold: 14  Epoch: 518  Training loss = 4.0535  Validation loss = 10.1661  \n",
      "\n",
      "Fold: 14  Epoch: 519  Training loss = 4.0532  Validation loss = 10.1657  \n",
      "\n",
      "Fold: 14  Epoch: 520  Training loss = 4.0530  Validation loss = 10.1653  \n",
      "\n",
      "Fold: 14  Epoch: 521  Training loss = 4.0527  Validation loss = 10.1649  \n",
      "\n",
      "Fold: 14  Epoch: 522  Training loss = 4.0525  Validation loss = 10.1646  \n",
      "\n",
      "Fold: 14  Epoch: 523  Training loss = 4.0522  Validation loss = 10.1643  \n",
      "\n",
      "Fold: 14  Epoch: 524  Training loss = 4.0520  Validation loss = 10.1639  \n",
      "\n",
      "Fold: 14  Epoch: 525  Training loss = 4.0517  Validation loss = 10.1636  \n",
      "\n",
      "Fold: 14  Epoch: 526  Training loss = 4.0515  Validation loss = 10.1632  \n",
      "\n",
      "Fold: 14  Epoch: 527  Training loss = 4.0512  Validation loss = 10.1627  \n",
      "\n",
      "Fold: 14  Epoch: 528  Training loss = 4.0509  Validation loss = 10.1623  \n",
      "\n",
      "Fold: 14  Epoch: 529  Training loss = 4.0506  Validation loss = 10.1620  \n",
      "\n",
      "Fold: 14  Epoch: 530  Training loss = 4.0504  Validation loss = 10.1616  \n",
      "\n",
      "Fold: 14  Epoch: 531  Training loss = 4.0502  Validation loss = 10.1613  \n",
      "\n",
      "Fold: 14  Epoch: 532  Training loss = 4.0499  Validation loss = 10.1609  \n",
      "\n",
      "Fold: 14  Epoch: 533  Training loss = 4.0496  Validation loss = 10.1605  \n",
      "\n",
      "Fold: 14  Epoch: 534  Training loss = 4.0493  Validation loss = 10.1601  \n",
      "\n",
      "Fold: 14  Epoch: 535  Training loss = 4.0491  Validation loss = 10.1597  \n",
      "\n",
      "Fold: 14  Epoch: 536  Training loss = 4.0488  Validation loss = 10.1593  \n",
      "\n",
      "Fold: 14  Epoch: 537  Training loss = 4.0486  Validation loss = 10.1590  \n",
      "\n",
      "Fold: 14  Epoch: 538  Training loss = 4.0483  Validation loss = 10.1585  \n",
      "\n",
      "Fold: 14  Epoch: 539  Training loss = 4.0481  Validation loss = 10.1582  \n",
      "\n",
      "Fold: 14  Epoch: 540  Training loss = 4.0478  Validation loss = 10.1578  \n",
      "\n",
      "Fold: 14  Epoch: 541  Training loss = 4.0475  Validation loss = 10.1574  \n",
      "\n",
      "Fold: 14  Epoch: 542  Training loss = 4.0473  Validation loss = 10.1570  \n",
      "\n",
      "Fold: 14  Epoch: 543  Training loss = 4.0469  Validation loss = 10.1565  \n",
      "\n",
      "Fold: 14  Epoch: 544  Training loss = 4.0466  Validation loss = 10.1561  \n",
      "\n",
      "Fold: 14  Epoch: 545  Training loss = 4.0464  Validation loss = 10.1558  \n",
      "\n",
      "Fold: 14  Epoch: 546  Training loss = 4.0461  Validation loss = 10.1554  \n",
      "\n",
      "Fold: 14  Epoch: 547  Training loss = 4.0459  Validation loss = 10.1551  \n",
      "\n",
      "Fold: 14  Epoch: 548  Training loss = 4.0456  Validation loss = 10.1547  \n",
      "\n",
      "Fold: 14  Epoch: 549  Training loss = 4.0454  Validation loss = 10.1543  \n",
      "\n",
      "Fold: 14  Epoch: 550  Training loss = 4.0451  Validation loss = 10.1539  \n",
      "\n",
      "Fold: 14  Epoch: 551  Training loss = 4.0448  Validation loss = 10.1535  \n",
      "\n",
      "Fold: 14  Epoch: 552  Training loss = 4.0446  Validation loss = 10.1531  \n",
      "\n",
      "Fold: 14  Epoch: 553  Training loss = 4.0443  Validation loss = 10.1527  \n",
      "\n",
      "Fold: 14  Epoch: 554  Training loss = 4.0440  Validation loss = 10.1523  \n",
      "\n",
      "Fold: 14  Epoch: 555  Training loss = 4.0438  Validation loss = 10.1520  \n",
      "\n",
      "Fold: 14  Epoch: 556  Training loss = 4.0435  Validation loss = 10.1515  \n",
      "\n",
      "Fold: 14  Epoch: 557  Training loss = 4.0432  Validation loss = 10.1511  \n",
      "\n",
      "Fold: 14  Epoch: 558  Training loss = 4.0429  Validation loss = 10.1507  \n",
      "\n",
      "Fold: 14  Epoch: 559  Training loss = 4.0427  Validation loss = 10.1503  \n",
      "\n",
      "Fold: 14  Epoch: 560  Training loss = 4.0424  Validation loss = 10.1499  \n",
      "\n",
      "Fold: 14  Epoch: 561  Training loss = 4.0421  Validation loss = 10.1495  \n",
      "\n",
      "Fold: 14  Epoch: 562  Training loss = 4.0419  Validation loss = 10.1492  \n",
      "\n",
      "Fold: 14  Epoch: 563  Training loss = 4.0417  Validation loss = 10.1488  \n",
      "\n",
      "Fold: 14  Epoch: 564  Training loss = 4.0414  Validation loss = 10.1484  \n",
      "\n",
      "Fold: 14  Epoch: 565  Training loss = 4.0412  Validation loss = 10.1481  \n",
      "\n",
      "Fold: 14  Epoch: 566  Training loss = 4.0409  Validation loss = 10.1477  \n",
      "\n",
      "Fold: 14  Epoch: 567  Training loss = 4.0406  Validation loss = 10.1473  \n",
      "\n",
      "Fold: 14  Epoch: 568  Training loss = 4.0403  Validation loss = 10.1469  \n",
      "\n",
      "Fold: 14  Epoch: 569  Training loss = 4.0401  Validation loss = 10.1465  \n",
      "\n",
      "Fold: 14  Epoch: 570  Training loss = 4.0398  Validation loss = 10.1460  \n",
      "\n",
      "Fold: 14  Epoch: 571  Training loss = 4.0395  Validation loss = 10.1456  \n",
      "\n",
      "Fold: 14  Epoch: 572  Training loss = 4.0392  Validation loss = 10.1452  \n",
      "\n",
      "Fold: 14  Epoch: 573  Training loss = 4.0390  Validation loss = 10.1448  \n",
      "\n",
      "Fold: 14  Epoch: 574  Training loss = 4.0388  Validation loss = 10.1445  \n",
      "\n",
      "Fold: 14  Epoch: 575  Training loss = 4.0385  Validation loss = 10.1441  \n",
      "\n",
      "Fold: 14  Epoch: 576  Training loss = 4.0382  Validation loss = 10.1437  \n",
      "\n",
      "Fold: 14  Epoch: 577  Training loss = 4.0380  Validation loss = 10.1434  \n",
      "\n",
      "Fold: 14  Epoch: 578  Training loss = 4.0377  Validation loss = 10.1430  \n",
      "\n",
      "Fold: 14  Epoch: 579  Training loss = 4.0374  Validation loss = 10.1426  \n",
      "\n",
      "Fold: 14  Epoch: 580  Training loss = 4.0372  Validation loss = 10.1422  \n",
      "\n",
      "Fold: 14  Epoch: 581  Training loss = 4.0369  Validation loss = 10.1418  \n",
      "\n",
      "Fold: 14  Epoch: 582  Training loss = 4.0367  Validation loss = 10.1415  \n",
      "\n",
      "Fold: 14  Epoch: 583  Training loss = 4.0365  Validation loss = 10.1411  \n",
      "\n",
      "Fold: 14  Epoch: 584  Training loss = 4.0362  Validation loss = 10.1407  \n",
      "\n",
      "Fold: 14  Epoch: 585  Training loss = 4.0359  Validation loss = 10.1404  \n",
      "\n",
      "Fold: 14  Epoch: 586  Training loss = 4.0357  Validation loss = 10.1401  \n",
      "\n",
      "Fold: 14  Epoch: 587  Training loss = 4.0355  Validation loss = 10.1397  \n",
      "\n",
      "Fold: 14  Epoch: 588  Training loss = 4.0352  Validation loss = 10.1393  \n",
      "\n",
      "Fold: 14  Epoch: 589  Training loss = 4.0350  Validation loss = 10.1389  \n",
      "\n",
      "Fold: 14  Epoch: 590  Training loss = 4.0347  Validation loss = 10.1386  \n",
      "\n",
      "Fold: 14  Epoch: 591  Training loss = 4.0345  Validation loss = 10.1381  \n",
      "\n",
      "Fold: 14  Epoch: 592  Training loss = 4.0342  Validation loss = 10.1378  \n",
      "\n",
      "Fold: 14  Epoch: 593  Training loss = 4.0340  Validation loss = 10.1374  \n",
      "\n",
      "Fold: 14  Epoch: 594  Training loss = 4.0337  Validation loss = 10.1370  \n",
      "\n",
      "Fold: 14  Epoch: 595  Training loss = 4.0334  Validation loss = 10.1365  \n",
      "\n",
      "Fold: 14  Epoch: 596  Training loss = 4.0331  Validation loss = 10.1361  \n",
      "\n",
      "Fold: 14  Epoch: 597  Training loss = 4.0328  Validation loss = 10.1357  \n",
      "\n",
      "Fold: 14  Epoch: 598  Training loss = 4.0325  Validation loss = 10.1353  \n",
      "\n",
      "Fold: 14  Epoch: 599  Training loss = 4.0322  Validation loss = 10.1349  \n",
      "\n",
      "Fold: 14  Epoch: 600  Training loss = 4.0320  Validation loss = 10.1345  \n",
      "\n",
      "Fold: 14  Epoch: 601  Training loss = 4.0318  Validation loss = 10.1341  \n",
      "\n",
      "Fold: 14  Epoch: 602  Training loss = 4.0315  Validation loss = 10.1338  \n",
      "\n",
      "Fold: 14  Epoch: 603  Training loss = 4.0312  Validation loss = 10.1334  \n",
      "\n",
      "Fold: 14  Epoch: 604  Training loss = 4.0310  Validation loss = 10.1330  \n",
      "\n",
      "Fold: 14  Epoch: 605  Training loss = 4.0307  Validation loss = 10.1326  \n",
      "\n",
      "Fold: 14  Epoch: 606  Training loss = 4.0304  Validation loss = 10.1322  \n",
      "\n",
      "Fold: 14  Epoch: 607  Training loss = 4.0301  Validation loss = 10.1317  \n",
      "\n",
      "Fold: 14  Epoch: 608  Training loss = 4.0299  Validation loss = 10.1313  \n",
      "\n",
      "Fold: 14  Epoch: 609  Training loss = 4.0296  Validation loss = 10.1309  \n",
      "\n",
      "Fold: 14  Epoch: 610  Training loss = 4.0293  Validation loss = 10.1305  \n",
      "\n",
      "Fold: 14  Epoch: 611  Training loss = 4.0291  Validation loss = 10.1302  \n",
      "\n",
      "Fold: 14  Epoch: 612  Training loss = 4.0288  Validation loss = 10.1298  \n",
      "\n",
      "Fold: 14  Epoch: 613  Training loss = 4.0286  Validation loss = 10.1294  \n",
      "\n",
      "Fold: 14  Epoch: 614  Training loss = 4.0283  Validation loss = 10.1290  \n",
      "\n",
      "Fold: 14  Epoch: 615  Training loss = 4.0281  Validation loss = 10.1287  \n",
      "\n",
      "Fold: 14  Epoch: 616  Training loss = 4.0278  Validation loss = 10.1283  \n",
      "\n",
      "Fold: 14  Epoch: 617  Training loss = 4.0276  Validation loss = 10.1279  \n",
      "\n",
      "Fold: 14  Epoch: 618  Training loss = 4.0273  Validation loss = 10.1276  \n",
      "\n",
      "Fold: 14  Epoch: 619  Training loss = 4.0270  Validation loss = 10.1271  \n",
      "\n",
      "Fold: 14  Epoch: 620  Training loss = 4.0268  Validation loss = 10.1267  \n",
      "\n",
      "Fold: 14  Epoch: 621  Training loss = 4.0265  Validation loss = 10.1264  \n",
      "\n",
      "Fold: 14  Epoch: 622  Training loss = 4.0263  Validation loss = 10.1260  \n",
      "\n",
      "Fold: 14  Epoch: 623  Training loss = 4.0261  Validation loss = 10.1257  \n",
      "\n",
      "Fold: 14  Epoch: 624  Training loss = 4.0258  Validation loss = 10.1253  \n",
      "\n",
      "Fold: 14  Epoch: 625  Training loss = 4.0255  Validation loss = 10.1249  \n",
      "\n",
      "Fold: 14  Epoch: 626  Training loss = 4.0253  Validation loss = 10.1245  \n",
      "\n",
      "Fold: 14  Epoch: 627  Training loss = 4.0250  Validation loss = 10.1240  \n",
      "\n",
      "Fold: 14  Epoch: 628  Training loss = 4.0247  Validation loss = 10.1236  \n",
      "\n",
      "Fold: 14  Epoch: 629  Training loss = 4.0244  Validation loss = 10.1232  \n",
      "\n",
      "Fold: 14  Epoch: 630  Training loss = 4.0241  Validation loss = 10.1228  \n",
      "\n",
      "Fold: 14  Epoch: 631  Training loss = 4.0238  Validation loss = 10.1224  \n",
      "\n",
      "Fold: 14  Epoch: 632  Training loss = 4.0236  Validation loss = 10.1220  \n",
      "\n",
      "Fold: 14  Epoch: 633  Training loss = 4.0233  Validation loss = 10.1216  \n",
      "\n",
      "Fold: 14  Epoch: 634  Training loss = 4.0230  Validation loss = 10.1211  \n",
      "\n",
      "Fold: 14  Epoch: 635  Training loss = 4.0228  Validation loss = 10.1208  \n",
      "\n",
      "Fold: 14  Epoch: 636  Training loss = 4.0225  Validation loss = 10.1204  \n",
      "\n",
      "Fold: 14  Epoch: 637  Training loss = 4.0223  Validation loss = 10.1201  \n",
      "\n",
      "Fold: 14  Epoch: 638  Training loss = 4.0220  Validation loss = 10.1196  \n",
      "\n",
      "Fold: 14  Epoch: 639  Training loss = 4.0218  Validation loss = 10.1193  \n",
      "\n",
      "Fold: 14  Epoch: 640  Training loss = 4.0215  Validation loss = 10.1189  \n",
      "\n",
      "Fold: 14  Epoch: 641  Training loss = 4.0212  Validation loss = 10.1185  \n",
      "\n",
      "Fold: 14  Epoch: 642  Training loss = 4.0210  Validation loss = 10.1182  \n",
      "\n",
      "Fold: 14  Epoch: 643  Training loss = 4.0208  Validation loss = 10.1178  \n",
      "\n",
      "Fold: 14  Epoch: 644  Training loss = 4.0205  Validation loss = 10.1174  \n",
      "\n",
      "Fold: 14  Epoch: 645  Training loss = 4.0203  Validation loss = 10.1171  \n",
      "\n",
      "Fold: 14  Epoch: 646  Training loss = 4.0201  Validation loss = 10.1167  \n",
      "\n",
      "Fold: 14  Epoch: 647  Training loss = 4.0198  Validation loss = 10.1163  \n",
      "\n",
      "Fold: 14  Epoch: 648  Training loss = 4.0195  Validation loss = 10.1159  \n",
      "\n",
      "Fold: 14  Epoch: 649  Training loss = 4.0192  Validation loss = 10.1155  \n",
      "\n",
      "Fold: 14  Epoch: 650  Training loss = 4.0190  Validation loss = 10.1152  \n",
      "\n",
      "Fold: 14  Epoch: 651  Training loss = 4.0187  Validation loss = 10.1148  \n",
      "\n",
      "Fold: 14  Epoch: 652  Training loss = 4.0185  Validation loss = 10.1144  \n",
      "\n",
      "Fold: 14  Epoch: 653  Training loss = 4.0182  Validation loss = 10.1140  \n",
      "\n",
      "Fold: 14  Epoch: 654  Training loss = 4.0180  Validation loss = 10.1136  \n",
      "\n",
      "Fold: 14  Epoch: 655  Training loss = 4.0177  Validation loss = 10.1132  \n",
      "\n",
      "Fold: 14  Epoch: 656  Training loss = 4.0175  Validation loss = 10.1129  \n",
      "\n",
      "Fold: 14  Epoch: 657  Training loss = 4.0172  Validation loss = 10.1125  \n",
      "\n",
      "Fold: 14  Epoch: 658  Training loss = 4.0169  Validation loss = 10.1121  \n",
      "\n",
      "Fold: 14  Epoch: 659  Training loss = 4.0167  Validation loss = 10.1117  \n",
      "\n",
      "Fold: 14  Epoch: 660  Training loss = 4.0164  Validation loss = 10.1113  \n",
      "\n",
      "Fold: 14  Epoch: 661  Training loss = 4.0161  Validation loss = 10.1109  \n",
      "\n",
      "Fold: 14  Epoch: 662  Training loss = 4.0159  Validation loss = 10.1105  \n",
      "\n",
      "Fold: 14  Epoch: 663  Training loss = 4.0157  Validation loss = 10.1102  \n",
      "\n",
      "Fold: 14  Epoch: 664  Training loss = 4.0154  Validation loss = 10.1098  \n",
      "\n",
      "Fold: 14  Epoch: 665  Training loss = 4.0153  Validation loss = 10.1096  \n",
      "\n",
      "Fold: 14  Epoch: 666  Training loss = 4.0150  Validation loss = 10.1092  \n",
      "\n",
      "Fold: 14  Epoch: 667  Training loss = 4.0148  Validation loss = 10.1089  \n",
      "\n",
      "Fold: 14  Epoch: 668  Training loss = 4.0145  Validation loss = 10.1085  \n",
      "\n",
      "Fold: 14  Epoch: 669  Training loss = 4.0143  Validation loss = 10.1081  \n",
      "\n",
      "Fold: 14  Epoch: 670  Training loss = 4.0140  Validation loss = 10.1077  \n",
      "\n",
      "Fold: 14  Epoch: 671  Training loss = 4.0137  Validation loss = 10.1073  \n",
      "\n",
      "Fold: 14  Epoch: 672  Training loss = 4.0135  Validation loss = 10.1069  \n",
      "\n",
      "Fold: 14  Epoch: 673  Training loss = 4.0132  Validation loss = 10.1066  \n",
      "\n",
      "Fold: 14  Epoch: 674  Training loss = 4.0130  Validation loss = 10.1062  \n",
      "\n",
      "Fold: 14  Epoch: 675  Training loss = 4.0127  Validation loss = 10.1058  \n",
      "\n",
      "Fold: 14  Epoch: 676  Training loss = 4.0124  Validation loss = 10.1053  \n",
      "\n",
      "Fold: 14  Epoch: 677  Training loss = 4.0121  Validation loss = 10.1049  \n",
      "\n",
      "Fold: 14  Epoch: 678  Training loss = 4.0118  Validation loss = 10.1045  \n",
      "\n",
      "Fold: 14  Epoch: 679  Training loss = 4.0116  Validation loss = 10.1041  \n",
      "\n",
      "Fold: 14  Epoch: 680  Training loss = 4.0113  Validation loss = 10.1037  \n",
      "\n",
      "Fold: 14  Epoch: 681  Training loss = 4.0110  Validation loss = 10.1032  \n",
      "\n",
      "Fold: 14  Epoch: 682  Training loss = 4.0107  Validation loss = 10.1028  \n",
      "\n",
      "Fold: 14  Epoch: 683  Training loss = 4.0105  Validation loss = 10.1024  \n",
      "\n",
      "Fold: 14  Epoch: 684  Training loss = 4.0102  Validation loss = 10.1020  \n",
      "\n",
      "Fold: 14  Epoch: 685  Training loss = 4.0099  Validation loss = 10.1016  \n",
      "\n",
      "Fold: 14  Epoch: 686  Training loss = 4.0097  Validation loss = 10.1012  \n",
      "\n",
      "Fold: 14  Epoch: 687  Training loss = 4.0094  Validation loss = 10.1008  \n",
      "\n",
      "Fold: 14  Epoch: 688  Training loss = 4.0092  Validation loss = 10.1004  \n",
      "\n",
      "Fold: 14  Epoch: 689  Training loss = 4.0089  Validation loss = 10.1000  \n",
      "\n",
      "Fold: 14  Epoch: 690  Training loss = 4.0087  Validation loss = 10.0996  \n",
      "\n",
      "Fold: 14  Epoch: 691  Training loss = 4.0084  Validation loss = 10.0992  \n",
      "\n",
      "Fold: 14  Epoch: 692  Training loss = 4.0081  Validation loss = 10.0989  \n",
      "\n",
      "Fold: 14  Epoch: 693  Training loss = 4.0078  Validation loss = 10.0984  \n",
      "\n",
      "Fold: 14  Epoch: 694  Training loss = 4.0076  Validation loss = 10.0980  \n",
      "\n",
      "Fold: 14  Epoch: 695  Training loss = 4.0073  Validation loss = 10.0976  \n",
      "\n",
      "Fold: 14  Epoch: 696  Training loss = 4.0071  Validation loss = 10.0973  \n",
      "\n",
      "Fold: 14  Epoch: 697  Training loss = 4.0068  Validation loss = 10.0969  \n",
      "\n",
      "Fold: 14  Epoch: 698  Training loss = 4.0066  Validation loss = 10.0965  \n",
      "\n",
      "Fold: 14  Epoch: 699  Training loss = 4.0064  Validation loss = 10.0962  \n",
      "\n",
      "Fold: 14  Epoch: 700  Training loss = 4.0062  Validation loss = 10.0958  \n",
      "\n",
      "Fold: 14  Epoch: 701  Training loss = 4.0058  Validation loss = 10.0954  \n",
      "\n",
      "Fold: 14  Epoch: 702  Training loss = 4.0055  Validation loss = 10.0949  \n",
      "\n",
      "Fold: 14  Epoch: 703  Training loss = 4.0053  Validation loss = 10.0945  \n",
      "\n",
      "Fold: 14  Epoch: 704  Training loss = 4.0050  Validation loss = 10.0941  \n",
      "\n",
      "Fold: 14  Epoch: 705  Training loss = 4.0047  Validation loss = 10.0936  \n",
      "\n",
      "Fold: 14  Epoch: 706  Training loss = 4.0044  Validation loss = 10.0932  \n",
      "\n",
      "Fold: 14  Epoch: 707  Training loss = 4.0042  Validation loss = 10.0929  \n",
      "\n",
      "Fold: 14  Epoch: 708  Training loss = 4.0039  Validation loss = 10.0925  \n",
      "\n",
      "Fold: 14  Epoch: 709  Training loss = 4.0036  Validation loss = 10.0921  \n",
      "\n",
      "Fold: 14  Epoch: 710  Training loss = 4.0035  Validation loss = 10.0918  \n",
      "\n",
      "Fold: 14  Epoch: 711  Training loss = 4.0031  Validation loss = 10.0913  \n",
      "\n",
      "Fold: 14  Epoch: 712  Training loss = 4.0029  Validation loss = 10.0910  \n",
      "\n",
      "Fold: 14  Epoch: 713  Training loss = 4.0027  Validation loss = 10.0907  \n",
      "\n",
      "Fold: 14  Epoch: 714  Training loss = 4.0024  Validation loss = 10.0903  \n",
      "\n",
      "Fold: 14  Epoch: 715  Training loss = 4.0022  Validation loss = 10.0899  \n",
      "\n",
      "Fold: 14  Epoch: 716  Training loss = 4.0019  Validation loss = 10.0895  \n",
      "\n",
      "Fold: 14  Epoch: 717  Training loss = 4.0017  Validation loss = 10.0891  \n",
      "\n",
      "Fold: 14  Epoch: 718  Training loss = 4.0014  Validation loss = 10.0887  \n",
      "\n",
      "Fold: 14  Epoch: 719  Training loss = 4.0012  Validation loss = 10.0883  \n",
      "\n",
      "Fold: 14  Epoch: 720  Training loss = 4.0010  Validation loss = 10.0880  \n",
      "\n",
      "Fold: 14  Epoch: 721  Training loss = 4.0007  Validation loss = 10.0876  \n",
      "\n",
      "Fold: 14  Epoch: 722  Training loss = 4.0004  Validation loss = 10.0871  \n",
      "\n",
      "Fold: 14  Epoch: 723  Training loss = 4.0002  Validation loss = 10.0868  \n",
      "\n",
      "Fold: 14  Epoch: 724  Training loss = 3.9999  Validation loss = 10.0864  \n",
      "\n",
      "Fold: 14  Epoch: 725  Training loss = 3.9996  Validation loss = 10.0861  \n",
      "\n",
      "Fold: 14  Epoch: 726  Training loss = 3.9994  Validation loss = 10.0857  \n",
      "\n",
      "Fold: 14  Epoch: 727  Training loss = 3.9992  Validation loss = 10.0853  \n",
      "\n",
      "Fold: 14  Epoch: 728  Training loss = 3.9989  Validation loss = 10.0850  \n",
      "\n",
      "Fold: 14  Epoch: 729  Training loss = 3.9987  Validation loss = 10.0846  \n",
      "\n",
      "Fold: 14  Epoch: 730  Training loss = 3.9984  Validation loss = 10.0842  \n",
      "\n",
      "Fold: 14  Epoch: 731  Training loss = 3.9982  Validation loss = 10.0839  \n",
      "\n",
      "Fold: 14  Epoch: 732  Training loss = 3.9980  Validation loss = 10.0836  \n",
      "\n",
      "Fold: 14  Epoch: 733  Training loss = 3.9978  Validation loss = 10.0833  \n",
      "\n",
      "Fold: 14  Epoch: 734  Training loss = 3.9975  Validation loss = 10.0828  \n",
      "\n",
      "Fold: 14  Epoch: 735  Training loss = 3.9972  Validation loss = 10.0824  \n",
      "\n",
      "Fold: 14  Epoch: 736  Training loss = 3.9970  Validation loss = 10.0820  \n",
      "\n",
      "Fold: 14  Epoch: 737  Training loss = 3.9967  Validation loss = 10.0817  \n",
      "\n",
      "Fold: 14  Epoch: 738  Training loss = 3.9965  Validation loss = 10.0813  \n",
      "\n",
      "Fold: 14  Epoch: 739  Training loss = 3.9962  Validation loss = 10.0808  \n",
      "\n",
      "Fold: 14  Epoch: 740  Training loss = 3.9959  Validation loss = 10.0804  \n",
      "\n",
      "Fold: 14  Epoch: 741  Training loss = 3.9957  Validation loss = 10.0800  \n",
      "\n",
      "Fold: 14  Epoch: 742  Training loss = 3.9954  Validation loss = 10.0796  \n",
      "\n",
      "Fold: 14  Epoch: 743  Training loss = 3.9951  Validation loss = 10.0792  \n",
      "\n",
      "Fold: 14  Epoch: 744  Training loss = 3.9948  Validation loss = 10.0788  \n",
      "\n",
      "Fold: 14  Epoch: 745  Training loss = 3.9946  Validation loss = 10.0784  \n",
      "\n",
      "Fold: 14  Epoch: 746  Training loss = 3.9944  Validation loss = 10.0780  \n",
      "\n",
      "Fold: 14  Epoch: 747  Training loss = 3.9940  Validation loss = 10.0775  \n",
      "\n",
      "Fold: 14  Epoch: 748  Training loss = 3.9938  Validation loss = 10.0772  \n",
      "\n",
      "Fold: 14  Epoch: 749  Training loss = 3.9935  Validation loss = 10.0768  \n",
      "\n",
      "Fold: 14  Epoch: 750  Training loss = 3.9932  Validation loss = 10.0763  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 750  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 4.7042  Validation loss = 10.8696  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 4.7038  Validation loss = 10.8692  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 4.7035  Validation loss = 10.8688  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 4.7031  Validation loss = 10.8685  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 4.7028  Validation loss = 10.8682  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 4.7024  Validation loss = 10.8678  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 4.7020  Validation loss = 10.8674  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 4.7017  Validation loss = 10.8670  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 4.7013  Validation loss = 10.8666  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 4.7010  Validation loss = 10.8663  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 4.7006  Validation loss = 10.8660  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 4.7003  Validation loss = 10.8656  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 4.7000  Validation loss = 10.8653  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 4.6996  Validation loss = 10.8649  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 4.6993  Validation loss = 10.8645  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 4.6989  Validation loss = 10.8641  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 4.6986  Validation loss = 10.8638  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 4.6983  Validation loss = 10.8635  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 4.6979  Validation loss = 10.8631  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 4.6976  Validation loss = 10.8627  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 4.6971  Validation loss = 10.8623  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 4.6968  Validation loss = 10.8619  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 4.6964  Validation loss = 10.8615  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 4.6961  Validation loss = 10.8612  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 4.6958  Validation loss = 10.8610  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 4.6955  Validation loss = 10.8607  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 4.6952  Validation loss = 10.8604  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 4.6949  Validation loss = 10.8601  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 4.6945  Validation loss = 10.8598  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 4.6943  Validation loss = 10.8595  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 4.6940  Validation loss = 10.8592  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 4.6936  Validation loss = 10.8588  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 4.6932  Validation loss = 10.8584  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 4.6929  Validation loss = 10.8581  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 4.6927  Validation loss = 10.8579  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 4.6923  Validation loss = 10.8575  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 4.6919  Validation loss = 10.8571  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 4.6916  Validation loss = 10.8567  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 4.6913  Validation loss = 10.8564  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 4.6910  Validation loss = 10.8561  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 4.6907  Validation loss = 10.8558  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 4.6904  Validation loss = 10.8555  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 4.6901  Validation loss = 10.8551  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 4.6897  Validation loss = 10.8546  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 4.6893  Validation loss = 10.8543  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 4.6890  Validation loss = 10.8540  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 4.6887  Validation loss = 10.8536  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 4.6883  Validation loss = 10.8533  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 4.6880  Validation loss = 10.8530  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 4.6878  Validation loss = 10.8527  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 4.6875  Validation loss = 10.8525  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 4.6871  Validation loss = 10.8521  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 4.6868  Validation loss = 10.8518  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 4.6865  Validation loss = 10.8515  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 4.6861  Validation loss = 10.8511  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 4.6857  Validation loss = 10.8507  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 4.6853  Validation loss = 10.8502  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 4.6850  Validation loss = 10.8498  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 4.6846  Validation loss = 10.8494  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 4.6843  Validation loss = 10.8492  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 4.6841  Validation loss = 10.8489  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 4.6837  Validation loss = 10.8485  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 4.6834  Validation loss = 10.8481  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 4.6831  Validation loss = 10.8478  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 4.6827  Validation loss = 10.8474  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 4.6824  Validation loss = 10.8470  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 4.6821  Validation loss = 10.8466  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 4.6817  Validation loss = 10.8462  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 4.6814  Validation loss = 10.8458  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 4.6810  Validation loss = 10.8454  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 4.6808  Validation loss = 10.8451  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 4.6805  Validation loss = 10.8449  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 4.6802  Validation loss = 10.8446  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 4.6799  Validation loss = 10.8443  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 4.6796  Validation loss = 10.8439  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 4.6792  Validation loss = 10.8436  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 4.6789  Validation loss = 10.8433  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 4.6785  Validation loss = 10.8429  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 4.6782  Validation loss = 10.8426  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 4.6779  Validation loss = 10.8422  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 4.6775  Validation loss = 10.8418  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 4.6772  Validation loss = 10.8414  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 4.6768  Validation loss = 10.8411  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 4.6765  Validation loss = 10.8408  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 4.6761  Validation loss = 10.8404  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 4.6758  Validation loss = 10.8400  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 4.6755  Validation loss = 10.8397  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 4.6752  Validation loss = 10.8393  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 4.6748  Validation loss = 10.8388  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 4.6744  Validation loss = 10.8384  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 4.6740  Validation loss = 10.8380  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 4.6737  Validation loss = 10.8376  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 4.6734  Validation loss = 10.8373  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 4.6730  Validation loss = 10.8367  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 4.6726  Validation loss = 10.8363  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 4.6723  Validation loss = 10.8360  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 4.6720  Validation loss = 10.8356  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 4.6717  Validation loss = 10.8352  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 4.6713  Validation loss = 10.8348  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 4.6709  Validation loss = 10.8344  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 4.6706  Validation loss = 10.8341  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 4.6703  Validation loss = 10.8338  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 4.6700  Validation loss = 10.8334  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 4.6697  Validation loss = 10.8331  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 4.6694  Validation loss = 10.8328  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 4.6691  Validation loss = 10.8324  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 4.6688  Validation loss = 10.8321  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 4.6685  Validation loss = 10.8318  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 4.6682  Validation loss = 10.8314  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 4.6678  Validation loss = 10.8309  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 4.6675  Validation loss = 10.8304  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 4.6672  Validation loss = 10.8301  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 4.6669  Validation loss = 10.8298  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 4.6666  Validation loss = 10.8295  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 4.6663  Validation loss = 10.8292  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 4.6660  Validation loss = 10.8288  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 4.6657  Validation loss = 10.8285  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 4.6654  Validation loss = 10.8282  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 4.6650  Validation loss = 10.8276  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 4.6647  Validation loss = 10.8273  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 4.6644  Validation loss = 10.8270  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 4.6639  Validation loss = 10.8264  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 4.6637  Validation loss = 10.8261  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 4.6634  Validation loss = 10.8258  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 4.6631  Validation loss = 10.8255  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 4.6628  Validation loss = 10.8252  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 4.6625  Validation loss = 10.8248  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 4.6622  Validation loss = 10.8244  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 4.6618  Validation loss = 10.8240  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 4.6614  Validation loss = 10.8234  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 4.6610  Validation loss = 10.8229  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 4.6606  Validation loss = 10.8224  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 4.6603  Validation loss = 10.8220  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 4.6600  Validation loss = 10.8217  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 4.6597  Validation loss = 10.8213  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 4.6594  Validation loss = 10.8209  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 4.6591  Validation loss = 10.8205  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 4.6587  Validation loss = 10.8199  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 4.6584  Validation loss = 10.8195  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 4.6580  Validation loss = 10.8191  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 4.6577  Validation loss = 10.8188  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 4.6573  Validation loss = 10.8182  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 4.6570  Validation loss = 10.8178  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 4.6567  Validation loss = 10.8175  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 4.6564  Validation loss = 10.8172  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 4.6560  Validation loss = 10.8167  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 4.6557  Validation loss = 10.8163  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 4.6554  Validation loss = 10.8158  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 4.6551  Validation loss = 10.8156  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 4.6548  Validation loss = 10.8152  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 4.6543  Validation loss = 10.8148  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 4.6540  Validation loss = 10.8145  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 4.6537  Validation loss = 10.8141  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 4.6533  Validation loss = 10.8136  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 4.6530  Validation loss = 10.8132  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 4.6526  Validation loss = 10.8128  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 4.6523  Validation loss = 10.8124  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 4.6520  Validation loss = 10.8121  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 4.6517  Validation loss = 10.8117  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 4.6513  Validation loss = 10.8113  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 4.6509  Validation loss = 10.8108  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 4.6506  Validation loss = 10.8105  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 4.6502  Validation loss = 10.8101  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 4.6499  Validation loss = 10.8098  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 4.6495  Validation loss = 10.8093  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 4.6492  Validation loss = 10.8088  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 4.6489  Validation loss = 10.8085  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 4.6485  Validation loss = 10.8080  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 4.6482  Validation loss = 10.8076  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 4.6478  Validation loss = 10.8072  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 4.6475  Validation loss = 10.8068  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 4.6471  Validation loss = 10.8064  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 4.6467  Validation loss = 10.8058  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 4.6464  Validation loss = 10.8054  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 4.6460  Validation loss = 10.8050  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 4.6456  Validation loss = 10.8046  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 4.6453  Validation loss = 10.8042  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 4.6449  Validation loss = 10.8038  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 4.6446  Validation loss = 10.8034  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 4.6443  Validation loss = 10.8030  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 4.6440  Validation loss = 10.8027  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 4.6437  Validation loss = 10.8024  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 4.6433  Validation loss = 10.8020  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 4.6430  Validation loss = 10.8016  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 4.6426  Validation loss = 10.8012  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 4.6423  Validation loss = 10.8009  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 4.6421  Validation loss = 10.8006  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 4.6418  Validation loss = 10.8003  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 4.6415  Validation loss = 10.7999  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 4.6411  Validation loss = 10.7995  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 4.6408  Validation loss = 10.7992  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 4.6405  Validation loss = 10.7989  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 4.6402  Validation loss = 10.7986  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 4.6399  Validation loss = 10.7982  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 4.6396  Validation loss = 10.7978  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 4.6393  Validation loss = 10.7975  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 4.6390  Validation loss = 10.7970  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 4.6386  Validation loss = 10.7966  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 4.6383  Validation loss = 10.7962  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 4.6380  Validation loss = 10.7959  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 4.6376  Validation loss = 10.7956  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 4.6373  Validation loss = 10.7953  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 4.6371  Validation loss = 10.7951  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 4.6368  Validation loss = 10.7947  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 4.6364  Validation loss = 10.7942  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 4.6361  Validation loss = 10.7938  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 4.6357  Validation loss = 10.7934  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 4.6354  Validation loss = 10.7930  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 4.6351  Validation loss = 10.7926  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 4.6347  Validation loss = 10.7921  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 4.6344  Validation loss = 10.7918  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 4.6341  Validation loss = 10.7915  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 4.6337  Validation loss = 10.7910  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 4.6334  Validation loss = 10.7907  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 4.6330  Validation loss = 10.7902  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 4.6327  Validation loss = 10.7897  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 4.6324  Validation loss = 10.7895  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 4.6321  Validation loss = 10.7891  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 4.6317  Validation loss = 10.7887  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 4.6315  Validation loss = 10.7884  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 4.6312  Validation loss = 10.7881  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 4.6308  Validation loss = 10.7876  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 4.6305  Validation loss = 10.7872  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 4.6301  Validation loss = 10.7868  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 4.6298  Validation loss = 10.7864  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 4.6296  Validation loss = 10.7861  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 4.6292  Validation loss = 10.7858  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 4.6289  Validation loss = 10.7853  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 4.6285  Validation loss = 10.7849  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 4.6282  Validation loss = 10.7846  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 4.6279  Validation loss = 10.7842  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 4.6275  Validation loss = 10.7839  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 4.6272  Validation loss = 10.7835  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 4.6268  Validation loss = 10.7831  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 4.6264  Validation loss = 10.7826  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 4.6261  Validation loss = 10.7822  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 4.6257  Validation loss = 10.7818  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 4.6254  Validation loss = 10.7815  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 4.6251  Validation loss = 10.7810  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 4.6247  Validation loss = 10.7806  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 4.6244  Validation loss = 10.7802  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 4.6240  Validation loss = 10.7797  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 4.6237  Validation loss = 10.7793  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 4.6233  Validation loss = 10.7790  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 4.6229  Validation loss = 10.7784  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 4.6226  Validation loss = 10.7780  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 4.6222  Validation loss = 10.7776  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 4.6218  Validation loss = 10.7772  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 4.6215  Validation loss = 10.7768  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 4.6212  Validation loss = 10.7764  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 4.6208  Validation loss = 10.7760  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 4.6205  Validation loss = 10.7757  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 4.6202  Validation loss = 10.7753  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 4.6198  Validation loss = 10.7750  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 4.6195  Validation loss = 10.7746  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 4.6191  Validation loss = 10.7742  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 4.6189  Validation loss = 10.7739  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 4.6185  Validation loss = 10.7735  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 4.6181  Validation loss = 10.7731  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 4.6178  Validation loss = 10.7727  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 4.6175  Validation loss = 10.7724  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 4.6172  Validation loss = 10.7721  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 4.6169  Validation loss = 10.7717  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 4.6165  Validation loss = 10.7713  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 4.6162  Validation loss = 10.7710  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 4.6159  Validation loss = 10.7707  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 4.6155  Validation loss = 10.7702  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 4.6152  Validation loss = 10.7699  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 4.6149  Validation loss = 10.7696  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 4.6146  Validation loss = 10.7692  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 4.6143  Validation loss = 10.7689  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 4.6140  Validation loss = 10.7685  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 4.6136  Validation loss = 10.7682  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 4.6133  Validation loss = 10.7678  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 4.6129  Validation loss = 10.7674  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 4.6126  Validation loss = 10.7670  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 4.6122  Validation loss = 10.7666  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 4.6120  Validation loss = 10.7664  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 4.6116  Validation loss = 10.7659  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 4.6112  Validation loss = 10.7656  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 4.6109  Validation loss = 10.7652  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 4.6106  Validation loss = 10.7648  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 4.6103  Validation loss = 10.7644  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 4.6099  Validation loss = 10.7640  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 4.6096  Validation loss = 10.7636  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 4.6093  Validation loss = 10.7633  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 4.6090  Validation loss = 10.7629  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 4.6086  Validation loss = 10.7625  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 4.6083  Validation loss = 10.7622  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 4.6080  Validation loss = 10.7619  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 4.6076  Validation loss = 10.7615  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 4.6073  Validation loss = 10.7611  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 4.6069  Validation loss = 10.7607  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 4.6066  Validation loss = 10.7604  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 4.6064  Validation loss = 10.7602  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 4.6061  Validation loss = 10.7599  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 4.6058  Validation loss = 10.7596  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 4.6055  Validation loss = 10.7593  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 4.6052  Validation loss = 10.7590  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 4.6049  Validation loss = 10.7586  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 4.6045  Validation loss = 10.7583  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 4.6042  Validation loss = 10.7578  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 4.6038  Validation loss = 10.7575  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 4.6035  Validation loss = 10.7571  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 4.6032  Validation loss = 10.7567  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 4.6029  Validation loss = 10.7564  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 4.6026  Validation loss = 10.7561  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 4.6022  Validation loss = 10.7557  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 4.6018  Validation loss = 10.7553  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 4.6014  Validation loss = 10.7548  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 4.6011  Validation loss = 10.7545  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 4.6009  Validation loss = 10.7542  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 4.6005  Validation loss = 10.7539  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 4.6002  Validation loss = 10.7535  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 4.5998  Validation loss = 10.7531  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 4.5994  Validation loss = 10.7527  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 4.5991  Validation loss = 10.7524  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 4.5988  Validation loss = 10.7520  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 4.5985  Validation loss = 10.7516  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 4.5982  Validation loss = 10.7513  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 4.5979  Validation loss = 10.7510  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 4.5975  Validation loss = 10.7506  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 4.5972  Validation loss = 10.7502  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 4.5968  Validation loss = 10.7499  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 4.5965  Validation loss = 10.7495  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 4.5962  Validation loss = 10.7492  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 4.5959  Validation loss = 10.7488  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 4.5956  Validation loss = 10.7485  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 4.5953  Validation loss = 10.7481  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 4.5949  Validation loss = 10.7478  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 4.5947  Validation loss = 10.7475  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 4.5943  Validation loss = 10.7471  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 4.5940  Validation loss = 10.7468  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 4.5937  Validation loss = 10.7466  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 4.5934  Validation loss = 10.7462  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 4.5931  Validation loss = 10.7459  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 4.5927  Validation loss = 10.7455  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 4.5924  Validation loss = 10.7452  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 4.5921  Validation loss = 10.7449  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 4.5918  Validation loss = 10.7446  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 4.5915  Validation loss = 10.7443  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 4.5911  Validation loss = 10.7439  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 4.5908  Validation loss = 10.7436  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 4.5905  Validation loss = 10.7433  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 4.5902  Validation loss = 10.7430  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 4.5899  Validation loss = 10.7427  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 4.5896  Validation loss = 10.7423  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 4.5892  Validation loss = 10.7419  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 4.5889  Validation loss = 10.7415  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 4.5886  Validation loss = 10.7412  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 4.5882  Validation loss = 10.7408  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 4.5879  Validation loss = 10.7404  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 4.5875  Validation loss = 10.7400  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 4.5872  Validation loss = 10.7397  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 4.5869  Validation loss = 10.7394  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 4.5866  Validation loss = 10.7390  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 4.5862  Validation loss = 10.7387  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 4.5859  Validation loss = 10.7383  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 4.5855  Validation loss = 10.7379  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 4.5852  Validation loss = 10.7376  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 4.5848  Validation loss = 10.7372  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 4.5845  Validation loss = 10.7369  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 4.5842  Validation loss = 10.7365  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 4.5838  Validation loss = 10.7362  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 4.5835  Validation loss = 10.7358  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 4.5832  Validation loss = 10.7355  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 4.5829  Validation loss = 10.7352  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 4.5826  Validation loss = 10.7348  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 4.5822  Validation loss = 10.7344  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 4.5819  Validation loss = 10.7341  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 4.5816  Validation loss = 10.7338  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 4.5813  Validation loss = 10.7334  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 4.5809  Validation loss = 10.7330  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 4.5805  Validation loss = 10.7326  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 4.5802  Validation loss = 10.7323  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 4.5799  Validation loss = 10.7320  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 4.5796  Validation loss = 10.7316  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 4.5792  Validation loss = 10.7312  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 4.5788  Validation loss = 10.7308  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 4.5785  Validation loss = 10.7305  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 4.5782  Validation loss = 10.7301  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 4.5779  Validation loss = 10.7298  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 4.5775  Validation loss = 10.7294  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 4.5773  Validation loss = 10.7292  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 4.5769  Validation loss = 10.7288  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 4.5765  Validation loss = 10.7283  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 4.5762  Validation loss = 10.7280  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 4.5759  Validation loss = 10.7276  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 4.5755  Validation loss = 10.7273  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 4.5751  Validation loss = 10.7269  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 4.5748  Validation loss = 10.7266  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 4.5745  Validation loss = 10.7262  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 4.5742  Validation loss = 10.7259  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 4.5738  Validation loss = 10.7255  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 4.5735  Validation loss = 10.7252  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 4.5732  Validation loss = 10.7248  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 4.5728  Validation loss = 10.7244  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 4.5724  Validation loss = 10.7240  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 4.5721  Validation loss = 10.7236  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 4.5718  Validation loss = 10.7233  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 4.5714  Validation loss = 10.7230  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 4.5711  Validation loss = 10.7225  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 4.5708  Validation loss = 10.7222  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 4.5704  Validation loss = 10.7218  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 4.5701  Validation loss = 10.7215  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 4.5698  Validation loss = 10.7211  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 4.5695  Validation loss = 10.7208  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 4.5692  Validation loss = 10.7204  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 4.5687  Validation loss = 10.7200  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 4.5684  Validation loss = 10.7196  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 4.5682  Validation loss = 10.7193  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 4.5678  Validation loss = 10.7189  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 4.5675  Validation loss = 10.7187  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 4.5672  Validation loss = 10.7183  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 4.5669  Validation loss = 10.7180  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 4.5665  Validation loss = 10.7175  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 4.5661  Validation loss = 10.7171  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 4.5658  Validation loss = 10.7167  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 4.5654  Validation loss = 10.7163  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 4.5651  Validation loss = 10.7160  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 4.5648  Validation loss = 10.7157  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 4.5644  Validation loss = 10.7154  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 4.5641  Validation loss = 10.7150  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 4.5638  Validation loss = 10.7147  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 4.5634  Validation loss = 10.7144  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 4.5631  Validation loss = 10.7140  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 4.5629  Validation loss = 10.7138  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 4.5626  Validation loss = 10.7134  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 4.5621  Validation loss = 10.7129  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 4.5618  Validation loss = 10.7126  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 4.5616  Validation loss = 10.7124  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 4.5613  Validation loss = 10.7121  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 4.5610  Validation loss = 10.7118  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 4.5607  Validation loss = 10.7114  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 4.5604  Validation loss = 10.7111  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 4.5601  Validation loss = 10.7109  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 4.5597  Validation loss = 10.7105  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 4.5595  Validation loss = 10.7102  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 4.5592  Validation loss = 10.7099  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 4.5589  Validation loss = 10.7096  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 4.5586  Validation loss = 10.7093  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 4.5583  Validation loss = 10.7090  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 4.5580  Validation loss = 10.7086  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 4.5577  Validation loss = 10.7083  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 4.5574  Validation loss = 10.7080  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 4.5570  Validation loss = 10.7077  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 4.5567  Validation loss = 10.7072  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 4.5564  Validation loss = 10.7069  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 4.5561  Validation loss = 10.7066  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 4.5558  Validation loss = 10.7063  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 4.5554  Validation loss = 10.7059  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 4.5550  Validation loss = 10.7055  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 4.5547  Validation loss = 10.7052  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 4.5544  Validation loss = 10.7048  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 4.5540  Validation loss = 10.7044  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 4.5537  Validation loss = 10.7041  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 4.5534  Validation loss = 10.7038  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 4.5531  Validation loss = 10.7035  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 4.5528  Validation loss = 10.7031  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 4.5524  Validation loss = 10.7028  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 4.5521  Validation loss = 10.7024  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 4.5517  Validation loss = 10.7021  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 4.5514  Validation loss = 10.7018  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 4.5511  Validation loss = 10.7014  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 4.5508  Validation loss = 10.7011  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 4.5504  Validation loss = 10.7008  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 4.5500  Validation loss = 10.7003  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 4.5497  Validation loss = 10.7000  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 4.5494  Validation loss = 10.6997  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 4.5492  Validation loss = 10.6995  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 4.5489  Validation loss = 10.6992  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 4.5485  Validation loss = 10.6988  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 4.5482  Validation loss = 10.6985  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 4.5479  Validation loss = 10.6982  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 4.5476  Validation loss = 10.6978  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 4.5473  Validation loss = 10.6975  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 4.5470  Validation loss = 10.6971  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 4.5467  Validation loss = 10.6968  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 4.5464  Validation loss = 10.6965  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 4.5460  Validation loss = 10.6961  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 4.5457  Validation loss = 10.6959  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 4.5454  Validation loss = 10.6956  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 4.5451  Validation loss = 10.6953  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 4.5448  Validation loss = 10.6949  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 4.5445  Validation loss = 10.6946  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 4.5443  Validation loss = 10.6943  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 4.5439  Validation loss = 10.6938  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 4.5436  Validation loss = 10.6936  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 4.5433  Validation loss = 10.6933  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 4.5430  Validation loss = 10.6929  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 4.5428  Validation loss = 10.6927  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 4.5425  Validation loss = 10.6924  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 4.5422  Validation loss = 10.6922  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 4.5419  Validation loss = 10.6918  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 4.5415  Validation loss = 10.6914  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 4.5412  Validation loss = 10.6910  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 4.5408  Validation loss = 10.6907  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 4.5405  Validation loss = 10.6904  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 4.5403  Validation loss = 10.6901  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 4.5400  Validation loss = 10.6898  \n",
      "\n",
      "Fold: 15  Epoch: 501  Training loss = 4.5397  Validation loss = 10.6895  \n",
      "\n",
      "Fold: 15  Epoch: 502  Training loss = 4.5394  Validation loss = 10.6891  \n",
      "\n",
      "Fold: 15  Epoch: 503  Training loss = 4.5391  Validation loss = 10.6888  \n",
      "\n",
      "Fold: 15  Epoch: 504  Training loss = 4.5388  Validation loss = 10.6885  \n",
      "\n",
      "Fold: 15  Epoch: 505  Training loss = 4.5385  Validation loss = 10.6882  \n",
      "\n",
      "Fold: 15  Epoch: 506  Training loss = 4.5382  Validation loss = 10.6879  \n",
      "\n",
      "Fold: 15  Epoch: 507  Training loss = 4.5379  Validation loss = 10.6876  \n",
      "\n",
      "Fold: 15  Epoch: 508  Training loss = 4.5376  Validation loss = 10.6872  \n",
      "\n",
      "Fold: 15  Epoch: 509  Training loss = 4.5373  Validation loss = 10.6869  \n",
      "\n",
      "Fold: 15  Epoch: 510  Training loss = 4.5370  Validation loss = 10.6866  \n",
      "\n",
      "Fold: 15  Epoch: 511  Training loss = 4.5367  Validation loss = 10.6863  \n",
      "\n",
      "Fold: 15  Epoch: 512  Training loss = 4.5364  Validation loss = 10.6859  \n",
      "\n",
      "Fold: 15  Epoch: 513  Training loss = 4.5360  Validation loss = 10.6856  \n",
      "\n",
      "Fold: 15  Epoch: 514  Training loss = 4.5358  Validation loss = 10.6853  \n",
      "\n",
      "Fold: 15  Epoch: 515  Training loss = 4.5354  Validation loss = 10.6849  \n",
      "\n",
      "Fold: 15  Epoch: 516  Training loss = 4.5352  Validation loss = 10.6847  \n",
      "\n",
      "Fold: 15  Epoch: 517  Training loss = 4.5349  Validation loss = 10.6844  \n",
      "\n",
      "Fold: 15  Epoch: 518  Training loss = 4.5347  Validation loss = 10.6841  \n",
      "\n",
      "Fold: 15  Epoch: 519  Training loss = 4.5344  Validation loss = 10.6839  \n",
      "\n",
      "Fold: 15  Epoch: 520  Training loss = 4.5341  Validation loss = 10.6835  \n",
      "\n",
      "Fold: 15  Epoch: 521  Training loss = 4.5338  Validation loss = 10.6832  \n",
      "\n",
      "Fold: 15  Epoch: 522  Training loss = 4.5335  Validation loss = 10.6829  \n",
      "\n",
      "Fold: 15  Epoch: 523  Training loss = 4.5332  Validation loss = 10.6825  \n",
      "\n",
      "Fold: 15  Epoch: 524  Training loss = 4.5329  Validation loss = 10.6821  \n",
      "\n",
      "Fold: 15  Epoch: 525  Training loss = 4.5325  Validation loss = 10.6818  \n",
      "\n",
      "Fold: 15  Epoch: 526  Training loss = 4.5322  Validation loss = 10.6815  \n",
      "\n",
      "Fold: 15  Epoch: 527  Training loss = 4.5320  Validation loss = 10.6813  \n",
      "\n",
      "Fold: 15  Epoch: 528  Training loss = 4.5317  Validation loss = 10.6809  \n",
      "\n",
      "Fold: 15  Epoch: 529  Training loss = 4.5313  Validation loss = 10.6805  \n",
      "\n",
      "Fold: 15  Epoch: 530  Training loss = 4.5310  Validation loss = 10.6802  \n",
      "\n",
      "Fold: 15  Epoch: 531  Training loss = 4.5307  Validation loss = 10.6798  \n",
      "\n",
      "Fold: 15  Epoch: 532  Training loss = 4.5303  Validation loss = 10.6794  \n",
      "\n",
      "Fold: 15  Epoch: 533  Training loss = 4.5301  Validation loss = 10.6791  \n",
      "\n",
      "Fold: 15  Epoch: 534  Training loss = 4.5298  Validation loss = 10.6788  \n",
      "\n",
      "Fold: 15  Epoch: 535  Training loss = 4.5294  Validation loss = 10.6785  \n",
      "\n",
      "Fold: 15  Epoch: 536  Training loss = 4.5291  Validation loss = 10.6781  \n",
      "\n",
      "Fold: 15  Epoch: 537  Training loss = 4.5287  Validation loss = 10.6777  \n",
      "\n",
      "Fold: 15  Epoch: 538  Training loss = 4.5284  Validation loss = 10.6773  \n",
      "\n",
      "Fold: 15  Epoch: 539  Training loss = 4.5280  Validation loss = 10.6770  \n",
      "\n",
      "Fold: 15  Epoch: 540  Training loss = 4.5277  Validation loss = 10.6766  \n",
      "\n",
      "Fold: 15  Epoch: 541  Training loss = 4.5274  Validation loss = 10.6762  \n",
      "\n",
      "Fold: 15  Epoch: 542  Training loss = 4.5270  Validation loss = 10.6758  \n",
      "\n",
      "Fold: 15  Epoch: 543  Training loss = 4.5268  Validation loss = 10.6756  \n",
      "\n",
      "Fold: 15  Epoch: 544  Training loss = 4.5264  Validation loss = 10.6752  \n",
      "\n",
      "Fold: 15  Epoch: 545  Training loss = 4.5262  Validation loss = 10.6749  \n",
      "\n",
      "Fold: 15  Epoch: 546  Training loss = 4.5258  Validation loss = 10.6745  \n",
      "\n",
      "Fold: 15  Epoch: 547  Training loss = 4.5254  Validation loss = 10.6741  \n",
      "\n",
      "Fold: 15  Epoch: 548  Training loss = 4.5251  Validation loss = 10.6738  \n",
      "\n",
      "Fold: 15  Epoch: 549  Training loss = 4.5248  Validation loss = 10.6734  \n",
      "\n",
      "Fold: 15  Epoch: 550  Training loss = 4.5244  Validation loss = 10.6730  \n",
      "\n",
      "Fold: 15  Epoch: 551  Training loss = 4.5241  Validation loss = 10.6727  \n",
      "\n",
      "Fold: 15  Epoch: 552  Training loss = 4.5238  Validation loss = 10.6725  \n",
      "\n",
      "Fold: 15  Epoch: 553  Training loss = 4.5236  Validation loss = 10.6721  \n",
      "\n",
      "Fold: 15  Epoch: 554  Training loss = 4.5232  Validation loss = 10.6718  \n",
      "\n",
      "Fold: 15  Epoch: 555  Training loss = 4.5230  Validation loss = 10.6715  \n",
      "\n",
      "Fold: 15  Epoch: 556  Training loss = 4.5227  Validation loss = 10.6712  \n",
      "\n",
      "Fold: 15  Epoch: 557  Training loss = 4.5224  Validation loss = 10.6707  \n",
      "\n",
      "Fold: 15  Epoch: 558  Training loss = 4.5220  Validation loss = 10.6704  \n",
      "\n",
      "Fold: 15  Epoch: 559  Training loss = 4.5217  Validation loss = 10.6701  \n",
      "\n",
      "Fold: 15  Epoch: 560  Training loss = 4.5214  Validation loss = 10.6697  \n",
      "\n",
      "Fold: 15  Epoch: 561  Training loss = 4.5211  Validation loss = 10.6693  \n",
      "\n",
      "Fold: 15  Epoch: 562  Training loss = 4.5207  Validation loss = 10.6690  \n",
      "\n",
      "Fold: 15  Epoch: 563  Training loss = 4.5204  Validation loss = 10.6686  \n",
      "\n",
      "Fold: 15  Epoch: 564  Training loss = 4.5200  Validation loss = 10.6682  \n",
      "\n",
      "Fold: 15  Epoch: 565  Training loss = 4.5198  Validation loss = 10.6680  \n",
      "\n",
      "Fold: 15  Epoch: 566  Training loss = 4.5194  Validation loss = 10.6676  \n",
      "\n",
      "Fold: 15  Epoch: 567  Training loss = 4.5190  Validation loss = 10.6672  \n",
      "\n",
      "Fold: 15  Epoch: 568  Training loss = 4.5187  Validation loss = 10.6669  \n",
      "\n",
      "Fold: 15  Epoch: 569  Training loss = 4.5184  Validation loss = 10.6666  \n",
      "\n",
      "Fold: 15  Epoch: 570  Training loss = 4.5181  Validation loss = 10.6662  \n",
      "\n",
      "Fold: 15  Epoch: 571  Training loss = 4.5177  Validation loss = 10.6658  \n",
      "\n",
      "Fold: 15  Epoch: 572  Training loss = 4.5174  Validation loss = 10.6655  \n",
      "\n",
      "Fold: 15  Epoch: 573  Training loss = 4.5171  Validation loss = 10.6652  \n",
      "\n",
      "Fold: 15  Epoch: 574  Training loss = 4.5168  Validation loss = 10.6649  \n",
      "\n",
      "Fold: 15  Epoch: 575  Training loss = 4.5164  Validation loss = 10.6645  \n",
      "\n",
      "Fold: 15  Epoch: 576  Training loss = 4.5161  Validation loss = 10.6642  \n",
      "\n",
      "Fold: 15  Epoch: 577  Training loss = 4.5159  Validation loss = 10.6639  \n",
      "\n",
      "Fold: 15  Epoch: 578  Training loss = 4.5156  Validation loss = 10.6636  \n",
      "\n",
      "Fold: 15  Epoch: 579  Training loss = 4.5152  Validation loss = 10.6633  \n",
      "\n",
      "Fold: 15  Epoch: 580  Training loss = 4.5149  Validation loss = 10.6630  \n",
      "\n",
      "Fold: 15  Epoch: 581  Training loss = 4.5146  Validation loss = 10.6627  \n",
      "\n",
      "Fold: 15  Epoch: 582  Training loss = 4.5143  Validation loss = 10.6623  \n",
      "\n",
      "Fold: 15  Epoch: 583  Training loss = 4.5140  Validation loss = 10.6620  \n",
      "\n",
      "Fold: 15  Epoch: 584  Training loss = 4.5137  Validation loss = 10.6616  \n",
      "\n",
      "Fold: 15  Epoch: 585  Training loss = 4.5133  Validation loss = 10.6613  \n",
      "\n",
      "Fold: 15  Epoch: 586  Training loss = 4.5130  Validation loss = 10.6609  \n",
      "\n",
      "Fold: 15  Epoch: 587  Training loss = 4.5127  Validation loss = 10.6606  \n",
      "\n",
      "Fold: 15  Epoch: 588  Training loss = 4.5124  Validation loss = 10.6603  \n",
      "\n",
      "Fold: 15  Epoch: 589  Training loss = 4.5121  Validation loss = 10.6600  \n",
      "\n",
      "Fold: 15  Epoch: 590  Training loss = 4.5118  Validation loss = 10.6597  \n",
      "\n",
      "Fold: 15  Epoch: 591  Training loss = 4.5115  Validation loss = 10.6593  \n",
      "\n",
      "Fold: 15  Epoch: 592  Training loss = 4.5112  Validation loss = 10.6589  \n",
      "\n",
      "Fold: 15  Epoch: 593  Training loss = 4.5109  Validation loss = 10.6586  \n",
      "\n",
      "Fold: 15  Epoch: 594  Training loss = 4.5105  Validation loss = 10.6583  \n",
      "\n",
      "Fold: 15  Epoch: 595  Training loss = 4.5103  Validation loss = 10.6580  \n",
      "\n",
      "Fold: 15  Epoch: 596  Training loss = 4.5101  Validation loss = 10.6577  \n",
      "\n",
      "Fold: 15  Epoch: 597  Training loss = 4.5097  Validation loss = 10.6574  \n",
      "\n",
      "Fold: 15  Epoch: 598  Training loss = 4.5095  Validation loss = 10.6571  \n",
      "\n",
      "Fold: 15  Epoch: 599  Training loss = 4.5091  Validation loss = 10.6568  \n",
      "\n",
      "Fold: 15  Epoch: 600  Training loss = 4.5088  Validation loss = 10.6565  \n",
      "\n",
      "Fold: 15  Epoch: 601  Training loss = 4.5085  Validation loss = 10.6561  \n",
      "\n",
      "Fold: 15  Epoch: 602  Training loss = 4.5081  Validation loss = 10.6557  \n",
      "\n",
      "Fold: 15  Epoch: 603  Training loss = 4.5078  Validation loss = 10.6553  \n",
      "\n",
      "Fold: 15  Epoch: 604  Training loss = 4.5075  Validation loss = 10.6550  \n",
      "\n",
      "Fold: 15  Epoch: 605  Training loss = 4.5072  Validation loss = 10.6547  \n",
      "\n",
      "Fold: 15  Epoch: 606  Training loss = 4.5069  Validation loss = 10.6544  \n",
      "\n",
      "Fold: 15  Epoch: 607  Training loss = 4.5066  Validation loss = 10.6541  \n",
      "\n",
      "Fold: 15  Epoch: 608  Training loss = 4.5063  Validation loss = 10.6538  \n",
      "\n",
      "Fold: 15  Epoch: 609  Training loss = 4.5059  Validation loss = 10.6534  \n",
      "\n",
      "Fold: 15  Epoch: 610  Training loss = 4.5055  Validation loss = 10.6530  \n",
      "\n",
      "Fold: 15  Epoch: 611  Training loss = 4.5052  Validation loss = 10.6526  \n",
      "\n",
      "Fold: 15  Epoch: 612  Training loss = 4.5048  Validation loss = 10.6522  \n",
      "\n",
      "Fold: 15  Epoch: 613  Training loss = 4.5045  Validation loss = 10.6518  \n",
      "\n",
      "Fold: 15  Epoch: 614  Training loss = 4.5042  Validation loss = 10.6515  \n",
      "\n",
      "Fold: 15  Epoch: 615  Training loss = 4.5038  Validation loss = 10.6511  \n",
      "\n",
      "Fold: 15  Epoch: 616  Training loss = 4.5035  Validation loss = 10.6508  \n",
      "\n",
      "Fold: 15  Epoch: 617  Training loss = 4.5031  Validation loss = 10.6503  \n",
      "\n",
      "Fold: 15  Epoch: 618  Training loss = 4.5028  Validation loss = 10.6500  \n",
      "\n",
      "Fold: 15  Epoch: 619  Training loss = 4.5025  Validation loss = 10.6497  \n",
      "\n",
      "Fold: 15  Epoch: 620  Training loss = 4.5023  Validation loss = 10.6494  \n",
      "\n",
      "Fold: 15  Epoch: 621  Training loss = 4.5019  Validation loss = 10.6491  \n",
      "\n",
      "Fold: 15  Epoch: 622  Training loss = 4.5016  Validation loss = 10.6488  \n",
      "\n",
      "Fold: 15  Epoch: 623  Training loss = 4.5013  Validation loss = 10.6485  \n",
      "\n",
      "Fold: 15  Epoch: 624  Training loss = 4.5010  Validation loss = 10.6482  \n",
      "\n",
      "Fold: 15  Epoch: 625  Training loss = 4.5007  Validation loss = 10.6479  \n",
      "\n",
      "Fold: 15  Epoch: 626  Training loss = 4.5005  Validation loss = 10.6476  \n",
      "\n",
      "Fold: 15  Epoch: 627  Training loss = 4.5002  Validation loss = 10.6473  \n",
      "\n",
      "Fold: 15  Epoch: 628  Training loss = 4.4999  Validation loss = 10.6470  \n",
      "\n",
      "Fold: 15  Epoch: 629  Training loss = 4.4996  Validation loss = 10.6467  \n",
      "\n",
      "Fold: 15  Epoch: 630  Training loss = 4.4993  Validation loss = 10.6463  \n",
      "\n",
      "Fold: 15  Epoch: 631  Training loss = 4.4989  Validation loss = 10.6459  \n",
      "\n",
      "Fold: 15  Epoch: 632  Training loss = 4.4986  Validation loss = 10.6456  \n",
      "\n",
      "Fold: 15  Epoch: 633  Training loss = 4.4983  Validation loss = 10.6453  \n",
      "\n",
      "Fold: 15  Epoch: 634  Training loss = 4.4979  Validation loss = 10.6449  \n",
      "\n",
      "Fold: 15  Epoch: 635  Training loss = 4.4976  Validation loss = 10.6445  \n",
      "\n",
      "Fold: 15  Epoch: 636  Training loss = 4.4972  Validation loss = 10.6441  \n",
      "\n",
      "Fold: 15  Epoch: 637  Training loss = 4.4969  Validation loss = 10.6438  \n",
      "\n",
      "Fold: 15  Epoch: 638  Training loss = 4.4966  Validation loss = 10.6434  \n",
      "\n",
      "Fold: 15  Epoch: 639  Training loss = 4.4963  Validation loss = 10.6431  \n",
      "\n",
      "Fold: 15  Epoch: 640  Training loss = 4.4960  Validation loss = 10.6428  \n",
      "\n",
      "Fold: 15  Epoch: 641  Training loss = 4.4957  Validation loss = 10.6425  \n",
      "\n",
      "Fold: 15  Epoch: 642  Training loss = 4.4954  Validation loss = 10.6421  \n",
      "\n",
      "Fold: 15  Epoch: 643  Training loss = 4.4951  Validation loss = 10.6418  \n",
      "\n",
      "Fold: 15  Epoch: 644  Training loss = 4.4947  Validation loss = 10.6414  \n",
      "\n",
      "Fold: 15  Epoch: 645  Training loss = 4.4944  Validation loss = 10.6411  \n",
      "\n",
      "Fold: 15  Epoch: 646  Training loss = 4.4941  Validation loss = 10.6408  \n",
      "\n",
      "Fold: 15  Epoch: 647  Training loss = 4.4938  Validation loss = 10.6405  \n",
      "\n",
      "Fold: 15  Epoch: 648  Training loss = 4.4935  Validation loss = 10.6401  \n",
      "\n",
      "Fold: 15  Epoch: 649  Training loss = 4.4932  Validation loss = 10.6398  \n",
      "\n",
      "Fold: 15  Epoch: 650  Training loss = 4.4929  Validation loss = 10.6394  \n",
      "\n",
      "Fold: 15  Epoch: 651  Training loss = 4.4925  Validation loss = 10.6391  \n",
      "\n",
      "Fold: 15  Epoch: 652  Training loss = 4.4923  Validation loss = 10.6388  \n",
      "\n",
      "Fold: 15  Epoch: 653  Training loss = 4.4920  Validation loss = 10.6384  \n",
      "\n",
      "Fold: 15  Epoch: 654  Training loss = 4.4916  Validation loss = 10.6381  \n",
      "\n",
      "Fold: 15  Epoch: 655  Training loss = 4.4914  Validation loss = 10.6378  \n",
      "\n",
      "Fold: 15  Epoch: 656  Training loss = 4.4910  Validation loss = 10.6374  \n",
      "\n",
      "Fold: 15  Epoch: 657  Training loss = 4.4907  Validation loss = 10.6370  \n",
      "\n",
      "Fold: 15  Epoch: 658  Training loss = 4.4904  Validation loss = 10.6367  \n",
      "\n",
      "Fold: 15  Epoch: 659  Training loss = 4.4901  Validation loss = 10.6364  \n",
      "\n",
      "Fold: 15  Epoch: 660  Training loss = 4.4898  Validation loss = 10.6360  \n",
      "\n",
      "Fold: 15  Epoch: 661  Training loss = 4.4895  Validation loss = 10.6357  \n",
      "\n",
      "Fold: 15  Epoch: 662  Training loss = 4.4892  Validation loss = 10.6354  \n",
      "\n",
      "Fold: 15  Epoch: 663  Training loss = 4.4889  Validation loss = 10.6351  \n",
      "\n",
      "Fold: 15  Epoch: 664  Training loss = 4.4886  Validation loss = 10.6348  \n",
      "\n",
      "Fold: 15  Epoch: 665  Training loss = 4.4883  Validation loss = 10.6345  \n",
      "\n",
      "Fold: 15  Epoch: 666  Training loss = 4.4880  Validation loss = 10.6340  \n",
      "\n",
      "Fold: 15  Epoch: 667  Training loss = 4.4877  Validation loss = 10.6337  \n",
      "\n",
      "Fold: 15  Epoch: 668  Training loss = 4.4874  Validation loss = 10.6334  \n",
      "\n",
      "Fold: 15  Epoch: 669  Training loss = 4.4871  Validation loss = 10.6331  \n",
      "\n",
      "Fold: 15  Epoch: 670  Training loss = 4.4868  Validation loss = 10.6328  \n",
      "\n",
      "Fold: 15  Epoch: 671  Training loss = 4.4865  Validation loss = 10.6325  \n",
      "\n",
      "Fold: 15  Epoch: 672  Training loss = 4.4861  Validation loss = 10.6320  \n",
      "\n",
      "Fold: 15  Epoch: 673  Training loss = 4.4858  Validation loss = 10.6317  \n",
      "\n",
      "Fold: 15  Epoch: 674  Training loss = 4.4854  Validation loss = 10.6313  \n",
      "\n",
      "Fold: 15  Epoch: 675  Training loss = 4.4851  Validation loss = 10.6309  \n",
      "\n",
      "Fold: 15  Epoch: 676  Training loss = 4.4848  Validation loss = 10.6306  \n",
      "\n",
      "Fold: 15  Epoch: 677  Training loss = 4.4845  Validation loss = 10.6303  \n",
      "\n",
      "Fold: 15  Epoch: 678  Training loss = 4.4842  Validation loss = 10.6300  \n",
      "\n",
      "Fold: 15  Epoch: 679  Training loss = 4.4839  Validation loss = 10.6297  \n",
      "\n",
      "Fold: 15  Epoch: 680  Training loss = 4.4836  Validation loss = 10.6295  \n",
      "\n",
      "Fold: 15  Epoch: 681  Training loss = 4.4833  Validation loss = 10.6291  \n",
      "\n",
      "Fold: 15  Epoch: 682  Training loss = 4.4831  Validation loss = 10.6289  \n",
      "\n",
      "Fold: 15  Epoch: 683  Training loss = 4.4827  Validation loss = 10.6285  \n",
      "\n",
      "Fold: 15  Epoch: 684  Training loss = 4.4825  Validation loss = 10.6282  \n",
      "\n",
      "Fold: 15  Epoch: 685  Training loss = 4.4821  Validation loss = 10.6278  \n",
      "\n",
      "Fold: 15  Epoch: 686  Training loss = 4.4819  Validation loss = 10.6276  \n",
      "\n",
      "Fold: 15  Epoch: 687  Training loss = 4.4815  Validation loss = 10.6272  \n",
      "\n",
      "Fold: 15  Epoch: 688  Training loss = 4.4812  Validation loss = 10.6268  \n",
      "\n",
      "Fold: 15  Epoch: 689  Training loss = 4.4809  Validation loss = 10.6265  \n",
      "\n",
      "Fold: 15  Epoch: 690  Training loss = 4.4806  Validation loss = 10.6262  \n",
      "\n",
      "Fold: 15  Epoch: 691  Training loss = 4.4803  Validation loss = 10.6259  \n",
      "\n",
      "Fold: 15  Epoch: 692  Training loss = 4.4799  Validation loss = 10.6255  \n",
      "\n",
      "Fold: 15  Epoch: 693  Training loss = 4.4797  Validation loss = 10.6253  \n",
      "\n",
      "Fold: 15  Epoch: 694  Training loss = 4.4794  Validation loss = 10.6250  \n",
      "\n",
      "Fold: 15  Epoch: 695  Training loss = 4.4790  Validation loss = 10.6246  \n",
      "\n",
      "Fold: 15  Epoch: 696  Training loss = 4.4786  Validation loss = 10.6242  \n",
      "\n",
      "Fold: 15  Epoch: 697  Training loss = 4.4783  Validation loss = 10.6239  \n",
      "\n",
      "Fold: 15  Epoch: 698  Training loss = 4.4781  Validation loss = 10.6236  \n",
      "\n",
      "Fold: 15  Epoch: 699  Training loss = 4.4777  Validation loss = 10.6232  \n",
      "\n",
      "Fold: 15  Epoch: 700  Training loss = 4.4774  Validation loss = 10.6229  \n",
      "\n",
      "Fold: 15  Epoch: 701  Training loss = 4.4771  Validation loss = 10.6226  \n",
      "\n",
      "Fold: 15  Epoch: 702  Training loss = 4.4768  Validation loss = 10.6222  \n",
      "\n",
      "Fold: 15  Epoch: 703  Training loss = 4.4765  Validation loss = 10.6220  \n",
      "\n",
      "Fold: 15  Epoch: 704  Training loss = 4.4762  Validation loss = 10.6217  \n",
      "\n",
      "Fold: 15  Epoch: 705  Training loss = 4.4759  Validation loss = 10.6214  \n",
      "\n",
      "Fold: 15  Epoch: 706  Training loss = 4.4756  Validation loss = 10.6211  \n",
      "\n",
      "Fold: 15  Epoch: 707  Training loss = 4.4754  Validation loss = 10.6208  \n",
      "\n",
      "Fold: 15  Epoch: 708  Training loss = 4.4750  Validation loss = 10.6204  \n",
      "\n",
      "Fold: 15  Epoch: 709  Training loss = 4.4747  Validation loss = 10.6201  \n",
      "\n",
      "Fold: 15  Epoch: 710  Training loss = 4.4744  Validation loss = 10.6198  \n",
      "\n",
      "Fold: 15  Epoch: 711  Training loss = 4.4741  Validation loss = 10.6195  \n",
      "\n",
      "Fold: 15  Epoch: 712  Training loss = 4.4738  Validation loss = 10.6191  \n",
      "\n",
      "Fold: 15  Epoch: 713  Training loss = 4.4735  Validation loss = 10.6189  \n",
      "\n",
      "Fold: 15  Epoch: 714  Training loss = 4.4732  Validation loss = 10.6185  \n",
      "\n",
      "Fold: 15  Epoch: 715  Training loss = 4.4728  Validation loss = 10.6180  \n",
      "\n",
      "Fold: 15  Epoch: 716  Training loss = 4.4725  Validation loss = 10.6177  \n",
      "\n",
      "Fold: 15  Epoch: 717  Training loss = 4.4722  Validation loss = 10.6174  \n",
      "\n",
      "Fold: 15  Epoch: 718  Training loss = 4.4719  Validation loss = 10.6171  \n",
      "\n",
      "Fold: 15  Epoch: 719  Training loss = 4.4715  Validation loss = 10.6167  \n",
      "\n",
      "Fold: 15  Epoch: 720  Training loss = 4.4712  Validation loss = 10.6164  \n",
      "\n",
      "Fold: 15  Epoch: 721  Training loss = 4.4709  Validation loss = 10.6161  \n",
      "\n",
      "Fold: 15  Epoch: 722  Training loss = 4.4706  Validation loss = 10.6157  \n",
      "\n",
      "Fold: 15  Epoch: 723  Training loss = 4.4703  Validation loss = 10.6154  \n",
      "\n",
      "Fold: 15  Epoch: 724  Training loss = 4.4699  Validation loss = 10.6150  \n",
      "\n",
      "Fold: 15  Epoch: 725  Training loss = 4.4696  Validation loss = 10.6147  \n",
      "\n",
      "Fold: 15  Epoch: 726  Training loss = 4.4693  Validation loss = 10.6143  \n",
      "\n",
      "Fold: 15  Epoch: 727  Training loss = 4.4689  Validation loss = 10.6139  \n",
      "\n",
      "Fold: 15  Epoch: 728  Training loss = 4.4687  Validation loss = 10.6137  \n",
      "\n",
      "Fold: 15  Epoch: 729  Training loss = 4.4683  Validation loss = 10.6133  \n",
      "\n",
      "Fold: 15  Epoch: 730  Training loss = 4.4680  Validation loss = 10.6129  \n",
      "\n",
      "Fold: 15  Epoch: 731  Training loss = 4.4677  Validation loss = 10.6126  \n",
      "\n",
      "Fold: 15  Epoch: 732  Training loss = 4.4674  Validation loss = 10.6123  \n",
      "\n",
      "Fold: 15  Epoch: 733  Training loss = 4.4670  Validation loss = 10.6119  \n",
      "\n",
      "Fold: 15  Epoch: 734  Training loss = 4.4667  Validation loss = 10.6116  \n",
      "\n",
      "Fold: 15  Epoch: 735  Training loss = 4.4664  Validation loss = 10.6112  \n",
      "\n",
      "Fold: 15  Epoch: 736  Training loss = 4.4661  Validation loss = 10.6109  \n",
      "\n",
      "Fold: 15  Epoch: 737  Training loss = 4.4658  Validation loss = 10.6106  \n",
      "\n",
      "Fold: 15  Epoch: 738  Training loss = 4.4655  Validation loss = 10.6103  \n",
      "\n",
      "Fold: 15  Epoch: 739  Training loss = 4.4652  Validation loss = 10.6099  \n",
      "\n",
      "Fold: 15  Epoch: 740  Training loss = 4.4648  Validation loss = 10.6096  \n",
      "\n",
      "Fold: 15  Epoch: 741  Training loss = 4.4645  Validation loss = 10.6092  \n",
      "\n",
      "Fold: 15  Epoch: 742  Training loss = 4.4642  Validation loss = 10.6089  \n",
      "\n",
      "Fold: 15  Epoch: 743  Training loss = 4.4639  Validation loss = 10.6086  \n",
      "\n",
      "Fold: 15  Epoch: 744  Training loss = 4.4636  Validation loss = 10.6082  \n",
      "\n",
      "Fold: 15  Epoch: 745  Training loss = 4.4633  Validation loss = 10.6080  \n",
      "\n",
      "Fold: 15  Epoch: 746  Training loss = 4.4631  Validation loss = 10.6077  \n",
      "\n",
      "Fold: 15  Epoch: 747  Training loss = 4.4627  Validation loss = 10.6073  \n",
      "\n",
      "Fold: 15  Epoch: 748  Training loss = 4.4624  Validation loss = 10.6070  \n",
      "\n",
      "Fold: 15  Epoch: 749  Training loss = 4.4621  Validation loss = 10.6067  \n",
      "\n",
      "Fold: 15  Epoch: 750  Training loss = 4.4618  Validation loss = 10.6064  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 750  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 5.1683  Validation loss = 7.3053  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 5.1680  Validation loss = 7.3048  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 5.1676  Validation loss = 7.3044  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 5.1672  Validation loss = 7.3039  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 5.1669  Validation loss = 7.3036  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 5.1665  Validation loss = 7.3032  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 5.1661  Validation loss = 7.3027  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 5.1658  Validation loss = 7.3023  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 5.1654  Validation loss = 7.3019  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 5.1651  Validation loss = 7.3015  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 5.1647  Validation loss = 7.3011  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 5.1643  Validation loss = 7.3006  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 5.1640  Validation loss = 7.3002  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 5.1635  Validation loss = 7.2997  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 5.1631  Validation loss = 7.2992  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 5.1628  Validation loss = 7.2988  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 5.1624  Validation loss = 7.2984  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 5.1620  Validation loss = 7.2979  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 5.1617  Validation loss = 7.2975  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 5.1613  Validation loss = 7.2971  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 5.1608  Validation loss = 7.2966  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 5.1605  Validation loss = 7.2961  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 5.1601  Validation loss = 7.2957  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 5.1597  Validation loss = 7.2953  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 5.1593  Validation loss = 7.2948  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 5.1590  Validation loss = 7.2945  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 5.1587  Validation loss = 7.2941  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 5.1584  Validation loss = 7.2937  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 5.1580  Validation loss = 7.2933  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 5.1576  Validation loss = 7.2928  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 5.1573  Validation loss = 7.2924  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 5.1569  Validation loss = 7.2920  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 5.1565  Validation loss = 7.2915  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 5.1561  Validation loss = 7.2911  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 5.1557  Validation loss = 7.2906  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 5.1554  Validation loss = 7.2903  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 5.1551  Validation loss = 7.2899  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 5.1548  Validation loss = 7.2896  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 5.1544  Validation loss = 7.2891  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 5.1541  Validation loss = 7.2887  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 5.1537  Validation loss = 7.2882  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 5.1533  Validation loss = 7.2879  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 5.1529  Validation loss = 7.2874  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 5.1525  Validation loss = 7.2870  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 5.1521  Validation loss = 7.2865  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 5.1518  Validation loss = 7.2861  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 5.1514  Validation loss = 7.2856  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 5.1510  Validation loss = 7.2852  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 5.1507  Validation loss = 7.2848  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 5.1502  Validation loss = 7.2843  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 5.1498  Validation loss = 7.2838  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 5.1495  Validation loss = 7.2834  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 5.1491  Validation loss = 7.2830  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 5.1487  Validation loss = 7.2825  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 5.1484  Validation loss = 7.2821  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 5.1479  Validation loss = 7.2815  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 5.1475  Validation loss = 7.2811  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 5.1471  Validation loss = 7.2805  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 5.1466  Validation loss = 7.2800  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 5.1462  Validation loss = 7.2796  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 5.1458  Validation loss = 7.2791  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 5.1454  Validation loss = 7.2786  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 5.1450  Validation loss = 7.2782  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 5.1446  Validation loss = 7.2777  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 5.1442  Validation loss = 7.2772  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 5.1438  Validation loss = 7.2767  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 5.1434  Validation loss = 7.2763  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 5.1430  Validation loss = 7.2758  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 5.1427  Validation loss = 7.2755  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 5.1423  Validation loss = 7.2749  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 5.1419  Validation loss = 7.2745  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 5.1415  Validation loss = 7.2740  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 5.1411  Validation loss = 7.2736  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 5.1407  Validation loss = 7.2731  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 5.1403  Validation loss = 7.2726  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 5.1399  Validation loss = 7.2721  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 5.1395  Validation loss = 7.2716  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 5.1390  Validation loss = 7.2711  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 5.1386  Validation loss = 7.2707  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 5.1383  Validation loss = 7.2702  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 5.1378  Validation loss = 7.2697  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 5.1374  Validation loss = 7.2692  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 5.1370  Validation loss = 7.2687  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 5.1366  Validation loss = 7.2682  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 5.1361  Validation loss = 7.2677  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 5.1358  Validation loss = 7.2673  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 5.1353  Validation loss = 7.2668  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 5.1349  Validation loss = 7.2663  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 5.1345  Validation loss = 7.2658  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 5.1341  Validation loss = 7.2653  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 5.1337  Validation loss = 7.2649  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 5.1334  Validation loss = 7.2645  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 5.1330  Validation loss = 7.2640  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 5.1325  Validation loss = 7.2635  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 5.1322  Validation loss = 7.2631  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 5.1318  Validation loss = 7.2626  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 5.1315  Validation loss = 7.2623  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 5.1310  Validation loss = 7.2618  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 5.1306  Validation loss = 7.2613  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 5.1302  Validation loss = 7.2608  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 5.1298  Validation loss = 7.2603  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 5.1294  Validation loss = 7.2598  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 5.1289  Validation loss = 7.2593  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 5.1286  Validation loss = 7.2589  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 5.1281  Validation loss = 7.2584  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 5.1277  Validation loss = 7.2578  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 5.1272  Validation loss = 7.2574  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 5.1269  Validation loss = 7.2569  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 5.1264  Validation loss = 7.2564  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 5.1260  Validation loss = 7.2559  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 5.1257  Validation loss = 7.2555  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 5.1253  Validation loss = 7.2551  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 5.1250  Validation loss = 7.2547  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 5.1246  Validation loss = 7.2543  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 5.1241  Validation loss = 7.2537  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 5.1237  Validation loss = 7.2532  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 5.1234  Validation loss = 7.2528  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 5.1230  Validation loss = 7.2524  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 5.1226  Validation loss = 7.2519  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 5.1222  Validation loss = 7.2515  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 5.1219  Validation loss = 7.2511  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 5.1216  Validation loss = 7.2507  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 5.1212  Validation loss = 7.2502  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 5.1207  Validation loss = 7.2497  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 5.1203  Validation loss = 7.2493  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 5.1200  Validation loss = 7.2489  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 5.1196  Validation loss = 7.2485  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 5.1193  Validation loss = 7.2481  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 5.1189  Validation loss = 7.2476  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 5.1185  Validation loss = 7.2471  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 5.1181  Validation loss = 7.2467  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 5.1177  Validation loss = 7.2462  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 5.1173  Validation loss = 7.2457  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 5.1168  Validation loss = 7.2451  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 5.1164  Validation loss = 7.2446  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 5.1160  Validation loss = 7.2442  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 5.1156  Validation loss = 7.2437  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 5.1153  Validation loss = 7.2433  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 5.1149  Validation loss = 7.2429  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 5.1144  Validation loss = 7.2424  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 5.1140  Validation loss = 7.2418  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 5.1137  Validation loss = 7.2415  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 5.1133  Validation loss = 7.2410  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 5.1129  Validation loss = 7.2406  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 5.1126  Validation loss = 7.2402  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 5.1122  Validation loss = 7.2398  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 5.1118  Validation loss = 7.2393  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 5.1114  Validation loss = 7.2389  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 5.1111  Validation loss = 7.2385  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 5.1106  Validation loss = 7.2379  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 5.1102  Validation loss = 7.2374  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 5.1097  Validation loss = 7.2369  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 5.1092  Validation loss = 7.2363  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 5.1088  Validation loss = 7.2358  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 5.1085  Validation loss = 7.2355  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 5.1081  Validation loss = 7.2350  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 5.1076  Validation loss = 7.2345  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 5.1073  Validation loss = 7.2341  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 5.1069  Validation loss = 7.2336  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 5.1066  Validation loss = 7.2332  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 5.1063  Validation loss = 7.2329  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 5.1059  Validation loss = 7.2325  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 5.1055  Validation loss = 7.2320  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 5.1051  Validation loss = 7.2315  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 5.1047  Validation loss = 7.2311  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 5.1043  Validation loss = 7.2306  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 5.1038  Validation loss = 7.2300  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 5.1035  Validation loss = 7.2296  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 5.1031  Validation loss = 7.2292  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 5.1027  Validation loss = 7.2287  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 5.1022  Validation loss = 7.2281  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 5.1018  Validation loss = 7.2276  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 5.1014  Validation loss = 7.2273  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 5.1010  Validation loss = 7.2268  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 5.1007  Validation loss = 7.2264  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 5.1002  Validation loss = 7.2259  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 5.0999  Validation loss = 7.2254  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 5.0995  Validation loss = 7.2250  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 5.0992  Validation loss = 7.2246  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 5.0988  Validation loss = 7.2242  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 5.0984  Validation loss = 7.2237  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 5.0981  Validation loss = 7.2233  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 5.0977  Validation loss = 7.2229  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 5.0972  Validation loss = 7.2223  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 5.0968  Validation loss = 7.2219  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 5.0964  Validation loss = 7.2214  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 5.0961  Validation loss = 7.2210  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 5.0957  Validation loss = 7.2206  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 5.0953  Validation loss = 7.2201  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 5.0948  Validation loss = 7.2195  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 5.0943  Validation loss = 7.2190  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 5.0940  Validation loss = 7.2186  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 5.0935  Validation loss = 7.2181  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 5.0931  Validation loss = 7.2176  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 5.0926  Validation loss = 7.2171  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 5.0922  Validation loss = 7.2166  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 5.0917  Validation loss = 7.2161  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 5.0913  Validation loss = 7.2156  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 5.0909  Validation loss = 7.2152  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 5.0905  Validation loss = 7.2147  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 5.0901  Validation loss = 7.2143  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 5.0897  Validation loss = 7.2138  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 5.0891  Validation loss = 7.2132  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 5.0886  Validation loss = 7.2128  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 5.0875  Validation loss = 7.2121  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 5.0866  Validation loss = 7.2116  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 5.0847  Validation loss = 7.2109  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 5.0838  Validation loss = 7.2104  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 5.0832  Validation loss = 7.2099  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 5.0827  Validation loss = 7.2094  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 5.0822  Validation loss = 7.2089  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 5.0819  Validation loss = 7.2086  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 5.0815  Validation loss = 7.2082  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 5.0811  Validation loss = 7.2077  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 5.0807  Validation loss = 7.2073  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 5.0802  Validation loss = 7.2067  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 5.0798  Validation loss = 7.2062  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 5.0794  Validation loss = 7.2058  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 5.0790  Validation loss = 7.2053  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 5.0786  Validation loss = 7.2048  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 5.0781  Validation loss = 7.2044  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 5.0778  Validation loss = 7.2039  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 5.0774  Validation loss = 7.2035  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 5.0771  Validation loss = 7.2031  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 5.0767  Validation loss = 7.2026  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 5.0763  Validation loss = 7.2022  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 5.0759  Validation loss = 7.2018  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 5.0756  Validation loss = 7.2014  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 5.0753  Validation loss = 7.2010  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 5.0749  Validation loss = 7.2006  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 5.0745  Validation loss = 7.2001  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 5.0741  Validation loss = 7.1997  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 5.0738  Validation loss = 7.1993  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 5.0733  Validation loss = 7.1988  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 5.0729  Validation loss = 7.1983  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 5.0726  Validation loss = 7.1979  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 5.0722  Validation loss = 7.1975  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 5.0718  Validation loss = 7.1970  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 5.0714  Validation loss = 7.1965  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 5.0709  Validation loss = 7.1960  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 5.0706  Validation loss = 7.1955  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 5.0702  Validation loss = 7.1951  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 5.0698  Validation loss = 7.1946  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 5.0694  Validation loss = 7.1942  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 5.0690  Validation loss = 7.1938  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 5.0687  Validation loss = 7.1933  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 5.0683  Validation loss = 7.1929  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 5.0678  Validation loss = 7.1924  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 5.0674  Validation loss = 7.1919  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 5.0670  Validation loss = 7.1914  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 5.0666  Validation loss = 7.1909  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 5.0661  Validation loss = 7.1904  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 5.0659  Validation loss = 7.1901  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 5.0654  Validation loss = 7.1896  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 5.0651  Validation loss = 7.1892  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 5.0647  Validation loss = 7.1888  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 5.0643  Validation loss = 7.1884  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 5.0639  Validation loss = 7.1879  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 5.0635  Validation loss = 7.1874  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 5.0632  Validation loss = 7.1870  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 5.0628  Validation loss = 7.1866  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 5.0624  Validation loss = 7.1861  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 5.0619  Validation loss = 7.1855  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 5.0616  Validation loss = 7.1852  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 5.0612  Validation loss = 7.1848  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 5.0609  Validation loss = 7.1843  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 5.0605  Validation loss = 7.1839  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 5.0602  Validation loss = 7.1836  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 5.0597  Validation loss = 7.1830  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 5.0593  Validation loss = 7.1825  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 5.0588  Validation loss = 7.1820  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 5.0585  Validation loss = 7.1816  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 5.0581  Validation loss = 7.1811  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 5.0577  Validation loss = 7.1807  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 5.0574  Validation loss = 7.1803  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 5.0570  Validation loss = 7.1799  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 5.0566  Validation loss = 7.1794  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 5.0563  Validation loss = 7.1790  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 5.0559  Validation loss = 7.1785  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 5.0555  Validation loss = 7.1781  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 5.0552  Validation loss = 7.1777  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 5.0548  Validation loss = 7.1773  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 5.0544  Validation loss = 7.1768  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 5.0540  Validation loss = 7.1763  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 5.0537  Validation loss = 7.1759  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 5.0533  Validation loss = 7.1755  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 5.0528  Validation loss = 7.1750  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 5.0524  Validation loss = 7.1745  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 5.0520  Validation loss = 7.1740  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 5.0516  Validation loss = 7.1735  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 5.0512  Validation loss = 7.1730  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 5.0508  Validation loss = 7.1726  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 5.0505  Validation loss = 7.1722  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 5.0501  Validation loss = 7.1717  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 5.0498  Validation loss = 7.1713  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 5.0494  Validation loss = 7.1710  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 5.0491  Validation loss = 7.1706  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 5.0488  Validation loss = 7.1702  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 5.0485  Validation loss = 7.1698  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 5.0482  Validation loss = 7.1694  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 5.0479  Validation loss = 7.1691  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 5.0474  Validation loss = 7.1686  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 5.0471  Validation loss = 7.1682  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 5.0468  Validation loss = 7.1678  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 5.0463  Validation loss = 7.1672  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 5.0458  Validation loss = 7.1667  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 5.0454  Validation loss = 7.1662  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 5.0451  Validation loss = 7.1659  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 5.0446  Validation loss = 7.1653  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 5.0443  Validation loss = 7.1649  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 5.0439  Validation loss = 7.1644  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 5.0435  Validation loss = 7.1640  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 5.0431  Validation loss = 7.1636  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 5.0428  Validation loss = 7.1631  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 5.0424  Validation loss = 7.1627  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 5.0420  Validation loss = 7.1623  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 5.0416  Validation loss = 7.1618  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 5.0412  Validation loss = 7.1613  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 5.0409  Validation loss = 7.1610  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 5.0405  Validation loss = 7.1604  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 5.0402  Validation loss = 7.1601  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 5.0398  Validation loss = 7.1597  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 5.0395  Validation loss = 7.1593  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 5.0392  Validation loss = 7.1589  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 5.0388  Validation loss = 7.1585  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 5.0384  Validation loss = 7.1580  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 5.0381  Validation loss = 7.1576  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 5.0377  Validation loss = 7.1571  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 5.0373  Validation loss = 7.1567  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 5.0370  Validation loss = 7.1563  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 5.0366  Validation loss = 7.1558  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 5.0362  Validation loss = 7.1554  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 5.0359  Validation loss = 7.1550  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 5.0355  Validation loss = 7.1546  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 5.0352  Validation loss = 7.1542  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 5.0348  Validation loss = 7.1538  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 5.0344  Validation loss = 7.1533  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 5.0341  Validation loss = 7.1529  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 5.0338  Validation loss = 7.1526  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 5.0334  Validation loss = 7.1522  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 5.0330  Validation loss = 7.1517  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 5.0326  Validation loss = 7.1512  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 5.0322  Validation loss = 7.1507  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 5.0317  Validation loss = 7.1501  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 5.0313  Validation loss = 7.1497  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 5.0309  Validation loss = 7.1492  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 5.0305  Validation loss = 7.1488  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 5.0302  Validation loss = 7.1484  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 5.0298  Validation loss = 7.1480  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 5.0295  Validation loss = 7.1475  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 5.0291  Validation loss = 7.1472  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 5.0288  Validation loss = 7.1467  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 5.0284  Validation loss = 7.1463  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 5.0280  Validation loss = 7.1459  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 5.0276  Validation loss = 7.1453  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 5.0272  Validation loss = 7.1449  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 5.0268  Validation loss = 7.1443  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 5.0264  Validation loss = 7.1439  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 5.0259  Validation loss = 7.1433  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 5.0255  Validation loss = 7.1429  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 5.0252  Validation loss = 7.1425  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 5.0249  Validation loss = 7.1421  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 5.0245  Validation loss = 7.1417  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 5.0242  Validation loss = 7.1413  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 5.0238  Validation loss = 7.1408  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 5.0234  Validation loss = 7.1404  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 5.0231  Validation loss = 7.1400  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 5.0226  Validation loss = 7.1395  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 5.0223  Validation loss = 7.1391  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 5.0218  Validation loss = 7.1386  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 5.0215  Validation loss = 7.1382  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 5.0212  Validation loss = 7.1378  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 5.0209  Validation loss = 7.1375  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 5.0206  Validation loss = 7.1371  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 5.0203  Validation loss = 7.1368  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 5.0200  Validation loss = 7.1364  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 5.0196  Validation loss = 7.1360  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 5.0193  Validation loss = 7.1356  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 5.0190  Validation loss = 7.1352  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 5.0186  Validation loss = 7.1348  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 5.0182  Validation loss = 7.1343  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 5.0178  Validation loss = 7.1339  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 5.0174  Validation loss = 7.1334  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 5.0170  Validation loss = 7.1329  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 5.0167  Validation loss = 7.1325  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 5.0163  Validation loss = 7.1321  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 5.0159  Validation loss = 7.1317  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 5.0155  Validation loss = 7.1312  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 5.0152  Validation loss = 7.1308  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 5.0148  Validation loss = 7.1304  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 5.0145  Validation loss = 7.1300  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 5.0141  Validation loss = 7.1296  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 5.0138  Validation loss = 7.1292  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 5.0135  Validation loss = 7.1288  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 5.0131  Validation loss = 7.1284  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 5.0128  Validation loss = 7.1279  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 5.0124  Validation loss = 7.1275  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 5.0120  Validation loss = 7.1270  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 5.0116  Validation loss = 7.1266  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 5.0113  Validation loss = 7.1261  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 5.0109  Validation loss = 7.1257  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 5.0104  Validation loss = 7.1251  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 5.0100  Validation loss = 7.1247  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 5.0097  Validation loss = 7.1243  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 5.0093  Validation loss = 7.1238  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 5.0089  Validation loss = 7.1233  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 5.0086  Validation loss = 7.1230  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 5.0082  Validation loss = 7.1225  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 5.0078  Validation loss = 7.1221  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 5.0075  Validation loss = 7.1217  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 5.0070  Validation loss = 7.1212  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 5.0067  Validation loss = 7.1208  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 5.0063  Validation loss = 7.1203  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 5.0059  Validation loss = 7.1199  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 5.0056  Validation loss = 7.1195  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 5.0051  Validation loss = 7.1190  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 5.0048  Validation loss = 7.1185  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 5.0044  Validation loss = 7.1180  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 5.0040  Validation loss = 7.1176  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 5.0035  Validation loss = 7.1171  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 5.0032  Validation loss = 7.1167  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 5.0029  Validation loss = 7.1162  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 5.0026  Validation loss = 7.1159  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 5.0022  Validation loss = 7.1155  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 5.0018  Validation loss = 7.1150  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 5.0014  Validation loss = 7.1145  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 5.0010  Validation loss = 7.1141  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 5.0007  Validation loss = 7.1137  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 5.0002  Validation loss = 7.1132  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 4.9998  Validation loss = 7.1127  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 4.9994  Validation loss = 7.1122  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 4.9990  Validation loss = 7.1117  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 4.9987  Validation loss = 7.1114  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 4.9984  Validation loss = 7.1110  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 4.9980  Validation loss = 7.1105  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 4.9976  Validation loss = 7.1101  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 4.9973  Validation loss = 7.1097  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 4.9969  Validation loss = 7.1092  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 4.9966  Validation loss = 7.1089  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 4.9962  Validation loss = 7.1084  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 4.9958  Validation loss = 7.1079  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 4.9954  Validation loss = 7.1074  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 4.9950  Validation loss = 7.1070  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 4.9947  Validation loss = 7.1066  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 4.9943  Validation loss = 7.1062  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 4.9940  Validation loss = 7.1058  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 4.9936  Validation loss = 7.1054  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 4.9932  Validation loss = 7.1049  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 4.9930  Validation loss = 7.1046  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 4.9927  Validation loss = 7.1043  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 4.9923  Validation loss = 7.1038  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 4.9919  Validation loss = 7.1034  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 4.9916  Validation loss = 7.1030  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 4.9912  Validation loss = 7.1025  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 4.9909  Validation loss = 7.1021  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 4.9905  Validation loss = 7.1017  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 4.9901  Validation loss = 7.1012  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 4.9897  Validation loss = 7.1007  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 4.9894  Validation loss = 7.1004  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 4.9890  Validation loss = 7.1000  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 4.9886  Validation loss = 7.0995  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 4.9883  Validation loss = 7.0990  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 4.9879  Validation loss = 7.0986  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 4.9876  Validation loss = 7.0982  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 4.9872  Validation loss = 7.0978  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 4.9868  Validation loss = 7.0974  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 4.9865  Validation loss = 7.0970  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 4.9862  Validation loss = 7.0966  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 4.9859  Validation loss = 7.0963  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 4.9856  Validation loss = 7.0960  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 4.9851  Validation loss = 7.0954  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 4.9847  Validation loss = 7.0950  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 4.9843  Validation loss = 7.0945  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 4.9839  Validation loss = 7.0940  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 4.9837  Validation loss = 7.0937  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 4.9833  Validation loss = 7.0933  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 4.9830  Validation loss = 7.0929  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 4.9826  Validation loss = 7.0925  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 4.9822  Validation loss = 7.0921  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 4.9819  Validation loss = 7.0917  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 4.9815  Validation loss = 7.0912  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 4.9811  Validation loss = 7.0908  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 4.9808  Validation loss = 7.0904  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 4.9804  Validation loss = 7.0900  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 4.9800  Validation loss = 7.0895  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 4.9796  Validation loss = 7.0890  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 4.9792  Validation loss = 7.0886  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 4.9789  Validation loss = 7.0882  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 4.9786  Validation loss = 7.0878  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 4.9781  Validation loss = 7.0873  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 4.9777  Validation loss = 7.0868  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 4.9773  Validation loss = 7.0864  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 4.9770  Validation loss = 7.0860  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 4.9767  Validation loss = 7.0856  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 4.9763  Validation loss = 7.0852  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 4.9760  Validation loss = 7.0848  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 4.9756  Validation loss = 7.0843  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 4.9752  Validation loss = 7.0839  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 4.9749  Validation loss = 7.0835  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 4.9745  Validation loss = 7.0830  \n",
      "\n",
      "Fold: 16  Epoch: 501  Training loss = 4.9742  Validation loss = 7.0826  \n",
      "\n",
      "Fold: 16  Epoch: 502  Training loss = 4.9738  Validation loss = 7.0822  \n",
      "\n",
      "Fold: 16  Epoch: 503  Training loss = 4.9735  Validation loss = 7.0818  \n",
      "\n",
      "Fold: 16  Epoch: 504  Training loss = 4.9731  Validation loss = 7.0814  \n",
      "\n",
      "Fold: 16  Epoch: 505  Training loss = 4.9727  Validation loss = 7.0809  \n",
      "\n",
      "Fold: 16  Epoch: 506  Training loss = 4.9723  Validation loss = 7.0804  \n",
      "\n",
      "Fold: 16  Epoch: 507  Training loss = 4.9719  Validation loss = 7.0799  \n",
      "\n",
      "Fold: 16  Epoch: 508  Training loss = 4.9715  Validation loss = 7.0795  \n",
      "\n",
      "Fold: 16  Epoch: 509  Training loss = 4.9711  Validation loss = 7.0791  \n",
      "\n",
      "Fold: 16  Epoch: 510  Training loss = 4.9708  Validation loss = 7.0786  \n",
      "\n",
      "Fold: 16  Epoch: 511  Training loss = 4.9705  Validation loss = 7.0783  \n",
      "\n",
      "Fold: 16  Epoch: 512  Training loss = 4.9701  Validation loss = 7.0778  \n",
      "\n",
      "Fold: 16  Epoch: 513  Training loss = 4.9697  Validation loss = 7.0774  \n",
      "\n",
      "Fold: 16  Epoch: 514  Training loss = 4.9694  Validation loss = 7.0769  \n",
      "\n",
      "Fold: 16  Epoch: 515  Training loss = 4.9690  Validation loss = 7.0766  \n",
      "\n",
      "Fold: 16  Epoch: 516  Training loss = 4.9687  Validation loss = 7.0762  \n",
      "\n",
      "Fold: 16  Epoch: 517  Training loss = 4.9683  Validation loss = 7.0757  \n",
      "\n",
      "Fold: 16  Epoch: 518  Training loss = 4.9680  Validation loss = 7.0753  \n",
      "\n",
      "Fold: 16  Epoch: 519  Training loss = 4.9676  Validation loss = 7.0749  \n",
      "\n",
      "Fold: 16  Epoch: 520  Training loss = 4.9673  Validation loss = 7.0745  \n",
      "\n",
      "Fold: 16  Epoch: 521  Training loss = 4.9669  Validation loss = 7.0741  \n",
      "\n",
      "Fold: 16  Epoch: 522  Training loss = 4.9666  Validation loss = 7.0737  \n",
      "\n",
      "Fold: 16  Epoch: 523  Training loss = 4.9662  Validation loss = 7.0732  \n",
      "\n",
      "Fold: 16  Epoch: 524  Training loss = 4.9658  Validation loss = 7.0728  \n",
      "\n",
      "Fold: 16  Epoch: 525  Training loss = 4.9654  Validation loss = 7.0723  \n",
      "\n",
      "Fold: 16  Epoch: 526  Training loss = 4.9650  Validation loss = 7.0719  \n",
      "\n",
      "Fold: 16  Epoch: 527  Training loss = 4.9647  Validation loss = 7.0715  \n",
      "\n",
      "Fold: 16  Epoch: 528  Training loss = 4.9643  Validation loss = 7.0711  \n",
      "\n",
      "Fold: 16  Epoch: 529  Training loss = 4.9640  Validation loss = 7.0706  \n",
      "\n",
      "Fold: 16  Epoch: 530  Training loss = 4.9636  Validation loss = 7.0703  \n",
      "\n",
      "Fold: 16  Epoch: 531  Training loss = 4.9633  Validation loss = 7.0699  \n",
      "\n",
      "Fold: 16  Epoch: 532  Training loss = 4.9629  Validation loss = 7.0694  \n",
      "\n",
      "Fold: 16  Epoch: 533  Training loss = 4.9626  Validation loss = 7.0691  \n",
      "\n",
      "Fold: 16  Epoch: 534  Training loss = 4.9622  Validation loss = 7.0686  \n",
      "\n",
      "Fold: 16  Epoch: 535  Training loss = 4.9618  Validation loss = 7.0681  \n",
      "\n",
      "Fold: 16  Epoch: 536  Training loss = 4.9614  Validation loss = 7.0676  \n",
      "\n",
      "Fold: 16  Epoch: 537  Training loss = 4.9610  Validation loss = 7.0671  \n",
      "\n",
      "Fold: 16  Epoch: 538  Training loss = 4.9606  Validation loss = 7.0666  \n",
      "\n",
      "Fold: 16  Epoch: 539  Training loss = 4.9602  Validation loss = 7.0662  \n",
      "\n",
      "Fold: 16  Epoch: 540  Training loss = 4.9600  Validation loss = 7.0659  \n",
      "\n",
      "Fold: 16  Epoch: 541  Training loss = 4.9595  Validation loss = 7.0654  \n",
      "\n",
      "Fold: 16  Epoch: 542  Training loss = 4.9591  Validation loss = 7.0649  \n",
      "\n",
      "Fold: 16  Epoch: 543  Training loss = 4.9586  Validation loss = 7.0644  \n",
      "\n",
      "Fold: 16  Epoch: 544  Training loss = 4.9583  Validation loss = 7.0640  \n",
      "\n",
      "Fold: 16  Epoch: 545  Training loss = 4.9580  Validation loss = 7.0636  \n",
      "\n",
      "Fold: 16  Epoch: 546  Training loss = 4.9577  Validation loss = 7.0632  \n",
      "\n",
      "Fold: 16  Epoch: 547  Training loss = 4.9573  Validation loss = 7.0628  \n",
      "\n",
      "Fold: 16  Epoch: 548  Training loss = 4.9569  Validation loss = 7.0623  \n",
      "\n",
      "Fold: 16  Epoch: 549  Training loss = 4.9565  Validation loss = 7.0619  \n",
      "\n",
      "Fold: 16  Epoch: 550  Training loss = 4.9562  Validation loss = 7.0615  \n",
      "\n",
      "Fold: 16  Epoch: 551  Training loss = 4.9559  Validation loss = 7.0612  \n",
      "\n",
      "Fold: 16  Epoch: 552  Training loss = 4.9555  Validation loss = 7.0607  \n",
      "\n",
      "Fold: 16  Epoch: 553  Training loss = 4.9551  Validation loss = 7.0602  \n",
      "\n",
      "Fold: 16  Epoch: 554  Training loss = 4.9548  Validation loss = 7.0599  \n",
      "\n",
      "Fold: 16  Epoch: 555  Training loss = 4.9544  Validation loss = 7.0594  \n",
      "\n",
      "Fold: 16  Epoch: 556  Training loss = 4.9540  Validation loss = 7.0589  \n",
      "\n",
      "Fold: 16  Epoch: 557  Training loss = 4.9537  Validation loss = 7.0585  \n",
      "\n",
      "Fold: 16  Epoch: 558  Training loss = 4.9533  Validation loss = 7.0581  \n",
      "\n",
      "Fold: 16  Epoch: 559  Training loss = 4.9530  Validation loss = 7.0577  \n",
      "\n",
      "Fold: 16  Epoch: 560  Training loss = 4.9526  Validation loss = 7.0573  \n",
      "\n",
      "Fold: 16  Epoch: 561  Training loss = 4.9522  Validation loss = 7.0568  \n",
      "\n",
      "Fold: 16  Epoch: 562  Training loss = 4.9518  Validation loss = 7.0564  \n",
      "\n",
      "Fold: 16  Epoch: 563  Training loss = 4.9514  Validation loss = 7.0559  \n",
      "\n",
      "Fold: 16  Epoch: 564  Training loss = 4.9510  Validation loss = 7.0554  \n",
      "\n",
      "Fold: 16  Epoch: 565  Training loss = 4.9507  Validation loss = 7.0551  \n",
      "\n",
      "Fold: 16  Epoch: 566  Training loss = 4.9504  Validation loss = 7.0546  \n",
      "\n",
      "Fold: 16  Epoch: 567  Training loss = 4.9500  Validation loss = 7.0542  \n",
      "\n",
      "Fold: 16  Epoch: 568  Training loss = 4.9497  Validation loss = 7.0539  \n",
      "\n",
      "Fold: 16  Epoch: 569  Training loss = 4.9494  Validation loss = 7.0535  \n",
      "\n",
      "Fold: 16  Epoch: 570  Training loss = 4.9490  Validation loss = 7.0530  \n",
      "\n",
      "Fold: 16  Epoch: 571  Training loss = 4.9485  Validation loss = 7.0525  \n",
      "\n",
      "Fold: 16  Epoch: 572  Training loss = 4.9481  Validation loss = 7.0520  \n",
      "\n",
      "Fold: 16  Epoch: 573  Training loss = 4.9478  Validation loss = 7.0517  \n",
      "\n",
      "Fold: 16  Epoch: 574  Training loss = 4.9475  Validation loss = 7.0513  \n",
      "\n",
      "Fold: 16  Epoch: 575  Training loss = 4.9471  Validation loss = 7.0509  \n",
      "\n",
      "Fold: 16  Epoch: 576  Training loss = 4.9468  Validation loss = 7.0505  \n",
      "\n",
      "Fold: 16  Epoch: 577  Training loss = 4.9464  Validation loss = 7.0500  \n",
      "\n",
      "Fold: 16  Epoch: 578  Training loss = 4.9460  Validation loss = 7.0496  \n",
      "\n",
      "Fold: 16  Epoch: 579  Training loss = 4.9457  Validation loss = 7.0492  \n",
      "\n",
      "Fold: 16  Epoch: 580  Training loss = 4.9453  Validation loss = 7.0487  \n",
      "\n",
      "Fold: 16  Epoch: 581  Training loss = 4.9449  Validation loss = 7.0482  \n",
      "\n",
      "Fold: 16  Epoch: 582  Training loss = 4.9445  Validation loss = 7.0478  \n",
      "\n",
      "Fold: 16  Epoch: 583  Training loss = 4.9442  Validation loss = 7.0474  \n",
      "\n",
      "Fold: 16  Epoch: 584  Training loss = 4.9438  Validation loss = 7.0470  \n",
      "\n",
      "Fold: 16  Epoch: 585  Training loss = 4.9434  Validation loss = 7.0465  \n",
      "\n",
      "Fold: 16  Epoch: 586  Training loss = 4.9432  Validation loss = 7.0462  \n",
      "\n",
      "Fold: 16  Epoch: 587  Training loss = 4.9427  Validation loss = 7.0457  \n",
      "\n",
      "Fold: 16  Epoch: 588  Training loss = 4.9423  Validation loss = 7.0453  \n",
      "\n",
      "Fold: 16  Epoch: 589  Training loss = 4.9419  Validation loss = 7.0448  \n",
      "\n",
      "Fold: 16  Epoch: 590  Training loss = 4.9416  Validation loss = 7.0444  \n",
      "\n",
      "Fold: 16  Epoch: 591  Training loss = 4.9413  Validation loss = 7.0440  \n",
      "\n",
      "Fold: 16  Epoch: 592  Training loss = 4.9409  Validation loss = 7.0435  \n",
      "\n",
      "Fold: 16  Epoch: 593  Training loss = 4.9405  Validation loss = 7.0430  \n",
      "\n",
      "Fold: 16  Epoch: 594  Training loss = 4.9402  Validation loss = 7.0426  \n",
      "\n",
      "Fold: 16  Epoch: 595  Training loss = 4.9398  Validation loss = 7.0422  \n",
      "\n",
      "Fold: 16  Epoch: 596  Training loss = 4.9393  Validation loss = 7.0417  \n",
      "\n",
      "Fold: 16  Epoch: 597  Training loss = 4.9390  Validation loss = 7.0413  \n",
      "\n",
      "Fold: 16  Epoch: 598  Training loss = 4.9386  Validation loss = 7.0408  \n",
      "\n",
      "Fold: 16  Epoch: 599  Training loss = 4.9382  Validation loss = 7.0404  \n",
      "\n",
      "Fold: 16  Epoch: 600  Training loss = 4.9378  Validation loss = 7.0398  \n",
      "\n",
      "Fold: 16  Epoch: 601  Training loss = 4.9373  Validation loss = 7.0393  \n",
      "\n",
      "Fold: 16  Epoch: 602  Training loss = 4.9370  Validation loss = 7.0388  \n",
      "\n",
      "Fold: 16  Epoch: 603  Training loss = 4.9365  Validation loss = 7.0384  \n",
      "\n",
      "Fold: 16  Epoch: 604  Training loss = 4.9362  Validation loss = 7.0380  \n",
      "\n",
      "Fold: 16  Epoch: 605  Training loss = 4.9358  Validation loss = 7.0376  \n",
      "\n",
      "Fold: 16  Epoch: 606  Training loss = 4.9355  Validation loss = 7.0371  \n",
      "\n",
      "Fold: 16  Epoch: 607  Training loss = 4.9351  Validation loss = 7.0367  \n",
      "\n",
      "Fold: 16  Epoch: 608  Training loss = 4.9348  Validation loss = 7.0363  \n",
      "\n",
      "Fold: 16  Epoch: 609  Training loss = 4.9344  Validation loss = 7.0359  \n",
      "\n",
      "Fold: 16  Epoch: 610  Training loss = 4.9340  Validation loss = 7.0354  \n",
      "\n",
      "Fold: 16  Epoch: 611  Training loss = 4.9336  Validation loss = 7.0349  \n",
      "\n",
      "Fold: 16  Epoch: 612  Training loss = 4.9332  Validation loss = 7.0344  \n",
      "\n",
      "Fold: 16  Epoch: 613  Training loss = 4.9328  Validation loss = 7.0339  \n",
      "\n",
      "Fold: 16  Epoch: 614  Training loss = 4.9324  Validation loss = 7.0335  \n",
      "\n",
      "Fold: 16  Epoch: 615  Training loss = 4.9321  Validation loss = 7.0331  \n",
      "\n",
      "Fold: 16  Epoch: 616  Training loss = 4.9317  Validation loss = 7.0326  \n",
      "\n",
      "Fold: 16  Epoch: 617  Training loss = 4.9313  Validation loss = 7.0321  \n",
      "\n",
      "Fold: 16  Epoch: 618  Training loss = 4.9309  Validation loss = 7.0317  \n",
      "\n",
      "Fold: 16  Epoch: 619  Training loss = 4.9305  Validation loss = 7.0312  \n",
      "\n",
      "Fold: 16  Epoch: 620  Training loss = 4.9301  Validation loss = 7.0307  \n",
      "\n",
      "Fold: 16  Epoch: 621  Training loss = 4.9298  Validation loss = 7.0304  \n",
      "\n",
      "Fold: 16  Epoch: 622  Training loss = 4.9295  Validation loss = 7.0300  \n",
      "\n",
      "Fold: 16  Epoch: 623  Training loss = 4.9292  Validation loss = 7.0296  \n",
      "\n",
      "Fold: 16  Epoch: 624  Training loss = 4.9288  Validation loss = 7.0292  \n",
      "\n",
      "Fold: 16  Epoch: 625  Training loss = 4.9284  Validation loss = 7.0288  \n",
      "\n",
      "Fold: 16  Epoch: 626  Training loss = 4.9281  Validation loss = 7.0284  \n",
      "\n",
      "Fold: 16  Epoch: 627  Training loss = 4.9277  Validation loss = 7.0279  \n",
      "\n",
      "Fold: 16  Epoch: 628  Training loss = 4.9273  Validation loss = 7.0274  \n",
      "\n",
      "Fold: 16  Epoch: 629  Training loss = 4.9268  Validation loss = 7.0268  \n",
      "\n",
      "Fold: 16  Epoch: 630  Training loss = 4.9264  Validation loss = 7.0263  \n",
      "\n",
      "Fold: 16  Epoch: 631  Training loss = 4.9261  Validation loss = 7.0260  \n",
      "\n",
      "Fold: 16  Epoch: 632  Training loss = 4.9257  Validation loss = 7.0255  \n",
      "\n",
      "Fold: 16  Epoch: 633  Training loss = 4.9252  Validation loss = 7.0250  \n",
      "\n",
      "Fold: 16  Epoch: 634  Training loss = 4.9249  Validation loss = 7.0246  \n",
      "\n",
      "Fold: 16  Epoch: 635  Training loss = 4.9245  Validation loss = 7.0242  \n",
      "\n",
      "Fold: 16  Epoch: 636  Training loss = 4.9242  Validation loss = 7.0238  \n",
      "\n",
      "Fold: 16  Epoch: 637  Training loss = 4.9239  Validation loss = 7.0234  \n",
      "\n",
      "Fold: 16  Epoch: 638  Training loss = 4.9235  Validation loss = 7.0229  \n",
      "\n",
      "Fold: 16  Epoch: 639  Training loss = 4.9231  Validation loss = 7.0224  \n",
      "\n",
      "Fold: 16  Epoch: 640  Training loss = 4.9227  Validation loss = 7.0219  \n",
      "\n",
      "Fold: 16  Epoch: 641  Training loss = 4.9223  Validation loss = 7.0214  \n",
      "\n",
      "Fold: 16  Epoch: 642  Training loss = 4.9219  Validation loss = 7.0210  \n",
      "\n",
      "Fold: 16  Epoch: 643  Training loss = 4.9215  Validation loss = 7.0206  \n",
      "\n",
      "Fold: 16  Epoch: 644  Training loss = 4.9212  Validation loss = 7.0202  \n",
      "\n",
      "Fold: 16  Epoch: 645  Training loss = 4.9208  Validation loss = 7.0198  \n",
      "\n",
      "Fold: 16  Epoch: 646  Training loss = 4.9205  Validation loss = 7.0194  \n",
      "\n",
      "Fold: 16  Epoch: 647  Training loss = 4.9202  Validation loss = 7.0190  \n",
      "\n",
      "Fold: 16  Epoch: 648  Training loss = 4.9198  Validation loss = 7.0186  \n",
      "\n",
      "Fold: 16  Epoch: 649  Training loss = 4.9195  Validation loss = 7.0182  \n",
      "\n",
      "Fold: 16  Epoch: 650  Training loss = 4.9191  Validation loss = 7.0177  \n",
      "\n",
      "Fold: 16  Epoch: 651  Training loss = 4.9187  Validation loss = 7.0173  \n",
      "\n",
      "Fold: 16  Epoch: 652  Training loss = 4.9183  Validation loss = 7.0168  \n",
      "\n",
      "Fold: 16  Epoch: 653  Training loss = 4.9179  Validation loss = 7.0164  \n",
      "\n",
      "Fold: 16  Epoch: 654  Training loss = 4.9175  Validation loss = 7.0159  \n",
      "\n",
      "Fold: 16  Epoch: 655  Training loss = 4.9172  Validation loss = 7.0155  \n",
      "\n",
      "Fold: 16  Epoch: 656  Training loss = 4.9169  Validation loss = 7.0152  \n",
      "\n",
      "Fold: 16  Epoch: 657  Training loss = 4.9166  Validation loss = 7.0148  \n",
      "\n",
      "Fold: 16  Epoch: 658  Training loss = 4.9162  Validation loss = 7.0143  \n",
      "\n",
      "Fold: 16  Epoch: 659  Training loss = 4.9158  Validation loss = 7.0139  \n",
      "\n",
      "Fold: 16  Epoch: 660  Training loss = 4.9154  Validation loss = 7.0135  \n",
      "\n",
      "Fold: 16  Epoch: 661  Training loss = 4.9151  Validation loss = 7.0131  \n",
      "\n",
      "Fold: 16  Epoch: 662  Training loss = 4.9147  Validation loss = 7.0126  \n",
      "\n",
      "Fold: 16  Epoch: 663  Training loss = 4.9143  Validation loss = 7.0122  \n",
      "\n",
      "Fold: 16  Epoch: 664  Training loss = 4.9139  Validation loss = 7.0117  \n",
      "\n",
      "Fold: 16  Epoch: 665  Training loss = 4.9136  Validation loss = 7.0113  \n",
      "\n",
      "Fold: 16  Epoch: 666  Training loss = 4.9132  Validation loss = 7.0109  \n",
      "\n",
      "Fold: 16  Epoch: 667  Training loss = 4.9129  Validation loss = 7.0105  \n",
      "\n",
      "Fold: 16  Epoch: 668  Training loss = 4.9125  Validation loss = 7.0101  \n",
      "\n",
      "Fold: 16  Epoch: 669  Training loss = 4.9120  Validation loss = 7.0095  \n",
      "\n",
      "Fold: 16  Epoch: 670  Training loss = 4.9117  Validation loss = 7.0091  \n",
      "\n",
      "Fold: 16  Epoch: 671  Training loss = 4.9113  Validation loss = 7.0087  \n",
      "\n",
      "Fold: 16  Epoch: 672  Training loss = 4.9110  Validation loss = 7.0083  \n",
      "\n",
      "Fold: 16  Epoch: 673  Training loss = 4.9106  Validation loss = 7.0079  \n",
      "\n",
      "Fold: 16  Epoch: 674  Training loss = 4.9102  Validation loss = 7.0074  \n",
      "\n",
      "Fold: 16  Epoch: 675  Training loss = 4.9098  Validation loss = 7.0069  \n",
      "\n",
      "Fold: 16  Epoch: 676  Training loss = 4.9094  Validation loss = 7.0064  \n",
      "\n",
      "Fold: 16  Epoch: 677  Training loss = 4.9090  Validation loss = 7.0060  \n",
      "\n",
      "Fold: 16  Epoch: 678  Training loss = 4.9085  Validation loss = 7.0054  \n",
      "\n",
      "Fold: 16  Epoch: 679  Training loss = 4.9081  Validation loss = 7.0049  \n",
      "\n",
      "Fold: 16  Epoch: 680  Training loss = 4.9077  Validation loss = 7.0044  \n",
      "\n",
      "Fold: 16  Epoch: 681  Training loss = 4.9073  Validation loss = 7.0040  \n",
      "\n",
      "Fold: 16  Epoch: 682  Training loss = 4.9069  Validation loss = 7.0035  \n",
      "\n",
      "Fold: 16  Epoch: 683  Training loss = 4.9066  Validation loss = 7.0031  \n",
      "\n",
      "Fold: 16  Epoch: 684  Training loss = 4.9061  Validation loss = 7.0026  \n",
      "\n",
      "Fold: 16  Epoch: 685  Training loss = 4.9058  Validation loss = 7.0021  \n",
      "\n",
      "Fold: 16  Epoch: 686  Training loss = 4.9054  Validation loss = 7.0017  \n",
      "\n",
      "Fold: 16  Epoch: 687  Training loss = 4.9050  Validation loss = 7.0013  \n",
      "\n",
      "Fold: 16  Epoch: 688  Training loss = 4.9047  Validation loss = 7.0009  \n",
      "\n",
      "Fold: 16  Epoch: 689  Training loss = 4.9042  Validation loss = 7.0004  \n",
      "\n",
      "Fold: 16  Epoch: 690  Training loss = 4.9039  Validation loss = 7.0000  \n",
      "\n",
      "Fold: 16  Epoch: 691  Training loss = 4.9034  Validation loss = 6.9994  \n",
      "\n",
      "Fold: 16  Epoch: 692  Training loss = 4.9031  Validation loss = 6.9991  \n",
      "\n",
      "Fold: 16  Epoch: 693  Training loss = 4.9029  Validation loss = 6.9988  \n",
      "\n",
      "Fold: 16  Epoch: 694  Training loss = 4.9024  Validation loss = 6.9982  \n",
      "\n",
      "Fold: 16  Epoch: 695  Training loss = 4.9020  Validation loss = 6.9977  \n",
      "\n",
      "Fold: 16  Epoch: 696  Training loss = 4.9015  Validation loss = 6.9972  \n",
      "\n",
      "Fold: 16  Epoch: 697  Training loss = 4.9012  Validation loss = 6.9968  \n",
      "\n",
      "Fold: 16  Epoch: 698  Training loss = 4.9008  Validation loss = 6.9964  \n",
      "\n",
      "Fold: 16  Epoch: 699  Training loss = 4.9004  Validation loss = 6.9959  \n",
      "\n",
      "Fold: 16  Epoch: 700  Training loss = 4.9001  Validation loss = 6.9955  \n",
      "\n",
      "Fold: 16  Epoch: 701  Training loss = 4.8997  Validation loss = 6.9951  \n",
      "\n",
      "Fold: 16  Epoch: 702  Training loss = 4.8994  Validation loss = 6.9947  \n",
      "\n",
      "Fold: 16  Epoch: 703  Training loss = 4.8991  Validation loss = 6.9943  \n",
      "\n",
      "Fold: 16  Epoch: 704  Training loss = 4.8988  Validation loss = 6.9940  \n",
      "\n",
      "Fold: 16  Epoch: 705  Training loss = 4.8985  Validation loss = 6.9936  \n",
      "\n",
      "Fold: 16  Epoch: 706  Training loss = 4.8982  Validation loss = 6.9932  \n",
      "\n",
      "Fold: 16  Epoch: 707  Training loss = 4.8977  Validation loss = 6.9927  \n",
      "\n",
      "Fold: 16  Epoch: 708  Training loss = 4.8975  Validation loss = 6.9923  \n",
      "\n",
      "Fold: 16  Epoch: 709  Training loss = 4.8971  Validation loss = 6.9919  \n",
      "\n",
      "Fold: 16  Epoch: 710  Training loss = 4.8967  Validation loss = 6.9915  \n",
      "\n",
      "Fold: 16  Epoch: 711  Training loss = 4.8963  Validation loss = 6.9910  \n",
      "\n",
      "Fold: 16  Epoch: 712  Training loss = 4.8960  Validation loss = 6.9905  \n",
      "\n",
      "Fold: 16  Epoch: 713  Training loss = 4.8956  Validation loss = 6.9902  \n",
      "\n",
      "Fold: 16  Epoch: 714  Training loss = 4.8953  Validation loss = 6.9898  \n",
      "\n",
      "Fold: 16  Epoch: 715  Training loss = 4.8950  Validation loss = 6.9893  \n",
      "\n",
      "Fold: 16  Epoch: 716  Training loss = 4.8946  Validation loss = 6.9889  \n",
      "\n",
      "Fold: 16  Epoch: 717  Training loss = 4.8942  Validation loss = 6.9885  \n",
      "\n",
      "Fold: 16  Epoch: 718  Training loss = 4.8938  Validation loss = 6.9880  \n",
      "\n",
      "Fold: 16  Epoch: 719  Training loss = 4.8935  Validation loss = 6.9876  \n",
      "\n",
      "Fold: 16  Epoch: 720  Training loss = 4.8931  Validation loss = 6.9872  \n",
      "\n",
      "Fold: 16  Epoch: 721  Training loss = 4.8927  Validation loss = 6.9868  \n",
      "\n",
      "Fold: 16  Epoch: 722  Training loss = 4.8924  Validation loss = 6.9864  \n",
      "\n",
      "Fold: 16  Epoch: 723  Training loss = 4.8921  Validation loss = 6.9860  \n",
      "\n",
      "Fold: 16  Epoch: 724  Training loss = 4.8917  Validation loss = 6.9856  \n",
      "\n",
      "Fold: 16  Epoch: 725  Training loss = 4.8914  Validation loss = 6.9852  \n",
      "\n",
      "Fold: 16  Epoch: 726  Training loss = 4.8911  Validation loss = 6.9848  \n",
      "\n",
      "Fold: 16  Epoch: 727  Training loss = 4.8907  Validation loss = 6.9843  \n",
      "\n",
      "Fold: 16  Epoch: 728  Training loss = 4.8903  Validation loss = 6.9840  \n",
      "\n",
      "Fold: 16  Epoch: 729  Training loss = 4.8899  Validation loss = 6.9835  \n",
      "\n",
      "Fold: 16  Epoch: 730  Training loss = 4.8894  Validation loss = 6.9829  \n",
      "\n",
      "Fold: 16  Epoch: 731  Training loss = 4.8891  Validation loss = 6.9825  \n",
      "\n",
      "Fold: 16  Epoch: 732  Training loss = 4.8887  Validation loss = 6.9820  \n",
      "\n",
      "Fold: 16  Epoch: 733  Training loss = 4.8883  Validation loss = 6.9816  \n",
      "\n",
      "Fold: 16  Epoch: 734  Training loss = 4.8880  Validation loss = 6.9812  \n",
      "\n",
      "Fold: 16  Epoch: 735  Training loss = 4.8877  Validation loss = 6.9808  \n",
      "\n",
      "Fold: 16  Epoch: 736  Training loss = 4.8873  Validation loss = 6.9804  \n",
      "\n",
      "Fold: 16  Epoch: 737  Training loss = 4.8869  Validation loss = 6.9799  \n",
      "\n",
      "Fold: 16  Epoch: 738  Training loss = 4.8864  Validation loss = 6.9793  \n",
      "\n",
      "Fold: 16  Epoch: 739  Training loss = 4.8861  Validation loss = 6.9789  \n",
      "\n",
      "Fold: 16  Epoch: 740  Training loss = 4.8857  Validation loss = 6.9785  \n",
      "\n",
      "Fold: 16  Epoch: 741  Training loss = 4.8854  Validation loss = 6.9781  \n",
      "\n",
      "Fold: 16  Epoch: 742  Training loss = 4.8852  Validation loss = 6.9778  \n",
      "\n",
      "Fold: 16  Epoch: 743  Training loss = 4.8848  Validation loss = 6.9774  \n",
      "\n",
      "Fold: 16  Epoch: 744  Training loss = 4.8843  Validation loss = 6.9768  \n",
      "\n",
      "Fold: 16  Epoch: 745  Training loss = 4.8839  Validation loss = 6.9763  \n",
      "\n",
      "Fold: 16  Epoch: 746  Training loss = 4.8835  Validation loss = 6.9758  \n",
      "\n",
      "Fold: 16  Epoch: 747  Training loss = 4.8831  Validation loss = 6.9753  \n",
      "\n",
      "Fold: 16  Epoch: 748  Training loss = 4.8827  Validation loss = 6.9748  \n",
      "\n",
      "Fold: 16  Epoch: 749  Training loss = 4.8822  Validation loss = 6.9743  \n",
      "\n",
      "Fold: 16  Epoch: 750  Training loss = 4.8819  Validation loss = 6.9739  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 750  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 5.1738  Validation loss = 2.7439  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 5.1734  Validation loss = 2.7433  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 5.1730  Validation loss = 2.7428  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 5.1726  Validation loss = 2.7424  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 5.1723  Validation loss = 2.7420  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 5.1718  Validation loss = 2.7415  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 5.1714  Validation loss = 2.7412  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 5.1709  Validation loss = 2.7409  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 5.1705  Validation loss = 2.7404  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 5.1702  Validation loss = 2.7401  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 5.1698  Validation loss = 2.7396  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 5.1692  Validation loss = 2.7387  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 5.1687  Validation loss = 2.7384  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 5.1683  Validation loss = 2.7379  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 5.1678  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 5.1675  Validation loss = 2.7370  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 5.1670  Validation loss = 2.7366  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 5.1665  Validation loss = 2.7362  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 5.1661  Validation loss = 2.7358  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 5.1658  Validation loss = 2.7353  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 5.1654  Validation loss = 2.7349  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 5.1650  Validation loss = 2.7343  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 5.1646  Validation loss = 2.7339  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 5.1643  Validation loss = 2.7337  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 5.1639  Validation loss = 2.7332  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 5.1634  Validation loss = 2.7326  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 5.1629  Validation loss = 2.7322  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 5.1626  Validation loss = 2.7318  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 5.1621  Validation loss = 2.7313  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 5.1616  Validation loss = 2.7308  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 5.1612  Validation loss = 2.7303  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 5.1607  Validation loss = 2.7299  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 5.1602  Validation loss = 2.7289  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 5.1598  Validation loss = 2.7285  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 5.1594  Validation loss = 2.7280  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 5.1590  Validation loss = 2.7278  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 5.1587  Validation loss = 2.7275  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 5.1582  Validation loss = 2.7269  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 5.1578  Validation loss = 2.7264  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 5.1573  Validation loss = 2.7258  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 5.1569  Validation loss = 2.7254  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 5.1565  Validation loss = 2.7251  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 5.1560  Validation loss = 2.7245  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 5.1556  Validation loss = 2.7239  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 5.1550  Validation loss = 2.7236  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 5.1545  Validation loss = 2.7230  \n",
      "\n",
      "Fold: 17  Epoch: 47  Training loss = 5.1542  Validation loss = 2.7224  \n",
      "\n",
      "Fold: 17  Epoch: 48  Training loss = 5.1537  Validation loss = 2.7221  \n",
      "\n",
      "Fold: 17  Epoch: 49  Training loss = 5.1533  Validation loss = 2.7217  \n",
      "\n",
      "Fold: 17  Epoch: 50  Training loss = 5.1528  Validation loss = 2.7211  \n",
      "\n",
      "Fold: 17  Epoch: 51  Training loss = 5.1524  Validation loss = 2.7207  \n",
      "\n",
      "Fold: 17  Epoch: 52  Training loss = 5.1519  Validation loss = 2.7200  \n",
      "\n",
      "Fold: 17  Epoch: 53  Training loss = 5.1515  Validation loss = 2.7197  \n",
      "\n",
      "Fold: 17  Epoch: 54  Training loss = 5.1511  Validation loss = 2.7192  \n",
      "\n",
      "Fold: 17  Epoch: 55  Training loss = 5.1507  Validation loss = 2.7188  \n",
      "\n",
      "Fold: 17  Epoch: 56  Training loss = 5.1502  Validation loss = 2.7184  \n",
      "\n",
      "Fold: 17  Epoch: 57  Training loss = 5.1498  Validation loss = 2.7180  \n",
      "\n",
      "Fold: 17  Epoch: 58  Training loss = 5.1493  Validation loss = 2.7175  \n",
      "\n",
      "Fold: 17  Epoch: 59  Training loss = 5.1489  Validation loss = 2.7169  \n",
      "\n",
      "Fold: 17  Epoch: 60  Training loss = 5.1485  Validation loss = 2.7166  \n",
      "\n",
      "Fold: 17  Epoch: 61  Training loss = 5.1479  Validation loss = 2.7162  \n",
      "\n",
      "Fold: 17  Epoch: 62  Training loss = 5.1476  Validation loss = 2.7159  \n",
      "\n",
      "Fold: 17  Epoch: 63  Training loss = 5.1471  Validation loss = 2.7154  \n",
      "\n",
      "Fold: 17  Epoch: 64  Training loss = 5.1467  Validation loss = 2.7152  \n",
      "\n",
      "Fold: 17  Epoch: 65  Training loss = 5.1462  Validation loss = 2.7142  \n",
      "\n",
      "Fold: 17  Epoch: 66  Training loss = 5.1457  Validation loss = 2.7138  \n",
      "\n",
      "Fold: 17  Epoch: 67  Training loss = 5.1453  Validation loss = 2.7135  \n",
      "\n",
      "Fold: 17  Epoch: 68  Training loss = 5.1450  Validation loss = 2.7131  \n",
      "\n",
      "Fold: 17  Epoch: 69  Training loss = 5.1445  Validation loss = 2.7126  \n",
      "\n",
      "Fold: 17  Epoch: 70  Training loss = 5.1440  Validation loss = 2.7122  \n",
      "\n",
      "Fold: 17  Epoch: 71  Training loss = 5.1435  Validation loss = 2.7118  \n",
      "\n",
      "Fold: 17  Epoch: 72  Training loss = 5.1430  Validation loss = 2.7114  \n",
      "\n",
      "Fold: 17  Epoch: 73  Training loss = 5.1425  Validation loss = 2.7108  \n",
      "\n",
      "Fold: 17  Epoch: 74  Training loss = 5.1420  Validation loss = 2.7105  \n",
      "\n",
      "Fold: 17  Epoch: 75  Training loss = 5.1416  Validation loss = 2.7099  \n",
      "\n",
      "Fold: 17  Epoch: 76  Training loss = 5.1411  Validation loss = 2.7095  \n",
      "\n",
      "Fold: 17  Epoch: 77  Training loss = 5.1408  Validation loss = 2.7091  \n",
      "\n",
      "Fold: 17  Epoch: 78  Training loss = 5.1402  Validation loss = 2.7087  \n",
      "\n",
      "Fold: 17  Epoch: 79  Training loss = 5.1398  Validation loss = 2.7082  \n",
      "\n",
      "Fold: 17  Epoch: 80  Training loss = 5.1393  Validation loss = 2.7075  \n",
      "\n",
      "Fold: 17  Epoch: 81  Training loss = 5.1389  Validation loss = 2.7072  \n",
      "\n",
      "Fold: 17  Epoch: 82  Training loss = 5.1384  Validation loss = 2.7066  \n",
      "\n",
      "Fold: 17  Epoch: 83  Training loss = 5.1380  Validation loss = 2.7062  \n",
      "\n",
      "Fold: 17  Epoch: 84  Training loss = 5.1375  Validation loss = 2.7057  \n",
      "\n",
      "Fold: 17  Epoch: 85  Training loss = 5.1371  Validation loss = 2.7052  \n",
      "\n",
      "Fold: 17  Epoch: 86  Training loss = 5.1367  Validation loss = 2.7049  \n",
      "\n",
      "Fold: 17  Epoch: 87  Training loss = 5.1362  Validation loss = 2.7044  \n",
      "\n",
      "Fold: 17  Epoch: 88  Training loss = 5.1359  Validation loss = 2.7042  \n",
      "\n",
      "Fold: 17  Epoch: 89  Training loss = 5.1354  Validation loss = 2.7039  \n",
      "\n",
      "Fold: 17  Epoch: 90  Training loss = 5.1351  Validation loss = 2.7033  \n",
      "\n",
      "Fold: 17  Epoch: 91  Training loss = 5.1346  Validation loss = 2.7030  \n",
      "\n",
      "Fold: 17  Epoch: 92  Training loss = 5.1343  Validation loss = 2.7028  \n",
      "\n",
      "Fold: 17  Epoch: 93  Training loss = 5.1339  Validation loss = 2.7023  \n",
      "\n",
      "Fold: 17  Epoch: 94  Training loss = 5.1333  Validation loss = 2.7019  \n",
      "\n",
      "Fold: 17  Epoch: 95  Training loss = 5.1330  Validation loss = 2.7017  \n",
      "\n",
      "Fold: 17  Epoch: 96  Training loss = 5.1326  Validation loss = 2.7012  \n",
      "\n",
      "Fold: 17  Epoch: 97  Training loss = 5.1322  Validation loss = 2.7009  \n",
      "\n",
      "Fold: 17  Epoch: 98  Training loss = 5.1317  Validation loss = 2.7005  \n",
      "\n",
      "Fold: 17  Epoch: 99  Training loss = 5.1312  Validation loss = 2.7001  \n",
      "\n",
      "Fold: 17  Epoch: 100  Training loss = 5.1308  Validation loss = 2.6997  \n",
      "\n",
      "Fold: 17  Epoch: 101  Training loss = 5.1303  Validation loss = 2.6991  \n",
      "\n",
      "Fold: 17  Epoch: 102  Training loss = 5.1299  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 17  Epoch: 103  Training loss = 5.1294  Validation loss = 2.6982  \n",
      "\n",
      "Fold: 17  Epoch: 104  Training loss = 5.1290  Validation loss = 2.6980  \n",
      "\n",
      "Fold: 17  Epoch: 105  Training loss = 5.1287  Validation loss = 2.6977  \n",
      "\n",
      "Fold: 17  Epoch: 106  Training loss = 5.1283  Validation loss = 2.6974  \n",
      "\n",
      "Fold: 17  Epoch: 107  Training loss = 5.1279  Validation loss = 2.6969  \n",
      "\n",
      "Fold: 17  Epoch: 108  Training loss = 5.1273  Validation loss = 2.6966  \n",
      "\n",
      "Fold: 17  Epoch: 109  Training loss = 5.1269  Validation loss = 2.6962  \n",
      "\n",
      "Fold: 17  Epoch: 110  Training loss = 5.1264  Validation loss = 2.6958  \n",
      "\n",
      "Fold: 17  Epoch: 111  Training loss = 5.1259  Validation loss = 2.6952  \n",
      "\n",
      "Fold: 17  Epoch: 112  Training loss = 5.1255  Validation loss = 2.6949  \n",
      "\n",
      "Fold: 17  Epoch: 113  Training loss = 5.1251  Validation loss = 2.6946  \n",
      "\n",
      "Fold: 17  Epoch: 114  Training loss = 5.1247  Validation loss = 2.6943  \n",
      "\n",
      "Fold: 17  Epoch: 115  Training loss = 5.1242  Validation loss = 2.6938  \n",
      "\n",
      "Fold: 17  Epoch: 116  Training loss = 5.1238  Validation loss = 2.6936  \n",
      "\n",
      "Fold: 17  Epoch: 117  Training loss = 5.1234  Validation loss = 2.6932  \n",
      "\n",
      "Fold: 17  Epoch: 118  Training loss = 5.1230  Validation loss = 2.6928  \n",
      "\n",
      "Fold: 17  Epoch: 119  Training loss = 5.1225  Validation loss = 2.6923  \n",
      "\n",
      "Fold: 17  Epoch: 120  Training loss = 5.1221  Validation loss = 2.6919  \n",
      "\n",
      "Fold: 17  Epoch: 121  Training loss = 5.1216  Validation loss = 2.6914  \n",
      "\n",
      "Fold: 17  Epoch: 122  Training loss = 5.1212  Validation loss = 2.6910  \n",
      "\n",
      "Fold: 17  Epoch: 123  Training loss = 5.1208  Validation loss = 2.6907  \n",
      "\n",
      "Fold: 17  Epoch: 124  Training loss = 5.1204  Validation loss = 2.6905  \n",
      "\n",
      "Fold: 17  Epoch: 125  Training loss = 5.1199  Validation loss = 2.6901  \n",
      "\n",
      "Fold: 17  Epoch: 126  Training loss = 5.1194  Validation loss = 2.6896  \n",
      "\n",
      "Fold: 17  Epoch: 127  Training loss = 5.1190  Validation loss = 2.6892  \n",
      "\n",
      "Fold: 17  Epoch: 128  Training loss = 5.1186  Validation loss = 2.6887  \n",
      "\n",
      "Fold: 17  Epoch: 129  Training loss = 5.1181  Validation loss = 2.6882  \n",
      "\n",
      "Fold: 17  Epoch: 130  Training loss = 5.1176  Validation loss = 2.6878  \n",
      "\n",
      "Fold: 17  Epoch: 131  Training loss = 5.1172  Validation loss = 2.6876  \n",
      "\n",
      "Fold: 17  Epoch: 132  Training loss = 5.1167  Validation loss = 2.6873  \n",
      "\n",
      "Fold: 17  Epoch: 133  Training loss = 5.1163  Validation loss = 2.6870  \n",
      "\n",
      "Fold: 17  Epoch: 134  Training loss = 5.1160  Validation loss = 2.6867  \n",
      "\n",
      "Fold: 17  Epoch: 135  Training loss = 5.1156  Validation loss = 2.6863  \n",
      "\n",
      "Fold: 17  Epoch: 136  Training loss = 5.1151  Validation loss = 2.6859  \n",
      "\n",
      "Fold: 17  Epoch: 137  Training loss = 5.1147  Validation loss = 2.6856  \n",
      "\n",
      "Fold: 17  Epoch: 138  Training loss = 5.1143  Validation loss = 2.6851  \n",
      "\n",
      "Fold: 17  Epoch: 139  Training loss = 5.1139  Validation loss = 2.6847  \n",
      "\n",
      "Fold: 17  Epoch: 140  Training loss = 5.1134  Validation loss = 2.6844  \n",
      "\n",
      "Fold: 17  Epoch: 141  Training loss = 5.1130  Validation loss = 2.6841  \n",
      "\n",
      "Fold: 17  Epoch: 142  Training loss = 5.1125  Validation loss = 2.6837  \n",
      "\n",
      "Fold: 17  Epoch: 143  Training loss = 5.1121  Validation loss = 2.6834  \n",
      "\n",
      "Fold: 17  Epoch: 144  Training loss = 5.1116  Validation loss = 2.6830  \n",
      "\n",
      "Fold: 17  Epoch: 145  Training loss = 5.1112  Validation loss = 2.6827  \n",
      "\n",
      "Fold: 17  Epoch: 146  Training loss = 5.1108  Validation loss = 2.6822  \n",
      "\n",
      "Fold: 17  Epoch: 147  Training loss = 5.1102  Validation loss = 2.6819  \n",
      "\n",
      "Fold: 17  Epoch: 148  Training loss = 5.1097  Validation loss = 2.6814  \n",
      "\n",
      "Fold: 17  Epoch: 149  Training loss = 5.1094  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 17  Epoch: 150  Training loss = 5.1088  Validation loss = 2.6807  \n",
      "\n",
      "Fold: 17  Epoch: 151  Training loss = 5.1084  Validation loss = 2.6803  \n",
      "\n",
      "Fold: 17  Epoch: 152  Training loss = 5.1080  Validation loss = 2.6799  \n",
      "\n",
      "Fold: 17  Epoch: 153  Training loss = 5.1076  Validation loss = 2.6797  \n",
      "\n",
      "Fold: 17  Epoch: 154  Training loss = 5.1072  Validation loss = 2.6793  \n",
      "\n",
      "Fold: 17  Epoch: 155  Training loss = 5.1069  Validation loss = 2.6790  \n",
      "\n",
      "Fold: 17  Epoch: 156  Training loss = 5.1064  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 17  Epoch: 157  Training loss = 5.1059  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 17  Epoch: 158  Training loss = 5.1054  Validation loss = 2.6777  \n",
      "\n",
      "Fold: 17  Epoch: 159  Training loss = 5.1051  Validation loss = 2.6774  \n",
      "\n",
      "Fold: 17  Epoch: 160  Training loss = 5.1046  Validation loss = 2.6770  \n",
      "\n",
      "Fold: 17  Epoch: 161  Training loss = 5.1041  Validation loss = 2.6767  \n",
      "\n",
      "Fold: 17  Epoch: 162  Training loss = 5.1037  Validation loss = 2.6764  \n",
      "\n",
      "Fold: 17  Epoch: 163  Training loss = 5.1033  Validation loss = 2.6760  \n",
      "\n",
      "Fold: 17  Epoch: 164  Training loss = 5.1028  Validation loss = 2.6756  \n",
      "\n",
      "Fold: 17  Epoch: 165  Training loss = 5.1025  Validation loss = 2.6753  \n",
      "\n",
      "Fold: 17  Epoch: 166  Training loss = 5.1021  Validation loss = 2.6750  \n",
      "\n",
      "Fold: 17  Epoch: 167  Training loss = 5.1017  Validation loss = 2.6747  \n",
      "\n",
      "Fold: 17  Epoch: 168  Training loss = 5.1012  Validation loss = 2.6744  \n",
      "\n",
      "Fold: 17  Epoch: 169  Training loss = 5.1008  Validation loss = 2.6741  \n",
      "\n",
      "Fold: 17  Epoch: 170  Training loss = 5.1004  Validation loss = 2.6737  \n",
      "\n",
      "Fold: 17  Epoch: 171  Training loss = 5.1000  Validation loss = 2.6733  \n",
      "\n",
      "Fold: 17  Epoch: 172  Training loss = 5.0996  Validation loss = 2.6729  \n",
      "\n",
      "Fold: 17  Epoch: 173  Training loss = 5.0991  Validation loss = 2.6723  \n",
      "\n",
      "Fold: 17  Epoch: 174  Training loss = 5.0986  Validation loss = 2.6720  \n",
      "\n",
      "Fold: 17  Epoch: 175  Training loss = 5.0981  Validation loss = 2.6715  \n",
      "\n",
      "Fold: 17  Epoch: 176  Training loss = 5.0977  Validation loss = 2.6712  \n",
      "\n",
      "Fold: 17  Epoch: 177  Training loss = 5.0973  Validation loss = 2.6709  \n",
      "\n",
      "Fold: 17  Epoch: 178  Training loss = 5.0969  Validation loss = 2.6706  \n",
      "\n",
      "Fold: 17  Epoch: 179  Training loss = 5.0964  Validation loss = 2.6702  \n",
      "\n",
      "Fold: 17  Epoch: 180  Training loss = 5.0959  Validation loss = 2.6698  \n",
      "\n",
      "Fold: 17  Epoch: 181  Training loss = 5.0954  Validation loss = 2.6695  \n",
      "\n",
      "Fold: 17  Epoch: 182  Training loss = 5.0951  Validation loss = 2.6691  \n",
      "\n",
      "Fold: 17  Epoch: 183  Training loss = 5.0947  Validation loss = 2.6688  \n",
      "\n",
      "Fold: 17  Epoch: 184  Training loss = 5.0942  Validation loss = 2.6685  \n",
      "\n",
      "Fold: 17  Epoch: 185  Training loss = 5.0939  Validation loss = 2.6682  \n",
      "\n",
      "Fold: 17  Epoch: 186  Training loss = 5.0935  Validation loss = 2.6679  \n",
      "\n",
      "Fold: 17  Epoch: 187  Training loss = 5.0931  Validation loss = 2.6676  \n",
      "\n",
      "Fold: 17  Epoch: 188  Training loss = 5.0927  Validation loss = 2.6673  \n",
      "\n",
      "Fold: 17  Epoch: 189  Training loss = 5.0922  Validation loss = 2.6669  \n",
      "\n",
      "Fold: 17  Epoch: 190  Training loss = 5.0919  Validation loss = 2.6666  \n",
      "\n",
      "Fold: 17  Epoch: 191  Training loss = 5.0915  Validation loss = 2.6664  \n",
      "\n",
      "Fold: 17  Epoch: 192  Training loss = 5.0910  Validation loss = 2.6659  \n",
      "\n",
      "Fold: 17  Epoch: 193  Training loss = 5.0906  Validation loss = 2.6656  \n",
      "\n",
      "Fold: 17  Epoch: 194  Training loss = 5.0903  Validation loss = 2.6653  \n",
      "\n",
      "Fold: 17  Epoch: 195  Training loss = 5.0899  Validation loss = 2.6651  \n",
      "\n",
      "Fold: 17  Epoch: 196  Training loss = 5.0895  Validation loss = 2.6648  \n",
      "\n",
      "Fold: 17  Epoch: 197  Training loss = 5.0890  Validation loss = 2.6644  \n",
      "\n",
      "Fold: 17  Epoch: 198  Training loss = 5.0886  Validation loss = 2.6642  \n",
      "\n",
      "Fold: 17  Epoch: 199  Training loss = 5.0882  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 17  Epoch: 200  Training loss = 5.0877  Validation loss = 2.6635  \n",
      "\n",
      "Fold: 17  Epoch: 201  Training loss = 5.0872  Validation loss = 2.6630  \n",
      "\n",
      "Fold: 17  Epoch: 202  Training loss = 5.0868  Validation loss = 2.6628  \n",
      "\n",
      "Fold: 17  Epoch: 203  Training loss = 5.0863  Validation loss = 2.6625  \n",
      "\n",
      "Fold: 17  Epoch: 204  Training loss = 5.0860  Validation loss = 2.6622  \n",
      "\n",
      "Fold: 17  Epoch: 205  Training loss = 5.0856  Validation loss = 2.6620  \n",
      "\n",
      "Fold: 17  Epoch: 206  Training loss = 5.0850  Validation loss = 2.6616  \n",
      "\n",
      "Fold: 17  Epoch: 207  Training loss = 5.0846  Validation loss = 2.6613  \n",
      "\n",
      "Fold: 17  Epoch: 208  Training loss = 5.0841  Validation loss = 2.6610  \n",
      "\n",
      "Fold: 17  Epoch: 209  Training loss = 5.0838  Validation loss = 2.6607  \n",
      "\n",
      "Fold: 17  Epoch: 210  Training loss = 5.0834  Validation loss = 2.6604  \n",
      "\n",
      "Fold: 17  Epoch: 211  Training loss = 5.0831  Validation loss = 2.6602  \n",
      "\n",
      "Fold: 17  Epoch: 212  Training loss = 5.0826  Validation loss = 2.6598  \n",
      "\n",
      "Fold: 17  Epoch: 213  Training loss = 5.0822  Validation loss = 2.6595  \n",
      "\n",
      "Fold: 17  Epoch: 214  Training loss = 5.0818  Validation loss = 2.6592  \n",
      "\n",
      "Fold: 17  Epoch: 215  Training loss = 5.0814  Validation loss = 2.6589  \n",
      "\n",
      "Fold: 17  Epoch: 216  Training loss = 5.0809  Validation loss = 2.6585  \n",
      "\n",
      "Fold: 17  Epoch: 217  Training loss = 5.0805  Validation loss = 2.6583  \n",
      "\n",
      "Fold: 17  Epoch: 218  Training loss = 5.0802  Validation loss = 2.6580  \n",
      "\n",
      "Fold: 17  Epoch: 219  Training loss = 5.0798  Validation loss = 2.6577  \n",
      "\n",
      "Fold: 17  Epoch: 220  Training loss = 5.0793  Validation loss = 2.6574  \n",
      "\n",
      "Fold: 17  Epoch: 221  Training loss = 5.0790  Validation loss = 2.6571  \n",
      "\n",
      "Fold: 17  Epoch: 222  Training loss = 5.0785  Validation loss = 2.6568  \n",
      "\n",
      "Fold: 17  Epoch: 223  Training loss = 5.0780  Validation loss = 2.6565  \n",
      "\n",
      "Fold: 17  Epoch: 224  Training loss = 5.0775  Validation loss = 2.6562  \n",
      "\n",
      "Fold: 17  Epoch: 225  Training loss = 5.0771  Validation loss = 2.6559  \n",
      "\n",
      "Fold: 17  Epoch: 226  Training loss = 5.0767  Validation loss = 2.6555  \n",
      "\n",
      "Fold: 17  Epoch: 227  Training loss = 5.0763  Validation loss = 2.6552  \n",
      "\n",
      "Fold: 17  Epoch: 228  Training loss = 5.0759  Validation loss = 2.6550  \n",
      "\n",
      "Fold: 17  Epoch: 229  Training loss = 5.0754  Validation loss = 2.6547  \n",
      "\n",
      "Fold: 17  Epoch: 230  Training loss = 5.0749  Validation loss = 2.6544  \n",
      "\n",
      "Fold: 17  Epoch: 231  Training loss = 5.0745  Validation loss = 2.6540  \n",
      "\n",
      "Fold: 17  Epoch: 232  Training loss = 5.0741  Validation loss = 2.6537  \n",
      "\n",
      "Fold: 17  Epoch: 233  Training loss = 5.0737  Validation loss = 2.6534  \n",
      "\n",
      "Fold: 17  Epoch: 234  Training loss = 5.0733  Validation loss = 2.6532  \n",
      "\n",
      "Fold: 17  Epoch: 235  Training loss = 5.0728  Validation loss = 2.6528  \n",
      "\n",
      "Fold: 17  Epoch: 236  Training loss = 5.0724  Validation loss = 2.6525  \n",
      "\n",
      "Fold: 17  Epoch: 237  Training loss = 5.0721  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 17  Epoch: 238  Training loss = 5.0716  Validation loss = 2.6520  \n",
      "\n",
      "Fold: 17  Epoch: 239  Training loss = 5.0711  Validation loss = 2.6517  \n",
      "\n",
      "Fold: 17  Epoch: 240  Training loss = 5.0706  Validation loss = 2.6513  \n",
      "\n",
      "Fold: 17  Epoch: 241  Training loss = 5.0703  Validation loss = 2.6511  \n",
      "\n",
      "Fold: 17  Epoch: 242  Training loss = 5.0699  Validation loss = 2.6508  \n",
      "\n",
      "Fold: 17  Epoch: 243  Training loss = 5.0694  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 17  Epoch: 244  Training loss = 5.0690  Validation loss = 2.6502  \n",
      "\n",
      "Fold: 17  Epoch: 245  Training loss = 5.0686  Validation loss = 2.6499  \n",
      "\n",
      "Fold: 17  Epoch: 246  Training loss = 5.0682  Validation loss = 2.6497  \n",
      "\n",
      "Fold: 17  Epoch: 247  Training loss = 5.0678  Validation loss = 2.6494  \n",
      "\n",
      "Fold: 17  Epoch: 248  Training loss = 5.0674  Validation loss = 2.6491  \n",
      "\n",
      "Fold: 17  Epoch: 249  Training loss = 5.0670  Validation loss = 2.6489  \n",
      "\n",
      "Fold: 17  Epoch: 250  Training loss = 5.0666  Validation loss = 2.6486  \n",
      "\n",
      "Fold: 17  Epoch: 251  Training loss = 5.0662  Validation loss = 2.6484  \n",
      "\n",
      "Fold: 17  Epoch: 252  Training loss = 5.0658  Validation loss = 2.6481  \n",
      "\n",
      "Fold: 17  Epoch: 253  Training loss = 5.0653  Validation loss = 2.6478  \n",
      "\n",
      "Fold: 17  Epoch: 254  Training loss = 5.0649  Validation loss = 2.6476  \n",
      "\n",
      "Fold: 17  Epoch: 255  Training loss = 5.0644  Validation loss = 2.6474  \n",
      "\n",
      "Fold: 17  Epoch: 256  Training loss = 5.0639  Validation loss = 2.6471  \n",
      "\n",
      "Fold: 17  Epoch: 257  Training loss = 5.0636  Validation loss = 2.6468  \n",
      "\n",
      "Fold: 17  Epoch: 258  Training loss = 5.0631  Validation loss = 2.6465  \n",
      "\n",
      "Fold: 17  Epoch: 259  Training loss = 5.0626  Validation loss = 2.6462  \n",
      "\n",
      "Fold: 17  Epoch: 260  Training loss = 5.0622  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 17  Epoch: 261  Training loss = 5.0617  Validation loss = 2.6457  \n",
      "\n",
      "Fold: 17  Epoch: 262  Training loss = 5.0613  Validation loss = 2.6454  \n",
      "\n",
      "Fold: 17  Epoch: 263  Training loss = 5.0609  Validation loss = 2.6452  \n",
      "\n",
      "Fold: 17  Epoch: 264  Training loss = 5.0604  Validation loss = 2.6448  \n",
      "\n",
      "Fold: 17  Epoch: 265  Training loss = 5.0600  Validation loss = 2.6446  \n",
      "\n",
      "Fold: 17  Epoch: 266  Training loss = 5.0595  Validation loss = 2.6443  \n",
      "\n",
      "Fold: 17  Epoch: 267  Training loss = 5.0591  Validation loss = 2.6440  \n",
      "\n",
      "Fold: 17  Epoch: 268  Training loss = 5.0587  Validation loss = 2.6437  \n",
      "\n",
      "Fold: 17  Epoch: 269  Training loss = 5.0583  Validation loss = 2.6435  \n",
      "\n",
      "Fold: 17  Epoch: 270  Training loss = 5.0579  Validation loss = 2.6432  \n",
      "\n",
      "Fold: 17  Epoch: 271  Training loss = 5.0575  Validation loss = 2.6430  \n",
      "\n",
      "Fold: 17  Epoch: 272  Training loss = 5.0572  Validation loss = 2.6428  \n",
      "\n",
      "Fold: 17  Epoch: 273  Training loss = 5.0568  Validation loss = 2.6425  \n",
      "\n",
      "Fold: 17  Epoch: 274  Training loss = 5.0564  Validation loss = 2.6422  \n",
      "\n",
      "Fold: 17  Epoch: 275  Training loss = 5.0560  Validation loss = 2.6420  \n",
      "\n",
      "Fold: 17  Epoch: 276  Training loss = 5.0556  Validation loss = 2.6416  \n",
      "\n",
      "Fold: 17  Epoch: 277  Training loss = 5.0551  Validation loss = 2.6413  \n",
      "\n",
      "Fold: 17  Epoch: 278  Training loss = 5.0547  Validation loss = 2.6410  \n",
      "\n",
      "Fold: 17  Epoch: 279  Training loss = 5.0543  Validation loss = 2.6407  \n",
      "\n",
      "Fold: 17  Epoch: 280  Training loss = 5.0539  Validation loss = 2.6405  \n",
      "\n",
      "Fold: 17  Epoch: 281  Training loss = 5.0534  Validation loss = 2.6402  \n",
      "\n",
      "Fold: 17  Epoch: 282  Training loss = 5.0530  Validation loss = 2.6400  \n",
      "\n",
      "Fold: 17  Epoch: 283  Training loss = 5.0525  Validation loss = 2.6396  \n",
      "\n",
      "Fold: 17  Epoch: 284  Training loss = 5.0521  Validation loss = 2.6393  \n",
      "\n",
      "Fold: 17  Epoch: 285  Training loss = 5.0517  Validation loss = 2.6391  \n",
      "\n",
      "Fold: 17  Epoch: 286  Training loss = 5.0513  Validation loss = 2.6388  \n",
      "\n",
      "Fold: 17  Epoch: 287  Training loss = 5.0509  Validation loss = 2.6385  \n",
      "\n",
      "Fold: 17  Epoch: 288  Training loss = 5.0504  Validation loss = 2.6382  \n",
      "\n",
      "Fold: 17  Epoch: 289  Training loss = 5.0500  Validation loss = 2.6380  \n",
      "\n",
      "Fold: 17  Epoch: 290  Training loss = 5.0495  Validation loss = 2.6377  \n",
      "\n",
      "Fold: 17  Epoch: 291  Training loss = 5.0491  Validation loss = 2.6375  \n",
      "\n",
      "Fold: 17  Epoch: 292  Training loss = 5.0488  Validation loss = 2.6371  \n",
      "\n",
      "Fold: 17  Epoch: 293  Training loss = 5.0484  Validation loss = 2.6369  \n",
      "\n",
      "Fold: 17  Epoch: 294  Training loss = 5.0480  Validation loss = 2.6366  \n",
      "\n",
      "Fold: 17  Epoch: 295  Training loss = 5.0475  Validation loss = 2.6364  \n",
      "\n",
      "Fold: 17  Epoch: 296  Training loss = 5.0471  Validation loss = 2.6361  \n",
      "\n",
      "Fold: 17  Epoch: 297  Training loss = 5.0466  Validation loss = 2.6358  \n",
      "\n",
      "Fold: 17  Epoch: 298  Training loss = 5.0463  Validation loss = 2.6356  \n",
      "\n",
      "Fold: 17  Epoch: 299  Training loss = 5.0457  Validation loss = 2.6352  \n",
      "\n",
      "Fold: 17  Epoch: 300  Training loss = 5.0453  Validation loss = 2.6350  \n",
      "\n",
      "Fold: 17  Epoch: 301  Training loss = 5.0449  Validation loss = 2.6347  \n",
      "\n",
      "Fold: 17  Epoch: 302  Training loss = 5.0444  Validation loss = 2.6343  \n",
      "\n",
      "Fold: 17  Epoch: 303  Training loss = 5.0440  Validation loss = 2.6340  \n",
      "\n",
      "Fold: 17  Epoch: 304  Training loss = 5.0436  Validation loss = 2.6338  \n",
      "\n",
      "Fold: 17  Epoch: 305  Training loss = 5.0432  Validation loss = 2.6335  \n",
      "\n",
      "Fold: 17  Epoch: 306  Training loss = 5.0427  Validation loss = 2.6332  \n",
      "\n",
      "Fold: 17  Epoch: 307  Training loss = 5.0423  Validation loss = 2.6330  \n",
      "\n",
      "Fold: 17  Epoch: 308  Training loss = 5.0420  Validation loss = 2.6328  \n",
      "\n",
      "Fold: 17  Epoch: 309  Training loss = 5.0416  Validation loss = 2.6326  \n",
      "\n",
      "Fold: 17  Epoch: 310  Training loss = 5.0412  Validation loss = 2.6323  \n",
      "\n",
      "Fold: 17  Epoch: 311  Training loss = 5.0408  Validation loss = 2.6320  \n",
      "\n",
      "Fold: 17  Epoch: 312  Training loss = 5.0403  Validation loss = 2.6317  \n",
      "\n",
      "Fold: 17  Epoch: 313  Training loss = 5.0400  Validation loss = 2.6315  \n",
      "\n",
      "Fold: 17  Epoch: 314  Training loss = 5.0396  Validation loss = 2.6312  \n",
      "\n",
      "Fold: 17  Epoch: 315  Training loss = 5.0392  Validation loss = 2.6309  \n",
      "\n",
      "Fold: 17  Epoch: 316  Training loss = 5.0388  Validation loss = 2.6307  \n",
      "\n",
      "Fold: 17  Epoch: 317  Training loss = 5.0383  Validation loss = 2.6304  \n",
      "\n",
      "Fold: 17  Epoch: 318  Training loss = 5.0379  Validation loss = 2.6301  \n",
      "\n",
      "Fold: 17  Epoch: 319  Training loss = 5.0375  Validation loss = 2.6299  \n",
      "\n",
      "Fold: 17  Epoch: 320  Training loss = 5.0371  Validation loss = 2.6296  \n",
      "\n",
      "Fold: 17  Epoch: 321  Training loss = 5.0365  Validation loss = 2.6293  \n",
      "\n",
      "Fold: 17  Epoch: 322  Training loss = 5.0361  Validation loss = 2.6291  \n",
      "\n",
      "Fold: 17  Epoch: 323  Training loss = 5.0356  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 17  Epoch: 324  Training loss = 5.0353  Validation loss = 2.6286  \n",
      "\n",
      "Fold: 17  Epoch: 325  Training loss = 5.0348  Validation loss = 2.6283  \n",
      "\n",
      "Fold: 17  Epoch: 326  Training loss = 5.0345  Validation loss = 2.6281  \n",
      "\n",
      "Fold: 17  Epoch: 327  Training loss = 5.0340  Validation loss = 2.6278  \n",
      "\n",
      "Fold: 17  Epoch: 328  Training loss = 5.0335  Validation loss = 2.6276  \n",
      "\n",
      "Fold: 17  Epoch: 329  Training loss = 5.0331  Validation loss = 2.6273  \n",
      "\n",
      "Fold: 17  Epoch: 330  Training loss = 5.0326  Validation loss = 2.6270  \n",
      "\n",
      "Fold: 17  Epoch: 331  Training loss = 5.0321  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 17  Epoch: 332  Training loss = 5.0318  Validation loss = 2.6264  \n",
      "\n",
      "Fold: 17  Epoch: 333  Training loss = 5.0313  Validation loss = 2.6261  \n",
      "\n",
      "Fold: 17  Epoch: 334  Training loss = 5.0309  Validation loss = 2.6258  \n",
      "\n",
      "Fold: 17  Epoch: 335  Training loss = 5.0304  Validation loss = 2.6256  \n",
      "\n",
      "Fold: 17  Epoch: 336  Training loss = 5.0299  Validation loss = 2.6252  \n",
      "\n",
      "Fold: 17  Epoch: 337  Training loss = 5.0295  Validation loss = 2.6249  \n",
      "\n",
      "Fold: 17  Epoch: 338  Training loss = 5.0291  Validation loss = 2.6247  \n",
      "\n",
      "Fold: 17  Epoch: 339  Training loss = 5.0286  Validation loss = 2.6244  \n",
      "\n",
      "Fold: 17  Epoch: 340  Training loss = 5.0281  Validation loss = 2.6240  \n",
      "\n",
      "Fold: 17  Epoch: 341  Training loss = 5.0277  Validation loss = 2.6238  \n",
      "\n",
      "Fold: 17  Epoch: 342  Training loss = 5.0272  Validation loss = 2.6236  \n",
      "\n",
      "Fold: 17  Epoch: 343  Training loss = 5.0266  Validation loss = 2.6233  \n",
      "\n",
      "Fold: 17  Epoch: 344  Training loss = 5.0262  Validation loss = 2.6229  \n",
      "\n",
      "Fold: 17  Epoch: 345  Training loss = 5.0258  Validation loss = 2.6227  \n",
      "\n",
      "Fold: 17  Epoch: 346  Training loss = 5.0254  Validation loss = 2.6225  \n",
      "\n",
      "Fold: 17  Epoch: 347  Training loss = 5.0248  Validation loss = 2.6222  \n",
      "\n",
      "Fold: 17  Epoch: 348  Training loss = 5.0243  Validation loss = 2.6219  \n",
      "\n",
      "Fold: 17  Epoch: 349  Training loss = 5.0239  Validation loss = 2.6216  \n",
      "\n",
      "Fold: 17  Epoch: 350  Training loss = 5.0235  Validation loss = 2.6214  \n",
      "\n",
      "Fold: 17  Epoch: 351  Training loss = 5.0231  Validation loss = 2.6211  \n",
      "\n",
      "Fold: 17  Epoch: 352  Training loss = 5.0227  Validation loss = 2.6209  \n",
      "\n",
      "Fold: 17  Epoch: 353  Training loss = 5.0223  Validation loss = 2.6207  \n",
      "\n",
      "Fold: 17  Epoch: 354  Training loss = 5.0220  Validation loss = 2.6204  \n",
      "\n",
      "Fold: 17  Epoch: 355  Training loss = 5.0215  Validation loss = 2.6202  \n",
      "\n",
      "Fold: 17  Epoch: 356  Training loss = 5.0211  Validation loss = 2.6199  \n",
      "\n",
      "Fold: 17  Epoch: 357  Training loss = 5.0207  Validation loss = 2.6196  \n",
      "\n",
      "Fold: 17  Epoch: 358  Training loss = 5.0203  Validation loss = 2.6194  \n",
      "\n",
      "Fold: 17  Epoch: 359  Training loss = 5.0199  Validation loss = 2.6192  \n",
      "\n",
      "Fold: 17  Epoch: 360  Training loss = 5.0195  Validation loss = 2.6190  \n",
      "\n",
      "Fold: 17  Epoch: 361  Training loss = 5.0191  Validation loss = 2.6188  \n",
      "\n",
      "Fold: 17  Epoch: 362  Training loss = 5.0187  Validation loss = 2.6185  \n",
      "\n",
      "Fold: 17  Epoch: 363  Training loss = 5.0183  Validation loss = 2.6183  \n",
      "\n",
      "Fold: 17  Epoch: 364  Training loss = 5.0180  Validation loss = 2.6181  \n",
      "\n",
      "Fold: 17  Epoch: 365  Training loss = 5.0176  Validation loss = 2.6178  \n",
      "\n",
      "Fold: 17  Epoch: 366  Training loss = 5.0171  Validation loss = 2.6175  \n",
      "\n",
      "Fold: 17  Epoch: 367  Training loss = 5.0167  Validation loss = 2.6173  \n",
      "\n",
      "Fold: 17  Epoch: 368  Training loss = 5.0164  Validation loss = 2.6170  \n",
      "\n",
      "Fold: 17  Epoch: 369  Training loss = 5.0158  Validation loss = 2.6167  \n",
      "\n",
      "Fold: 17  Epoch: 370  Training loss = 5.0155  Validation loss = 2.6165  \n",
      "\n",
      "Fold: 17  Epoch: 371  Training loss = 5.0151  Validation loss = 2.6162  \n",
      "\n",
      "Fold: 17  Epoch: 372  Training loss = 5.0146  Validation loss = 2.6160  \n",
      "\n",
      "Fold: 17  Epoch: 373  Training loss = 5.0142  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 17  Epoch: 374  Training loss = 5.0137  Validation loss = 2.6154  \n",
      "\n",
      "Fold: 17  Epoch: 375  Training loss = 5.0133  Validation loss = 2.6152  \n",
      "\n",
      "Fold: 17  Epoch: 376  Training loss = 5.0130  Validation loss = 2.6150  \n",
      "\n",
      "Fold: 17  Epoch: 377  Training loss = 5.0126  Validation loss = 2.6148  \n",
      "\n",
      "Fold: 17  Epoch: 378  Training loss = 5.0121  Validation loss = 2.6145  \n",
      "\n",
      "Fold: 17  Epoch: 379  Training loss = 5.0116  Validation loss = 2.6143  \n",
      "\n",
      "Fold: 17  Epoch: 380  Training loss = 5.0111  Validation loss = 2.6140  \n",
      "\n",
      "Fold: 17  Epoch: 381  Training loss = 5.0107  Validation loss = 2.6137  \n",
      "\n",
      "Fold: 17  Epoch: 382  Training loss = 5.0103  Validation loss = 2.6135  \n",
      "\n",
      "Fold: 17  Epoch: 383  Training loss = 5.0097  Validation loss = 2.6132  \n",
      "\n",
      "Fold: 17  Epoch: 384  Training loss = 5.0093  Validation loss = 2.6130  \n",
      "\n",
      "Fold: 17  Epoch: 385  Training loss = 5.0088  Validation loss = 2.6127  \n",
      "\n",
      "Fold: 17  Epoch: 386  Training loss = 5.0084  Validation loss = 2.6124  \n",
      "\n",
      "Fold: 17  Epoch: 387  Training loss = 5.0080  Validation loss = 2.6122  \n",
      "\n",
      "Fold: 17  Epoch: 388  Training loss = 5.0076  Validation loss = 2.6120  \n",
      "\n",
      "Fold: 17  Epoch: 389  Training loss = 5.0071  Validation loss = 2.6117  \n",
      "\n",
      "Fold: 17  Epoch: 390  Training loss = 5.0067  Validation loss = 2.6114  \n",
      "\n",
      "Fold: 17  Epoch: 391  Training loss = 5.0062  Validation loss = 2.6112  \n",
      "\n",
      "Fold: 17  Epoch: 392  Training loss = 5.0058  Validation loss = 2.6109  \n",
      "\n",
      "Fold: 17  Epoch: 393  Training loss = 5.0054  Validation loss = 2.6107  \n",
      "\n",
      "Fold: 17  Epoch: 394  Training loss = 5.0050  Validation loss = 2.6105  \n",
      "\n",
      "Fold: 17  Epoch: 395  Training loss = 5.0046  Validation loss = 2.6101  \n",
      "\n",
      "Fold: 17  Epoch: 396  Training loss = 5.0041  Validation loss = 2.6099  \n",
      "\n",
      "Fold: 17  Epoch: 397  Training loss = 5.0037  Validation loss = 2.6097  \n",
      "\n",
      "Fold: 17  Epoch: 398  Training loss = 5.0033  Validation loss = 2.6095  \n",
      "\n",
      "Fold: 17  Epoch: 399  Training loss = 5.0029  Validation loss = 2.6092  \n",
      "\n",
      "Fold: 17  Epoch: 400  Training loss = 5.0024  Validation loss = 2.6090  \n",
      "\n",
      "Fold: 17  Epoch: 401  Training loss = 5.0020  Validation loss = 2.6087  \n",
      "\n",
      "Fold: 17  Epoch: 402  Training loss = 5.0016  Validation loss = 2.6085  \n",
      "\n",
      "Fold: 17  Epoch: 403  Training loss = 5.0012  Validation loss = 2.6082  \n",
      "\n",
      "Fold: 17  Epoch: 404  Training loss = 5.0008  Validation loss = 2.6080  \n",
      "\n",
      "Fold: 17  Epoch: 405  Training loss = 5.0004  Validation loss = 2.6078  \n",
      "\n",
      "Fold: 17  Epoch: 406  Training loss = 5.0000  Validation loss = 2.6076  \n",
      "\n",
      "Fold: 17  Epoch: 407  Training loss = 4.9996  Validation loss = 2.6073  \n",
      "\n",
      "Fold: 17  Epoch: 408  Training loss = 4.9992  Validation loss = 2.6071  \n",
      "\n",
      "Fold: 17  Epoch: 409  Training loss = 4.9987  Validation loss = 2.6069  \n",
      "\n",
      "Fold: 17  Epoch: 410  Training loss = 4.9982  Validation loss = 2.6066  \n",
      "\n",
      "Fold: 17  Epoch: 411  Training loss = 4.9977  Validation loss = 2.6063  \n",
      "\n",
      "Fold: 17  Epoch: 412  Training loss = 4.9973  Validation loss = 2.6061  \n",
      "\n",
      "Fold: 17  Epoch: 413  Training loss = 4.9969  Validation loss = 2.6058  \n",
      "\n",
      "Fold: 17  Epoch: 414  Training loss = 4.9965  Validation loss = 2.6056  \n",
      "\n",
      "Fold: 17  Epoch: 415  Training loss = 4.9960  Validation loss = 2.6053  \n",
      "\n",
      "Fold: 17  Epoch: 416  Training loss = 4.9955  Validation loss = 2.6050  \n",
      "\n",
      "Fold: 17  Epoch: 417  Training loss = 4.9951  Validation loss = 2.6048  \n",
      "\n",
      "Fold: 17  Epoch: 418  Training loss = 4.9947  Validation loss = 2.6046  \n",
      "\n",
      "Fold: 17  Epoch: 419  Training loss = 4.9943  Validation loss = 2.6043  \n",
      "\n",
      "Fold: 17  Epoch: 420  Training loss = 4.9939  Validation loss = 2.6041  \n",
      "\n",
      "Fold: 17  Epoch: 421  Training loss = 4.9935  Validation loss = 2.6038  \n",
      "\n",
      "Fold: 17  Epoch: 422  Training loss = 4.9930  Validation loss = 2.6036  \n",
      "\n",
      "Fold: 17  Epoch: 423  Training loss = 4.9926  Validation loss = 2.6033  \n",
      "\n",
      "Fold: 17  Epoch: 424  Training loss = 4.9922  Validation loss = 2.6031  \n",
      "\n",
      "Fold: 17  Epoch: 425  Training loss = 4.9917  Validation loss = 2.6028  \n",
      "\n",
      "Fold: 17  Epoch: 426  Training loss = 4.9913  Validation loss = 2.6026  \n",
      "\n",
      "Fold: 17  Epoch: 427  Training loss = 4.9910  Validation loss = 2.6024  \n",
      "\n",
      "Fold: 17  Epoch: 428  Training loss = 4.9906  Validation loss = 2.6022  \n",
      "\n",
      "Fold: 17  Epoch: 429  Training loss = 4.9902  Validation loss = 2.6020  \n",
      "\n",
      "Fold: 17  Epoch: 430  Training loss = 4.9897  Validation loss = 2.6018  \n",
      "\n",
      "Fold: 17  Epoch: 431  Training loss = 4.9893  Validation loss = 2.6016  \n",
      "\n",
      "Fold: 17  Epoch: 432  Training loss = 4.9889  Validation loss = 2.6014  \n",
      "\n",
      "Fold: 17  Epoch: 433  Training loss = 4.9886  Validation loss = 2.6012  \n",
      "\n",
      "Fold: 17  Epoch: 434  Training loss = 4.9881  Validation loss = 2.6010  \n",
      "\n",
      "Fold: 17  Epoch: 435  Training loss = 4.9877  Validation loss = 2.6008  \n",
      "\n",
      "Fold: 17  Epoch: 436  Training loss = 4.9872  Validation loss = 2.6005  \n",
      "\n",
      "Fold: 17  Epoch: 437  Training loss = 4.9868  Validation loss = 2.6002  \n",
      "\n",
      "Fold: 17  Epoch: 438  Training loss = 4.9865  Validation loss = 2.6000  \n",
      "\n",
      "Fold: 17  Epoch: 439  Training loss = 4.9861  Validation loss = 2.5998  \n",
      "\n",
      "Fold: 17  Epoch: 440  Training loss = 4.9857  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 17  Epoch: 441  Training loss = 4.9853  Validation loss = 2.5993  \n",
      "\n",
      "Fold: 17  Epoch: 442  Training loss = 4.9848  Validation loss = 2.5991  \n",
      "\n",
      "Fold: 17  Epoch: 443  Training loss = 4.9843  Validation loss = 2.5988  \n",
      "\n",
      "Fold: 17  Epoch: 444  Training loss = 4.9839  Validation loss = 2.5986  \n",
      "\n",
      "Fold: 17  Epoch: 445  Training loss = 4.9836  Validation loss = 2.5984  \n",
      "\n",
      "Fold: 17  Epoch: 446  Training loss = 4.9832  Validation loss = 2.5982  \n",
      "\n",
      "Fold: 17  Epoch: 447  Training loss = 4.9828  Validation loss = 2.5980  \n",
      "\n",
      "Fold: 17  Epoch: 448  Training loss = 4.9823  Validation loss = 2.5978  \n",
      "\n",
      "Fold: 17  Epoch: 449  Training loss = 4.9820  Validation loss = 2.5976  \n",
      "\n",
      "Fold: 17  Epoch: 450  Training loss = 4.9815  Validation loss = 2.5974  \n",
      "\n",
      "Fold: 17  Epoch: 451  Training loss = 4.9812  Validation loss = 2.5972  \n",
      "\n",
      "Fold: 17  Epoch: 452  Training loss = 4.9808  Validation loss = 2.5971  \n",
      "\n",
      "Fold: 17  Epoch: 453  Training loss = 4.9804  Validation loss = 2.5969  \n",
      "\n",
      "Fold: 17  Epoch: 454  Training loss = 4.9800  Validation loss = 2.5967  \n",
      "\n",
      "Fold: 17  Epoch: 455  Training loss = 4.9796  Validation loss = 2.5964  \n",
      "\n",
      "Fold: 17  Epoch: 456  Training loss = 4.9791  Validation loss = 2.5962  \n",
      "\n",
      "Fold: 17  Epoch: 457  Training loss = 4.9787  Validation loss = 2.5959  \n",
      "\n",
      "Fold: 17  Epoch: 458  Training loss = 4.9783  Validation loss = 2.5957  \n",
      "\n",
      "Fold: 17  Epoch: 459  Training loss = 4.9778  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 17  Epoch: 460  Training loss = 4.9773  Validation loss = 2.5952  \n",
      "\n",
      "Fold: 17  Epoch: 461  Training loss = 4.9769  Validation loss = 2.5950  \n",
      "\n",
      "Fold: 17  Epoch: 462  Training loss = 4.9765  Validation loss = 2.5948  \n",
      "\n",
      "Fold: 17  Epoch: 463  Training loss = 4.9762  Validation loss = 2.5946  \n",
      "\n",
      "Fold: 17  Epoch: 464  Training loss = 4.9756  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 17  Epoch: 465  Training loss = 4.9753  Validation loss = 2.5941  \n",
      "\n",
      "Fold: 17  Epoch: 466  Training loss = 4.9749  Validation loss = 2.5939  \n",
      "\n",
      "Fold: 17  Epoch: 467  Training loss = 4.9745  Validation loss = 2.5937  \n",
      "\n",
      "Fold: 17  Epoch: 468  Training loss = 4.9741  Validation loss = 2.5935  \n",
      "\n",
      "Fold: 17  Epoch: 469  Training loss = 4.9737  Validation loss = 2.5933  \n",
      "\n",
      "Fold: 17  Epoch: 470  Training loss = 4.9732  Validation loss = 2.5930  \n",
      "\n",
      "Fold: 17  Epoch: 471  Training loss = 4.9729  Validation loss = 2.5928  \n",
      "\n",
      "Fold: 17  Epoch: 472  Training loss = 4.9724  Validation loss = 2.5926  \n",
      "\n",
      "Fold: 17  Epoch: 473  Training loss = 4.9720  Validation loss = 2.5923  \n",
      "\n",
      "Fold: 17  Epoch: 474  Training loss = 4.9715  Validation loss = 2.5921  \n",
      "\n",
      "Fold: 17  Epoch: 475  Training loss = 4.9710  Validation loss = 2.5918  \n",
      "\n",
      "Fold: 17  Epoch: 476  Training loss = 4.9707  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 17  Epoch: 477  Training loss = 4.9701  Validation loss = 2.5913  \n",
      "\n",
      "Fold: 17  Epoch: 478  Training loss = 4.9697  Validation loss = 2.5911  \n",
      "\n",
      "Fold: 17  Epoch: 479  Training loss = 4.9693  Validation loss = 2.5909  \n",
      "\n",
      "Fold: 17  Epoch: 480  Training loss = 4.9690  Validation loss = 2.5907  \n",
      "\n",
      "Fold: 17  Epoch: 481  Training loss = 4.9685  Validation loss = 2.5905  \n",
      "\n",
      "Fold: 17  Epoch: 482  Training loss = 4.9681  Validation loss = 2.5902  \n",
      "\n",
      "Fold: 17  Epoch: 483  Training loss = 4.9677  Validation loss = 2.5900  \n",
      "\n",
      "Fold: 17  Epoch: 484  Training loss = 4.9672  Validation loss = 2.5898  \n",
      "\n",
      "Fold: 17  Epoch: 485  Training loss = 4.9667  Validation loss = 2.5895  \n",
      "\n",
      "Fold: 17  Epoch: 486  Training loss = 4.9663  Validation loss = 2.5893  \n",
      "\n",
      "Fold: 17  Epoch: 487  Training loss = 4.9659  Validation loss = 2.5891  \n",
      "\n",
      "Fold: 17  Epoch: 488  Training loss = 4.9655  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 17  Epoch: 489  Training loss = 4.9650  Validation loss = 2.5886  \n",
      "\n",
      "Fold: 17  Epoch: 490  Training loss = 4.9646  Validation loss = 2.5884  \n",
      "\n",
      "Fold: 17  Epoch: 491  Training loss = 4.9643  Validation loss = 2.5882  \n",
      "\n",
      "Fold: 17  Epoch: 492  Training loss = 4.9638  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 17  Epoch: 493  Training loss = 4.9634  Validation loss = 2.5878  \n",
      "\n",
      "Fold: 17  Epoch: 494  Training loss = 4.9630  Validation loss = 2.5876  \n",
      "\n",
      "Fold: 17  Epoch: 495  Training loss = 4.9626  Validation loss = 2.5874  \n",
      "\n",
      "Fold: 17  Epoch: 496  Training loss = 4.9621  Validation loss = 2.5871  \n",
      "\n",
      "Fold: 17  Epoch: 497  Training loss = 4.9615  Validation loss = 2.5868  \n",
      "\n",
      "Fold: 17  Epoch: 498  Training loss = 4.9611  Validation loss = 2.5866  \n",
      "\n",
      "Fold: 17  Epoch: 499  Training loss = 4.9605  Validation loss = 2.5863  \n",
      "\n",
      "Fold: 17  Epoch: 500  Training loss = 4.9601  Validation loss = 2.5861  \n",
      "\n",
      "Fold: 17  Epoch: 501  Training loss = 4.9597  Validation loss = 2.5859  \n",
      "\n",
      "Fold: 17  Epoch: 502  Training loss = 4.9593  Validation loss = 2.5857  \n",
      "\n",
      "Fold: 17  Epoch: 503  Training loss = 4.9588  Validation loss = 2.5854  \n",
      "\n",
      "Fold: 17  Epoch: 504  Training loss = 4.9585  Validation loss = 2.5852  \n",
      "\n",
      "Fold: 17  Epoch: 505  Training loss = 4.9581  Validation loss = 2.5850  \n",
      "\n",
      "Fold: 17  Epoch: 506  Training loss = 4.9576  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 17  Epoch: 507  Training loss = 4.9572  Validation loss = 2.5846  \n",
      "\n",
      "Fold: 17  Epoch: 508  Training loss = 4.9567  Validation loss = 2.5843  \n",
      "\n",
      "Fold: 17  Epoch: 509  Training loss = 4.9563  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 17  Epoch: 510  Training loss = 4.9560  Validation loss = 2.5839  \n",
      "\n",
      "Fold: 17  Epoch: 511  Training loss = 4.9556  Validation loss = 2.5837  \n",
      "\n",
      "Fold: 17  Epoch: 512  Training loss = 4.9551  Validation loss = 2.5834  \n",
      "\n",
      "Fold: 17  Epoch: 513  Training loss = 4.9547  Validation loss = 2.5832  \n",
      "\n",
      "Fold: 17  Epoch: 514  Training loss = 4.9543  Validation loss = 2.5830  \n",
      "\n",
      "Fold: 17  Epoch: 515  Training loss = 4.9539  Validation loss = 2.5828  \n",
      "\n",
      "Fold: 17  Epoch: 516  Training loss = 4.9535  Validation loss = 2.5827  \n",
      "\n",
      "Fold: 17  Epoch: 517  Training loss = 4.9531  Validation loss = 2.5824  \n",
      "\n",
      "Fold: 17  Epoch: 518  Training loss = 4.9527  Validation loss = 2.5822  \n",
      "\n",
      "Fold: 17  Epoch: 519  Training loss = 4.9523  Validation loss = 2.5820  \n",
      "\n",
      "Fold: 17  Epoch: 520  Training loss = 4.9518  Validation loss = 2.5818  \n",
      "\n",
      "Fold: 17  Epoch: 521  Training loss = 4.9514  Validation loss = 2.5816  \n",
      "\n",
      "Fold: 17  Epoch: 522  Training loss = 4.9510  Validation loss = 2.5813  \n",
      "\n",
      "Fold: 17  Epoch: 523  Training loss = 4.9507  Validation loss = 2.5812  \n",
      "\n",
      "Fold: 17  Epoch: 524  Training loss = 4.9503  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 17  Epoch: 525  Training loss = 4.9498  Validation loss = 2.5807  \n",
      "\n",
      "Fold: 17  Epoch: 526  Training loss = 4.9493  Validation loss = 2.5805  \n",
      "\n",
      "Fold: 17  Epoch: 527  Training loss = 4.9488  Validation loss = 2.5802  \n",
      "\n",
      "Fold: 17  Epoch: 528  Training loss = 4.9484  Validation loss = 2.5800  \n",
      "\n",
      "Fold: 17  Epoch: 529  Training loss = 4.9479  Validation loss = 2.5797  \n",
      "\n",
      "Fold: 17  Epoch: 530  Training loss = 4.9475  Validation loss = 2.5795  \n",
      "\n",
      "Fold: 17  Epoch: 531  Training loss = 4.9470  Validation loss = 2.5793  \n",
      "\n",
      "Fold: 17  Epoch: 532  Training loss = 4.9465  Validation loss = 2.5791  \n",
      "\n",
      "Fold: 17  Epoch: 533  Training loss = 4.9462  Validation loss = 2.5789  \n",
      "\n",
      "Fold: 17  Epoch: 534  Training loss = 4.9457  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 17  Epoch: 535  Training loss = 4.9454  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 17  Epoch: 536  Training loss = 4.9449  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 17  Epoch: 537  Training loss = 4.9444  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 17  Epoch: 538  Training loss = 4.9440  Validation loss = 2.5777  \n",
      "\n",
      "Fold: 17  Epoch: 539  Training loss = 4.9436  Validation loss = 2.5775  \n",
      "\n",
      "Fold: 17  Epoch: 540  Training loss = 4.9433  Validation loss = 2.5773  \n",
      "\n",
      "Fold: 17  Epoch: 541  Training loss = 4.9429  Validation loss = 2.5771  \n",
      "\n",
      "Fold: 17  Epoch: 542  Training loss = 4.9425  Validation loss = 2.5768  \n",
      "\n",
      "Fold: 17  Epoch: 543  Training loss = 4.9420  Validation loss = 2.5766  \n",
      "\n",
      "Fold: 17  Epoch: 544  Training loss = 4.9417  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 17  Epoch: 545  Training loss = 4.9413  Validation loss = 2.5762  \n",
      "\n",
      "Fold: 17  Epoch: 546  Training loss = 4.9408  Validation loss = 2.5760  \n",
      "\n",
      "Fold: 17  Epoch: 547  Training loss = 4.9405  Validation loss = 2.5758  \n",
      "\n",
      "Fold: 17  Epoch: 548  Training loss = 4.9401  Validation loss = 2.5756  \n",
      "\n",
      "Fold: 17  Epoch: 549  Training loss = 4.9397  Validation loss = 2.5754  \n",
      "\n",
      "Fold: 17  Epoch: 550  Training loss = 4.9393  Validation loss = 2.5752  \n",
      "\n",
      "Fold: 17  Epoch: 551  Training loss = 4.9389  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 17  Epoch: 552  Training loss = 4.9384  Validation loss = 2.5748  \n",
      "\n",
      "Fold: 17  Epoch: 553  Training loss = 4.9380  Validation loss = 2.5746  \n",
      "\n",
      "Fold: 17  Epoch: 554  Training loss = 4.9376  Validation loss = 2.5744  \n",
      "\n",
      "Fold: 17  Epoch: 555  Training loss = 4.9371  Validation loss = 2.5742  \n",
      "\n",
      "Fold: 17  Epoch: 556  Training loss = 4.9368  Validation loss = 2.5740  \n",
      "\n",
      "Fold: 17  Epoch: 557  Training loss = 4.9363  Validation loss = 2.5738  \n",
      "\n",
      "Fold: 17  Epoch: 558  Training loss = 4.9359  Validation loss = 2.5735  \n",
      "\n",
      "Fold: 17  Epoch: 559  Training loss = 4.9354  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 17  Epoch: 560  Training loss = 4.9350  Validation loss = 2.5731  \n",
      "\n",
      "Fold: 17  Epoch: 561  Training loss = 4.9346  Validation loss = 2.5729  \n",
      "\n",
      "Fold: 17  Epoch: 562  Training loss = 4.9341  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 17  Epoch: 563  Training loss = 4.9336  Validation loss = 2.5724  \n",
      "\n",
      "Fold: 17  Epoch: 564  Training loss = 4.9332  Validation loss = 2.5722  \n",
      "\n",
      "Fold: 17  Epoch: 565  Training loss = 4.9328  Validation loss = 2.5720  \n",
      "\n",
      "Fold: 17  Epoch: 566  Training loss = 4.9324  Validation loss = 2.5718  \n",
      "\n",
      "Fold: 17  Epoch: 567  Training loss = 4.9320  Validation loss = 2.5716  \n",
      "\n",
      "Fold: 17  Epoch: 568  Training loss = 4.9316  Validation loss = 2.5714  \n",
      "\n",
      "Fold: 17  Epoch: 569  Training loss = 4.9312  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 17  Epoch: 570  Training loss = 4.9307  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 17  Epoch: 571  Training loss = 4.9303  Validation loss = 2.5708  \n",
      "\n",
      "Fold: 17  Epoch: 572  Training loss = 4.9299  Validation loss = 2.5706  \n",
      "\n",
      "Fold: 17  Epoch: 573  Training loss = 4.9295  Validation loss = 2.5704  \n",
      "\n",
      "Fold: 17  Epoch: 574  Training loss = 4.9291  Validation loss = 2.5702  \n",
      "\n",
      "Fold: 17  Epoch: 575  Training loss = 4.9287  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 17  Epoch: 576  Training loss = 4.9282  Validation loss = 2.5698  \n",
      "\n",
      "Fold: 17  Epoch: 577  Training loss = 4.9278  Validation loss = 2.5696  \n",
      "\n",
      "Fold: 17  Epoch: 578  Training loss = 4.9274  Validation loss = 2.5694  \n",
      "\n",
      "Fold: 17  Epoch: 579  Training loss = 4.9269  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 17  Epoch: 580  Training loss = 4.9264  Validation loss = 2.5689  \n",
      "\n",
      "Fold: 17  Epoch: 581  Training loss = 4.9260  Validation loss = 2.5687  \n",
      "\n",
      "Fold: 17  Epoch: 582  Training loss = 4.9256  Validation loss = 2.5685  \n",
      "\n",
      "Fold: 17  Epoch: 583  Training loss = 4.9252  Validation loss = 2.5683  \n",
      "\n",
      "Fold: 17  Epoch: 584  Training loss = 4.9249  Validation loss = 2.5681  \n",
      "\n",
      "Fold: 17  Epoch: 585  Training loss = 4.9245  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 17  Epoch: 586  Training loss = 4.9240  Validation loss = 2.5677  \n",
      "\n",
      "Fold: 17  Epoch: 587  Training loss = 4.9237  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 17  Epoch: 588  Training loss = 4.9232  Validation loss = 2.5673  \n",
      "\n",
      "Fold: 17  Epoch: 589  Training loss = 4.9228  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 17  Epoch: 590  Training loss = 4.9224  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 17  Epoch: 591  Training loss = 4.9219  Validation loss = 2.5666  \n",
      "\n",
      "Fold: 17  Epoch: 592  Training loss = 4.9214  Validation loss = 2.5664  \n",
      "\n",
      "Fold: 17  Epoch: 593  Training loss = 4.9210  Validation loss = 2.5661  \n",
      "\n",
      "Fold: 17  Epoch: 594  Training loss = 4.9206  Validation loss = 2.5659  \n",
      "\n",
      "Fold: 17  Epoch: 595  Training loss = 4.9202  Validation loss = 2.5657  \n",
      "\n",
      "Fold: 17  Epoch: 596  Training loss = 4.9197  Validation loss = 2.5655  \n",
      "\n",
      "Fold: 17  Epoch: 597  Training loss = 4.9192  Validation loss = 2.5653  \n",
      "\n",
      "Fold: 17  Epoch: 598  Training loss = 4.9189  Validation loss = 2.5651  \n",
      "\n",
      "Fold: 17  Epoch: 599  Training loss = 4.9184  Validation loss = 2.5649  \n",
      "\n",
      "Fold: 17  Epoch: 600  Training loss = 4.9179  Validation loss = 2.5647  \n",
      "\n",
      "Fold: 17  Epoch: 601  Training loss = 4.9176  Validation loss = 2.5645  \n",
      "\n",
      "Fold: 17  Epoch: 602  Training loss = 4.9171  Validation loss = 2.5643  \n",
      "\n",
      "Fold: 17  Epoch: 603  Training loss = 4.9166  Validation loss = 2.5641  \n",
      "\n",
      "Fold: 17  Epoch: 604  Training loss = 4.9162  Validation loss = 2.5640  \n",
      "\n",
      "Fold: 17  Epoch: 605  Training loss = 4.9157  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 17  Epoch: 606  Training loss = 4.9153  Validation loss = 2.5635  \n",
      "\n",
      "Fold: 17  Epoch: 607  Training loss = 4.9148  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 17  Epoch: 608  Training loss = 4.9143  Validation loss = 2.5630  \n",
      "\n",
      "Fold: 17  Epoch: 609  Training loss = 4.9139  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 17  Epoch: 610  Training loss = 4.9135  Validation loss = 2.5626  \n",
      "\n",
      "Fold: 17  Epoch: 611  Training loss = 4.9131  Validation loss = 2.5625  \n",
      "\n",
      "Fold: 17  Epoch: 612  Training loss = 4.9126  Validation loss = 2.5622  \n",
      "\n",
      "Fold: 17  Epoch: 613  Training loss = 4.9121  Validation loss = 2.5620  \n",
      "\n",
      "Fold: 17  Epoch: 614  Training loss = 4.9116  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 17  Epoch: 615  Training loss = 4.9111  Validation loss = 2.5616  \n",
      "\n",
      "Fold: 17  Epoch: 616  Training loss = 4.9106  Validation loss = 2.5614  \n",
      "\n",
      "Fold: 17  Epoch: 617  Training loss = 4.9102  Validation loss = 2.5612  \n",
      "\n",
      "Fold: 17  Epoch: 618  Training loss = 4.9098  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 17  Epoch: 619  Training loss = 4.9093  Validation loss = 2.5607  \n",
      "\n",
      "Fold: 17  Epoch: 620  Training loss = 4.9089  Validation loss = 2.5605  \n",
      "\n",
      "Fold: 17  Epoch: 621  Training loss = 4.9085  Validation loss = 2.5603  \n",
      "\n",
      "Fold: 17  Epoch: 622  Training loss = 4.9081  Validation loss = 2.5601  \n",
      "\n",
      "Fold: 17  Epoch: 623  Training loss = 4.9076  Validation loss = 2.5599  \n",
      "\n",
      "Fold: 17  Epoch: 624  Training loss = 4.9071  Validation loss = 2.5597  \n",
      "\n",
      "Fold: 17  Epoch: 625  Training loss = 4.9067  Validation loss = 2.5595  \n",
      "\n",
      "Fold: 17  Epoch: 626  Training loss = 4.9064  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 17  Epoch: 627  Training loss = 4.9059  Validation loss = 2.5591  \n",
      "\n",
      "Fold: 17  Epoch: 628  Training loss = 4.9055  Validation loss = 2.5590  \n",
      "\n",
      "Fold: 17  Epoch: 629  Training loss = 4.9051  Validation loss = 2.5588  \n",
      "\n",
      "Fold: 17  Epoch: 630  Training loss = 4.9046  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 17  Epoch: 631  Training loss = 4.9042  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 17  Epoch: 632  Training loss = 4.9038  Validation loss = 2.5582  \n",
      "\n",
      "Fold: 17  Epoch: 633  Training loss = 4.9033  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 17  Epoch: 634  Training loss = 4.9029  Validation loss = 2.5577  \n",
      "\n",
      "Fold: 17  Epoch: 635  Training loss = 4.9025  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 17  Epoch: 636  Training loss = 4.9021  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 17  Epoch: 637  Training loss = 4.9016  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 17  Epoch: 638  Training loss = 4.9011  Validation loss = 2.5568  \n",
      "\n",
      "Fold: 17  Epoch: 639  Training loss = 4.9007  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 17  Epoch: 640  Training loss = 4.9003  Validation loss = 2.5565  \n",
      "\n",
      "Fold: 17  Epoch: 641  Training loss = 4.8999  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 17  Epoch: 642  Training loss = 4.8995  Validation loss = 2.5562  \n",
      "\n",
      "Fold: 17  Epoch: 643  Training loss = 4.8992  Validation loss = 2.5560  \n",
      "\n",
      "Fold: 17  Epoch: 644  Training loss = 4.8987  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 17  Epoch: 645  Training loss = 4.8983  Validation loss = 2.5556  \n",
      "\n",
      "Fold: 17  Epoch: 646  Training loss = 4.8979  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 17  Epoch: 647  Training loss = 4.8975  Validation loss = 2.5552  \n",
      "\n",
      "Fold: 17  Epoch: 648  Training loss = 4.8971  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 17  Epoch: 649  Training loss = 4.8967  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 17  Epoch: 650  Training loss = 4.8963  Validation loss = 2.5547  \n",
      "\n",
      "Fold: 17  Epoch: 651  Training loss = 4.8959  Validation loss = 2.5545  \n",
      "\n",
      "Fold: 17  Epoch: 652  Training loss = 4.8956  Validation loss = 2.5543  \n",
      "\n",
      "Fold: 17  Epoch: 653  Training loss = 4.8952  Validation loss = 2.5541  \n",
      "\n",
      "Fold: 17  Epoch: 654  Training loss = 4.8947  Validation loss = 2.5538  \n",
      "\n",
      "Fold: 17  Epoch: 655  Training loss = 4.8943  Validation loss = 2.5536  \n",
      "\n",
      "Fold: 17  Epoch: 656  Training loss = 4.8939  Validation loss = 2.5535  \n",
      "\n",
      "Fold: 17  Epoch: 657  Training loss = 4.8935  Validation loss = 2.5533  \n",
      "\n",
      "Fold: 17  Epoch: 658  Training loss = 4.8930  Validation loss = 2.5531  \n",
      "\n",
      "Fold: 17  Epoch: 659  Training loss = 4.8927  Validation loss = 2.5530  \n",
      "\n",
      "Fold: 17  Epoch: 660  Training loss = 4.8922  Validation loss = 2.5528  \n",
      "\n",
      "Fold: 17  Epoch: 661  Training loss = 4.8917  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 17  Epoch: 662  Training loss = 4.8913  Validation loss = 2.5524  \n",
      "\n",
      "Fold: 17  Epoch: 663  Training loss = 4.8908  Validation loss = 2.5522  \n",
      "\n",
      "Fold: 17  Epoch: 664  Training loss = 4.8904  Validation loss = 2.5520  \n",
      "\n",
      "Fold: 17  Epoch: 665  Training loss = 4.8901  Validation loss = 2.5518  \n",
      "\n",
      "Fold: 17  Epoch: 666  Training loss = 4.8896  Validation loss = 2.5516  \n",
      "\n",
      "Fold: 17  Epoch: 667  Training loss = 4.8892  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 17  Epoch: 668  Training loss = 4.8887  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 17  Epoch: 669  Training loss = 4.8883  Validation loss = 2.5510  \n",
      "\n",
      "Fold: 17  Epoch: 670  Training loss = 4.8880  Validation loss = 2.5508  \n",
      "\n",
      "Fold: 17  Epoch: 671  Training loss = 4.8875  Validation loss = 2.5507  \n",
      "\n",
      "Fold: 17  Epoch: 672  Training loss = 4.8871  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 17  Epoch: 673  Training loss = 4.8866  Validation loss = 2.5503  \n",
      "\n",
      "Fold: 17  Epoch: 674  Training loss = 4.8861  Validation loss = 2.5501  \n",
      "\n",
      "Fold: 17  Epoch: 675  Training loss = 4.8857  Validation loss = 2.5499  \n",
      "\n",
      "Fold: 17  Epoch: 676  Training loss = 4.8853  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 17  Epoch: 677  Training loss = 4.8849  Validation loss = 2.5495  \n",
      "\n",
      "Fold: 17  Epoch: 678  Training loss = 4.8844  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 17  Epoch: 679  Training loss = 4.8839  Validation loss = 2.5491  \n",
      "\n",
      "Fold: 17  Epoch: 680  Training loss = 4.8835  Validation loss = 2.5490  \n",
      "\n",
      "Fold: 17  Epoch: 681  Training loss = 4.8831  Validation loss = 2.5487  \n",
      "\n",
      "Fold: 17  Epoch: 682  Training loss = 4.8826  Validation loss = 2.5486  \n",
      "\n",
      "Fold: 17  Epoch: 683  Training loss = 4.8822  Validation loss = 2.5484  \n",
      "\n",
      "Fold: 17  Epoch: 684  Training loss = 4.8817  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 17  Epoch: 685  Training loss = 4.8812  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 17  Epoch: 686  Training loss = 4.8807  Validation loss = 2.5478  \n",
      "\n",
      "Fold: 17  Epoch: 687  Training loss = 4.8803  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 17  Epoch: 688  Training loss = 4.8799  Validation loss = 2.5474  \n",
      "\n",
      "Fold: 17  Epoch: 689  Training loss = 4.8794  Validation loss = 2.5473  \n",
      "\n",
      "Fold: 17  Epoch: 690  Training loss = 4.8789  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 17  Epoch: 691  Training loss = 4.8784  Validation loss = 2.5469  \n",
      "\n",
      "Fold: 17  Epoch: 692  Training loss = 4.8780  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 17  Epoch: 693  Training loss = 4.8777  Validation loss = 2.5465  \n",
      "\n",
      "Fold: 17  Epoch: 694  Training loss = 4.8772  Validation loss = 2.5463  \n",
      "\n",
      "Fold: 17  Epoch: 695  Training loss = 4.8768  Validation loss = 2.5462  \n",
      "\n",
      "Fold: 17  Epoch: 696  Training loss = 4.8765  Validation loss = 2.5460  \n",
      "\n",
      "Fold: 17  Epoch: 697  Training loss = 4.8762  Validation loss = 2.5458  \n",
      "\n",
      "Fold: 17  Epoch: 698  Training loss = 4.8757  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 17  Epoch: 699  Training loss = 4.8753  Validation loss = 2.5454  \n",
      "\n",
      "Fold: 17  Epoch: 700  Training loss = 4.8749  Validation loss = 2.5452  \n",
      "\n",
      "Fold: 17  Epoch: 701  Training loss = 4.8744  Validation loss = 2.5450  \n",
      "\n",
      "Fold: 17  Epoch: 702  Training loss = 4.8740  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 17  Epoch: 703  Training loss = 4.8735  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 17  Epoch: 704  Training loss = 4.8731  Validation loss = 2.5445  \n",
      "\n",
      "Fold: 17  Epoch: 705  Training loss = 4.8726  Validation loss = 2.5443  \n",
      "\n",
      "Fold: 17  Epoch: 706  Training loss = 4.8722  Validation loss = 2.5441  \n",
      "\n",
      "Fold: 17  Epoch: 707  Training loss = 4.8717  Validation loss = 2.5438  \n",
      "\n",
      "Fold: 17  Epoch: 708  Training loss = 4.8713  Validation loss = 2.5436  \n",
      "\n",
      "Fold: 17  Epoch: 709  Training loss = 4.8708  Validation loss = 2.5433  \n",
      "\n",
      "Fold: 17  Epoch: 710  Training loss = 4.8702  Validation loss = 2.5431  \n",
      "\n",
      "Fold: 17  Epoch: 711  Training loss = 4.8698  Validation loss = 2.5430  \n",
      "\n",
      "Fold: 17  Epoch: 712  Training loss = 4.8694  Validation loss = 2.5428  \n",
      "\n",
      "Fold: 17  Epoch: 713  Training loss = 4.8689  Validation loss = 2.5426  \n",
      "\n",
      "Fold: 17  Epoch: 714  Training loss = 4.8685  Validation loss = 2.5424  \n",
      "\n",
      "Fold: 17  Epoch: 715  Training loss = 4.8681  Validation loss = 2.5422  \n",
      "\n",
      "Fold: 17  Epoch: 716  Training loss = 4.8676  Validation loss = 2.5420  \n",
      "\n",
      "Fold: 17  Epoch: 717  Training loss = 4.8671  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 17  Epoch: 718  Training loss = 4.8667  Validation loss = 2.5416  \n",
      "\n",
      "Fold: 17  Epoch: 719  Training loss = 4.8663  Validation loss = 2.5415  \n",
      "\n",
      "Fold: 17  Epoch: 720  Training loss = 4.8657  Validation loss = 2.5412  \n",
      "\n",
      "Fold: 17  Epoch: 721  Training loss = 4.8653  Validation loss = 2.5410  \n",
      "\n",
      "Fold: 17  Epoch: 722  Training loss = 4.8648  Validation loss = 2.5408  \n",
      "\n",
      "Fold: 17  Epoch: 723  Training loss = 4.8643  Validation loss = 2.5407  \n",
      "\n",
      "Fold: 17  Epoch: 724  Training loss = 4.8640  Validation loss = 2.5406  \n",
      "\n",
      "Fold: 17  Epoch: 725  Training loss = 4.8636  Validation loss = 2.5403  \n",
      "\n",
      "Fold: 17  Epoch: 726  Training loss = 4.8631  Validation loss = 2.5401  \n",
      "\n",
      "Fold: 17  Epoch: 727  Training loss = 4.8627  Validation loss = 2.5400  \n",
      "\n",
      "Fold: 17  Epoch: 728  Training loss = 4.8622  Validation loss = 2.5398  \n",
      "\n",
      "Fold: 17  Epoch: 729  Training loss = 4.8617  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 17  Epoch: 730  Training loss = 4.8613  Validation loss = 2.5394  \n",
      "\n",
      "Fold: 17  Epoch: 731  Training loss = 4.8609  Validation loss = 2.5392  \n",
      "\n",
      "Fold: 17  Epoch: 732  Training loss = 4.8605  Validation loss = 2.5391  \n",
      "\n",
      "Fold: 17  Epoch: 733  Training loss = 4.8601  Validation loss = 2.5389  \n",
      "\n",
      "Fold: 17  Epoch: 734  Training loss = 4.8596  Validation loss = 2.5387  \n",
      "\n",
      "Fold: 17  Epoch: 735  Training loss = 4.8592  Validation loss = 2.5385  \n",
      "\n",
      "Fold: 17  Epoch: 736  Training loss = 4.8587  Validation loss = 2.5383  \n",
      "\n",
      "Fold: 17  Epoch: 737  Training loss = 4.8583  Validation loss = 2.5381  \n",
      "\n",
      "Fold: 17  Epoch: 738  Training loss = 4.8579  Validation loss = 2.5379  \n",
      "\n",
      "Fold: 17  Epoch: 739  Training loss = 4.8574  Validation loss = 2.5377  \n",
      "\n",
      "Fold: 17  Epoch: 740  Training loss = 4.8570  Validation loss = 2.5376  \n",
      "\n",
      "Fold: 17  Epoch: 741  Training loss = 4.8566  Validation loss = 2.5374  \n",
      "\n",
      "Fold: 17  Epoch: 742  Training loss = 4.8562  Validation loss = 2.5372  \n",
      "\n",
      "Fold: 17  Epoch: 743  Training loss = 4.8558  Validation loss = 2.5370  \n",
      "\n",
      "Fold: 17  Epoch: 744  Training loss = 4.8553  Validation loss = 2.5368  \n",
      "\n",
      "Fold: 17  Epoch: 745  Training loss = 4.8550  Validation loss = 2.5366  \n",
      "\n",
      "Fold: 17  Epoch: 746  Training loss = 4.8547  Validation loss = 2.5365  \n",
      "\n",
      "Fold: 17  Epoch: 747  Training loss = 4.8543  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 17  Epoch: 748  Training loss = 4.8539  Validation loss = 2.5361  \n",
      "\n",
      "Fold: 17  Epoch: 749  Training loss = 4.8534  Validation loss = 2.5360  \n",
      "\n",
      "Fold: 17  Epoch: 750  Training loss = 4.8528  Validation loss = 2.5358  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 750  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 4.8910  Validation loss = 1.2703  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 4.8905  Validation loss = 1.2700  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 4.8900  Validation loss = 1.2696  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 4.8895  Validation loss = 1.2693  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 4.8891  Validation loss = 1.2691  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 4.8886  Validation loss = 1.2687  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 4.8882  Validation loss = 1.2684  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 4.8878  Validation loss = 1.2681  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 4.8873  Validation loss = 1.2678  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 4.8868  Validation loss = 1.2674  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 4.8864  Validation loss = 1.2671  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 4.8859  Validation loss = 1.2667  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 4.8855  Validation loss = 1.2665  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 4.8850  Validation loss = 1.2662  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 4.8845  Validation loss = 1.2658  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 4.8840  Validation loss = 1.2655  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 4.8835  Validation loss = 1.2650  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 4.8831  Validation loss = 1.2648  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 4.8827  Validation loss = 1.2645  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 4.8823  Validation loss = 1.2642  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 4.8819  Validation loss = 1.2640  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 4.8815  Validation loss = 1.2636  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 4.8810  Validation loss = 1.2633  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 4.8807  Validation loss = 1.2630  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 4.8802  Validation loss = 1.2627  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 4.8797  Validation loss = 1.2623  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 4.8794  Validation loss = 1.2621  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 4.8790  Validation loss = 1.2619  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 4.8786  Validation loss = 1.2616  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 4.8782  Validation loss = 1.2613  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 4.8777  Validation loss = 1.2609  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 4.8773  Validation loss = 1.2606  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 4.8768  Validation loss = 1.2603  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 4.8764  Validation loss = 1.2600  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 4.8761  Validation loss = 1.2598  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 4.8756  Validation loss = 1.2595  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 4.8751  Validation loss = 1.2591  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 4.8746  Validation loss = 1.2588  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 4.8741  Validation loss = 1.2584  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 4.8736  Validation loss = 1.2581  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 4.8731  Validation loss = 1.2577  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 4.8727  Validation loss = 1.2574  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 4.8723  Validation loss = 1.2572  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 4.8720  Validation loss = 1.2570  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 4.8715  Validation loss = 1.2566  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 4.8711  Validation loss = 1.2563  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 4.8708  Validation loss = 1.2561  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 4.8704  Validation loss = 1.2558  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 4.8700  Validation loss = 1.2555  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 4.8695  Validation loss = 1.2552  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 4.8692  Validation loss = 1.2550  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 4.8687  Validation loss = 1.2545  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 4.8682  Validation loss = 1.2542  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 4.8678  Validation loss = 1.2539  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 4.8673  Validation loss = 1.2536  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 4.8669  Validation loss = 1.2533  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 4.8666  Validation loss = 1.2531  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 4.8661  Validation loss = 1.2528  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 4.8657  Validation loss = 1.2526  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 4.8654  Validation loss = 1.2524  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 4.8650  Validation loss = 1.2522  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 4.8646  Validation loss = 1.2519  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 4.8641  Validation loss = 1.2516  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 4.8637  Validation loss = 1.2513  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 4.8632  Validation loss = 1.2510  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 4.8628  Validation loss = 1.2507  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 4.8624  Validation loss = 1.2504  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 4.8620  Validation loss = 1.2501  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 4.8615  Validation loss = 1.2498  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 4.8611  Validation loss = 1.2495  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 4.8607  Validation loss = 1.2492  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 4.8602  Validation loss = 1.2488  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 4.8598  Validation loss = 1.2486  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 4.8594  Validation loss = 1.2483  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 4.8590  Validation loss = 1.2480  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 4.8586  Validation loss = 1.2477  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 4.8582  Validation loss = 1.2473  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 4.8578  Validation loss = 1.2470  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 4.8573  Validation loss = 1.2467  \n",
      "\n",
      "Fold: 18  Epoch: 80  Training loss = 4.8570  Validation loss = 1.2464  \n",
      "\n",
      "Fold: 18  Epoch: 81  Training loss = 4.8566  Validation loss = 1.2461  \n",
      "\n",
      "Fold: 18  Epoch: 82  Training loss = 4.8562  Validation loss = 1.2458  \n",
      "\n",
      "Fold: 18  Epoch: 83  Training loss = 4.8558  Validation loss = 1.2455  \n",
      "\n",
      "Fold: 18  Epoch: 84  Training loss = 4.8553  Validation loss = 1.2452  \n",
      "\n",
      "Fold: 18  Epoch: 85  Training loss = 4.8549  Validation loss = 1.2448  \n",
      "\n",
      "Fold: 18  Epoch: 86  Training loss = 4.8544  Validation loss = 1.2444  \n",
      "\n",
      "Fold: 18  Epoch: 87  Training loss = 4.8539  Validation loss = 1.2441  \n",
      "\n",
      "Fold: 18  Epoch: 88  Training loss = 4.8534  Validation loss = 1.2437  \n",
      "\n",
      "Fold: 18  Epoch: 89  Training loss = 4.8530  Validation loss = 1.2434  \n",
      "\n",
      "Fold: 18  Epoch: 90  Training loss = 4.8526  Validation loss = 1.2432  \n",
      "\n",
      "Fold: 18  Epoch: 91  Training loss = 4.8521  Validation loss = 1.2427  \n",
      "\n",
      "Fold: 18  Epoch: 92  Training loss = 4.8516  Validation loss = 1.2423  \n",
      "\n",
      "Fold: 18  Epoch: 93  Training loss = 4.8512  Validation loss = 1.2420  \n",
      "\n",
      "Fold: 18  Epoch: 94  Training loss = 4.8507  Validation loss = 1.2417  \n",
      "\n",
      "Fold: 18  Epoch: 95  Training loss = 4.8503  Validation loss = 1.2414  \n",
      "\n",
      "Fold: 18  Epoch: 96  Training loss = 4.8499  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 18  Epoch: 97  Training loss = 4.8495  Validation loss = 1.2407  \n",
      "\n",
      "Fold: 18  Epoch: 98  Training loss = 4.8491  Validation loss = 1.2403  \n",
      "\n",
      "Fold: 18  Epoch: 99  Training loss = 4.8487  Validation loss = 1.2400  \n",
      "\n",
      "Fold: 18  Epoch: 100  Training loss = 4.8482  Validation loss = 1.2397  \n",
      "\n",
      "Fold: 18  Epoch: 101  Training loss = 4.8477  Validation loss = 1.2393  \n",
      "\n",
      "Fold: 18  Epoch: 102  Training loss = 4.8472  Validation loss = 1.2389  \n",
      "\n",
      "Fold: 18  Epoch: 103  Training loss = 4.8469  Validation loss = 1.2387  \n",
      "\n",
      "Fold: 18  Epoch: 104  Training loss = 4.8464  Validation loss = 1.2384  \n",
      "\n",
      "Fold: 18  Epoch: 105  Training loss = 4.8461  Validation loss = 1.2382  \n",
      "\n",
      "Fold: 18  Epoch: 106  Training loss = 4.8457  Validation loss = 1.2380  \n",
      "\n",
      "Fold: 18  Epoch: 107  Training loss = 4.8453  Validation loss = 1.2377  \n",
      "\n",
      "Fold: 18  Epoch: 108  Training loss = 4.8449  Validation loss = 1.2373  \n",
      "\n",
      "Fold: 18  Epoch: 109  Training loss = 4.8446  Validation loss = 1.2371  \n",
      "\n",
      "Fold: 18  Epoch: 110  Training loss = 4.8441  Validation loss = 1.2367  \n",
      "\n",
      "Fold: 18  Epoch: 111  Training loss = 4.8437  Validation loss = 1.2364  \n",
      "\n",
      "Fold: 18  Epoch: 112  Training loss = 4.8433  Validation loss = 1.2361  \n",
      "\n",
      "Fold: 18  Epoch: 113  Training loss = 4.8429  Validation loss = 1.2359  \n",
      "\n",
      "Fold: 18  Epoch: 114  Training loss = 4.8425  Validation loss = 1.2355  \n",
      "\n",
      "Fold: 18  Epoch: 115  Training loss = 4.8421  Validation loss = 1.2353  \n",
      "\n",
      "Fold: 18  Epoch: 116  Training loss = 4.8417  Validation loss = 1.2350  \n",
      "\n",
      "Fold: 18  Epoch: 117  Training loss = 4.8411  Validation loss = 1.2345  \n",
      "\n",
      "Fold: 18  Epoch: 118  Training loss = 4.8407  Validation loss = 1.2342  \n",
      "\n",
      "Fold: 18  Epoch: 119  Training loss = 4.8403  Validation loss = 1.2340  \n",
      "\n",
      "Fold: 18  Epoch: 120  Training loss = 4.8399  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 18  Epoch: 121  Training loss = 4.8395  Validation loss = 1.2333  \n",
      "\n",
      "Fold: 18  Epoch: 122  Training loss = 4.8391  Validation loss = 1.2331  \n",
      "\n",
      "Fold: 18  Epoch: 123  Training loss = 4.8386  Validation loss = 1.2327  \n",
      "\n",
      "Fold: 18  Epoch: 124  Training loss = 4.8382  Validation loss = 1.2324  \n",
      "\n",
      "Fold: 18  Epoch: 125  Training loss = 4.8379  Validation loss = 1.2322  \n",
      "\n",
      "Fold: 18  Epoch: 126  Training loss = 4.8374  Validation loss = 1.2318  \n",
      "\n",
      "Fold: 18  Epoch: 127  Training loss = 4.8370  Validation loss = 1.2315  \n",
      "\n",
      "Fold: 18  Epoch: 128  Training loss = 4.8366  Validation loss = 1.2313  \n",
      "\n",
      "Fold: 18  Epoch: 129  Training loss = 4.8362  Validation loss = 1.2311  \n",
      "\n",
      "Fold: 18  Epoch: 130  Training loss = 4.8359  Validation loss = 1.2309  \n",
      "\n",
      "Fold: 18  Epoch: 131  Training loss = 4.8354  Validation loss = 1.2304  \n",
      "\n",
      "Fold: 18  Epoch: 132  Training loss = 4.8350  Validation loss = 1.2302  \n",
      "\n",
      "Fold: 18  Epoch: 133  Training loss = 4.8345  Validation loss = 1.2299  \n",
      "\n",
      "Fold: 18  Epoch: 134  Training loss = 4.8341  Validation loss = 1.2296  \n",
      "\n",
      "Fold: 18  Epoch: 135  Training loss = 4.8337  Validation loss = 1.2293  \n",
      "\n",
      "Fold: 18  Epoch: 136  Training loss = 4.8333  Validation loss = 1.2291  \n",
      "\n",
      "Fold: 18  Epoch: 137  Training loss = 4.8328  Validation loss = 1.2287  \n",
      "\n",
      "Fold: 18  Epoch: 138  Training loss = 4.8323  Validation loss = 1.2284  \n",
      "\n",
      "Fold: 18  Epoch: 139  Training loss = 4.8319  Validation loss = 1.2281  \n",
      "\n",
      "Fold: 18  Epoch: 140  Training loss = 4.8314  Validation loss = 1.2277  \n",
      "\n",
      "Fold: 18  Epoch: 141  Training loss = 4.8311  Validation loss = 1.2275  \n",
      "\n",
      "Fold: 18  Epoch: 142  Training loss = 4.8307  Validation loss = 1.2273  \n",
      "\n",
      "Fold: 18  Epoch: 143  Training loss = 4.8304  Validation loss = 1.2271  \n",
      "\n",
      "Fold: 18  Epoch: 144  Training loss = 4.8298  Validation loss = 1.2267  \n",
      "\n",
      "Fold: 18  Epoch: 145  Training loss = 4.8293  Validation loss = 1.2264  \n",
      "\n",
      "Fold: 18  Epoch: 146  Training loss = 4.8288  Validation loss = 1.2260  \n",
      "\n",
      "Fold: 18  Epoch: 147  Training loss = 4.8285  Validation loss = 1.2258  \n",
      "\n",
      "Fold: 18  Epoch: 148  Training loss = 4.8281  Validation loss = 1.2256  \n",
      "\n",
      "Fold: 18  Epoch: 149  Training loss = 4.8278  Validation loss = 1.2254  \n",
      "\n",
      "Fold: 18  Epoch: 150  Training loss = 4.8274  Validation loss = 1.2252  \n",
      "\n",
      "Fold: 18  Epoch: 151  Training loss = 4.8270  Validation loss = 1.2249  \n",
      "\n",
      "Fold: 18  Epoch: 152  Training loss = 4.8266  Validation loss = 1.2246  \n",
      "\n",
      "Fold: 18  Epoch: 153  Training loss = 4.8261  Validation loss = 1.2243  \n",
      "\n",
      "Fold: 18  Epoch: 154  Training loss = 4.8257  Validation loss = 1.2241  \n",
      "\n",
      "Fold: 18  Epoch: 155  Training loss = 4.8253  Validation loss = 1.2238  \n",
      "\n",
      "Fold: 18  Epoch: 156  Training loss = 4.8250  Validation loss = 1.2236  \n",
      "\n",
      "Fold: 18  Epoch: 157  Training loss = 4.8246  Validation loss = 1.2234  \n",
      "\n",
      "Fold: 18  Epoch: 158  Training loss = 4.8242  Validation loss = 1.2231  \n",
      "\n",
      "Fold: 18  Epoch: 159  Training loss = 4.8238  Validation loss = 1.2229  \n",
      "\n",
      "Fold: 18  Epoch: 160  Training loss = 4.8235  Validation loss = 1.2226  \n",
      "\n",
      "Fold: 18  Epoch: 161  Training loss = 4.8230  Validation loss = 1.2223  \n",
      "\n",
      "Fold: 18  Epoch: 162  Training loss = 4.8226  Validation loss = 1.2220  \n",
      "\n",
      "Fold: 18  Epoch: 163  Training loss = 4.8222  Validation loss = 1.2218  \n",
      "\n",
      "Fold: 18  Epoch: 164  Training loss = 4.8218  Validation loss = 1.2215  \n",
      "\n",
      "Fold: 18  Epoch: 165  Training loss = 4.8214  Validation loss = 1.2212  \n",
      "\n",
      "Fold: 18  Epoch: 166  Training loss = 4.8209  Validation loss = 1.2209  \n",
      "\n",
      "Fold: 18  Epoch: 167  Training loss = 4.8205  Validation loss = 1.2206  \n",
      "\n",
      "Fold: 18  Epoch: 168  Training loss = 4.8202  Validation loss = 1.2203  \n",
      "\n",
      "Fold: 18  Epoch: 169  Training loss = 4.8198  Validation loss = 1.2200  \n",
      "\n",
      "Fold: 18  Epoch: 170  Training loss = 4.8193  Validation loss = 1.2198  \n",
      "\n",
      "Fold: 18  Epoch: 171  Training loss = 4.8189  Validation loss = 1.2195  \n",
      "\n",
      "Fold: 18  Epoch: 172  Training loss = 4.8185  Validation loss = 1.2192  \n",
      "\n",
      "Fold: 18  Epoch: 173  Training loss = 4.8181  Validation loss = 1.2189  \n",
      "\n",
      "Fold: 18  Epoch: 174  Training loss = 4.8177  Validation loss = 1.2187  \n",
      "\n",
      "Fold: 18  Epoch: 175  Training loss = 4.8174  Validation loss = 1.2184  \n",
      "\n",
      "Fold: 18  Epoch: 176  Training loss = 4.8170  Validation loss = 1.2182  \n",
      "\n",
      "Fold: 18  Epoch: 177  Training loss = 4.8166  Validation loss = 1.2179  \n",
      "\n",
      "Fold: 18  Epoch: 178  Training loss = 4.8162  Validation loss = 1.2175  \n",
      "\n",
      "Fold: 18  Epoch: 179  Training loss = 4.8158  Validation loss = 1.2173  \n",
      "\n",
      "Fold: 18  Epoch: 180  Training loss = 4.8154  Validation loss = 1.2171  \n",
      "\n",
      "Fold: 18  Epoch: 181  Training loss = 4.8149  Validation loss = 1.2167  \n",
      "\n",
      "Fold: 18  Epoch: 182  Training loss = 4.8144  Validation loss = 1.2165  \n",
      "\n",
      "Fold: 18  Epoch: 183  Training loss = 4.8141  Validation loss = 1.2162  \n",
      "\n",
      "Fold: 18  Epoch: 184  Training loss = 4.8138  Validation loss = 1.2160  \n",
      "\n",
      "Fold: 18  Epoch: 185  Training loss = 4.8133  Validation loss = 1.2157  \n",
      "\n",
      "Fold: 18  Epoch: 186  Training loss = 4.8129  Validation loss = 1.2154  \n",
      "\n",
      "Fold: 18  Epoch: 187  Training loss = 4.8125  Validation loss = 1.2151  \n",
      "\n",
      "Fold: 18  Epoch: 188  Training loss = 4.8121  Validation loss = 1.2148  \n",
      "\n",
      "Fold: 18  Epoch: 189  Training loss = 4.8116  Validation loss = 1.2144  \n",
      "\n",
      "Fold: 18  Epoch: 190  Training loss = 4.8112  Validation loss = 1.2142  \n",
      "\n",
      "Fold: 18  Epoch: 191  Training loss = 4.8109  Validation loss = 1.2139  \n",
      "\n",
      "Fold: 18  Epoch: 192  Training loss = 4.8103  Validation loss = 1.2135  \n",
      "\n",
      "Fold: 18  Epoch: 193  Training loss = 4.8099  Validation loss = 1.2132  \n",
      "\n",
      "Fold: 18  Epoch: 194  Training loss = 4.8095  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 18  Epoch: 195  Training loss = 4.8092  Validation loss = 1.2128  \n",
      "\n",
      "Fold: 18  Epoch: 196  Training loss = 4.8087  Validation loss = 1.2125  \n",
      "\n",
      "Fold: 18  Epoch: 197  Training loss = 4.8084  Validation loss = 1.2123  \n",
      "\n",
      "Fold: 18  Epoch: 198  Training loss = 4.8080  Validation loss = 1.2120  \n",
      "\n",
      "Fold: 18  Epoch: 199  Training loss = 4.8076  Validation loss = 1.2117  \n",
      "\n",
      "Fold: 18  Epoch: 200  Training loss = 4.8072  Validation loss = 1.2114  \n",
      "\n",
      "Fold: 18  Epoch: 201  Training loss = 4.8068  Validation loss = 1.2112  \n",
      "\n",
      "Fold: 18  Epoch: 202  Training loss = 4.8063  Validation loss = 1.2108  \n",
      "\n",
      "Fold: 18  Epoch: 203  Training loss = 4.8059  Validation loss = 1.2105  \n",
      "\n",
      "Fold: 18  Epoch: 204  Training loss = 4.8055  Validation loss = 1.2102  \n",
      "\n",
      "Fold: 18  Epoch: 205  Training loss = 4.8051  Validation loss = 1.2099  \n",
      "\n",
      "Fold: 18  Epoch: 206  Training loss = 4.8046  Validation loss = 1.2095  \n",
      "\n",
      "Fold: 18  Epoch: 207  Training loss = 4.8042  Validation loss = 1.2093  \n",
      "\n",
      "Fold: 18  Epoch: 208  Training loss = 4.8038  Validation loss = 1.2090  \n",
      "\n",
      "Fold: 18  Epoch: 209  Training loss = 4.8033  Validation loss = 1.2088  \n",
      "\n",
      "Fold: 18  Epoch: 210  Training loss = 4.8030  Validation loss = 1.2085  \n",
      "\n",
      "Fold: 18  Epoch: 211  Training loss = 4.8026  Validation loss = 1.2082  \n",
      "\n",
      "Fold: 18  Epoch: 212  Training loss = 4.8021  Validation loss = 1.2079  \n",
      "\n",
      "Fold: 18  Epoch: 213  Training loss = 4.8017  Validation loss = 1.2076  \n",
      "\n",
      "Fold: 18  Epoch: 214  Training loss = 4.8013  Validation loss = 1.2074  \n",
      "\n",
      "Fold: 18  Epoch: 215  Training loss = 4.8009  Validation loss = 1.2071  \n",
      "\n",
      "Fold: 18  Epoch: 216  Training loss = 4.8005  Validation loss = 1.2069  \n",
      "\n",
      "Fold: 18  Epoch: 217  Training loss = 4.8000  Validation loss = 1.2065  \n",
      "\n",
      "Fold: 18  Epoch: 218  Training loss = 4.7995  Validation loss = 1.2062  \n",
      "\n",
      "Fold: 18  Epoch: 219  Training loss = 4.7992  Validation loss = 1.2060  \n",
      "\n",
      "Fold: 18  Epoch: 220  Training loss = 4.7987  Validation loss = 1.2057  \n",
      "\n",
      "Fold: 18  Epoch: 221  Training loss = 4.7983  Validation loss = 1.2055  \n",
      "\n",
      "Fold: 18  Epoch: 222  Training loss = 4.7979  Validation loss = 1.2052  \n",
      "\n",
      "Fold: 18  Epoch: 223  Training loss = 4.7975  Validation loss = 1.2049  \n",
      "\n",
      "Fold: 18  Epoch: 224  Training loss = 4.7971  Validation loss = 1.2046  \n",
      "\n",
      "Fold: 18  Epoch: 225  Training loss = 4.7968  Validation loss = 1.2044  \n",
      "\n",
      "Fold: 18  Epoch: 226  Training loss = 4.7964  Validation loss = 1.2042  \n",
      "\n",
      "Fold: 18  Epoch: 227  Training loss = 4.7961  Validation loss = 1.2040  \n",
      "\n",
      "Fold: 18  Epoch: 228  Training loss = 4.7958  Validation loss = 1.2038  \n",
      "\n",
      "Fold: 18  Epoch: 229  Training loss = 4.7954  Validation loss = 1.2035  \n",
      "\n",
      "Fold: 18  Epoch: 230  Training loss = 4.7950  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 18  Epoch: 231  Training loss = 4.7945  Validation loss = 1.2030  \n",
      "\n",
      "Fold: 18  Epoch: 232  Training loss = 4.7942  Validation loss = 1.2027  \n",
      "\n",
      "Fold: 18  Epoch: 233  Training loss = 4.7938  Validation loss = 1.2025  \n",
      "\n",
      "Fold: 18  Epoch: 234  Training loss = 4.7935  Validation loss = 1.2022  \n",
      "\n",
      "Fold: 18  Epoch: 235  Training loss = 4.7931  Validation loss = 1.2020  \n",
      "\n",
      "Fold: 18  Epoch: 236  Training loss = 4.7927  Validation loss = 1.2017  \n",
      "\n",
      "Fold: 18  Epoch: 237  Training loss = 4.7922  Validation loss = 1.2014  \n",
      "\n",
      "Fold: 18  Epoch: 238  Training loss = 4.7918  Validation loss = 1.2012  \n",
      "\n",
      "Fold: 18  Epoch: 239  Training loss = 4.7914  Validation loss = 1.2009  \n",
      "\n",
      "Fold: 18  Epoch: 240  Training loss = 4.7909  Validation loss = 1.2006  \n",
      "\n",
      "Fold: 18  Epoch: 241  Training loss = 4.7906  Validation loss = 1.2004  \n",
      "\n",
      "Fold: 18  Epoch: 242  Training loss = 4.7901  Validation loss = 1.2001  \n",
      "\n",
      "Fold: 18  Epoch: 243  Training loss = 4.7897  Validation loss = 1.1998  \n",
      "\n",
      "Fold: 18  Epoch: 244  Training loss = 4.7893  Validation loss = 1.1996  \n",
      "\n",
      "Fold: 18  Epoch: 245  Training loss = 4.7889  Validation loss = 1.1993  \n",
      "\n",
      "Fold: 18  Epoch: 246  Training loss = 4.7885  Validation loss = 1.1991  \n",
      "\n",
      "Fold: 18  Epoch: 247  Training loss = 4.7882  Validation loss = 1.1989  \n",
      "\n",
      "Fold: 18  Epoch: 248  Training loss = 4.7877  Validation loss = 1.1987  \n",
      "\n",
      "Fold: 18  Epoch: 249  Training loss = 4.7873  Validation loss = 1.1984  \n",
      "\n",
      "Fold: 18  Epoch: 250  Training loss = 4.7869  Validation loss = 1.1981  \n",
      "\n",
      "Fold: 18  Epoch: 251  Training loss = 4.7865  Validation loss = 1.1978  \n",
      "\n",
      "Fold: 18  Epoch: 252  Training loss = 4.7860  Validation loss = 1.1975  \n",
      "\n",
      "Fold: 18  Epoch: 253  Training loss = 4.7856  Validation loss = 1.1973  \n",
      "\n",
      "Fold: 18  Epoch: 254  Training loss = 4.7852  Validation loss = 1.1970  \n",
      "\n",
      "Fold: 18  Epoch: 255  Training loss = 4.7849  Validation loss = 1.1968  \n",
      "\n",
      "Fold: 18  Epoch: 256  Training loss = 4.7846  Validation loss = 1.1965  \n",
      "\n",
      "Fold: 18  Epoch: 257  Training loss = 4.7841  Validation loss = 1.1962  \n",
      "\n",
      "Fold: 18  Epoch: 258  Training loss = 4.7836  Validation loss = 1.1958  \n",
      "\n",
      "Fold: 18  Epoch: 259  Training loss = 4.7830  Validation loss = 1.1954  \n",
      "\n",
      "Fold: 18  Epoch: 260  Training loss = 4.7827  Validation loss = 1.1952  \n",
      "\n",
      "Fold: 18  Epoch: 261  Training loss = 4.7823  Validation loss = 1.1950  \n",
      "\n",
      "Fold: 18  Epoch: 262  Training loss = 4.7819  Validation loss = 1.1948  \n",
      "\n",
      "Fold: 18  Epoch: 263  Training loss = 4.7817  Validation loss = 1.1947  \n",
      "\n",
      "Fold: 18  Epoch: 264  Training loss = 4.7813  Validation loss = 1.1944  \n",
      "\n",
      "Fold: 18  Epoch: 265  Training loss = 4.7808  Validation loss = 1.1941  \n",
      "\n",
      "Fold: 18  Epoch: 266  Training loss = 4.7804  Validation loss = 1.1938  \n",
      "\n",
      "Fold: 18  Epoch: 267  Training loss = 4.7800  Validation loss = 1.1936  \n",
      "\n",
      "Fold: 18  Epoch: 268  Training loss = 4.7796  Validation loss = 1.1933  \n",
      "\n",
      "Fold: 18  Epoch: 269  Training loss = 4.7791  Validation loss = 1.1930  \n",
      "\n",
      "Fold: 18  Epoch: 270  Training loss = 4.7786  Validation loss = 1.1927  \n",
      "\n",
      "Fold: 18  Epoch: 271  Training loss = 4.7783  Validation loss = 1.1925  \n",
      "\n",
      "Fold: 18  Epoch: 272  Training loss = 4.7779  Validation loss = 1.1923  \n",
      "\n",
      "Fold: 18  Epoch: 273  Training loss = 4.7775  Validation loss = 1.1920  \n",
      "\n",
      "Fold: 18  Epoch: 274  Training loss = 4.7771  Validation loss = 1.1918  \n",
      "\n",
      "Fold: 18  Epoch: 275  Training loss = 4.7767  Validation loss = 1.1915  \n",
      "\n",
      "Fold: 18  Epoch: 276  Training loss = 4.7764  Validation loss = 1.1913  \n",
      "\n",
      "Fold: 18  Epoch: 277  Training loss = 4.7759  Validation loss = 1.1910  \n",
      "\n",
      "Fold: 18  Epoch: 278  Training loss = 4.7756  Validation loss = 1.1908  \n",
      "\n",
      "Fold: 18  Epoch: 279  Training loss = 4.7752  Validation loss = 1.1905  \n",
      "\n",
      "Fold: 18  Epoch: 280  Training loss = 4.7748  Validation loss = 1.1903  \n",
      "\n",
      "Fold: 18  Epoch: 281  Training loss = 4.7743  Validation loss = 1.1900  \n",
      "\n",
      "Fold: 18  Epoch: 282  Training loss = 4.7739  Validation loss = 1.1897  \n",
      "\n",
      "Fold: 18  Epoch: 283  Training loss = 4.7735  Validation loss = 1.1894  \n",
      "\n",
      "Fold: 18  Epoch: 284  Training loss = 4.7731  Validation loss = 1.1891  \n",
      "\n",
      "Fold: 18  Epoch: 285  Training loss = 4.7727  Validation loss = 1.1888  \n",
      "\n",
      "Fold: 18  Epoch: 286  Training loss = 4.7722  Validation loss = 1.1885  \n",
      "\n",
      "Fold: 18  Epoch: 287  Training loss = 4.7718  Validation loss = 1.1883  \n",
      "\n",
      "Fold: 18  Epoch: 288  Training loss = 4.7713  Validation loss = 1.1880  \n",
      "\n",
      "Fold: 18  Epoch: 289  Training loss = 4.7709  Validation loss = 1.1876  \n",
      "\n",
      "Fold: 18  Epoch: 290  Training loss = 4.7705  Validation loss = 1.1874  \n",
      "\n",
      "Fold: 18  Epoch: 291  Training loss = 4.7700  Validation loss = 1.1871  \n",
      "\n",
      "Fold: 18  Epoch: 292  Training loss = 4.7696  Validation loss = 1.1870  \n",
      "\n",
      "Fold: 18  Epoch: 293  Training loss = 4.7693  Validation loss = 1.1867  \n",
      "\n",
      "Fold: 18  Epoch: 294  Training loss = 4.7688  Validation loss = 1.1865  \n",
      "\n",
      "Fold: 18  Epoch: 295  Training loss = 4.7684  Validation loss = 1.1862  \n",
      "\n",
      "Fold: 18  Epoch: 296  Training loss = 4.7680  Validation loss = 1.1860  \n",
      "\n",
      "Fold: 18  Epoch: 297  Training loss = 4.7675  Validation loss = 1.1856  \n",
      "\n",
      "Fold: 18  Epoch: 298  Training loss = 4.7670  Validation loss = 1.1853  \n",
      "\n",
      "Fold: 18  Epoch: 299  Training loss = 4.7666  Validation loss = 1.1851  \n",
      "\n",
      "Fold: 18  Epoch: 300  Training loss = 4.7662  Validation loss = 1.1848  \n",
      "\n",
      "Fold: 18  Epoch: 301  Training loss = 4.7658  Validation loss = 1.1845  \n",
      "\n",
      "Fold: 18  Epoch: 302  Training loss = 4.7654  Validation loss = 1.1842  \n",
      "\n",
      "Fold: 18  Epoch: 303  Training loss = 4.7649  Validation loss = 1.1840  \n",
      "\n",
      "Fold: 18  Epoch: 304  Training loss = 4.7645  Validation loss = 1.1837  \n",
      "\n",
      "Fold: 18  Epoch: 305  Training loss = 4.7641  Validation loss = 1.1834  \n",
      "\n",
      "Fold: 18  Epoch: 306  Training loss = 4.7637  Validation loss = 1.1832  \n",
      "\n",
      "Fold: 18  Epoch: 307  Training loss = 4.7631  Validation loss = 1.1829  \n",
      "\n",
      "Fold: 18  Epoch: 308  Training loss = 4.7627  Validation loss = 1.1826  \n",
      "\n",
      "Fold: 18  Epoch: 309  Training loss = 4.7623  Validation loss = 1.1823  \n",
      "\n",
      "Fold: 18  Epoch: 310  Training loss = 4.7619  Validation loss = 1.1820  \n",
      "\n",
      "Fold: 18  Epoch: 311  Training loss = 4.7615  Validation loss = 1.1818  \n",
      "\n",
      "Fold: 18  Epoch: 312  Training loss = 4.7611  Validation loss = 1.1815  \n",
      "\n",
      "Fold: 18  Epoch: 313  Training loss = 4.7606  Validation loss = 1.1813  \n",
      "\n",
      "Fold: 18  Epoch: 314  Training loss = 4.7602  Validation loss = 1.1810  \n",
      "\n",
      "Fold: 18  Epoch: 315  Training loss = 4.7598  Validation loss = 1.1808  \n",
      "\n",
      "Fold: 18  Epoch: 316  Training loss = 4.7593  Validation loss = 1.1805  \n",
      "\n",
      "Fold: 18  Epoch: 317  Training loss = 4.7589  Validation loss = 1.1802  \n",
      "\n",
      "Fold: 18  Epoch: 318  Training loss = 4.7585  Validation loss = 1.1800  \n",
      "\n",
      "Fold: 18  Epoch: 319  Training loss = 4.7581  Validation loss = 1.1797  \n",
      "\n",
      "Fold: 18  Epoch: 320  Training loss = 4.7577  Validation loss = 1.1795  \n",
      "\n",
      "Fold: 18  Epoch: 321  Training loss = 4.7572  Validation loss = 1.1793  \n",
      "\n",
      "Fold: 18  Epoch: 322  Training loss = 4.7569  Validation loss = 1.1791  \n",
      "\n",
      "Fold: 18  Epoch: 323  Training loss = 4.7565  Validation loss = 1.1788  \n",
      "\n",
      "Fold: 18  Epoch: 324  Training loss = 4.7560  Validation loss = 1.1785  \n",
      "\n",
      "Fold: 18  Epoch: 325  Training loss = 4.7556  Validation loss = 1.1782  \n",
      "\n",
      "Fold: 18  Epoch: 326  Training loss = 4.7552  Validation loss = 1.1780  \n",
      "\n",
      "Fold: 18  Epoch: 327  Training loss = 4.7548  Validation loss = 1.1778  \n",
      "\n",
      "Fold: 18  Epoch: 328  Training loss = 4.7543  Validation loss = 1.1775  \n",
      "\n",
      "Fold: 18  Epoch: 329  Training loss = 4.7539  Validation loss = 1.1773  \n",
      "\n",
      "Fold: 18  Epoch: 330  Training loss = 4.7536  Validation loss = 1.1771  \n",
      "\n",
      "Fold: 18  Epoch: 331  Training loss = 4.7532  Validation loss = 1.1769  \n",
      "\n",
      "Fold: 18  Epoch: 332  Training loss = 4.7529  Validation loss = 1.1767  \n",
      "\n",
      "Fold: 18  Epoch: 333  Training loss = 4.7525  Validation loss = 1.1764  \n",
      "\n",
      "Fold: 18  Epoch: 334  Training loss = 4.7521  Validation loss = 1.1762  \n",
      "\n",
      "Fold: 18  Epoch: 335  Training loss = 4.7517  Validation loss = 1.1759  \n",
      "\n",
      "Fold: 18  Epoch: 336  Training loss = 4.7513  Validation loss = 1.1757  \n",
      "\n",
      "Fold: 18  Epoch: 337  Training loss = 4.7509  Validation loss = 1.1755  \n",
      "\n",
      "Fold: 18  Epoch: 338  Training loss = 4.7506  Validation loss = 1.1753  \n",
      "\n",
      "Fold: 18  Epoch: 339  Training loss = 4.7502  Validation loss = 1.1750  \n",
      "\n",
      "Fold: 18  Epoch: 340  Training loss = 4.7498  Validation loss = 1.1748  \n",
      "\n",
      "Fold: 18  Epoch: 341  Training loss = 4.7494  Validation loss = 1.1746  \n",
      "\n",
      "Fold: 18  Epoch: 342  Training loss = 4.7489  Validation loss = 1.1743  \n",
      "\n",
      "Fold: 18  Epoch: 343  Training loss = 4.7485  Validation loss = 1.1740  \n",
      "\n",
      "Fold: 18  Epoch: 344  Training loss = 4.7482  Validation loss = 1.1738  \n",
      "\n",
      "Fold: 18  Epoch: 345  Training loss = 4.7477  Validation loss = 1.1735  \n",
      "\n",
      "Fold: 18  Epoch: 346  Training loss = 4.7473  Validation loss = 1.1733  \n",
      "\n",
      "Fold: 18  Epoch: 347  Training loss = 4.7469  Validation loss = 1.1731  \n",
      "\n",
      "Fold: 18  Epoch: 348  Training loss = 4.7465  Validation loss = 1.1729  \n",
      "\n",
      "Fold: 18  Epoch: 349  Training loss = 4.7461  Validation loss = 1.1727  \n",
      "\n",
      "Fold: 18  Epoch: 350  Training loss = 4.7457  Validation loss = 1.1725  \n",
      "\n",
      "Fold: 18  Epoch: 351  Training loss = 4.7452  Validation loss = 1.1722  \n",
      "\n",
      "Fold: 18  Epoch: 352  Training loss = 4.7449  Validation loss = 1.1719  \n",
      "\n",
      "Fold: 18  Epoch: 353  Training loss = 4.7445  Validation loss = 1.1717  \n",
      "\n",
      "Fold: 18  Epoch: 354  Training loss = 4.7442  Validation loss = 1.1715  \n",
      "\n",
      "Fold: 18  Epoch: 355  Training loss = 4.7438  Validation loss = 1.1713  \n",
      "\n",
      "Fold: 18  Epoch: 356  Training loss = 4.7433  Validation loss = 1.1710  \n",
      "\n",
      "Fold: 18  Epoch: 357  Training loss = 4.7430  Validation loss = 1.1707  \n",
      "\n",
      "Fold: 18  Epoch: 358  Training loss = 4.7426  Validation loss = 1.1705  \n",
      "\n",
      "Fold: 18  Epoch: 359  Training loss = 4.7422  Validation loss = 1.1702  \n",
      "\n",
      "Fold: 18  Epoch: 360  Training loss = 4.7417  Validation loss = 1.1699  \n",
      "\n",
      "Fold: 18  Epoch: 361  Training loss = 4.7413  Validation loss = 1.1697  \n",
      "\n",
      "Fold: 18  Epoch: 362  Training loss = 4.7409  Validation loss = 1.1694  \n",
      "\n",
      "Fold: 18  Epoch: 363  Training loss = 4.7405  Validation loss = 1.1692  \n",
      "\n",
      "Fold: 18  Epoch: 364  Training loss = 4.7401  Validation loss = 1.1689  \n",
      "\n",
      "Fold: 18  Epoch: 365  Training loss = 4.7397  Validation loss = 1.1687  \n",
      "\n",
      "Fold: 18  Epoch: 366  Training loss = 4.7393  Validation loss = 1.1684  \n",
      "\n",
      "Fold: 18  Epoch: 367  Training loss = 4.7389  Validation loss = 1.1682  \n",
      "\n",
      "Fold: 18  Epoch: 368  Training loss = 4.7386  Validation loss = 1.1681  \n",
      "\n",
      "Fold: 18  Epoch: 369  Training loss = 4.7381  Validation loss = 1.1679  \n",
      "\n",
      "Fold: 18  Epoch: 370  Training loss = 4.7376  Validation loss = 1.1676  \n",
      "\n",
      "Fold: 18  Epoch: 371  Training loss = 4.7372  Validation loss = 1.1674  \n",
      "\n",
      "Fold: 18  Epoch: 372  Training loss = 4.7369  Validation loss = 1.1672  \n",
      "\n",
      "Fold: 18  Epoch: 373  Training loss = 4.7363  Validation loss = 1.1669  \n",
      "\n",
      "Fold: 18  Epoch: 374  Training loss = 4.7359  Validation loss = 1.1666  \n",
      "\n",
      "Fold: 18  Epoch: 375  Training loss = 4.7355  Validation loss = 1.1664  \n",
      "\n",
      "Fold: 18  Epoch: 376  Training loss = 4.7350  Validation loss = 1.1662  \n",
      "\n",
      "Fold: 18  Epoch: 377  Training loss = 4.7346  Validation loss = 1.1659  \n",
      "\n",
      "Fold: 18  Epoch: 378  Training loss = 4.7342  Validation loss = 1.1657  \n",
      "\n",
      "Fold: 18  Epoch: 379  Training loss = 4.7338  Validation loss = 1.1655  \n",
      "\n",
      "Fold: 18  Epoch: 380  Training loss = 4.7334  Validation loss = 1.1653  \n",
      "\n",
      "Fold: 18  Epoch: 381  Training loss = 4.7330  Validation loss = 1.1651  \n",
      "\n",
      "Fold: 18  Epoch: 382  Training loss = 4.7325  Validation loss = 1.1648  \n",
      "\n",
      "Fold: 18  Epoch: 383  Training loss = 4.7322  Validation loss = 1.1646  \n",
      "\n",
      "Fold: 18  Epoch: 384  Training loss = 4.7318  Validation loss = 1.1643  \n",
      "\n",
      "Fold: 18  Epoch: 385  Training loss = 4.7315  Validation loss = 1.1641  \n",
      "\n",
      "Fold: 18  Epoch: 386  Training loss = 4.7310  Validation loss = 1.1639  \n",
      "\n",
      "Fold: 18  Epoch: 387  Training loss = 4.7306  Validation loss = 1.1637  \n",
      "\n",
      "Fold: 18  Epoch: 388  Training loss = 4.7302  Validation loss = 1.1634  \n",
      "\n",
      "Fold: 18  Epoch: 389  Training loss = 4.7297  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 18  Epoch: 390  Training loss = 4.7292  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 18  Epoch: 391  Training loss = 4.7289  Validation loss = 1.1626  \n",
      "\n",
      "Fold: 18  Epoch: 392  Training loss = 4.7285  Validation loss = 1.1623  \n",
      "\n",
      "Fold: 18  Epoch: 393  Training loss = 4.7280  Validation loss = 1.1621  \n",
      "\n",
      "Fold: 18  Epoch: 394  Training loss = 4.7275  Validation loss = 1.1618  \n",
      "\n",
      "Fold: 18  Epoch: 395  Training loss = 4.7271  Validation loss = 1.1616  \n",
      "\n",
      "Fold: 18  Epoch: 396  Training loss = 4.7268  Validation loss = 1.1615  \n",
      "\n",
      "Fold: 18  Epoch: 397  Training loss = 4.7264  Validation loss = 1.1613  \n",
      "\n",
      "Fold: 18  Epoch: 398  Training loss = 4.7260  Validation loss = 1.1610  \n",
      "\n",
      "Fold: 18  Epoch: 399  Training loss = 4.7256  Validation loss = 1.1608  \n",
      "\n",
      "Fold: 18  Epoch: 400  Training loss = 4.7250  Validation loss = 1.1605  \n",
      "\n",
      "Fold: 18  Epoch: 401  Training loss = 4.7245  Validation loss = 1.1602  \n",
      "\n",
      "Fold: 18  Epoch: 402  Training loss = 4.7242  Validation loss = 1.1601  \n",
      "\n",
      "Fold: 18  Epoch: 403  Training loss = 4.7238  Validation loss = 1.1599  \n",
      "\n",
      "Fold: 18  Epoch: 404  Training loss = 4.7234  Validation loss = 1.1596  \n",
      "\n",
      "Fold: 18  Epoch: 405  Training loss = 4.7230  Validation loss = 1.1594  \n",
      "\n",
      "Fold: 18  Epoch: 406  Training loss = 4.7226  Validation loss = 1.1592  \n",
      "\n",
      "Fold: 18  Epoch: 407  Training loss = 4.7222  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 18  Epoch: 408  Training loss = 4.7216  Validation loss = 1.1587  \n",
      "\n",
      "Fold: 18  Epoch: 409  Training loss = 4.7212  Validation loss = 1.1585  \n",
      "\n",
      "Fold: 18  Epoch: 410  Training loss = 4.7208  Validation loss = 1.1582  \n",
      "\n",
      "Fold: 18  Epoch: 411  Training loss = 4.7204  Validation loss = 1.1579  \n",
      "\n",
      "Fold: 18  Epoch: 412  Training loss = 4.7200  Validation loss = 1.1577  \n",
      "\n",
      "Fold: 18  Epoch: 413  Training loss = 4.7197  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 18  Epoch: 414  Training loss = 4.7193  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 18  Epoch: 415  Training loss = 4.7189  Validation loss = 1.1572  \n",
      "\n",
      "Fold: 18  Epoch: 416  Training loss = 4.7185  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 18  Epoch: 417  Training loss = 4.7181  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 18  Epoch: 418  Training loss = 4.7177  Validation loss = 1.1565  \n",
      "\n",
      "Fold: 18  Epoch: 419  Training loss = 4.7174  Validation loss = 1.1563  \n",
      "\n",
      "Fold: 18  Epoch: 420  Training loss = 4.7170  Validation loss = 1.1561  \n",
      "\n",
      "Fold: 18  Epoch: 421  Training loss = 4.7166  Validation loss = 1.1559  \n",
      "\n",
      "Fold: 18  Epoch: 422  Training loss = 4.7162  Validation loss = 1.1557  \n",
      "\n",
      "Fold: 18  Epoch: 423  Training loss = 4.7158  Validation loss = 1.1555  \n",
      "\n",
      "Fold: 18  Epoch: 424  Training loss = 4.7155  Validation loss = 1.1554  \n",
      "\n",
      "Fold: 18  Epoch: 425  Training loss = 4.7150  Validation loss = 1.1552  \n",
      "\n",
      "Fold: 18  Epoch: 426  Training loss = 4.7146  Validation loss = 1.1550  \n",
      "\n",
      "Fold: 18  Epoch: 427  Training loss = 4.7141  Validation loss = 1.1548  \n",
      "\n",
      "Fold: 18  Epoch: 428  Training loss = 4.7135  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 18  Epoch: 429  Training loss = 4.7130  Validation loss = 1.1542  \n",
      "\n",
      "Fold: 18  Epoch: 430  Training loss = 4.7126  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 18  Epoch: 431  Training loss = 4.7122  Validation loss = 1.1538  \n",
      "\n",
      "Fold: 18  Epoch: 432  Training loss = 4.7117  Validation loss = 1.1536  \n",
      "\n",
      "Fold: 18  Epoch: 433  Training loss = 4.7114  Validation loss = 1.1534  \n",
      "\n",
      "Fold: 18  Epoch: 434  Training loss = 4.7110  Validation loss = 1.1531  \n",
      "\n",
      "Fold: 18  Epoch: 435  Training loss = 4.7106  Validation loss = 1.1529  \n",
      "\n",
      "Fold: 18  Epoch: 436  Training loss = 4.7103  Validation loss = 1.1528  \n",
      "\n",
      "Fold: 18  Epoch: 437  Training loss = 4.7099  Validation loss = 1.1526  \n",
      "\n",
      "Fold: 18  Epoch: 438  Training loss = 4.7095  Validation loss = 1.1524  \n",
      "\n",
      "Fold: 18  Epoch: 439  Training loss = 4.7090  Validation loss = 1.1522  \n",
      "\n",
      "Fold: 18  Epoch: 440  Training loss = 4.7087  Validation loss = 1.1520  \n",
      "\n",
      "Fold: 18  Epoch: 441  Training loss = 4.7083  Validation loss = 1.1518  \n",
      "\n",
      "Fold: 18  Epoch: 442  Training loss = 4.7078  Validation loss = 1.1516  \n",
      "\n",
      "Fold: 18  Epoch: 443  Training loss = 4.7073  Validation loss = 1.1514  \n",
      "\n",
      "Fold: 18  Epoch: 444  Training loss = 4.7069  Validation loss = 1.1512  \n",
      "\n",
      "Fold: 18  Epoch: 445  Training loss = 4.7065  Validation loss = 1.1510  \n",
      "\n",
      "Fold: 18  Epoch: 446  Training loss = 4.7061  Validation loss = 1.1509  \n",
      "\n",
      "Fold: 18  Epoch: 447  Training loss = 4.7058  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 18  Epoch: 448  Training loss = 4.7054  Validation loss = 1.1505  \n",
      "\n",
      "Fold: 18  Epoch: 449  Training loss = 4.7051  Validation loss = 1.1503  \n",
      "\n",
      "Fold: 18  Epoch: 450  Training loss = 4.7047  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 18  Epoch: 451  Training loss = 4.7043  Validation loss = 1.1500  \n",
      "\n",
      "Fold: 18  Epoch: 452  Training loss = 4.7038  Validation loss = 1.1498  \n",
      "\n",
      "Fold: 18  Epoch: 453  Training loss = 4.7034  Validation loss = 1.1496  \n",
      "\n",
      "Fold: 18  Epoch: 454  Training loss = 4.7029  Validation loss = 1.1494  \n",
      "\n",
      "Fold: 18  Epoch: 455  Training loss = 4.7025  Validation loss = 1.1492  \n",
      "\n",
      "Fold: 18  Epoch: 456  Training loss = 4.7021  Validation loss = 1.1489  \n",
      "\n",
      "Fold: 18  Epoch: 457  Training loss = 4.7016  Validation loss = 1.1487  \n",
      "\n",
      "Fold: 18  Epoch: 458  Training loss = 4.7011  Validation loss = 1.1485  \n",
      "\n",
      "Fold: 18  Epoch: 459  Training loss = 4.7006  Validation loss = 1.1483  \n",
      "\n",
      "Fold: 18  Epoch: 460  Training loss = 4.7001  Validation loss = 1.1481  \n",
      "\n",
      "Fold: 18  Epoch: 461  Training loss = 4.6998  Validation loss = 1.1479  \n",
      "\n",
      "Fold: 18  Epoch: 462  Training loss = 4.6993  Validation loss = 1.1477  \n",
      "\n",
      "Fold: 18  Epoch: 463  Training loss = 4.6989  Validation loss = 1.1475  \n",
      "\n",
      "Fold: 18  Epoch: 464  Training loss = 4.6986  Validation loss = 1.1474  \n",
      "\n",
      "Fold: 18  Epoch: 465  Training loss = 4.6982  Validation loss = 1.1472  \n",
      "\n",
      "Fold: 18  Epoch: 466  Training loss = 4.6978  Validation loss = 1.1470  \n",
      "\n",
      "Fold: 18  Epoch: 467  Training loss = 4.6973  Validation loss = 1.1469  \n",
      "\n",
      "Fold: 18  Epoch: 468  Training loss = 4.6970  Validation loss = 1.1467  \n",
      "\n",
      "Fold: 18  Epoch: 469  Training loss = 4.6965  Validation loss = 1.1465  \n",
      "\n",
      "Fold: 18  Epoch: 470  Training loss = 4.6961  Validation loss = 1.1463  \n",
      "\n",
      "Fold: 18  Epoch: 471  Training loss = 4.6958  Validation loss = 1.1462  \n",
      "\n",
      "Fold: 18  Epoch: 472  Training loss = 4.6954  Validation loss = 1.1460  \n",
      "\n",
      "Fold: 18  Epoch: 473  Training loss = 4.6950  Validation loss = 1.1458  \n",
      "\n",
      "Fold: 18  Epoch: 474  Training loss = 4.6946  Validation loss = 1.1456  \n",
      "\n",
      "Fold: 18  Epoch: 475  Training loss = 4.6941  Validation loss = 1.1453  \n",
      "\n",
      "Fold: 18  Epoch: 476  Training loss = 4.6938  Validation loss = 1.1452  \n",
      "\n",
      "Fold: 18  Epoch: 477  Training loss = 4.6934  Validation loss = 1.1450  \n",
      "\n",
      "Fold: 18  Epoch: 478  Training loss = 4.6931  Validation loss = 1.1448  \n",
      "\n",
      "Fold: 18  Epoch: 479  Training loss = 4.6925  Validation loss = 1.1446  \n",
      "\n",
      "Fold: 18  Epoch: 480  Training loss = 4.6921  Validation loss = 1.1444  \n",
      "\n",
      "Fold: 18  Epoch: 481  Training loss = 4.6916  Validation loss = 1.1442  \n",
      "\n",
      "Fold: 18  Epoch: 482  Training loss = 4.6912  Validation loss = 1.1441  \n",
      "\n",
      "Fold: 18  Epoch: 483  Training loss = 4.6908  Validation loss = 1.1439  \n",
      "\n",
      "Fold: 18  Epoch: 484  Training loss = 4.6904  Validation loss = 1.1437  \n",
      "\n",
      "Fold: 18  Epoch: 485  Training loss = 4.6901  Validation loss = 1.1435  \n",
      "\n",
      "Fold: 18  Epoch: 486  Training loss = 4.6896  Validation loss = 1.1433  \n",
      "\n",
      "Fold: 18  Epoch: 487  Training loss = 4.6892  Validation loss = 1.1430  \n",
      "\n",
      "Fold: 18  Epoch: 488  Training loss = 4.6888  Validation loss = 1.1429  \n",
      "\n",
      "Fold: 18  Epoch: 489  Training loss = 4.6884  Validation loss = 1.1427  \n",
      "\n",
      "Fold: 18  Epoch: 490  Training loss = 4.6880  Validation loss = 1.1426  \n",
      "\n",
      "Fold: 18  Epoch: 491  Training loss = 4.6876  Validation loss = 1.1424  \n",
      "\n",
      "Fold: 18  Epoch: 492  Training loss = 4.6872  Validation loss = 1.1422  \n",
      "\n",
      "Fold: 18  Epoch: 493  Training loss = 4.6867  Validation loss = 1.1420  \n",
      "\n",
      "Fold: 18  Epoch: 494  Training loss = 4.6862  Validation loss = 1.1418  \n",
      "\n",
      "Fold: 18  Epoch: 495  Training loss = 4.6857  Validation loss = 1.1416  \n",
      "\n",
      "Fold: 18  Epoch: 496  Training loss = 4.6853  Validation loss = 1.1414  \n",
      "\n",
      "Fold: 18  Epoch: 497  Training loss = 4.6848  Validation loss = 1.1412  \n",
      "\n",
      "Fold: 18  Epoch: 498  Training loss = 4.6845  Validation loss = 1.1410  \n",
      "\n",
      "Fold: 18  Epoch: 499  Training loss = 4.6841  Validation loss = 1.1409  \n",
      "\n",
      "Fold: 18  Epoch: 500  Training loss = 4.6836  Validation loss = 1.1407  \n",
      "\n",
      "Fold: 18  Epoch: 501  Training loss = 4.6832  Validation loss = 1.1405  \n",
      "\n",
      "Fold: 18  Epoch: 502  Training loss = 4.6827  Validation loss = 1.1404  \n",
      "\n",
      "Fold: 18  Epoch: 503  Training loss = 4.6823  Validation loss = 1.1402  \n",
      "\n",
      "Fold: 18  Epoch: 504  Training loss = 4.6819  Validation loss = 1.1400  \n",
      "\n",
      "Fold: 18  Epoch: 505  Training loss = 4.6814  Validation loss = 1.1397  \n",
      "\n",
      "Fold: 18  Epoch: 506  Training loss = 4.6810  Validation loss = 1.1395  \n",
      "\n",
      "Fold: 18  Epoch: 507  Training loss = 4.6805  Validation loss = 1.1393  \n",
      "\n",
      "Fold: 18  Epoch: 508  Training loss = 4.6800  Validation loss = 1.1391  \n",
      "\n",
      "Fold: 18  Epoch: 509  Training loss = 4.6796  Validation loss = 1.1388  \n",
      "\n",
      "Fold: 18  Epoch: 510  Training loss = 4.6792  Validation loss = 1.1387  \n",
      "\n",
      "Fold: 18  Epoch: 511  Training loss = 4.6788  Validation loss = 1.1385  \n",
      "\n",
      "Fold: 18  Epoch: 512  Training loss = 4.6782  Validation loss = 1.1382  \n",
      "\n",
      "Fold: 18  Epoch: 513  Training loss = 4.6778  Validation loss = 1.1380  \n",
      "\n",
      "Fold: 18  Epoch: 514  Training loss = 4.6774  Validation loss = 1.1379  \n",
      "\n",
      "Fold: 18  Epoch: 515  Training loss = 4.6767  Validation loss = 1.1375  \n",
      "\n",
      "Fold: 18  Epoch: 516  Training loss = 4.6763  Validation loss = 1.1372  \n",
      "\n",
      "Fold: 18  Epoch: 517  Training loss = 4.6759  Validation loss = 1.1371  \n",
      "\n",
      "Fold: 18  Epoch: 518  Training loss = 4.6752  Validation loss = 1.1366  \n",
      "\n",
      "Fold: 18  Epoch: 519  Training loss = 4.6747  Validation loss = 1.1364  \n",
      "\n",
      "Fold: 18  Epoch: 520  Training loss = 4.6740  Validation loss = 1.1360  \n",
      "\n",
      "Fold: 18  Epoch: 521  Training loss = 4.6731  Validation loss = 1.1356  \n",
      "\n",
      "Fold: 18  Epoch: 522  Training loss = 4.6727  Validation loss = 1.1355  \n",
      "\n",
      "Fold: 18  Epoch: 523  Training loss = 4.6725  Validation loss = 1.1354  \n",
      "\n",
      "Fold: 18  Epoch: 524  Training loss = 4.6709  Validation loss = 1.1347  \n",
      "\n",
      "Fold: 18  Epoch: 525  Training loss = 4.6678  Validation loss = 1.1337  \n",
      "\n",
      "Fold: 18  Epoch: 526  Training loss = 4.6656  Validation loss = 1.1324  \n",
      "\n",
      "Fold: 18  Epoch: 527  Training loss = 4.6650  Validation loss = 1.1320  \n",
      "\n",
      "Fold: 18  Epoch: 528  Training loss = 4.6647  Validation loss = 1.1319  \n",
      "\n",
      "Fold: 18  Epoch: 529  Training loss = 4.6643  Validation loss = 1.1318  \n",
      "\n",
      "Fold: 18  Epoch: 530  Training loss = 4.6638  Validation loss = 1.1315  \n",
      "\n",
      "Fold: 18  Epoch: 531  Training loss = 4.6634  Validation loss = 1.1313  \n",
      "\n",
      "Fold: 18  Epoch: 532  Training loss = 4.6630  Validation loss = 1.1311  \n",
      "\n",
      "Fold: 18  Epoch: 533  Training loss = 4.6626  Validation loss = 1.1309  \n",
      "\n",
      "Fold: 18  Epoch: 534  Training loss = 4.6621  Validation loss = 1.1307  \n",
      "\n",
      "Fold: 18  Epoch: 535  Training loss = 4.6617  Validation loss = 1.1305  \n",
      "\n",
      "Fold: 18  Epoch: 536  Training loss = 4.6613  Validation loss = 1.1303  \n",
      "\n",
      "Fold: 18  Epoch: 537  Training loss = 4.6609  Validation loss = 1.1301  \n",
      "\n",
      "Fold: 18  Epoch: 538  Training loss = 4.6604  Validation loss = 1.1299  \n",
      "\n",
      "Fold: 18  Epoch: 539  Training loss = 4.6599  Validation loss = 1.1297  \n",
      "\n",
      "Fold: 18  Epoch: 540  Training loss = 4.6595  Validation loss = 1.1296  \n",
      "\n",
      "Fold: 18  Epoch: 541  Training loss = 4.6591  Validation loss = 1.1294  \n",
      "\n",
      "Fold: 18  Epoch: 542  Training loss = 4.6587  Validation loss = 1.1292  \n",
      "\n",
      "Fold: 18  Epoch: 543  Training loss = 4.6583  Validation loss = 1.1291  \n",
      "\n",
      "Fold: 18  Epoch: 544  Training loss = 4.6579  Validation loss = 1.1289  \n",
      "\n",
      "Fold: 18  Epoch: 545  Training loss = 4.6575  Validation loss = 1.1287  \n",
      "\n",
      "Fold: 18  Epoch: 546  Training loss = 4.6570  Validation loss = 1.1285  \n",
      "\n",
      "Fold: 18  Epoch: 547  Training loss = 4.6565  Validation loss = 1.1283  \n",
      "\n",
      "Fold: 18  Epoch: 548  Training loss = 4.6561  Validation loss = 1.1281  \n",
      "\n",
      "Fold: 18  Epoch: 549  Training loss = 4.6556  Validation loss = 1.1280  \n",
      "\n",
      "Fold: 18  Epoch: 550  Training loss = 4.6552  Validation loss = 1.1278  \n",
      "\n",
      "Fold: 18  Epoch: 551  Training loss = 4.6549  Validation loss = 1.1277  \n",
      "\n",
      "Fold: 18  Epoch: 552  Training loss = 4.6544  Validation loss = 1.1275  \n",
      "\n",
      "Fold: 18  Epoch: 553  Training loss = 4.6539  Validation loss = 1.1273  \n",
      "\n",
      "Fold: 18  Epoch: 554  Training loss = 4.6535  Validation loss = 1.1271  \n",
      "\n",
      "Fold: 18  Epoch: 555  Training loss = 4.6531  Validation loss = 1.1270  \n",
      "\n",
      "Fold: 18  Epoch: 556  Training loss = 4.6526  Validation loss = 1.1268  \n",
      "\n",
      "Fold: 18  Epoch: 557  Training loss = 4.6522  Validation loss = 1.1266  \n",
      "\n",
      "Fold: 18  Epoch: 558  Training loss = 4.6518  Validation loss = 1.1265  \n",
      "\n",
      "Fold: 18  Epoch: 559  Training loss = 4.6514  Validation loss = 1.1263  \n",
      "\n",
      "Fold: 18  Epoch: 560  Training loss = 4.6510  Validation loss = 1.1262  \n",
      "\n",
      "Fold: 18  Epoch: 561  Training loss = 4.6506  Validation loss = 1.1260  \n",
      "\n",
      "Fold: 18  Epoch: 562  Training loss = 4.6502  Validation loss = 1.1259  \n",
      "\n",
      "Fold: 18  Epoch: 563  Training loss = 4.6499  Validation loss = 1.1257  \n",
      "\n",
      "Fold: 18  Epoch: 564  Training loss = 4.6495  Validation loss = 1.1256  \n",
      "\n",
      "Fold: 18  Epoch: 565  Training loss = 4.6492  Validation loss = 1.1254  \n",
      "\n",
      "Fold: 18  Epoch: 566  Training loss = 4.6489  Validation loss = 1.1253  \n",
      "\n",
      "Fold: 18  Epoch: 567  Training loss = 4.6483  Validation loss = 1.1251  \n",
      "\n",
      "Fold: 18  Epoch: 568  Training loss = 4.6479  Validation loss = 1.1250  \n",
      "\n",
      "Fold: 18  Epoch: 569  Training loss = 4.6473  Validation loss = 1.1248  \n",
      "\n",
      "Fold: 18  Epoch: 570  Training loss = 4.6468  Validation loss = 1.1245  \n",
      "\n",
      "Fold: 18  Epoch: 571  Training loss = 4.6463  Validation loss = 1.1244  \n",
      "\n",
      "Fold: 18  Epoch: 572  Training loss = 4.6460  Validation loss = 1.1242  \n",
      "\n",
      "Fold: 18  Epoch: 573  Training loss = 4.6455  Validation loss = 1.1241  \n",
      "\n",
      "Fold: 18  Epoch: 574  Training loss = 4.6450  Validation loss = 1.1239  \n",
      "\n",
      "Fold: 18  Epoch: 575  Training loss = 4.6445  Validation loss = 1.1237  \n",
      "\n",
      "Fold: 18  Epoch: 576  Training loss = 4.6441  Validation loss = 1.1236  \n",
      "\n",
      "Fold: 18  Epoch: 577  Training loss = 4.6436  Validation loss = 1.1234  \n",
      "\n",
      "Fold: 18  Epoch: 578  Training loss = 4.6431  Validation loss = 1.1233  \n",
      "\n",
      "Fold: 18  Epoch: 579  Training loss = 4.6428  Validation loss = 1.1231  \n",
      "\n",
      "Fold: 18  Epoch: 580  Training loss = 4.6423  Validation loss = 1.1230  \n",
      "\n",
      "Fold: 18  Epoch: 581  Training loss = 4.6419  Validation loss = 1.1228  \n",
      "\n",
      "Fold: 18  Epoch: 582  Training loss = 4.6414  Validation loss = 1.1226  \n",
      "\n",
      "Fold: 18  Epoch: 583  Training loss = 4.6409  Validation loss = 1.1225  \n",
      "\n",
      "Fold: 18  Epoch: 584  Training loss = 4.6404  Validation loss = 1.1223  \n",
      "\n",
      "Fold: 18  Epoch: 585  Training loss = 4.6400  Validation loss = 1.1222  \n",
      "\n",
      "Fold: 18  Epoch: 586  Training loss = 4.6397  Validation loss = 1.1220  \n",
      "\n",
      "Fold: 18  Epoch: 587  Training loss = 4.6393  Validation loss = 1.1219  \n",
      "\n",
      "Fold: 18  Epoch: 588  Training loss = 4.6388  Validation loss = 1.1217  \n",
      "\n",
      "Fold: 18  Epoch: 589  Training loss = 4.6384  Validation loss = 1.1215  \n",
      "\n",
      "Fold: 18  Epoch: 590  Training loss = 4.6380  Validation loss = 1.1214  \n",
      "\n",
      "Fold: 18  Epoch: 591  Training loss = 4.6376  Validation loss = 1.1212  \n",
      "\n",
      "Fold: 18  Epoch: 592  Training loss = 4.6373  Validation loss = 1.1211  \n",
      "\n",
      "Fold: 18  Epoch: 593  Training loss = 4.6369  Validation loss = 1.1209  \n",
      "\n",
      "Fold: 18  Epoch: 594  Training loss = 4.6365  Validation loss = 1.1208  \n",
      "\n",
      "Fold: 18  Epoch: 595  Training loss = 4.6361  Validation loss = 1.1206  \n",
      "\n",
      "Fold: 18  Epoch: 596  Training loss = 4.6357  Validation loss = 1.1205  \n",
      "\n",
      "Fold: 18  Epoch: 597  Training loss = 4.6353  Validation loss = 1.1203  \n",
      "\n",
      "Fold: 18  Epoch: 598  Training loss = 4.6349  Validation loss = 1.1202  \n",
      "\n",
      "Fold: 18  Epoch: 599  Training loss = 4.6345  Validation loss = 1.1200  \n",
      "\n",
      "Fold: 18  Epoch: 600  Training loss = 4.6341  Validation loss = 1.1198  \n",
      "\n",
      "Fold: 18  Epoch: 601  Training loss = 4.6336  Validation loss = 1.1197  \n",
      "\n",
      "Fold: 18  Epoch: 602  Training loss = 4.6329  Validation loss = 1.1195  \n",
      "\n",
      "Fold: 18  Epoch: 603  Training loss = 4.6324  Validation loss = 1.1193  \n",
      "\n",
      "Fold: 18  Epoch: 604  Training loss = 4.6319  Validation loss = 1.1191  \n",
      "\n",
      "Fold: 18  Epoch: 605  Training loss = 4.6315  Validation loss = 1.1190  \n",
      "\n",
      "Fold: 18  Epoch: 606  Training loss = 4.6311  Validation loss = 1.1189  \n",
      "\n",
      "Fold: 18  Epoch: 607  Training loss = 4.6307  Validation loss = 1.1187  \n",
      "\n",
      "Fold: 18  Epoch: 608  Training loss = 4.6302  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 18  Epoch: 609  Training loss = 4.6297  Validation loss = 1.1184  \n",
      "\n",
      "Fold: 18  Epoch: 610  Training loss = 4.6292  Validation loss = 1.1182  \n",
      "\n",
      "Fold: 18  Epoch: 611  Training loss = 4.6287  Validation loss = 1.1180  \n",
      "\n",
      "Fold: 18  Epoch: 612  Training loss = 4.6282  Validation loss = 1.1178  \n",
      "\n",
      "Fold: 18  Epoch: 613  Training loss = 4.6276  Validation loss = 1.1176  \n",
      "\n",
      "Fold: 18  Epoch: 614  Training loss = 4.6271  Validation loss = 1.1175  \n",
      "\n",
      "Fold: 18  Epoch: 615  Training loss = 4.6268  Validation loss = 1.1174  \n",
      "\n",
      "Fold: 18  Epoch: 616  Training loss = 4.6264  Validation loss = 1.1172  \n",
      "\n",
      "Fold: 18  Epoch: 617  Training loss = 4.6260  Validation loss = 1.1170  \n",
      "\n",
      "Fold: 18  Epoch: 618  Training loss = 4.6256  Validation loss = 1.1169  \n",
      "\n",
      "Fold: 18  Epoch: 619  Training loss = 4.6251  Validation loss = 1.1167  \n",
      "\n",
      "Fold: 18  Epoch: 620  Training loss = 4.6246  Validation loss = 1.1166  \n",
      "\n",
      "Fold: 18  Epoch: 621  Training loss = 4.6243  Validation loss = 1.1165  \n",
      "\n",
      "Fold: 18  Epoch: 622  Training loss = 4.6238  Validation loss = 1.1163  \n",
      "\n",
      "Fold: 18  Epoch: 623  Training loss = 4.6233  Validation loss = 1.1161  \n",
      "\n",
      "Fold: 18  Epoch: 624  Training loss = 4.6229  Validation loss = 1.1160  \n",
      "\n",
      "Fold: 18  Epoch: 625  Training loss = 4.6224  Validation loss = 1.1158  \n",
      "\n",
      "Fold: 18  Epoch: 626  Training loss = 4.6221  Validation loss = 1.1156  \n",
      "\n",
      "Fold: 18  Epoch: 627  Training loss = 4.6217  Validation loss = 1.1155  \n",
      "\n",
      "Fold: 18  Epoch: 628  Training loss = 4.6212  Validation loss = 1.1153  \n",
      "\n",
      "Fold: 18  Epoch: 629  Training loss = 4.6207  Validation loss = 1.1151  \n",
      "\n",
      "Fold: 18  Epoch: 630  Training loss = 4.6203  Validation loss = 1.1150  \n",
      "\n",
      "Fold: 18  Epoch: 631  Training loss = 4.6198  Validation loss = 1.1148  \n",
      "\n",
      "Fold: 18  Epoch: 632  Training loss = 4.6191  Validation loss = 1.1146  \n",
      "\n",
      "Fold: 18  Epoch: 633  Training loss = 4.6188  Validation loss = 1.1145  \n",
      "\n",
      "Fold: 18  Epoch: 634  Training loss = 4.6183  Validation loss = 1.1144  \n",
      "\n",
      "Fold: 18  Epoch: 635  Training loss = 4.6178  Validation loss = 1.1142  \n",
      "\n",
      "Fold: 18  Epoch: 636  Training loss = 4.6175  Validation loss = 1.1141  \n",
      "\n",
      "Fold: 18  Epoch: 637  Training loss = 4.6171  Validation loss = 1.1139  \n",
      "\n",
      "Fold: 18  Epoch: 638  Training loss = 4.6167  Validation loss = 1.1138  \n",
      "\n",
      "Fold: 18  Epoch: 639  Training loss = 4.6163  Validation loss = 1.1137  \n",
      "\n",
      "Fold: 18  Epoch: 640  Training loss = 4.6159  Validation loss = 1.1135  \n",
      "\n",
      "Fold: 18  Epoch: 641  Training loss = 4.6155  Validation loss = 1.1134  \n",
      "\n",
      "Fold: 18  Epoch: 642  Training loss = 4.6151  Validation loss = 1.1133  \n",
      "\n",
      "Fold: 18  Epoch: 643  Training loss = 4.6147  Validation loss = 1.1131  \n",
      "\n",
      "Fold: 18  Epoch: 644  Training loss = 4.6144  Validation loss = 1.1130  \n",
      "\n",
      "Fold: 18  Epoch: 645  Training loss = 4.6140  Validation loss = 1.1128  \n",
      "\n",
      "Fold: 18  Epoch: 646  Training loss = 4.6136  Validation loss = 1.1127  \n",
      "\n",
      "Fold: 18  Epoch: 647  Training loss = 4.6132  Validation loss = 1.1125  \n",
      "\n",
      "Fold: 18  Epoch: 648  Training loss = 4.6128  Validation loss = 1.1124  \n",
      "\n",
      "Fold: 18  Epoch: 649  Training loss = 4.6125  Validation loss = 1.1122  \n",
      "\n",
      "Fold: 18  Epoch: 650  Training loss = 4.6121  Validation loss = 1.1121  \n",
      "\n",
      "Fold: 18  Epoch: 651  Training loss = 4.6117  Validation loss = 1.1119  \n",
      "\n",
      "Fold: 18  Epoch: 652  Training loss = 4.6111  Validation loss = 1.1117  \n",
      "\n",
      "Fold: 18  Epoch: 653  Training loss = 4.6107  Validation loss = 1.1115  \n",
      "\n",
      "Fold: 18  Epoch: 654  Training loss = 4.6102  Validation loss = 1.1114  \n",
      "\n",
      "Fold: 18  Epoch: 655  Training loss = 4.6099  Validation loss = 1.1113  \n",
      "\n",
      "Fold: 18  Epoch: 656  Training loss = 4.6095  Validation loss = 1.1111  \n",
      "\n",
      "Fold: 18  Epoch: 657  Training loss = 4.6091  Validation loss = 1.1109  \n",
      "\n",
      "Fold: 18  Epoch: 658  Training loss = 4.6087  Validation loss = 1.1108  \n",
      "\n",
      "Fold: 18  Epoch: 659  Training loss = 4.6082  Validation loss = 1.1106  \n",
      "\n",
      "Fold: 18  Epoch: 660  Training loss = 4.6077  Validation loss = 1.1104  \n",
      "\n",
      "Fold: 18  Epoch: 661  Training loss = 4.6072  Validation loss = 1.1103  \n",
      "\n",
      "Fold: 18  Epoch: 662  Training loss = 4.6068  Validation loss = 1.1101  \n",
      "\n",
      "Fold: 18  Epoch: 663  Training loss = 4.6065  Validation loss = 1.1100  \n",
      "\n",
      "Fold: 18  Epoch: 664  Training loss = 4.6060  Validation loss = 1.1098  \n",
      "\n",
      "Fold: 18  Epoch: 665  Training loss = 4.6057  Validation loss = 1.1097  \n",
      "\n",
      "Fold: 18  Epoch: 666  Training loss = 4.6053  Validation loss = 1.1095  \n",
      "\n",
      "Fold: 18  Epoch: 667  Training loss = 4.6047  Validation loss = 1.1093  \n",
      "\n",
      "Fold: 18  Epoch: 668  Training loss = 4.6044  Validation loss = 1.1092  \n",
      "\n",
      "Fold: 18  Epoch: 669  Training loss = 4.6040  Validation loss = 1.1090  \n",
      "\n",
      "Fold: 18  Epoch: 670  Training loss = 4.6035  Validation loss = 1.1089  \n",
      "\n",
      "Fold: 18  Epoch: 671  Training loss = 4.6031  Validation loss = 1.1087  \n",
      "\n",
      "Fold: 18  Epoch: 672  Training loss = 4.6027  Validation loss = 1.1086  \n",
      "\n",
      "Fold: 18  Epoch: 673  Training loss = 4.6024  Validation loss = 1.1085  \n",
      "\n",
      "Fold: 18  Epoch: 674  Training loss = 4.6021  Validation loss = 1.1084  \n",
      "\n",
      "Fold: 18  Epoch: 675  Training loss = 4.6018  Validation loss = 1.1082  \n",
      "\n",
      "Fold: 18  Epoch: 676  Training loss = 4.6013  Validation loss = 1.1081  \n",
      "\n",
      "Fold: 18  Epoch: 677  Training loss = 4.6009  Validation loss = 1.1079  \n",
      "\n",
      "Fold: 18  Epoch: 678  Training loss = 4.6006  Validation loss = 1.1078  \n",
      "\n",
      "Fold: 18  Epoch: 679  Training loss = 4.6003  Validation loss = 1.1077  \n",
      "\n",
      "Fold: 18  Epoch: 680  Training loss = 4.5999  Validation loss = 1.1075  \n",
      "\n",
      "Fold: 18  Epoch: 681  Training loss = 4.5995  Validation loss = 1.1074  \n",
      "\n",
      "Fold: 18  Epoch: 682  Training loss = 4.5990  Validation loss = 1.1072  \n",
      "\n",
      "Fold: 18  Epoch: 683  Training loss = 4.5986  Validation loss = 1.1071  \n",
      "\n",
      "Fold: 18  Epoch: 684  Training loss = 4.5983  Validation loss = 1.1070  \n",
      "\n",
      "Fold: 18  Epoch: 685  Training loss = 4.5979  Validation loss = 1.1068  \n",
      "\n",
      "Fold: 18  Epoch: 686  Training loss = 4.5975  Validation loss = 1.1067  \n",
      "\n",
      "Fold: 18  Epoch: 687  Training loss = 4.5972  Validation loss = 1.1065  \n",
      "\n",
      "Fold: 18  Epoch: 688  Training loss = 4.5968  Validation loss = 1.1064  \n",
      "\n",
      "Fold: 18  Epoch: 689  Training loss = 4.5964  Validation loss = 1.1062  \n",
      "\n",
      "Fold: 18  Epoch: 690  Training loss = 4.5960  Validation loss = 1.1061  \n",
      "\n",
      "Fold: 18  Epoch: 691  Training loss = 4.5956  Validation loss = 1.1060  \n",
      "\n",
      "Fold: 18  Epoch: 692  Training loss = 4.5951  Validation loss = 1.1058  \n",
      "\n",
      "Fold: 18  Epoch: 693  Training loss = 4.5947  Validation loss = 1.1056  \n",
      "\n",
      "Fold: 18  Epoch: 694  Training loss = 4.5944  Validation loss = 1.1055  \n",
      "\n",
      "Fold: 18  Epoch: 695  Training loss = 4.5939  Validation loss = 1.1053  \n",
      "\n",
      "Fold: 18  Epoch: 696  Training loss = 4.5935  Validation loss = 1.1051  \n",
      "\n",
      "Fold: 18  Epoch: 697  Training loss = 4.5932  Validation loss = 1.1050  \n",
      "\n",
      "Fold: 18  Epoch: 698  Training loss = 4.5927  Validation loss = 1.1048  \n",
      "\n",
      "Fold: 18  Epoch: 699  Training loss = 4.5923  Validation loss = 1.1047  \n",
      "\n",
      "Fold: 18  Epoch: 700  Training loss = 4.5919  Validation loss = 1.1045  \n",
      "\n",
      "Fold: 18  Epoch: 701  Training loss = 4.5915  Validation loss = 1.1044  \n",
      "\n",
      "Fold: 18  Epoch: 702  Training loss = 4.5910  Validation loss = 1.1042  \n",
      "\n",
      "Fold: 18  Epoch: 703  Training loss = 4.5905  Validation loss = 1.1040  \n",
      "\n",
      "Fold: 18  Epoch: 704  Training loss = 4.5902  Validation loss = 1.1039  \n",
      "\n",
      "Fold: 18  Epoch: 705  Training loss = 4.5899  Validation loss = 1.1038  \n",
      "\n",
      "Fold: 18  Epoch: 706  Training loss = 4.5895  Validation loss = 1.1036  \n",
      "\n",
      "Fold: 18  Epoch: 707  Training loss = 4.5891  Validation loss = 1.1034  \n",
      "\n",
      "Fold: 18  Epoch: 708  Training loss = 4.5889  Validation loss = 1.1033  \n",
      "\n",
      "Fold: 18  Epoch: 709  Training loss = 4.5886  Validation loss = 1.1032  \n",
      "\n",
      "Fold: 18  Epoch: 710  Training loss = 4.5883  Validation loss = 1.1031  \n",
      "\n",
      "Fold: 18  Epoch: 711  Training loss = 4.5879  Validation loss = 1.1029  \n",
      "\n",
      "Fold: 18  Epoch: 712  Training loss = 4.5876  Validation loss = 1.1028  \n",
      "\n",
      "Fold: 18  Epoch: 713  Training loss = 4.5872  Validation loss = 1.1027  \n",
      "\n",
      "Fold: 18  Epoch: 714  Training loss = 4.5868  Validation loss = 1.1025  \n",
      "\n",
      "Fold: 18  Epoch: 715  Training loss = 4.5865  Validation loss = 1.1024  \n",
      "\n",
      "Fold: 18  Epoch: 716  Training loss = 4.5861  Validation loss = 1.1022  \n",
      "\n",
      "Fold: 18  Epoch: 717  Training loss = 4.5857  Validation loss = 1.1021  \n",
      "\n",
      "Fold: 18  Epoch: 718  Training loss = 4.5853  Validation loss = 1.1019  \n",
      "\n",
      "Fold: 18  Epoch: 719  Training loss = 4.5849  Validation loss = 1.1018  \n",
      "\n",
      "Fold: 18  Epoch: 720  Training loss = 4.5846  Validation loss = 1.1017  \n",
      "\n",
      "Fold: 18  Epoch: 721  Training loss = 4.5842  Validation loss = 1.1015  \n",
      "\n",
      "Fold: 18  Epoch: 722  Training loss = 4.5840  Validation loss = 1.1014  \n",
      "\n",
      "Fold: 18  Epoch: 723  Training loss = 4.5836  Validation loss = 1.1013  \n",
      "\n",
      "Fold: 18  Epoch: 724  Training loss = 4.5833  Validation loss = 1.1012  \n",
      "\n",
      "Fold: 18  Epoch: 725  Training loss = 4.5829  Validation loss = 1.1010  \n",
      "\n",
      "Fold: 18  Epoch: 726  Training loss = 4.5825  Validation loss = 1.1009  \n",
      "\n",
      "Fold: 18  Epoch: 727  Training loss = 4.5821  Validation loss = 1.1007  \n",
      "\n",
      "Fold: 18  Epoch: 728  Training loss = 4.5817  Validation loss = 1.1006  \n",
      "\n",
      "Fold: 18  Epoch: 729  Training loss = 4.5813  Validation loss = 1.1004  \n",
      "\n",
      "Fold: 18  Epoch: 730  Training loss = 4.5809  Validation loss = 1.1003  \n",
      "\n",
      "Fold: 18  Epoch: 731  Training loss = 4.5806  Validation loss = 1.1002  \n",
      "\n",
      "Fold: 18  Epoch: 732  Training loss = 4.5803  Validation loss = 1.1001  \n",
      "\n",
      "Fold: 18  Epoch: 733  Training loss = 4.5799  Validation loss = 1.0999  \n",
      "\n",
      "Fold: 18  Epoch: 734  Training loss = 4.5795  Validation loss = 1.0998  \n",
      "\n",
      "Fold: 18  Epoch: 735  Training loss = 4.5791  Validation loss = 1.0996  \n",
      "\n",
      "Fold: 18  Epoch: 736  Training loss = 4.5786  Validation loss = 1.0994  \n",
      "\n",
      "Fold: 18  Epoch: 737  Training loss = 4.5782  Validation loss = 1.0993  \n",
      "\n",
      "Fold: 18  Epoch: 738  Training loss = 4.5778  Validation loss = 1.0991  \n",
      "\n",
      "Fold: 18  Epoch: 739  Training loss = 4.5774  Validation loss = 1.0990  \n",
      "\n",
      "Fold: 18  Epoch: 740  Training loss = 4.5770  Validation loss = 1.0988  \n",
      "\n",
      "Fold: 18  Epoch: 741  Training loss = 4.5766  Validation loss = 1.0987  \n",
      "\n",
      "Fold: 18  Epoch: 742  Training loss = 4.5763  Validation loss = 1.0986  \n",
      "\n",
      "Fold: 18  Epoch: 743  Training loss = 4.5759  Validation loss = 1.0985  \n",
      "\n",
      "Fold: 18  Epoch: 744  Training loss = 4.5755  Validation loss = 1.0983  \n",
      "\n",
      "Fold: 18  Epoch: 745  Training loss = 4.5751  Validation loss = 1.0982  \n",
      "\n",
      "Fold: 18  Epoch: 746  Training loss = 4.5747  Validation loss = 1.0980  \n",
      "\n",
      "Fold: 18  Epoch: 747  Training loss = 4.5744  Validation loss = 1.0979  \n",
      "\n",
      "Fold: 18  Epoch: 748  Training loss = 4.5741  Validation loss = 1.0978  \n",
      "\n",
      "Fold: 18  Epoch: 749  Training loss = 4.5737  Validation loss = 1.0976  \n",
      "\n",
      "Fold: 18  Epoch: 750  Training loss = 4.5735  Validation loss = 1.0976  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 750  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 4.5632  Validation loss = 2.2087  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 4.5629  Validation loss = 2.2087  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 4.5624  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 4.5621  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 4.5618  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 4.5614  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 4.5610  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 4.5607  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 4.5603  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 4.5600  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 4.5596  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 4.5593  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 4.5589  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 4.5586  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 4.5582  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 4.5579  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 4.5575  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 4.5571  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 4.5568  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 4.5564  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 4.5560  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 4.5557  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 4.5554  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 4.5549  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 4.5546  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 4.5542  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 4.5539  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 4.5534  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 4.5530  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 4.5526  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 4.5523  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 4.5518  Validation loss = 2.2086  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 29  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 4.5800  Validation loss = 0.9875  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 4.5796  Validation loss = 0.9875  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 4.5793  Validation loss = 0.9874  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 4.5790  Validation loss = 0.9873  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 4.5786  Validation loss = 0.9873  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 4.5783  Validation loss = 0.9873  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 4.5779  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 4.5775  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 4.5771  Validation loss = 0.9870  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 4.5767  Validation loss = 0.9870  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 4.5762  Validation loss = 0.9870  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 4.5759  Validation loss = 0.9869  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 4.5755  Validation loss = 0.9868  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 4.5751  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 4.5748  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 4.5744  Validation loss = 0.9866  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 4.5741  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 4.5738  Validation loss = 0.9864  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 4.5733  Validation loss = 0.9862  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 4.5730  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 4.5726  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 4.5722  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 4.5718  Validation loss = 0.9860  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 4.5714  Validation loss = 0.9859  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 4.5711  Validation loss = 0.9859  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 4.5707  Validation loss = 0.9858  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 4.5704  Validation loss = 0.9857  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 4.5701  Validation loss = 0.9856  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 4.5696  Validation loss = 0.9855  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 4.5693  Validation loss = 0.9855  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 4.5689  Validation loss = 0.9854  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 4.5685  Validation loss = 0.9853  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 4.5681  Validation loss = 0.9852  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 4.5678  Validation loss = 0.9851  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 4.5674  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 4.5671  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 4.5668  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 4.5664  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 4.5661  Validation loss = 0.9849  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 4.5658  Validation loss = 0.9848  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 4.5655  Validation loss = 0.9847  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 4.5651  Validation loss = 0.9847  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 4.5648  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 4.5645  Validation loss = 0.9845  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 4.5642  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 4.5638  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 4.5634  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 4.5630  Validation loss = 0.9842  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 4.5627  Validation loss = 0.9841  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 4.5623  Validation loss = 0.9840  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 4.5620  Validation loss = 0.9840  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 4.5616  Validation loss = 0.9839  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 4.5613  Validation loss = 0.9839  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 4.5610  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 4.5607  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 4.5604  Validation loss = 0.9837  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 4.5600  Validation loss = 0.9836  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 4.5597  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 4.5593  Validation loss = 0.9834  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 4.5589  Validation loss = 0.9834  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 4.5586  Validation loss = 0.9833  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 4.5583  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 4.5579  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 4.5576  Validation loss = 0.9831  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 4.5572  Validation loss = 0.9829  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 4.5569  Validation loss = 0.9829  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 4.5566  Validation loss = 0.9828  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 4.5562  Validation loss = 0.9827  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 4.5559  Validation loss = 0.9826  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 4.5555  Validation loss = 0.9826  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 4.5553  Validation loss = 0.9825  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 4.5549  Validation loss = 0.9825  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 4.5544  Validation loss = 0.9824  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 4.5541  Validation loss = 0.9823  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 4.5537  Validation loss = 0.9822  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 4.5533  Validation loss = 0.9822  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 4.5529  Validation loss = 0.9822  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 4.5525  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 4.5521  Validation loss = 0.9820  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 4.5517  Validation loss = 0.9820  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 4.5514  Validation loss = 0.9819  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 4.5511  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 4.5507  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 4.5503  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 4.5499  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 4.5495  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 4.5491  Validation loss = 0.9817  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 4.5488  Validation loss = 0.9817  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 4.5484  Validation loss = 0.9817  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 4.5481  Validation loss = 0.9817  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 4.5477  Validation loss = 0.9816  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 4.5474  Validation loss = 0.9816  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 4.5470  Validation loss = 0.9814  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 4.5467  Validation loss = 0.9814  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 4.5464  Validation loss = 0.9814  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 4.5460  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 4.5457  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 4.5454  Validation loss = 0.9811  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 4.5450  Validation loss = 0.9810  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 4.5446  Validation loss = 0.9810  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 4.5442  Validation loss = 0.9809  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 4.5439  Validation loss = 0.9809  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 4.5436  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 4.5433  Validation loss = 0.9806  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 4.5429  Validation loss = 0.9805  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 4.5426  Validation loss = 0.9804  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 4.5423  Validation loss = 0.9804  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 4.5420  Validation loss = 0.9803  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 4.5416  Validation loss = 0.9802  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 4.5413  Validation loss = 0.9802  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 4.5411  Validation loss = 0.9801  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 4.5408  Validation loss = 0.9801  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 4.5404  Validation loss = 0.9800  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 4.5402  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 4.5399  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 4.5396  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 4.5393  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 4.5390  Validation loss = 0.9798  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 4.5387  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 4.5383  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 4.5380  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 4.5376  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 4.5372  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 4.5369  Validation loss = 0.9796  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 4.5365  Validation loss = 0.9796  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 4.5362  Validation loss = 0.9796  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 4.5358  Validation loss = 0.9794  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 4.5355  Validation loss = 0.9794  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 4.5352  Validation loss = 0.9793  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 4.5348  Validation loss = 0.9793  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 4.5345  Validation loss = 0.9792  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 4.5341  Validation loss = 0.9792  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 4.5338  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 4.5334  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 4.5331  Validation loss = 0.9790  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 4.5327  Validation loss = 0.9789  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 4.5324  Validation loss = 0.9788  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 4.5321  Validation loss = 0.9787  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 4.5318  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 4.5314  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 4.5311  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 4.5307  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 4.5303  Validation loss = 0.9784  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 4.5300  Validation loss = 0.9784  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 4.5297  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 4.5294  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 4.5290  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 4.5287  Validation loss = 0.9782  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 4.5284  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 4.5281  Validation loss = 0.9782  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 4.5278  Validation loss = 0.9781  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 4.5274  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 4.5271  Validation loss = 0.9779  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 4.5268  Validation loss = 0.9779  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 4.5264  Validation loss = 0.9778  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 4.5260  Validation loss = 0.9778  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 4.5257  Validation loss = 0.9777  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 4.5254  Validation loss = 0.9775  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 4.5250  Validation loss = 0.9774  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 4.5247  Validation loss = 0.9773  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 4.5243  Validation loss = 0.9773  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 4.5240  Validation loss = 0.9772  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 4.5237  Validation loss = 0.9772  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 4.5234  Validation loss = 0.9771  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 4.5231  Validation loss = 0.9771  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 4.5228  Validation loss = 0.9770  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 4.5226  Validation loss = 0.9769  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 4.5224  Validation loss = 0.9769  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 4.5220  Validation loss = 0.9768  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 4.5218  Validation loss = 0.9767  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 4.5214  Validation loss = 0.9766  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 4.5211  Validation loss = 0.9765  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 4.5207  Validation loss = 0.9765  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 4.5203  Validation loss = 0.9765  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 4.5200  Validation loss = 0.9764  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 4.5198  Validation loss = 0.9764  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 4.5194  Validation loss = 0.9764  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 4.5191  Validation loss = 0.9763  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 4.5187  Validation loss = 0.9762  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 4.5183  Validation loss = 0.9761  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 4.5180  Validation loss = 0.9761  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 4.5176  Validation loss = 0.9760  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 4.5173  Validation loss = 0.9760  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 4.5169  Validation loss = 0.9759  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 4.5166  Validation loss = 0.9760  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 4.5163  Validation loss = 0.9759  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 4.5160  Validation loss = 0.9758  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 4.5157  Validation loss = 0.9758  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 4.5154  Validation loss = 0.9757  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 4.5151  Validation loss = 0.9757  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 4.5147  Validation loss = 0.9756  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 4.5144  Validation loss = 0.9755  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 4.5141  Validation loss = 0.9754  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 4.5138  Validation loss = 0.9753  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 4.5134  Validation loss = 0.9752  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 4.5131  Validation loss = 0.9751  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 4.5127  Validation loss = 0.9750  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 4.5124  Validation loss = 0.9750  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 4.5120  Validation loss = 0.9748  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 4.5117  Validation loss = 0.9748  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 4.5114  Validation loss = 0.9748  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 4.5111  Validation loss = 0.9748  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 4.5108  Validation loss = 0.9747  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 4.5104  Validation loss = 0.9746  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 4.5101  Validation loss = 0.9746  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 4.5097  Validation loss = 0.9746  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 4.5094  Validation loss = 0.9745  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 4.5089  Validation loss = 0.9744  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 4.5086  Validation loss = 0.9743  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 4.5082  Validation loss = 0.9743  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 4.5079  Validation loss = 0.9742  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 4.5075  Validation loss = 0.9742  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 4.5072  Validation loss = 0.9741  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 4.5069  Validation loss = 0.9741  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 4.5066  Validation loss = 0.9741  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 4.5063  Validation loss = 0.9741  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 4.5059  Validation loss = 0.9740  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 4.5056  Validation loss = 0.9740  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 4.5052  Validation loss = 0.9740  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 4.5050  Validation loss = 0.9740  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 4.5047  Validation loss = 0.9739  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 4.5043  Validation loss = 0.9739  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 4.5040  Validation loss = 0.9738  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 4.5037  Validation loss = 0.9738  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 4.5032  Validation loss = 0.9737  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 4.5028  Validation loss = 0.9737  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 4.5025  Validation loss = 0.9736  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 4.5021  Validation loss = 0.9735  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 4.5019  Validation loss = 0.9735  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 4.5016  Validation loss = 0.9735  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 4.5013  Validation loss = 0.9735  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 4.5010  Validation loss = 0.9735  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 4.5007  Validation loss = 0.9735  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 4.5005  Validation loss = 0.9733  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 4.5001  Validation loss = 0.9732  \n",
      "\n",
      "Fold: 20  Epoch: 236  Training loss = 4.4998  Validation loss = 0.9732  \n",
      "\n",
      "Fold: 20  Epoch: 237  Training loss = 4.4995  Validation loss = 0.9732  \n",
      "\n",
      "Fold: 20  Epoch: 238  Training loss = 4.4992  Validation loss = 0.9731  \n",
      "\n",
      "Fold: 20  Epoch: 239  Training loss = 4.4989  Validation loss = 0.9731  \n",
      "\n",
      "Fold: 20  Epoch: 240  Training loss = 4.4985  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 20  Epoch: 241  Training loss = 4.4981  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 20  Epoch: 242  Training loss = 4.4978  Validation loss = 0.9728  \n",
      "\n",
      "Fold: 20  Epoch: 243  Training loss = 4.4974  Validation loss = 0.9728  \n",
      "\n",
      "Fold: 20  Epoch: 244  Training loss = 4.4971  Validation loss = 0.9728  \n",
      "\n",
      "Fold: 20  Epoch: 245  Training loss = 4.4967  Validation loss = 0.9727  \n",
      "\n",
      "Fold: 20  Epoch: 246  Training loss = 4.4964  Validation loss = 0.9726  \n",
      "\n",
      "Fold: 20  Epoch: 247  Training loss = 4.4961  Validation loss = 0.9725  \n",
      "\n",
      "Fold: 20  Epoch: 248  Training loss = 4.4958  Validation loss = 0.9725  \n",
      "\n",
      "Fold: 20  Epoch: 249  Training loss = 4.4955  Validation loss = 0.9724  \n",
      "\n",
      "Fold: 20  Epoch: 250  Training loss = 4.4951  Validation loss = 0.9724  \n",
      "\n",
      "Fold: 20  Epoch: 251  Training loss = 4.4947  Validation loss = 0.9723  \n",
      "\n",
      "Fold: 20  Epoch: 252  Training loss = 4.4943  Validation loss = 0.9723  \n",
      "\n",
      "Fold: 20  Epoch: 253  Training loss = 4.4939  Validation loss = 0.9723  \n",
      "\n",
      "Fold: 20  Epoch: 254  Training loss = 4.4936  Validation loss = 0.9723  \n",
      "\n",
      "Fold: 20  Epoch: 255  Training loss = 4.4933  Validation loss = 0.9722  \n",
      "\n",
      "Fold: 20  Epoch: 256  Training loss = 4.4930  Validation loss = 0.9721  \n",
      "\n",
      "Fold: 20  Epoch: 257  Training loss = 4.4927  Validation loss = 0.9721  \n",
      "\n",
      "Fold: 20  Epoch: 258  Training loss = 4.4924  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 20  Epoch: 259  Training loss = 4.4920  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 20  Epoch: 260  Training loss = 4.4918  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 20  Epoch: 261  Training loss = 4.4915  Validation loss = 0.9718  \n",
      "\n",
      "Fold: 20  Epoch: 262  Training loss = 4.4912  Validation loss = 0.9718  \n",
      "\n",
      "Fold: 20  Epoch: 263  Training loss = 4.4908  Validation loss = 0.9718  \n",
      "\n",
      "Fold: 20  Epoch: 264  Training loss = 4.4904  Validation loss = 0.9718  \n",
      "\n",
      "Fold: 20  Epoch: 265  Training loss = 4.4901  Validation loss = 0.9717  \n",
      "\n",
      "Fold: 20  Epoch: 266  Training loss = 4.4898  Validation loss = 0.9716  \n",
      "\n",
      "Fold: 20  Epoch: 267  Training loss = 4.4895  Validation loss = 0.9716  \n",
      "\n",
      "Fold: 20  Epoch: 268  Training loss = 4.4892  Validation loss = 0.9717  \n",
      "\n",
      "Fold: 20  Epoch: 269  Training loss = 4.4888  Validation loss = 0.9717  \n",
      "\n",
      "Fold: 20  Epoch: 270  Training loss = 4.4885  Validation loss = 0.9716  \n",
      "\n",
      "Fold: 20  Epoch: 271  Training loss = 4.4882  Validation loss = 0.9715  \n",
      "\n",
      "Fold: 20  Epoch: 272  Training loss = 4.4878  Validation loss = 0.9715  \n",
      "\n",
      "Fold: 20  Epoch: 273  Training loss = 4.4875  Validation loss = 0.9714  \n",
      "\n",
      "Fold: 20  Epoch: 274  Training loss = 4.4871  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 20  Epoch: 275  Training loss = 4.4867  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 20  Epoch: 276  Training loss = 4.4864  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 20  Epoch: 277  Training loss = 4.4860  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 20  Epoch: 278  Training loss = 4.4856  Validation loss = 0.9712  \n",
      "\n",
      "Fold: 20  Epoch: 279  Training loss = 4.4853  Validation loss = 0.9712  \n",
      "\n",
      "Fold: 20  Epoch: 280  Training loss = 4.4850  Validation loss = 0.9711  \n",
      "\n",
      "Fold: 20  Epoch: 281  Training loss = 4.4846  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 20  Epoch: 282  Training loss = 4.4843  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 20  Epoch: 283  Training loss = 4.4840  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 20  Epoch: 284  Training loss = 4.4838  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 20  Epoch: 285  Training loss = 4.4834  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 20  Epoch: 286  Training loss = 4.4830  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 20  Epoch: 287  Training loss = 4.4827  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 20  Epoch: 288  Training loss = 4.4823  Validation loss = 0.9708  \n",
      "\n",
      "Fold: 20  Epoch: 289  Training loss = 4.4820  Validation loss = 0.9708  \n",
      "\n",
      "Fold: 20  Epoch: 290  Training loss = 4.4817  Validation loss = 0.9708  \n",
      "\n",
      "Fold: 20  Epoch: 291  Training loss = 4.4815  Validation loss = 0.9707  \n",
      "\n",
      "Fold: 20  Epoch: 292  Training loss = 4.4812  Validation loss = 0.9707  \n",
      "\n",
      "Fold: 20  Epoch: 293  Training loss = 4.4809  Validation loss = 0.9706  \n",
      "\n",
      "Fold: 20  Epoch: 294  Training loss = 4.4805  Validation loss = 0.9706  \n",
      "\n",
      "Fold: 20  Epoch: 295  Training loss = 4.4801  Validation loss = 0.9706  \n",
      "\n",
      "Fold: 20  Epoch: 296  Training loss = 4.4798  Validation loss = 0.9706  \n",
      "\n",
      "Fold: 20  Epoch: 297  Training loss = 4.4795  Validation loss = 0.9705  \n",
      "\n",
      "Fold: 20  Epoch: 298  Training loss = 4.4793  Validation loss = 0.9705  \n",
      "\n",
      "Fold: 20  Epoch: 299  Training loss = 4.4790  Validation loss = 0.9704  \n",
      "\n",
      "Fold: 20  Epoch: 300  Training loss = 4.4786  Validation loss = 0.9704  \n",
      "\n",
      "Fold: 20  Epoch: 301  Training loss = 4.4783  Validation loss = 0.9704  \n",
      "\n",
      "Fold: 20  Epoch: 302  Training loss = 4.4779  Validation loss = 0.9703  \n",
      "\n",
      "Fold: 20  Epoch: 303  Training loss = 4.4774  Validation loss = 0.9703  \n",
      "\n",
      "Fold: 20  Epoch: 304  Training loss = 4.4771  Validation loss = 0.9703  \n",
      "\n",
      "Fold: 20  Epoch: 305  Training loss = 4.4767  Validation loss = 0.9702  \n",
      "\n",
      "Fold: 20  Epoch: 306  Training loss = 4.4764  Validation loss = 0.9702  \n",
      "\n",
      "Fold: 20  Epoch: 307  Training loss = 4.4761  Validation loss = 0.9701  \n",
      "\n",
      "Fold: 20  Epoch: 308  Training loss = 4.4758  Validation loss = 0.9701  \n",
      "\n",
      "Fold: 20  Epoch: 309  Training loss = 4.4755  Validation loss = 0.9700  \n",
      "\n",
      "Fold: 20  Epoch: 310  Training loss = 4.4751  Validation loss = 0.9700  \n",
      "\n",
      "Fold: 20  Epoch: 311  Training loss = 4.4748  Validation loss = 0.9699  \n",
      "\n",
      "Fold: 20  Epoch: 312  Training loss = 4.4744  Validation loss = 0.9699  \n",
      "\n",
      "Fold: 20  Epoch: 313  Training loss = 4.4741  Validation loss = 0.9699  \n",
      "\n",
      "Fold: 20  Epoch: 314  Training loss = 4.4739  Validation loss = 0.9698  \n",
      "\n",
      "Fold: 20  Epoch: 315  Training loss = 4.4736  Validation loss = 0.9697  \n",
      "\n",
      "Fold: 20  Epoch: 316  Training loss = 4.4732  Validation loss = 0.9697  \n",
      "\n",
      "Fold: 20  Epoch: 317  Training loss = 4.4729  Validation loss = 0.9696  \n",
      "\n",
      "Fold: 20  Epoch: 318  Training loss = 4.4727  Validation loss = 0.9695  \n",
      "\n",
      "Fold: 20  Epoch: 319  Training loss = 4.4725  Validation loss = 0.9695  \n",
      "\n",
      "Fold: 20  Epoch: 320  Training loss = 4.4721  Validation loss = 0.9694  \n",
      "\n",
      "Fold: 20  Epoch: 321  Training loss = 4.4718  Validation loss = 0.9693  \n",
      "\n",
      "Fold: 20  Epoch: 322  Training loss = 4.4715  Validation loss = 0.9693  \n",
      "\n",
      "Fold: 20  Epoch: 323  Training loss = 4.4712  Validation loss = 0.9692  \n",
      "\n",
      "Fold: 20  Epoch: 324  Training loss = 4.4709  Validation loss = 0.9691  \n",
      "\n",
      "Fold: 20  Epoch: 325  Training loss = 4.4706  Validation loss = 0.9691  \n",
      "\n",
      "Fold: 20  Epoch: 326  Training loss = 4.4703  Validation loss = 0.9691  \n",
      "\n",
      "Fold: 20  Epoch: 327  Training loss = 4.4699  Validation loss = 0.9691  \n",
      "\n",
      "Fold: 20  Epoch: 328  Training loss = 4.4696  Validation loss = 0.9691  \n",
      "\n",
      "Fold: 20  Epoch: 329  Training loss = 4.4692  Validation loss = 0.9690  \n",
      "\n",
      "Fold: 20  Epoch: 330  Training loss = 4.4688  Validation loss = 0.9690  \n",
      "\n",
      "Fold: 20  Epoch: 331  Training loss = 4.4685  Validation loss = 0.9690  \n",
      "\n",
      "Fold: 20  Epoch: 332  Training loss = 4.4682  Validation loss = 0.9690  \n",
      "\n",
      "Fold: 20  Epoch: 333  Training loss = 4.4679  Validation loss = 0.9690  \n",
      "\n",
      "Fold: 20  Epoch: 334  Training loss = 4.4676  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 20  Epoch: 335  Training loss = 4.4673  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 20  Epoch: 336  Training loss = 4.4669  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 20  Epoch: 337  Training loss = 4.4667  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 20  Epoch: 338  Training loss = 4.4664  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 20  Epoch: 339  Training loss = 4.4661  Validation loss = 0.9688  \n",
      "\n",
      "Fold: 20  Epoch: 340  Training loss = 4.4658  Validation loss = 0.9687  \n",
      "\n",
      "Fold: 20  Epoch: 341  Training loss = 4.4654  Validation loss = 0.9687  \n",
      "\n",
      "Fold: 20  Epoch: 342  Training loss = 4.4651  Validation loss = 0.9687  \n",
      "\n",
      "Fold: 20  Epoch: 343  Training loss = 4.4648  Validation loss = 0.9687  \n",
      "\n",
      "Fold: 20  Epoch: 344  Training loss = 4.4644  Validation loss = 0.9687  \n",
      "\n",
      "Fold: 20  Epoch: 345  Training loss = 4.4642  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 20  Epoch: 346  Training loss = 4.4638  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 20  Epoch: 347  Training loss = 4.4635  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 20  Epoch: 348  Training loss = 4.4631  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 20  Epoch: 349  Training loss = 4.4628  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 20  Epoch: 350  Training loss = 4.4625  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 20  Epoch: 351  Training loss = 4.4622  Validation loss = 0.9685  \n",
      "\n",
      "Fold: 20  Epoch: 352  Training loss = 4.4619  Validation loss = 0.9685  \n",
      "\n",
      "Fold: 20  Epoch: 353  Training loss = 4.4615  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 20  Epoch: 354  Training loss = 4.4612  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 20  Epoch: 355  Training loss = 4.4609  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 20  Epoch: 356  Training loss = 4.4606  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 20  Epoch: 357  Training loss = 4.4602  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 20  Epoch: 358  Training loss = 4.4598  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 20  Epoch: 359  Training loss = 4.4595  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 20  Epoch: 360  Training loss = 4.4592  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 20  Epoch: 361  Training loss = 4.4589  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 20  Epoch: 362  Training loss = 4.4585  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 20  Epoch: 363  Training loss = 4.4581  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 20  Epoch: 364  Training loss = 4.4579  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 20  Epoch: 365  Training loss = 4.4575  Validation loss = 0.9682  \n",
      "\n",
      "Fold: 20  Epoch: 366  Training loss = 4.4572  Validation loss = 0.9682  \n",
      "\n",
      "Fold: 20  Epoch: 367  Training loss = 4.4569  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 20  Epoch: 368  Training loss = 4.4566  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 20  Epoch: 369  Training loss = 4.4563  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 20  Epoch: 370  Training loss = 4.4561  Validation loss = 0.9680  \n",
      "\n",
      "Fold: 20  Epoch: 371  Training loss = 4.4558  Validation loss = 0.9679  \n",
      "\n",
      "Fold: 20  Epoch: 372  Training loss = 4.4555  Validation loss = 0.9679  \n",
      "\n",
      "Fold: 20  Epoch: 373  Training loss = 4.4552  Validation loss = 0.9679  \n",
      "\n",
      "Fold: 20  Epoch: 374  Training loss = 4.4548  Validation loss = 0.9679  \n",
      "\n",
      "Fold: 20  Epoch: 375  Training loss = 4.4544  Validation loss = 0.9678  \n",
      "\n",
      "Fold: 20  Epoch: 376  Training loss = 4.4541  Validation loss = 0.9678  \n",
      "\n",
      "Fold: 20  Epoch: 377  Training loss = 4.4538  Validation loss = 0.9678  \n",
      "\n",
      "Fold: 20  Epoch: 378  Training loss = 4.4535  Validation loss = 0.9677  \n",
      "\n",
      "Fold: 20  Epoch: 379  Training loss = 4.4531  Validation loss = 0.9678  \n",
      "\n",
      "Fold: 20  Epoch: 380  Training loss = 4.4528  Validation loss = 0.9677  \n",
      "\n",
      "Fold: 20  Epoch: 381  Training loss = 4.4525  Validation loss = 0.9677  \n",
      "\n",
      "Fold: 20  Epoch: 382  Training loss = 4.4523  Validation loss = 0.9677  \n",
      "\n",
      "Fold: 20  Epoch: 383  Training loss = 4.4519  Validation loss = 0.9676  \n",
      "\n",
      "Fold: 20  Epoch: 384  Training loss = 4.4516  Validation loss = 0.9676  \n",
      "\n",
      "Fold: 20  Epoch: 385  Training loss = 4.4513  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 386  Training loss = 4.4510  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 387  Training loss = 4.4507  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 388  Training loss = 4.4504  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 389  Training loss = 4.4500  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 390  Training loss = 4.4497  Validation loss = 0.9674  \n",
      "\n",
      "Fold: 20  Epoch: 391  Training loss = 4.4494  Validation loss = 0.9674  \n",
      "\n",
      "Fold: 20  Epoch: 392  Training loss = 4.4490  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 393  Training loss = 4.4486  Validation loss = 0.9674  \n",
      "\n",
      "Fold: 20  Epoch: 394  Training loss = 4.4483  Validation loss = 0.9674  \n",
      "\n",
      "Fold: 20  Epoch: 395  Training loss = 4.4479  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 396  Training loss = 4.4476  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 397  Training loss = 4.4473  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 398  Training loss = 4.4470  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 399  Training loss = 4.4467  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 400  Training loss = 4.4464  Validation loss = 0.9674  \n",
      "\n",
      "Fold: 20  Epoch: 401  Training loss = 4.4460  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 402  Training loss = 4.4457  Validation loss = 0.9674  \n",
      "\n",
      "Fold: 20  Epoch: 403  Training loss = 4.4454  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 404  Training loss = 4.4451  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 405  Training loss = 4.4447  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 406  Training loss = 4.4444  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 407  Training loss = 4.4442  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 408  Training loss = 4.4439  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 409  Training loss = 4.4435  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 410  Training loss = 4.4432  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 411  Training loss = 4.4430  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 412  Training loss = 4.4426  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 413  Training loss = 4.4422  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 414  Training loss = 4.4418  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 415  Training loss = 4.4415  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 416  Training loss = 4.4412  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 417  Training loss = 4.4410  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 418  Training loss = 4.4406  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 419  Training loss = 4.4403  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 420  Training loss = 4.4399  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 421  Training loss = 4.4397  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 422  Training loss = 4.4394  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 423  Training loss = 4.4390  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 424  Training loss = 4.4388  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 425  Training loss = 4.4384  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 426  Training loss = 4.4382  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 427  Training loss = 4.4379  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 428  Training loss = 4.4376  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 429  Training loss = 4.4373  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 430  Training loss = 4.4370  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 431  Training loss = 4.4367  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 432  Training loss = 4.4363  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 433  Training loss = 4.4359  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 434  Training loss = 4.4356  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 435  Training loss = 4.4352  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 436  Training loss = 4.4350  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 437  Training loss = 4.4346  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 20  Epoch: 438  Training loss = 4.4344  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 439  Training loss = 4.4341  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 440  Training loss = 4.4338  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 441  Training loss = 4.4334  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 442  Training loss = 4.4331  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 443  Training loss = 4.4327  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 444  Training loss = 4.4324  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 445  Training loss = 4.4320  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 446  Training loss = 4.4316  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 447  Training loss = 4.4312  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 20  Epoch: 448  Training loss = 4.4309  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 449  Training loss = 4.4306  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 450  Training loss = 4.4303  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 451  Training loss = 4.4300  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 20  Epoch: 452  Training loss = 4.4296  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 20  Epoch: 453  Training loss = 4.4293  Validation loss = 0.9666  \n",
      "\n",
      "Fold: 20  Epoch: 454  Training loss = 4.4290  Validation loss = 0.9665  \n",
      "\n",
      "Fold: 20  Epoch: 455  Training loss = 4.4286  Validation loss = 0.9664  \n",
      "\n",
      "Fold: 20  Epoch: 456  Training loss = 4.4283  Validation loss = 0.9664  \n",
      "\n",
      "Fold: 20  Epoch: 457  Training loss = 4.4280  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 458  Training loss = 4.4277  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 459  Training loss = 4.4272  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 460  Training loss = 4.4268  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 461  Training loss = 4.4266  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 20  Epoch: 462  Training loss = 4.4263  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 20  Epoch: 463  Training loss = 4.4260  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 20  Epoch: 464  Training loss = 4.4256  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 465  Training loss = 4.4254  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 466  Training loss = 4.4251  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 467  Training loss = 4.4248  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 468  Training loss = 4.4244  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 469  Training loss = 4.4241  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 470  Training loss = 4.4238  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 471  Training loss = 4.4236  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 472  Training loss = 4.4232  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 473  Training loss = 4.4229  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 474  Training loss = 4.4226  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 475  Training loss = 4.4223  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 476  Training loss = 4.4220  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 477  Training loss = 4.4217  Validation loss = 0.9662  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 469  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 4.4120  Validation loss = 3.4652  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 4.4118  Validation loss = 3.4655  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 4.4115  Validation loss = 3.4659  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 4.4112  Validation loss = 3.4663  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 4.4110  Validation loss = 3.4666  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 4.4107  Validation loss = 3.4669  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 4.4103  Validation loss = 3.4674  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 4.4101  Validation loss = 3.4677  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 4.4097  Validation loss = 3.4682  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 4.4094  Validation loss = 3.4686  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 4.4092  Validation loss = 3.4690  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 4.4089  Validation loss = 3.4694  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 4.4086  Validation loss = 3.4698  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 4.4083  Validation loss = 3.4701  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 4.4081  Validation loss = 3.4704  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 4.4077  Validation loss = 3.4709  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 4.4751  Validation loss = 2.3516  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 4.4749  Validation loss = 2.3513  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 4.4747  Validation loss = 2.3511  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 4.4745  Validation loss = 2.3509  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 4.4744  Validation loss = 2.3508  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 4.4742  Validation loss = 2.3507  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 4.4739  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 4.4737  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 4.4734  Validation loss = 2.3503  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 4.4732  Validation loss = 2.3502  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 4.4729  Validation loss = 2.3500  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 4.4727  Validation loss = 2.3499  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 4.4725  Validation loss = 2.3496  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 4.4723  Validation loss = 2.3494  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 4.4721  Validation loss = 2.3494  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 4.4719  Validation loss = 2.3491  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 4.4716  Validation loss = 2.3489  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 4.4713  Validation loss = 2.3487  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 4.4711  Validation loss = 2.3485  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 4.4708  Validation loss = 2.3483  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 4.4706  Validation loss = 2.3483  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 4.4704  Validation loss = 2.3482  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 4.4701  Validation loss = 2.3480  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 4.4699  Validation loss = 2.3478  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 4.4697  Validation loss = 2.3477  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 4.4695  Validation loss = 2.3476  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 4.4692  Validation loss = 2.3473  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 4.4689  Validation loss = 2.3472  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 4.4687  Validation loss = 2.3471  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 4.4684  Validation loss = 2.3469  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 4.4681  Validation loss = 2.3467  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 4.4679  Validation loss = 2.3465  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 4.4677  Validation loss = 2.3463  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 4.4674  Validation loss = 2.3461  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 4.4671  Validation loss = 2.3459  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 4.4668  Validation loss = 2.3457  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 4.4666  Validation loss = 2.3456  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 4.4663  Validation loss = 2.3455  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 4.4661  Validation loss = 2.3451  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 4.4658  Validation loss = 2.3450  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 4.4655  Validation loss = 2.3447  \n",
      "\n",
      "Fold: 22  Epoch: 42  Training loss = 4.4653  Validation loss = 2.3447  \n",
      "\n",
      "Fold: 22  Epoch: 43  Training loss = 4.4651  Validation loss = 2.3445  \n",
      "\n",
      "Fold: 22  Epoch: 44  Training loss = 4.4649  Validation loss = 2.3444  \n",
      "\n",
      "Fold: 22  Epoch: 45  Training loss = 4.4647  Validation loss = 2.3441  \n",
      "\n",
      "Fold: 22  Epoch: 46  Training loss = 4.4644  Validation loss = 2.3440  \n",
      "\n",
      "Fold: 22  Epoch: 47  Training loss = 4.4642  Validation loss = 2.3438  \n",
      "\n",
      "Fold: 22  Epoch: 48  Training loss = 4.4639  Validation loss = 2.3434  \n",
      "\n",
      "Fold: 22  Epoch: 49  Training loss = 4.4637  Validation loss = 2.3432  \n",
      "\n",
      "Fold: 22  Epoch: 50  Training loss = 4.4635  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 22  Epoch: 51  Training loss = 4.4633  Validation loss = 2.3427  \n",
      "\n",
      "Fold: 22  Epoch: 52  Training loss = 4.4631  Validation loss = 2.3426  \n",
      "\n",
      "Fold: 22  Epoch: 53  Training loss = 4.4628  Validation loss = 2.3424  \n",
      "\n",
      "Fold: 22  Epoch: 54  Training loss = 4.4626  Validation loss = 2.3422  \n",
      "\n",
      "Fold: 22  Epoch: 55  Training loss = 4.4623  Validation loss = 2.3421  \n",
      "\n",
      "Fold: 22  Epoch: 56  Training loss = 4.4621  Validation loss = 2.3419  \n",
      "\n",
      "Fold: 22  Epoch: 57  Training loss = 4.4620  Validation loss = 2.3418  \n",
      "\n",
      "Fold: 22  Epoch: 58  Training loss = 4.4617  Validation loss = 2.3416  \n",
      "\n",
      "Fold: 22  Epoch: 59  Training loss = 4.4614  Validation loss = 2.3414  \n",
      "\n",
      "Fold: 22  Epoch: 60  Training loss = 4.4612  Validation loss = 2.3413  \n",
      "\n",
      "Fold: 22  Epoch: 61  Training loss = 4.4610  Validation loss = 2.3411  \n",
      "\n",
      "Fold: 22  Epoch: 62  Training loss = 4.4607  Validation loss = 2.3410  \n",
      "\n",
      "Fold: 22  Epoch: 63  Training loss = 4.4605  Validation loss = 2.3407  \n",
      "\n",
      "Fold: 22  Epoch: 64  Training loss = 4.4602  Validation loss = 2.3404  \n",
      "\n",
      "Fold: 22  Epoch: 65  Training loss = 4.4599  Validation loss = 2.3402  \n",
      "\n",
      "Fold: 22  Epoch: 66  Training loss = 4.4597  Validation loss = 2.3401  \n",
      "\n",
      "Fold: 22  Epoch: 67  Training loss = 4.4595  Validation loss = 2.3400  \n",
      "\n",
      "Fold: 22  Epoch: 68  Training loss = 4.4593  Validation loss = 2.3397  \n",
      "\n",
      "Fold: 22  Epoch: 69  Training loss = 4.4591  Validation loss = 2.3397  \n",
      "\n",
      "Fold: 22  Epoch: 70  Training loss = 4.4588  Validation loss = 2.3396  \n",
      "\n",
      "Fold: 22  Epoch: 71  Training loss = 4.4587  Validation loss = 2.3394  \n",
      "\n",
      "Fold: 22  Epoch: 72  Training loss = 4.4585  Validation loss = 2.3392  \n",
      "\n",
      "Fold: 22  Epoch: 73  Training loss = 4.4582  Validation loss = 2.3390  \n",
      "\n",
      "Fold: 22  Epoch: 74  Training loss = 4.4581  Validation loss = 2.3390  \n",
      "\n",
      "Fold: 22  Epoch: 75  Training loss = 4.4579  Validation loss = 2.3388  \n",
      "\n",
      "Fold: 22  Epoch: 76  Training loss = 4.4576  Validation loss = 2.3387  \n",
      "\n",
      "Fold: 22  Epoch: 77  Training loss = 4.4574  Validation loss = 2.3386  \n",
      "\n",
      "Fold: 22  Epoch: 78  Training loss = 4.4571  Validation loss = 2.3384  \n",
      "\n",
      "Fold: 22  Epoch: 79  Training loss = 4.4569  Validation loss = 2.3382  \n",
      "\n",
      "Fold: 22  Epoch: 80  Training loss = 4.4567  Validation loss = 2.3380  \n",
      "\n",
      "Fold: 22  Epoch: 81  Training loss = 4.4566  Validation loss = 2.3379  \n",
      "\n",
      "Fold: 22  Epoch: 82  Training loss = 4.4563  Validation loss = 2.3378  \n",
      "\n",
      "Fold: 22  Epoch: 83  Training loss = 4.4560  Validation loss = 2.3376  \n",
      "\n",
      "Fold: 22  Epoch: 84  Training loss = 4.4557  Validation loss = 2.3375  \n",
      "\n",
      "Fold: 22  Epoch: 85  Training loss = 4.4555  Validation loss = 2.3372  \n",
      "\n",
      "Fold: 22  Epoch: 86  Training loss = 4.4552  Validation loss = 2.3371  \n",
      "\n",
      "Fold: 22  Epoch: 87  Training loss = 4.4550  Validation loss = 2.3370  \n",
      "\n",
      "Fold: 22  Epoch: 88  Training loss = 4.4547  Validation loss = 2.3368  \n",
      "\n",
      "Fold: 22  Epoch: 89  Training loss = 4.4545  Validation loss = 2.3367  \n",
      "\n",
      "Fold: 22  Epoch: 90  Training loss = 4.4543  Validation loss = 2.3367  \n",
      "\n",
      "Fold: 22  Epoch: 91  Training loss = 4.4542  Validation loss = 2.3366  \n",
      "\n",
      "Fold: 22  Epoch: 92  Training loss = 4.4539  Validation loss = 2.3365  \n",
      "\n",
      "Fold: 22  Epoch: 93  Training loss = 4.4537  Validation loss = 2.3363  \n",
      "\n",
      "Fold: 22  Epoch: 94  Training loss = 4.4534  Validation loss = 2.3362  \n",
      "\n",
      "Fold: 22  Epoch: 95  Training loss = 4.4532  Validation loss = 2.3360  \n",
      "\n",
      "Fold: 22  Epoch: 96  Training loss = 4.4530  Validation loss = 2.3358  \n",
      "\n",
      "Fold: 22  Epoch: 97  Training loss = 4.4527  Validation loss = 2.3356  \n",
      "\n",
      "Fold: 22  Epoch: 98  Training loss = 4.4524  Validation loss = 2.3354  \n",
      "\n",
      "Fold: 22  Epoch: 99  Training loss = 4.4523  Validation loss = 2.3352  \n",
      "\n",
      "Fold: 22  Epoch: 100  Training loss = 4.4520  Validation loss = 2.3351  \n",
      "\n",
      "Fold: 22  Epoch: 101  Training loss = 4.4518  Validation loss = 2.3350  \n",
      "\n",
      "Fold: 22  Epoch: 102  Training loss = 4.4515  Validation loss = 2.3348  \n",
      "\n",
      "Fold: 22  Epoch: 103  Training loss = 4.4512  Validation loss = 2.3345  \n",
      "\n",
      "Fold: 22  Epoch: 104  Training loss = 4.4510  Validation loss = 2.3343  \n",
      "\n",
      "Fold: 22  Epoch: 105  Training loss = 4.4507  Validation loss = 2.3341  \n",
      "\n",
      "Fold: 22  Epoch: 106  Training loss = 4.4504  Validation loss = 2.3340  \n",
      "\n",
      "Fold: 22  Epoch: 107  Training loss = 4.4502  Validation loss = 2.3339  \n",
      "\n",
      "Fold: 22  Epoch: 108  Training loss = 4.4500  Validation loss = 2.3338  \n",
      "\n",
      "Fold: 22  Epoch: 109  Training loss = 4.4497  Validation loss = 2.3336  \n",
      "\n",
      "Fold: 22  Epoch: 110  Training loss = 4.4495  Validation loss = 2.3334  \n",
      "\n",
      "Fold: 22  Epoch: 111  Training loss = 4.4493  Validation loss = 2.3332  \n",
      "\n",
      "Fold: 22  Epoch: 112  Training loss = 4.4491  Validation loss = 2.3332  \n",
      "\n",
      "Fold: 22  Epoch: 113  Training loss = 4.4489  Validation loss = 2.3331  \n",
      "\n",
      "Fold: 22  Epoch: 114  Training loss = 4.4487  Validation loss = 2.3329  \n",
      "\n",
      "Fold: 22  Epoch: 115  Training loss = 4.4485  Validation loss = 2.3327  \n",
      "\n",
      "Fold: 22  Epoch: 116  Training loss = 4.4482  Validation loss = 2.3325  \n",
      "\n",
      "Fold: 22  Epoch: 117  Training loss = 4.4480  Validation loss = 2.3324  \n",
      "\n",
      "Fold: 22  Epoch: 118  Training loss = 4.4478  Validation loss = 2.3324  \n",
      "\n",
      "Fold: 22  Epoch: 119  Training loss = 4.4477  Validation loss = 2.3323  \n",
      "\n",
      "Fold: 22  Epoch: 120  Training loss = 4.4474  Validation loss = 2.3321  \n",
      "\n",
      "Fold: 22  Epoch: 121  Training loss = 4.4472  Validation loss = 2.3319  \n",
      "\n",
      "Fold: 22  Epoch: 122  Training loss = 4.4470  Validation loss = 2.3318  \n",
      "\n",
      "Fold: 22  Epoch: 123  Training loss = 4.4468  Validation loss = 2.3316  \n",
      "\n",
      "Fold: 22  Epoch: 124  Training loss = 4.4465  Validation loss = 2.3315  \n",
      "\n",
      "Fold: 22  Epoch: 125  Training loss = 4.4463  Validation loss = 2.3314  \n",
      "\n",
      "Fold: 22  Epoch: 126  Training loss = 4.4461  Validation loss = 2.3312  \n",
      "\n",
      "Fold: 22  Epoch: 127  Training loss = 4.4458  Validation loss = 2.3308  \n",
      "\n",
      "Fold: 22  Epoch: 128  Training loss = 4.4456  Validation loss = 2.3306  \n",
      "\n",
      "Fold: 22  Epoch: 129  Training loss = 4.4454  Validation loss = 2.3306  \n",
      "\n",
      "Fold: 22  Epoch: 130  Training loss = 4.4451  Validation loss = 2.3304  \n",
      "\n",
      "Fold: 22  Epoch: 131  Training loss = 4.4449  Validation loss = 2.3301  \n",
      "\n",
      "Fold: 22  Epoch: 132  Training loss = 4.4446  Validation loss = 2.3300  \n",
      "\n",
      "Fold: 22  Epoch: 133  Training loss = 4.4444  Validation loss = 2.3298  \n",
      "\n",
      "Fold: 22  Epoch: 134  Training loss = 4.4442  Validation loss = 2.3297  \n",
      "\n",
      "Fold: 22  Epoch: 135  Training loss = 4.4440  Validation loss = 2.3296  \n",
      "\n",
      "Fold: 22  Epoch: 136  Training loss = 4.4437  Validation loss = 2.3295  \n",
      "\n",
      "Fold: 22  Epoch: 137  Training loss = 4.4434  Validation loss = 2.3293  \n",
      "\n",
      "Fold: 22  Epoch: 138  Training loss = 4.4431  Validation loss = 2.3291  \n",
      "\n",
      "Fold: 22  Epoch: 139  Training loss = 4.4430  Validation loss = 2.3288  \n",
      "\n",
      "Fold: 22  Epoch: 140  Training loss = 4.4428  Validation loss = 2.3286  \n",
      "\n",
      "Fold: 22  Epoch: 141  Training loss = 4.4426  Validation loss = 2.3284  \n",
      "\n",
      "Fold: 22  Epoch: 142  Training loss = 4.4423  Validation loss = 2.3282  \n",
      "\n",
      "Fold: 22  Epoch: 143  Training loss = 4.4421  Validation loss = 2.3281  \n",
      "\n",
      "Fold: 22  Epoch: 144  Training loss = 4.4417  Validation loss = 2.3279  \n",
      "\n",
      "Fold: 22  Epoch: 145  Training loss = 4.4414  Validation loss = 2.3276  \n",
      "\n",
      "Fold: 22  Epoch: 146  Training loss = 4.4412  Validation loss = 2.3276  \n",
      "\n",
      "Fold: 22  Epoch: 147  Training loss = 4.4410  Validation loss = 2.3274  \n",
      "\n",
      "Fold: 22  Epoch: 148  Training loss = 4.4408  Validation loss = 2.3273  \n",
      "\n",
      "Fold: 22  Epoch: 149  Training loss = 4.4407  Validation loss = 2.3268  \n",
      "\n",
      "Fold: 22  Epoch: 150  Training loss = 4.4404  Validation loss = 2.3266  \n",
      "\n",
      "Fold: 22  Epoch: 151  Training loss = 4.4403  Validation loss = 2.3265  \n",
      "\n",
      "Fold: 22  Epoch: 152  Training loss = 4.4400  Validation loss = 2.3264  \n",
      "\n",
      "Fold: 22  Epoch: 153  Training loss = 4.4399  Validation loss = 2.3262  \n",
      "\n",
      "Fold: 22  Epoch: 154  Training loss = 4.4396  Validation loss = 2.3259  \n",
      "\n",
      "Fold: 22  Epoch: 155  Training loss = 4.4393  Validation loss = 2.3258  \n",
      "\n",
      "Fold: 22  Epoch: 156  Training loss = 4.4391  Validation loss = 2.3256  \n",
      "\n",
      "Fold: 22  Epoch: 157  Training loss = 4.4389  Validation loss = 2.3255  \n",
      "\n",
      "Fold: 22  Epoch: 158  Training loss = 4.4387  Validation loss = 2.3253  \n",
      "\n",
      "Fold: 22  Epoch: 159  Training loss = 4.4383  Validation loss = 2.3251  \n",
      "\n",
      "Fold: 22  Epoch: 160  Training loss = 4.4381  Validation loss = 2.3250  \n",
      "\n",
      "Fold: 22  Epoch: 161  Training loss = 4.4379  Validation loss = 2.3249  \n",
      "\n",
      "Fold: 22  Epoch: 162  Training loss = 4.4376  Validation loss = 2.3247  \n",
      "\n",
      "Fold: 22  Epoch: 163  Training loss = 4.4374  Validation loss = 2.3246  \n",
      "\n",
      "Fold: 22  Epoch: 164  Training loss = 4.4371  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 22  Epoch: 165  Training loss = 4.4368  Validation loss = 2.3242  \n",
      "\n",
      "Fold: 22  Epoch: 166  Training loss = 4.4366  Validation loss = 2.3241  \n",
      "\n",
      "Fold: 22  Epoch: 167  Training loss = 4.4363  Validation loss = 2.3240  \n",
      "\n",
      "Fold: 22  Epoch: 168  Training loss = 4.4361  Validation loss = 2.3238  \n",
      "\n",
      "Fold: 22  Epoch: 169  Training loss = 4.4358  Validation loss = 2.3236  \n",
      "\n",
      "Fold: 22  Epoch: 170  Training loss = 4.4356  Validation loss = 2.3234  \n",
      "\n",
      "Fold: 22  Epoch: 171  Training loss = 4.4354  Validation loss = 2.3231  \n",
      "\n",
      "Fold: 22  Epoch: 172  Training loss = 4.4351  Validation loss = 2.3229  \n",
      "\n",
      "Fold: 22  Epoch: 173  Training loss = 4.4349  Validation loss = 2.3227  \n",
      "\n",
      "Fold: 22  Epoch: 174  Training loss = 4.4347  Validation loss = 2.3225  \n",
      "\n",
      "Fold: 22  Epoch: 175  Training loss = 4.4345  Validation loss = 2.3222  \n",
      "\n",
      "Fold: 22  Epoch: 176  Training loss = 4.4342  Validation loss = 2.3222  \n",
      "\n",
      "Fold: 22  Epoch: 177  Training loss = 4.4340  Validation loss = 2.3219  \n",
      "\n",
      "Fold: 22  Epoch: 178  Training loss = 4.4338  Validation loss = 2.3217  \n",
      "\n",
      "Fold: 22  Epoch: 179  Training loss = 4.4335  Validation loss = 2.3215  \n",
      "\n",
      "Fold: 22  Epoch: 180  Training loss = 4.4333  Validation loss = 2.3212  \n",
      "\n",
      "Fold: 22  Epoch: 181  Training loss = 4.4331  Validation loss = 2.3211  \n",
      "\n",
      "Fold: 22  Epoch: 182  Training loss = 4.4328  Validation loss = 2.3208  \n",
      "\n",
      "Fold: 22  Epoch: 183  Training loss = 4.4326  Validation loss = 2.3205  \n",
      "\n",
      "Fold: 22  Epoch: 184  Training loss = 4.4324  Validation loss = 2.3203  \n",
      "\n",
      "Fold: 22  Epoch: 185  Training loss = 4.4322  Validation loss = 2.3202  \n",
      "\n",
      "Fold: 22  Epoch: 186  Training loss = 4.4320  Validation loss = 2.3200  \n",
      "\n",
      "Fold: 22  Epoch: 187  Training loss = 4.4317  Validation loss = 2.3198  \n",
      "\n",
      "Fold: 22  Epoch: 188  Training loss = 4.4315  Validation loss = 2.3197  \n",
      "\n",
      "Fold: 22  Epoch: 189  Training loss = 4.4312  Validation loss = 2.3193  \n",
      "\n",
      "Fold: 22  Epoch: 190  Training loss = 4.4310  Validation loss = 2.3191  \n",
      "\n",
      "Fold: 22  Epoch: 191  Training loss = 4.4307  Validation loss = 2.3188  \n",
      "\n",
      "Fold: 22  Epoch: 192  Training loss = 4.4305  Validation loss = 2.3187  \n",
      "\n",
      "Fold: 22  Epoch: 193  Training loss = 4.4302  Validation loss = 2.3185  \n",
      "\n",
      "Fold: 22  Epoch: 194  Training loss = 4.4300  Validation loss = 2.3182  \n",
      "\n",
      "Fold: 22  Epoch: 195  Training loss = 4.4298  Validation loss = 2.3181  \n",
      "\n",
      "Fold: 22  Epoch: 196  Training loss = 4.4296  Validation loss = 2.3179  \n",
      "\n",
      "Fold: 22  Epoch: 197  Training loss = 4.4294  Validation loss = 2.3177  \n",
      "\n",
      "Fold: 22  Epoch: 198  Training loss = 4.4291  Validation loss = 2.3175  \n",
      "\n",
      "Fold: 22  Epoch: 199  Training loss = 4.4288  Validation loss = 2.3175  \n",
      "\n",
      "Fold: 22  Epoch: 200  Training loss = 4.4285  Validation loss = 2.3172  \n",
      "\n",
      "Fold: 22  Epoch: 201  Training loss = 4.4282  Validation loss = 2.3170  \n",
      "\n",
      "Fold: 22  Epoch: 202  Training loss = 4.4280  Validation loss = 2.3168  \n",
      "\n",
      "Fold: 22  Epoch: 203  Training loss = 4.4277  Validation loss = 2.3167  \n",
      "\n",
      "Fold: 22  Epoch: 204  Training loss = 4.4275  Validation loss = 2.3165  \n",
      "\n",
      "Fold: 22  Epoch: 205  Training loss = 4.4273  Validation loss = 2.3163  \n",
      "\n",
      "Fold: 22  Epoch: 206  Training loss = 4.4271  Validation loss = 2.3163  \n",
      "\n",
      "Fold: 22  Epoch: 207  Training loss = 4.4269  Validation loss = 2.3160  \n",
      "\n",
      "Fold: 22  Epoch: 208  Training loss = 4.4266  Validation loss = 2.3157  \n",
      "\n",
      "Fold: 22  Epoch: 209  Training loss = 4.4263  Validation loss = 2.3156  \n",
      "\n",
      "Fold: 22  Epoch: 210  Training loss = 4.4261  Validation loss = 2.3156  \n",
      "\n",
      "Fold: 22  Epoch: 211  Training loss = 4.4259  Validation loss = 2.3152  \n",
      "\n",
      "Fold: 22  Epoch: 212  Training loss = 4.4256  Validation loss = 2.3151  \n",
      "\n",
      "Fold: 22  Epoch: 213  Training loss = 4.4254  Validation loss = 2.3150  \n",
      "\n",
      "Fold: 22  Epoch: 214  Training loss = 4.4251  Validation loss = 2.3147  \n",
      "\n",
      "Fold: 22  Epoch: 215  Training loss = 4.4249  Validation loss = 2.3147  \n",
      "\n",
      "Fold: 22  Epoch: 216  Training loss = 4.4246  Validation loss = 2.3145  \n",
      "\n",
      "Fold: 22  Epoch: 217  Training loss = 4.4243  Validation loss = 2.3143  \n",
      "\n",
      "Fold: 22  Epoch: 218  Training loss = 4.4240  Validation loss = 2.3143  \n",
      "\n",
      "Fold: 22  Epoch: 219  Training loss = 4.4238  Validation loss = 2.3139  \n",
      "\n",
      "Fold: 22  Epoch: 220  Training loss = 4.4236  Validation loss = 2.3135  \n",
      "\n",
      "Fold: 22  Epoch: 221  Training loss = 4.4234  Validation loss = 2.3132  \n",
      "\n",
      "Fold: 22  Epoch: 222  Training loss = 4.4232  Validation loss = 2.3131  \n",
      "\n",
      "Fold: 22  Epoch: 223  Training loss = 4.4229  Validation loss = 2.3129  \n",
      "\n",
      "Fold: 22  Epoch: 224  Training loss = 4.4227  Validation loss = 2.3129  \n",
      "\n",
      "Fold: 22  Epoch: 225  Training loss = 4.4224  Validation loss = 2.3126  \n",
      "\n",
      "Fold: 22  Epoch: 226  Training loss = 4.4221  Validation loss = 2.3124  \n",
      "\n",
      "Fold: 22  Epoch: 227  Training loss = 4.4219  Validation loss = 2.3122  \n",
      "\n",
      "Fold: 22  Epoch: 228  Training loss = 4.4217  Validation loss = 2.3121  \n",
      "\n",
      "Fold: 22  Epoch: 229  Training loss = 4.4214  Validation loss = 2.3119  \n",
      "\n",
      "Fold: 22  Epoch: 230  Training loss = 4.4212  Validation loss = 2.3118  \n",
      "\n",
      "Fold: 22  Epoch: 231  Training loss = 4.4209  Validation loss = 2.3116  \n",
      "\n",
      "Fold: 22  Epoch: 232  Training loss = 4.4208  Validation loss = 2.3115  \n",
      "\n",
      "Fold: 22  Epoch: 233  Training loss = 4.4204  Validation loss = 2.3114  \n",
      "\n",
      "Fold: 22  Epoch: 234  Training loss = 4.4201  Validation loss = 2.3111  \n",
      "\n",
      "Fold: 22  Epoch: 235  Training loss = 4.4199  Validation loss = 2.3109  \n",
      "\n",
      "Fold: 22  Epoch: 236  Training loss = 4.4198  Validation loss = 2.3108  \n",
      "\n",
      "Fold: 22  Epoch: 237  Training loss = 4.4195  Validation loss = 2.3106  \n",
      "\n",
      "Fold: 22  Epoch: 238  Training loss = 4.4194  Validation loss = 2.3104  \n",
      "\n",
      "Fold: 22  Epoch: 239  Training loss = 4.4191  Validation loss = 2.3101  \n",
      "\n",
      "Fold: 22  Epoch: 240  Training loss = 4.4188  Validation loss = 2.3100  \n",
      "\n",
      "Fold: 22  Epoch: 241  Training loss = 4.4186  Validation loss = 2.3097  \n",
      "\n",
      "Fold: 22  Epoch: 242  Training loss = 4.4184  Validation loss = 2.3096  \n",
      "\n",
      "Fold: 22  Epoch: 243  Training loss = 4.4181  Validation loss = 2.3096  \n",
      "\n",
      "Fold: 22  Epoch: 244  Training loss = 4.4179  Validation loss = 2.3093  \n",
      "\n",
      "Fold: 22  Epoch: 245  Training loss = 4.4177  Validation loss = 2.3092  \n",
      "\n",
      "Fold: 22  Epoch: 246  Training loss = 4.4175  Validation loss = 2.3088  \n",
      "\n",
      "Fold: 22  Epoch: 247  Training loss = 4.4173  Validation loss = 2.3086  \n",
      "\n",
      "Fold: 22  Epoch: 248  Training loss = 4.4171  Validation loss = 2.3083  \n",
      "\n",
      "Fold: 22  Epoch: 249  Training loss = 4.4168  Validation loss = 2.3080  \n",
      "\n",
      "Fold: 22  Epoch: 250  Training loss = 4.4164  Validation loss = 2.3079  \n",
      "\n",
      "Fold: 22  Epoch: 251  Training loss = 4.4162  Validation loss = 2.3077  \n",
      "\n",
      "Fold: 22  Epoch: 252  Training loss = 4.4160  Validation loss = 2.3077  \n",
      "\n",
      "Fold: 22  Epoch: 253  Training loss = 4.4156  Validation loss = 2.3075  \n",
      "\n",
      "Fold: 22  Epoch: 254  Training loss = 4.4154  Validation loss = 2.3074  \n",
      "\n",
      "Fold: 22  Epoch: 255  Training loss = 4.4152  Validation loss = 2.3073  \n",
      "\n",
      "Fold: 22  Epoch: 256  Training loss = 4.4150  Validation loss = 2.3070  \n",
      "\n",
      "Fold: 22  Epoch: 257  Training loss = 4.4148  Validation loss = 2.3067  \n",
      "\n",
      "Fold: 22  Epoch: 258  Training loss = 4.4145  Validation loss = 2.3065  \n",
      "\n",
      "Fold: 22  Epoch: 259  Training loss = 4.4142  Validation loss = 2.3062  \n",
      "\n",
      "Fold: 22  Epoch: 260  Training loss = 4.4141  Validation loss = 2.3060  \n",
      "\n",
      "Fold: 22  Epoch: 261  Training loss = 4.4138  Validation loss = 2.3058  \n",
      "\n",
      "Fold: 22  Epoch: 262  Training loss = 4.4135  Validation loss = 2.3057  \n",
      "\n",
      "Fold: 22  Epoch: 263  Training loss = 4.4133  Validation loss = 2.3055  \n",
      "\n",
      "Fold: 22  Epoch: 264  Training loss = 4.4131  Validation loss = 2.3053  \n",
      "\n",
      "Fold: 22  Epoch: 265  Training loss = 4.4128  Validation loss = 2.3051  \n",
      "\n",
      "Fold: 22  Epoch: 266  Training loss = 4.4126  Validation loss = 2.3049  \n",
      "\n",
      "Fold: 22  Epoch: 267  Training loss = 4.4124  Validation loss = 2.3046  \n",
      "\n",
      "Fold: 22  Epoch: 268  Training loss = 4.4122  Validation loss = 2.3045  \n",
      "\n",
      "Fold: 22  Epoch: 269  Training loss = 4.4120  Validation loss = 2.3042  \n",
      "\n",
      "Fold: 22  Epoch: 270  Training loss = 4.4117  Validation loss = 2.3040  \n",
      "\n",
      "Fold: 22  Epoch: 271  Training loss = 4.4115  Validation loss = 2.3039  \n",
      "\n",
      "Fold: 22  Epoch: 272  Training loss = 4.4112  Validation loss = 2.3036  \n",
      "\n",
      "Fold: 22  Epoch: 273  Training loss = 4.4110  Validation loss = 2.3035  \n",
      "\n",
      "Fold: 22  Epoch: 274  Training loss = 4.4107  Validation loss = 2.3033  \n",
      "\n",
      "Fold: 22  Epoch: 275  Training loss = 4.4104  Validation loss = 2.3032  \n",
      "\n",
      "Fold: 22  Epoch: 276  Training loss = 4.4102  Validation loss = 2.3031  \n",
      "\n",
      "Fold: 22  Epoch: 277  Training loss = 4.4100  Validation loss = 2.3028  \n",
      "\n",
      "Fold: 22  Epoch: 278  Training loss = 4.4098  Validation loss = 2.3026  \n",
      "\n",
      "Fold: 22  Epoch: 279  Training loss = 4.4096  Validation loss = 2.3025  \n",
      "\n",
      "Fold: 22  Epoch: 280  Training loss = 4.4094  Validation loss = 2.3022  \n",
      "\n",
      "Fold: 22  Epoch: 281  Training loss = 4.4092  Validation loss = 2.3020  \n",
      "\n",
      "Fold: 22  Epoch: 282  Training loss = 4.4090  Validation loss = 2.3019  \n",
      "\n",
      "Fold: 22  Epoch: 283  Training loss = 4.4087  Validation loss = 2.3017  \n",
      "\n",
      "Fold: 22  Epoch: 284  Training loss = 4.4086  Validation loss = 2.3016  \n",
      "\n",
      "Fold: 22  Epoch: 285  Training loss = 4.4084  Validation loss = 2.3013  \n",
      "\n",
      "Fold: 22  Epoch: 286  Training loss = 4.4082  Validation loss = 2.3011  \n",
      "\n",
      "Fold: 22  Epoch: 287  Training loss = 4.4080  Validation loss = 2.3010  \n",
      "\n",
      "Fold: 22  Epoch: 288  Training loss = 4.4078  Validation loss = 2.3009  \n",
      "\n",
      "Fold: 22  Epoch: 289  Training loss = 4.4076  Validation loss = 2.3007  \n",
      "\n",
      "Fold: 22  Epoch: 290  Training loss = 4.4073  Validation loss = 2.3005  \n",
      "\n",
      "Fold: 22  Epoch: 291  Training loss = 4.4071  Validation loss = 2.3003  \n",
      "\n",
      "Fold: 22  Epoch: 292  Training loss = 4.4069  Validation loss = 2.3000  \n",
      "\n",
      "Fold: 22  Epoch: 293  Training loss = 4.4066  Validation loss = 2.2998  \n",
      "\n",
      "Fold: 22  Epoch: 294  Training loss = 4.4063  Validation loss = 2.2996  \n",
      "\n",
      "Fold: 22  Epoch: 295  Training loss = 4.4061  Validation loss = 2.2995  \n",
      "\n",
      "Fold: 22  Epoch: 296  Training loss = 4.4058  Validation loss = 2.2993  \n",
      "\n",
      "Fold: 22  Epoch: 297  Training loss = 4.4056  Validation loss = 2.2991  \n",
      "\n",
      "Fold: 22  Epoch: 298  Training loss = 4.4054  Validation loss = 2.2988  \n",
      "\n",
      "Fold: 22  Epoch: 299  Training loss = 4.4051  Validation loss = 2.2987  \n",
      "\n",
      "Fold: 22  Epoch: 300  Training loss = 4.4049  Validation loss = 2.2984  \n",
      "\n",
      "Fold: 22  Epoch: 301  Training loss = 4.4047  Validation loss = 2.2983  \n",
      "\n",
      "Fold: 22  Epoch: 302  Training loss = 4.4044  Validation loss = 2.2982  \n",
      "\n",
      "Fold: 22  Epoch: 303  Training loss = 4.4041  Validation loss = 2.2979  \n",
      "\n",
      "Fold: 22  Epoch: 304  Training loss = 4.4039  Validation loss = 2.2978  \n",
      "\n",
      "Fold: 22  Epoch: 305  Training loss = 4.4036  Validation loss = 2.2976  \n",
      "\n",
      "Fold: 22  Epoch: 306  Training loss = 4.4033  Validation loss = 2.2974  \n",
      "\n",
      "Fold: 22  Epoch: 307  Training loss = 4.4031  Validation loss = 2.2972  \n",
      "\n",
      "Fold: 22  Epoch: 308  Training loss = 4.4029  Validation loss = 2.2970  \n",
      "\n",
      "Fold: 22  Epoch: 309  Training loss = 4.4026  Validation loss = 2.2970  \n",
      "\n",
      "Fold: 22  Epoch: 310  Training loss = 4.4024  Validation loss = 2.2968  \n",
      "\n",
      "Fold: 22  Epoch: 311  Training loss = 4.4021  Validation loss = 2.2967  \n",
      "\n",
      "Fold: 22  Epoch: 312  Training loss = 4.4017  Validation loss = 2.2966  \n",
      "\n",
      "Fold: 22  Epoch: 313  Training loss = 4.4014  Validation loss = 2.2965  \n",
      "\n",
      "Fold: 22  Epoch: 314  Training loss = 4.4011  Validation loss = 2.2963  \n",
      "\n",
      "Fold: 22  Epoch: 315  Training loss = 4.4009  Validation loss = 2.2961  \n",
      "\n",
      "Fold: 22  Epoch: 316  Training loss = 4.4007  Validation loss = 2.2959  \n",
      "\n",
      "Fold: 22  Epoch: 317  Training loss = 4.4005  Validation loss = 2.2957  \n",
      "\n",
      "Fold: 22  Epoch: 318  Training loss = 4.4002  Validation loss = 2.2956  \n",
      "\n",
      "Fold: 22  Epoch: 319  Training loss = 4.4000  Validation loss = 2.2953  \n",
      "\n",
      "Fold: 22  Epoch: 320  Training loss = 4.3998  Validation loss = 2.2952  \n",
      "\n",
      "Fold: 22  Epoch: 321  Training loss = 4.3996  Validation loss = 2.2951  \n",
      "\n",
      "Fold: 22  Epoch: 322  Training loss = 4.3995  Validation loss = 2.2951  \n",
      "\n",
      "Fold: 22  Epoch: 323  Training loss = 4.3992  Validation loss = 2.2949  \n",
      "\n",
      "Fold: 22  Epoch: 324  Training loss = 4.3990  Validation loss = 2.2949  \n",
      "\n",
      "Fold: 22  Epoch: 325  Training loss = 4.3989  Validation loss = 2.2948  \n",
      "\n",
      "Fold: 22  Epoch: 326  Training loss = 4.3987  Validation loss = 2.2947  \n",
      "\n",
      "Fold: 22  Epoch: 327  Training loss = 4.3984  Validation loss = 2.2944  \n",
      "\n",
      "Fold: 22  Epoch: 328  Training loss = 4.3982  Validation loss = 2.2943  \n",
      "\n",
      "Fold: 22  Epoch: 329  Training loss = 4.3980  Validation loss = 2.2941  \n",
      "\n",
      "Fold: 22  Epoch: 330  Training loss = 4.3976  Validation loss = 2.2940  \n",
      "\n",
      "Fold: 22  Epoch: 331  Training loss = 4.3974  Validation loss = 2.2937  \n",
      "\n",
      "Fold: 22  Epoch: 332  Training loss = 4.3972  Validation loss = 2.2936  \n",
      "\n",
      "Fold: 22  Epoch: 333  Training loss = 4.3968  Validation loss = 2.2934  \n",
      "\n",
      "Fold: 22  Epoch: 334  Training loss = 4.3966  Validation loss = 2.2931  \n",
      "\n",
      "Fold: 22  Epoch: 335  Training loss = 4.3963  Validation loss = 2.2929  \n",
      "\n",
      "Fold: 22  Epoch: 336  Training loss = 4.3961  Validation loss = 2.2927  \n",
      "\n",
      "Fold: 22  Epoch: 337  Training loss = 4.3958  Validation loss = 2.2925  \n",
      "\n",
      "Fold: 22  Epoch: 338  Training loss = 4.3956  Validation loss = 2.2923  \n",
      "\n",
      "Fold: 22  Epoch: 339  Training loss = 4.3953  Validation loss = 2.2923  \n",
      "\n",
      "Fold: 22  Epoch: 340  Training loss = 4.3950  Validation loss = 2.2920  \n",
      "\n",
      "Fold: 22  Epoch: 341  Training loss = 4.3947  Validation loss = 2.2919  \n",
      "\n",
      "Fold: 22  Epoch: 342  Training loss = 4.3945  Validation loss = 2.2916  \n",
      "\n",
      "Fold: 22  Epoch: 343  Training loss = 4.3942  Validation loss = 2.2914  \n",
      "\n",
      "Fold: 22  Epoch: 344  Training loss = 4.3940  Validation loss = 2.2913  \n",
      "\n",
      "Fold: 22  Epoch: 345  Training loss = 4.3938  Validation loss = 2.2908  \n",
      "\n",
      "Fold: 22  Epoch: 346  Training loss = 4.3936  Validation loss = 2.2907  \n",
      "\n",
      "Fold: 22  Epoch: 347  Training loss = 4.3934  Validation loss = 2.2905  \n",
      "\n",
      "Fold: 22  Epoch: 348  Training loss = 4.3932  Validation loss = 2.2903  \n",
      "\n",
      "Fold: 22  Epoch: 349  Training loss = 4.3930  Validation loss = 2.2901  \n",
      "\n",
      "Fold: 22  Epoch: 350  Training loss = 4.3928  Validation loss = 2.2900  \n",
      "\n",
      "Fold: 22  Epoch: 351  Training loss = 4.3926  Validation loss = 2.2898  \n",
      "\n",
      "Fold: 22  Epoch: 352  Training loss = 4.3924  Validation loss = 2.2896  \n",
      "\n",
      "Fold: 22  Epoch: 353  Training loss = 4.3921  Validation loss = 2.2893  \n",
      "\n",
      "Fold: 22  Epoch: 354  Training loss = 4.3919  Validation loss = 2.2892  \n",
      "\n",
      "Fold: 22  Epoch: 355  Training loss = 4.3916  Validation loss = 2.2888  \n",
      "\n",
      "Fold: 22  Epoch: 356  Training loss = 4.3913  Validation loss = 2.2887  \n",
      "\n",
      "Fold: 22  Epoch: 357  Training loss = 4.3910  Validation loss = 2.2885  \n",
      "\n",
      "Fold: 22  Epoch: 358  Training loss = 4.3907  Validation loss = 2.2881  \n",
      "\n",
      "Fold: 22  Epoch: 359  Training loss = 4.3905  Validation loss = 2.2879  \n",
      "\n",
      "Fold: 22  Epoch: 360  Training loss = 4.3902  Validation loss = 2.2877  \n",
      "\n",
      "Fold: 22  Epoch: 361  Training loss = 4.3900  Validation loss = 2.2876  \n",
      "\n",
      "Fold: 22  Epoch: 362  Training loss = 4.3898  Validation loss = 2.2875  \n",
      "\n",
      "Fold: 22  Epoch: 363  Training loss = 4.3896  Validation loss = 2.2873  \n",
      "\n",
      "Fold: 22  Epoch: 364  Training loss = 4.3894  Validation loss = 2.2872  \n",
      "\n",
      "Fold: 22  Epoch: 365  Training loss = 4.3892  Validation loss = 2.2869  \n",
      "\n",
      "Fold: 22  Epoch: 366  Training loss = 4.3890  Validation loss = 2.2869  \n",
      "\n",
      "Fold: 22  Epoch: 367  Training loss = 4.3888  Validation loss = 2.2868  \n",
      "\n",
      "Fold: 22  Epoch: 368  Training loss = 4.3886  Validation loss = 2.2865  \n",
      "\n",
      "Fold: 22  Epoch: 369  Training loss = 4.3883  Validation loss = 2.2864  \n",
      "\n",
      "Fold: 22  Epoch: 370  Training loss = 4.3881  Validation loss = 2.2864  \n",
      "\n",
      "Fold: 22  Epoch: 371  Training loss = 4.3879  Validation loss = 2.2862  \n",
      "\n",
      "Fold: 22  Epoch: 372  Training loss = 4.3878  Validation loss = 2.2861  \n",
      "\n",
      "Fold: 22  Epoch: 373  Training loss = 4.3875  Validation loss = 2.2858  \n",
      "\n",
      "Fold: 22  Epoch: 374  Training loss = 4.3873  Validation loss = 2.2856  \n",
      "\n",
      "Fold: 22  Epoch: 375  Training loss = 4.3870  Validation loss = 2.2855  \n",
      "\n",
      "Fold: 22  Epoch: 376  Training loss = 4.3867  Validation loss = 2.2852  \n",
      "\n",
      "Fold: 22  Epoch: 377  Training loss = 4.3865  Validation loss = 2.2849  \n",
      "\n",
      "Fold: 22  Epoch: 378  Training loss = 4.3862  Validation loss = 2.2848  \n",
      "\n",
      "Fold: 22  Epoch: 379  Training loss = 4.3859  Validation loss = 2.2845  \n",
      "\n",
      "Fold: 22  Epoch: 380  Training loss = 4.3857  Validation loss = 2.2844  \n",
      "\n",
      "Fold: 22  Epoch: 381  Training loss = 4.3854  Validation loss = 2.2842  \n",
      "\n",
      "Fold: 22  Epoch: 382  Training loss = 4.3853  Validation loss = 2.2839  \n",
      "\n",
      "Fold: 22  Epoch: 383  Training loss = 4.3851  Validation loss = 2.2836  \n",
      "\n",
      "Fold: 22  Epoch: 384  Training loss = 4.3850  Validation loss = 2.2834  \n",
      "\n",
      "Fold: 22  Epoch: 385  Training loss = 4.3846  Validation loss = 2.2833  \n",
      "\n",
      "Fold: 22  Epoch: 386  Training loss = 4.3844  Validation loss = 2.2831  \n",
      "\n",
      "Fold: 22  Epoch: 387  Training loss = 4.3842  Validation loss = 2.2830  \n",
      "\n",
      "Fold: 22  Epoch: 388  Training loss = 4.3840  Validation loss = 2.2828  \n",
      "\n",
      "Fold: 22  Epoch: 389  Training loss = 4.3837  Validation loss = 2.2827  \n",
      "\n",
      "Fold: 22  Epoch: 390  Training loss = 4.3834  Validation loss = 2.2825  \n",
      "\n",
      "Fold: 22  Epoch: 391  Training loss = 4.3832  Validation loss = 2.2825  \n",
      "\n",
      "Fold: 22  Epoch: 392  Training loss = 4.3830  Validation loss = 2.2821  \n",
      "\n",
      "Fold: 22  Epoch: 393  Training loss = 4.3827  Validation loss = 2.2819  \n",
      "\n",
      "Fold: 22  Epoch: 394  Training loss = 4.3824  Validation loss = 2.2817  \n",
      "\n",
      "Fold: 22  Epoch: 395  Training loss = 4.3822  Validation loss = 2.2816  \n",
      "\n",
      "Fold: 22  Epoch: 396  Training loss = 4.3819  Validation loss = 2.2811  \n",
      "\n",
      "Fold: 22  Epoch: 397  Training loss = 4.3816  Validation loss = 2.2810  \n",
      "\n",
      "Fold: 22  Epoch: 398  Training loss = 4.3813  Validation loss = 2.2806  \n",
      "\n",
      "Fold: 22  Epoch: 399  Training loss = 4.3810  Validation loss = 2.2805  \n",
      "\n",
      "Fold: 22  Epoch: 400  Training loss = 4.3808  Validation loss = 2.2804  \n",
      "\n",
      "Fold: 22  Epoch: 401  Training loss = 4.3806  Validation loss = 2.2803  \n",
      "\n",
      "Fold: 22  Epoch: 402  Training loss = 4.3803  Validation loss = 2.2799  \n",
      "\n",
      "Fold: 22  Epoch: 403  Training loss = 4.3801  Validation loss = 2.2799  \n",
      "\n",
      "Fold: 22  Epoch: 404  Training loss = 4.3798  Validation loss = 2.2794  \n",
      "\n",
      "Fold: 22  Epoch: 405  Training loss = 4.3795  Validation loss = 2.2794  \n",
      "\n",
      "Fold: 22  Epoch: 406  Training loss = 4.3793  Validation loss = 2.2791  \n",
      "\n",
      "Fold: 22  Epoch: 407  Training loss = 4.3790  Validation loss = 2.2789  \n",
      "\n",
      "Fold: 22  Epoch: 408  Training loss = 4.3787  Validation loss = 2.2787  \n",
      "\n",
      "Fold: 22  Epoch: 409  Training loss = 4.3784  Validation loss = 2.2785  \n",
      "\n",
      "Fold: 22  Epoch: 410  Training loss = 4.3782  Validation loss = 2.2783  \n",
      "\n",
      "Fold: 22  Epoch: 411  Training loss = 4.3780  Validation loss = 2.2782  \n",
      "\n",
      "Fold: 22  Epoch: 412  Training loss = 4.3778  Validation loss = 2.2781  \n",
      "\n",
      "Fold: 22  Epoch: 413  Training loss = 4.3775  Validation loss = 2.2780  \n",
      "\n",
      "Fold: 22  Epoch: 414  Training loss = 4.3772  Validation loss = 2.2779  \n",
      "\n",
      "Fold: 22  Epoch: 415  Training loss = 4.3771  Validation loss = 2.2779  \n",
      "\n",
      "Fold: 22  Epoch: 416  Training loss = 4.3768  Validation loss = 2.2776  \n",
      "\n",
      "Fold: 22  Epoch: 417  Training loss = 4.3765  Validation loss = 2.2775  \n",
      "\n",
      "Fold: 22  Epoch: 418  Training loss = 4.3763  Validation loss = 2.2774  \n",
      "\n",
      "Fold: 22  Epoch: 419  Training loss = 4.3760  Validation loss = 2.2772  \n",
      "\n",
      "Fold: 22  Epoch: 420  Training loss = 4.3757  Validation loss = 2.2768  \n",
      "\n",
      "Fold: 22  Epoch: 421  Training loss = 4.3754  Validation loss = 2.2767  \n",
      "\n",
      "Fold: 22  Epoch: 422  Training loss = 4.3752  Validation loss = 2.2764  \n",
      "\n",
      "Fold: 22  Epoch: 423  Training loss = 4.3750  Validation loss = 2.2762  \n",
      "\n",
      "Fold: 22  Epoch: 424  Training loss = 4.3748  Validation loss = 2.2760  \n",
      "\n",
      "Fold: 22  Epoch: 425  Training loss = 4.3745  Validation loss = 2.2759  \n",
      "\n",
      "Fold: 22  Epoch: 426  Training loss = 4.3743  Validation loss = 2.2759  \n",
      "\n",
      "Fold: 22  Epoch: 427  Training loss = 4.3741  Validation loss = 2.2755  \n",
      "\n",
      "Fold: 22  Epoch: 428  Training loss = 4.3739  Validation loss = 2.2753  \n",
      "\n",
      "Fold: 22  Epoch: 429  Training loss = 4.3737  Validation loss = 2.2751  \n",
      "\n",
      "Fold: 22  Epoch: 430  Training loss = 4.3734  Validation loss = 2.2750  \n",
      "\n",
      "Fold: 22  Epoch: 431  Training loss = 4.3731  Validation loss = 2.2748  \n",
      "\n",
      "Fold: 22  Epoch: 432  Training loss = 4.3729  Validation loss = 2.2746  \n",
      "\n",
      "Fold: 22  Epoch: 433  Training loss = 4.3726  Validation loss = 2.2745  \n",
      "\n",
      "Fold: 22  Epoch: 434  Training loss = 4.3724  Validation loss = 2.2745  \n",
      "\n",
      "Fold: 22  Epoch: 435  Training loss = 4.3722  Validation loss = 2.2743  \n",
      "\n",
      "Fold: 22  Epoch: 436  Training loss = 4.3718  Validation loss = 2.2741  \n",
      "\n",
      "Fold: 22  Epoch: 437  Training loss = 4.3716  Validation loss = 2.2741  \n",
      "\n",
      "Fold: 22  Epoch: 438  Training loss = 4.3713  Validation loss = 2.2740  \n",
      "\n",
      "Fold: 22  Epoch: 439  Training loss = 4.3711  Validation loss = 2.2739  \n",
      "\n",
      "Fold: 22  Epoch: 440  Training loss = 4.3708  Validation loss = 2.2736  \n",
      "\n",
      "Fold: 22  Epoch: 441  Training loss = 4.3705  Validation loss = 2.2732  \n",
      "\n",
      "Fold: 22  Epoch: 442  Training loss = 4.3702  Validation loss = 2.2729  \n",
      "\n",
      "Fold: 22  Epoch: 443  Training loss = 4.3700  Validation loss = 2.2726  \n",
      "\n",
      "Fold: 22  Epoch: 444  Training loss = 4.3697  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 22  Epoch: 445  Training loss = 4.3695  Validation loss = 2.2720  \n",
      "\n",
      "Fold: 22  Epoch: 446  Training loss = 4.3693  Validation loss = 2.2719  \n",
      "\n",
      "Fold: 22  Epoch: 447  Training loss = 4.3690  Validation loss = 2.2718  \n",
      "\n",
      "Fold: 22  Epoch: 448  Training loss = 4.3688  Validation loss = 2.2716  \n",
      "\n",
      "Fold: 22  Epoch: 449  Training loss = 4.3685  Validation loss = 2.2714  \n",
      "\n",
      "Fold: 22  Epoch: 450  Training loss = 4.3683  Validation loss = 2.2713  \n",
      "\n",
      "Fold: 22  Epoch: 451  Training loss = 4.3680  Validation loss = 2.2710  \n",
      "\n",
      "Fold: 22  Epoch: 452  Training loss = 4.3678  Validation loss = 2.2708  \n",
      "\n",
      "Fold: 22  Epoch: 453  Training loss = 4.3676  Validation loss = 2.2707  \n",
      "\n",
      "Fold: 22  Epoch: 454  Training loss = 4.3673  Validation loss = 2.2704  \n",
      "\n",
      "Fold: 22  Epoch: 455  Training loss = 4.3671  Validation loss = 2.2701  \n",
      "\n",
      "Fold: 22  Epoch: 456  Training loss = 4.3669  Validation loss = 2.2700  \n",
      "\n",
      "Fold: 22  Epoch: 457  Training loss = 4.3666  Validation loss = 2.2698  \n",
      "\n",
      "Fold: 22  Epoch: 458  Training loss = 4.3663  Validation loss = 2.2696  \n",
      "\n",
      "Fold: 22  Epoch: 459  Training loss = 4.3662  Validation loss = 2.2696  \n",
      "\n",
      "Fold: 22  Epoch: 460  Training loss = 4.3658  Validation loss = 2.2694  \n",
      "\n",
      "Fold: 22  Epoch: 461  Training loss = 4.3657  Validation loss = 2.2693  \n",
      "\n",
      "Fold: 22  Epoch: 462  Training loss = 4.3653  Validation loss = 2.2691  \n",
      "\n",
      "Fold: 22  Epoch: 463  Training loss = 4.3650  Validation loss = 2.2689  \n",
      "\n",
      "Fold: 22  Epoch: 464  Training loss = 4.3648  Validation loss = 2.2688  \n",
      "\n",
      "Fold: 22  Epoch: 465  Training loss = 4.3645  Validation loss = 2.2686  \n",
      "\n",
      "Fold: 22  Epoch: 466  Training loss = 4.3642  Validation loss = 2.2683  \n",
      "\n",
      "Fold: 22  Epoch: 467  Training loss = 4.3639  Validation loss = 2.2682  \n",
      "\n",
      "Fold: 22  Epoch: 468  Training loss = 4.3635  Validation loss = 2.2679  \n",
      "\n",
      "Fold: 22  Epoch: 469  Training loss = 4.3633  Validation loss = 2.2678  \n",
      "\n",
      "Fold: 22  Epoch: 470  Training loss = 4.3630  Validation loss = 2.2676  \n",
      "\n",
      "Fold: 22  Epoch: 471  Training loss = 4.3628  Validation loss = 2.2674  \n",
      "\n",
      "Fold: 22  Epoch: 472  Training loss = 4.3625  Validation loss = 2.2673  \n",
      "\n",
      "Fold: 22  Epoch: 473  Training loss = 4.3623  Validation loss = 2.2670  \n",
      "\n",
      "Fold: 22  Epoch: 474  Training loss = 4.3620  Validation loss = 2.2669  \n",
      "\n",
      "Fold: 22  Epoch: 475  Training loss = 4.3617  Validation loss = 2.2667  \n",
      "\n",
      "Fold: 22  Epoch: 476  Training loss = 4.3614  Validation loss = 2.2666  \n",
      "\n",
      "Fold: 22  Epoch: 477  Training loss = 4.3612  Validation loss = 2.2665  \n",
      "\n",
      "Fold: 22  Epoch: 478  Training loss = 4.3609  Validation loss = 2.2661  \n",
      "\n",
      "Fold: 22  Epoch: 479  Training loss = 4.3606  Validation loss = 2.2658  \n",
      "\n",
      "Fold: 22  Epoch: 480  Training loss = 4.3604  Validation loss = 2.2658  \n",
      "\n",
      "Fold: 22  Epoch: 481  Training loss = 4.3602  Validation loss = 2.2655  \n",
      "\n",
      "Fold: 22  Epoch: 482  Training loss = 4.3600  Validation loss = 2.2653  \n",
      "\n",
      "Fold: 22  Epoch: 483  Training loss = 4.3597  Validation loss = 2.2651  \n",
      "\n",
      "Fold: 22  Epoch: 484  Training loss = 4.3595  Validation loss = 2.2649  \n",
      "\n",
      "Fold: 22  Epoch: 485  Training loss = 4.3592  Validation loss = 2.2648  \n",
      "\n",
      "Fold: 22  Epoch: 486  Training loss = 4.3588  Validation loss = 2.2646  \n",
      "\n",
      "Fold: 22  Epoch: 487  Training loss = 4.3585  Validation loss = 2.2644  \n",
      "\n",
      "Fold: 22  Epoch: 488  Training loss = 4.3583  Validation loss = 2.2643  \n",
      "\n",
      "Fold: 22  Epoch: 489  Training loss = 4.3580  Validation loss = 2.2639  \n",
      "\n",
      "Fold: 22  Epoch: 490  Training loss = 4.3577  Validation loss = 2.2636  \n",
      "\n",
      "Fold: 22  Epoch: 491  Training loss = 4.3575  Validation loss = 2.2634  \n",
      "\n",
      "Fold: 22  Epoch: 492  Training loss = 4.3573  Validation loss = 2.2631  \n",
      "\n",
      "Fold: 22  Epoch: 493  Training loss = 4.3570  Validation loss = 2.2630  \n",
      "\n",
      "Fold: 22  Epoch: 494  Training loss = 4.3567  Validation loss = 2.2628  \n",
      "\n",
      "Fold: 22  Epoch: 495  Training loss = 4.3565  Validation loss = 2.2626  \n",
      "\n",
      "Fold: 22  Epoch: 496  Training loss = 4.3562  Validation loss = 2.2624  \n",
      "\n",
      "Fold: 22  Epoch: 497  Training loss = 4.3559  Validation loss = 2.2622  \n",
      "\n",
      "Fold: 22  Epoch: 498  Training loss = 4.3556  Validation loss = 2.2619  \n",
      "\n",
      "Fold: 22  Epoch: 499  Training loss = 4.3554  Validation loss = 2.2618  \n",
      "\n",
      "Fold: 22  Epoch: 500  Training loss = 4.3551  Validation loss = 2.2616  \n",
      "\n",
      "Fold: 22  Epoch: 501  Training loss = 4.3549  Validation loss = 2.2611  \n",
      "\n",
      "Fold: 22  Epoch: 502  Training loss = 4.3547  Validation loss = 2.2610  \n",
      "\n",
      "Fold: 22  Epoch: 503  Training loss = 4.3543  Validation loss = 2.2607  \n",
      "\n",
      "Fold: 22  Epoch: 504  Training loss = 4.3541  Validation loss = 2.2606  \n",
      "\n",
      "Fold: 22  Epoch: 505  Training loss = 4.3538  Validation loss = 2.2603  \n",
      "\n",
      "Fold: 22  Epoch: 506  Training loss = 4.3534  Validation loss = 2.2600  \n",
      "\n",
      "Fold: 22  Epoch: 507  Training loss = 4.3531  Validation loss = 2.2598  \n",
      "\n",
      "Fold: 22  Epoch: 508  Training loss = 4.3530  Validation loss = 2.2596  \n",
      "\n",
      "Fold: 22  Epoch: 509  Training loss = 4.3527  Validation loss = 2.2595  \n",
      "\n",
      "Fold: 22  Epoch: 510  Training loss = 4.3525  Validation loss = 2.2594  \n",
      "\n",
      "Fold: 22  Epoch: 511  Training loss = 4.3522  Validation loss = 2.2594  \n",
      "\n",
      "Fold: 22  Epoch: 512  Training loss = 4.3519  Validation loss = 2.2592  \n",
      "\n",
      "Fold: 22  Epoch: 513  Training loss = 4.3516  Validation loss = 2.2590  \n",
      "\n",
      "Fold: 22  Epoch: 514  Training loss = 4.3513  Validation loss = 2.2588  \n",
      "\n",
      "Fold: 22  Epoch: 515  Training loss = 4.3509  Validation loss = 2.2586  \n",
      "\n",
      "Fold: 22  Epoch: 516  Training loss = 4.3507  Validation loss = 2.2585  \n",
      "\n",
      "Fold: 22  Epoch: 517  Training loss = 4.3505  Validation loss = 2.2583  \n",
      "\n",
      "Fold: 22  Epoch: 518  Training loss = 4.3502  Validation loss = 2.2582  \n",
      "\n",
      "Fold: 22  Epoch: 519  Training loss = 4.3500  Validation loss = 2.2580  \n",
      "\n",
      "Fold: 22  Epoch: 520  Training loss = 4.3497  Validation loss = 2.2577  \n",
      "\n",
      "Fold: 22  Epoch: 521  Training loss = 4.3495  Validation loss = 2.2575  \n",
      "\n",
      "Fold: 22  Epoch: 522  Training loss = 4.3494  Validation loss = 2.2573  \n",
      "\n",
      "Fold: 22  Epoch: 523  Training loss = 4.3491  Validation loss = 2.2572  \n",
      "\n",
      "Fold: 22  Epoch: 524  Training loss = 4.3488  Validation loss = 2.2571  \n",
      "\n",
      "Fold: 22  Epoch: 525  Training loss = 4.3483  Validation loss = 2.2567  \n",
      "\n",
      "Fold: 22  Epoch: 526  Training loss = 4.3481  Validation loss = 2.2564  \n",
      "\n",
      "Fold: 22  Epoch: 527  Training loss = 4.3479  Validation loss = 2.2561  \n",
      "\n",
      "Fold: 22  Epoch: 528  Training loss = 4.3476  Validation loss = 2.2560  \n",
      "\n",
      "Fold: 22  Epoch: 529  Training loss = 4.3473  Validation loss = 2.2559  \n",
      "\n",
      "Fold: 22  Epoch: 530  Training loss = 4.3471  Validation loss = 2.2557  \n",
      "\n",
      "Fold: 22  Epoch: 531  Training loss = 4.3469  Validation loss = 2.2555  \n",
      "\n",
      "Fold: 22  Epoch: 532  Training loss = 4.3466  Validation loss = 2.2554  \n",
      "\n",
      "Fold: 22  Epoch: 533  Training loss = 4.3463  Validation loss = 2.2554  \n",
      "\n",
      "Fold: 22  Epoch: 534  Training loss = 4.3460  Validation loss = 2.2552  \n",
      "\n",
      "Fold: 22  Epoch: 535  Training loss = 4.3456  Validation loss = 2.2551  \n",
      "\n",
      "Fold: 22  Epoch: 536  Training loss = 4.3454  Validation loss = 2.2548  \n",
      "\n",
      "Fold: 22  Epoch: 537  Training loss = 4.3452  Validation loss = 2.2546  \n",
      "\n",
      "Fold: 22  Epoch: 538  Training loss = 4.3449  Validation loss = 2.2545  \n",
      "\n",
      "Fold: 22  Epoch: 539  Training loss = 4.3447  Validation loss = 2.2544  \n",
      "\n",
      "Fold: 22  Epoch: 540  Training loss = 4.3445  Validation loss = 2.2541  \n",
      "\n",
      "Fold: 22  Epoch: 541  Training loss = 4.3441  Validation loss = 2.2539  \n",
      "\n",
      "Fold: 22  Epoch: 542  Training loss = 4.3438  Validation loss = 2.2536  \n",
      "\n",
      "Fold: 22  Epoch: 543  Training loss = 4.3434  Validation loss = 2.2536  \n",
      "\n",
      "Fold: 22  Epoch: 544  Training loss = 4.3431  Validation loss = 2.2533  \n",
      "\n",
      "Fold: 22  Epoch: 545  Training loss = 4.3429  Validation loss = 2.2531  \n",
      "\n",
      "Fold: 22  Epoch: 546  Training loss = 4.3426  Validation loss = 2.2529  \n",
      "\n",
      "Fold: 22  Epoch: 547  Training loss = 4.3423  Validation loss = 2.2527  \n",
      "\n",
      "Fold: 22  Epoch: 548  Training loss = 4.3421  Validation loss = 2.2527  \n",
      "\n",
      "Fold: 22  Epoch: 549  Training loss = 4.3418  Validation loss = 2.2525  \n",
      "\n",
      "Fold: 22  Epoch: 550  Training loss = 4.3415  Validation loss = 2.2525  \n",
      "\n",
      "Fold: 22  Epoch: 551  Training loss = 4.3413  Validation loss = 2.2522  \n",
      "\n",
      "Fold: 22  Epoch: 552  Training loss = 4.3410  Validation loss = 2.2520  \n",
      "\n",
      "Fold: 22  Epoch: 553  Training loss = 4.3408  Validation loss = 2.2519  \n",
      "\n",
      "Fold: 22  Epoch: 554  Training loss = 4.3405  Validation loss = 2.2516  \n",
      "\n",
      "Fold: 22  Epoch: 555  Training loss = 4.3404  Validation loss = 2.2515  \n",
      "\n",
      "Fold: 22  Epoch: 556  Training loss = 4.3401  Validation loss = 2.2514  \n",
      "\n",
      "Fold: 22  Epoch: 557  Training loss = 4.3398  Validation loss = 2.2513  \n",
      "\n",
      "Fold: 22  Epoch: 558  Training loss = 4.3396  Validation loss = 2.2512  \n",
      "\n",
      "Fold: 22  Epoch: 559  Training loss = 4.3393  Validation loss = 2.2510  \n",
      "\n",
      "Fold: 22  Epoch: 560  Training loss = 4.3390  Validation loss = 2.2509  \n",
      "\n",
      "Fold: 22  Epoch: 561  Training loss = 4.3388  Validation loss = 2.2508  \n",
      "\n",
      "Fold: 22  Epoch: 562  Training loss = 4.3386  Validation loss = 2.2507  \n",
      "\n",
      "Fold: 22  Epoch: 563  Training loss = 4.3383  Validation loss = 2.2506  \n",
      "\n",
      "Fold: 22  Epoch: 564  Training loss = 4.3381  Validation loss = 2.2505  \n",
      "\n",
      "Fold: 22  Epoch: 565  Training loss = 4.3378  Validation loss = 2.2504  \n",
      "\n",
      "Fold: 22  Epoch: 566  Training loss = 4.3375  Validation loss = 2.2501  \n",
      "\n",
      "Fold: 22  Epoch: 567  Training loss = 4.3372  Validation loss = 2.2498  \n",
      "\n",
      "Fold: 22  Epoch: 568  Training loss = 4.3370  Validation loss = 2.2497  \n",
      "\n",
      "Fold: 22  Epoch: 569  Training loss = 4.3365  Validation loss = 2.2495  \n",
      "\n",
      "Fold: 22  Epoch: 570  Training loss = 4.3362  Validation loss = 2.2494  \n",
      "\n",
      "Fold: 22  Epoch: 571  Training loss = 4.3359  Validation loss = 2.2493  \n",
      "\n",
      "Fold: 22  Epoch: 572  Training loss = 4.3355  Validation loss = 2.2491  \n",
      "\n",
      "Fold: 22  Epoch: 573  Training loss = 4.3352  Validation loss = 2.2489  \n",
      "\n",
      "Fold: 22  Epoch: 574  Training loss = 4.3349  Validation loss = 2.2486  \n",
      "\n",
      "Fold: 22  Epoch: 575  Training loss = 4.3346  Validation loss = 2.2486  \n",
      "\n",
      "Fold: 22  Epoch: 576  Training loss = 4.3342  Validation loss = 2.2484  \n",
      "\n",
      "Fold: 22  Epoch: 577  Training loss = 4.3341  Validation loss = 2.2482  \n",
      "\n",
      "Fold: 22  Epoch: 578  Training loss = 4.3339  Validation loss = 2.2481  \n",
      "\n",
      "Fold: 22  Epoch: 579  Training loss = 4.3337  Validation loss = 2.2478  \n",
      "\n",
      "Fold: 22  Epoch: 580  Training loss = 4.3335  Validation loss = 2.2475  \n",
      "\n",
      "Fold: 22  Epoch: 581  Training loss = 4.3332  Validation loss = 2.2473  \n",
      "\n",
      "Fold: 22  Epoch: 582  Training loss = 4.3329  Validation loss = 2.2470  \n",
      "\n",
      "Fold: 22  Epoch: 583  Training loss = 4.3327  Validation loss = 2.2468  \n",
      "\n",
      "Fold: 22  Epoch: 584  Training loss = 4.3324  Validation loss = 2.2466  \n",
      "\n",
      "Fold: 22  Epoch: 585  Training loss = 4.3320  Validation loss = 2.2464  \n",
      "\n",
      "Fold: 22  Epoch: 586  Training loss = 4.3318  Validation loss = 2.2464  \n",
      "\n",
      "Fold: 22  Epoch: 587  Training loss = 4.3316  Validation loss = 2.2460  \n",
      "\n",
      "Fold: 22  Epoch: 588  Training loss = 4.3314  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 22  Epoch: 589  Training loss = 4.3311  Validation loss = 2.2457  \n",
      "\n",
      "Fold: 22  Epoch: 590  Training loss = 4.3309  Validation loss = 2.2455  \n",
      "\n",
      "Fold: 22  Epoch: 591  Training loss = 4.3306  Validation loss = 2.2452  \n",
      "\n",
      "Fold: 22  Epoch: 592  Training loss = 4.3302  Validation loss = 2.2449  \n",
      "\n",
      "Fold: 22  Epoch: 593  Training loss = 4.3299  Validation loss = 2.2447  \n",
      "\n",
      "Fold: 22  Epoch: 594  Training loss = 4.3296  Validation loss = 2.2444  \n",
      "\n",
      "Fold: 22  Epoch: 595  Training loss = 4.3293  Validation loss = 2.2443  \n",
      "\n",
      "Fold: 22  Epoch: 596  Training loss = 4.3280  Validation loss = 2.2440  \n",
      "\n",
      "Fold: 22  Epoch: 597  Training loss = 4.3255  Validation loss = 2.2436  \n",
      "\n",
      "Fold: 22  Epoch: 598  Training loss = 4.3248  Validation loss = 2.2433  \n",
      "\n",
      "Fold: 22  Epoch: 599  Training loss = 4.3246  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 22  Epoch: 600  Training loss = 4.3243  Validation loss = 2.2430  \n",
      "\n",
      "Fold: 22  Epoch: 601  Training loss = 4.3241  Validation loss = 2.2428  \n",
      "\n",
      "Fold: 22  Epoch: 602  Training loss = 4.3239  Validation loss = 2.2426  \n",
      "\n",
      "Fold: 22  Epoch: 603  Training loss = 4.3236  Validation loss = 2.2425  \n",
      "\n",
      "Fold: 22  Epoch: 604  Training loss = 4.3233  Validation loss = 2.2423  \n",
      "\n",
      "Fold: 22  Epoch: 605  Training loss = 4.3230  Validation loss = 2.2422  \n",
      "\n",
      "Fold: 22  Epoch: 606  Training loss = 4.3228  Validation loss = 2.2421  \n",
      "\n",
      "Fold: 22  Epoch: 607  Training loss = 4.3225  Validation loss = 2.2421  \n",
      "\n",
      "Fold: 22  Epoch: 608  Training loss = 4.3222  Validation loss = 2.2418  \n",
      "\n",
      "Fold: 22  Epoch: 609  Training loss = 4.3219  Validation loss = 2.2414  \n",
      "\n",
      "Fold: 22  Epoch: 610  Training loss = 4.3217  Validation loss = 2.2412  \n",
      "\n",
      "Fold: 22  Epoch: 611  Training loss = 4.3214  Validation loss = 2.2410  \n",
      "\n",
      "Fold: 22  Epoch: 612  Training loss = 4.3211  Validation loss = 2.2410  \n",
      "\n",
      "Fold: 22  Epoch: 613  Training loss = 4.3208  Validation loss = 2.2404  \n",
      "\n",
      "Fold: 22  Epoch: 614  Training loss = 4.3205  Validation loss = 2.2403  \n",
      "\n",
      "Fold: 22  Epoch: 615  Training loss = 4.3203  Validation loss = 2.2400  \n",
      "\n",
      "Fold: 22  Epoch: 616  Training loss = 4.3200  Validation loss = 2.2398  \n",
      "\n",
      "Fold: 22  Epoch: 617  Training loss = 4.3198  Validation loss = 2.2397  \n",
      "\n",
      "Fold: 22  Epoch: 618  Training loss = 4.3195  Validation loss = 2.2395  \n",
      "\n",
      "Fold: 22  Epoch: 619  Training loss = 4.3194  Validation loss = 2.2393  \n",
      "\n",
      "Fold: 22  Epoch: 620  Training loss = 4.3191  Validation loss = 2.2390  \n",
      "\n",
      "Fold: 22  Epoch: 621  Training loss = 4.3188  Validation loss = 2.2388  \n",
      "\n",
      "Fold: 22  Epoch: 622  Training loss = 4.3185  Validation loss = 2.2387  \n",
      "\n",
      "Fold: 22  Epoch: 623  Training loss = 4.3183  Validation loss = 2.2385  \n",
      "\n",
      "Fold: 22  Epoch: 624  Training loss = 4.3180  Validation loss = 2.2381  \n",
      "\n",
      "Fold: 22  Epoch: 625  Training loss = 4.3178  Validation loss = 2.2378  \n",
      "\n",
      "Fold: 22  Epoch: 626  Training loss = 4.3175  Validation loss = 2.2375  \n",
      "\n",
      "Fold: 22  Epoch: 627  Training loss = 4.3173  Validation loss = 2.2374  \n",
      "\n",
      "Fold: 22  Epoch: 628  Training loss = 4.3170  Validation loss = 2.2372  \n",
      "\n",
      "Fold: 22  Epoch: 629  Training loss = 4.3167  Validation loss = 2.2371  \n",
      "\n",
      "Fold: 22  Epoch: 630  Training loss = 4.3164  Validation loss = 2.2371  \n",
      "\n",
      "Fold: 22  Epoch: 631  Training loss = 4.3162  Validation loss = 2.2368  \n",
      "\n",
      "Fold: 22  Epoch: 632  Training loss = 4.3159  Validation loss = 2.2368  \n",
      "\n",
      "Fold: 22  Epoch: 633  Training loss = 4.3156  Validation loss = 2.2367  \n",
      "\n",
      "Fold: 22  Epoch: 634  Training loss = 4.3153  Validation loss = 2.2367  \n",
      "\n",
      "Fold: 22  Epoch: 635  Training loss = 4.3151  Validation loss = 2.2365  \n",
      "\n",
      "Fold: 22  Epoch: 636  Training loss = 4.3148  Validation loss = 2.2363  \n",
      "\n",
      "Fold: 22  Epoch: 637  Training loss = 4.3145  Validation loss = 2.2361  \n",
      "\n",
      "Fold: 22  Epoch: 638  Training loss = 4.3144  Validation loss = 2.2359  \n",
      "\n",
      "Fold: 22  Epoch: 639  Training loss = 4.3142  Validation loss = 2.2356  \n",
      "\n",
      "Fold: 22  Epoch: 640  Training loss = 4.3139  Validation loss = 2.2355  \n",
      "\n",
      "Fold: 22  Epoch: 641  Training loss = 4.3136  Validation loss = 2.2353  \n",
      "\n",
      "Fold: 22  Epoch: 642  Training loss = 4.3133  Validation loss = 2.2350  \n",
      "\n",
      "Fold: 22  Epoch: 643  Training loss = 4.3131  Validation loss = 2.2347  \n",
      "\n",
      "Fold: 22  Epoch: 644  Training loss = 4.3129  Validation loss = 2.2346  \n",
      "\n",
      "Fold: 22  Epoch: 645  Training loss = 4.3127  Validation loss = 2.2342  \n",
      "\n",
      "Fold: 22  Epoch: 646  Training loss = 4.3124  Validation loss = 2.2341  \n",
      "\n",
      "Fold: 22  Epoch: 647  Training loss = 4.3122  Validation loss = 2.2339  \n",
      "\n",
      "Fold: 22  Epoch: 648  Training loss = 4.3119  Validation loss = 2.2338  \n",
      "\n",
      "Fold: 22  Epoch: 649  Training loss = 4.3117  Validation loss = 2.2335  \n",
      "\n",
      "Fold: 22  Epoch: 650  Training loss = 4.3115  Validation loss = 2.2331  \n",
      "\n",
      "Fold: 22  Epoch: 651  Training loss = 4.3113  Validation loss = 2.2330  \n",
      "\n",
      "Fold: 22  Epoch: 652  Training loss = 4.3110  Validation loss = 2.2329  \n",
      "\n",
      "Fold: 22  Epoch: 653  Training loss = 4.3108  Validation loss = 2.2327  \n",
      "\n",
      "Fold: 22  Epoch: 654  Training loss = 4.3106  Validation loss = 2.2325  \n",
      "\n",
      "Fold: 22  Epoch: 655  Training loss = 4.3104  Validation loss = 2.2324  \n",
      "\n",
      "Fold: 22  Epoch: 656  Training loss = 4.3102  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 22  Epoch: 657  Training loss = 4.3100  Validation loss = 2.2320  \n",
      "\n",
      "Fold: 22  Epoch: 658  Training loss = 4.3097  Validation loss = 2.2315  \n",
      "\n",
      "Fold: 22  Epoch: 659  Training loss = 4.3094  Validation loss = 2.2312  \n",
      "\n",
      "Fold: 22  Epoch: 660  Training loss = 4.3091  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 22  Epoch: 661  Training loss = 4.3089  Validation loss = 2.2307  \n",
      "\n",
      "Fold: 22  Epoch: 662  Training loss = 4.3087  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 22  Epoch: 663  Training loss = 4.3084  Validation loss = 2.2305  \n",
      "\n",
      "Fold: 22  Epoch: 664  Training loss = 4.3081  Validation loss = 2.2304  \n",
      "\n",
      "Fold: 22  Epoch: 665  Training loss = 4.3078  Validation loss = 2.2304  \n",
      "\n",
      "Fold: 22  Epoch: 666  Training loss = 4.3075  Validation loss = 2.2302  \n",
      "\n",
      "Fold: 22  Epoch: 667  Training loss = 4.3073  Validation loss = 2.2302  \n",
      "\n",
      "Fold: 22  Epoch: 668  Training loss = 4.3070  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 22  Epoch: 669  Training loss = 4.3068  Validation loss = 2.2296  \n",
      "\n",
      "Fold: 22  Epoch: 670  Training loss = 4.3064  Validation loss = 2.2296  \n",
      "\n",
      "Fold: 22  Epoch: 671  Training loss = 4.3061  Validation loss = 2.2294  \n",
      "\n",
      "Fold: 22  Epoch: 672  Training loss = 4.3058  Validation loss = 2.2292  \n",
      "\n",
      "Fold: 22  Epoch: 673  Training loss = 4.3056  Validation loss = 2.2291  \n",
      "\n",
      "Fold: 22  Epoch: 674  Training loss = 4.3053  Validation loss = 2.2289  \n",
      "\n",
      "Fold: 22  Epoch: 675  Training loss = 4.3051  Validation loss = 2.2287  \n",
      "\n",
      "Fold: 22  Epoch: 676  Training loss = 4.3049  Validation loss = 2.2286  \n",
      "\n",
      "Fold: 22  Epoch: 677  Training loss = 4.3046  Validation loss = 2.2284  \n",
      "\n",
      "Fold: 22  Epoch: 678  Training loss = 4.3043  Validation loss = 2.2282  \n",
      "\n",
      "Fold: 22  Epoch: 679  Training loss = 4.3041  Validation loss = 2.2277  \n",
      "\n",
      "Fold: 22  Epoch: 680  Training loss = 4.3038  Validation loss = 2.2276  \n",
      "\n",
      "Fold: 22  Epoch: 681  Training loss = 4.3035  Validation loss = 2.2274  \n",
      "\n",
      "Fold: 22  Epoch: 682  Training loss = 4.3032  Validation loss = 2.2273  \n",
      "\n",
      "Fold: 22  Epoch: 683  Training loss = 4.3029  Validation loss = 2.2273  \n",
      "\n",
      "Fold: 22  Epoch: 684  Training loss = 4.3027  Validation loss = 2.2273  \n",
      "\n",
      "Fold: 22  Epoch: 685  Training loss = 4.3024  Validation loss = 2.2272  \n",
      "\n",
      "Fold: 22  Epoch: 686  Training loss = 4.3021  Validation loss = 2.2269  \n",
      "\n",
      "Fold: 22  Epoch: 687  Training loss = 4.3019  Validation loss = 2.2266  \n",
      "\n",
      "Fold: 22  Epoch: 688  Training loss = 4.3016  Validation loss = 2.2263  \n",
      "\n",
      "Fold: 22  Epoch: 689  Training loss = 4.3013  Validation loss = 2.2263  \n",
      "\n",
      "Fold: 22  Epoch: 690  Training loss = 4.3011  Validation loss = 2.2263  \n",
      "\n",
      "Fold: 22  Epoch: 691  Training loss = 4.3008  Validation loss = 2.2262  \n",
      "\n",
      "Fold: 22  Epoch: 692  Training loss = 4.3006  Validation loss = 2.2257  \n",
      "\n",
      "Fold: 22  Epoch: 693  Training loss = 4.3003  Validation loss = 2.2253  \n",
      "\n",
      "Fold: 22  Epoch: 694  Training loss = 4.2999  Validation loss = 2.2251  \n",
      "\n",
      "Fold: 22  Epoch: 695  Training loss = 4.2996  Validation loss = 2.2249  \n",
      "\n",
      "Fold: 22  Epoch: 696  Training loss = 4.2993  Validation loss = 2.2248  \n",
      "\n",
      "Fold: 22  Epoch: 697  Training loss = 4.2990  Validation loss = 2.2246  \n",
      "\n",
      "Fold: 22  Epoch: 698  Training loss = 4.2988  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 22  Epoch: 699  Training loss = 4.2985  Validation loss = 2.2242  \n",
      "\n",
      "Fold: 22  Epoch: 700  Training loss = 4.2983  Validation loss = 2.2239  \n",
      "\n",
      "Fold: 22  Epoch: 701  Training loss = 4.2981  Validation loss = 2.2236  \n",
      "\n",
      "Fold: 22  Epoch: 702  Training loss = 4.2979  Validation loss = 2.2235  \n",
      "\n",
      "Fold: 22  Epoch: 703  Training loss = 4.2976  Validation loss = 2.2234  \n",
      "\n",
      "Fold: 22  Epoch: 704  Training loss = 4.2974  Validation loss = 2.2229  \n",
      "\n",
      "Fold: 22  Epoch: 705  Training loss = 4.2972  Validation loss = 2.2227  \n",
      "\n",
      "Fold: 22  Epoch: 706  Training loss = 4.2969  Validation loss = 2.2223  \n",
      "\n",
      "Fold: 22  Epoch: 707  Training loss = 4.2966  Validation loss = 2.2221  \n",
      "\n",
      "Fold: 22  Epoch: 708  Training loss = 4.2964  Validation loss = 2.2218  \n",
      "\n",
      "Fold: 22  Epoch: 709  Training loss = 4.2962  Validation loss = 2.2216  \n",
      "\n",
      "Fold: 22  Epoch: 710  Training loss = 4.2960  Validation loss = 2.2215  \n",
      "\n",
      "Fold: 22  Epoch: 711  Training loss = 4.2957  Validation loss = 2.2212  \n",
      "\n",
      "Fold: 22  Epoch: 712  Training loss = 4.2954  Validation loss = 2.2210  \n",
      "\n",
      "Fold: 22  Epoch: 713  Training loss = 4.2953  Validation loss = 2.2209  \n",
      "\n",
      "Fold: 22  Epoch: 714  Training loss = 4.2950  Validation loss = 2.2208  \n",
      "\n",
      "Fold: 22  Epoch: 715  Training loss = 4.2948  Validation loss = 2.2206  \n",
      "\n",
      "Fold: 22  Epoch: 716  Training loss = 4.2945  Validation loss = 2.2204  \n",
      "\n",
      "Fold: 22  Epoch: 717  Training loss = 4.2943  Validation loss = 2.2202  \n",
      "\n",
      "Fold: 22  Epoch: 718  Training loss = 4.2940  Validation loss = 2.2200  \n",
      "\n",
      "Fold: 22  Epoch: 719  Training loss = 4.2938  Validation loss = 2.2199  \n",
      "\n",
      "Fold: 22  Epoch: 720  Training loss = 4.2935  Validation loss = 2.2197  \n",
      "\n",
      "Fold: 22  Epoch: 721  Training loss = 4.2933  Validation loss = 2.2195  \n",
      "\n",
      "Fold: 22  Epoch: 722  Training loss = 4.2931  Validation loss = 2.2194  \n",
      "\n",
      "Fold: 22  Epoch: 723  Training loss = 4.2928  Validation loss = 2.2194  \n",
      "\n",
      "Fold: 22  Epoch: 724  Training loss = 4.2924  Validation loss = 2.2192  \n",
      "\n",
      "Fold: 22  Epoch: 725  Training loss = 4.2922  Validation loss = 2.2192  \n",
      "\n",
      "Fold: 22  Epoch: 726  Training loss = 4.2919  Validation loss = 2.2190  \n",
      "\n",
      "Fold: 22  Epoch: 727  Training loss = 4.2916  Validation loss = 2.2189  \n",
      "\n",
      "Fold: 22  Epoch: 728  Training loss = 4.2913  Validation loss = 2.2185  \n",
      "\n",
      "Fold: 22  Epoch: 729  Training loss = 4.2911  Validation loss = 2.2185  \n",
      "\n",
      "Fold: 22  Epoch: 730  Training loss = 4.2909  Validation loss = 2.2184  \n",
      "\n",
      "Fold: 22  Epoch: 731  Training loss = 4.2907  Validation loss = 2.2181  \n",
      "\n",
      "Fold: 22  Epoch: 732  Training loss = 4.2904  Validation loss = 2.2178  \n",
      "\n",
      "Fold: 22  Epoch: 733  Training loss = 4.2902  Validation loss = 2.2176  \n",
      "\n",
      "Fold: 22  Epoch: 734  Training loss = 4.2900  Validation loss = 2.2175  \n",
      "\n",
      "Fold: 22  Epoch: 735  Training loss = 4.2896  Validation loss = 2.2173  \n",
      "\n",
      "Fold: 22  Epoch: 736  Training loss = 4.2894  Validation loss = 2.2169  \n",
      "\n",
      "Fold: 22  Epoch: 737  Training loss = 4.2891  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 22  Epoch: 738  Training loss = 4.2889  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 22  Epoch: 739  Training loss = 4.2887  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 22  Epoch: 740  Training loss = 4.2885  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 22  Epoch: 741  Training loss = 4.2882  Validation loss = 2.2163  \n",
      "\n",
      "Fold: 22  Epoch: 742  Training loss = 4.2880  Validation loss = 2.2160  \n",
      "\n",
      "Fold: 22  Epoch: 743  Training loss = 4.2878  Validation loss = 2.2158  \n",
      "\n",
      "Fold: 22  Epoch: 744  Training loss = 4.2876  Validation loss = 2.2156  \n",
      "\n",
      "Fold: 22  Epoch: 745  Training loss = 4.2873  Validation loss = 2.2154  \n",
      "\n",
      "Fold: 22  Epoch: 746  Training loss = 4.2870  Validation loss = 2.2150  \n",
      "\n",
      "Fold: 22  Epoch: 747  Training loss = 4.2867  Validation loss = 2.2149  \n",
      "\n",
      "Fold: 22  Epoch: 748  Training loss = 4.2866  Validation loss = 2.2148  \n",
      "\n",
      "Fold: 22  Epoch: 749  Training loss = 4.2864  Validation loss = 2.2148  \n",
      "\n",
      "Fold: 22  Epoch: 750  Training loss = 4.2861  Validation loss = 2.2147  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 750  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 4.3133  Validation loss = 1.4770  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 4.3130  Validation loss = 1.4771  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 4.3127  Validation loss = 1.4770  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 4.3124  Validation loss = 1.4770  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 4.3120  Validation loss = 1.4770  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 4.3118  Validation loss = 1.4770  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 4.3115  Validation loss = 1.4770  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 4.3113  Validation loss = 1.4769  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 4.3110  Validation loss = 1.4768  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 4.3107  Validation loss = 1.4768  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 4.3103  Validation loss = 1.4768  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 4.3101  Validation loss = 1.4767  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 4.3099  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 4.3097  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 4.3095  Validation loss = 1.4765  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 4.3091  Validation loss = 1.4765  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 4.3088  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 4.3086  Validation loss = 1.4767  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 4.3083  Validation loss = 1.4767  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 4.3080  Validation loss = 1.4768  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 4.3078  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 4.3075  Validation loss = 1.4767  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 4.3073  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 4.3070  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 4.3068  Validation loss = 1.4765  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 4.3065  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 4.3062  Validation loss = 1.4767  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 4.3060  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 4.3059  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 4.3056  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 4.3054  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 23  Epoch: 32  Training loss = 4.3052  Validation loss = 1.4765  \n",
      "\n",
      "Fold: 23  Epoch: 33  Training loss = 4.3050  Validation loss = 1.4764  \n",
      "\n",
      "Fold: 23  Epoch: 34  Training loss = 4.3048  Validation loss = 1.4763  \n",
      "\n",
      "Fold: 23  Epoch: 35  Training loss = 4.3045  Validation loss = 1.4765  \n",
      "\n",
      "Fold: 23  Epoch: 36  Training loss = 4.3043  Validation loss = 1.4763  \n",
      "\n",
      "Fold: 23  Epoch: 37  Training loss = 4.3042  Validation loss = 1.4762  \n",
      "\n",
      "Fold: 23  Epoch: 38  Training loss = 4.3038  Validation loss = 1.4763  \n",
      "\n",
      "Fold: 23  Epoch: 39  Training loss = 4.3035  Validation loss = 1.4763  \n",
      "\n",
      "Fold: 23  Epoch: 40  Training loss = 4.3032  Validation loss = 1.4762  \n",
      "\n",
      "Fold: 23  Epoch: 41  Training loss = 4.3031  Validation loss = 1.4762  \n",
      "\n",
      "Fold: 23  Epoch: 42  Training loss = 4.3028  Validation loss = 1.4763  \n",
      "\n",
      "Fold: 23  Epoch: 43  Training loss = 4.3026  Validation loss = 1.4763  \n",
      "\n",
      "Fold: 23  Epoch: 44  Training loss = 4.3024  Validation loss = 1.4762  \n",
      "\n",
      "Fold: 23  Epoch: 45  Training loss = 4.3021  Validation loss = 1.4763  \n",
      "\n",
      "Fold: 23  Epoch: 46  Training loss = 4.3019  Validation loss = 1.4762  \n",
      "\n",
      "Fold: 23  Epoch: 47  Training loss = 4.3016  Validation loss = 1.4762  \n",
      "\n",
      "Fold: 23  Epoch: 48  Training loss = 4.3014  Validation loss = 1.4761  \n",
      "\n",
      "Fold: 23  Epoch: 49  Training loss = 4.3012  Validation loss = 1.4760  \n",
      "\n",
      "Fold: 23  Epoch: 50  Training loss = 4.3009  Validation loss = 1.4760  \n",
      "\n",
      "Fold: 23  Epoch: 51  Training loss = 4.3007  Validation loss = 1.4761  \n",
      "\n",
      "Fold: 23  Epoch: 52  Training loss = 4.3004  Validation loss = 1.4762  \n",
      "\n",
      "Fold: 23  Epoch: 53  Training loss = 4.3001  Validation loss = 1.4763  \n",
      "\n",
      "Fold: 23  Epoch: 54  Training loss = 4.2997  Validation loss = 1.4764  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 50  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 4.2914  Validation loss = 1.9787  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 4.2912  Validation loss = 1.9780  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 4.2909  Validation loss = 1.9777  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 4.2907  Validation loss = 1.9775  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 4.2905  Validation loss = 1.9771  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 4.2903  Validation loss = 1.9765  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 4.2899  Validation loss = 1.9762  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 4.2896  Validation loss = 1.9758  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 4.2893  Validation loss = 1.9754  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 4.2890  Validation loss = 1.9749  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 4.2888  Validation loss = 1.9740  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 4.2885  Validation loss = 1.9734  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 4.2882  Validation loss = 1.9729  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 4.2880  Validation loss = 1.9723  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 4.2877  Validation loss = 1.9718  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 4.2874  Validation loss = 1.9713  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 4.2872  Validation loss = 1.9708  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 4.2869  Validation loss = 1.9705  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 4.2867  Validation loss = 1.9702  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 4.2864  Validation loss = 1.9693  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 4.2861  Validation loss = 1.9687  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 4.2858  Validation loss = 1.9683  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 4.2855  Validation loss = 1.9677  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 4.2852  Validation loss = 1.9669  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 4.2849  Validation loss = 1.9662  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 4.2846  Validation loss = 1.9655  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 4.2842  Validation loss = 1.9643  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 4.2839  Validation loss = 1.9640  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 4.2837  Validation loss = 1.9636  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 4.2834  Validation loss = 1.9630  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 4.2832  Validation loss = 1.9626  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 4.2829  Validation loss = 1.9622  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 4.2825  Validation loss = 1.9619  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 4.2822  Validation loss = 1.9611  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 4.2819  Validation loss = 1.9607  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 4.2816  Validation loss = 1.9593  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 4.2813  Validation loss = 1.9588  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 4.2810  Validation loss = 1.9580  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 4.2807  Validation loss = 1.9573  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 4.2805  Validation loss = 1.9569  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 4.2803  Validation loss = 1.9564  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 4.2801  Validation loss = 1.9561  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 4.2798  Validation loss = 1.9555  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 4.2795  Validation loss = 1.9551  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 4.2793  Validation loss = 1.9548  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 4.2790  Validation loss = 1.9542  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 4.2788  Validation loss = 1.9538  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 4.2785  Validation loss = 1.9529  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 4.2782  Validation loss = 1.9523  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 4.2779  Validation loss = 1.9515  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 4.2777  Validation loss = 1.9510  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 4.2774  Validation loss = 1.9506  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 4.2770  Validation loss = 1.9501  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 4.2766  Validation loss = 1.9496  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 4.2764  Validation loss = 1.9487  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 4.2761  Validation loss = 1.9483  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 4.2759  Validation loss = 1.9475  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 4.2756  Validation loss = 1.9468  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 4.2753  Validation loss = 1.9464  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 4.2750  Validation loss = 1.9459  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 4.2747  Validation loss = 1.9456  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 4.2744  Validation loss = 1.9452  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 4.2741  Validation loss = 1.9447  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 4.2738  Validation loss = 1.9442  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 4.2736  Validation loss = 1.9438  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 4.2733  Validation loss = 1.9431  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 4.2730  Validation loss = 1.9425  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 4.2728  Validation loss = 1.9420  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 4.2726  Validation loss = 1.9414  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 4.2723  Validation loss = 1.9407  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 4.2721  Validation loss = 1.9399  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 4.2719  Validation loss = 1.9394  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 4.2716  Validation loss = 1.9387  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 4.2713  Validation loss = 1.9383  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 4.2710  Validation loss = 1.9378  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 4.2707  Validation loss = 1.9374  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 4.2705  Validation loss = 1.9369  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 4.2702  Validation loss = 1.9360  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 4.2699  Validation loss = 1.9352  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 4.2696  Validation loss = 1.9345  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 4.2693  Validation loss = 1.9341  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 4.2690  Validation loss = 1.9334  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 4.2687  Validation loss = 1.9328  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 4.2684  Validation loss = 1.9322  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 4.2682  Validation loss = 1.9318  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 4.2679  Validation loss = 1.9309  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 4.2677  Validation loss = 1.9306  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 4.2673  Validation loss = 1.9301  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 4.2671  Validation loss = 1.9295  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 4.2670  Validation loss = 1.9294  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 4.2667  Validation loss = 1.9288  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 4.2664  Validation loss = 1.9282  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 4.2662  Validation loss = 1.9275  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 4.2660  Validation loss = 1.9269  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 4.2656  Validation loss = 1.9264  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 4.2654  Validation loss = 1.9259  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 4.2651  Validation loss = 1.9254  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 4.2649  Validation loss = 1.9248  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 4.2647  Validation loss = 1.9245  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 4.2644  Validation loss = 1.9242  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 4.2642  Validation loss = 1.9237  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 4.2638  Validation loss = 1.9230  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 4.2636  Validation loss = 1.9224  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 4.2632  Validation loss = 1.9215  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 4.2629  Validation loss = 1.9212  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 4.2627  Validation loss = 1.9208  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 4.2625  Validation loss = 1.9203  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 4.2622  Validation loss = 1.9196  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 4.2619  Validation loss = 1.9191  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 4.2617  Validation loss = 1.9185  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 4.2614  Validation loss = 1.9178  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 4.2612  Validation loss = 1.9175  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 4.2609  Validation loss = 1.9168  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 4.2606  Validation loss = 1.9161  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 4.2604  Validation loss = 1.9158  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 4.2601  Validation loss = 1.9153  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 4.2598  Validation loss = 1.9145  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 4.2597  Validation loss = 1.9141  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 4.2593  Validation loss = 1.9137  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 4.2590  Validation loss = 1.9130  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 4.2588  Validation loss = 1.9123  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 4.2585  Validation loss = 1.9117  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 4.2583  Validation loss = 1.9111  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 4.2581  Validation loss = 1.9107  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 4.2578  Validation loss = 1.9095  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 4.2576  Validation loss = 1.9089  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 4.2573  Validation loss = 1.9082  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 4.2570  Validation loss = 1.9076  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 4.2567  Validation loss = 1.9069  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 4.2564  Validation loss = 1.9063  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 4.2562  Validation loss = 1.9059  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 4.2560  Validation loss = 1.9050  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 4.2558  Validation loss = 1.9047  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 4.2555  Validation loss = 1.9042  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 4.2553  Validation loss = 1.9037  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 4.2550  Validation loss = 1.9033  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 4.2548  Validation loss = 1.9028  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 4.2545  Validation loss = 1.9022  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 4.2543  Validation loss = 1.9017  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 4.2540  Validation loss = 1.9007  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 4.2537  Validation loss = 1.9003  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 4.2534  Validation loss = 1.8997  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 4.2532  Validation loss = 1.8993  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 4.2530  Validation loss = 1.8989  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 4.2528  Validation loss = 1.8985  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 4.2526  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 4.2522  Validation loss = 1.8969  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 4.2519  Validation loss = 1.8964  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 4.2516  Validation loss = 1.8959  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 4.2513  Validation loss = 1.8952  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 4.2511  Validation loss = 1.8947  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 4.2508  Validation loss = 1.8943  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 4.2505  Validation loss = 1.8939  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 4.2502  Validation loss = 1.8936  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 4.2500  Validation loss = 1.8929  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 4.2497  Validation loss = 1.8924  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 4.2494  Validation loss = 1.8919  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 4.2492  Validation loss = 1.8914  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 4.2490  Validation loss = 1.8911  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 4.2488  Validation loss = 1.8906  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 4.2485  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 4.2483  Validation loss = 1.8894  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 4.2480  Validation loss = 1.8889  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 4.2479  Validation loss = 1.8887  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 4.2476  Validation loss = 1.8881  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 4.2474  Validation loss = 1.8879  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 4.2470  Validation loss = 1.8875  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 4.2468  Validation loss = 1.8870  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 4.2465  Validation loss = 1.8863  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 4.2463  Validation loss = 1.8859  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 4.2460  Validation loss = 1.8850  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 4.2458  Validation loss = 1.8846  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 4.2454  Validation loss = 1.8840  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 4.2452  Validation loss = 1.8836  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 4.2450  Validation loss = 1.8830  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 4.2447  Validation loss = 1.8823  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 4.2446  Validation loss = 1.8822  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 4.2444  Validation loss = 1.8816  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 4.2442  Validation loss = 1.8812  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 4.2439  Validation loss = 1.8807  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 4.2437  Validation loss = 1.8805  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 4.2435  Validation loss = 1.8800  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 4.2433  Validation loss = 1.8797  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 4.2431  Validation loss = 1.8794  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 4.2428  Validation loss = 1.8789  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 4.2425  Validation loss = 1.8781  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 4.2422  Validation loss = 1.8772  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 4.2420  Validation loss = 1.8768  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 4.2417  Validation loss = 1.8760  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 4.2415  Validation loss = 1.8754  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 4.2413  Validation loss = 1.8752  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 4.2411  Validation loss = 1.8747  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 4.2408  Validation loss = 1.8739  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 4.2405  Validation loss = 1.8734  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 4.2402  Validation loss = 1.8731  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 4.2401  Validation loss = 1.8727  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 4.2398  Validation loss = 1.8722  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 4.2396  Validation loss = 1.8718  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 4.2393  Validation loss = 1.8714  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 4.2391  Validation loss = 1.8708  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 4.2388  Validation loss = 1.8705  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 4.2386  Validation loss = 1.8697  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 4.2384  Validation loss = 1.8691  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 4.2382  Validation loss = 1.8687  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 4.2380  Validation loss = 1.8684  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 4.2378  Validation loss = 1.8680  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 4.2376  Validation loss = 1.8676  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 4.2373  Validation loss = 1.8670  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 4.2371  Validation loss = 1.8665  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 4.2368  Validation loss = 1.8660  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 4.2366  Validation loss = 1.8657  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 4.2364  Validation loss = 1.8652  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 4.2361  Validation loss = 1.8645  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 4.2359  Validation loss = 1.8639  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 4.2357  Validation loss = 1.8635  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 4.2355  Validation loss = 1.8631  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 4.2353  Validation loss = 1.8625  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 4.2351  Validation loss = 1.8620  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 4.2349  Validation loss = 1.8615  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 4.2347  Validation loss = 1.8611  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 4.2345  Validation loss = 1.8608  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 4.2344  Validation loss = 1.8603  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 4.2341  Validation loss = 1.8597  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 4.2338  Validation loss = 1.8593  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 4.2337  Validation loss = 1.8587  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 4.2334  Validation loss = 1.8582  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 4.2331  Validation loss = 1.8576  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 4.2329  Validation loss = 1.8572  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 4.2328  Validation loss = 1.8570  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 4.2326  Validation loss = 1.8567  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 4.2324  Validation loss = 1.8564  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 4.2321  Validation loss = 1.8554  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 4.2319  Validation loss = 1.8548  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 4.2317  Validation loss = 1.8544  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 4.2315  Validation loss = 1.8540  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 4.2312  Validation loss = 1.8535  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 4.2310  Validation loss = 1.8532  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 4.2308  Validation loss = 1.8527  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 4.2305  Validation loss = 1.8519  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 4.2302  Validation loss = 1.8514  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 4.2300  Validation loss = 1.8508  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 4.2298  Validation loss = 1.8504  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 4.2296  Validation loss = 1.8499  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 4.2293  Validation loss = 1.8491  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 4.2290  Validation loss = 1.8485  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 4.2288  Validation loss = 1.8480  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 4.2286  Validation loss = 1.8474  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 4.2284  Validation loss = 1.8470  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 4.2281  Validation loss = 1.8464  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 4.2279  Validation loss = 1.8459  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 4.2276  Validation loss = 1.8453  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 4.2273  Validation loss = 1.8450  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 4.2271  Validation loss = 1.8442  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 4.2269  Validation loss = 1.8441  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 4.2267  Validation loss = 1.8437  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 4.2264  Validation loss = 1.8431  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 4.2262  Validation loss = 1.8426  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 4.2260  Validation loss = 1.8419  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 4.2258  Validation loss = 1.8416  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 4.2256  Validation loss = 1.8414  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 4.2254  Validation loss = 1.8407  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 4.2251  Validation loss = 1.8402  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 4.2249  Validation loss = 1.8398  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 4.2247  Validation loss = 1.8396  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 4.2244  Validation loss = 1.8387  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 4.2241  Validation loss = 1.8383  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 4.2239  Validation loss = 1.8380  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 4.2236  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 4.2234  Validation loss = 1.8371  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 4.2232  Validation loss = 1.8369  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 4.2229  Validation loss = 1.8366  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 4.2228  Validation loss = 1.8362  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 4.2225  Validation loss = 1.8358  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 4.2223  Validation loss = 1.8354  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 4.2221  Validation loss = 1.8350  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 4.2219  Validation loss = 1.8347  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 4.2217  Validation loss = 1.8343  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 4.2215  Validation loss = 1.8340  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 4.2213  Validation loss = 1.8335  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 4.2211  Validation loss = 1.8332  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 4.2209  Validation loss = 1.8329  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 4.2207  Validation loss = 1.8327  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 4.2205  Validation loss = 1.8322  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 4.2202  Validation loss = 1.8317  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 4.2200  Validation loss = 1.8312  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 4.2198  Validation loss = 1.8308  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 4.2197  Validation loss = 1.8305  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 4.2194  Validation loss = 1.8298  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 4.2192  Validation loss = 1.8291  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 4.2190  Validation loss = 1.8287  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 4.2187  Validation loss = 1.8282  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 4.2185  Validation loss = 1.8278  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 4.2183  Validation loss = 1.8273  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 4.2180  Validation loss = 1.8268  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 4.2178  Validation loss = 1.8261  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 4.2176  Validation loss = 1.8258  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 4.2175  Validation loss = 1.8253  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 4.2173  Validation loss = 1.8248  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 4.2172  Validation loss = 1.8248  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 4.2169  Validation loss = 1.8242  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 4.2168  Validation loss = 1.8239  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 4.2165  Validation loss = 1.8234  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 4.2163  Validation loss = 1.8230  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 4.2160  Validation loss = 1.8224  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 4.2158  Validation loss = 1.8220  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 4.2155  Validation loss = 1.8213  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 4.2154  Validation loss = 1.8210  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 4.2151  Validation loss = 1.8204  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 4.2150  Validation loss = 1.8203  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 4.2148  Validation loss = 1.8200  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 4.2145  Validation loss = 1.8196  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 4.2143  Validation loss = 1.8191  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 4.2141  Validation loss = 1.8185  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 4.2139  Validation loss = 1.8182  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 4.2137  Validation loss = 1.8175  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 4.2135  Validation loss = 1.8172  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 4.2133  Validation loss = 1.8167  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 4.2130  Validation loss = 1.8161  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 4.2128  Validation loss = 1.8159  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 4.2126  Validation loss = 1.8153  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 4.2123  Validation loss = 1.8151  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 4.2121  Validation loss = 1.8146  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 4.2119  Validation loss = 1.8139  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 4.2116  Validation loss = 1.8133  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 4.2114  Validation loss = 1.8127  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 4.2112  Validation loss = 1.8122  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 4.2110  Validation loss = 1.8115  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 4.2108  Validation loss = 1.8111  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 4.2105  Validation loss = 1.8105  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 4.2103  Validation loss = 1.8100  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 4.2100  Validation loss = 1.8096  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 4.2099  Validation loss = 1.8091  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 4.2097  Validation loss = 1.8088  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 4.2095  Validation loss = 1.8084  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 4.2092  Validation loss = 1.8080  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 4.2090  Validation loss = 1.8077  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 4.2088  Validation loss = 1.8071  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 4.2086  Validation loss = 1.8064  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 4.2084  Validation loss = 1.8060  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 4.2082  Validation loss = 1.8056  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 4.2080  Validation loss = 1.8055  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 4.2078  Validation loss = 1.8050  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 4.2075  Validation loss = 1.8045  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 4.2073  Validation loss = 1.8042  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 4.2071  Validation loss = 1.8039  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 4.2069  Validation loss = 1.8035  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 4.2067  Validation loss = 1.8027  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 4.2065  Validation loss = 1.8024  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 4.2063  Validation loss = 1.8019  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 4.2062  Validation loss = 1.8018  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 4.2059  Validation loss = 1.8015  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 4.2057  Validation loss = 1.8008  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 4.2055  Validation loss = 1.8004  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 4.2052  Validation loss = 1.8001  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 4.2050  Validation loss = 1.7994  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 4.2048  Validation loss = 1.7990  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 4.2046  Validation loss = 1.7986  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 4.2045  Validation loss = 1.7981  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 4.2043  Validation loss = 1.7977  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 4.2041  Validation loss = 1.7974  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 4.2039  Validation loss = 1.7972  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 4.2037  Validation loss = 1.7965  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 4.2034  Validation loss = 1.7959  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 4.2033  Validation loss = 1.7957  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 4.2031  Validation loss = 1.7954  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 4.2029  Validation loss = 1.7949  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 4.2027  Validation loss = 1.7942  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 4.2025  Validation loss = 1.7938  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 4.2022  Validation loss = 1.7932  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 4.2021  Validation loss = 1.7929  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 4.2018  Validation loss = 1.7924  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 4.2016  Validation loss = 1.7918  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 4.2015  Validation loss = 1.7915  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 4.2012  Validation loss = 1.7909  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 4.2010  Validation loss = 1.7903  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 4.2009  Validation loss = 1.7899  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 4.2007  Validation loss = 1.7894  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 4.2005  Validation loss = 1.7891  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 4.2002  Validation loss = 1.7888  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 4.2001  Validation loss = 1.7885  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 4.1998  Validation loss = 1.7879  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 4.1996  Validation loss = 1.7872  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 4.1994  Validation loss = 1.7868  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 4.1992  Validation loss = 1.7864  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 4.1990  Validation loss = 1.7858  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 4.1988  Validation loss = 1.7854  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 4.1985  Validation loss = 1.7850  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 4.1983  Validation loss = 1.7845  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 4.1981  Validation loss = 1.7841  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 4.1978  Validation loss = 1.7835  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 4.1976  Validation loss = 1.7832  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 4.1974  Validation loss = 1.7825  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 4.1973  Validation loss = 1.7821  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 4.1971  Validation loss = 1.7816  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 4.1969  Validation loss = 1.7814  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 4.1967  Validation loss = 1.7810  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 4.1965  Validation loss = 1.7807  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 4.1963  Validation loss = 1.7803  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 4.1961  Validation loss = 1.7801  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 4.1958  Validation loss = 1.7796  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 4.1957  Validation loss = 1.7792  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 4.1955  Validation loss = 1.7788  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 4.1953  Validation loss = 1.7784  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 4.1950  Validation loss = 1.7779  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 4.1948  Validation loss = 1.7774  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 4.1946  Validation loss = 1.7768  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 4.1945  Validation loss = 1.7764  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 4.1942  Validation loss = 1.7758  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 4.1939  Validation loss = 1.7752  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 4.1937  Validation loss = 1.7747  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 4.1935  Validation loss = 1.7740  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 4.1932  Validation loss = 1.7737  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 4.1930  Validation loss = 1.7733  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 4.1927  Validation loss = 1.7727  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 4.1925  Validation loss = 1.7723  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 4.1923  Validation loss = 1.7718  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 4.1920  Validation loss = 1.7716  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 4.1918  Validation loss = 1.7710  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 4.1916  Validation loss = 1.7705  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 4.1914  Validation loss = 1.7698  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 4.1912  Validation loss = 1.7694  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 4.1911  Validation loss = 1.7690  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 4.1908  Validation loss = 1.7682  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 4.1906  Validation loss = 1.7675  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 4.1903  Validation loss = 1.7668  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 4.1901  Validation loss = 1.7662  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 4.1899  Validation loss = 1.7657  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 4.1896  Validation loss = 1.7653  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 4.1895  Validation loss = 1.7649  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 4.1892  Validation loss = 1.7643  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 4.1891  Validation loss = 1.7639  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 4.1889  Validation loss = 1.7635  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 4.1887  Validation loss = 1.7631  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 4.1884  Validation loss = 1.7627  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 4.1882  Validation loss = 1.7622  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 4.1880  Validation loss = 1.7617  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 4.1879  Validation loss = 1.7616  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 4.1877  Validation loss = 1.7612  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 4.1875  Validation loss = 1.7606  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 4.1873  Validation loss = 1.7602  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 4.1872  Validation loss = 1.7600  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 4.1869  Validation loss = 1.7594  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 4.1868  Validation loss = 1.7593  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 4.1866  Validation loss = 1.7587  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 4.1863  Validation loss = 1.7578  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 4.1861  Validation loss = 1.7570  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 4.1859  Validation loss = 1.7566  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 4.1857  Validation loss = 1.7563  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 4.1854  Validation loss = 1.7559  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 4.1852  Validation loss = 1.7554  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 4.1850  Validation loss = 1.7549  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 4.1848  Validation loss = 1.7543  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 4.1846  Validation loss = 1.7537  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 4.1844  Validation loss = 1.7531  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 4.1842  Validation loss = 1.7527  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 4.1839  Validation loss = 1.7521  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 4.1836  Validation loss = 1.7514  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 4.1834  Validation loss = 1.7508  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 4.1833  Validation loss = 1.7504  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 4.1831  Validation loss = 1.7501  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 4.1829  Validation loss = 1.7498  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 4.1827  Validation loss = 1.7491  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 4.1824  Validation loss = 1.7484  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 4.1822  Validation loss = 1.7480  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 4.1820  Validation loss = 1.7477  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 4.1817  Validation loss = 1.7474  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 4.1816  Validation loss = 1.7469  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 4.1814  Validation loss = 1.7465  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 4.1812  Validation loss = 1.7459  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 4.1810  Validation loss = 1.7455  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 4.1808  Validation loss = 1.7449  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 4.1806  Validation loss = 1.7445  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 4.1805  Validation loss = 1.7442  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 4.1802  Validation loss = 1.7438  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 4.1801  Validation loss = 1.7434  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 4.1798  Validation loss = 1.7429  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 4.1796  Validation loss = 1.7425  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 4.1793  Validation loss = 1.7420  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 4.1791  Validation loss = 1.7416  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 4.1789  Validation loss = 1.7410  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 4.1788  Validation loss = 1.7407  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 4.1786  Validation loss = 1.7402  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 4.1784  Validation loss = 1.7398  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 4.1781  Validation loss = 1.7395  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 4.1779  Validation loss = 1.7390  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 4.1776  Validation loss = 1.7386  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 4.1774  Validation loss = 1.7381  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 4.1773  Validation loss = 1.7379  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 4.1770  Validation loss = 1.7376  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 4.1769  Validation loss = 1.7369  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 4.1767  Validation loss = 1.7363  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 4.1764  Validation loss = 1.7360  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 4.1763  Validation loss = 1.7355  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 4.1761  Validation loss = 1.7354  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 4.1759  Validation loss = 1.7348  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 4.1757  Validation loss = 1.7347  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 4.1755  Validation loss = 1.7341  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 4.1753  Validation loss = 1.7338  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 4.1750  Validation loss = 1.7335  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 4.1748  Validation loss = 1.7329  \n",
      "\n",
      "Fold: 24  Epoch: 501  Training loss = 4.1746  Validation loss = 1.7326  \n",
      "\n",
      "Fold: 24  Epoch: 502  Training loss = 4.1745  Validation loss = 1.7323  \n",
      "\n",
      "Fold: 24  Epoch: 503  Training loss = 4.1743  Validation loss = 1.7321  \n",
      "\n",
      "Fold: 24  Epoch: 504  Training loss = 4.1741  Validation loss = 1.7314  \n",
      "\n",
      "Fold: 24  Epoch: 505  Training loss = 4.1739  Validation loss = 1.7310  \n",
      "\n",
      "Fold: 24  Epoch: 506  Training loss = 4.1737  Validation loss = 1.7306  \n",
      "\n",
      "Fold: 24  Epoch: 507  Training loss = 4.1735  Validation loss = 1.7302  \n",
      "\n",
      "Fold: 24  Epoch: 508  Training loss = 4.1733  Validation loss = 1.7298  \n",
      "\n",
      "Fold: 24  Epoch: 509  Training loss = 4.1731  Validation loss = 1.7293  \n",
      "\n",
      "Fold: 24  Epoch: 510  Training loss = 4.1729  Validation loss = 1.7287  \n",
      "\n",
      "Fold: 24  Epoch: 511  Training loss = 4.1728  Validation loss = 1.7282  \n",
      "\n",
      "Fold: 24  Epoch: 512  Training loss = 4.1726  Validation loss = 1.7279  \n",
      "\n",
      "Fold: 24  Epoch: 513  Training loss = 4.1724  Validation loss = 1.7274  \n",
      "\n",
      "Fold: 24  Epoch: 514  Training loss = 4.1722  Validation loss = 1.7269  \n",
      "\n",
      "Fold: 24  Epoch: 515  Training loss = 4.1720  Validation loss = 1.7263  \n",
      "\n",
      "Fold: 24  Epoch: 516  Training loss = 4.1719  Validation loss = 1.7260  \n",
      "\n",
      "Fold: 24  Epoch: 517  Training loss = 4.1717  Validation loss = 1.7255  \n",
      "\n",
      "Fold: 24  Epoch: 518  Training loss = 4.1715  Validation loss = 1.7250  \n",
      "\n",
      "Fold: 24  Epoch: 519  Training loss = 4.1714  Validation loss = 1.7246  \n",
      "\n",
      "Fold: 24  Epoch: 520  Training loss = 4.1712  Validation loss = 1.7242  \n",
      "\n",
      "Fold: 24  Epoch: 521  Training loss = 4.1710  Validation loss = 1.7235  \n",
      "\n",
      "Fold: 24  Epoch: 522  Training loss = 4.1708  Validation loss = 1.7231  \n",
      "\n",
      "Fold: 24  Epoch: 523  Training loss = 4.1706  Validation loss = 1.7226  \n",
      "\n",
      "Fold: 24  Epoch: 524  Training loss = 4.1704  Validation loss = 1.7222  \n",
      "\n",
      "Fold: 24  Epoch: 525  Training loss = 4.1702  Validation loss = 1.7219  \n",
      "\n",
      "Fold: 24  Epoch: 526  Training loss = 4.1701  Validation loss = 1.7214  \n",
      "\n",
      "Fold: 24  Epoch: 527  Training loss = 4.1698  Validation loss = 1.7206  \n",
      "\n",
      "Fold: 24  Epoch: 528  Training loss = 4.1696  Validation loss = 1.7202  \n",
      "\n",
      "Fold: 24  Epoch: 529  Training loss = 4.1694  Validation loss = 1.7198  \n",
      "\n",
      "Fold: 24  Epoch: 530  Training loss = 4.1692  Validation loss = 1.7194  \n",
      "\n",
      "Fold: 24  Epoch: 531  Training loss = 4.1691  Validation loss = 1.7192  \n",
      "\n",
      "Fold: 24  Epoch: 532  Training loss = 4.1689  Validation loss = 1.7188  \n",
      "\n",
      "Fold: 24  Epoch: 533  Training loss = 4.1687  Validation loss = 1.7188  \n",
      "\n",
      "Fold: 24  Epoch: 534  Training loss = 4.1685  Validation loss = 1.7183  \n",
      "\n",
      "Fold: 24  Epoch: 535  Training loss = 4.1683  Validation loss = 1.7178  \n",
      "\n",
      "Fold: 24  Epoch: 536  Training loss = 4.1681  Validation loss = 1.7173  \n",
      "\n",
      "Fold: 24  Epoch: 537  Training loss = 4.1679  Validation loss = 1.7169  \n",
      "\n",
      "Fold: 24  Epoch: 538  Training loss = 4.1678  Validation loss = 1.7165  \n",
      "\n",
      "Fold: 24  Epoch: 539  Training loss = 4.1676  Validation loss = 1.7161  \n",
      "\n",
      "Fold: 24  Epoch: 540  Training loss = 4.1674  Validation loss = 1.7155  \n",
      "\n",
      "Fold: 24  Epoch: 541  Training loss = 4.1672  Validation loss = 1.7150  \n",
      "\n",
      "Fold: 24  Epoch: 542  Training loss = 4.1669  Validation loss = 1.7147  \n",
      "\n",
      "Fold: 24  Epoch: 543  Training loss = 4.1667  Validation loss = 1.7141  \n",
      "\n",
      "Fold: 24  Epoch: 544  Training loss = 4.1666  Validation loss = 1.7137  \n",
      "\n",
      "Fold: 24  Epoch: 545  Training loss = 4.1664  Validation loss = 1.7130  \n",
      "\n",
      "Fold: 24  Epoch: 546  Training loss = 4.1662  Validation loss = 1.7124  \n",
      "\n",
      "Fold: 24  Epoch: 547  Training loss = 4.1661  Validation loss = 1.7120  \n",
      "\n",
      "Fold: 24  Epoch: 548  Training loss = 4.1659  Validation loss = 1.7116  \n",
      "\n",
      "Fold: 24  Epoch: 549  Training loss = 4.1657  Validation loss = 1.7108  \n",
      "\n",
      "Fold: 24  Epoch: 550  Training loss = 4.1655  Validation loss = 1.7107  \n",
      "\n",
      "Fold: 24  Epoch: 551  Training loss = 4.1654  Validation loss = 1.7101  \n",
      "\n",
      "Fold: 24  Epoch: 552  Training loss = 4.1652  Validation loss = 1.7098  \n",
      "\n",
      "Fold: 24  Epoch: 553  Training loss = 4.1650  Validation loss = 1.7096  \n",
      "\n",
      "Fold: 24  Epoch: 554  Training loss = 4.1648  Validation loss = 1.7091  \n",
      "\n",
      "Fold: 24  Epoch: 555  Training loss = 4.1646  Validation loss = 1.7087  \n",
      "\n",
      "Fold: 24  Epoch: 556  Training loss = 4.1644  Validation loss = 1.7083  \n",
      "\n",
      "Fold: 24  Epoch: 557  Training loss = 4.1642  Validation loss = 1.7080  \n",
      "\n",
      "Fold: 24  Epoch: 558  Training loss = 4.1641  Validation loss = 1.7076  \n",
      "\n",
      "Fold: 24  Epoch: 559  Training loss = 4.1639  Validation loss = 1.7072  \n",
      "\n",
      "Fold: 24  Epoch: 560  Training loss = 4.1637  Validation loss = 1.7064  \n",
      "\n",
      "Fold: 24  Epoch: 561  Training loss = 4.1636  Validation loss = 1.7062  \n",
      "\n",
      "Fold: 24  Epoch: 562  Training loss = 4.1633  Validation loss = 1.7057  \n",
      "\n",
      "Fold: 24  Epoch: 563  Training loss = 4.1631  Validation loss = 1.7054  \n",
      "\n",
      "Fold: 24  Epoch: 564  Training loss = 4.1630  Validation loss = 1.7048  \n",
      "\n",
      "Fold: 24  Epoch: 565  Training loss = 4.1628  Validation loss = 1.7043  \n",
      "\n",
      "Fold: 24  Epoch: 566  Training loss = 4.1626  Validation loss = 1.7036  \n",
      "\n",
      "Fold: 24  Epoch: 567  Training loss = 4.1624  Validation loss = 1.7032  \n",
      "\n",
      "Fold: 24  Epoch: 568  Training loss = 4.1622  Validation loss = 1.7026  \n",
      "\n",
      "Fold: 24  Epoch: 569  Training loss = 4.1621  Validation loss = 1.7023  \n",
      "\n",
      "Fold: 24  Epoch: 570  Training loss = 4.1619  Validation loss = 1.7019  \n",
      "\n",
      "Fold: 24  Epoch: 571  Training loss = 4.1617  Validation loss = 1.7017  \n",
      "\n",
      "Fold: 24  Epoch: 572  Training loss = 4.1616  Validation loss = 1.7012  \n",
      "\n",
      "Fold: 24  Epoch: 573  Training loss = 4.1614  Validation loss = 1.7003  \n",
      "\n",
      "Fold: 24  Epoch: 574  Training loss = 4.1612  Validation loss = 1.6998  \n",
      "\n",
      "Fold: 24  Epoch: 575  Training loss = 4.1610  Validation loss = 1.6994  \n",
      "\n",
      "Fold: 24  Epoch: 576  Training loss = 4.1608  Validation loss = 1.6990  \n",
      "\n",
      "Fold: 24  Epoch: 577  Training loss = 4.1607  Validation loss = 1.6986  \n",
      "\n",
      "Fold: 24  Epoch: 578  Training loss = 4.1606  Validation loss = 1.6985  \n",
      "\n",
      "Fold: 24  Epoch: 579  Training loss = 4.1604  Validation loss = 1.6980  \n",
      "\n",
      "Fold: 24  Epoch: 580  Training loss = 4.1602  Validation loss = 1.6976  \n",
      "\n",
      "Fold: 24  Epoch: 581  Training loss = 4.1601  Validation loss = 1.6973  \n",
      "\n",
      "Fold: 24  Epoch: 582  Training loss = 4.1599  Validation loss = 1.6967  \n",
      "\n",
      "Fold: 24  Epoch: 583  Training loss = 4.1597  Validation loss = 1.6963  \n",
      "\n",
      "Fold: 24  Epoch: 584  Training loss = 4.1595  Validation loss = 1.6959  \n",
      "\n",
      "Fold: 24  Epoch: 585  Training loss = 4.1593  Validation loss = 1.6955  \n",
      "\n",
      "Fold: 24  Epoch: 586  Training loss = 4.1591  Validation loss = 1.6951  \n",
      "\n",
      "Fold: 24  Epoch: 587  Training loss = 4.1589  Validation loss = 1.6949  \n",
      "\n",
      "Fold: 24  Epoch: 588  Training loss = 4.1587  Validation loss = 1.6943  \n",
      "\n",
      "Fold: 24  Epoch: 589  Training loss = 4.1586  Validation loss = 1.6939  \n",
      "\n",
      "Fold: 24  Epoch: 590  Training loss = 4.1583  Validation loss = 1.6936  \n",
      "\n",
      "Fold: 24  Epoch: 591  Training loss = 4.1582  Validation loss = 1.6930  \n",
      "\n",
      "Fold: 24  Epoch: 592  Training loss = 4.1580  Validation loss = 1.6926  \n",
      "\n",
      "Fold: 24  Epoch: 593  Training loss = 4.1578  Validation loss = 1.6919  \n",
      "\n",
      "Fold: 24  Epoch: 594  Training loss = 4.1576  Validation loss = 1.6913  \n",
      "\n",
      "Fold: 24  Epoch: 595  Training loss = 4.1574  Validation loss = 1.6912  \n",
      "\n",
      "Fold: 24  Epoch: 596  Training loss = 4.1572  Validation loss = 1.6905  \n",
      "\n",
      "Fold: 24  Epoch: 597  Training loss = 4.1571  Validation loss = 1.6898  \n",
      "\n",
      "Fold: 24  Epoch: 598  Training loss = 4.1568  Validation loss = 1.6894  \n",
      "\n",
      "Fold: 24  Epoch: 599  Training loss = 4.1567  Validation loss = 1.6888  \n",
      "\n",
      "Fold: 24  Epoch: 600  Training loss = 4.1565  Validation loss = 1.6885  \n",
      "\n",
      "Fold: 24  Epoch: 601  Training loss = 4.1564  Validation loss = 1.6882  \n",
      "\n",
      "Fold: 24  Epoch: 602  Training loss = 4.1562  Validation loss = 1.6879  \n",
      "\n",
      "Fold: 24  Epoch: 603  Training loss = 4.1560  Validation loss = 1.6870  \n",
      "\n",
      "Fold: 24  Epoch: 604  Training loss = 4.1557  Validation loss = 1.6866  \n",
      "\n",
      "Fold: 24  Epoch: 605  Training loss = 4.1556  Validation loss = 1.6861  \n",
      "\n",
      "Fold: 24  Epoch: 606  Training loss = 4.1554  Validation loss = 1.6860  \n",
      "\n",
      "Fold: 24  Epoch: 607  Training loss = 4.1552  Validation loss = 1.6854  \n",
      "\n",
      "Fold: 24  Epoch: 608  Training loss = 4.1550  Validation loss = 1.6849  \n",
      "\n",
      "Fold: 24  Epoch: 609  Training loss = 4.1549  Validation loss = 1.6844  \n",
      "\n",
      "Fold: 24  Epoch: 610  Training loss = 4.1546  Validation loss = 1.6839  \n",
      "\n",
      "Fold: 24  Epoch: 611  Training loss = 4.1544  Validation loss = 1.6836  \n",
      "\n",
      "Fold: 24  Epoch: 612  Training loss = 4.1542  Validation loss = 1.6833  \n",
      "\n",
      "Fold: 24  Epoch: 613  Training loss = 4.1541  Validation loss = 1.6829  \n",
      "\n",
      "Fold: 24  Epoch: 614  Training loss = 4.1539  Validation loss = 1.6825  \n",
      "\n",
      "Fold: 24  Epoch: 615  Training loss = 4.1537  Validation loss = 1.6822  \n",
      "\n",
      "Fold: 24  Epoch: 616  Training loss = 4.1536  Validation loss = 1.6814  \n",
      "\n",
      "Fold: 24  Epoch: 617  Training loss = 4.1534  Validation loss = 1.6810  \n",
      "\n",
      "Fold: 24  Epoch: 618  Training loss = 4.1533  Validation loss = 1.6807  \n",
      "\n",
      "Fold: 24  Epoch: 619  Training loss = 4.1531  Validation loss = 1.6799  \n",
      "\n",
      "Fold: 24  Epoch: 620  Training loss = 4.1529  Validation loss = 1.6793  \n",
      "\n",
      "Fold: 24  Epoch: 621  Training loss = 4.1528  Validation loss = 1.6791  \n",
      "\n",
      "Fold: 24  Epoch: 622  Training loss = 4.1526  Validation loss = 1.6784  \n",
      "\n",
      "Fold: 24  Epoch: 623  Training loss = 4.1525  Validation loss = 1.6779  \n",
      "\n",
      "Fold: 24  Epoch: 624  Training loss = 4.1523  Validation loss = 1.6779  \n",
      "\n",
      "Fold: 24  Epoch: 625  Training loss = 4.1521  Validation loss = 1.6774  \n",
      "\n",
      "Fold: 24  Epoch: 626  Training loss = 4.1520  Validation loss = 1.6768  \n",
      "\n",
      "Fold: 24  Epoch: 627  Training loss = 4.1518  Validation loss = 1.6764  \n",
      "\n",
      "Fold: 24  Epoch: 628  Training loss = 4.1517  Validation loss = 1.6757  \n",
      "\n",
      "Fold: 24  Epoch: 629  Training loss = 4.1516  Validation loss = 1.6752  \n",
      "\n",
      "Fold: 24  Epoch: 630  Training loss = 4.1514  Validation loss = 1.6749  \n",
      "\n",
      "Fold: 24  Epoch: 631  Training loss = 4.1512  Validation loss = 1.6746  \n",
      "\n",
      "Fold: 24  Epoch: 632  Training loss = 4.1510  Validation loss = 1.6741  \n",
      "\n",
      "Fold: 24  Epoch: 633  Training loss = 4.1508  Validation loss = 1.6739  \n",
      "\n",
      "Fold: 24  Epoch: 634  Training loss = 4.1507  Validation loss = 1.6733  \n",
      "\n",
      "Fold: 24  Epoch: 635  Training loss = 4.1504  Validation loss = 1.6727  \n",
      "\n",
      "Fold: 24  Epoch: 636  Training loss = 4.1503  Validation loss = 1.6722  \n",
      "\n",
      "Fold: 24  Epoch: 637  Training loss = 4.1501  Validation loss = 1.6717  \n",
      "\n",
      "Fold: 24  Epoch: 638  Training loss = 4.1499  Validation loss = 1.6710  \n",
      "\n",
      "Fold: 24  Epoch: 639  Training loss = 4.1497  Validation loss = 1.6704  \n",
      "\n",
      "Fold: 24  Epoch: 640  Training loss = 4.1495  Validation loss = 1.6699  \n",
      "\n",
      "Fold: 24  Epoch: 641  Training loss = 4.1493  Validation loss = 1.6696  \n",
      "\n",
      "Fold: 24  Epoch: 642  Training loss = 4.1492  Validation loss = 1.6693  \n",
      "\n",
      "Fold: 24  Epoch: 643  Training loss = 4.1490  Validation loss = 1.6687  \n",
      "\n",
      "Fold: 24  Epoch: 644  Training loss = 4.1488  Validation loss = 1.6679  \n",
      "\n",
      "Fold: 24  Epoch: 645  Training loss = 4.1486  Validation loss = 1.6678  \n",
      "\n",
      "Fold: 24  Epoch: 646  Training loss = 4.1484  Validation loss = 1.6672  \n",
      "\n",
      "Fold: 24  Epoch: 647  Training loss = 4.1483  Validation loss = 1.6671  \n",
      "\n",
      "Fold: 24  Epoch: 648  Training loss = 4.1481  Validation loss = 1.6665  \n",
      "\n",
      "Fold: 24  Epoch: 649  Training loss = 4.1479  Validation loss = 1.6659  \n",
      "\n",
      "Fold: 24  Epoch: 650  Training loss = 4.1477  Validation loss = 1.6655  \n",
      "\n",
      "Fold: 24  Epoch: 651  Training loss = 4.1475  Validation loss = 1.6651  \n",
      "\n",
      "Fold: 24  Epoch: 652  Training loss = 4.1473  Validation loss = 1.6648  \n",
      "\n",
      "Fold: 24  Epoch: 653  Training loss = 4.1471  Validation loss = 1.6638  \n",
      "\n",
      "Fold: 24  Epoch: 654  Training loss = 4.1468  Validation loss = 1.6634  \n",
      "\n",
      "Fold: 24  Epoch: 655  Training loss = 4.1466  Validation loss = 1.6631  \n",
      "\n",
      "Fold: 24  Epoch: 656  Training loss = 4.1463  Validation loss = 1.6628  \n",
      "\n",
      "Fold: 24  Epoch: 657  Training loss = 4.1461  Validation loss = 1.6619  \n",
      "\n",
      "Fold: 24  Epoch: 658  Training loss = 4.1459  Validation loss = 1.6613  \n",
      "\n",
      "Fold: 24  Epoch: 659  Training loss = 4.1458  Validation loss = 1.6610  \n",
      "\n",
      "Fold: 24  Epoch: 660  Training loss = 4.1456  Validation loss = 1.6603  \n",
      "\n",
      "Fold: 24  Epoch: 661  Training loss = 4.1455  Validation loss = 1.6599  \n",
      "\n",
      "Fold: 24  Epoch: 662  Training loss = 4.1453  Validation loss = 1.6595  \n",
      "\n",
      "Fold: 24  Epoch: 663  Training loss = 4.1452  Validation loss = 1.6590  \n",
      "\n",
      "Fold: 24  Epoch: 664  Training loss = 4.1450  Validation loss = 1.6586  \n",
      "\n",
      "Fold: 24  Epoch: 665  Training loss = 4.1448  Validation loss = 1.6582  \n",
      "\n",
      "Fold: 24  Epoch: 666  Training loss = 4.1446  Validation loss = 1.6579  \n",
      "\n",
      "Fold: 24  Epoch: 667  Training loss = 4.1443  Validation loss = 1.6575  \n",
      "\n",
      "Fold: 24  Epoch: 668  Training loss = 4.1441  Validation loss = 1.6570  \n",
      "\n",
      "Fold: 24  Epoch: 669  Training loss = 4.1439  Validation loss = 1.6567  \n",
      "\n",
      "Fold: 24  Epoch: 670  Training loss = 4.1437  Validation loss = 1.6563  \n",
      "\n",
      "Fold: 24  Epoch: 671  Training loss = 4.1436  Validation loss = 1.6559  \n",
      "\n",
      "Fold: 24  Epoch: 672  Training loss = 4.1434  Validation loss = 1.6557  \n",
      "\n",
      "Fold: 24  Epoch: 673  Training loss = 4.1432  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 24  Epoch: 674  Training loss = 4.1431  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 24  Epoch: 675  Training loss = 4.1429  Validation loss = 1.6548  \n",
      "\n",
      "Fold: 24  Epoch: 676  Training loss = 4.1427  Validation loss = 1.6546  \n",
      "\n",
      "Fold: 24  Epoch: 677  Training loss = 4.1425  Validation loss = 1.6543  \n",
      "\n",
      "Fold: 24  Epoch: 678  Training loss = 4.1423  Validation loss = 1.6538  \n",
      "\n",
      "Fold: 24  Epoch: 679  Training loss = 4.1422  Validation loss = 1.6533  \n",
      "\n",
      "Fold: 24  Epoch: 680  Training loss = 4.1420  Validation loss = 1.6531  \n",
      "\n",
      "Fold: 24  Epoch: 681  Training loss = 4.1418  Validation loss = 1.6529  \n",
      "\n",
      "Fold: 24  Epoch: 682  Training loss = 4.1417  Validation loss = 1.6523  \n",
      "\n",
      "Fold: 24  Epoch: 683  Training loss = 4.1415  Validation loss = 1.6518  \n",
      "\n",
      "Fold: 24  Epoch: 684  Training loss = 4.1413  Validation loss = 1.6513  \n",
      "\n",
      "Fold: 24  Epoch: 685  Training loss = 4.1411  Validation loss = 1.6510  \n",
      "\n",
      "Fold: 24  Epoch: 686  Training loss = 4.1410  Validation loss = 1.6508  \n",
      "\n",
      "Fold: 24  Epoch: 687  Training loss = 4.1408  Validation loss = 1.6504  \n",
      "\n",
      "Fold: 24  Epoch: 688  Training loss = 4.1406  Validation loss = 1.6500  \n",
      "\n",
      "Fold: 24  Epoch: 689  Training loss = 4.1404  Validation loss = 1.6494  \n",
      "\n",
      "Fold: 24  Epoch: 690  Training loss = 4.1402  Validation loss = 1.6492  \n",
      "\n",
      "Fold: 24  Epoch: 691  Training loss = 4.1400  Validation loss = 1.6489  \n",
      "\n",
      "Fold: 24  Epoch: 692  Training loss = 4.1399  Validation loss = 1.6484  \n",
      "\n",
      "Fold: 24  Epoch: 693  Training loss = 4.1397  Validation loss = 1.6481  \n",
      "\n",
      "Fold: 24  Epoch: 694  Training loss = 4.1395  Validation loss = 1.6475  \n",
      "\n",
      "Fold: 24  Epoch: 695  Training loss = 4.1393  Validation loss = 1.6468  \n",
      "\n",
      "Fold: 24  Epoch: 696  Training loss = 4.1391  Validation loss = 1.6468  \n",
      "\n",
      "Fold: 24  Epoch: 697  Training loss = 4.1389  Validation loss = 1.6463  \n",
      "\n",
      "Fold: 24  Epoch: 698  Training loss = 4.1387  Validation loss = 1.6458  \n",
      "\n",
      "Fold: 24  Epoch: 699  Training loss = 4.1385  Validation loss = 1.6453  \n",
      "\n",
      "Fold: 24  Epoch: 700  Training loss = 4.1383  Validation loss = 1.6448  \n",
      "\n",
      "Fold: 24  Epoch: 701  Training loss = 4.1381  Validation loss = 1.6444  \n",
      "\n",
      "Fold: 24  Epoch: 702  Training loss = 4.1379  Validation loss = 1.6440  \n",
      "\n",
      "Fold: 24  Epoch: 703  Training loss = 4.1377  Validation loss = 1.6434  \n",
      "\n",
      "Fold: 24  Epoch: 704  Training loss = 4.1375  Validation loss = 1.6431  \n",
      "\n",
      "Fold: 24  Epoch: 705  Training loss = 4.1374  Validation loss = 1.6427  \n",
      "\n",
      "Fold: 24  Epoch: 706  Training loss = 4.1372  Validation loss = 1.6421  \n",
      "\n",
      "Fold: 24  Epoch: 707  Training loss = 4.1370  Validation loss = 1.6418  \n",
      "\n",
      "Fold: 24  Epoch: 708  Training loss = 4.1368  Validation loss = 1.6416  \n",
      "\n",
      "Fold: 24  Epoch: 709  Training loss = 4.1366  Validation loss = 1.6410  \n",
      "\n",
      "Fold: 24  Epoch: 710  Training loss = 4.1365  Validation loss = 1.6409  \n",
      "\n",
      "Fold: 24  Epoch: 711  Training loss = 4.1363  Validation loss = 1.6407  \n",
      "\n",
      "Fold: 24  Epoch: 712  Training loss = 4.1361  Validation loss = 1.6405  \n",
      "\n",
      "Fold: 24  Epoch: 713  Training loss = 4.1359  Validation loss = 1.6399  \n",
      "\n",
      "Fold: 24  Epoch: 714  Training loss = 4.1358  Validation loss = 1.6397  \n",
      "\n",
      "Fold: 24  Epoch: 715  Training loss = 4.1356  Validation loss = 1.6392  \n",
      "\n",
      "Fold: 24  Epoch: 716  Training loss = 4.1355  Validation loss = 1.6388  \n",
      "\n",
      "Fold: 24  Epoch: 717  Training loss = 4.1353  Validation loss = 1.6382  \n",
      "\n",
      "Fold: 24  Epoch: 718  Training loss = 4.1351  Validation loss = 1.6378  \n",
      "\n",
      "Fold: 24  Epoch: 719  Training loss = 4.1349  Validation loss = 1.6375  \n",
      "\n",
      "Fold: 24  Epoch: 720  Training loss = 4.1346  Validation loss = 1.6371  \n",
      "\n",
      "Fold: 24  Epoch: 721  Training loss = 4.1345  Validation loss = 1.6369  \n",
      "\n",
      "Fold: 24  Epoch: 722  Training loss = 4.1343  Validation loss = 1.6363  \n",
      "\n",
      "Fold: 24  Epoch: 723  Training loss = 4.1341  Validation loss = 1.6361  \n",
      "\n",
      "Fold: 24  Epoch: 724  Training loss = 4.1340  Validation loss = 1.6358  \n",
      "\n",
      "Fold: 24  Epoch: 725  Training loss = 4.1338  Validation loss = 1.6356  \n",
      "\n",
      "Fold: 24  Epoch: 726  Training loss = 4.1336  Validation loss = 1.6353  \n",
      "\n",
      "Fold: 24  Epoch: 727  Training loss = 4.1335  Validation loss = 1.6346  \n",
      "\n",
      "Fold: 24  Epoch: 728  Training loss = 4.1333  Validation loss = 1.6343  \n",
      "\n",
      "Fold: 24  Epoch: 729  Training loss = 4.1331  Validation loss = 1.6338  \n",
      "\n",
      "Fold: 24  Epoch: 730  Training loss = 4.1329  Validation loss = 1.6332  \n",
      "\n",
      "Fold: 24  Epoch: 731  Training loss = 4.1328  Validation loss = 1.6327  \n",
      "\n",
      "Fold: 24  Epoch: 732  Training loss = 4.1326  Validation loss = 1.6323  \n",
      "\n",
      "Fold: 24  Epoch: 733  Training loss = 4.1325  Validation loss = 1.6320  \n",
      "\n",
      "Fold: 24  Epoch: 734  Training loss = 4.1324  Validation loss = 1.6317  \n",
      "\n",
      "Fold: 24  Epoch: 735  Training loss = 4.1322  Validation loss = 1.6314  \n",
      "\n",
      "Fold: 24  Epoch: 736  Training loss = 4.1319  Validation loss = 1.6311  \n",
      "\n",
      "Fold: 24  Epoch: 737  Training loss = 4.1318  Validation loss = 1.6309  \n",
      "\n",
      "Fold: 24  Epoch: 738  Training loss = 4.1317  Validation loss = 1.6305  \n",
      "\n",
      "Fold: 24  Epoch: 739  Training loss = 4.1315  Validation loss = 1.6300  \n",
      "\n",
      "Fold: 24  Epoch: 740  Training loss = 4.1312  Validation loss = 1.6293  \n",
      "\n",
      "Fold: 24  Epoch: 741  Training loss = 4.1311  Validation loss = 1.6290  \n",
      "\n",
      "Fold: 24  Epoch: 742  Training loss = 4.1309  Validation loss = 1.6286  \n",
      "\n",
      "Fold: 24  Epoch: 743  Training loss = 4.1308  Validation loss = 1.6285  \n",
      "\n",
      "Fold: 24  Epoch: 744  Training loss = 4.1306  Validation loss = 1.6283  \n",
      "\n",
      "Fold: 24  Epoch: 745  Training loss = 4.1304  Validation loss = 1.6278  \n",
      "\n",
      "Fold: 24  Epoch: 746  Training loss = 4.1303  Validation loss = 1.6274  \n",
      "\n",
      "Fold: 24  Epoch: 747  Training loss = 4.1300  Validation loss = 1.6269  \n",
      "\n",
      "Fold: 24  Epoch: 748  Training loss = 4.1299  Validation loss = 1.6265  \n",
      "\n",
      "Fold: 24  Epoch: 749  Training loss = 4.1298  Validation loss = 1.6264  \n",
      "\n",
      "Fold: 24  Epoch: 750  Training loss = 4.1295  Validation loss = 1.6262  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 750  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 4.0894  Validation loss = 2.6930  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 4.0892  Validation loss = 2.6926  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 4.0890  Validation loss = 2.6924  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 4.0888  Validation loss = 2.6921  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 4.0886  Validation loss = 2.6917  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 4.0884  Validation loss = 2.6913  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 4.0882  Validation loss = 2.6910  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 4.0880  Validation loss = 2.6908  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 4.0878  Validation loss = 2.6905  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 4.0876  Validation loss = 2.6901  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 4.0875  Validation loss = 2.6899  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 4.0872  Validation loss = 2.6895  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 4.0870  Validation loss = 2.6892  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 4.0869  Validation loss = 2.6891  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 4.0867  Validation loss = 2.6887  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 4.0865  Validation loss = 2.6884  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 4.0863  Validation loss = 2.6881  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 4.0861  Validation loss = 2.6879  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 4.0859  Validation loss = 2.6875  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 4.0857  Validation loss = 2.6873  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 4.0856  Validation loss = 2.6871  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 4.0854  Validation loss = 2.6868  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 4.0852  Validation loss = 2.6864  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 4.0850  Validation loss = 2.6861  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 4.0849  Validation loss = 2.6859  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 4.0847  Validation loss = 2.6855  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 4.0844  Validation loss = 2.6852  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 4.0842  Validation loss = 2.6847  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 4.0840  Validation loss = 2.6844  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 4.0838  Validation loss = 2.6842  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 4.0837  Validation loss = 2.6840  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 4.0836  Validation loss = 2.6838  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 4.0834  Validation loss = 2.6836  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 4.0831  Validation loss = 2.6832  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 4.0830  Validation loss = 2.6830  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 4.0828  Validation loss = 2.6829  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 4.0826  Validation loss = 2.6827  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 4.0825  Validation loss = 2.6823  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 4.0822  Validation loss = 2.6819  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 4.0820  Validation loss = 2.6816  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 4.0818  Validation loss = 2.6814  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 4.0816  Validation loss = 2.6810  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 4.0814  Validation loss = 2.6808  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 4.0812  Validation loss = 2.6805  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 4.0811  Validation loss = 2.6802  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 4.0810  Validation loss = 2.6800  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 4.0808  Validation loss = 2.6798  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 4.0806  Validation loss = 2.6794  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 4.0805  Validation loss = 2.6792  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 4.0804  Validation loss = 2.6791  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 4.0802  Validation loss = 2.6788  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 4.0801  Validation loss = 2.6787  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 4.0799  Validation loss = 2.6785  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 4.0797  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 4.0795  Validation loss = 2.6779  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 4.0794  Validation loss = 2.6776  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 4.0791  Validation loss = 2.6773  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 4.0790  Validation loss = 2.6772  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 4.0788  Validation loss = 2.6769  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 4.0786  Validation loss = 2.6766  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 4.0785  Validation loss = 2.6765  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 4.0783  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 4.0782  Validation loss = 2.6761  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 4.0780  Validation loss = 2.6758  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 4.0778  Validation loss = 2.6756  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 4.0776  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 4.0774  Validation loss = 2.6752  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 4.0773  Validation loss = 2.6750  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 4.0772  Validation loss = 2.6748  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 4.0770  Validation loss = 2.6746  \n",
      "\n",
      "Fold: 25  Epoch: 71  Training loss = 4.0768  Validation loss = 2.6742  \n",
      "\n",
      "Fold: 25  Epoch: 72  Training loss = 4.0766  Validation loss = 2.6737  \n",
      "\n",
      "Fold: 25  Epoch: 73  Training loss = 4.0764  Validation loss = 2.6734  \n",
      "\n",
      "Fold: 25  Epoch: 74  Training loss = 4.0762  Validation loss = 2.6732  \n",
      "\n",
      "Fold: 25  Epoch: 75  Training loss = 4.0760  Validation loss = 2.6728  \n",
      "\n",
      "Fold: 25  Epoch: 76  Training loss = 4.0758  Validation loss = 2.6725  \n",
      "\n",
      "Fold: 25  Epoch: 77  Training loss = 4.0757  Validation loss = 2.6724  \n",
      "\n",
      "Fold: 25  Epoch: 78  Training loss = 4.0755  Validation loss = 2.6722  \n",
      "\n",
      "Fold: 25  Epoch: 79  Training loss = 4.0753  Validation loss = 2.6719  \n",
      "\n",
      "Fold: 25  Epoch: 80  Training loss = 4.0752  Validation loss = 2.6717  \n",
      "\n",
      "Fold: 25  Epoch: 81  Training loss = 4.0750  Validation loss = 2.6715  \n",
      "\n",
      "Fold: 25  Epoch: 82  Training loss = 4.0749  Validation loss = 2.6714  \n",
      "\n",
      "Fold: 25  Epoch: 83  Training loss = 4.0747  Validation loss = 2.6711  \n",
      "\n",
      "Fold: 25  Epoch: 84  Training loss = 4.0744  Validation loss = 2.6707  \n",
      "\n",
      "Fold: 25  Epoch: 85  Training loss = 4.0742  Validation loss = 2.6705  \n",
      "\n",
      "Fold: 25  Epoch: 86  Training loss = 4.0741  Validation loss = 2.6704  \n",
      "\n",
      "Fold: 25  Epoch: 87  Training loss = 4.0740  Validation loss = 2.6703  \n",
      "\n",
      "Fold: 25  Epoch: 88  Training loss = 4.0738  Validation loss = 2.6701  \n",
      "\n",
      "Fold: 25  Epoch: 89  Training loss = 4.0736  Validation loss = 2.6699  \n",
      "\n",
      "Fold: 25  Epoch: 90  Training loss = 4.0735  Validation loss = 2.6696  \n",
      "\n",
      "Fold: 25  Epoch: 91  Training loss = 4.0732  Validation loss = 2.6691  \n",
      "\n",
      "Fold: 25  Epoch: 92  Training loss = 4.0730  Validation loss = 2.6688  \n",
      "\n",
      "Fold: 25  Epoch: 93  Training loss = 4.0728  Validation loss = 2.6684  \n",
      "\n",
      "Fold: 25  Epoch: 94  Training loss = 4.0726  Validation loss = 2.6682  \n",
      "\n",
      "Fold: 25  Epoch: 95  Training loss = 4.0724  Validation loss = 2.6680  \n",
      "\n",
      "Fold: 25  Epoch: 96  Training loss = 4.0723  Validation loss = 2.6677  \n",
      "\n",
      "Fold: 25  Epoch: 97  Training loss = 4.0721  Validation loss = 2.6676  \n",
      "\n",
      "Fold: 25  Epoch: 98  Training loss = 4.0719  Validation loss = 2.6672  \n",
      "\n",
      "Fold: 25  Epoch: 99  Training loss = 4.0717  Validation loss = 2.6669  \n",
      "\n",
      "Fold: 25  Epoch: 100  Training loss = 4.0715  Validation loss = 2.6665  \n",
      "\n",
      "Fold: 25  Epoch: 101  Training loss = 4.0713  Validation loss = 2.6663  \n",
      "\n",
      "Fold: 25  Epoch: 102  Training loss = 4.0710  Validation loss = 2.6658  \n",
      "\n",
      "Fold: 25  Epoch: 103  Training loss = 4.0708  Validation loss = 2.6656  \n",
      "\n",
      "Fold: 25  Epoch: 104  Training loss = 4.0706  Validation loss = 2.6652  \n",
      "\n",
      "Fold: 25  Epoch: 105  Training loss = 4.0705  Validation loss = 2.6650  \n",
      "\n",
      "Fold: 25  Epoch: 106  Training loss = 4.0704  Validation loss = 2.6650  \n",
      "\n",
      "Fold: 25  Epoch: 107  Training loss = 4.0703  Validation loss = 2.6649  \n",
      "\n",
      "Fold: 25  Epoch: 108  Training loss = 4.0700  Validation loss = 2.6644  \n",
      "\n",
      "Fold: 25  Epoch: 109  Training loss = 4.0699  Validation loss = 2.6642  \n",
      "\n",
      "Fold: 25  Epoch: 110  Training loss = 4.0697  Validation loss = 2.6640  \n",
      "\n",
      "Fold: 25  Epoch: 111  Training loss = 4.0695  Validation loss = 2.6637  \n",
      "\n",
      "Fold: 25  Epoch: 112  Training loss = 4.0694  Validation loss = 2.6634  \n",
      "\n",
      "Fold: 25  Epoch: 113  Training loss = 4.0692  Validation loss = 2.6632  \n",
      "\n",
      "Fold: 25  Epoch: 114  Training loss = 4.0691  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 25  Epoch: 115  Training loss = 4.0690  Validation loss = 2.6628  \n",
      "\n",
      "Fold: 25  Epoch: 116  Training loss = 4.0688  Validation loss = 2.6626  \n",
      "\n",
      "Fold: 25  Epoch: 117  Training loss = 4.0686  Validation loss = 2.6623  \n",
      "\n",
      "Fold: 25  Epoch: 118  Training loss = 4.0685  Validation loss = 2.6622  \n",
      "\n",
      "Fold: 25  Epoch: 119  Training loss = 4.0683  Validation loss = 2.6619  \n",
      "\n",
      "Fold: 25  Epoch: 120  Training loss = 4.0682  Validation loss = 2.6617  \n",
      "\n",
      "Fold: 25  Epoch: 121  Training loss = 4.0680  Validation loss = 2.6616  \n",
      "\n",
      "Fold: 25  Epoch: 122  Training loss = 4.0679  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 25  Epoch: 123  Training loss = 4.0677  Validation loss = 2.6610  \n",
      "\n",
      "Fold: 25  Epoch: 124  Training loss = 4.0675  Validation loss = 2.6607  \n",
      "\n",
      "Fold: 25  Epoch: 125  Training loss = 4.0673  Validation loss = 2.6604  \n",
      "\n",
      "Fold: 25  Epoch: 126  Training loss = 4.0671  Validation loss = 2.6600  \n",
      "\n",
      "Fold: 25  Epoch: 127  Training loss = 4.0669  Validation loss = 2.6597  \n",
      "\n",
      "Fold: 25  Epoch: 128  Training loss = 4.0668  Validation loss = 2.6594  \n",
      "\n",
      "Fold: 25  Epoch: 129  Training loss = 4.0666  Validation loss = 2.6590  \n",
      "\n",
      "Fold: 25  Epoch: 130  Training loss = 4.0664  Validation loss = 2.6588  \n",
      "\n",
      "Fold: 25  Epoch: 131  Training loss = 4.0663  Validation loss = 2.6587  \n",
      "\n",
      "Fold: 25  Epoch: 132  Training loss = 4.0661  Validation loss = 2.6585  \n",
      "\n",
      "Fold: 25  Epoch: 133  Training loss = 4.0659  Validation loss = 2.6583  \n",
      "\n",
      "Fold: 25  Epoch: 134  Training loss = 4.0658  Validation loss = 2.6579  \n",
      "\n",
      "Fold: 25  Epoch: 135  Training loss = 4.0656  Validation loss = 2.6576  \n",
      "\n",
      "Fold: 25  Epoch: 136  Training loss = 4.0654  Validation loss = 2.6573  \n",
      "\n",
      "Fold: 25  Epoch: 137  Training loss = 4.0653  Validation loss = 2.6571  \n",
      "\n",
      "Fold: 25  Epoch: 138  Training loss = 4.0651  Validation loss = 2.6569  \n",
      "\n",
      "Fold: 25  Epoch: 139  Training loss = 4.0649  Validation loss = 2.6567  \n",
      "\n",
      "Fold: 25  Epoch: 140  Training loss = 4.0647  Validation loss = 2.6563  \n",
      "\n",
      "Fold: 25  Epoch: 141  Training loss = 4.0645  Validation loss = 2.6561  \n",
      "\n",
      "Fold: 25  Epoch: 142  Training loss = 4.0644  Validation loss = 2.6559  \n",
      "\n",
      "Fold: 25  Epoch: 143  Training loss = 4.0642  Validation loss = 2.6558  \n",
      "\n",
      "Fold: 25  Epoch: 144  Training loss = 4.0640  Validation loss = 2.6557  \n",
      "\n",
      "Fold: 25  Epoch: 145  Training loss = 4.0639  Validation loss = 2.6556  \n",
      "\n",
      "Fold: 25  Epoch: 146  Training loss = 4.0637  Validation loss = 2.6553  \n",
      "\n",
      "Fold: 25  Epoch: 147  Training loss = 4.0636  Validation loss = 2.6551  \n",
      "\n",
      "Fold: 25  Epoch: 148  Training loss = 4.0634  Validation loss = 2.6550  \n",
      "\n",
      "Fold: 25  Epoch: 149  Training loss = 4.0633  Validation loss = 2.6550  \n",
      "\n",
      "Fold: 25  Epoch: 150  Training loss = 4.0631  Validation loss = 2.6548  \n",
      "\n",
      "Fold: 25  Epoch: 151  Training loss = 4.0629  Validation loss = 2.6543  \n",
      "\n",
      "Fold: 25  Epoch: 152  Training loss = 4.0627  Validation loss = 2.6542  \n",
      "\n",
      "Fold: 25  Epoch: 153  Training loss = 4.0626  Validation loss = 2.6541  \n",
      "\n",
      "Fold: 25  Epoch: 154  Training loss = 4.0625  Validation loss = 2.6540  \n",
      "\n",
      "Fold: 25  Epoch: 155  Training loss = 4.0623  Validation loss = 2.6537  \n",
      "\n",
      "Fold: 25  Epoch: 156  Training loss = 4.0621  Validation loss = 2.6535  \n",
      "\n",
      "Fold: 25  Epoch: 157  Training loss = 4.0620  Validation loss = 2.6535  \n",
      "\n",
      "Fold: 25  Epoch: 158  Training loss = 4.0618  Validation loss = 2.6531  \n",
      "\n",
      "Fold: 25  Epoch: 159  Training loss = 4.0616  Validation loss = 2.6528  \n",
      "\n",
      "Fold: 25  Epoch: 160  Training loss = 4.0614  Validation loss = 2.6525  \n",
      "\n",
      "Fold: 25  Epoch: 161  Training loss = 4.0611  Validation loss = 2.6520  \n",
      "\n",
      "Fold: 25  Epoch: 162  Training loss = 4.0609  Validation loss = 2.6518  \n",
      "\n",
      "Fold: 25  Epoch: 163  Training loss = 4.0608  Validation loss = 2.6515  \n",
      "\n",
      "Fold: 25  Epoch: 164  Training loss = 4.0605  Validation loss = 2.6511  \n",
      "\n",
      "Fold: 25  Epoch: 165  Training loss = 4.0603  Validation loss = 2.6506  \n",
      "\n",
      "Fold: 25  Epoch: 166  Training loss = 4.0601  Validation loss = 2.6502  \n",
      "\n",
      "Fold: 25  Epoch: 167  Training loss = 4.0599  Validation loss = 2.6498  \n",
      "\n",
      "Fold: 25  Epoch: 168  Training loss = 4.0597  Validation loss = 2.6494  \n",
      "\n",
      "Fold: 25  Epoch: 169  Training loss = 4.0596  Validation loss = 2.6493  \n",
      "\n",
      "Fold: 25  Epoch: 170  Training loss = 4.0594  Validation loss = 2.6489  \n",
      "\n",
      "Fold: 25  Epoch: 171  Training loss = 4.0593  Validation loss = 2.6486  \n",
      "\n",
      "Fold: 25  Epoch: 172  Training loss = 4.0591  Validation loss = 2.6484  \n",
      "\n",
      "Fold: 25  Epoch: 173  Training loss = 4.0589  Validation loss = 2.6481  \n",
      "\n",
      "Fold: 25  Epoch: 174  Training loss = 4.0587  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 25  Epoch: 175  Training loss = 4.0586  Validation loss = 2.6477  \n",
      "\n",
      "Fold: 25  Epoch: 176  Training loss = 4.0584  Validation loss = 2.6475  \n",
      "\n",
      "Fold: 25  Epoch: 177  Training loss = 4.0583  Validation loss = 2.6473  \n",
      "\n",
      "Fold: 25  Epoch: 178  Training loss = 4.0582  Validation loss = 2.6472  \n",
      "\n",
      "Fold: 25  Epoch: 179  Training loss = 4.0579  Validation loss = 2.6468  \n",
      "\n",
      "Fold: 25  Epoch: 180  Training loss = 4.0577  Validation loss = 2.6463  \n",
      "\n",
      "Fold: 25  Epoch: 181  Training loss = 4.0575  Validation loss = 2.6462  \n",
      "\n",
      "Fold: 25  Epoch: 182  Training loss = 4.0574  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 25  Epoch: 183  Training loss = 4.0573  Validation loss = 2.6459  \n",
      "\n",
      "Fold: 25  Epoch: 184  Training loss = 4.0571  Validation loss = 2.6457  \n",
      "\n",
      "Fold: 25  Epoch: 185  Training loss = 4.0570  Validation loss = 2.6455  \n",
      "\n",
      "Fold: 25  Epoch: 186  Training loss = 4.0567  Validation loss = 2.6452  \n",
      "\n",
      "Fold: 25  Epoch: 187  Training loss = 4.0565  Validation loss = 2.6448  \n",
      "\n",
      "Fold: 25  Epoch: 188  Training loss = 4.0563  Validation loss = 2.6445  \n",
      "\n",
      "Fold: 25  Epoch: 189  Training loss = 4.0562  Validation loss = 2.6445  \n",
      "\n",
      "Fold: 25  Epoch: 190  Training loss = 4.0560  Validation loss = 2.6441  \n",
      "\n",
      "Fold: 25  Epoch: 191  Training loss = 4.0558  Validation loss = 2.6437  \n",
      "\n",
      "Fold: 25  Epoch: 192  Training loss = 4.0557  Validation loss = 2.6435  \n",
      "\n",
      "Fold: 25  Epoch: 193  Training loss = 4.0555  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 25  Epoch: 194  Training loss = 4.0553  Validation loss = 2.6428  \n",
      "\n",
      "Fold: 25  Epoch: 195  Training loss = 4.0551  Validation loss = 2.6426  \n",
      "\n",
      "Fold: 25  Epoch: 196  Training loss = 4.0550  Validation loss = 2.6425  \n",
      "\n",
      "Fold: 25  Epoch: 197  Training loss = 4.0548  Validation loss = 2.6422  \n",
      "\n",
      "Fold: 25  Epoch: 198  Training loss = 4.0546  Validation loss = 2.6421  \n",
      "\n",
      "Fold: 25  Epoch: 199  Training loss = 4.0544  Validation loss = 2.6419  \n",
      "\n",
      "Fold: 25  Epoch: 200  Training loss = 4.0543  Validation loss = 2.6417  \n",
      "\n",
      "Fold: 25  Epoch: 201  Training loss = 4.0542  Validation loss = 2.6415  \n",
      "\n",
      "Fold: 25  Epoch: 202  Training loss = 4.0541  Validation loss = 2.6414  \n",
      "\n",
      "Fold: 25  Epoch: 203  Training loss = 4.0539  Validation loss = 2.6411  \n",
      "\n",
      "Fold: 25  Epoch: 204  Training loss = 4.0537  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 25  Epoch: 205  Training loss = 4.0535  Validation loss = 2.6407  \n",
      "\n",
      "Fold: 25  Epoch: 206  Training loss = 4.0533  Validation loss = 2.6403  \n",
      "\n",
      "Fold: 25  Epoch: 207  Training loss = 4.0532  Validation loss = 2.6402  \n",
      "\n",
      "Fold: 25  Epoch: 208  Training loss = 4.0530  Validation loss = 2.6400  \n",
      "\n",
      "Fold: 25  Epoch: 209  Training loss = 4.0529  Validation loss = 2.6399  \n",
      "\n",
      "Fold: 25  Epoch: 210  Training loss = 4.0527  Validation loss = 2.6396  \n",
      "\n",
      "Fold: 25  Epoch: 211  Training loss = 4.0525  Validation loss = 2.6394  \n",
      "\n",
      "Fold: 25  Epoch: 212  Training loss = 4.0522  Validation loss = 2.6388  \n",
      "\n",
      "Fold: 25  Epoch: 213  Training loss = 4.0521  Validation loss = 2.6387  \n",
      "\n",
      "Fold: 25  Epoch: 214  Training loss = 4.0519  Validation loss = 2.6384  \n",
      "\n",
      "Fold: 25  Epoch: 215  Training loss = 4.0517  Validation loss = 2.6379  \n",
      "\n",
      "Fold: 25  Epoch: 216  Training loss = 4.0515  Validation loss = 2.6375  \n",
      "\n",
      "Fold: 25  Epoch: 217  Training loss = 4.0513  Validation loss = 2.6373  \n",
      "\n",
      "Fold: 25  Epoch: 218  Training loss = 4.0511  Validation loss = 2.6370  \n",
      "\n",
      "Fold: 25  Epoch: 219  Training loss = 4.0510  Validation loss = 2.6368  \n",
      "\n",
      "Fold: 25  Epoch: 220  Training loss = 4.0508  Validation loss = 2.6366  \n",
      "\n",
      "Fold: 25  Epoch: 221  Training loss = 4.0507  Validation loss = 2.6364  \n",
      "\n",
      "Fold: 25  Epoch: 222  Training loss = 4.0505  Validation loss = 2.6362  \n",
      "\n",
      "Fold: 25  Epoch: 223  Training loss = 4.0503  Validation loss = 2.6360  \n",
      "\n",
      "Fold: 25  Epoch: 224  Training loss = 4.0502  Validation loss = 2.6359  \n",
      "\n",
      "Fold: 25  Epoch: 225  Training loss = 4.0499  Validation loss = 2.6353  \n",
      "\n",
      "Fold: 25  Epoch: 226  Training loss = 4.0498  Validation loss = 2.6351  \n",
      "\n",
      "Fold: 25  Epoch: 227  Training loss = 4.0496  Validation loss = 2.6350  \n",
      "\n",
      "Fold: 25  Epoch: 228  Training loss = 4.0494  Validation loss = 2.6347  \n",
      "\n",
      "Fold: 25  Epoch: 229  Training loss = 4.0492  Validation loss = 2.6342  \n",
      "\n",
      "Fold: 25  Epoch: 230  Training loss = 4.0491  Validation loss = 2.6340  \n",
      "\n",
      "Fold: 25  Epoch: 231  Training loss = 4.0488  Validation loss = 2.6337  \n",
      "\n",
      "Fold: 25  Epoch: 232  Training loss = 4.0486  Validation loss = 2.6332  \n",
      "\n",
      "Fold: 25  Epoch: 233  Training loss = 4.0484  Validation loss = 2.6329  \n",
      "\n",
      "Fold: 25  Epoch: 234  Training loss = 4.0483  Validation loss = 2.6325  \n",
      "\n",
      "Fold: 25  Epoch: 235  Training loss = 4.0481  Validation loss = 2.6321  \n",
      "\n",
      "Fold: 25  Epoch: 236  Training loss = 4.0480  Validation loss = 2.6319  \n",
      "\n",
      "Fold: 25  Epoch: 237  Training loss = 4.0478  Validation loss = 2.6316  \n",
      "\n",
      "Fold: 25  Epoch: 238  Training loss = 4.0476  Validation loss = 2.6313  \n",
      "\n",
      "Fold: 25  Epoch: 239  Training loss = 4.0474  Validation loss = 2.6308  \n",
      "\n",
      "Fold: 25  Epoch: 240  Training loss = 4.0472  Validation loss = 2.6307  \n",
      "\n",
      "Fold: 25  Epoch: 241  Training loss = 4.0471  Validation loss = 2.6305  \n",
      "\n",
      "Fold: 25  Epoch: 242  Training loss = 4.0469  Validation loss = 2.6302  \n",
      "\n",
      "Fold: 25  Epoch: 243  Training loss = 4.0467  Validation loss = 2.6297  \n",
      "\n",
      "Fold: 25  Epoch: 244  Training loss = 4.0465  Validation loss = 2.6292  \n",
      "\n",
      "Fold: 25  Epoch: 245  Training loss = 4.0463  Validation loss = 2.6289  \n",
      "\n",
      "Fold: 25  Epoch: 246  Training loss = 4.0462  Validation loss = 2.6285  \n",
      "\n",
      "Fold: 25  Epoch: 247  Training loss = 4.0460  Validation loss = 2.6282  \n",
      "\n",
      "Fold: 25  Epoch: 248  Training loss = 4.0458  Validation loss = 2.6280  \n",
      "\n",
      "Fold: 25  Epoch: 249  Training loss = 4.0456  Validation loss = 2.6278  \n",
      "\n",
      "Fold: 25  Epoch: 250  Training loss = 4.0454  Validation loss = 2.6274  \n",
      "\n",
      "Fold: 25  Epoch: 251  Training loss = 4.0452  Validation loss = 2.6271  \n",
      "\n",
      "Fold: 25  Epoch: 252  Training loss = 4.0451  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 25  Epoch: 253  Training loss = 4.0449  Validation loss = 2.6264  \n",
      "\n",
      "Fold: 25  Epoch: 254  Training loss = 4.0447  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 25  Epoch: 255  Training loss = 4.0445  Validation loss = 2.6258  \n",
      "\n",
      "Fold: 25  Epoch: 256  Training loss = 4.0443  Validation loss = 2.6255  \n",
      "\n",
      "Fold: 25  Epoch: 257  Training loss = 4.0442  Validation loss = 2.6253  \n",
      "\n",
      "Fold: 25  Epoch: 258  Training loss = 4.0440  Validation loss = 2.6253  \n",
      "\n",
      "Fold: 25  Epoch: 259  Training loss = 4.0439  Validation loss = 2.6252  \n",
      "\n",
      "Fold: 25  Epoch: 260  Training loss = 4.0437  Validation loss = 2.6250  \n",
      "\n",
      "Fold: 25  Epoch: 261  Training loss = 4.0435  Validation loss = 2.6244  \n",
      "\n",
      "Fold: 25  Epoch: 262  Training loss = 4.0433  Validation loss = 2.6239  \n",
      "\n",
      "Fold: 25  Epoch: 263  Training loss = 4.0431  Validation loss = 2.6236  \n",
      "\n",
      "Fold: 25  Epoch: 264  Training loss = 4.0430  Validation loss = 2.6232  \n",
      "\n",
      "Fold: 25  Epoch: 265  Training loss = 4.0428  Validation loss = 2.6229  \n",
      "\n",
      "Fold: 25  Epoch: 266  Training loss = 4.0427  Validation loss = 2.6227  \n",
      "\n",
      "Fold: 25  Epoch: 267  Training loss = 4.0425  Validation loss = 2.6223  \n",
      "\n",
      "Fold: 25  Epoch: 268  Training loss = 4.0423  Validation loss = 2.6220  \n",
      "\n",
      "Fold: 25  Epoch: 269  Training loss = 4.0422  Validation loss = 2.6217  \n",
      "\n",
      "Fold: 25  Epoch: 270  Training loss = 4.0420  Validation loss = 2.6216  \n",
      "\n",
      "Fold: 25  Epoch: 271  Training loss = 4.0418  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 25  Epoch: 272  Training loss = 4.0417  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 25  Epoch: 273  Training loss = 4.0415  Validation loss = 2.6211  \n",
      "\n",
      "Fold: 25  Epoch: 274  Training loss = 4.0414  Validation loss = 2.6209  \n",
      "\n",
      "Fold: 25  Epoch: 275  Training loss = 4.0412  Validation loss = 2.6205  \n",
      "\n",
      "Fold: 25  Epoch: 276  Training loss = 4.0410  Validation loss = 2.6202  \n",
      "\n",
      "Fold: 25  Epoch: 277  Training loss = 4.0408  Validation loss = 2.6199  \n",
      "\n",
      "Fold: 25  Epoch: 278  Training loss = 4.0407  Validation loss = 2.6198  \n",
      "\n",
      "Fold: 25  Epoch: 279  Training loss = 4.0405  Validation loss = 2.6195  \n",
      "\n",
      "Fold: 25  Epoch: 280  Training loss = 4.0403  Validation loss = 2.6193  \n",
      "\n",
      "Fold: 25  Epoch: 281  Training loss = 4.0402  Validation loss = 2.6191  \n",
      "\n",
      "Fold: 25  Epoch: 282  Training loss = 4.0402  Validation loss = 2.6191  \n",
      "\n",
      "Fold: 25  Epoch: 283  Training loss = 4.0399  Validation loss = 2.6188  \n",
      "\n",
      "Fold: 25  Epoch: 284  Training loss = 4.0398  Validation loss = 2.6186  \n",
      "\n",
      "Fold: 25  Epoch: 285  Training loss = 4.0396  Validation loss = 2.6184  \n",
      "\n",
      "Fold: 25  Epoch: 286  Training loss = 4.0394  Validation loss = 2.6179  \n",
      "\n",
      "Fold: 25  Epoch: 287  Training loss = 4.0392  Validation loss = 2.6178  \n",
      "\n",
      "Fold: 25  Epoch: 288  Training loss = 4.0391  Validation loss = 2.6176  \n",
      "\n",
      "Fold: 25  Epoch: 289  Training loss = 4.0390  Validation loss = 2.6172  \n",
      "\n",
      "Fold: 25  Epoch: 290  Training loss = 4.0388  Validation loss = 2.6168  \n",
      "\n",
      "Fold: 25  Epoch: 291  Training loss = 4.0386  Validation loss = 2.6165  \n",
      "\n",
      "Fold: 25  Epoch: 292  Training loss = 4.0384  Validation loss = 2.6159  \n",
      "\n",
      "Fold: 25  Epoch: 293  Training loss = 4.0382  Validation loss = 2.6155  \n",
      "\n",
      "Fold: 25  Epoch: 294  Training loss = 4.0380  Validation loss = 2.6151  \n",
      "\n",
      "Fold: 25  Epoch: 295  Training loss = 4.0378  Validation loss = 2.6148  \n",
      "\n",
      "Fold: 25  Epoch: 296  Training loss = 4.0377  Validation loss = 2.6148  \n",
      "\n",
      "Fold: 25  Epoch: 297  Training loss = 4.0375  Validation loss = 2.6147  \n",
      "\n",
      "Fold: 25  Epoch: 298  Training loss = 4.0373  Validation loss = 2.6143  \n",
      "\n",
      "Fold: 25  Epoch: 299  Training loss = 4.0372  Validation loss = 2.6143  \n",
      "\n",
      "Fold: 25  Epoch: 300  Training loss = 4.0370  Validation loss = 2.6140  \n",
      "\n",
      "Fold: 25  Epoch: 301  Training loss = 4.0368  Validation loss = 2.6137  \n",
      "\n",
      "Fold: 25  Epoch: 302  Training loss = 4.0366  Validation loss = 2.6135  \n",
      "\n",
      "Fold: 25  Epoch: 303  Training loss = 4.0364  Validation loss = 2.6130  \n",
      "\n",
      "Fold: 25  Epoch: 304  Training loss = 4.0362  Validation loss = 2.6127  \n",
      "\n",
      "Fold: 25  Epoch: 305  Training loss = 4.0360  Validation loss = 2.6122  \n",
      "\n",
      "Fold: 25  Epoch: 306  Training loss = 4.0358  Validation loss = 2.6118  \n",
      "\n",
      "Fold: 25  Epoch: 307  Training loss = 4.0357  Validation loss = 2.6117  \n",
      "\n",
      "Fold: 25  Epoch: 308  Training loss = 4.0355  Validation loss = 2.6116  \n",
      "\n",
      "Fold: 25  Epoch: 309  Training loss = 4.0354  Validation loss = 2.6115  \n",
      "\n",
      "Fold: 25  Epoch: 310  Training loss = 4.0351  Validation loss = 2.6109  \n",
      "\n",
      "Fold: 25  Epoch: 311  Training loss = 4.0350  Validation loss = 2.6104  \n",
      "\n",
      "Fold: 25  Epoch: 312  Training loss = 4.0348  Validation loss = 2.6103  \n",
      "\n",
      "Fold: 25  Epoch: 313  Training loss = 4.0347  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 25  Epoch: 314  Training loss = 4.0345  Validation loss = 2.6100  \n",
      "\n",
      "Fold: 25  Epoch: 315  Training loss = 4.0344  Validation loss = 2.6098  \n",
      "\n",
      "Fold: 25  Epoch: 316  Training loss = 4.0343  Validation loss = 2.6098  \n",
      "\n",
      "Fold: 25  Epoch: 317  Training loss = 4.0341  Validation loss = 2.6097  \n",
      "\n",
      "Fold: 25  Epoch: 318  Training loss = 4.0339  Validation loss = 2.6096  \n",
      "\n",
      "Fold: 25  Epoch: 319  Training loss = 4.0337  Validation loss = 2.6091  \n",
      "\n",
      "Fold: 25  Epoch: 320  Training loss = 4.0336  Validation loss = 2.6090  \n",
      "\n",
      "Fold: 25  Epoch: 321  Training loss = 4.0334  Validation loss = 2.6086  \n",
      "\n",
      "Fold: 25  Epoch: 322  Training loss = 4.0333  Validation loss = 2.6084  \n",
      "\n",
      "Fold: 25  Epoch: 323  Training loss = 4.0332  Validation loss = 2.6082  \n",
      "\n",
      "Fold: 25  Epoch: 324  Training loss = 4.0331  Validation loss = 2.6082  \n",
      "\n",
      "Fold: 25  Epoch: 325  Training loss = 4.0329  Validation loss = 2.6081  \n",
      "\n",
      "Fold: 25  Epoch: 326  Training loss = 4.0327  Validation loss = 2.6076  \n",
      "\n",
      "Fold: 25  Epoch: 327  Training loss = 4.0326  Validation loss = 2.6075  \n",
      "\n",
      "Fold: 25  Epoch: 328  Training loss = 4.0324  Validation loss = 2.6072  \n",
      "\n",
      "Fold: 25  Epoch: 329  Training loss = 4.0323  Validation loss = 2.6070  \n",
      "\n",
      "Fold: 25  Epoch: 330  Training loss = 4.0321  Validation loss = 2.6067  \n",
      "\n",
      "Fold: 25  Epoch: 331  Training loss = 4.0319  Validation loss = 2.6062  \n",
      "\n",
      "Fold: 25  Epoch: 332  Training loss = 4.0318  Validation loss = 2.6060  \n",
      "\n",
      "Fold: 25  Epoch: 333  Training loss = 4.0316  Validation loss = 2.6059  \n",
      "\n",
      "Fold: 25  Epoch: 334  Training loss = 4.0314  Validation loss = 2.6056  \n",
      "\n",
      "Fold: 25  Epoch: 335  Training loss = 4.0313  Validation loss = 2.6055  \n",
      "\n",
      "Fold: 25  Epoch: 336  Training loss = 4.0311  Validation loss = 2.6052  \n",
      "\n",
      "Fold: 25  Epoch: 337  Training loss = 4.0309  Validation loss = 2.6048  \n",
      "\n",
      "Fold: 25  Epoch: 338  Training loss = 4.0307  Validation loss = 2.6046  \n",
      "\n",
      "Fold: 25  Epoch: 339  Training loss = 4.0305  Validation loss = 2.6042  \n",
      "\n",
      "Fold: 25  Epoch: 340  Training loss = 4.0303  Validation loss = 2.6039  \n",
      "\n",
      "Fold: 25  Epoch: 341  Training loss = 4.0302  Validation loss = 2.6038  \n",
      "\n",
      "Fold: 25  Epoch: 342  Training loss = 4.0301  Validation loss = 2.6035  \n",
      "\n",
      "Fold: 25  Epoch: 343  Training loss = 4.0299  Validation loss = 2.6032  \n",
      "\n",
      "Fold: 25  Epoch: 344  Training loss = 4.0298  Validation loss = 2.6030  \n",
      "\n",
      "Fold: 25  Epoch: 345  Training loss = 4.0295  Validation loss = 2.6028  \n",
      "\n",
      "Fold: 25  Epoch: 346  Training loss = 4.0294  Validation loss = 2.6026  \n",
      "\n",
      "Fold: 25  Epoch: 347  Training loss = 4.0292  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 25  Epoch: 348  Training loss = 4.0289  Validation loss = 2.6016  \n",
      "\n",
      "Fold: 25  Epoch: 349  Training loss = 4.0288  Validation loss = 2.6015  \n",
      "\n",
      "Fold: 25  Epoch: 350  Training loss = 4.0286  Validation loss = 2.6013  \n",
      "\n",
      "Fold: 25  Epoch: 351  Training loss = 4.0285  Validation loss = 2.6011  \n",
      "\n",
      "Fold: 25  Epoch: 352  Training loss = 4.0283  Validation loss = 2.6009  \n",
      "\n",
      "Fold: 25  Epoch: 353  Training loss = 4.0281  Validation loss = 2.6006  \n",
      "\n",
      "Fold: 25  Epoch: 354  Training loss = 4.0280  Validation loss = 2.6003  \n",
      "\n",
      "Fold: 25  Epoch: 355  Training loss = 4.0279  Validation loss = 2.6002  \n",
      "\n",
      "Fold: 25  Epoch: 356  Training loss = 4.0277  Validation loss = 2.6001  \n",
      "\n",
      "Fold: 25  Epoch: 357  Training loss = 4.0276  Validation loss = 2.5998  \n",
      "\n",
      "Fold: 25  Epoch: 358  Training loss = 4.0274  Validation loss = 2.5994  \n",
      "\n",
      "Fold: 25  Epoch: 359  Training loss = 4.0273  Validation loss = 2.5991  \n",
      "\n",
      "Fold: 25  Epoch: 360  Training loss = 4.0271  Validation loss = 2.5988  \n",
      "\n",
      "Fold: 25  Epoch: 361  Training loss = 4.0269  Validation loss = 2.5985  \n",
      "\n",
      "Fold: 25  Epoch: 362  Training loss = 4.0267  Validation loss = 2.5983  \n",
      "\n",
      "Fold: 25  Epoch: 363  Training loss = 4.0266  Validation loss = 2.5981  \n",
      "\n",
      "Fold: 25  Epoch: 364  Training loss = 4.0264  Validation loss = 2.5978  \n",
      "\n",
      "Fold: 25  Epoch: 365  Training loss = 4.0262  Validation loss = 2.5976  \n",
      "\n",
      "Fold: 25  Epoch: 366  Training loss = 4.0262  Validation loss = 2.5977  \n",
      "\n",
      "Fold: 25  Epoch: 367  Training loss = 4.0260  Validation loss = 2.5975  \n",
      "\n",
      "Fold: 25  Epoch: 368  Training loss = 4.0259  Validation loss = 2.5973  \n",
      "\n",
      "Fold: 25  Epoch: 369  Training loss = 4.0257  Validation loss = 2.5970  \n",
      "\n",
      "Fold: 25  Epoch: 370  Training loss = 4.0255  Validation loss = 2.5967  \n",
      "\n",
      "Fold: 25  Epoch: 371  Training loss = 4.0253  Validation loss = 2.5962  \n",
      "\n",
      "Fold: 25  Epoch: 372  Training loss = 4.0251  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 25  Epoch: 373  Training loss = 4.0250  Validation loss = 2.5957  \n",
      "\n",
      "Fold: 25  Epoch: 374  Training loss = 4.0249  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 25  Epoch: 375  Training loss = 4.0247  Validation loss = 2.5952  \n",
      "\n",
      "Fold: 25  Epoch: 376  Training loss = 4.0245  Validation loss = 2.5950  \n",
      "\n",
      "Fold: 25  Epoch: 377  Training loss = 4.0244  Validation loss = 2.5948  \n",
      "\n",
      "Fold: 25  Epoch: 378  Training loss = 4.0242  Validation loss = 2.5946  \n",
      "\n",
      "Fold: 25  Epoch: 379  Training loss = 4.0241  Validation loss = 2.5945  \n",
      "\n",
      "Fold: 25  Epoch: 380  Training loss = 4.0240  Validation loss = 2.5945  \n",
      "\n",
      "Fold: 25  Epoch: 381  Training loss = 4.0238  Validation loss = 2.5941  \n",
      "\n",
      "Fold: 25  Epoch: 382  Training loss = 4.0237  Validation loss = 2.5940  \n",
      "\n",
      "Fold: 25  Epoch: 383  Training loss = 4.0236  Validation loss = 2.5937  \n",
      "\n",
      "Fold: 25  Epoch: 384  Training loss = 4.0234  Validation loss = 2.5936  \n",
      "\n",
      "Fold: 25  Epoch: 385  Training loss = 4.0233  Validation loss = 2.5934  \n",
      "\n",
      "Fold: 25  Epoch: 386  Training loss = 4.0232  Validation loss = 2.5933  \n",
      "\n",
      "Fold: 25  Epoch: 387  Training loss = 4.0230  Validation loss = 2.5930  \n",
      "\n",
      "Fold: 25  Epoch: 388  Training loss = 4.0228  Validation loss = 2.5926  \n",
      "\n",
      "Fold: 25  Epoch: 389  Training loss = 4.0227  Validation loss = 2.5925  \n",
      "\n",
      "Fold: 25  Epoch: 390  Training loss = 4.0225  Validation loss = 2.5922  \n",
      "\n",
      "Fold: 25  Epoch: 391  Training loss = 4.0223  Validation loss = 2.5921  \n",
      "\n",
      "Fold: 25  Epoch: 392  Training loss = 4.0222  Validation loss = 2.5918  \n",
      "\n",
      "Fold: 25  Epoch: 393  Training loss = 4.0220  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 25  Epoch: 394  Training loss = 4.0219  Validation loss = 2.5914  \n",
      "\n",
      "Fold: 25  Epoch: 395  Training loss = 4.0217  Validation loss = 2.5913  \n",
      "\n",
      "Fold: 25  Epoch: 396  Training loss = 4.0215  Validation loss = 2.5909  \n",
      "\n",
      "Fold: 25  Epoch: 397  Training loss = 4.0214  Validation loss = 2.5907  \n",
      "\n",
      "Fold: 25  Epoch: 398  Training loss = 4.0213  Validation loss = 2.5905  \n",
      "\n",
      "Fold: 25  Epoch: 399  Training loss = 4.0211  Validation loss = 2.5903  \n",
      "\n",
      "Fold: 25  Epoch: 400  Training loss = 4.0209  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 25  Epoch: 401  Training loss = 4.0207  Validation loss = 2.5897  \n",
      "\n",
      "Fold: 25  Epoch: 402  Training loss = 4.0206  Validation loss = 2.5895  \n",
      "\n",
      "Fold: 25  Epoch: 403  Training loss = 4.0204  Validation loss = 2.5893  \n",
      "\n",
      "Fold: 25  Epoch: 404  Training loss = 4.0202  Validation loss = 2.5889  \n",
      "\n",
      "Fold: 25  Epoch: 405  Training loss = 4.0201  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 25  Epoch: 406  Training loss = 4.0200  Validation loss = 2.5887  \n",
      "\n",
      "Fold: 25  Epoch: 407  Training loss = 4.0199  Validation loss = 2.5885  \n",
      "\n",
      "Fold: 25  Epoch: 408  Training loss = 4.0197  Validation loss = 2.5883  \n",
      "\n",
      "Fold: 25  Epoch: 409  Training loss = 4.0196  Validation loss = 2.5883  \n",
      "\n",
      "Fold: 25  Epoch: 410  Training loss = 4.0195  Validation loss = 2.5882  \n",
      "\n",
      "Fold: 25  Epoch: 411  Training loss = 4.0193  Validation loss = 2.5879  \n",
      "\n",
      "Fold: 25  Epoch: 412  Training loss = 4.0192  Validation loss = 2.5877  \n",
      "\n",
      "Fold: 25  Epoch: 413  Training loss = 4.0191  Validation loss = 2.5876  \n",
      "\n",
      "Fold: 25  Epoch: 414  Training loss = 4.0189  Validation loss = 2.5875  \n",
      "\n",
      "Fold: 25  Epoch: 415  Training loss = 4.0188  Validation loss = 2.5873  \n",
      "\n",
      "Fold: 25  Epoch: 416  Training loss = 4.0185  Validation loss = 2.5869  \n",
      "\n",
      "Fold: 25  Epoch: 417  Training loss = 4.0184  Validation loss = 2.5867  \n",
      "\n",
      "Fold: 25  Epoch: 418  Training loss = 4.0183  Validation loss = 2.5866  \n",
      "\n",
      "Fold: 25  Epoch: 419  Training loss = 4.0181  Validation loss = 2.5863  \n",
      "\n",
      "Fold: 25  Epoch: 420  Training loss = 4.0180  Validation loss = 2.5864  \n",
      "\n",
      "Fold: 25  Epoch: 421  Training loss = 4.0178  Validation loss = 2.5859  \n",
      "\n",
      "Fold: 25  Epoch: 422  Training loss = 4.0177  Validation loss = 2.5857  \n",
      "\n",
      "Fold: 25  Epoch: 423  Training loss = 4.0175  Validation loss = 2.5855  \n",
      "\n",
      "Fold: 25  Epoch: 424  Training loss = 4.0173  Validation loss = 2.5852  \n",
      "\n",
      "Fold: 25  Epoch: 425  Training loss = 4.0172  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 25  Epoch: 426  Training loss = 4.0170  Validation loss = 2.5847  \n",
      "\n",
      "Fold: 25  Epoch: 427  Training loss = 4.0168  Validation loss = 2.5845  \n",
      "\n",
      "Fold: 25  Epoch: 428  Training loss = 4.0166  Validation loss = 2.5843  \n",
      "\n",
      "Fold: 25  Epoch: 429  Training loss = 4.0165  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 25  Epoch: 430  Training loss = 4.0163  Validation loss = 2.5836  \n",
      "\n",
      "Fold: 25  Epoch: 431  Training loss = 4.0162  Validation loss = 2.5837  \n",
      "\n",
      "Fold: 25  Epoch: 432  Training loss = 4.0161  Validation loss = 2.5837  \n",
      "\n",
      "Fold: 25  Epoch: 433  Training loss = 4.0159  Validation loss = 2.5835  \n",
      "\n",
      "Fold: 25  Epoch: 434  Training loss = 4.0157  Validation loss = 2.5831  \n",
      "\n",
      "Fold: 25  Epoch: 435  Training loss = 4.0154  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 25  Epoch: 436  Training loss = 4.0152  Validation loss = 2.5824  \n",
      "\n",
      "Fold: 25  Epoch: 437  Training loss = 4.0151  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 25  Epoch: 438  Training loss = 4.0150  Validation loss = 2.5822  \n",
      "\n",
      "Fold: 25  Epoch: 439  Training loss = 4.0148  Validation loss = 2.5821  \n",
      "\n",
      "Fold: 25  Epoch: 440  Training loss = 4.0147  Validation loss = 2.5820  \n",
      "\n",
      "Fold: 25  Epoch: 441  Training loss = 4.0146  Validation loss = 2.5820  \n",
      "\n",
      "Fold: 25  Epoch: 442  Training loss = 4.0145  Validation loss = 2.5817  \n",
      "\n",
      "Fold: 25  Epoch: 443  Training loss = 4.0143  Validation loss = 2.5815  \n",
      "\n",
      "Fold: 25  Epoch: 444  Training loss = 4.0142  Validation loss = 2.5812  \n",
      "\n",
      "Fold: 25  Epoch: 445  Training loss = 4.0141  Validation loss = 2.5811  \n",
      "\n",
      "Fold: 25  Epoch: 446  Training loss = 4.0140  Validation loss = 2.5809  \n",
      "\n",
      "Fold: 25  Epoch: 447  Training loss = 4.0138  Validation loss = 2.5808  \n",
      "\n",
      "Fold: 25  Epoch: 448  Training loss = 4.0137  Validation loss = 2.5805  \n",
      "\n",
      "Fold: 25  Epoch: 449  Training loss = 4.0135  Validation loss = 2.5804  \n",
      "\n",
      "Fold: 25  Epoch: 450  Training loss = 4.0133  Validation loss = 2.5800  \n",
      "\n",
      "Fold: 25  Epoch: 451  Training loss = 4.0132  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 25  Epoch: 452  Training loss = 4.0131  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 25  Epoch: 453  Training loss = 4.0130  Validation loss = 2.5797  \n",
      "\n",
      "Fold: 25  Epoch: 454  Training loss = 4.0128  Validation loss = 2.5795  \n",
      "\n",
      "Fold: 25  Epoch: 455  Training loss = 4.0126  Validation loss = 2.5791  \n",
      "\n",
      "Fold: 25  Epoch: 456  Training loss = 4.0125  Validation loss = 2.5788  \n",
      "\n",
      "Fold: 25  Epoch: 457  Training loss = 4.0123  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 25  Epoch: 458  Training loss = 4.0121  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 25  Epoch: 459  Training loss = 4.0120  Validation loss = 2.5782  \n",
      "\n",
      "Fold: 25  Epoch: 460  Training loss = 4.0118  Validation loss = 2.5778  \n",
      "\n",
      "Fold: 25  Epoch: 461  Training loss = 4.0116  Validation loss = 2.5777  \n",
      "\n",
      "Fold: 25  Epoch: 462  Training loss = 4.0115  Validation loss = 2.5776  \n",
      "\n",
      "Fold: 25  Epoch: 463  Training loss = 4.0114  Validation loss = 2.5776  \n",
      "\n",
      "Fold: 25  Epoch: 464  Training loss = 4.0112  Validation loss = 2.5772  \n",
      "\n",
      "Fold: 25  Epoch: 465  Training loss = 4.0111  Validation loss = 2.5769  \n",
      "\n",
      "Fold: 25  Epoch: 466  Training loss = 4.0109  Validation loss = 2.5766  \n",
      "\n",
      "Fold: 25  Epoch: 467  Training loss = 4.0107  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 25  Epoch: 468  Training loss = 4.0106  Validation loss = 2.5763  \n",
      "\n",
      "Fold: 25  Epoch: 469  Training loss = 4.0104  Validation loss = 2.5762  \n",
      "\n",
      "Fold: 25  Epoch: 470  Training loss = 4.0103  Validation loss = 2.5760  \n",
      "\n",
      "Fold: 25  Epoch: 471  Training loss = 4.0102  Validation loss = 2.5758  \n",
      "\n",
      "Fold: 25  Epoch: 472  Training loss = 4.0100  Validation loss = 2.5757  \n",
      "\n",
      "Fold: 25  Epoch: 473  Training loss = 4.0098  Validation loss = 2.5754  \n",
      "\n",
      "Fold: 25  Epoch: 474  Training loss = 4.0096  Validation loss = 2.5752  \n",
      "\n",
      "Fold: 25  Epoch: 475  Training loss = 4.0095  Validation loss = 2.5751  \n",
      "\n",
      "Fold: 25  Epoch: 476  Training loss = 4.0094  Validation loss = 2.5751  \n",
      "\n",
      "Fold: 25  Epoch: 477  Training loss = 4.0093  Validation loss = 2.5751  \n",
      "\n",
      "Fold: 25  Epoch: 478  Training loss = 4.0092  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 25  Epoch: 479  Training loss = 4.0090  Validation loss = 2.5749  \n",
      "\n",
      "Fold: 25  Epoch: 480  Training loss = 4.0089  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 25  Epoch: 481  Training loss = 4.0088  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 25  Epoch: 482  Training loss = 4.0087  Validation loss = 2.5748  \n",
      "\n",
      "Fold: 25  Epoch: 483  Training loss = 4.0085  Validation loss = 2.5745  \n",
      "\n",
      "Fold: 25  Epoch: 484  Training loss = 4.0083  Validation loss = 2.5742  \n",
      "\n",
      "Fold: 25  Epoch: 485  Training loss = 4.0082  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 25  Epoch: 486  Training loss = 4.0080  Validation loss = 2.5736  \n",
      "\n",
      "Fold: 25  Epoch: 487  Training loss = 4.0079  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 25  Epoch: 488  Training loss = 4.0077  Validation loss = 2.5732  \n",
      "\n",
      "Fold: 25  Epoch: 489  Training loss = 4.0075  Validation loss = 2.5728  \n",
      "\n",
      "Fold: 25  Epoch: 490  Training loss = 4.0074  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 25  Epoch: 491  Training loss = 4.0072  Validation loss = 2.5726  \n",
      "\n",
      "Fold: 25  Epoch: 492  Training loss = 4.0071  Validation loss = 2.5726  \n",
      "\n",
      "Fold: 25  Epoch: 493  Training loss = 4.0070  Validation loss = 2.5724  \n",
      "\n",
      "Fold: 25  Epoch: 494  Training loss = 4.0069  Validation loss = 2.5724  \n",
      "\n",
      "Fold: 25  Epoch: 495  Training loss = 4.0068  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 25  Epoch: 496  Training loss = 4.0067  Validation loss = 2.5721  \n",
      "\n",
      "Fold: 25  Epoch: 497  Training loss = 4.0066  Validation loss = 2.5720  \n",
      "\n",
      "Fold: 25  Epoch: 498  Training loss = 4.0065  Validation loss = 2.5720  \n",
      "\n",
      "Fold: 25  Epoch: 499  Training loss = 4.0063  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 25  Epoch: 500  Training loss = 4.0061  Validation loss = 2.5717  \n",
      "\n",
      "Fold: 25  Epoch: 501  Training loss = 4.0059  Validation loss = 2.5714  \n",
      "\n",
      "Fold: 25  Epoch: 502  Training loss = 4.0058  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 25  Epoch: 503  Training loss = 4.0056  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 25  Epoch: 504  Training loss = 4.0055  Validation loss = 2.5709  \n",
      "\n",
      "Fold: 25  Epoch: 505  Training loss = 4.0054  Validation loss = 2.5707  \n",
      "\n",
      "Fold: 25  Epoch: 506  Training loss = 4.0053  Validation loss = 2.5707  \n",
      "\n",
      "Fold: 25  Epoch: 507  Training loss = 4.0052  Validation loss = 2.5706  \n",
      "\n",
      "Fold: 25  Epoch: 508  Training loss = 4.0051  Validation loss = 2.5705  \n",
      "\n",
      "Fold: 25  Epoch: 509  Training loss = 4.0049  Validation loss = 2.5703  \n",
      "\n",
      "Fold: 25  Epoch: 510  Training loss = 4.0048  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 25  Epoch: 511  Training loss = 4.0047  Validation loss = 2.5702  \n",
      "\n",
      "Fold: 25  Epoch: 512  Training loss = 4.0046  Validation loss = 2.5702  \n",
      "\n",
      "Fold: 25  Epoch: 513  Training loss = 4.0045  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 25  Epoch: 514  Training loss = 4.0044  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 25  Epoch: 515  Training loss = 4.0042  Validation loss = 2.5698  \n",
      "\n",
      "Fold: 25  Epoch: 516  Training loss = 4.0040  Validation loss = 2.5695  \n",
      "\n",
      "Fold: 25  Epoch: 517  Training loss = 4.0038  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 25  Epoch: 518  Training loss = 4.0036  Validation loss = 2.5690  \n",
      "\n",
      "Fold: 25  Epoch: 519  Training loss = 4.0035  Validation loss = 2.5687  \n",
      "\n",
      "Fold: 25  Epoch: 520  Training loss = 4.0034  Validation loss = 2.5687  \n",
      "\n",
      "Fold: 25  Epoch: 521  Training loss = 4.0034  Validation loss = 2.5687  \n",
      "\n",
      "Fold: 25  Epoch: 522  Training loss = 4.0032  Validation loss = 2.5684  \n",
      "\n",
      "Fold: 25  Epoch: 523  Training loss = 4.0031  Validation loss = 2.5681  \n",
      "\n",
      "Fold: 25  Epoch: 524  Training loss = 4.0029  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 25  Epoch: 525  Training loss = 4.0028  Validation loss = 2.5677  \n",
      "\n",
      "Fold: 25  Epoch: 526  Training loss = 4.0026  Validation loss = 2.5674  \n",
      "\n",
      "Fold: 25  Epoch: 527  Training loss = 4.0024  Validation loss = 2.5673  \n",
      "\n",
      "Fold: 25  Epoch: 528  Training loss = 4.0023  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 25  Epoch: 529  Training loss = 4.0021  Validation loss = 2.5669  \n",
      "\n",
      "Fold: 25  Epoch: 530  Training loss = 4.0020  Validation loss = 2.5669  \n",
      "\n",
      "Fold: 25  Epoch: 531  Training loss = 4.0019  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 25  Epoch: 532  Training loss = 4.0018  Validation loss = 2.5666  \n",
      "\n",
      "Fold: 25  Epoch: 533  Training loss = 4.0016  Validation loss = 2.5665  \n",
      "\n",
      "Fold: 25  Epoch: 534  Training loss = 4.0015  Validation loss = 2.5662  \n",
      "\n",
      "Fold: 25  Epoch: 535  Training loss = 4.0014  Validation loss = 2.5661  \n",
      "\n",
      "Fold: 25  Epoch: 536  Training loss = 4.0012  Validation loss = 2.5659  \n",
      "\n",
      "Fold: 25  Epoch: 537  Training loss = 4.0010  Validation loss = 2.5657  \n",
      "\n",
      "Fold: 25  Epoch: 538  Training loss = 4.0009  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 25  Epoch: 539  Training loss = 4.0007  Validation loss = 2.5653  \n",
      "\n",
      "Fold: 25  Epoch: 540  Training loss = 4.0005  Validation loss = 2.5651  \n",
      "\n",
      "Fold: 25  Epoch: 541  Training loss = 4.0004  Validation loss = 2.5649  \n",
      "\n",
      "Fold: 25  Epoch: 542  Training loss = 4.0002  Validation loss = 2.5646  \n",
      "\n",
      "Fold: 25  Epoch: 543  Training loss = 4.0000  Validation loss = 2.5644  \n",
      "\n",
      "Fold: 25  Epoch: 544  Training loss = 3.9999  Validation loss = 2.5641  \n",
      "\n",
      "Fold: 25  Epoch: 545  Training loss = 3.9998  Validation loss = 2.5641  \n",
      "\n",
      "Fold: 25  Epoch: 546  Training loss = 3.9996  Validation loss = 2.5639  \n",
      "\n",
      "Fold: 25  Epoch: 547  Training loss = 3.9995  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 25  Epoch: 548  Training loss = 3.9993  Validation loss = 2.5635  \n",
      "\n",
      "Fold: 25  Epoch: 549  Training loss = 3.9992  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 25  Epoch: 550  Training loss = 3.9990  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 25  Epoch: 551  Training loss = 3.9988  Validation loss = 2.5626  \n",
      "\n",
      "Fold: 25  Epoch: 552  Training loss = 3.9987  Validation loss = 2.5623  \n",
      "\n",
      "Fold: 25  Epoch: 553  Training loss = 3.9986  Validation loss = 2.5620  \n",
      "\n",
      "Fold: 25  Epoch: 554  Training loss = 3.9984  Validation loss = 2.5620  \n",
      "\n",
      "Fold: 25  Epoch: 555  Training loss = 3.9983  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 25  Epoch: 556  Training loss = 3.9982  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 25  Epoch: 557  Training loss = 3.9981  Validation loss = 2.5615  \n",
      "\n",
      "Fold: 25  Epoch: 558  Training loss = 3.9979  Validation loss = 2.5612  \n",
      "\n",
      "Fold: 25  Epoch: 559  Training loss = 3.9977  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 25  Epoch: 560  Training loss = 3.9976  Validation loss = 2.5608  \n",
      "\n",
      "Fold: 25  Epoch: 561  Training loss = 3.9974  Validation loss = 2.5606  \n",
      "\n",
      "Fold: 25  Epoch: 562  Training loss = 3.9973  Validation loss = 2.5607  \n",
      "\n",
      "Fold: 25  Epoch: 563  Training loss = 3.9972  Validation loss = 2.5606  \n",
      "\n",
      "Fold: 25  Epoch: 564  Training loss = 3.9970  Validation loss = 2.5603  \n",
      "\n",
      "Fold: 25  Epoch: 565  Training loss = 3.9969  Validation loss = 2.5601  \n",
      "\n",
      "Fold: 25  Epoch: 566  Training loss = 3.9968  Validation loss = 2.5601  \n",
      "\n",
      "Fold: 25  Epoch: 567  Training loss = 3.9967  Validation loss = 2.5599  \n",
      "\n",
      "Fold: 25  Epoch: 568  Training loss = 3.9965  Validation loss = 2.5597  \n",
      "\n",
      "Fold: 25  Epoch: 569  Training loss = 3.9964  Validation loss = 2.5595  \n",
      "\n",
      "Fold: 25  Epoch: 570  Training loss = 3.9962  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 25  Epoch: 571  Training loss = 3.9961  Validation loss = 2.5590  \n",
      "\n",
      "Fold: 25  Epoch: 572  Training loss = 3.9960  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 25  Epoch: 573  Training loss = 3.9959  Validation loss = 2.5587  \n",
      "\n",
      "Fold: 25  Epoch: 574  Training loss = 3.9957  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 25  Epoch: 575  Training loss = 3.9955  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 25  Epoch: 576  Training loss = 3.9953  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 25  Epoch: 577  Training loss = 3.9952  Validation loss = 2.5578  \n",
      "\n",
      "Fold: 25  Epoch: 578  Training loss = 3.9950  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 25  Epoch: 579  Training loss = 3.9949  Validation loss = 2.5572  \n",
      "\n",
      "Fold: 25  Epoch: 580  Training loss = 3.9947  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 25  Epoch: 581  Training loss = 3.9945  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 25  Epoch: 582  Training loss = 3.9944  Validation loss = 2.5570  \n",
      "\n",
      "Fold: 25  Epoch: 583  Training loss = 3.9943  Validation loss = 2.5568  \n",
      "\n",
      "Fold: 25  Epoch: 584  Training loss = 3.9941  Validation loss = 2.5566  \n",
      "\n",
      "Fold: 25  Epoch: 585  Training loss = 3.9939  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 25  Epoch: 586  Training loss = 3.9937  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 25  Epoch: 587  Training loss = 3.9936  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 25  Epoch: 588  Training loss = 3.9934  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 25  Epoch: 589  Training loss = 3.9933  Validation loss = 2.5558  \n",
      "\n",
      "Fold: 25  Epoch: 590  Training loss = 3.9932  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 25  Epoch: 591  Training loss = 3.9930  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 25  Epoch: 592  Training loss = 3.9929  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 25  Epoch: 593  Training loss = 3.9928  Validation loss = 2.5551  \n",
      "\n",
      "Fold: 25  Epoch: 594  Training loss = 3.9927  Validation loss = 2.5551  \n",
      "\n",
      "Fold: 25  Epoch: 595  Training loss = 3.9925  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 25  Epoch: 596  Training loss = 3.9923  Validation loss = 2.5546  \n",
      "\n",
      "Fold: 25  Epoch: 597  Training loss = 3.9922  Validation loss = 2.5544  \n",
      "\n",
      "Fold: 25  Epoch: 598  Training loss = 3.9920  Validation loss = 2.5542  \n",
      "\n",
      "Fold: 25  Epoch: 599  Training loss = 3.9919  Validation loss = 2.5539  \n",
      "\n",
      "Fold: 25  Epoch: 600  Training loss = 3.9917  Validation loss = 2.5537  \n",
      "\n",
      "Fold: 25  Epoch: 601  Training loss = 3.9915  Validation loss = 2.5535  \n",
      "\n",
      "Fold: 25  Epoch: 602  Training loss = 3.9914  Validation loss = 2.5534  \n",
      "\n",
      "Fold: 25  Epoch: 603  Training loss = 3.9913  Validation loss = 2.5532  \n",
      "\n",
      "Fold: 25  Epoch: 604  Training loss = 3.9911  Validation loss = 2.5531  \n",
      "\n",
      "Fold: 25  Epoch: 605  Training loss = 3.9910  Validation loss = 2.5530  \n",
      "\n",
      "Fold: 25  Epoch: 606  Training loss = 3.9909  Validation loss = 2.5530  \n",
      "\n",
      "Fold: 25  Epoch: 607  Training loss = 3.9907  Validation loss = 2.5527  \n",
      "\n",
      "Fold: 25  Epoch: 608  Training loss = 3.9906  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 25  Epoch: 609  Training loss = 3.9905  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 25  Epoch: 610  Training loss = 3.9904  Validation loss = 2.5524  \n",
      "\n",
      "Fold: 25  Epoch: 611  Training loss = 3.9903  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 25  Epoch: 612  Training loss = 3.9902  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 25  Epoch: 613  Training loss = 3.9900  Validation loss = 2.5520  \n",
      "\n",
      "Fold: 25  Epoch: 614  Training loss = 3.9899  Validation loss = 2.5518  \n",
      "\n",
      "Fold: 25  Epoch: 615  Training loss = 3.9897  Validation loss = 2.5516  \n",
      "\n",
      "Fold: 25  Epoch: 616  Training loss = 3.9896  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 25  Epoch: 617  Training loss = 3.9895  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 25  Epoch: 618  Training loss = 3.9893  Validation loss = 2.5509  \n",
      "\n",
      "Fold: 25  Epoch: 619  Training loss = 3.9891  Validation loss = 2.5506  \n",
      "\n",
      "Fold: 25  Epoch: 620  Training loss = 3.9890  Validation loss = 2.5506  \n",
      "\n",
      "Fold: 25  Epoch: 621  Training loss = 3.9889  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 25  Epoch: 622  Training loss = 3.9888  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 25  Epoch: 623  Training loss = 3.9886  Validation loss = 2.5501  \n",
      "\n",
      "Fold: 25  Epoch: 624  Training loss = 3.9885  Validation loss = 2.5498  \n",
      "\n",
      "Fold: 25  Epoch: 625  Training loss = 3.9883  Validation loss = 2.5496  \n",
      "\n",
      "Fold: 25  Epoch: 626  Training loss = 3.9882  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 25  Epoch: 627  Training loss = 3.9880  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 25  Epoch: 628  Training loss = 3.9879  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 25  Epoch: 629  Training loss = 3.9878  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 25  Epoch: 630  Training loss = 3.9877  Validation loss = 2.5491  \n",
      "\n",
      "Fold: 25  Epoch: 631  Training loss = 3.9876  Validation loss = 2.5489  \n",
      "\n",
      "Fold: 25  Epoch: 632  Training loss = 3.9874  Validation loss = 2.5485  \n",
      "\n",
      "Fold: 25  Epoch: 633  Training loss = 3.9873  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 25  Epoch: 634  Training loss = 3.9871  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 25  Epoch: 635  Training loss = 3.9870  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 25  Epoch: 636  Training loss = 3.9868  Validation loss = 2.5479  \n",
      "\n",
      "Fold: 25  Epoch: 637  Training loss = 3.9866  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 25  Epoch: 638  Training loss = 3.9865  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 25  Epoch: 639  Training loss = 3.9864  Validation loss = 2.5473  \n",
      "\n",
      "Fold: 25  Epoch: 640  Training loss = 3.9863  Validation loss = 2.5472  \n",
      "\n",
      "Fold: 25  Epoch: 641  Training loss = 3.9861  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 25  Epoch: 642  Training loss = 3.9859  Validation loss = 2.5468  \n",
      "\n",
      "Fold: 25  Epoch: 643  Training loss = 3.9857  Validation loss = 2.5466  \n",
      "\n",
      "Fold: 25  Epoch: 644  Training loss = 3.9856  Validation loss = 2.5464  \n",
      "\n",
      "Fold: 25  Epoch: 645  Training loss = 3.9855  Validation loss = 2.5464  \n",
      "\n",
      "Fold: 25  Epoch: 646  Training loss = 3.9854  Validation loss = 2.5463  \n",
      "\n",
      "Fold: 25  Epoch: 647  Training loss = 3.9852  Validation loss = 2.5462  \n",
      "\n",
      "Fold: 25  Epoch: 648  Training loss = 3.9851  Validation loss = 2.5461  \n",
      "\n",
      "Fold: 25  Epoch: 649  Training loss = 3.9850  Validation loss = 2.5459  \n",
      "\n",
      "Fold: 25  Epoch: 650  Training loss = 3.9849  Validation loss = 2.5459  \n",
      "\n",
      "Fold: 25  Epoch: 651  Training loss = 3.9848  Validation loss = 2.5455  \n",
      "\n",
      "Fold: 25  Epoch: 652  Training loss = 3.9846  Validation loss = 2.5454  \n",
      "\n",
      "Fold: 25  Epoch: 653  Training loss = 3.9845  Validation loss = 2.5453  \n",
      "\n",
      "Fold: 25  Epoch: 654  Training loss = 3.9844  Validation loss = 2.5452  \n",
      "\n",
      "Fold: 25  Epoch: 655  Training loss = 3.9842  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 25  Epoch: 656  Training loss = 3.9841  Validation loss = 2.5448  \n",
      "\n",
      "Fold: 25  Epoch: 657  Training loss = 3.9839  Validation loss = 2.5445  \n",
      "\n",
      "Fold: 25  Epoch: 658  Training loss = 3.9838  Validation loss = 2.5443  \n",
      "\n",
      "Fold: 25  Epoch: 659  Training loss = 3.9836  Validation loss = 2.5441  \n",
      "\n",
      "Fold: 25  Epoch: 660  Training loss = 3.9834  Validation loss = 2.5439  \n",
      "\n",
      "Fold: 25  Epoch: 661  Training loss = 3.9833  Validation loss = 2.5437  \n",
      "\n",
      "Fold: 25  Epoch: 662  Training loss = 3.9832  Validation loss = 2.5437  \n",
      "\n",
      "Fold: 25  Epoch: 663  Training loss = 3.9830  Validation loss = 2.5436  \n",
      "\n",
      "Fold: 25  Epoch: 664  Training loss = 3.9829  Validation loss = 2.5435  \n",
      "\n",
      "Fold: 25  Epoch: 665  Training loss = 3.9828  Validation loss = 2.5434  \n",
      "\n",
      "Fold: 25  Epoch: 666  Training loss = 3.9826  Validation loss = 2.5433  \n",
      "\n",
      "Fold: 25  Epoch: 667  Training loss = 3.9824  Validation loss = 2.5431  \n",
      "\n",
      "Fold: 25  Epoch: 668  Training loss = 3.9823  Validation loss = 2.5427  \n",
      "\n",
      "Fold: 25  Epoch: 669  Training loss = 3.9821  Validation loss = 2.5425  \n",
      "\n",
      "Fold: 25  Epoch: 670  Training loss = 3.9820  Validation loss = 2.5424  \n",
      "\n",
      "Fold: 25  Epoch: 671  Training loss = 3.9819  Validation loss = 2.5423  \n",
      "\n",
      "Fold: 25  Epoch: 672  Training loss = 3.9817  Validation loss = 2.5423  \n",
      "\n",
      "Fold: 25  Epoch: 673  Training loss = 3.9816  Validation loss = 2.5421  \n",
      "\n",
      "Fold: 25  Epoch: 674  Training loss = 3.9815  Validation loss = 2.5419  \n",
      "\n",
      "Fold: 25  Epoch: 675  Training loss = 3.9814  Validation loss = 2.5419  \n",
      "\n",
      "Fold: 25  Epoch: 676  Training loss = 3.9813  Validation loss = 2.5416  \n",
      "\n",
      "Fold: 25  Epoch: 677  Training loss = 3.9811  Validation loss = 2.5414  \n",
      "\n",
      "Fold: 25  Epoch: 678  Training loss = 3.9809  Validation loss = 2.5411  \n",
      "\n",
      "Fold: 25  Epoch: 679  Training loss = 3.9808  Validation loss = 2.5409  \n",
      "\n",
      "Fold: 25  Epoch: 680  Training loss = 3.9806  Validation loss = 2.5407  \n",
      "\n",
      "Fold: 25  Epoch: 681  Training loss = 3.9805  Validation loss = 2.5405  \n",
      "\n",
      "Fold: 25  Epoch: 682  Training loss = 3.9803  Validation loss = 2.5402  \n",
      "\n",
      "Fold: 25  Epoch: 683  Training loss = 3.9802  Validation loss = 2.5402  \n",
      "\n",
      "Fold: 25  Epoch: 684  Training loss = 3.9800  Validation loss = 2.5400  \n",
      "\n",
      "Fold: 25  Epoch: 685  Training loss = 3.9799  Validation loss = 2.5398  \n",
      "\n",
      "Fold: 25  Epoch: 686  Training loss = 3.9798  Validation loss = 2.5399  \n",
      "\n",
      "Fold: 25  Epoch: 687  Training loss = 3.9796  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 25  Epoch: 688  Training loss = 3.9795  Validation loss = 2.5394  \n",
      "\n",
      "Fold: 25  Epoch: 689  Training loss = 3.9794  Validation loss = 2.5395  \n",
      "\n",
      "Fold: 25  Epoch: 690  Training loss = 3.9792  Validation loss = 2.5393  \n",
      "\n",
      "Fold: 25  Epoch: 691  Training loss = 3.9791  Validation loss = 2.5392  \n",
      "\n",
      "Fold: 25  Epoch: 692  Training loss = 3.9790  Validation loss = 2.5390  \n",
      "\n",
      "Fold: 25  Epoch: 693  Training loss = 3.9788  Validation loss = 2.5387  \n",
      "\n",
      "Fold: 25  Epoch: 694  Training loss = 3.9787  Validation loss = 2.5385  \n",
      "\n",
      "Fold: 25  Epoch: 695  Training loss = 3.9785  Validation loss = 2.5382  \n",
      "\n",
      "Fold: 25  Epoch: 696  Training loss = 3.9784  Validation loss = 2.5381  \n",
      "\n",
      "Fold: 25  Epoch: 697  Training loss = 3.9782  Validation loss = 2.5377  \n",
      "\n",
      "Fold: 25  Epoch: 698  Training loss = 3.9781  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 25  Epoch: 699  Training loss = 3.9779  Validation loss = 2.5376  \n",
      "\n",
      "Fold: 25  Epoch: 700  Training loss = 3.9778  Validation loss = 2.5373  \n",
      "\n",
      "Fold: 25  Epoch: 701  Training loss = 3.9776  Validation loss = 2.5371  \n",
      "\n",
      "Fold: 25  Epoch: 702  Training loss = 3.9775  Validation loss = 2.5370  \n",
      "\n",
      "Fold: 25  Epoch: 703  Training loss = 3.9774  Validation loss = 2.5371  \n",
      "\n",
      "Fold: 25  Epoch: 704  Training loss = 3.9773  Validation loss = 2.5367  \n",
      "\n",
      "Fold: 25  Epoch: 705  Training loss = 3.9771  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 25  Epoch: 706  Training loss = 3.9769  Validation loss = 2.5360  \n",
      "\n",
      "Fold: 25  Epoch: 707  Training loss = 3.9768  Validation loss = 2.5358  \n",
      "\n",
      "Fold: 25  Epoch: 708  Training loss = 3.9767  Validation loss = 2.5359  \n",
      "\n",
      "Fold: 25  Epoch: 709  Training loss = 3.9765  Validation loss = 2.5358  \n",
      "\n",
      "Fold: 25  Epoch: 710  Training loss = 3.9764  Validation loss = 2.5356  \n",
      "\n",
      "Fold: 25  Epoch: 711  Training loss = 3.9762  Validation loss = 2.5355  \n",
      "\n",
      "Fold: 25  Epoch: 712  Training loss = 3.9761  Validation loss = 2.5354  \n",
      "\n",
      "Fold: 25  Epoch: 713  Training loss = 3.9760  Validation loss = 2.5352  \n",
      "\n",
      "Fold: 25  Epoch: 714  Training loss = 3.9758  Validation loss = 2.5351  \n",
      "\n",
      "Fold: 25  Epoch: 715  Training loss = 3.9756  Validation loss = 2.5349  \n",
      "\n",
      "Fold: 25  Epoch: 716  Training loss = 3.9756  Validation loss = 2.5350  \n",
      "\n",
      "Fold: 25  Epoch: 717  Training loss = 3.9755  Validation loss = 2.5351  \n",
      "\n",
      "Fold: 25  Epoch: 718  Training loss = 3.9754  Validation loss = 2.5348  \n",
      "\n",
      "Fold: 25  Epoch: 719  Training loss = 3.9753  Validation loss = 2.5348  \n",
      "\n",
      "Fold: 25  Epoch: 720  Training loss = 3.9751  Validation loss = 2.5347  \n",
      "\n",
      "Fold: 25  Epoch: 721  Training loss = 3.9751  Validation loss = 2.5349  \n",
      "\n",
      "Fold: 25  Epoch: 722  Training loss = 3.9750  Validation loss = 2.5347  \n",
      "\n",
      "Fold: 25  Epoch: 723  Training loss = 3.9748  Validation loss = 2.5346  \n",
      "\n",
      "Fold: 25  Epoch: 724  Training loss = 3.9747  Validation loss = 2.5344  \n",
      "\n",
      "Fold: 25  Epoch: 725  Training loss = 3.9745  Validation loss = 2.5343  \n",
      "\n",
      "Fold: 25  Epoch: 726  Training loss = 3.9744  Validation loss = 2.5342  \n",
      "\n",
      "Fold: 25  Epoch: 727  Training loss = 3.9743  Validation loss = 2.5341  \n",
      "\n",
      "Fold: 25  Epoch: 728  Training loss = 3.9741  Validation loss = 2.5340  \n",
      "\n",
      "Fold: 25  Epoch: 729  Training loss = 3.9741  Validation loss = 2.5340  \n",
      "\n",
      "Fold: 25  Epoch: 730  Training loss = 3.9740  Validation loss = 2.5338  \n",
      "\n",
      "Fold: 25  Epoch: 731  Training loss = 3.9738  Validation loss = 2.5334  \n",
      "\n",
      "Fold: 25  Epoch: 732  Training loss = 3.9737  Validation loss = 2.5334  \n",
      "\n",
      "Fold: 25  Epoch: 733  Training loss = 3.9735  Validation loss = 2.5331  \n",
      "\n",
      "Fold: 25  Epoch: 734  Training loss = 3.9734  Validation loss = 2.5330  \n",
      "\n",
      "Fold: 25  Epoch: 735  Training loss = 3.9733  Validation loss = 2.5328  \n",
      "\n",
      "Fold: 25  Epoch: 736  Training loss = 3.9732  Validation loss = 2.5326  \n",
      "\n",
      "Fold: 25  Epoch: 737  Training loss = 3.9731  Validation loss = 2.5327  \n",
      "\n",
      "Fold: 25  Epoch: 738  Training loss = 3.9729  Validation loss = 2.5323  \n",
      "\n",
      "Fold: 25  Epoch: 739  Training loss = 3.9728  Validation loss = 2.5322  \n",
      "\n",
      "Fold: 25  Epoch: 740  Training loss = 3.9726  Validation loss = 2.5319  \n",
      "\n",
      "Fold: 25  Epoch: 741  Training loss = 3.9725  Validation loss = 2.5318  \n",
      "\n",
      "Fold: 25  Epoch: 742  Training loss = 3.9724  Validation loss = 2.5317  \n",
      "\n",
      "Fold: 25  Epoch: 743  Training loss = 3.9723  Validation loss = 2.5315  \n",
      "\n",
      "Fold: 25  Epoch: 744  Training loss = 3.9721  Validation loss = 2.5313  \n",
      "\n",
      "Fold: 25  Epoch: 745  Training loss = 3.9719  Validation loss = 2.5312  \n",
      "\n",
      "Fold: 25  Epoch: 746  Training loss = 3.9718  Validation loss = 2.5310  \n",
      "\n",
      "Fold: 25  Epoch: 747  Training loss = 3.9717  Validation loss = 2.5308  \n",
      "\n",
      "Fold: 25  Epoch: 748  Training loss = 3.9715  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 25  Epoch: 749  Training loss = 3.9714  Validation loss = 2.5305  \n",
      "\n",
      "Fold: 25  Epoch: 750  Training loss = 3.9713  Validation loss = 2.5304  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 750  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.7113  Validation loss = 1.6189  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.7113  Validation loss = 1.6185  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.7111  Validation loss = 1.6186  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.7110  Validation loss = 1.6186  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.7109  Validation loss = 1.6184  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.7108  Validation loss = 1.6190  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.7106  Validation loss = 1.6190  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.7106  Validation loss = 1.6197  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.7104  Validation loss = 1.6194  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.7103  Validation loss = 1.6192  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.7102  Validation loss = 1.6196  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 3.7101  Validation loss = 1.6192  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 3.7101  Validation loss = 1.6193  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 3.7099  Validation loss = 1.6214  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 3.7098  Validation loss = 1.6220  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 3.7097  Validation loss = 1.6231  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 5  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.5892  Validation loss = 1.2876  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.5891  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.5890  Validation loss = 1.2871  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.5889  Validation loss = 1.2873  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.5887  Validation loss = 1.2871  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.5886  Validation loss = 1.2870  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.5885  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.5884  Validation loss = 1.2874  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.5883  Validation loss = 1.2874  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.5882  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.5881  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 3.5879  Validation loss = 1.2871  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 3.5879  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 3.5877  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 3.5876  Validation loss = 1.2869  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 3.5874  Validation loss = 1.2870  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 3.5873  Validation loss = 1.2870  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 3.5871  Validation loss = 1.2870  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 3.5870  Validation loss = 1.2871  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 3.5869  Validation loss = 1.2871  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 3.5868  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 3.5867  Validation loss = 1.2873  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 3.5866  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 3.5865  Validation loss = 1.2869  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 3.5864  Validation loss = 1.2868  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 3.5863  Validation loss = 1.2865  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 3.5861  Validation loss = 1.2864  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 3.5860  Validation loss = 1.2862  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 3.5859  Validation loss = 1.2862  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 3.5857  Validation loss = 1.2863  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 3.5857  Validation loss = 1.2863  \n",
      "\n",
      "Fold: 27  Epoch: 32  Training loss = 3.5855  Validation loss = 1.2862  \n",
      "\n",
      "Fold: 27  Epoch: 33  Training loss = 3.5854  Validation loss = 1.2861  \n",
      "\n",
      "Fold: 27  Epoch: 34  Training loss = 3.5853  Validation loss = 1.2859  \n",
      "\n",
      "Fold: 27  Epoch: 35  Training loss = 3.5852  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 27  Epoch: 36  Training loss = 3.5851  Validation loss = 1.2859  \n",
      "\n",
      "Fold: 27  Epoch: 37  Training loss = 3.5850  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 27  Epoch: 38  Training loss = 3.5849  Validation loss = 1.2859  \n",
      "\n",
      "Fold: 27  Epoch: 39  Training loss = 3.5848  Validation loss = 1.2858  \n",
      "\n",
      "Fold: 27  Epoch: 40  Training loss = 3.5847  Validation loss = 1.2857  \n",
      "\n",
      "Fold: 27  Epoch: 41  Training loss = 3.5846  Validation loss = 1.2857  \n",
      "\n",
      "Fold: 27  Epoch: 42  Training loss = 3.5845  Validation loss = 1.2857  \n",
      "\n",
      "Fold: 27  Epoch: 43  Training loss = 3.5843  Validation loss = 1.2856  \n",
      "\n",
      "Fold: 27  Epoch: 44  Training loss = 3.5843  Validation loss = 1.2858  \n",
      "\n",
      "Fold: 27  Epoch: 45  Training loss = 3.5842  Validation loss = 1.2858  \n",
      "\n",
      "Fold: 27  Epoch: 46  Training loss = 3.5841  Validation loss = 1.2858  \n",
      "\n",
      "Fold: 27  Epoch: 47  Training loss = 3.5840  Validation loss = 1.2857  \n",
      "\n",
      "Fold: 27  Epoch: 48  Training loss = 3.5839  Validation loss = 1.2858  \n",
      "\n",
      "Fold: 27  Epoch: 49  Training loss = 3.5838  Validation loss = 1.2859  \n",
      "\n",
      "Fold: 27  Epoch: 50  Training loss = 3.5836  Validation loss = 1.2859  \n",
      "\n",
      "Fold: 27  Epoch: 51  Training loss = 3.5835  Validation loss = 1.2859  \n",
      "\n",
      "Fold: 27  Epoch: 52  Training loss = 3.5834  Validation loss = 1.2857  \n",
      "\n",
      "Fold: 27  Epoch: 53  Training loss = 3.5833  Validation loss = 1.2859  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 43  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.5819  Validation loss = 1.9032  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.5817  Validation loss = 1.9026  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.5816  Validation loss = 1.9023  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.5815  Validation loss = 1.9025  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.5814  Validation loss = 1.9020  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.5812  Validation loss = 1.9016  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.5810  Validation loss = 1.9012  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.5809  Validation loss = 1.9012  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.5808  Validation loss = 1.9014  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.5806  Validation loss = 1.9012  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.5805  Validation loss = 1.9012  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.5804  Validation loss = 1.9014  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 3.5803  Validation loss = 1.9014  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 3.5802  Validation loss = 1.9011  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 3.5801  Validation loss = 1.9010  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 3.5800  Validation loss = 1.9011  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 3.5799  Validation loss = 1.9011  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 3.5798  Validation loss = 1.9010  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 3.5796  Validation loss = 1.9008  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 3.5795  Validation loss = 1.9003  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 3.5793  Validation loss = 1.9000  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 3.5792  Validation loss = 1.8998  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 3.5791  Validation loss = 1.8998  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 3.5790  Validation loss = 1.8996  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 3.5790  Validation loss = 1.8994  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 3.5788  Validation loss = 1.8992  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 3.5787  Validation loss = 1.8992  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 3.5786  Validation loss = 1.8989  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 3.5785  Validation loss = 1.8988  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 3.5784  Validation loss = 1.8989  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 3.5782  Validation loss = 1.8987  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 3.5781  Validation loss = 1.8987  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 3.5779  Validation loss = 1.8981  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 3.5778  Validation loss = 1.8980  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 3.5777  Validation loss = 1.8982  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 3.5776  Validation loss = 1.8982  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 3.5775  Validation loss = 1.8982  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 3.5774  Validation loss = 1.8979  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 3.5772  Validation loss = 1.8977  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 3.5772  Validation loss = 1.8977  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 3.5770  Validation loss = 1.8975  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 3.5769  Validation loss = 1.8974  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 3.5769  Validation loss = 1.8976  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 3.5767  Validation loss = 1.8971  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 3.5766  Validation loss = 1.8969  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 3.5764  Validation loss = 1.8968  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 3.5764  Validation loss = 1.8968  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 3.5762  Validation loss = 1.8969  \n",
      "\n",
      "Fold: 28  Epoch: 49  Training loss = 3.5761  Validation loss = 1.8965  \n",
      "\n",
      "Fold: 28  Epoch: 50  Training loss = 3.5759  Validation loss = 1.8963  \n",
      "\n",
      "Fold: 28  Epoch: 51  Training loss = 3.5758  Validation loss = 1.8963  \n",
      "\n",
      "Fold: 28  Epoch: 52  Training loss = 3.5757  Validation loss = 1.8962  \n",
      "\n",
      "Fold: 28  Epoch: 53  Training loss = 3.5756  Validation loss = 1.8958  \n",
      "\n",
      "Fold: 28  Epoch: 54  Training loss = 3.5755  Validation loss = 1.8955  \n",
      "\n",
      "Fold: 28  Epoch: 55  Training loss = 3.5753  Validation loss = 1.8955  \n",
      "\n",
      "Fold: 28  Epoch: 56  Training loss = 3.5752  Validation loss = 1.8957  \n",
      "\n",
      "Fold: 28  Epoch: 57  Training loss = 3.5751  Validation loss = 1.8953  \n",
      "\n",
      "Fold: 28  Epoch: 58  Training loss = 3.5750  Validation loss = 1.8953  \n",
      "\n",
      "Fold: 28  Epoch: 59  Training loss = 3.5749  Validation loss = 1.8948  \n",
      "\n",
      "Fold: 28  Epoch: 60  Training loss = 3.5747  Validation loss = 1.8947  \n",
      "\n",
      "Fold: 28  Epoch: 61  Training loss = 3.5746  Validation loss = 1.8945  \n",
      "\n",
      "Fold: 28  Epoch: 62  Training loss = 3.5745  Validation loss = 1.8944  \n",
      "\n",
      "Fold: 28  Epoch: 63  Training loss = 3.5743  Validation loss = 1.8942  \n",
      "\n",
      "Fold: 28  Epoch: 64  Training loss = 3.5742  Validation loss = 1.8940  \n",
      "\n",
      "Fold: 28  Epoch: 65  Training loss = 3.5741  Validation loss = 1.8945  \n",
      "\n",
      "Fold: 28  Epoch: 66  Training loss = 3.5740  Validation loss = 1.8945  \n",
      "\n",
      "Fold: 28  Epoch: 67  Training loss = 3.5739  Validation loss = 1.8944  \n",
      "\n",
      "Fold: 28  Epoch: 68  Training loss = 3.5737  Validation loss = 1.8943  \n",
      "\n",
      "Fold: 28  Epoch: 69  Training loss = 3.5737  Validation loss = 1.8945  \n",
      "\n",
      "Fold: 28  Epoch: 70  Training loss = 3.5735  Validation loss = 1.8941  \n",
      "\n",
      "Fold: 28  Epoch: 71  Training loss = 3.5735  Validation loss = 1.8943  \n",
      "\n",
      "Fold: 28  Epoch: 72  Training loss = 3.5734  Validation loss = 1.8944  \n",
      "\n",
      "Fold: 28  Epoch: 73  Training loss = 3.5733  Validation loss = 1.8944  \n",
      "\n",
      "Fold: 28  Epoch: 74  Training loss = 3.5732  Validation loss = 1.8940  \n",
      "\n",
      "Fold: 28  Epoch: 75  Training loss = 3.5730  Validation loss = 1.8941  \n",
      "\n",
      "Fold: 28  Epoch: 76  Training loss = 3.5729  Validation loss = 1.8938  \n",
      "\n",
      "Fold: 28  Epoch: 77  Training loss = 3.5727  Validation loss = 1.8937  \n",
      "\n",
      "Fold: 28  Epoch: 78  Training loss = 3.5725  Validation loss = 1.8932  \n",
      "\n",
      "Fold: 28  Epoch: 79  Training loss = 3.5725  Validation loss = 1.8934  \n",
      "\n",
      "Fold: 28  Epoch: 80  Training loss = 3.5724  Validation loss = 1.8935  \n",
      "\n",
      "Fold: 28  Epoch: 81  Training loss = 3.5722  Validation loss = 1.8931  \n",
      "\n",
      "Fold: 28  Epoch: 82  Training loss = 3.5721  Validation loss = 1.8927  \n",
      "\n",
      "Fold: 28  Epoch: 83  Training loss = 3.5720  Validation loss = 1.8921  \n",
      "\n",
      "Fold: 28  Epoch: 84  Training loss = 3.5718  Validation loss = 1.8915  \n",
      "\n",
      "Fold: 28  Epoch: 85  Training loss = 3.5717  Validation loss = 1.8916  \n",
      "\n",
      "Fold: 28  Epoch: 86  Training loss = 3.5716  Validation loss = 1.8916  \n",
      "\n",
      "Fold: 28  Epoch: 87  Training loss = 3.5716  Validation loss = 1.8919  \n",
      "\n",
      "Fold: 28  Epoch: 88  Training loss = 3.5715  Validation loss = 1.8916  \n",
      "\n",
      "Fold: 28  Epoch: 89  Training loss = 3.5714  Validation loss = 1.8913  \n",
      "\n",
      "Fold: 28  Epoch: 90  Training loss = 3.5713  Validation loss = 1.8912  \n",
      "\n",
      "Fold: 28  Epoch: 91  Training loss = 3.5712  Validation loss = 1.8914  \n",
      "\n",
      "Fold: 28  Epoch: 92  Training loss = 3.5711  Validation loss = 1.8915  \n",
      "\n",
      "Fold: 28  Epoch: 93  Training loss = 3.5710  Validation loss = 1.8916  \n",
      "\n",
      "Fold: 28  Epoch: 94  Training loss = 3.5709  Validation loss = 1.8912  \n",
      "\n",
      "Fold: 28  Epoch: 95  Training loss = 3.5708  Validation loss = 1.8910  \n",
      "\n",
      "Fold: 28  Epoch: 96  Training loss = 3.5707  Validation loss = 1.8905  \n",
      "\n",
      "Fold: 28  Epoch: 97  Training loss = 3.5706  Validation loss = 1.8905  \n",
      "\n",
      "Fold: 28  Epoch: 98  Training loss = 3.5705  Validation loss = 1.8906  \n",
      "\n",
      "Fold: 28  Epoch: 99  Training loss = 3.5704  Validation loss = 1.8905  \n",
      "\n",
      "Fold: 28  Epoch: 100  Training loss = 3.5703  Validation loss = 1.8903  \n",
      "\n",
      "Fold: 28  Epoch: 101  Training loss = 3.5702  Validation loss = 1.8901  \n",
      "\n",
      "Fold: 28  Epoch: 102  Training loss = 3.5701  Validation loss = 1.8905  \n",
      "\n",
      "Fold: 28  Epoch: 103  Training loss = 3.5701  Validation loss = 1.8905  \n",
      "\n",
      "Fold: 28  Epoch: 104  Training loss = 3.5700  Validation loss = 1.8907  \n",
      "\n",
      "Fold: 28  Epoch: 105  Training loss = 3.5699  Validation loss = 1.8907  \n",
      "\n",
      "Fold: 28  Epoch: 106  Training loss = 3.5698  Validation loss = 1.8907  \n",
      "\n",
      "Fold: 28  Epoch: 107  Training loss = 3.5697  Validation loss = 1.8907  \n",
      "\n",
      "Fold: 28  Epoch: 108  Training loss = 3.5696  Validation loss = 1.8901  \n",
      "\n",
      "Fold: 28  Epoch: 109  Training loss = 3.5695  Validation loss = 1.8900  \n",
      "\n",
      "Fold: 28  Epoch: 110  Training loss = 3.5695  Validation loss = 1.8903  \n",
      "\n",
      "Fold: 28  Epoch: 111  Training loss = 3.5694  Validation loss = 1.8900  \n",
      "\n",
      "Fold: 28  Epoch: 112  Training loss = 3.5693  Validation loss = 1.8895  \n",
      "\n",
      "Fold: 28  Epoch: 113  Training loss = 3.5692  Validation loss = 1.8895  \n",
      "\n",
      "Fold: 28  Epoch: 114  Training loss = 3.5691  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 28  Epoch: 115  Training loss = 3.5691  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 28  Epoch: 116  Training loss = 3.5690  Validation loss = 1.8897  \n",
      "\n",
      "Fold: 28  Epoch: 117  Training loss = 3.5689  Validation loss = 1.8899  \n",
      "\n",
      "Fold: 28  Epoch: 118  Training loss = 3.5688  Validation loss = 1.8902  \n",
      "\n",
      "Fold: 28  Epoch: 119  Training loss = 3.5688  Validation loss = 1.8903  \n",
      "\n",
      "Fold: 28  Epoch: 120  Training loss = 3.5687  Validation loss = 1.8902  \n",
      "\n",
      "Fold: 28  Epoch: 121  Training loss = 3.5687  Validation loss = 1.8905  \n",
      "\n",
      "Fold: 28  Epoch: 122  Training loss = 3.5685  Validation loss = 1.8899  \n",
      "\n",
      "Fold: 28  Epoch: 123  Training loss = 3.5685  Validation loss = 1.8897  \n",
      "\n",
      "Fold: 28  Epoch: 124  Training loss = 3.5684  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 28  Epoch: 125  Training loss = 3.5684  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 28  Epoch: 126  Training loss = 3.5683  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 28  Epoch: 127  Training loss = 3.5683  Validation loss = 1.8900  \n",
      "\n",
      "Fold: 28  Epoch: 128  Training loss = 3.5682  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 28  Epoch: 129  Training loss = 3.5680  Validation loss = 1.8895  \n",
      "\n",
      "Fold: 28  Epoch: 130  Training loss = 3.5680  Validation loss = 1.8895  \n",
      "\n",
      "Fold: 28  Epoch: 131  Training loss = 3.5679  Validation loss = 1.8893  \n",
      "\n",
      "Fold: 28  Epoch: 132  Training loss = 3.5678  Validation loss = 1.8891  \n",
      "\n",
      "Fold: 28  Epoch: 133  Training loss = 3.5677  Validation loss = 1.8891  \n",
      "\n",
      "Fold: 28  Epoch: 134  Training loss = 3.5676  Validation loss = 1.8893  \n",
      "\n",
      "Fold: 28  Epoch: 135  Training loss = 3.5675  Validation loss = 1.8893  \n",
      "\n",
      "Fold: 28  Epoch: 136  Training loss = 3.5675  Validation loss = 1.8891  \n",
      "\n",
      "Fold: 28  Epoch: 137  Training loss = 3.5675  Validation loss = 1.8895  \n",
      "\n",
      "Fold: 28  Epoch: 138  Training loss = 3.5674  Validation loss = 1.8893  \n",
      "\n",
      "Fold: 28  Epoch: 139  Training loss = 3.5673  Validation loss = 1.8897  \n",
      "\n",
      "Fold: 28  Epoch: 140  Training loss = 3.5672  Validation loss = 1.8894  \n",
      "\n",
      "Fold: 28  Epoch: 141  Training loss = 3.5672  Validation loss = 1.8891  \n",
      "\n",
      "Fold: 28  Epoch: 142  Training loss = 3.5671  Validation loss = 1.8891  \n",
      "\n",
      "Fold: 28  Epoch: 143  Training loss = 3.5671  Validation loss = 1.8893  \n",
      "\n",
      "Fold: 28  Epoch: 144  Training loss = 3.5670  Validation loss = 1.8893  \n",
      "\n",
      "Fold: 28  Epoch: 145  Training loss = 3.5669  Validation loss = 1.8893  \n",
      "\n",
      "Fold: 28  Epoch: 146  Training loss = 3.5668  Validation loss = 1.8892  \n",
      "\n",
      "Fold: 28  Epoch: 147  Training loss = 3.5668  Validation loss = 1.8892  \n",
      "\n",
      "Fold: 28  Epoch: 148  Training loss = 3.5667  Validation loss = 1.8893  \n",
      "\n",
      "Fold: 28  Epoch: 149  Training loss = 3.5666  Validation loss = 1.8895  \n",
      "\n",
      "Fold: 28  Epoch: 150  Training loss = 3.5665  Validation loss = 1.8888  \n",
      "\n",
      "Fold: 28  Epoch: 151  Training loss = 3.5664  Validation loss = 1.8887  \n",
      "\n",
      "Fold: 28  Epoch: 152  Training loss = 3.5663  Validation loss = 1.8889  \n",
      "\n",
      "Fold: 28  Epoch: 153  Training loss = 3.5662  Validation loss = 1.8889  \n",
      "\n",
      "Fold: 28  Epoch: 154  Training loss = 3.5662  Validation loss = 1.8890  \n",
      "\n",
      "Fold: 28  Epoch: 155  Training loss = 3.5660  Validation loss = 1.8890  \n",
      "\n",
      "Fold: 28  Epoch: 156  Training loss = 3.5659  Validation loss = 1.8885  \n",
      "\n",
      "Fold: 28  Epoch: 157  Training loss = 3.5658  Validation loss = 1.8884  \n",
      "\n",
      "Fold: 28  Epoch: 158  Training loss = 3.5658  Validation loss = 1.8883  \n",
      "\n",
      "Fold: 28  Epoch: 159  Training loss = 3.5657  Validation loss = 1.8883  \n",
      "\n",
      "Fold: 28  Epoch: 160  Training loss = 3.5656  Validation loss = 1.8884  \n",
      "\n",
      "Fold: 28  Epoch: 161  Training loss = 3.5655  Validation loss = 1.8884  \n",
      "\n",
      "Fold: 28  Epoch: 162  Training loss = 3.5654  Validation loss = 1.8880  \n",
      "\n",
      "Fold: 28  Epoch: 163  Training loss = 3.5653  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 28  Epoch: 164  Training loss = 3.5652  Validation loss = 1.8873  \n",
      "\n",
      "Fold: 28  Epoch: 165  Training loss = 3.5651  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 28  Epoch: 166  Training loss = 3.5651  Validation loss = 1.8875  \n",
      "\n",
      "Fold: 28  Epoch: 167  Training loss = 3.5649  Validation loss = 1.8872  \n",
      "\n",
      "Fold: 28  Epoch: 168  Training loss = 3.5648  Validation loss = 1.8875  \n",
      "\n",
      "Fold: 28  Epoch: 169  Training loss = 3.5648  Validation loss = 1.8875  \n",
      "\n",
      "Fold: 28  Epoch: 170  Training loss = 3.5647  Validation loss = 1.8879  \n",
      "\n",
      "Fold: 28  Epoch: 171  Training loss = 3.5647  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 28  Epoch: 172  Training loss = 3.5646  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 28  Epoch: 173  Training loss = 3.5646  Validation loss = 1.8880  \n",
      "\n",
      "Fold: 28  Epoch: 174  Training loss = 3.5644  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 28  Epoch: 175  Training loss = 3.5644  Validation loss = 1.8880  \n",
      "\n",
      "Fold: 28  Epoch: 176  Training loss = 3.5643  Validation loss = 1.8879  \n",
      "\n",
      "Fold: 28  Epoch: 177  Training loss = 3.5642  Validation loss = 1.8877  \n",
      "\n",
      "Fold: 28  Epoch: 178  Training loss = 3.5641  Validation loss = 1.8873  \n",
      "\n",
      "Fold: 28  Epoch: 179  Training loss = 3.5641  Validation loss = 1.8875  \n",
      "\n",
      "Fold: 28  Epoch: 180  Training loss = 3.5641  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 28  Epoch: 181  Training loss = 3.5640  Validation loss = 1.8879  \n",
      "\n",
      "Fold: 28  Epoch: 182  Training loss = 3.5639  Validation loss = 1.8874  \n",
      "\n",
      "Fold: 28  Epoch: 183  Training loss = 3.5638  Validation loss = 1.8873  \n",
      "\n",
      "Fold: 28  Epoch: 184  Training loss = 3.5637  Validation loss = 1.8870  \n",
      "\n",
      "Fold: 28  Epoch: 185  Training loss = 3.5636  Validation loss = 1.8868  \n",
      "\n",
      "Fold: 28  Epoch: 186  Training loss = 3.5636  Validation loss = 1.8868  \n",
      "\n",
      "Fold: 28  Epoch: 187  Training loss = 3.5636  Validation loss = 1.8868  \n",
      "\n",
      "Fold: 28  Epoch: 188  Training loss = 3.5635  Validation loss = 1.8870  \n",
      "\n",
      "Fold: 28  Epoch: 189  Training loss = 3.5634  Validation loss = 1.8869  \n",
      "\n",
      "Fold: 28  Epoch: 190  Training loss = 3.5633  Validation loss = 1.8868  \n",
      "\n",
      "Fold: 28  Epoch: 191  Training loss = 3.5632  Validation loss = 1.8870  \n",
      "\n",
      "Fold: 28  Epoch: 192  Training loss = 3.5631  Validation loss = 1.8874  \n",
      "\n",
      "Fold: 28  Epoch: 193  Training loss = 3.5631  Validation loss = 1.8874  \n",
      "\n",
      "Fold: 28  Epoch: 194  Training loss = 3.5630  Validation loss = 1.8875  \n",
      "\n",
      "Fold: 28  Epoch: 195  Training loss = 3.5629  Validation loss = 1.8873  \n",
      "\n",
      "Fold: 28  Epoch: 196  Training loss = 3.5628  Validation loss = 1.8874  \n",
      "\n",
      "Fold: 28  Epoch: 197  Training loss = 3.5628  Validation loss = 1.8874  \n",
      "\n",
      "Fold: 28  Epoch: 198  Training loss = 3.5627  Validation loss = 1.8873  \n",
      "\n",
      "Fold: 28  Epoch: 199  Training loss = 3.5626  Validation loss = 1.8872  \n",
      "\n",
      "Fold: 28  Epoch: 200  Training loss = 3.5626  Validation loss = 1.8871  \n",
      "\n",
      "Fold: 28  Epoch: 201  Training loss = 3.5625  Validation loss = 1.8871  \n",
      "\n",
      "Fold: 28  Epoch: 202  Training loss = 3.5624  Validation loss = 1.8870  \n",
      "\n",
      "Fold: 28  Epoch: 203  Training loss = 3.5623  Validation loss = 1.8869  \n",
      "\n",
      "Fold: 28  Epoch: 204  Training loss = 3.5623  Validation loss = 1.8872  \n",
      "\n",
      "Fold: 28  Epoch: 205  Training loss = 3.5622  Validation loss = 1.8872  \n",
      "\n",
      "Fold: 28  Epoch: 206  Training loss = 3.5621  Validation loss = 1.8872  \n",
      "\n",
      "Fold: 28  Epoch: 207  Training loss = 3.5620  Validation loss = 1.8870  \n",
      "\n",
      "Fold: 28  Epoch: 208  Training loss = 3.5619  Validation loss = 1.8873  \n",
      "\n",
      "Fold: 28  Epoch: 209  Training loss = 3.5619  Validation loss = 1.8876  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 187  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.5680  Validation loss = 1.2407  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.5680  Validation loss = 1.2407  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.5679  Validation loss = 1.2409  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.5678  Validation loss = 1.2408  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.5678  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.5677  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.5677  Validation loss = 1.2409  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.5676  Validation loss = 1.2405  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.5675  Validation loss = 1.2405  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.5675  Validation loss = 1.2408  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.5674  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 3.5674  Validation loss = 1.2412  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.5673  Validation loss = 1.2418  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 3.5673  Validation loss = 1.2421  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 3.5673  Validation loss = 1.2419  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 3.5672  Validation loss = 1.2416  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 3.5672  Validation loss = 1.2418  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 3.5671  Validation loss = 1.2423  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 8  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.5118  Validation loss = 1.8215  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.5117  Validation loss = 1.8221  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.5117  Validation loss = 1.8215  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.5116  Validation loss = 1.8213  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.5116  Validation loss = 1.8207  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.5115  Validation loss = 1.8204  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.5114  Validation loss = 1.8199  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.5113  Validation loss = 1.8194  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.5113  Validation loss = 1.8201  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.5112  Validation loss = 1.8193  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.5112  Validation loss = 1.8188  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.5111  Validation loss = 1.8181  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.5111  Validation loss = 1.8186  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 3.5110  Validation loss = 1.8182  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 3.5110  Validation loss = 1.8193  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 3.5110  Validation loss = 1.8196  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 3.5110  Validation loss = 1.8209  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 3.5109  Validation loss = 1.8212  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 3.5109  Validation loss = 1.8215  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 12  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 3.1643  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 3.1643  Validation loss = 1.1633  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 3.1643  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 3.1643  Validation loss = 1.1640  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 3.1642  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 3.1641  Validation loss = 1.1635  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 3.1641  Validation loss = 1.1637  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 3.1640  Validation loss = 1.1635  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 3.1640  Validation loss = 1.1630  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 3.1639  Validation loss = 1.1630  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 3.1639  Validation loss = 1.1632  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 3.1639  Validation loss = 1.1634  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 3.1639  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 3.1638  Validation loss = 1.1628  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 3.1638  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 3.1638  Validation loss = 1.1632  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 3.1637  Validation loss = 1.1628  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 3.1637  Validation loss = 1.1633  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 3.1637  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 3.1637  Validation loss = 1.1632  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 3.1636  Validation loss = 1.1630  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 3.1636  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 3.1635  Validation loss = 1.1618  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 3.1634  Validation loss = 1.1616  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 3.1634  Validation loss = 1.1618  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 3.1633  Validation loss = 1.1616  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 3.1634  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 3.1634  Validation loss = 1.1621  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 3.1633  Validation loss = 1.1617  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 3.1632  Validation loss = 1.1613  \n",
      "\n",
      "Fold: 31  Epoch: 31  Training loss = 3.1632  Validation loss = 1.1609  \n",
      "\n",
      "Fold: 31  Epoch: 32  Training loss = 3.1632  Validation loss = 1.1613  \n",
      "\n",
      "Fold: 31  Epoch: 33  Training loss = 3.1632  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 31  Epoch: 34  Training loss = 3.1631  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 31  Epoch: 35  Training loss = 3.1631  Validation loss = 1.1624  \n",
      "\n",
      "Fold: 31  Epoch: 36  Training loss = 3.1631  Validation loss = 1.1617  \n",
      "\n",
      "Fold: 31  Epoch: 37  Training loss = 3.1630  Validation loss = 1.1615  \n",
      "\n",
      "Fold: 31  Epoch: 38  Training loss = 3.1630  Validation loss = 1.1612  \n",
      "\n",
      "Fold: 31  Epoch: 39  Training loss = 3.1629  Validation loss = 1.1610  \n",
      "\n",
      "Fold: 31  Epoch: 40  Training loss = 3.1629  Validation loss = 1.1613  \n",
      "\n",
      "Fold: 31  Epoch: 41  Training loss = 3.1629  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 31  Epoch: 42  Training loss = 3.1629  Validation loss = 1.1613  \n",
      "\n",
      "Fold: 31  Epoch: 43  Training loss = 3.1628  Validation loss = 1.1610  \n",
      "\n",
      "Fold: 31  Epoch: 44  Training loss = 3.1628  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 31  Epoch: 45  Training loss = 3.1628  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 31  Epoch: 46  Training loss = 3.1627  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 31  Epoch: 47  Training loss = 3.1627  Validation loss = 1.1612  \n",
      "\n",
      "Fold: 31  Epoch: 48  Training loss = 3.1627  Validation loss = 1.1614  \n",
      "\n",
      "Fold: 31  Epoch: 49  Training loss = 3.1627  Validation loss = 1.1614  \n",
      "\n",
      "Fold: 31  Epoch: 50  Training loss = 3.1626  Validation loss = 1.1612  \n",
      "\n",
      "Fold: 31  Epoch: 51  Training loss = 3.1626  Validation loss = 1.1604  \n",
      "\n",
      "Fold: 31  Epoch: 52  Training loss = 3.1626  Validation loss = 1.1603  \n",
      "\n",
      "Fold: 31  Epoch: 53  Training loss = 3.1625  Validation loss = 1.1604  \n",
      "\n",
      "Fold: 31  Epoch: 54  Training loss = 3.1625  Validation loss = 1.1605  \n",
      "\n",
      "Fold: 31  Epoch: 55  Training loss = 3.1624  Validation loss = 1.1601  \n",
      "\n",
      "Fold: 31  Epoch: 56  Training loss = 3.1624  Validation loss = 1.1595  \n",
      "\n",
      "Fold: 31  Epoch: 57  Training loss = 3.1624  Validation loss = 1.1594  \n",
      "\n",
      "Fold: 31  Epoch: 58  Training loss = 3.1623  Validation loss = 1.1596  \n",
      "\n",
      "Fold: 31  Epoch: 59  Training loss = 3.1623  Validation loss = 1.1590  \n",
      "\n",
      "Fold: 31  Epoch: 60  Training loss = 3.1623  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 31  Epoch: 61  Training loss = 3.1623  Validation loss = 1.1586  \n",
      "\n",
      "Fold: 31  Epoch: 62  Training loss = 3.1623  Validation loss = 1.1586  \n",
      "\n",
      "Fold: 31  Epoch: 63  Training loss = 3.1622  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 31  Epoch: 64  Training loss = 3.1622  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 31  Epoch: 65  Training loss = 3.1622  Validation loss = 1.1577  \n",
      "\n",
      "Fold: 31  Epoch: 66  Training loss = 3.1622  Validation loss = 1.1575  \n",
      "\n",
      "Fold: 31  Epoch: 67  Training loss = 3.1621  Validation loss = 1.1575  \n",
      "\n",
      "Fold: 31  Epoch: 68  Training loss = 3.1621  Validation loss = 1.1580  \n",
      "\n",
      "Fold: 31  Epoch: 69  Training loss = 3.1621  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 31  Epoch: 70  Training loss = 3.1621  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 31  Epoch: 71  Training loss = 3.1620  Validation loss = 1.1588  \n",
      "\n",
      "Fold: 31  Epoch: 72  Training loss = 3.1620  Validation loss = 1.1585  \n",
      "\n",
      "Fold: 31  Epoch: 73  Training loss = 3.1620  Validation loss = 1.1580  \n",
      "\n",
      "Fold: 31  Epoch: 74  Training loss = 3.1619  Validation loss = 1.1575  \n",
      "\n",
      "Fold: 31  Epoch: 75  Training loss = 3.1619  Validation loss = 1.1577  \n",
      "\n",
      "Fold: 31  Epoch: 76  Training loss = 3.1619  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 31  Epoch: 77  Training loss = 3.1619  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 31  Epoch: 78  Training loss = 3.1619  Validation loss = 1.1580  \n",
      "\n",
      "Fold: 31  Epoch: 79  Training loss = 3.1619  Validation loss = 1.1579  \n",
      "\n",
      "Fold: 31  Epoch: 80  Training loss = 3.1619  Validation loss = 1.1582  \n",
      "\n",
      "Fold: 31  Epoch: 81  Training loss = 3.1618  Validation loss = 1.1582  \n",
      "\n",
      "Fold: 31  Epoch: 82  Training loss = 3.1618  Validation loss = 1.1577  \n",
      "\n",
      "Fold: 31  Epoch: 83  Training loss = 3.1618  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 31  Epoch: 84  Training loss = 3.1618  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 31  Epoch: 85  Training loss = 3.1617  Validation loss = 1.1581  \n",
      "\n",
      "Fold: 31  Epoch: 86  Training loss = 3.1617  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 31  Epoch: 87  Training loss = 3.1617  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 31  Epoch: 88  Training loss = 3.1617  Validation loss = 1.1575  \n",
      "\n",
      "Fold: 31  Epoch: 89  Training loss = 3.1617  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 31  Epoch: 90  Training loss = 3.1617  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 31  Epoch: 91  Training loss = 3.1616  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 31  Epoch: 92  Training loss = 3.1616  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 31  Epoch: 93  Training loss = 3.1616  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 31  Epoch: 94  Training loss = 3.1616  Validation loss = 1.1571  \n",
      "\n",
      "Fold: 31  Epoch: 95  Training loss = 3.1616  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 31  Epoch: 96  Training loss = 3.1615  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 31  Epoch: 97  Training loss = 3.1615  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 31  Epoch: 98  Training loss = 3.1615  Validation loss = 1.1564  \n",
      "\n",
      "Fold: 31  Epoch: 99  Training loss = 3.1615  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 31  Epoch: 100  Training loss = 3.1615  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 31  Epoch: 101  Training loss = 3.1614  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 31  Epoch: 102  Training loss = 3.1614  Validation loss = 1.1569  \n",
      "\n",
      "Fold: 31  Epoch: 103  Training loss = 3.1614  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 31  Epoch: 104  Training loss = 3.1614  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 31  Epoch: 105  Training loss = 3.1614  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 31  Epoch: 106  Training loss = 3.1614  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 31  Epoch: 107  Training loss = 3.1614  Validation loss = 1.1572  \n",
      "\n",
      "Fold: 31  Epoch: 108  Training loss = 3.1613  Validation loss = 1.1569  \n",
      "\n",
      "Fold: 31  Epoch: 109  Training loss = 3.1613  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 31  Epoch: 110  Training loss = 3.1613  Validation loss = 1.1572  \n",
      "\n",
      "Fold: 31  Epoch: 111  Training loss = 3.1613  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 31  Epoch: 112  Training loss = 3.1613  Validation loss = 1.1569  \n",
      "\n",
      "Fold: 31  Epoch: 113  Training loss = 3.1612  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 31  Epoch: 114  Training loss = 3.1612  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 31  Epoch: 115  Training loss = 3.1612  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 31  Epoch: 116  Training loss = 3.1611  Validation loss = 1.1571  \n",
      "\n",
      "Fold: 31  Epoch: 117  Training loss = 3.1611  Validation loss = 1.1572  \n",
      "\n",
      "Fold: 31  Epoch: 118  Training loss = 3.1611  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 31  Epoch: 119  Training loss = 3.1611  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 31  Epoch: 120  Training loss = 3.1611  Validation loss = 1.1573  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 98  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.3604  Validation loss = 2.8436  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.3601  Validation loss = 2.8423  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.3598  Validation loss = 2.8410  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.3599  Validation loss = 2.8411  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.3596  Validation loss = 2.8398  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.3593  Validation loss = 2.8385  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.3592  Validation loss = 2.8377  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.3589  Validation loss = 2.8366  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.3588  Validation loss = 2.8357  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.3586  Validation loss = 2.8345  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.3584  Validation loss = 2.8335  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.3581  Validation loss = 2.8321  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.3579  Validation loss = 2.8311  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.3577  Validation loss = 2.8300  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.3575  Validation loss = 2.8289  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.3574  Validation loss = 2.8281  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.3572  Validation loss = 2.8270  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.3570  Validation loss = 2.8259  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.3569  Validation loss = 2.8254  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.3567  Validation loss = 2.8245  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.3565  Validation loss = 2.8233  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.3563  Validation loss = 2.8222  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.3560  Validation loss = 2.8205  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.3558  Validation loss = 2.8198  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.3555  Validation loss = 2.8184  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.3554  Validation loss = 2.8178  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.3553  Validation loss = 2.8168  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.3551  Validation loss = 2.8161  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.3549  Validation loss = 2.8146  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.3547  Validation loss = 2.8138  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.3545  Validation loss = 2.8125  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.3543  Validation loss = 2.8113  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.3541  Validation loss = 2.8105  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.3539  Validation loss = 2.8092  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.3537  Validation loss = 2.8086  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.3536  Validation loss = 2.8076  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.3533  Validation loss = 2.8061  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.3532  Validation loss = 2.8056  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.3531  Validation loss = 2.8049  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.3529  Validation loss = 2.8043  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.3527  Validation loss = 2.8030  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.3525  Validation loss = 2.8017  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.3523  Validation loss = 2.8008  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.3521  Validation loss = 2.7997  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.3521  Validation loss = 2.7999  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.3520  Validation loss = 2.7991  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.3518  Validation loss = 2.7982  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.3516  Validation loss = 2.7973  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.3515  Validation loss = 2.7967  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.3513  Validation loss = 2.7953  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.3511  Validation loss = 2.7943  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.3510  Validation loss = 2.7938  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.3509  Validation loss = 2.7931  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.3507  Validation loss = 2.7916  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.3505  Validation loss = 2.7907  \n",
      "\n",
      "Fold: 32  Epoch: 56  Training loss = 2.3503  Validation loss = 2.7895  \n",
      "\n",
      "Fold: 32  Epoch: 57  Training loss = 2.3501  Validation loss = 2.7885  \n",
      "\n",
      "Fold: 32  Epoch: 58  Training loss = 2.3499  Validation loss = 2.7875  \n",
      "\n",
      "Fold: 32  Epoch: 59  Training loss = 2.3498  Validation loss = 2.7866  \n",
      "\n",
      "Fold: 32  Epoch: 60  Training loss = 2.3496  Validation loss = 2.7854  \n",
      "\n",
      "Fold: 32  Epoch: 61  Training loss = 2.3495  Validation loss = 2.7849  \n",
      "\n",
      "Fold: 32  Epoch: 62  Training loss = 2.3494  Validation loss = 2.7845  \n",
      "\n",
      "Fold: 32  Epoch: 63  Training loss = 2.3491  Validation loss = 2.7828  \n",
      "\n",
      "Fold: 32  Epoch: 64  Training loss = 2.3489  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 32  Epoch: 65  Training loss = 2.3488  Validation loss = 2.7812  \n",
      "\n",
      "Fold: 32  Epoch: 66  Training loss = 2.3487  Validation loss = 2.7803  \n",
      "\n",
      "Fold: 32  Epoch: 67  Training loss = 2.3485  Validation loss = 2.7792  \n",
      "\n",
      "Fold: 32  Epoch: 68  Training loss = 2.3483  Validation loss = 2.7780  \n",
      "\n",
      "Fold: 32  Epoch: 69  Training loss = 2.3481  Validation loss = 2.7767  \n",
      "\n",
      "Fold: 32  Epoch: 70  Training loss = 2.3479  Validation loss = 2.7758  \n",
      "\n",
      "Fold: 32  Epoch: 71  Training loss = 2.3478  Validation loss = 2.7752  \n",
      "\n",
      "Fold: 32  Epoch: 72  Training loss = 2.3477  Validation loss = 2.7743  \n",
      "\n",
      "Fold: 32  Epoch: 73  Training loss = 2.3475  Validation loss = 2.7736  \n",
      "\n",
      "Fold: 32  Epoch: 74  Training loss = 2.3474  Validation loss = 2.7725  \n",
      "\n",
      "Fold: 32  Epoch: 75  Training loss = 2.3473  Validation loss = 2.7721  \n",
      "\n",
      "Fold: 32  Epoch: 76  Training loss = 2.3471  Validation loss = 2.7708  \n",
      "\n",
      "Fold: 32  Epoch: 77  Training loss = 2.3470  Validation loss = 2.7702  \n",
      "\n",
      "Fold: 32  Epoch: 78  Training loss = 2.3468  Validation loss = 2.7694  \n",
      "\n",
      "Fold: 32  Epoch: 79  Training loss = 2.3467  Validation loss = 2.7690  \n",
      "\n",
      "Fold: 32  Epoch: 80  Training loss = 2.3467  Validation loss = 2.7691  \n",
      "\n",
      "Fold: 32  Epoch: 81  Training loss = 2.3465  Validation loss = 2.7681  \n",
      "\n",
      "Fold: 32  Epoch: 82  Training loss = 2.3464  Validation loss = 2.7676  \n",
      "\n",
      "Fold: 32  Epoch: 83  Training loss = 2.3463  Validation loss = 2.7669  \n",
      "\n",
      "Fold: 32  Epoch: 84  Training loss = 2.3461  Validation loss = 2.7657  \n",
      "\n",
      "Fold: 32  Epoch: 85  Training loss = 2.3461  Validation loss = 2.7654  \n",
      "\n",
      "Fold: 32  Epoch: 86  Training loss = 2.3459  Validation loss = 2.7647  \n",
      "\n",
      "Fold: 32  Epoch: 87  Training loss = 2.3458  Validation loss = 2.7637  \n",
      "\n",
      "Fold: 32  Epoch: 88  Training loss = 2.3457  Validation loss = 2.7632  \n",
      "\n",
      "Fold: 32  Epoch: 89  Training loss = 2.3456  Validation loss = 2.7627  \n",
      "\n",
      "Fold: 32  Epoch: 90  Training loss = 2.3454  Validation loss = 2.7614  \n",
      "\n",
      "Fold: 32  Epoch: 91  Training loss = 2.3454  Validation loss = 2.7612  \n",
      "\n",
      "Fold: 32  Epoch: 92  Training loss = 2.3452  Validation loss = 2.7601  \n",
      "\n",
      "Fold: 32  Epoch: 93  Training loss = 2.3452  Validation loss = 2.7602  \n",
      "\n",
      "Fold: 32  Epoch: 94  Training loss = 2.3450  Validation loss = 2.7594  \n",
      "\n",
      "Fold: 32  Epoch: 95  Training loss = 2.3450  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 32  Epoch: 96  Training loss = 2.3448  Validation loss = 2.7580  \n",
      "\n",
      "Fold: 32  Epoch: 97  Training loss = 2.3446  Validation loss = 2.7571  \n",
      "\n",
      "Fold: 32  Epoch: 98  Training loss = 2.3445  Validation loss = 2.7560  \n",
      "\n",
      "Fold: 32  Epoch: 99  Training loss = 2.3443  Validation loss = 2.7552  \n",
      "\n",
      "Fold: 32  Epoch: 100  Training loss = 2.3442  Validation loss = 2.7546  \n",
      "\n",
      "Fold: 32  Epoch: 101  Training loss = 2.3441  Validation loss = 2.7538  \n",
      "\n",
      "Fold: 32  Epoch: 102  Training loss = 2.3439  Validation loss = 2.7526  \n",
      "\n",
      "Fold: 32  Epoch: 103  Training loss = 2.3437  Validation loss = 2.7515  \n",
      "\n",
      "Fold: 32  Epoch: 104  Training loss = 2.3435  Validation loss = 2.7504  \n",
      "\n",
      "Fold: 32  Epoch: 105  Training loss = 2.3436  Validation loss = 2.7506  \n",
      "\n",
      "Fold: 32  Epoch: 106  Training loss = 2.3434  Validation loss = 2.7495  \n",
      "\n",
      "Fold: 32  Epoch: 107  Training loss = 2.3433  Validation loss = 2.7493  \n",
      "\n",
      "Fold: 32  Epoch: 108  Training loss = 2.3431  Validation loss = 2.7481  \n",
      "\n",
      "Fold: 32  Epoch: 109  Training loss = 2.3431  Validation loss = 2.7475  \n",
      "\n",
      "Fold: 32  Epoch: 110  Training loss = 2.3429  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 32  Epoch: 111  Training loss = 2.3429  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 32  Epoch: 112  Training loss = 2.3428  Validation loss = 2.7459  \n",
      "\n",
      "Fold: 32  Epoch: 113  Training loss = 2.3426  Validation loss = 2.7448  \n",
      "\n",
      "Fold: 32  Epoch: 114  Training loss = 2.3424  Validation loss = 2.7440  \n",
      "\n",
      "Fold: 32  Epoch: 115  Training loss = 2.3424  Validation loss = 2.7437  \n",
      "\n",
      "Fold: 32  Epoch: 116  Training loss = 2.3422  Validation loss = 2.7427  \n",
      "\n",
      "Fold: 32  Epoch: 117  Training loss = 2.3421  Validation loss = 2.7421  \n",
      "\n",
      "Fold: 32  Epoch: 118  Training loss = 2.3420  Validation loss = 2.7417  \n",
      "\n",
      "Fold: 32  Epoch: 119  Training loss = 2.3419  Validation loss = 2.7412  \n",
      "\n",
      "Fold: 32  Epoch: 120  Training loss = 2.3418  Validation loss = 2.7402  \n",
      "\n",
      "Fold: 32  Epoch: 121  Training loss = 2.3417  Validation loss = 2.7397  \n",
      "\n",
      "Fold: 32  Epoch: 122  Training loss = 2.3416  Validation loss = 2.7393  \n",
      "\n",
      "Fold: 32  Epoch: 123  Training loss = 2.3415  Validation loss = 2.7387  \n",
      "\n",
      "Fold: 32  Epoch: 124  Training loss = 2.3414  Validation loss = 2.7384  \n",
      "\n",
      "Fold: 32  Epoch: 125  Training loss = 2.3414  Validation loss = 2.7381  \n",
      "\n",
      "Fold: 32  Epoch: 126  Training loss = 2.3412  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 32  Epoch: 127  Training loss = 2.3411  Validation loss = 2.7363  \n",
      "\n",
      "Fold: 32  Epoch: 128  Training loss = 2.3409  Validation loss = 2.7355  \n",
      "\n",
      "Fold: 32  Epoch: 129  Training loss = 2.3409  Validation loss = 2.7351  \n",
      "\n",
      "Fold: 32  Epoch: 130  Training loss = 2.3407  Validation loss = 2.7343  \n",
      "\n",
      "Fold: 32  Epoch: 131  Training loss = 2.3406  Validation loss = 2.7336  \n",
      "\n",
      "Fold: 32  Epoch: 132  Training loss = 2.3404  Validation loss = 2.7326  \n",
      "\n",
      "Fold: 32  Epoch: 133  Training loss = 2.3402  Validation loss = 2.7314  \n",
      "\n",
      "Fold: 32  Epoch: 134  Training loss = 2.3403  Validation loss = 2.7322  \n",
      "\n",
      "Fold: 32  Epoch: 135  Training loss = 2.3401  Validation loss = 2.7310  \n",
      "\n",
      "Fold: 32  Epoch: 136  Training loss = 2.3400  Validation loss = 2.7303  \n",
      "\n",
      "Fold: 32  Epoch: 137  Training loss = 2.3398  Validation loss = 2.7294  \n",
      "\n",
      "Fold: 32  Epoch: 138  Training loss = 2.3398  Validation loss = 2.7293  \n",
      "\n",
      "Fold: 32  Epoch: 139  Training loss = 2.3397  Validation loss = 2.7288  \n",
      "\n",
      "Fold: 32  Epoch: 140  Training loss = 2.3397  Validation loss = 2.7285  \n",
      "\n",
      "Fold: 32  Epoch: 141  Training loss = 2.3395  Validation loss = 2.7277  \n",
      "\n",
      "Fold: 32  Epoch: 142  Training loss = 2.3394  Validation loss = 2.7267  \n",
      "\n",
      "Fold: 32  Epoch: 143  Training loss = 2.3392  Validation loss = 2.7258  \n",
      "\n",
      "Fold: 32  Epoch: 144  Training loss = 2.3391  Validation loss = 2.7251  \n",
      "\n",
      "Fold: 32  Epoch: 145  Training loss = 2.3389  Validation loss = 2.7241  \n",
      "\n",
      "Fold: 32  Epoch: 146  Training loss = 2.3388  Validation loss = 2.7235  \n",
      "\n",
      "Fold: 32  Epoch: 147  Training loss = 2.3388  Validation loss = 2.7232  \n",
      "\n",
      "Fold: 32  Epoch: 148  Training loss = 2.3388  Validation loss = 2.7232  \n",
      "\n",
      "Fold: 32  Epoch: 149  Training loss = 2.3386  Validation loss = 2.7223  \n",
      "\n",
      "Fold: 32  Epoch: 150  Training loss = 2.3385  Validation loss = 2.7217  \n",
      "\n",
      "Fold: 32  Epoch: 151  Training loss = 2.3384  Validation loss = 2.7211  \n",
      "\n",
      "Fold: 32  Epoch: 152  Training loss = 2.3382  Validation loss = 2.7200  \n",
      "\n",
      "Fold: 32  Epoch: 153  Training loss = 2.3381  Validation loss = 2.7189  \n",
      "\n",
      "Fold: 32  Epoch: 154  Training loss = 2.3380  Validation loss = 2.7183  \n",
      "\n",
      "Fold: 32  Epoch: 155  Training loss = 2.3378  Validation loss = 2.7175  \n",
      "\n",
      "Fold: 32  Epoch: 156  Training loss = 2.3378  Validation loss = 2.7178  \n",
      "\n",
      "Fold: 32  Epoch: 157  Training loss = 2.3377  Validation loss = 2.7173  \n",
      "\n",
      "Fold: 32  Epoch: 158  Training loss = 2.3377  Validation loss = 2.7176  \n",
      "\n",
      "Fold: 32  Epoch: 159  Training loss = 2.3377  Validation loss = 2.7172  \n",
      "\n",
      "Fold: 32  Epoch: 160  Training loss = 2.3376  Validation loss = 2.7167  \n",
      "\n",
      "Fold: 32  Epoch: 161  Training loss = 2.3373  Validation loss = 2.7152  \n",
      "\n",
      "Fold: 32  Epoch: 162  Training loss = 2.3373  Validation loss = 2.7151  \n",
      "\n",
      "Fold: 32  Epoch: 163  Training loss = 2.3371  Validation loss = 2.7140  \n",
      "\n",
      "Fold: 32  Epoch: 164  Training loss = 2.3370  Validation loss = 2.7132  \n",
      "\n",
      "Fold: 32  Epoch: 165  Training loss = 2.3368  Validation loss = 2.7124  \n",
      "\n",
      "Fold: 32  Epoch: 166  Training loss = 2.3368  Validation loss = 2.7121  \n",
      "\n",
      "Fold: 32  Epoch: 167  Training loss = 2.3367  Validation loss = 2.7121  \n",
      "\n",
      "Fold: 32  Epoch: 168  Training loss = 2.3367  Validation loss = 2.7118  \n",
      "\n",
      "Fold: 32  Epoch: 169  Training loss = 2.3366  Validation loss = 2.7113  \n",
      "\n",
      "Fold: 32  Epoch: 170  Training loss = 2.3365  Validation loss = 2.7107  \n",
      "\n",
      "Fold: 32  Epoch: 171  Training loss = 2.3363  Validation loss = 2.7098  \n",
      "\n",
      "Fold: 32  Epoch: 172  Training loss = 2.3362  Validation loss = 2.7088  \n",
      "\n",
      "Fold: 32  Epoch: 173  Training loss = 2.3361  Validation loss = 2.7086  \n",
      "\n",
      "Fold: 32  Epoch: 174  Training loss = 2.3360  Validation loss = 2.7081  \n",
      "\n",
      "Fold: 32  Epoch: 175  Training loss = 2.3360  Validation loss = 2.7081  \n",
      "\n",
      "Fold: 32  Epoch: 176  Training loss = 2.3360  Validation loss = 2.7079  \n",
      "\n",
      "Fold: 32  Epoch: 177  Training loss = 2.3358  Validation loss = 2.7070  \n",
      "\n",
      "Fold: 32  Epoch: 178  Training loss = 2.3357  Validation loss = 2.7063  \n",
      "\n",
      "Fold: 32  Epoch: 179  Training loss = 2.3356  Validation loss = 2.7055  \n",
      "\n",
      "Fold: 32  Epoch: 180  Training loss = 2.3355  Validation loss = 2.7051  \n",
      "\n",
      "Fold: 32  Epoch: 181  Training loss = 2.3354  Validation loss = 2.7045  \n",
      "\n",
      "Fold: 32  Epoch: 182  Training loss = 2.3353  Validation loss = 2.7041  \n",
      "\n",
      "Fold: 32  Epoch: 183  Training loss = 2.3351  Validation loss = 2.7033  \n",
      "\n",
      "Fold: 32  Epoch: 184  Training loss = 2.3351  Validation loss = 2.7028  \n",
      "\n",
      "Fold: 32  Epoch: 185  Training loss = 2.3349  Validation loss = 2.7022  \n",
      "\n",
      "Fold: 32  Epoch: 186  Training loss = 2.3348  Validation loss = 2.7013  \n",
      "\n",
      "Fold: 32  Epoch: 187  Training loss = 2.3346  Validation loss = 2.7003  \n",
      "\n",
      "Fold: 32  Epoch: 188  Training loss = 2.3346  Validation loss = 2.7000  \n",
      "\n",
      "Fold: 32  Epoch: 189  Training loss = 2.3344  Validation loss = 2.6993  \n",
      "\n",
      "Fold: 32  Epoch: 190  Training loss = 2.3344  Validation loss = 2.6990  \n",
      "\n",
      "Fold: 32  Epoch: 191  Training loss = 2.3343  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 32  Epoch: 192  Training loss = 2.3343  Validation loss = 2.6988  \n",
      "\n",
      "Fold: 32  Epoch: 193  Training loss = 2.3342  Validation loss = 2.6982  \n",
      "\n",
      "Fold: 32  Epoch: 194  Training loss = 2.3342  Validation loss = 2.6979  \n",
      "\n",
      "Fold: 32  Epoch: 195  Training loss = 2.3340  Validation loss = 2.6971  \n",
      "\n",
      "Fold: 32  Epoch: 196  Training loss = 2.3340  Validation loss = 2.6970  \n",
      "\n",
      "Fold: 32  Epoch: 197  Training loss = 2.3339  Validation loss = 2.6969  \n",
      "\n",
      "Fold: 32  Epoch: 198  Training loss = 2.3338  Validation loss = 2.6959  \n",
      "\n",
      "Fold: 32  Epoch: 199  Training loss = 2.3337  Validation loss = 2.6956  \n",
      "\n",
      "Fold: 32  Epoch: 200  Training loss = 2.3336  Validation loss = 2.6949  \n",
      "\n",
      "Fold: 32  Epoch: 201  Training loss = 2.3335  Validation loss = 2.6943  \n",
      "\n",
      "Fold: 32  Epoch: 202  Training loss = 2.3335  Validation loss = 2.6939  \n",
      "\n",
      "Fold: 32  Epoch: 203  Training loss = 2.3334  Validation loss = 2.6936  \n",
      "\n",
      "Fold: 32  Epoch: 204  Training loss = 2.3333  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 32  Epoch: 205  Training loss = 2.3331  Validation loss = 2.6917  \n",
      "\n",
      "Fold: 32  Epoch: 206  Training loss = 2.3330  Validation loss = 2.6910  \n",
      "\n",
      "Fold: 32  Epoch: 207  Training loss = 2.3329  Validation loss = 2.6909  \n",
      "\n",
      "Fold: 32  Epoch: 208  Training loss = 2.3328  Validation loss = 2.6900  \n",
      "\n",
      "Fold: 32  Epoch: 209  Training loss = 2.3327  Validation loss = 2.6893  \n",
      "\n",
      "Fold: 32  Epoch: 210  Training loss = 2.3325  Validation loss = 2.6886  \n",
      "\n",
      "Fold: 32  Epoch: 211  Training loss = 2.3325  Validation loss = 2.6883  \n",
      "\n",
      "Fold: 32  Epoch: 212  Training loss = 2.3324  Validation loss = 2.6879  \n",
      "\n",
      "Fold: 32  Epoch: 213  Training loss = 2.3323  Validation loss = 2.6869  \n",
      "\n",
      "Fold: 32  Epoch: 214  Training loss = 2.3322  Validation loss = 2.6863  \n",
      "\n",
      "Fold: 32  Epoch: 215  Training loss = 2.3320  Validation loss = 2.6856  \n",
      "\n",
      "Fold: 32  Epoch: 216  Training loss = 2.3319  Validation loss = 2.6849  \n",
      "\n",
      "Fold: 32  Epoch: 217  Training loss = 2.3319  Validation loss = 2.6845  \n",
      "\n",
      "Fold: 32  Epoch: 218  Training loss = 2.3317  Validation loss = 2.6837  \n",
      "\n",
      "Fold: 32  Epoch: 219  Training loss = 2.3316  Validation loss = 2.6829  \n",
      "\n",
      "Fold: 32  Epoch: 220  Training loss = 2.3315  Validation loss = 2.6820  \n",
      "\n",
      "Fold: 32  Epoch: 221  Training loss = 2.3314  Validation loss = 2.6817  \n",
      "\n",
      "Fold: 32  Epoch: 222  Training loss = 2.3313  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 32  Epoch: 223  Training loss = 2.3312  Validation loss = 2.6807  \n",
      "\n",
      "Fold: 32  Epoch: 224  Training loss = 2.3311  Validation loss = 2.6801  \n",
      "\n",
      "Fold: 32  Epoch: 225  Training loss = 2.3310  Validation loss = 2.6797  \n",
      "\n",
      "Fold: 32  Epoch: 226  Training loss = 2.3309  Validation loss = 2.6790  \n",
      "\n",
      "Fold: 32  Epoch: 227  Training loss = 2.3309  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 32  Epoch: 228  Training loss = 2.3308  Validation loss = 2.6787  \n",
      "\n",
      "Fold: 32  Epoch: 229  Training loss = 2.3307  Validation loss = 2.6777  \n",
      "\n",
      "Fold: 32  Epoch: 230  Training loss = 2.3305  Validation loss = 2.6770  \n",
      "\n",
      "Fold: 32  Epoch: 231  Training loss = 2.3304  Validation loss = 2.6761  \n",
      "\n",
      "Fold: 32  Epoch: 232  Training loss = 2.3304  Validation loss = 2.6761  \n",
      "\n",
      "Fold: 32  Epoch: 233  Training loss = 2.3302  Validation loss = 2.6752  \n",
      "\n",
      "Fold: 32  Epoch: 234  Training loss = 2.3301  Validation loss = 2.6745  \n",
      "\n",
      "Fold: 32  Epoch: 235  Training loss = 2.3300  Validation loss = 2.6737  \n",
      "\n",
      "Fold: 32  Epoch: 236  Training loss = 2.3299  Validation loss = 2.6733  \n",
      "\n",
      "Fold: 32  Epoch: 237  Training loss = 2.3298  Validation loss = 2.6728  \n",
      "\n",
      "Fold: 32  Epoch: 238  Training loss = 2.3297  Validation loss = 2.6720  \n",
      "\n",
      "Fold: 32  Epoch: 239  Training loss = 2.3296  Validation loss = 2.6717  \n",
      "\n",
      "Fold: 32  Epoch: 240  Training loss = 2.3295  Validation loss = 2.6712  \n",
      "\n",
      "Fold: 32  Epoch: 241  Training loss = 2.3294  Validation loss = 2.6706  \n",
      "\n",
      "Fold: 32  Epoch: 242  Training loss = 2.3293  Validation loss = 2.6699  \n",
      "\n",
      "Fold: 32  Epoch: 243  Training loss = 2.3293  Validation loss = 2.6698  \n",
      "\n",
      "Fold: 32  Epoch: 244  Training loss = 2.3292  Validation loss = 2.6694  \n",
      "\n",
      "Fold: 32  Epoch: 245  Training loss = 2.3292  Validation loss = 2.6692  \n",
      "\n",
      "Fold: 32  Epoch: 246  Training loss = 2.3292  Validation loss = 2.6691  \n",
      "\n",
      "Fold: 32  Epoch: 247  Training loss = 2.3291  Validation loss = 2.6686  \n",
      "\n",
      "Fold: 32  Epoch: 248  Training loss = 2.3290  Validation loss = 2.6680  \n",
      "\n",
      "Fold: 32  Epoch: 249  Training loss = 2.3289  Validation loss = 2.6679  \n",
      "\n",
      "Fold: 32  Epoch: 250  Training loss = 2.3288  Validation loss = 2.6673  \n",
      "\n",
      "Fold: 32  Epoch: 251  Training loss = 2.3287  Validation loss = 2.6668  \n",
      "\n",
      "Fold: 32  Epoch: 252  Training loss = 2.3287  Validation loss = 2.6664  \n",
      "\n",
      "Fold: 32  Epoch: 253  Training loss = 2.3287  Validation loss = 2.6664  \n",
      "\n",
      "Fold: 32  Epoch: 254  Training loss = 2.3286  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 32  Epoch: 255  Training loss = 2.3285  Validation loss = 2.6660  \n",
      "\n",
      "Fold: 32  Epoch: 256  Training loss = 2.3285  Validation loss = 2.6656  \n",
      "\n",
      "Fold: 32  Epoch: 257  Training loss = 2.3284  Validation loss = 2.6650  \n",
      "\n",
      "Fold: 32  Epoch: 258  Training loss = 2.3283  Validation loss = 2.6647  \n",
      "\n",
      "Fold: 32  Epoch: 259  Training loss = 2.3283  Validation loss = 2.6643  \n",
      "\n",
      "Fold: 32  Epoch: 260  Training loss = 2.3282  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 32  Epoch: 261  Training loss = 2.3281  Validation loss = 2.6637  \n",
      "\n",
      "Fold: 32  Epoch: 262  Training loss = 2.3281  Validation loss = 2.6638  \n",
      "\n",
      "Fold: 32  Epoch: 263  Training loss = 2.3280  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 32  Epoch: 264  Training loss = 2.3280  Validation loss = 2.6633  \n",
      "\n",
      "Fold: 32  Epoch: 265  Training loss = 2.3280  Validation loss = 2.6630  \n",
      "\n",
      "Fold: 32  Epoch: 266  Training loss = 2.3279  Validation loss = 2.6629  \n",
      "\n",
      "Fold: 32  Epoch: 267  Training loss = 2.3278  Validation loss = 2.6622  \n",
      "\n",
      "Fold: 32  Epoch: 268  Training loss = 2.3278  Validation loss = 2.6619  \n",
      "\n",
      "Fold: 32  Epoch: 269  Training loss = 2.3277  Validation loss = 2.6619  \n",
      "\n",
      "Fold: 32  Epoch: 270  Training loss = 2.3276  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 32  Epoch: 271  Training loss = 2.3276  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 32  Epoch: 272  Training loss = 2.3275  Validation loss = 2.6606  \n",
      "\n",
      "Fold: 32  Epoch: 273  Training loss = 2.3274  Validation loss = 2.6599  \n",
      "\n",
      "Fold: 32  Epoch: 274  Training loss = 2.3273  Validation loss = 2.6595  \n",
      "\n",
      "Fold: 32  Epoch: 275  Training loss = 2.3272  Validation loss = 2.6591  \n",
      "\n",
      "Fold: 32  Epoch: 276  Training loss = 2.3271  Validation loss = 2.6585  \n",
      "\n",
      "Fold: 32  Epoch: 277  Training loss = 2.3271  Validation loss = 2.6583  \n",
      "\n",
      "Fold: 32  Epoch: 278  Training loss = 2.3270  Validation loss = 2.6576  \n",
      "\n",
      "Fold: 32  Epoch: 279  Training loss = 2.3269  Validation loss = 2.6573  \n",
      "\n",
      "Fold: 32  Epoch: 280  Training loss = 2.3268  Validation loss = 2.6568  \n",
      "\n",
      "Fold: 32  Epoch: 281  Training loss = 2.3268  Validation loss = 2.6567  \n",
      "\n",
      "Fold: 32  Epoch: 282  Training loss = 2.3267  Validation loss = 2.6562  \n",
      "\n",
      "Fold: 32  Epoch: 283  Training loss = 2.3265  Validation loss = 2.6553  \n",
      "\n",
      "Fold: 32  Epoch: 284  Training loss = 2.3264  Validation loss = 2.6547  \n",
      "\n",
      "Fold: 32  Epoch: 285  Training loss = 2.3263  Validation loss = 2.6541  \n",
      "\n",
      "Fold: 32  Epoch: 286  Training loss = 2.3263  Validation loss = 2.6537  \n",
      "\n",
      "Fold: 32  Epoch: 287  Training loss = 2.3262  Validation loss = 2.6534  \n",
      "\n",
      "Fold: 32  Epoch: 288  Training loss = 2.3262  Validation loss = 2.6532  \n",
      "\n",
      "Fold: 32  Epoch: 289  Training loss = 2.3261  Validation loss = 2.6525  \n",
      "\n",
      "Fold: 32  Epoch: 290  Training loss = 2.3260  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 32  Epoch: 291  Training loss = 2.3259  Validation loss = 2.6516  \n",
      "\n",
      "Fold: 32  Epoch: 292  Training loss = 2.3258  Validation loss = 2.6511  \n",
      "\n",
      "Fold: 32  Epoch: 293  Training loss = 2.3258  Validation loss = 2.6509  \n",
      "\n",
      "Fold: 32  Epoch: 294  Training loss = 2.3257  Validation loss = 2.6503  \n",
      "\n",
      "Fold: 32  Epoch: 295  Training loss = 2.3256  Validation loss = 2.6497  \n",
      "\n",
      "Fold: 32  Epoch: 296  Training loss = 2.3255  Validation loss = 2.6493  \n",
      "\n",
      "Fold: 32  Epoch: 297  Training loss = 2.3254  Validation loss = 2.6487  \n",
      "\n",
      "Fold: 32  Epoch: 298  Training loss = 2.3254  Validation loss = 2.6487  \n",
      "\n",
      "Fold: 32  Epoch: 299  Training loss = 2.3254  Validation loss = 2.6484  \n",
      "\n",
      "Fold: 32  Epoch: 300  Training loss = 2.3253  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 32  Epoch: 301  Training loss = 2.3252  Validation loss = 2.6476  \n",
      "\n",
      "Fold: 32  Epoch: 302  Training loss = 2.3252  Validation loss = 2.6477  \n",
      "\n",
      "Fold: 32  Epoch: 303  Training loss = 2.3251  Validation loss = 2.6470  \n",
      "\n",
      "Fold: 32  Epoch: 304  Training loss = 2.3250  Validation loss = 2.6466  \n",
      "\n",
      "Fold: 32  Epoch: 305  Training loss = 2.3250  Validation loss = 2.6464  \n",
      "\n",
      "Fold: 32  Epoch: 306  Training loss = 2.3250  Validation loss = 2.6465  \n",
      "\n",
      "Fold: 32  Epoch: 307  Training loss = 2.3250  Validation loss = 2.6462  \n",
      "\n",
      "Fold: 32  Epoch: 308  Training loss = 2.3248  Validation loss = 2.6453  \n",
      "\n",
      "Fold: 32  Epoch: 309  Training loss = 2.3248  Validation loss = 2.6451  \n",
      "\n",
      "Fold: 32  Epoch: 310  Training loss = 2.3247  Validation loss = 2.6443  \n",
      "\n",
      "Fold: 32  Epoch: 311  Training loss = 2.3245  Validation loss = 2.6433  \n",
      "\n",
      "Fold: 32  Epoch: 312  Training loss = 2.3245  Validation loss = 2.6429  \n",
      "\n",
      "Fold: 32  Epoch: 313  Training loss = 2.3244  Validation loss = 2.6423  \n",
      "\n",
      "Fold: 32  Epoch: 314  Training loss = 2.3243  Validation loss = 2.6417  \n",
      "\n",
      "Fold: 32  Epoch: 315  Training loss = 2.3242  Validation loss = 2.6414  \n",
      "\n",
      "Fold: 32  Epoch: 316  Training loss = 2.3242  Validation loss = 2.6410  \n",
      "\n",
      "Fold: 32  Epoch: 317  Training loss = 2.3241  Validation loss = 2.6406  \n",
      "\n",
      "Fold: 32  Epoch: 318  Training loss = 2.3240  Validation loss = 2.6401  \n",
      "\n",
      "Fold: 32  Epoch: 319  Training loss = 2.3239  Validation loss = 2.6398  \n",
      "\n",
      "Fold: 32  Epoch: 320  Training loss = 2.3239  Validation loss = 2.6398  \n",
      "\n",
      "Fold: 32  Epoch: 321  Training loss = 2.3238  Validation loss = 2.6390  \n",
      "\n",
      "Fold: 32  Epoch: 322  Training loss = 2.3237  Validation loss = 2.6384  \n",
      "\n",
      "Fold: 32  Epoch: 323  Training loss = 2.3236  Validation loss = 2.6380  \n",
      "\n",
      "Fold: 32  Epoch: 324  Training loss = 2.3236  Validation loss = 2.6375  \n",
      "\n",
      "Fold: 32  Epoch: 325  Training loss = 2.3235  Validation loss = 2.6371  \n",
      "\n",
      "Fold: 32  Epoch: 326  Training loss = 2.3234  Validation loss = 2.6370  \n",
      "\n",
      "Fold: 32  Epoch: 327  Training loss = 2.3234  Validation loss = 2.6369  \n",
      "\n",
      "Fold: 32  Epoch: 328  Training loss = 2.3233  Validation loss = 2.6364  \n",
      "\n",
      "Fold: 32  Epoch: 329  Training loss = 2.3233  Validation loss = 2.6359  \n",
      "\n",
      "Fold: 32  Epoch: 330  Training loss = 2.3232  Validation loss = 2.6359  \n",
      "\n",
      "Fold: 32  Epoch: 331  Training loss = 2.3232  Validation loss = 2.6354  \n",
      "\n",
      "Fold: 32  Epoch: 332  Training loss = 2.3231  Validation loss = 2.6353  \n",
      "\n",
      "Fold: 32  Epoch: 333  Training loss = 2.3231  Validation loss = 2.6350  \n",
      "\n",
      "Fold: 32  Epoch: 334  Training loss = 2.3230  Validation loss = 2.6347  \n",
      "\n",
      "Fold: 32  Epoch: 335  Training loss = 2.3230  Validation loss = 2.6345  \n",
      "\n",
      "Fold: 32  Epoch: 336  Training loss = 2.3229  Validation loss = 2.6342  \n",
      "\n",
      "Fold: 32  Epoch: 337  Training loss = 2.3228  Validation loss = 2.6338  \n",
      "\n",
      "Fold: 32  Epoch: 338  Training loss = 2.3228  Validation loss = 2.6334  \n",
      "\n",
      "Fold: 32  Epoch: 339  Training loss = 2.3227  Validation loss = 2.6331  \n",
      "\n",
      "Fold: 32  Epoch: 340  Training loss = 2.3227  Validation loss = 2.6328  \n",
      "\n",
      "Fold: 32  Epoch: 341  Training loss = 2.3226  Validation loss = 2.6324  \n",
      "\n",
      "Fold: 32  Epoch: 342  Training loss = 2.3226  Validation loss = 2.6319  \n",
      "\n",
      "Fold: 32  Epoch: 343  Training loss = 2.3226  Validation loss = 2.6321  \n",
      "\n",
      "Fold: 32  Epoch: 344  Training loss = 2.3225  Validation loss = 2.6313  \n",
      "\n",
      "Fold: 32  Epoch: 345  Training loss = 2.3224  Validation loss = 2.6309  \n",
      "\n",
      "Fold: 32  Epoch: 346  Training loss = 2.3224  Validation loss = 2.6308  \n",
      "\n",
      "Fold: 32  Epoch: 347  Training loss = 2.3224  Validation loss = 2.6309  \n",
      "\n",
      "Fold: 32  Epoch: 348  Training loss = 2.3223  Validation loss = 2.6306  \n",
      "\n",
      "Fold: 32  Epoch: 349  Training loss = 2.3222  Validation loss = 2.6301  \n",
      "\n",
      "Fold: 32  Epoch: 350  Training loss = 2.3222  Validation loss = 2.6297  \n",
      "\n",
      "Fold: 32  Epoch: 351  Training loss = 2.3221  Validation loss = 2.6293  \n",
      "\n",
      "Fold: 32  Epoch: 352  Training loss = 2.3220  Validation loss = 2.6289  \n",
      "\n",
      "Fold: 32  Epoch: 353  Training loss = 2.3220  Validation loss = 2.6285  \n",
      "\n",
      "Fold: 32  Epoch: 354  Training loss = 2.3219  Validation loss = 2.6283  \n",
      "\n",
      "Fold: 32  Epoch: 355  Training loss = 2.3218  Validation loss = 2.6278  \n",
      "\n",
      "Fold: 32  Epoch: 356  Training loss = 2.3217  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 32  Epoch: 357  Training loss = 2.3216  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 32  Epoch: 358  Training loss = 2.3216  Validation loss = 2.6261  \n",
      "\n",
      "Fold: 32  Epoch: 359  Training loss = 2.3216  Validation loss = 2.6261  \n",
      "\n",
      "Fold: 32  Epoch: 360  Training loss = 2.3215  Validation loss = 2.6255  \n",
      "\n",
      "Fold: 32  Epoch: 361  Training loss = 2.3215  Validation loss = 2.6253  \n",
      "\n",
      "Fold: 32  Epoch: 362  Training loss = 2.3214  Validation loss = 2.6246  \n",
      "\n",
      "Fold: 32  Epoch: 363  Training loss = 2.3213  Validation loss = 2.6243  \n",
      "\n",
      "Fold: 32  Epoch: 364  Training loss = 2.3213  Validation loss = 2.6238  \n",
      "\n",
      "Fold: 32  Epoch: 365  Training loss = 2.3213  Validation loss = 2.6238  \n",
      "\n",
      "Fold: 32  Epoch: 366  Training loss = 2.3212  Validation loss = 2.6236  \n",
      "\n",
      "Fold: 32  Epoch: 367  Training loss = 2.3211  Validation loss = 2.6229  \n",
      "\n",
      "Fold: 32  Epoch: 368  Training loss = 2.3210  Validation loss = 2.6224  \n",
      "\n",
      "Fold: 32  Epoch: 369  Training loss = 2.3210  Validation loss = 2.6220  \n",
      "\n",
      "Fold: 32  Epoch: 370  Training loss = 2.3209  Validation loss = 2.6216  \n",
      "\n",
      "Fold: 32  Epoch: 371  Training loss = 2.3208  Validation loss = 2.6209  \n",
      "\n",
      "Fold: 32  Epoch: 372  Training loss = 2.3208  Validation loss = 2.6208  \n",
      "\n",
      "Fold: 32  Epoch: 373  Training loss = 2.3207  Validation loss = 2.6204  \n",
      "\n",
      "Fold: 32  Epoch: 374  Training loss = 2.3206  Validation loss = 2.6197  \n",
      "\n",
      "Fold: 32  Epoch: 375  Training loss = 2.3205  Validation loss = 2.6190  \n",
      "\n",
      "Fold: 32  Epoch: 376  Training loss = 2.3204  Validation loss = 2.6184  \n",
      "\n",
      "Fold: 32  Epoch: 377  Training loss = 2.3204  Validation loss = 2.6181  \n",
      "\n",
      "Fold: 32  Epoch: 378  Training loss = 2.3203  Validation loss = 2.6176  \n",
      "\n",
      "Fold: 32  Epoch: 379  Training loss = 2.3202  Validation loss = 2.6171  \n",
      "\n",
      "Fold: 32  Epoch: 380  Training loss = 2.3202  Validation loss = 2.6174  \n",
      "\n",
      "Fold: 32  Epoch: 381  Training loss = 2.3201  Validation loss = 2.6167  \n",
      "\n",
      "Fold: 32  Epoch: 382  Training loss = 2.3200  Validation loss = 2.6162  \n",
      "\n",
      "Fold: 32  Epoch: 383  Training loss = 2.3200  Validation loss = 2.6159  \n",
      "\n",
      "Fold: 32  Epoch: 384  Training loss = 2.3200  Validation loss = 2.6156  \n",
      "\n",
      "Fold: 32  Epoch: 385  Training loss = 2.3198  Validation loss = 2.6149  \n",
      "\n",
      "Fold: 32  Epoch: 386  Training loss = 2.3198  Validation loss = 2.6145  \n",
      "\n",
      "Fold: 32  Epoch: 387  Training loss = 2.3197  Validation loss = 2.6140  \n",
      "\n",
      "Fold: 32  Epoch: 388  Training loss = 2.3198  Validation loss = 2.6145  \n",
      "\n",
      "Fold: 32  Epoch: 389  Training loss = 2.3197  Validation loss = 2.6146  \n",
      "\n",
      "Fold: 32  Epoch: 390  Training loss = 2.3197  Validation loss = 2.6141  \n",
      "\n",
      "Fold: 32  Epoch: 391  Training loss = 2.3196  Validation loss = 2.6139  \n",
      "\n",
      "Fold: 32  Epoch: 392  Training loss = 2.3196  Validation loss = 2.6137  \n",
      "\n",
      "Fold: 32  Epoch: 393  Training loss = 2.3196  Validation loss = 2.6137  \n",
      "\n",
      "Fold: 32  Epoch: 394  Training loss = 2.3196  Validation loss = 2.6137  \n",
      "\n",
      "Fold: 32  Epoch: 395  Training loss = 2.3195  Validation loss = 2.6134  \n",
      "\n",
      "Fold: 32  Epoch: 396  Training loss = 2.3194  Validation loss = 2.6129  \n",
      "\n",
      "Fold: 32  Epoch: 397  Training loss = 2.3194  Validation loss = 2.6127  \n",
      "\n",
      "Fold: 32  Epoch: 398  Training loss = 2.3194  Validation loss = 2.6124  \n",
      "\n",
      "Fold: 32  Epoch: 399  Training loss = 2.3193  Validation loss = 2.6118  \n",
      "\n",
      "Fold: 32  Epoch: 400  Training loss = 2.3192  Validation loss = 2.6115  \n",
      "\n",
      "Fold: 32  Epoch: 401  Training loss = 2.3191  Validation loss = 2.6110  \n",
      "\n",
      "Fold: 32  Epoch: 402  Training loss = 2.3190  Validation loss = 2.6103  \n",
      "\n",
      "Fold: 32  Epoch: 403  Training loss = 2.3190  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 32  Epoch: 404  Training loss = 2.3190  Validation loss = 2.6100  \n",
      "\n",
      "Fold: 32  Epoch: 405  Training loss = 2.3189  Validation loss = 2.6095  \n",
      "\n",
      "Fold: 32  Epoch: 406  Training loss = 2.3189  Validation loss = 2.6093  \n",
      "\n",
      "Fold: 32  Epoch: 407  Training loss = 2.3188  Validation loss = 2.6089  \n",
      "\n",
      "Fold: 32  Epoch: 408  Training loss = 2.3188  Validation loss = 2.6089  \n",
      "\n",
      "Fold: 32  Epoch: 409  Training loss = 2.3187  Validation loss = 2.6087  \n",
      "\n",
      "Fold: 32  Epoch: 410  Training loss = 2.3187  Validation loss = 2.6086  \n",
      "\n",
      "Fold: 32  Epoch: 411  Training loss = 2.3186  Validation loss = 2.6077  \n",
      "\n",
      "Fold: 32  Epoch: 412  Training loss = 2.3186  Validation loss = 2.6077  \n",
      "\n",
      "Fold: 32  Epoch: 413  Training loss = 2.3185  Validation loss = 2.6074  \n",
      "\n",
      "Fold: 32  Epoch: 414  Training loss = 2.3185  Validation loss = 2.6072  \n",
      "\n",
      "Fold: 32  Epoch: 415  Training loss = 2.3184  Validation loss = 2.6065  \n",
      "\n",
      "Fold: 32  Epoch: 416  Training loss = 2.3183  Validation loss = 2.6061  \n",
      "\n",
      "Fold: 32  Epoch: 417  Training loss = 2.3182  Validation loss = 2.6057  \n",
      "\n",
      "Fold: 32  Epoch: 418  Training loss = 2.3182  Validation loss = 2.6058  \n",
      "\n",
      "Fold: 32  Epoch: 419  Training loss = 2.3182  Validation loss = 2.6056  \n",
      "\n",
      "Fold: 32  Epoch: 420  Training loss = 2.3182  Validation loss = 2.6055  \n",
      "\n",
      "Fold: 32  Epoch: 421  Training loss = 2.3181  Validation loss = 2.6053  \n",
      "\n",
      "Fold: 32  Epoch: 422  Training loss = 2.3181  Validation loss = 2.6052  \n",
      "\n",
      "Fold: 32  Epoch: 423  Training loss = 2.3180  Validation loss = 2.6047  \n",
      "\n",
      "Fold: 32  Epoch: 424  Training loss = 2.3180  Validation loss = 2.6042  \n",
      "\n",
      "Fold: 32  Epoch: 425  Training loss = 2.3179  Validation loss = 2.6042  \n",
      "\n",
      "Fold: 32  Epoch: 426  Training loss = 2.3179  Validation loss = 2.6037  \n",
      "\n",
      "Fold: 32  Epoch: 427  Training loss = 2.3178  Validation loss = 2.6033  \n",
      "\n",
      "Fold: 32  Epoch: 428  Training loss = 2.3178  Validation loss = 2.6032  \n",
      "\n",
      "Fold: 32  Epoch: 429  Training loss = 2.3177  Validation loss = 2.6028  \n",
      "\n",
      "Fold: 32  Epoch: 430  Training loss = 2.3176  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 32  Epoch: 431  Training loss = 2.3176  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 32  Epoch: 432  Training loss = 2.3176  Validation loss = 2.6021  \n",
      "\n",
      "Fold: 32  Epoch: 433  Training loss = 2.3176  Validation loss = 2.6019  \n",
      "\n",
      "Fold: 32  Epoch: 434  Training loss = 2.3176  Validation loss = 2.6019  \n",
      "\n",
      "Fold: 32  Epoch: 435  Training loss = 2.3175  Validation loss = 2.6013  \n",
      "\n",
      "Fold: 32  Epoch: 436  Training loss = 2.3175  Validation loss = 2.6012  \n",
      "\n",
      "Fold: 32  Epoch: 437  Training loss = 2.3174  Validation loss = 2.6008  \n",
      "\n",
      "Fold: 32  Epoch: 438  Training loss = 2.3174  Validation loss = 2.6004  \n",
      "\n",
      "Fold: 32  Epoch: 439  Training loss = 2.3173  Validation loss = 2.5997  \n",
      "\n",
      "Fold: 32  Epoch: 440  Training loss = 2.3172  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 32  Epoch: 441  Training loss = 2.3172  Validation loss = 2.5996  \n",
      "\n",
      "Fold: 32  Epoch: 442  Training loss = 2.3171  Validation loss = 2.5989  \n",
      "\n",
      "Fold: 32  Epoch: 443  Training loss = 2.3171  Validation loss = 2.5986  \n",
      "\n",
      "Fold: 32  Epoch: 444  Training loss = 2.3170  Validation loss = 2.5983  \n",
      "\n",
      "Fold: 32  Epoch: 445  Training loss = 2.3170  Validation loss = 2.5983  \n",
      "\n",
      "Fold: 32  Epoch: 446  Training loss = 2.3170  Validation loss = 2.5984  \n",
      "\n",
      "Fold: 32  Epoch: 447  Training loss = 2.3170  Validation loss = 2.5981  \n",
      "\n",
      "Fold: 32  Epoch: 448  Training loss = 2.3169  Validation loss = 2.5978  \n",
      "\n",
      "Fold: 32  Epoch: 449  Training loss = 2.3169  Validation loss = 2.5976  \n",
      "\n",
      "Fold: 32  Epoch: 450  Training loss = 2.3169  Validation loss = 2.5973  \n",
      "\n",
      "Fold: 32  Epoch: 451  Training loss = 2.3168  Validation loss = 2.5968  \n",
      "\n",
      "Fold: 32  Epoch: 452  Training loss = 2.3167  Validation loss = 2.5963  \n",
      "\n",
      "Fold: 32  Epoch: 453  Training loss = 2.3167  Validation loss = 2.5959  \n",
      "\n",
      "Fold: 32  Epoch: 454  Training loss = 2.3166  Validation loss = 2.5954  \n",
      "\n",
      "Fold: 32  Epoch: 455  Training loss = 2.3166  Validation loss = 2.5952  \n",
      "\n",
      "Fold: 32  Epoch: 456  Training loss = 2.3165  Validation loss = 2.5948  \n",
      "\n",
      "Fold: 32  Epoch: 457  Training loss = 2.3165  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 32  Epoch: 458  Training loss = 2.3164  Validation loss = 2.5942  \n",
      "\n",
      "Fold: 32  Epoch: 459  Training loss = 2.3164  Validation loss = 2.5938  \n",
      "\n",
      "Fold: 32  Epoch: 460  Training loss = 2.3163  Validation loss = 2.5932  \n",
      "\n",
      "Fold: 32  Epoch: 461  Training loss = 2.3162  Validation loss = 2.5928  \n",
      "\n",
      "Fold: 32  Epoch: 462  Training loss = 2.3162  Validation loss = 2.5925  \n",
      "\n",
      "Fold: 32  Epoch: 463  Training loss = 2.3161  Validation loss = 2.5920  \n",
      "\n",
      "Fold: 32  Epoch: 464  Training loss = 2.3160  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 32  Epoch: 465  Training loss = 2.3160  Validation loss = 2.5913  \n",
      "\n",
      "Fold: 32  Epoch: 466  Training loss = 2.3159  Validation loss = 2.5912  \n",
      "\n",
      "Fold: 32  Epoch: 467  Training loss = 2.3159  Validation loss = 2.5909  \n",
      "\n",
      "Fold: 32  Epoch: 468  Training loss = 2.3159  Validation loss = 2.5909  \n",
      "\n",
      "Fold: 32  Epoch: 469  Training loss = 2.3158  Validation loss = 2.5907  \n",
      "\n",
      "Fold: 32  Epoch: 470  Training loss = 2.3158  Validation loss = 2.5902  \n",
      "\n",
      "Fold: 32  Epoch: 471  Training loss = 2.3157  Validation loss = 2.5898  \n",
      "\n",
      "Fold: 32  Epoch: 472  Training loss = 2.3156  Validation loss = 2.5889  \n",
      "\n",
      "Fold: 32  Epoch: 473  Training loss = 2.3155  Validation loss = 2.5885  \n",
      "\n",
      "Fold: 32  Epoch: 474  Training loss = 2.3155  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 32  Epoch: 475  Training loss = 2.3154  Validation loss = 2.5875  \n",
      "\n",
      "Fold: 32  Epoch: 476  Training loss = 2.3154  Validation loss = 2.5872  \n",
      "\n",
      "Fold: 32  Epoch: 477  Training loss = 2.3153  Validation loss = 2.5865  \n",
      "\n",
      "Fold: 32  Epoch: 478  Training loss = 2.3153  Validation loss = 2.5866  \n",
      "\n",
      "Fold: 32  Epoch: 479  Training loss = 2.3152  Validation loss = 2.5860  \n",
      "\n",
      "Fold: 32  Epoch: 480  Training loss = 2.3151  Validation loss = 2.5854  \n",
      "\n",
      "Fold: 32  Epoch: 481  Training loss = 2.3151  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 32  Epoch: 482  Training loss = 2.3150  Validation loss = 2.5850  \n",
      "\n",
      "Fold: 32  Epoch: 483  Training loss = 2.3150  Validation loss = 2.5845  \n",
      "\n",
      "Fold: 32  Epoch: 484  Training loss = 2.3149  Validation loss = 2.5843  \n",
      "\n",
      "Fold: 32  Epoch: 485  Training loss = 2.3150  Validation loss = 2.5846  \n",
      "\n",
      "Fold: 32  Epoch: 486  Training loss = 2.3149  Validation loss = 2.5840  \n",
      "\n",
      "Fold: 32  Epoch: 487  Training loss = 2.3149  Validation loss = 2.5842  \n",
      "\n",
      "Fold: 32  Epoch: 488  Training loss = 2.3148  Validation loss = 2.5839  \n",
      "\n",
      "Fold: 32  Epoch: 489  Training loss = 2.3148  Validation loss = 2.5840  \n",
      "\n",
      "Fold: 32  Epoch: 490  Training loss = 2.3147  Validation loss = 2.5834  \n",
      "\n",
      "Fold: 32  Epoch: 491  Training loss = 2.3147  Validation loss = 2.5831  \n",
      "\n",
      "Fold: 32  Epoch: 492  Training loss = 2.3147  Validation loss = 2.5829  \n",
      "\n",
      "Fold: 32  Epoch: 493  Training loss = 2.3146  Validation loss = 2.5829  \n",
      "\n",
      "Fold: 32  Epoch: 494  Training loss = 2.3146  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 32  Epoch: 495  Training loss = 2.3145  Validation loss = 2.5819  \n",
      "\n",
      "Fold: 32  Epoch: 496  Training loss = 2.3144  Validation loss = 2.5815  \n",
      "\n",
      "Fold: 32  Epoch: 497  Training loss = 2.3144  Validation loss = 2.5813  \n",
      "\n",
      "Fold: 32  Epoch: 498  Training loss = 2.3144  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 32  Epoch: 499  Training loss = 2.3143  Validation loss = 2.5808  \n",
      "\n",
      "Fold: 32  Epoch: 500  Training loss = 2.3142  Validation loss = 2.5802  \n",
      "\n",
      "Fold: 32  Epoch: 501  Training loss = 2.3142  Validation loss = 2.5799  \n",
      "\n",
      "Fold: 32  Epoch: 502  Training loss = 2.3142  Validation loss = 2.5797  \n",
      "\n",
      "Fold: 32  Epoch: 503  Training loss = 2.3141  Validation loss = 2.5796  \n",
      "\n",
      "Fold: 32  Epoch: 504  Training loss = 2.3141  Validation loss = 2.5799  \n",
      "\n",
      "Fold: 32  Epoch: 505  Training loss = 2.3141  Validation loss = 2.5797  \n",
      "\n",
      "Fold: 32  Epoch: 506  Training loss = 2.3141  Validation loss = 2.5795  \n",
      "\n",
      "Fold: 32  Epoch: 507  Training loss = 2.3140  Validation loss = 2.5791  \n",
      "\n",
      "Fold: 32  Epoch: 508  Training loss = 2.3140  Validation loss = 2.5788  \n",
      "\n",
      "Fold: 32  Epoch: 509  Training loss = 2.3140  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 32  Epoch: 510  Training loss = 2.3139  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 32  Epoch: 511  Training loss = 2.3139  Validation loss = 2.5778  \n",
      "\n",
      "Fold: 32  Epoch: 512  Training loss = 2.3138  Validation loss = 2.5776  \n",
      "\n",
      "Fold: 32  Epoch: 513  Training loss = 2.3138  Validation loss = 2.5774  \n",
      "\n",
      "Fold: 32  Epoch: 514  Training loss = 2.3137  Validation loss = 2.5769  \n",
      "\n",
      "Fold: 32  Epoch: 515  Training loss = 2.3138  Validation loss = 2.5772  \n",
      "\n",
      "Fold: 32  Epoch: 516  Training loss = 2.3137  Validation loss = 2.5772  \n",
      "\n",
      "Fold: 32  Epoch: 517  Training loss = 2.3136  Validation loss = 2.5767  \n",
      "\n",
      "Fold: 32  Epoch: 518  Training loss = 2.3136  Validation loss = 2.5762  \n",
      "\n",
      "Fold: 32  Epoch: 519  Training loss = 2.3136  Validation loss = 2.5762  \n",
      "\n",
      "Fold: 32  Epoch: 520  Training loss = 2.3135  Validation loss = 2.5755  \n",
      "\n",
      "Fold: 32  Epoch: 521  Training loss = 2.3135  Validation loss = 2.5753  \n",
      "\n",
      "Fold: 32  Epoch: 522  Training loss = 2.3134  Validation loss = 2.5753  \n",
      "\n",
      "Fold: 32  Epoch: 523  Training loss = 2.3134  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 32  Epoch: 524  Training loss = 2.3133  Validation loss = 2.5744  \n",
      "\n",
      "Fold: 32  Epoch: 525  Training loss = 2.3132  Validation loss = 2.5740  \n",
      "\n",
      "Fold: 32  Epoch: 526  Training loss = 2.3132  Validation loss = 2.5737  \n",
      "\n",
      "Fold: 32  Epoch: 527  Training loss = 2.3131  Validation loss = 2.5732  \n",
      "\n",
      "Fold: 32  Epoch: 528  Training loss = 2.3131  Validation loss = 2.5728  \n",
      "\n",
      "Fold: 32  Epoch: 529  Training loss = 2.3130  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 32  Epoch: 530  Training loss = 2.3130  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 32  Epoch: 531  Training loss = 2.3130  Validation loss = 2.5728  \n",
      "\n",
      "Fold: 32  Epoch: 532  Training loss = 2.3130  Validation loss = 2.5724  \n",
      "\n",
      "Fold: 32  Epoch: 533  Training loss = 2.3130  Validation loss = 2.5722  \n",
      "\n",
      "Fold: 32  Epoch: 534  Training loss = 2.3129  Validation loss = 2.5714  \n",
      "\n",
      "Fold: 32  Epoch: 535  Training loss = 2.3128  Validation loss = 2.5711  \n",
      "\n",
      "Fold: 32  Epoch: 536  Training loss = 2.3128  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 32  Epoch: 537  Training loss = 2.3127  Validation loss = 2.5705  \n",
      "\n",
      "Fold: 32  Epoch: 538  Training loss = 2.3127  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 32  Epoch: 539  Training loss = 2.3126  Validation loss = 2.5698  \n",
      "\n",
      "Fold: 32  Epoch: 540  Training loss = 2.3126  Validation loss = 2.5694  \n",
      "\n",
      "Fold: 32  Epoch: 541  Training loss = 2.3125  Validation loss = 2.5691  \n",
      "\n",
      "Fold: 32  Epoch: 542  Training loss = 2.3125  Validation loss = 2.5685  \n",
      "\n",
      "Fold: 32  Epoch: 543  Training loss = 2.3124  Validation loss = 2.5682  \n",
      "\n",
      "Fold: 32  Epoch: 544  Training loss = 2.3124  Validation loss = 2.5677  \n",
      "\n",
      "Fold: 32  Epoch: 545  Training loss = 2.3123  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 32  Epoch: 546  Training loss = 2.3122  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 32  Epoch: 547  Training loss = 2.3122  Validation loss = 2.5664  \n",
      "\n",
      "Fold: 32  Epoch: 548  Training loss = 2.3121  Validation loss = 2.5662  \n",
      "\n",
      "Fold: 32  Epoch: 549  Training loss = 2.3121  Validation loss = 2.5658  \n",
      "\n",
      "Fold: 32  Epoch: 550  Training loss = 2.3120  Validation loss = 2.5658  \n",
      "\n",
      "Fold: 32  Epoch: 551  Training loss = 2.3120  Validation loss = 2.5654  \n",
      "\n",
      "Fold: 32  Epoch: 552  Training loss = 2.3120  Validation loss = 2.5654  \n",
      "\n",
      "Fold: 32  Epoch: 553  Training loss = 2.3119  Validation loss = 2.5655  \n",
      "\n",
      "Fold: 32  Epoch: 554  Training loss = 2.3119  Validation loss = 2.5652  \n",
      "\n",
      "Fold: 32  Epoch: 555  Training loss = 2.3119  Validation loss = 2.5647  \n",
      "\n",
      "Fold: 32  Epoch: 556  Training loss = 2.3118  Validation loss = 2.5643  \n",
      "\n",
      "Fold: 32  Epoch: 557  Training loss = 2.3118  Validation loss = 2.5640  \n",
      "\n",
      "Fold: 32  Epoch: 558  Training loss = 2.3117  Validation loss = 2.5640  \n",
      "\n",
      "Fold: 32  Epoch: 559  Training loss = 2.3117  Validation loss = 2.5635  \n",
      "\n",
      "Fold: 32  Epoch: 560  Training loss = 2.3116  Validation loss = 2.5631  \n",
      "\n",
      "Fold: 32  Epoch: 561  Training loss = 2.3116  Validation loss = 2.5631  \n",
      "\n",
      "Fold: 32  Epoch: 562  Training loss = 2.3115  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 32  Epoch: 563  Training loss = 2.3115  Validation loss = 2.5624  \n",
      "\n",
      "Fold: 32  Epoch: 564  Training loss = 2.3114  Validation loss = 2.5619  \n",
      "\n",
      "Fold: 32  Epoch: 565  Training loss = 2.3114  Validation loss = 2.5617  \n",
      "\n",
      "Fold: 32  Epoch: 566  Training loss = 2.3114  Validation loss = 2.5615  \n",
      "\n",
      "Fold: 32  Epoch: 567  Training loss = 2.3113  Validation loss = 2.5616  \n",
      "\n",
      "Fold: 32  Epoch: 568  Training loss = 2.3113  Validation loss = 2.5613  \n",
      "\n",
      "Fold: 32  Epoch: 569  Training loss = 2.3113  Validation loss = 2.5616  \n",
      "\n",
      "Fold: 32  Epoch: 570  Training loss = 2.3113  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 32  Epoch: 571  Training loss = 2.3113  Validation loss = 2.5616  \n",
      "\n",
      "Fold: 32  Epoch: 572  Training loss = 2.3112  Validation loss = 2.5615  \n",
      "\n",
      "Fold: 32  Epoch: 573  Training loss = 2.3112  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 32  Epoch: 574  Training loss = 2.3111  Validation loss = 2.5607  \n",
      "\n",
      "Fold: 32  Epoch: 575  Training loss = 2.3111  Validation loss = 2.5605  \n",
      "\n",
      "Fold: 32  Epoch: 576  Training loss = 2.3110  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 32  Epoch: 577  Training loss = 2.3111  Validation loss = 2.5605  \n",
      "\n",
      "Fold: 32  Epoch: 578  Training loss = 2.3110  Validation loss = 2.5599  \n",
      "\n",
      "Fold: 32  Epoch: 579  Training loss = 2.3109  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 32  Epoch: 580  Training loss = 2.3109  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 32  Epoch: 581  Training loss = 2.3108  Validation loss = 2.5588  \n",
      "\n",
      "Fold: 32  Epoch: 582  Training loss = 2.3108  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 32  Epoch: 583  Training loss = 2.3108  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 32  Epoch: 584  Training loss = 2.3107  Validation loss = 2.5583  \n",
      "\n",
      "Fold: 32  Epoch: 585  Training loss = 2.3107  Validation loss = 2.5578  \n",
      "\n",
      "Fold: 32  Epoch: 586  Training loss = 2.3106  Validation loss = 2.5574  \n",
      "\n",
      "Fold: 32  Epoch: 587  Training loss = 2.3106  Validation loss = 2.5569  \n",
      "\n",
      "Fold: 32  Epoch: 588  Training loss = 2.3106  Validation loss = 2.5572  \n",
      "\n",
      "Fold: 32  Epoch: 589  Training loss = 2.3106  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 32  Epoch: 590  Training loss = 2.3105  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 32  Epoch: 591  Training loss = 2.3105  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 32  Epoch: 592  Training loss = 2.3104  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 32  Epoch: 593  Training loss = 2.3104  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 32  Epoch: 594  Training loss = 2.3103  Validation loss = 2.5561  \n",
      "\n",
      "Fold: 32  Epoch: 595  Training loss = 2.3103  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 32  Epoch: 596  Training loss = 2.3102  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 32  Epoch: 597  Training loss = 2.3102  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 32  Epoch: 598  Training loss = 2.3102  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 32  Epoch: 599  Training loss = 2.3101  Validation loss = 2.5552  \n",
      "\n",
      "Fold: 32  Epoch: 600  Training loss = 2.3101  Validation loss = 2.5553  \n",
      "\n",
      "Fold: 32  Epoch: 601  Training loss = 2.3101  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 32  Epoch: 602  Training loss = 2.3101  Validation loss = 2.5558  \n",
      "\n",
      "Fold: 32  Epoch: 603  Training loss = 2.3101  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 32  Epoch: 604  Training loss = 2.3101  Validation loss = 2.5558  \n",
      "\n",
      "Fold: 32  Epoch: 605  Training loss = 2.3100  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 32  Epoch: 606  Training loss = 2.3100  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 32  Epoch: 607  Training loss = 2.3100  Validation loss = 2.5547  \n",
      "\n",
      "Fold: 32  Epoch: 608  Training loss = 2.3099  Validation loss = 2.5541  \n",
      "\n",
      "Fold: 32  Epoch: 609  Training loss = 2.3098  Validation loss = 2.5536  \n",
      "\n",
      "Fold: 32  Epoch: 610  Training loss = 2.3098  Validation loss = 2.5536  \n",
      "\n",
      "Fold: 32  Epoch: 611  Training loss = 2.3097  Validation loss = 2.5530  \n",
      "\n",
      "Fold: 32  Epoch: 612  Training loss = 2.3097  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 32  Epoch: 613  Training loss = 2.3096  Validation loss = 2.5521  \n",
      "\n",
      "Fold: 32  Epoch: 614  Training loss = 2.3096  Validation loss = 2.5518  \n",
      "\n",
      "Fold: 32  Epoch: 615  Training loss = 2.3095  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 32  Epoch: 616  Training loss = 2.3095  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 32  Epoch: 617  Training loss = 2.3095  Validation loss = 2.5515  \n",
      "\n",
      "Fold: 32  Epoch: 618  Training loss = 2.3094  Validation loss = 2.5513  \n",
      "\n",
      "Fold: 32  Epoch: 619  Training loss = 2.3094  Validation loss = 2.5510  \n",
      "\n",
      "Fold: 32  Epoch: 620  Training loss = 2.3094  Validation loss = 2.5509  \n",
      "\n",
      "Fold: 32  Epoch: 621  Training loss = 2.3093  Validation loss = 2.5506  \n",
      "\n",
      "Fold: 32  Epoch: 622  Training loss = 2.3093  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 32  Epoch: 623  Training loss = 2.3093  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 32  Epoch: 624  Training loss = 2.3093  Validation loss = 2.5501  \n",
      "\n",
      "Fold: 32  Epoch: 625  Training loss = 2.3092  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 32  Epoch: 626  Training loss = 2.3091  Validation loss = 2.5491  \n",
      "\n",
      "Fold: 32  Epoch: 627  Training loss = 2.3091  Validation loss = 2.5489  \n",
      "\n",
      "Fold: 32  Epoch: 628  Training loss = 2.3090  Validation loss = 2.5483  \n",
      "\n",
      "Fold: 32  Epoch: 629  Training loss = 2.3089  Validation loss = 2.5478  \n",
      "\n",
      "Fold: 32  Epoch: 630  Training loss = 2.3089  Validation loss = 2.5474  \n",
      "\n",
      "Fold: 32  Epoch: 631  Training loss = 2.3089  Validation loss = 2.5472  \n",
      "\n",
      "Fold: 32  Epoch: 632  Training loss = 2.3088  Validation loss = 2.5463  \n",
      "\n",
      "Fold: 32  Epoch: 633  Training loss = 2.3087  Validation loss = 2.5459  \n",
      "\n",
      "Fold: 32  Epoch: 634  Training loss = 2.3087  Validation loss = 2.5453  \n",
      "\n",
      "Fold: 32  Epoch: 635  Training loss = 2.3086  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 32  Epoch: 636  Training loss = 2.3086  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 32  Epoch: 637  Training loss = 2.3086  Validation loss = 2.5448  \n",
      "\n",
      "Fold: 32  Epoch: 638  Training loss = 2.3085  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 32  Epoch: 639  Training loss = 2.3086  Validation loss = 2.5454  \n",
      "\n",
      "Fold: 32  Epoch: 640  Training loss = 2.3085  Validation loss = 2.5452  \n",
      "\n",
      "Fold: 32  Epoch: 641  Training loss = 2.3085  Validation loss = 2.5446  \n",
      "\n",
      "Fold: 32  Epoch: 642  Training loss = 2.3085  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 32  Epoch: 643  Training loss = 2.3084  Validation loss = 2.5443  \n",
      "\n",
      "Fold: 32  Epoch: 644  Training loss = 2.3084  Validation loss = 2.5446  \n",
      "\n",
      "Fold: 32  Epoch: 645  Training loss = 2.3084  Validation loss = 2.5440  \n",
      "\n",
      "Fold: 32  Epoch: 646  Training loss = 2.3083  Validation loss = 2.5435  \n",
      "\n",
      "Fold: 32  Epoch: 647  Training loss = 2.3083  Validation loss = 2.5434  \n",
      "\n",
      "Fold: 32  Epoch: 648  Training loss = 2.3082  Validation loss = 2.5433  \n",
      "\n",
      "Fold: 32  Epoch: 649  Training loss = 2.3082  Validation loss = 2.5433  \n",
      "\n",
      "Fold: 32  Epoch: 650  Training loss = 2.3082  Validation loss = 2.5432  \n",
      "\n",
      "Fold: 32  Epoch: 651  Training loss = 2.3082  Validation loss = 2.5434  \n",
      "\n",
      "Fold: 32  Epoch: 652  Training loss = 2.3081  Validation loss = 2.5427  \n",
      "\n",
      "Fold: 32  Epoch: 653  Training loss = 2.3081  Validation loss = 2.5426  \n",
      "\n",
      "Fold: 32  Epoch: 654  Training loss = 2.3081  Validation loss = 2.5427  \n",
      "\n",
      "Fold: 32  Epoch: 655  Training loss = 2.3081  Validation loss = 2.5424  \n",
      "\n",
      "Fold: 32  Epoch: 656  Training loss = 2.3080  Validation loss = 2.5420  \n",
      "\n",
      "Fold: 32  Epoch: 657  Training loss = 2.3080  Validation loss = 2.5421  \n",
      "\n",
      "Fold: 32  Epoch: 658  Training loss = 2.3079  Validation loss = 2.5414  \n",
      "\n",
      "Fold: 32  Epoch: 659  Training loss = 2.3079  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 32  Epoch: 660  Training loss = 2.3079  Validation loss = 2.5413  \n",
      "\n",
      "Fold: 32  Epoch: 661  Training loss = 2.3079  Validation loss = 2.5414  \n",
      "\n",
      "Fold: 32  Epoch: 662  Training loss = 2.3078  Validation loss = 2.5414  \n",
      "\n",
      "Fold: 32  Epoch: 663  Training loss = 2.3078  Validation loss = 2.5413  \n",
      "\n",
      "Fold: 32  Epoch: 664  Training loss = 2.3078  Validation loss = 2.5411  \n",
      "\n",
      "Fold: 32  Epoch: 665  Training loss = 2.3077  Validation loss = 2.5407  \n",
      "\n",
      "Fold: 32  Epoch: 666  Training loss = 2.3077  Validation loss = 2.5401  \n",
      "\n",
      "Fold: 32  Epoch: 667  Training loss = 2.3076  Validation loss = 2.5402  \n",
      "\n",
      "Fold: 32  Epoch: 668  Training loss = 2.3076  Validation loss = 2.5399  \n",
      "\n",
      "Fold: 32  Epoch: 669  Training loss = 2.3076  Validation loss = 2.5399  \n",
      "\n",
      "Fold: 32  Epoch: 670  Training loss = 2.3075  Validation loss = 2.5395  \n",
      "\n",
      "Fold: 32  Epoch: 671  Training loss = 2.3075  Validation loss = 2.5390  \n",
      "\n",
      "Fold: 32  Epoch: 672  Training loss = 2.3074  Validation loss = 2.5390  \n",
      "\n",
      "Fold: 32  Epoch: 673  Training loss = 2.3074  Validation loss = 2.5388  \n",
      "\n",
      "Fold: 32  Epoch: 674  Training loss = 2.3074  Validation loss = 2.5385  \n",
      "\n",
      "Fold: 32  Epoch: 675  Training loss = 2.3073  Validation loss = 2.5381  \n",
      "\n",
      "Fold: 32  Epoch: 676  Training loss = 2.3073  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 32  Epoch: 677  Training loss = 2.3072  Validation loss = 2.5373  \n",
      "\n",
      "Fold: 32  Epoch: 678  Training loss = 2.3072  Validation loss = 2.5369  \n",
      "\n",
      "Fold: 32  Epoch: 679  Training loss = 2.3071  Validation loss = 2.5362  \n",
      "\n",
      "Fold: 32  Epoch: 680  Training loss = 2.3071  Validation loss = 2.5358  \n",
      "\n",
      "Fold: 32  Epoch: 681  Training loss = 2.3071  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 32  Epoch: 682  Training loss = 2.3070  Validation loss = 2.5361  \n",
      "\n",
      "Fold: 32  Epoch: 683  Training loss = 2.3070  Validation loss = 2.5360  \n",
      "\n",
      "Fold: 32  Epoch: 684  Training loss = 2.3070  Validation loss = 2.5357  \n",
      "\n",
      "Fold: 32  Epoch: 685  Training loss = 2.3069  Validation loss = 2.5353  \n",
      "\n",
      "Fold: 32  Epoch: 686  Training loss = 2.3069  Validation loss = 2.5351  \n",
      "\n",
      "Fold: 32  Epoch: 687  Training loss = 2.3068  Validation loss = 2.5344  \n",
      "\n",
      "Fold: 32  Epoch: 688  Training loss = 2.3068  Validation loss = 2.5340  \n",
      "\n",
      "Fold: 32  Epoch: 689  Training loss = 2.3067  Validation loss = 2.5339  \n",
      "\n",
      "Fold: 32  Epoch: 690  Training loss = 2.3067  Validation loss = 2.5339  \n",
      "\n",
      "Fold: 32  Epoch: 691  Training loss = 2.3067  Validation loss = 2.5337  \n",
      "\n",
      "Fold: 32  Epoch: 692  Training loss = 2.3067  Validation loss = 2.5337  \n",
      "\n",
      "Fold: 32  Epoch: 693  Training loss = 2.3066  Validation loss = 2.5337  \n",
      "\n",
      "Fold: 32  Epoch: 694  Training loss = 2.3066  Validation loss = 2.5333  \n",
      "\n",
      "Fold: 32  Epoch: 695  Training loss = 2.3065  Validation loss = 2.5329  \n",
      "\n",
      "Fold: 32  Epoch: 696  Training loss = 2.3065  Validation loss = 2.5331  \n",
      "\n",
      "Fold: 32  Epoch: 697  Training loss = 2.3065  Validation loss = 2.5328  \n",
      "\n",
      "Fold: 32  Epoch: 698  Training loss = 2.3065  Validation loss = 2.5329  \n",
      "\n",
      "Fold: 32  Epoch: 699  Training loss = 2.3065  Validation loss = 2.5328  \n",
      "\n",
      "Fold: 32  Epoch: 700  Training loss = 2.3064  Validation loss = 2.5325  \n",
      "\n",
      "Fold: 32  Epoch: 701  Training loss = 2.3064  Validation loss = 2.5322  \n",
      "\n",
      "Fold: 32  Epoch: 702  Training loss = 2.3064  Validation loss = 2.5323  \n",
      "\n",
      "Fold: 32  Epoch: 703  Training loss = 2.3063  Validation loss = 2.5322  \n",
      "\n",
      "Fold: 32  Epoch: 704  Training loss = 2.3063  Validation loss = 2.5322  \n",
      "\n",
      "Fold: 32  Epoch: 705  Training loss = 2.3063  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 32  Epoch: 706  Training loss = 2.3062  Validation loss = 2.5316  \n",
      "\n",
      "Fold: 32  Epoch: 707  Training loss = 2.3062  Validation loss = 2.5318  \n",
      "\n",
      "Fold: 32  Epoch: 708  Training loss = 2.3062  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 32  Epoch: 709  Training loss = 2.3062  Validation loss = 2.5315  \n",
      "\n",
      "Fold: 32  Epoch: 710  Training loss = 2.3062  Validation loss = 2.5315  \n",
      "\n",
      "Fold: 32  Epoch: 711  Training loss = 2.3062  Validation loss = 2.5314  \n",
      "\n",
      "Fold: 32  Epoch: 712  Training loss = 2.3062  Validation loss = 2.5316  \n",
      "\n",
      "Fold: 32  Epoch: 713  Training loss = 2.3062  Validation loss = 2.5317  \n",
      "\n",
      "Fold: 32  Epoch: 714  Training loss = 2.3061  Validation loss = 2.5315  \n",
      "\n",
      "Fold: 32  Epoch: 715  Training loss = 2.3061  Validation loss = 2.5312  \n",
      "\n",
      "Fold: 32  Epoch: 716  Training loss = 2.3060  Validation loss = 2.5309  \n",
      "\n",
      "Fold: 32  Epoch: 717  Training loss = 2.3060  Validation loss = 2.5306  \n",
      "\n",
      "Fold: 32  Epoch: 718  Training loss = 2.3060  Validation loss = 2.5304  \n",
      "\n",
      "Fold: 32  Epoch: 719  Training loss = 2.3059  Validation loss = 2.5302  \n",
      "\n",
      "Fold: 32  Epoch: 720  Training loss = 2.3059  Validation loss = 2.5301  \n",
      "\n",
      "Fold: 32  Epoch: 721  Training loss = 2.3058  Validation loss = 2.5298  \n",
      "\n",
      "Fold: 32  Epoch: 722  Training loss = 2.3058  Validation loss = 2.5293  \n",
      "\n",
      "Fold: 32  Epoch: 723  Training loss = 2.3058  Validation loss = 2.5293  \n",
      "\n",
      "Fold: 32  Epoch: 724  Training loss = 2.3058  Validation loss = 2.5294  \n",
      "\n",
      "Fold: 32  Epoch: 725  Training loss = 2.3057  Validation loss = 2.5292  \n",
      "\n",
      "Fold: 32  Epoch: 726  Training loss = 2.3057  Validation loss = 2.5289  \n",
      "\n",
      "Fold: 32  Epoch: 727  Training loss = 2.3056  Validation loss = 2.5286  \n",
      "\n",
      "Fold: 32  Epoch: 728  Training loss = 2.3056  Validation loss = 2.5285  \n",
      "\n",
      "Fold: 32  Epoch: 729  Training loss = 2.3056  Validation loss = 2.5285  \n",
      "\n",
      "Fold: 32  Epoch: 730  Training loss = 2.3056  Validation loss = 2.5283  \n",
      "\n",
      "Fold: 32  Epoch: 731  Training loss = 2.3056  Validation loss = 2.5284  \n",
      "\n",
      "Fold: 32  Epoch: 732  Training loss = 2.3056  Validation loss = 2.5287  \n",
      "\n",
      "Fold: 32  Epoch: 733  Training loss = 2.3055  Validation loss = 2.5284  \n",
      "\n",
      "Fold: 32  Epoch: 734  Training loss = 2.3055  Validation loss = 2.5278  \n",
      "\n",
      "Fold: 32  Epoch: 735  Training loss = 2.3054  Validation loss = 2.5278  \n",
      "\n",
      "Fold: 32  Epoch: 736  Training loss = 2.3055  Validation loss = 2.5281  \n",
      "\n",
      "Fold: 32  Epoch: 737  Training loss = 2.3054  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 32  Epoch: 738  Training loss = 2.3054  Validation loss = 2.5279  \n",
      "\n",
      "Fold: 32  Epoch: 739  Training loss = 2.3054  Validation loss = 2.5279  \n",
      "\n",
      "Fold: 32  Epoch: 740  Training loss = 2.3053  Validation loss = 2.5274  \n",
      "\n",
      "Fold: 32  Epoch: 741  Training loss = 2.3052  Validation loss = 2.5265  \n",
      "\n",
      "Fold: 32  Epoch: 742  Training loss = 2.3052  Validation loss = 2.5266  \n",
      "\n",
      "Fold: 32  Epoch: 743  Training loss = 2.3052  Validation loss = 2.5262  \n",
      "\n",
      "Fold: 32  Epoch: 744  Training loss = 2.3051  Validation loss = 2.5256  \n",
      "\n",
      "Fold: 32  Epoch: 745  Training loss = 2.3051  Validation loss = 2.5251  \n",
      "\n",
      "Fold: 32  Epoch: 746  Training loss = 2.3051  Validation loss = 2.5248  \n",
      "\n",
      "Fold: 32  Epoch: 747  Training loss = 2.3050  Validation loss = 2.5246  \n",
      "\n",
      "Fold: 32  Epoch: 748  Training loss = 2.3050  Validation loss = 2.5243  \n",
      "\n",
      "Fold: 32  Epoch: 749  Training loss = 2.3050  Validation loss = 2.5238  \n",
      "\n",
      "Fold: 32  Epoch: 750  Training loss = 2.3049  Validation loss = 2.5235  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 750  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 543\n",
      "Average validation error: 3.85279\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.9109  Test loss = 2.7087  \n",
      "\n",
      "Epoch: 2  Training loss = 1.9109  Test loss = 2.7087  \n",
      "\n",
      "Epoch: 3  Training loss = 1.9109  Test loss = 2.7087  \n",
      "\n",
      "Epoch: 4  Training loss = 1.9109  Test loss = 2.7086  \n",
      "\n",
      "Epoch: 5  Training loss = 1.9108  Test loss = 2.7086  \n",
      "\n",
      "Epoch: 6  Training loss = 1.9108  Test loss = 2.7086  \n",
      "\n",
      "Epoch: 7  Training loss = 1.9108  Test loss = 2.7086  \n",
      "\n",
      "Epoch: 8  Training loss = 1.9108  Test loss = 2.7085  \n",
      "\n",
      "Epoch: 9  Training loss = 1.9108  Test loss = 2.7085  \n",
      "\n",
      "Epoch: 10  Training loss = 1.9108  Test loss = 2.7085  \n",
      "\n",
      "Epoch: 11  Training loss = 1.9107  Test loss = 2.7085  \n",
      "\n",
      "Epoch: 12  Training loss = 1.9107  Test loss = 2.7084  \n",
      "\n",
      "Epoch: 13  Training loss = 1.9107  Test loss = 2.7084  \n",
      "\n",
      "Epoch: 14  Training loss = 1.9107  Test loss = 2.7084  \n",
      "\n",
      "Epoch: 15  Training loss = 1.9107  Test loss = 2.7084  \n",
      "\n",
      "Epoch: 16  Training loss = 1.9107  Test loss = 2.7084  \n",
      "\n",
      "Epoch: 17  Training loss = 1.9106  Test loss = 2.7083  \n",
      "\n",
      "Epoch: 18  Training loss = 1.9106  Test loss = 2.7083  \n",
      "\n",
      "Epoch: 19  Training loss = 1.9106  Test loss = 2.7083  \n",
      "\n",
      "Epoch: 20  Training loss = 1.9106  Test loss = 2.7083  \n",
      "\n",
      "Epoch: 21  Training loss = 1.9106  Test loss = 2.7082  \n",
      "\n",
      "Epoch: 22  Training loss = 1.9105  Test loss = 2.7082  \n",
      "\n",
      "Epoch: 23  Training loss = 1.9105  Test loss = 2.7082  \n",
      "\n",
      "Epoch: 24  Training loss = 1.9105  Test loss = 2.7082  \n",
      "\n",
      "Epoch: 25  Training loss = 1.9105  Test loss = 2.7081  \n",
      "\n",
      "Epoch: 26  Training loss = 1.9105  Test loss = 2.7081  \n",
      "\n",
      "Epoch: 27  Training loss = 1.9105  Test loss = 2.7081  \n",
      "\n",
      "Epoch: 28  Training loss = 1.9104  Test loss = 2.7081  \n",
      "\n",
      "Epoch: 29  Training loss = 1.9104  Test loss = 2.7081  \n",
      "\n",
      "Epoch: 30  Training loss = 1.9104  Test loss = 2.7080  \n",
      "\n",
      "Epoch: 31  Training loss = 1.9104  Test loss = 2.7080  \n",
      "\n",
      "Epoch: 32  Training loss = 1.9104  Test loss = 2.7080  \n",
      "\n",
      "Epoch: 33  Training loss = 1.9103  Test loss = 2.7080  \n",
      "\n",
      "Epoch: 34  Training loss = 1.9103  Test loss = 2.7079  \n",
      "\n",
      "Epoch: 35  Training loss = 1.9103  Test loss = 2.7079  \n",
      "\n",
      "Epoch: 36  Training loss = 1.9103  Test loss = 2.7079  \n",
      "\n",
      "Epoch: 37  Training loss = 1.9103  Test loss = 2.7079  \n",
      "\n",
      "Epoch: 38  Training loss = 1.9103  Test loss = 2.7078  \n",
      "\n",
      "Epoch: 39  Training loss = 1.9102  Test loss = 2.7078  \n",
      "\n",
      "Epoch: 40  Training loss = 1.9102  Test loss = 2.7078  \n",
      "\n",
      "Epoch: 41  Training loss = 1.9102  Test loss = 2.7078  \n",
      "\n",
      "Epoch: 42  Training loss = 1.9102  Test loss = 2.7077  \n",
      "\n",
      "Epoch: 43  Training loss = 1.9102  Test loss = 2.7077  \n",
      "\n",
      "Epoch: 44  Training loss = 1.9101  Test loss = 2.7077  \n",
      "\n",
      "Epoch: 45  Training loss = 1.9101  Test loss = 2.7077  \n",
      "\n",
      "Epoch: 46  Training loss = 1.9101  Test loss = 2.7077  \n",
      "\n",
      "Epoch: 47  Training loss = 1.9101  Test loss = 2.7076  \n",
      "\n",
      "Epoch: 48  Training loss = 1.9101  Test loss = 2.7076  \n",
      "\n",
      "Epoch: 49  Training loss = 1.9101  Test loss = 2.7076  \n",
      "\n",
      "Epoch: 50  Training loss = 1.9100  Test loss = 2.7076  \n",
      "\n",
      "Epoch: 51  Training loss = 1.9100  Test loss = 2.7075  \n",
      "\n",
      "Epoch: 52  Training loss = 1.9100  Test loss = 2.7075  \n",
      "\n",
      "Epoch: 53  Training loss = 1.9100  Test loss = 2.7075  \n",
      "\n",
      "Epoch: 54  Training loss = 1.9100  Test loss = 2.7075  \n",
      "\n",
      "Epoch: 55  Training loss = 1.9099  Test loss = 2.7074  \n",
      "\n",
      "Epoch: 56  Training loss = 1.9099  Test loss = 2.7074  \n",
      "\n",
      "Epoch: 57  Training loss = 1.9099  Test loss = 2.7074  \n",
      "\n",
      "Epoch: 58  Training loss = 1.9099  Test loss = 2.7074  \n",
      "\n",
      "Epoch: 59  Training loss = 1.9099  Test loss = 2.7074  \n",
      "\n",
      "Epoch: 60  Training loss = 1.9099  Test loss = 2.7073  \n",
      "\n",
      "Epoch: 61  Training loss = 1.9098  Test loss = 2.7073  \n",
      "\n",
      "Epoch: 62  Training loss = 1.9098  Test loss = 2.7073  \n",
      "\n",
      "Epoch: 63  Training loss = 1.9098  Test loss = 2.7073  \n",
      "\n",
      "Epoch: 64  Training loss = 1.9098  Test loss = 2.7072  \n",
      "\n",
      "Epoch: 65  Training loss = 1.9098  Test loss = 2.7072  \n",
      "\n",
      "Epoch: 66  Training loss = 1.9098  Test loss = 2.7072  \n",
      "\n",
      "Epoch: 67  Training loss = 1.9097  Test loss = 2.7072  \n",
      "\n",
      "Epoch: 68  Training loss = 1.9097  Test loss = 2.7071  \n",
      "\n",
      "Epoch: 69  Training loss = 1.9097  Test loss = 2.7071  \n",
      "\n",
      "Epoch: 70  Training loss = 1.9097  Test loss = 2.7071  \n",
      "\n",
      "Epoch: 71  Training loss = 1.9097  Test loss = 2.7071  \n",
      "\n",
      "Epoch: 72  Training loss = 1.9096  Test loss = 2.7071  \n",
      "\n",
      "Epoch: 73  Training loss = 1.9096  Test loss = 2.7070  \n",
      "\n",
      "Epoch: 74  Training loss = 1.9096  Test loss = 2.7070  \n",
      "\n",
      "Epoch: 75  Training loss = 1.9096  Test loss = 2.7070  \n",
      "\n",
      "Epoch: 76  Training loss = 1.9096  Test loss = 2.7070  \n",
      "\n",
      "Epoch: 77  Training loss = 1.9096  Test loss = 2.7069  \n",
      "\n",
      "Epoch: 78  Training loss = 1.9095  Test loss = 2.7069  \n",
      "\n",
      "Epoch: 79  Training loss = 1.9095  Test loss = 2.7069  \n",
      "\n",
      "Epoch: 80  Training loss = 1.9095  Test loss = 2.7069  \n",
      "\n",
      "Epoch: 81  Training loss = 1.9095  Test loss = 2.7068  \n",
      "\n",
      "Epoch: 82  Training loss = 1.9095  Test loss = 2.7068  \n",
      "\n",
      "Epoch: 83  Training loss = 1.9094  Test loss = 2.7068  \n",
      "\n",
      "Epoch: 84  Training loss = 1.9094  Test loss = 2.7068  \n",
      "\n",
      "Epoch: 85  Training loss = 1.9094  Test loss = 2.7068  \n",
      "\n",
      "Epoch: 86  Training loss = 1.9094  Test loss = 2.7067  \n",
      "\n",
      "Epoch: 87  Training loss = 1.9094  Test loss = 2.7067  \n",
      "\n",
      "Epoch: 88  Training loss = 1.9094  Test loss = 2.7067  \n",
      "\n",
      "Epoch: 89  Training loss = 1.9093  Test loss = 2.7067  \n",
      "\n",
      "Epoch: 90  Training loss = 1.9093  Test loss = 2.7066  \n",
      "\n",
      "Epoch: 91  Training loss = 1.9093  Test loss = 2.7066  \n",
      "\n",
      "Epoch: 92  Training loss = 1.9093  Test loss = 2.7066  \n",
      "\n",
      "Epoch: 93  Training loss = 1.9093  Test loss = 2.7066  \n",
      "\n",
      "Epoch: 94  Training loss = 1.9092  Test loss = 2.7065  \n",
      "\n",
      "Epoch: 95  Training loss = 1.9092  Test loss = 2.7065  \n",
      "\n",
      "Epoch: 96  Training loss = 1.9092  Test loss = 2.7065  \n",
      "\n",
      "Epoch: 97  Training loss = 1.9092  Test loss = 2.7065  \n",
      "\n",
      "Epoch: 98  Training loss = 1.9092  Test loss = 2.7065  \n",
      "\n",
      "Epoch: 99  Training loss = 1.9092  Test loss = 2.7064  \n",
      "\n",
      "Epoch: 100  Training loss = 1.9091  Test loss = 2.7064  \n",
      "\n",
      "Epoch: 101  Training loss = 1.9091  Test loss = 2.7064  \n",
      "\n",
      "Epoch: 102  Training loss = 1.9091  Test loss = 2.7064  \n",
      "\n",
      "Epoch: 103  Training loss = 1.9091  Test loss = 2.7063  \n",
      "\n",
      "Epoch: 104  Training loss = 1.9091  Test loss = 2.7063  \n",
      "\n",
      "Epoch: 105  Training loss = 1.9091  Test loss = 2.7063  \n",
      "\n",
      "Epoch: 106  Training loss = 1.9090  Test loss = 2.7063  \n",
      "\n",
      "Epoch: 107  Training loss = 1.9090  Test loss = 2.7062  \n",
      "\n",
      "Epoch: 108  Training loss = 1.9090  Test loss = 2.7062  \n",
      "\n",
      "Epoch: 109  Training loss = 1.9090  Test loss = 2.7062  \n",
      "\n",
      "Epoch: 110  Training loss = 1.9090  Test loss = 2.7062  \n",
      "\n",
      "Epoch: 111  Training loss = 1.9089  Test loss = 2.7062  \n",
      "\n",
      "Epoch: 112  Training loss = 1.9089  Test loss = 2.7061  \n",
      "\n",
      "Epoch: 113  Training loss = 1.9089  Test loss = 2.7061  \n",
      "\n",
      "Epoch: 114  Training loss = 1.9089  Test loss = 2.7061  \n",
      "\n",
      "Epoch: 115  Training loss = 1.9089  Test loss = 2.7061  \n",
      "\n",
      "Epoch: 116  Training loss = 1.9089  Test loss = 2.7060  \n",
      "\n",
      "Epoch: 117  Training loss = 1.9088  Test loss = 2.7060  \n",
      "\n",
      "Epoch: 118  Training loss = 1.9088  Test loss = 2.7060  \n",
      "\n",
      "Epoch: 119  Training loss = 1.9088  Test loss = 2.7060  \n",
      "\n",
      "Epoch: 120  Training loss = 1.9088  Test loss = 2.7059  \n",
      "\n",
      "Epoch: 121  Training loss = 1.9088  Test loss = 2.7059  \n",
      "\n",
      "Epoch: 122  Training loss = 1.9087  Test loss = 2.7059  \n",
      "\n",
      "Epoch: 123  Training loss = 1.9087  Test loss = 2.7059  \n",
      "\n",
      "Epoch: 124  Training loss = 1.9087  Test loss = 2.7059  \n",
      "\n",
      "Epoch: 125  Training loss = 1.9087  Test loss = 2.7058  \n",
      "\n",
      "Epoch: 126  Training loss = 1.9087  Test loss = 2.7058  \n",
      "\n",
      "Epoch: 127  Training loss = 1.9087  Test loss = 2.7058  \n",
      "\n",
      "Epoch: 128  Training loss = 1.9086  Test loss = 2.7058  \n",
      "\n",
      "Epoch: 129  Training loss = 1.9086  Test loss = 2.7057  \n",
      "\n",
      "Epoch: 130  Training loss = 1.9086  Test loss = 2.7057  \n",
      "\n",
      "Epoch: 131  Training loss = 1.9086  Test loss = 2.7057  \n",
      "\n",
      "Epoch: 132  Training loss = 1.9086  Test loss = 2.7057  \n",
      "\n",
      "Epoch: 133  Training loss = 1.9086  Test loss = 2.7056  \n",
      "\n",
      "Epoch: 134  Training loss = 1.9085  Test loss = 2.7056  \n",
      "\n",
      "Epoch: 135  Training loss = 1.9085  Test loss = 2.7056  \n",
      "\n",
      "Epoch: 136  Training loss = 1.9085  Test loss = 2.7056  \n",
      "\n",
      "Epoch: 137  Training loss = 1.9085  Test loss = 2.7056  \n",
      "\n",
      "Epoch: 138  Training loss = 1.9085  Test loss = 2.7055  \n",
      "\n",
      "Epoch: 139  Training loss = 1.9084  Test loss = 2.7055  \n",
      "\n",
      "Epoch: 140  Training loss = 1.9084  Test loss = 2.7055  \n",
      "\n",
      "Epoch: 141  Training loss = 1.9084  Test loss = 2.7055  \n",
      "\n",
      "Epoch: 142  Training loss = 1.9084  Test loss = 2.7054  \n",
      "\n",
      "Epoch: 143  Training loss = 1.9084  Test loss = 2.7054  \n",
      "\n",
      "Epoch: 144  Training loss = 1.9084  Test loss = 2.7054  \n",
      "\n",
      "Epoch: 145  Training loss = 1.9083  Test loss = 2.7054  \n",
      "\n",
      "Epoch: 146  Training loss = 1.9083  Test loss = 2.7054  \n",
      "\n",
      "Epoch: 147  Training loss = 1.9083  Test loss = 2.7053  \n",
      "\n",
      "Epoch: 148  Training loss = 1.9083  Test loss = 2.7053  \n",
      "\n",
      "Epoch: 149  Training loss = 1.9083  Test loss = 2.7053  \n",
      "\n",
      "Epoch: 150  Training loss = 1.9082  Test loss = 2.7053  \n",
      "\n",
      "Epoch: 151  Training loss = 1.9082  Test loss = 2.7052  \n",
      "\n",
      "Epoch: 152  Training loss = 1.9082  Test loss = 2.7052  \n",
      "\n",
      "Epoch: 153  Training loss = 1.9082  Test loss = 2.7052  \n",
      "\n",
      "Epoch: 154  Training loss = 1.9082  Test loss = 2.7052  \n",
      "\n",
      "Epoch: 155  Training loss = 1.9082  Test loss = 2.7051  \n",
      "\n",
      "Epoch: 156  Training loss = 1.9081  Test loss = 2.7051  \n",
      "\n",
      "Epoch: 157  Training loss = 1.9081  Test loss = 2.7051  \n",
      "\n",
      "Epoch: 158  Training loss = 1.9081  Test loss = 2.7051  \n",
      "\n",
      "Epoch: 159  Training loss = 1.9081  Test loss = 2.7051  \n",
      "\n",
      "Epoch: 160  Training loss = 1.9081  Test loss = 2.7050  \n",
      "\n",
      "Epoch: 161  Training loss = 1.9081  Test loss = 2.7050  \n",
      "\n",
      "Epoch: 162  Training loss = 1.9080  Test loss = 2.7050  \n",
      "\n",
      "Epoch: 163  Training loss = 1.9080  Test loss = 2.7050  \n",
      "\n",
      "Epoch: 164  Training loss = 1.9080  Test loss = 2.7049  \n",
      "\n",
      "Epoch: 165  Training loss = 1.9080  Test loss = 2.7049  \n",
      "\n",
      "Epoch: 166  Training loss = 1.9080  Test loss = 2.7049  \n",
      "\n",
      "Epoch: 167  Training loss = 1.9079  Test loss = 2.7049  \n",
      "\n",
      "Epoch: 168  Training loss = 1.9079  Test loss = 2.7048  \n",
      "\n",
      "Epoch: 169  Training loss = 1.9079  Test loss = 2.7048  \n",
      "\n",
      "Epoch: 170  Training loss = 1.9079  Test loss = 2.7048  \n",
      "\n",
      "Epoch: 171  Training loss = 1.9079  Test loss = 2.7048  \n",
      "\n",
      "Epoch: 172  Training loss = 1.9079  Test loss = 2.7048  \n",
      "\n",
      "Epoch: 173  Training loss = 1.9078  Test loss = 2.7047  \n",
      "\n",
      "Epoch: 174  Training loss = 1.9078  Test loss = 2.7047  \n",
      "\n",
      "Epoch: 175  Training loss = 1.9078  Test loss = 2.7047  \n",
      "\n",
      "Epoch: 176  Training loss = 1.9078  Test loss = 2.7047  \n",
      "\n",
      "Epoch: 177  Training loss = 1.9078  Test loss = 2.7046  \n",
      "\n",
      "Epoch: 178  Training loss = 1.9077  Test loss = 2.7046  \n",
      "\n",
      "Epoch: 179  Training loss = 1.9077  Test loss = 2.7046  \n",
      "\n",
      "Epoch: 180  Training loss = 1.9077  Test loss = 2.7046  \n",
      "\n",
      "Epoch: 181  Training loss = 1.9077  Test loss = 2.7046  \n",
      "\n",
      "Epoch: 182  Training loss = 1.9077  Test loss = 2.7045  \n",
      "\n",
      "Epoch: 183  Training loss = 1.9077  Test loss = 2.7045  \n",
      "\n",
      "Epoch: 184  Training loss = 1.9076  Test loss = 2.7045  \n",
      "\n",
      "Epoch: 185  Training loss = 1.9076  Test loss = 2.7045  \n",
      "\n",
      "Epoch: 186  Training loss = 1.9076  Test loss = 2.7044  \n",
      "\n",
      "Epoch: 187  Training loss = 1.9076  Test loss = 2.7044  \n",
      "\n",
      "Epoch: 188  Training loss = 1.9076  Test loss = 2.7044  \n",
      "\n",
      "Epoch: 189  Training loss = 1.9076  Test loss = 2.7044  \n",
      "\n",
      "Epoch: 190  Training loss = 1.9075  Test loss = 2.7043  \n",
      "\n",
      "Epoch: 191  Training loss = 1.9075  Test loss = 2.7043  \n",
      "\n",
      "Epoch: 192  Training loss = 1.9075  Test loss = 2.7043  \n",
      "\n",
      "Epoch: 193  Training loss = 1.9075  Test loss = 2.7043  \n",
      "\n",
      "Epoch: 194  Training loss = 1.9075  Test loss = 2.7043  \n",
      "\n",
      "Epoch: 195  Training loss = 1.9074  Test loss = 2.7042  \n",
      "\n",
      "Epoch: 196  Training loss = 1.9074  Test loss = 2.7042  \n",
      "\n",
      "Epoch: 197  Training loss = 1.9074  Test loss = 2.7042  \n",
      "\n",
      "Epoch: 198  Training loss = 1.9074  Test loss = 2.7042  \n",
      "\n",
      "Epoch: 199  Training loss = 1.9074  Test loss = 2.7041  \n",
      "\n",
      "Epoch: 200  Training loss = 1.9074  Test loss = 2.7041  \n",
      "\n",
      "Epoch: 201  Training loss = 1.9073  Test loss = 2.7041  \n",
      "\n",
      "Epoch: 202  Training loss = 1.9073  Test loss = 2.7041  \n",
      "\n",
      "Epoch: 203  Training loss = 1.9073  Test loss = 2.7041  \n",
      "\n",
      "Epoch: 204  Training loss = 1.9073  Test loss = 2.7040  \n",
      "\n",
      "Epoch: 205  Training loss = 1.9073  Test loss = 2.7040  \n",
      "\n",
      "Epoch: 206  Training loss = 1.9073  Test loss = 2.7040  \n",
      "\n",
      "Epoch: 207  Training loss = 1.9072  Test loss = 2.7040  \n",
      "\n",
      "Epoch: 208  Training loss = 1.9072  Test loss = 2.7039  \n",
      "\n",
      "Epoch: 209  Training loss = 1.9072  Test loss = 2.7039  \n",
      "\n",
      "Epoch: 210  Training loss = 1.9072  Test loss = 2.7039  \n",
      "\n",
      "Epoch: 211  Training loss = 1.9072  Test loss = 2.7039  \n",
      "\n",
      "Epoch: 212  Training loss = 1.9071  Test loss = 2.7039  \n",
      "\n",
      "Epoch: 213  Training loss = 1.9071  Test loss = 2.7038  \n",
      "\n",
      "Epoch: 214  Training loss = 1.9071  Test loss = 2.7038  \n",
      "\n",
      "Epoch: 215  Training loss = 1.9071  Test loss = 2.7038  \n",
      "\n",
      "Epoch: 216  Training loss = 1.9071  Test loss = 2.7038  \n",
      "\n",
      "Epoch: 217  Training loss = 1.9071  Test loss = 2.7037  \n",
      "\n",
      "Epoch: 218  Training loss = 1.9070  Test loss = 2.7037  \n",
      "\n",
      "Epoch: 219  Training loss = 1.9070  Test loss = 2.7037  \n",
      "\n",
      "Epoch: 220  Training loss = 1.9070  Test loss = 2.7037  \n",
      "\n",
      "Epoch: 221  Training loss = 1.9070  Test loss = 2.7036  \n",
      "\n",
      "Epoch: 222  Training loss = 1.9070  Test loss = 2.7036  \n",
      "\n",
      "Epoch: 223  Training loss = 1.9070  Test loss = 2.7036  \n",
      "\n",
      "Epoch: 224  Training loss = 1.9069  Test loss = 2.7036  \n",
      "\n",
      "Epoch: 225  Training loss = 1.9069  Test loss = 2.7036  \n",
      "\n",
      "Epoch: 226  Training loss = 1.9069  Test loss = 2.7035  \n",
      "\n",
      "Epoch: 227  Training loss = 1.9069  Test loss = 2.7035  \n",
      "\n",
      "Epoch: 228  Training loss = 1.9069  Test loss = 2.7035  \n",
      "\n",
      "Epoch: 229  Training loss = 1.9068  Test loss = 2.7035  \n",
      "\n",
      "Epoch: 230  Training loss = 1.9068  Test loss = 2.7034  \n",
      "\n",
      "Epoch: 231  Training loss = 1.9068  Test loss = 2.7034  \n",
      "\n",
      "Epoch: 232  Training loss = 1.9068  Test loss = 2.7034  \n",
      "\n",
      "Epoch: 233  Training loss = 1.9068  Test loss = 2.7034  \n",
      "\n",
      "Epoch: 234  Training loss = 1.9068  Test loss = 2.7034  \n",
      "\n",
      "Epoch: 235  Training loss = 1.9067  Test loss = 2.7033  \n",
      "\n",
      "Epoch: 236  Training loss = 1.9067  Test loss = 2.7033  \n",
      "\n",
      "Epoch: 237  Training loss = 1.9067  Test loss = 2.7033  \n",
      "\n",
      "Epoch: 238  Training loss = 1.9067  Test loss = 2.7033  \n",
      "\n",
      "Epoch: 239  Training loss = 1.9067  Test loss = 2.7032  \n",
      "\n",
      "Epoch: 240  Training loss = 1.9067  Test loss = 2.7032  \n",
      "\n",
      "Epoch: 241  Training loss = 1.9066  Test loss = 2.7032  \n",
      "\n",
      "Epoch: 242  Training loss = 1.9066  Test loss = 2.7032  \n",
      "\n",
      "Epoch: 243  Training loss = 1.9066  Test loss = 2.7032  \n",
      "\n",
      "Epoch: 244  Training loss = 1.9066  Test loss = 2.7031  \n",
      "\n",
      "Epoch: 245  Training loss = 1.9066  Test loss = 2.7031  \n",
      "\n",
      "Epoch: 246  Training loss = 1.9065  Test loss = 2.7031  \n",
      "\n",
      "Epoch: 247  Training loss = 1.9065  Test loss = 2.7031  \n",
      "\n",
      "Epoch: 248  Training loss = 1.9065  Test loss = 2.7030  \n",
      "\n",
      "Epoch: 249  Training loss = 1.9065  Test loss = 2.7030  \n",
      "\n",
      "Epoch: 250  Training loss = 1.9065  Test loss = 2.7030  \n",
      "\n",
      "Epoch: 251  Training loss = 1.9065  Test loss = 2.7030  \n",
      "\n",
      "Epoch: 252  Training loss = 1.9064  Test loss = 2.7029  \n",
      "\n",
      "Epoch: 253  Training loss = 1.9064  Test loss = 2.7029  \n",
      "\n",
      "Epoch: 254  Training loss = 1.9064  Test loss = 2.7029  \n",
      "\n",
      "Epoch: 255  Training loss = 1.9064  Test loss = 2.7029  \n",
      "\n",
      "Epoch: 256  Training loss = 1.9064  Test loss = 2.7029  \n",
      "\n",
      "Epoch: 257  Training loss = 1.9064  Test loss = 2.7028  \n",
      "\n",
      "Epoch: 258  Training loss = 1.9063  Test loss = 2.7028  \n",
      "\n",
      "Epoch: 259  Training loss = 1.9063  Test loss = 2.7028  \n",
      "\n",
      "Epoch: 260  Training loss = 1.9063  Test loss = 2.7028  \n",
      "\n",
      "Epoch: 261  Training loss = 1.9063  Test loss = 2.7027  \n",
      "\n",
      "Epoch: 262  Training loss = 1.9063  Test loss = 2.7027  \n",
      "\n",
      "Epoch: 263  Training loss = 1.9062  Test loss = 2.7027  \n",
      "\n",
      "Epoch: 264  Training loss = 1.9062  Test loss = 2.7027  \n",
      "\n",
      "Epoch: 265  Training loss = 1.9062  Test loss = 2.7027  \n",
      "\n",
      "Epoch: 266  Training loss = 1.9062  Test loss = 2.7026  \n",
      "\n",
      "Epoch: 267  Training loss = 1.9062  Test loss = 2.7026  \n",
      "\n",
      "Epoch: 268  Training loss = 1.9062  Test loss = 2.7026  \n",
      "\n",
      "Epoch: 269  Training loss = 1.9061  Test loss = 2.7026  \n",
      "\n",
      "Epoch: 270  Training loss = 1.9061  Test loss = 2.7025  \n",
      "\n",
      "Epoch: 271  Training loss = 1.9061  Test loss = 2.7025  \n",
      "\n",
      "Epoch: 272  Training loss = 1.9061  Test loss = 2.7025  \n",
      "\n",
      "Epoch: 273  Training loss = 1.9061  Test loss = 2.7025  \n",
      "\n",
      "Epoch: 274  Training loss = 1.9061  Test loss = 2.7025  \n",
      "\n",
      "Epoch: 275  Training loss = 1.9060  Test loss = 2.7024  \n",
      "\n",
      "Epoch: 276  Training loss = 1.9060  Test loss = 2.7024  \n",
      "\n",
      "Epoch: 277  Training loss = 1.9060  Test loss = 2.7024  \n",
      "\n",
      "Epoch: 278  Training loss = 1.9060  Test loss = 2.7024  \n",
      "\n",
      "Epoch: 279  Training loss = 1.9060  Test loss = 2.7023  \n",
      "\n",
      "Epoch: 280  Training loss = 1.9059  Test loss = 2.7023  \n",
      "\n",
      "Epoch: 281  Training loss = 1.9059  Test loss = 2.7023  \n",
      "\n",
      "Epoch: 282  Training loss = 1.9059  Test loss = 2.7023  \n",
      "\n",
      "Epoch: 283  Training loss = 1.9059  Test loss = 2.7023  \n",
      "\n",
      "Epoch: 284  Training loss = 1.9059  Test loss = 2.7022  \n",
      "\n",
      "Epoch: 285  Training loss = 1.9059  Test loss = 2.7022  \n",
      "\n",
      "Epoch: 286  Training loss = 1.9058  Test loss = 2.7022  \n",
      "\n",
      "Epoch: 287  Training loss = 1.9058  Test loss = 2.7022  \n",
      "\n",
      "Epoch: 288  Training loss = 1.9058  Test loss = 2.7021  \n",
      "\n",
      "Epoch: 289  Training loss = 1.9058  Test loss = 2.7021  \n",
      "\n",
      "Epoch: 290  Training loss = 1.9058  Test loss = 2.7021  \n",
      "\n",
      "Epoch: 291  Training loss = 1.9058  Test loss = 2.7021  \n",
      "\n",
      "Epoch: 292  Training loss = 1.9057  Test loss = 2.7021  \n",
      "\n",
      "Epoch: 293  Training loss = 1.9057  Test loss = 2.7020  \n",
      "\n",
      "Epoch: 294  Training loss = 1.9057  Test loss = 2.7020  \n",
      "\n",
      "Epoch: 295  Training loss = 1.9057  Test loss = 2.7020  \n",
      "\n",
      "Epoch: 296  Training loss = 1.9057  Test loss = 2.7020  \n",
      "\n",
      "Epoch: 297  Training loss = 1.9056  Test loss = 2.7019  \n",
      "\n",
      "Epoch: 298  Training loss = 1.9056  Test loss = 2.7019  \n",
      "\n",
      "Epoch: 299  Training loss = 1.9056  Test loss = 2.7019  \n",
      "\n",
      "Epoch: 300  Training loss = 1.9056  Test loss = 2.7019  \n",
      "\n",
      "Epoch: 301  Training loss = 1.9056  Test loss = 2.7019  \n",
      "\n",
      "Epoch: 302  Training loss = 1.9056  Test loss = 2.7018  \n",
      "\n",
      "Epoch: 303  Training loss = 1.9055  Test loss = 2.7018  \n",
      "\n",
      "Epoch: 304  Training loss = 1.9055  Test loss = 2.7018  \n",
      "\n",
      "Epoch: 305  Training loss = 1.9055  Test loss = 2.7018  \n",
      "\n",
      "Epoch: 306  Training loss = 1.9055  Test loss = 2.7017  \n",
      "\n",
      "Epoch: 307  Training loss = 1.9055  Test loss = 2.7017  \n",
      "\n",
      "Epoch: 308  Training loss = 1.9055  Test loss = 2.7017  \n",
      "\n",
      "Epoch: 309  Training loss = 1.9054  Test loss = 2.7017  \n",
      "\n",
      "Epoch: 310  Training loss = 1.9054  Test loss = 2.7017  \n",
      "\n",
      "Epoch: 311  Training loss = 1.9054  Test loss = 2.7016  \n",
      "\n",
      "Epoch: 312  Training loss = 1.9054  Test loss = 2.7016  \n",
      "\n",
      "Epoch: 313  Training loss = 1.9054  Test loss = 2.7016  \n",
      "\n",
      "Epoch: 314  Training loss = 1.9053  Test loss = 2.7016  \n",
      "\n",
      "Epoch: 315  Training loss = 1.9053  Test loss = 2.7015  \n",
      "\n",
      "Epoch: 316  Training loss = 1.9053  Test loss = 2.7015  \n",
      "\n",
      "Epoch: 317  Training loss = 1.9053  Test loss = 2.7015  \n",
      "\n",
      "Epoch: 318  Training loss = 1.9053  Test loss = 2.7015  \n",
      "\n",
      "Epoch: 319  Training loss = 1.9053  Test loss = 2.7015  \n",
      "\n",
      "Epoch: 320  Training loss = 1.9052  Test loss = 2.7014  \n",
      "\n",
      "Epoch: 321  Training loss = 1.9052  Test loss = 2.7014  \n",
      "\n",
      "Epoch: 322  Training loss = 1.9052  Test loss = 2.7014  \n",
      "\n",
      "Epoch: 323  Training loss = 1.9052  Test loss = 2.7014  \n",
      "\n",
      "Epoch: 324  Training loss = 1.9052  Test loss = 2.7013  \n",
      "\n",
      "Epoch: 325  Training loss = 1.9052  Test loss = 2.7013  \n",
      "\n",
      "Epoch: 326  Training loss = 1.9051  Test loss = 2.7013  \n",
      "\n",
      "Epoch: 327  Training loss = 1.9051  Test loss = 2.7013  \n",
      "\n",
      "Epoch: 328  Training loss = 1.9051  Test loss = 2.7013  \n",
      "\n",
      "Epoch: 329  Training loss = 1.9051  Test loss = 2.7012  \n",
      "\n",
      "Epoch: 330  Training loss = 1.9051  Test loss = 2.7012  \n",
      "\n",
      "Epoch: 331  Training loss = 1.9050  Test loss = 2.7012  \n",
      "\n",
      "Epoch: 332  Training loss = 1.9050  Test loss = 2.7012  \n",
      "\n",
      "Epoch: 333  Training loss = 1.9050  Test loss = 2.7011  \n",
      "\n",
      "Epoch: 334  Training loss = 1.9050  Test loss = 2.7011  \n",
      "\n",
      "Epoch: 335  Training loss = 1.9050  Test loss = 2.7011  \n",
      "\n",
      "Epoch: 336  Training loss = 1.9050  Test loss = 2.7011  \n",
      "\n",
      "Epoch: 337  Training loss = 1.9049  Test loss = 2.7011  \n",
      "\n",
      "Epoch: 338  Training loss = 1.9049  Test loss = 2.7010  \n",
      "\n",
      "Epoch: 339  Training loss = 1.9049  Test loss = 2.7010  \n",
      "\n",
      "Epoch: 340  Training loss = 1.9049  Test loss = 2.7010  \n",
      "\n",
      "Epoch: 341  Training loss = 1.9049  Test loss = 2.7010  \n",
      "\n",
      "Epoch: 342  Training loss = 1.9049  Test loss = 2.7009  \n",
      "\n",
      "Epoch: 343  Training loss = 1.9048  Test loss = 2.7009  \n",
      "\n",
      "Epoch: 344  Training loss = 1.9048  Test loss = 2.7009  \n",
      "\n",
      "Epoch: 345  Training loss = 1.9048  Test loss = 2.7009  \n",
      "\n",
      "Epoch: 346  Training loss = 1.9048  Test loss = 2.7009  \n",
      "\n",
      "Epoch: 347  Training loss = 1.9048  Test loss = 2.7008  \n",
      "\n",
      "Epoch: 348  Training loss = 1.9048  Test loss = 2.7008  \n",
      "\n",
      "Epoch: 349  Training loss = 1.9047  Test loss = 2.7008  \n",
      "\n",
      "Epoch: 350  Training loss = 1.9047  Test loss = 2.7008  \n",
      "\n",
      "Epoch: 351  Training loss = 1.9047  Test loss = 2.7007  \n",
      "\n",
      "Epoch: 352  Training loss = 1.9047  Test loss = 2.7007  \n",
      "\n",
      "Epoch: 353  Training loss = 1.9047  Test loss = 2.7007  \n",
      "\n",
      "Epoch: 354  Training loss = 1.9046  Test loss = 2.7007  \n",
      "\n",
      "Epoch: 355  Training loss = 1.9046  Test loss = 2.7007  \n",
      "\n",
      "Epoch: 356  Training loss = 1.9046  Test loss = 2.7006  \n",
      "\n",
      "Epoch: 357  Training loss = 1.9046  Test loss = 2.7006  \n",
      "\n",
      "Epoch: 358  Training loss = 1.9046  Test loss = 2.7006  \n",
      "\n",
      "Epoch: 359  Training loss = 1.9046  Test loss = 2.7006  \n",
      "\n",
      "Epoch: 360  Training loss = 1.9045  Test loss = 2.7005  \n",
      "\n",
      "Epoch: 361  Training loss = 1.9045  Test loss = 2.7005  \n",
      "\n",
      "Epoch: 362  Training loss = 1.9045  Test loss = 2.7005  \n",
      "\n",
      "Epoch: 363  Training loss = 1.9045  Test loss = 2.7005  \n",
      "\n",
      "Epoch: 364  Training loss = 1.9045  Test loss = 2.7005  \n",
      "\n",
      "Epoch: 365  Training loss = 1.9045  Test loss = 2.7004  \n",
      "\n",
      "Epoch: 366  Training loss = 1.9044  Test loss = 2.7004  \n",
      "\n",
      "Epoch: 367  Training loss = 1.9044  Test loss = 2.7004  \n",
      "\n",
      "Epoch: 368  Training loss = 1.9044  Test loss = 2.7004  \n",
      "\n",
      "Epoch: 369  Training loss = 1.9044  Test loss = 2.7004  \n",
      "\n",
      "Epoch: 370  Training loss = 1.9044  Test loss = 2.7003  \n",
      "\n",
      "Epoch: 371  Training loss = 1.9043  Test loss = 2.7003  \n",
      "\n",
      "Epoch: 372  Training loss = 1.9043  Test loss = 2.7003  \n",
      "\n",
      "Epoch: 373  Training loss = 1.9043  Test loss = 2.7003  \n",
      "\n",
      "Epoch: 374  Training loss = 1.9043  Test loss = 2.7002  \n",
      "\n",
      "Epoch: 375  Training loss = 1.9043  Test loss = 2.7002  \n",
      "\n",
      "Epoch: 376  Training loss = 1.9043  Test loss = 2.7002  \n",
      "\n",
      "Epoch: 377  Training loss = 1.9042  Test loss = 2.7002  \n",
      "\n",
      "Epoch: 378  Training loss = 1.9042  Test loss = 2.7002  \n",
      "\n",
      "Epoch: 379  Training loss = 1.9042  Test loss = 2.7001  \n",
      "\n",
      "Epoch: 380  Training loss = 1.9042  Test loss = 2.7001  \n",
      "\n",
      "Epoch: 381  Training loss = 1.9042  Test loss = 2.7001  \n",
      "\n",
      "Epoch: 382  Training loss = 1.9042  Test loss = 2.7001  \n",
      "\n",
      "Epoch: 383  Training loss = 1.9041  Test loss = 2.7000  \n",
      "\n",
      "Epoch: 384  Training loss = 1.9041  Test loss = 2.7000  \n",
      "\n",
      "Epoch: 385  Training loss = 1.9041  Test loss = 2.7000  \n",
      "\n",
      "Epoch: 386  Training loss = 1.9041  Test loss = 2.7000  \n",
      "\n",
      "Epoch: 387  Training loss = 1.9041  Test loss = 2.7000  \n",
      "\n",
      "Epoch: 388  Training loss = 1.9041  Test loss = 2.6999  \n",
      "\n",
      "Epoch: 389  Training loss = 1.9040  Test loss = 2.6999  \n",
      "\n",
      "Epoch: 390  Training loss = 1.9040  Test loss = 2.6999  \n",
      "\n",
      "Epoch: 391  Training loss = 1.9040  Test loss = 2.6999  \n",
      "\n",
      "Epoch: 392  Training loss = 1.9040  Test loss = 2.6998  \n",
      "\n",
      "Epoch: 393  Training loss = 1.9040  Test loss = 2.6998  \n",
      "\n",
      "Epoch: 394  Training loss = 1.9039  Test loss = 2.6998  \n",
      "\n",
      "Epoch: 395  Training loss = 1.9039  Test loss = 2.6998  \n",
      "\n",
      "Epoch: 396  Training loss = 1.9039  Test loss = 2.6998  \n",
      "\n",
      "Epoch: 397  Training loss = 1.9039  Test loss = 2.6997  \n",
      "\n",
      "Epoch: 398  Training loss = 1.9039  Test loss = 2.6997  \n",
      "\n",
      "Epoch: 399  Training loss = 1.9039  Test loss = 2.6997  \n",
      "\n",
      "Epoch: 400  Training loss = 1.9038  Test loss = 2.6997  \n",
      "\n",
      "Epoch: 401  Training loss = 1.9038  Test loss = 2.6997  \n",
      "\n",
      "Epoch: 402  Training loss = 1.9038  Test loss = 2.6996  \n",
      "\n",
      "Epoch: 403  Training loss = 1.9038  Test loss = 2.6996  \n",
      "\n",
      "Epoch: 404  Training loss = 1.9038  Test loss = 2.6996  \n",
      "\n",
      "Epoch: 405  Training loss = 1.9038  Test loss = 2.6996  \n",
      "\n",
      "Epoch: 406  Training loss = 1.9037  Test loss = 2.6995  \n",
      "\n",
      "Epoch: 407  Training loss = 1.9037  Test loss = 2.6995  \n",
      "\n",
      "Epoch: 408  Training loss = 1.9037  Test loss = 2.6995  \n",
      "\n",
      "Epoch: 409  Training loss = 1.9037  Test loss = 2.6995  \n",
      "\n",
      "Epoch: 410  Training loss = 1.9037  Test loss = 2.6995  \n",
      "\n",
      "Epoch: 411  Training loss = 1.9037  Test loss = 2.6994  \n",
      "\n",
      "Epoch: 412  Training loss = 1.9036  Test loss = 2.6994  \n",
      "\n",
      "Epoch: 413  Training loss = 1.9036  Test loss = 2.6994  \n",
      "\n",
      "Epoch: 414  Training loss = 1.9036  Test loss = 2.6994  \n",
      "\n",
      "Epoch: 415  Training loss = 1.9036  Test loss = 2.6993  \n",
      "\n",
      "Epoch: 416  Training loss = 1.9036  Test loss = 2.6993  \n",
      "\n",
      "Epoch: 417  Training loss = 1.9035  Test loss = 2.6993  \n",
      "\n",
      "Epoch: 418  Training loss = 1.9035  Test loss = 2.6993  \n",
      "\n",
      "Epoch: 419  Training loss = 1.9035  Test loss = 2.6993  \n",
      "\n",
      "Epoch: 420  Training loss = 1.9035  Test loss = 2.6992  \n",
      "\n",
      "Epoch: 421  Training loss = 1.9035  Test loss = 2.6992  \n",
      "\n",
      "Epoch: 422  Training loss = 1.9035  Test loss = 2.6992  \n",
      "\n",
      "Epoch: 423  Training loss = 1.9034  Test loss = 2.6992  \n",
      "\n",
      "Epoch: 424  Training loss = 1.9034  Test loss = 2.6991  \n",
      "\n",
      "Epoch: 425  Training loss = 1.9034  Test loss = 2.6991  \n",
      "\n",
      "Epoch: 426  Training loss = 1.9034  Test loss = 2.6991  \n",
      "\n",
      "Epoch: 427  Training loss = 1.9034  Test loss = 2.6991  \n",
      "\n",
      "Epoch: 428  Training loss = 1.9034  Test loss = 2.6991  \n",
      "\n",
      "Epoch: 429  Training loss = 1.9033  Test loss = 2.6990  \n",
      "\n",
      "Epoch: 430  Training loss = 1.9033  Test loss = 2.6990  \n",
      "\n",
      "Epoch: 431  Training loss = 1.9033  Test loss = 2.6990  \n",
      "\n",
      "Epoch: 432  Training loss = 1.9033  Test loss = 2.6990  \n",
      "\n",
      "Epoch: 433  Training loss = 1.9033  Test loss = 2.6990  \n",
      "\n",
      "Epoch: 434  Training loss = 1.9033  Test loss = 2.6989  \n",
      "\n",
      "Epoch: 435  Training loss = 1.9032  Test loss = 2.6989  \n",
      "\n",
      "Epoch: 436  Training loss = 1.9032  Test loss = 2.6989  \n",
      "\n",
      "Epoch: 437  Training loss = 1.9032  Test loss = 2.6989  \n",
      "\n",
      "Epoch: 438  Training loss = 1.9032  Test loss = 2.6988  \n",
      "\n",
      "Epoch: 439  Training loss = 1.9032  Test loss = 2.6988  \n",
      "\n",
      "Epoch: 440  Training loss = 1.9031  Test loss = 2.6988  \n",
      "\n",
      "Epoch: 441  Training loss = 1.9031  Test loss = 2.6988  \n",
      "\n",
      "Epoch: 442  Training loss = 1.9031  Test loss = 2.6988  \n",
      "\n",
      "Epoch: 443  Training loss = 1.9031  Test loss = 2.6987  \n",
      "\n",
      "Epoch: 444  Training loss = 1.9031  Test loss = 2.6987  \n",
      "\n",
      "Epoch: 445  Training loss = 1.9031  Test loss = 2.6987  \n",
      "\n",
      "Epoch: 446  Training loss = 1.9030  Test loss = 2.6987  \n",
      "\n",
      "Epoch: 447  Training loss = 1.9030  Test loss = 2.6986  \n",
      "\n",
      "Epoch: 448  Training loss = 1.9030  Test loss = 2.6986  \n",
      "\n",
      "Epoch: 449  Training loss = 1.9030  Test loss = 2.6986  \n",
      "\n",
      "Epoch: 450  Training loss = 1.9030  Test loss = 2.6986  \n",
      "\n",
      "Epoch: 451  Training loss = 1.9030  Test loss = 2.6986  \n",
      "\n",
      "Epoch: 452  Training loss = 1.9029  Test loss = 2.6985  \n",
      "\n",
      "Epoch: 453  Training loss = 1.9029  Test loss = 2.6985  \n",
      "\n",
      "Epoch: 454  Training loss = 1.9029  Test loss = 2.6985  \n",
      "\n",
      "Epoch: 455  Training loss = 1.9029  Test loss = 2.6985  \n",
      "\n",
      "Epoch: 456  Training loss = 1.9029  Test loss = 2.6985  \n",
      "\n",
      "Epoch: 457  Training loss = 1.9029  Test loss = 2.6984  \n",
      "\n",
      "Epoch: 458  Training loss = 1.9028  Test loss = 2.6984  \n",
      "\n",
      "Epoch: 459  Training loss = 1.9028  Test loss = 2.6984  \n",
      "\n",
      "Epoch: 460  Training loss = 1.9028  Test loss = 2.6984  \n",
      "\n",
      "Epoch: 461  Training loss = 1.9028  Test loss = 2.6983  \n",
      "\n",
      "Epoch: 462  Training loss = 1.9028  Test loss = 2.6983  \n",
      "\n",
      "Epoch: 463  Training loss = 1.9028  Test loss = 2.6983  \n",
      "\n",
      "Epoch: 464  Training loss = 1.9027  Test loss = 2.6983  \n",
      "\n",
      "Epoch: 465  Training loss = 1.9027  Test loss = 2.6983  \n",
      "\n",
      "Epoch: 466  Training loss = 1.9027  Test loss = 2.6982  \n",
      "\n",
      "Epoch: 467  Training loss = 1.9027  Test loss = 2.6982  \n",
      "\n",
      "Epoch: 468  Training loss = 1.9027  Test loss = 2.6982  \n",
      "\n",
      "Epoch: 469  Training loss = 1.9026  Test loss = 2.6982  \n",
      "\n",
      "Epoch: 470  Training loss = 1.9026  Test loss = 2.6981  \n",
      "\n",
      "Epoch: 471  Training loss = 1.9026  Test loss = 2.6981  \n",
      "\n",
      "Epoch: 472  Training loss = 1.9026  Test loss = 2.6981  \n",
      "\n",
      "Epoch: 473  Training loss = 1.9026  Test loss = 2.6981  \n",
      "\n",
      "Epoch: 474  Training loss = 1.9026  Test loss = 2.6981  \n",
      "\n",
      "Epoch: 475  Training loss = 1.9025  Test loss = 2.6980  \n",
      "\n",
      "Epoch: 476  Training loss = 1.9025  Test loss = 2.6980  \n",
      "\n",
      "Epoch: 477  Training loss = 1.9025  Test loss = 2.6980  \n",
      "\n",
      "Epoch: 478  Training loss = 1.9025  Test loss = 2.6980  \n",
      "\n",
      "Epoch: 479  Training loss = 1.9025  Test loss = 2.6980  \n",
      "\n",
      "Epoch: 480  Training loss = 1.9025  Test loss = 2.6979  \n",
      "\n",
      "Epoch: 481  Training loss = 1.9024  Test loss = 2.6979  \n",
      "\n",
      "Epoch: 482  Training loss = 1.9024  Test loss = 2.6979  \n",
      "\n",
      "Epoch: 483  Training loss = 1.9024  Test loss = 2.6979  \n",
      "\n",
      "Epoch: 484  Training loss = 1.9024  Test loss = 2.6978  \n",
      "\n",
      "Epoch: 485  Training loss = 1.9024  Test loss = 2.6978  \n",
      "\n",
      "Epoch: 486  Training loss = 1.9024  Test loss = 2.6978  \n",
      "\n",
      "Epoch: 487  Training loss = 1.9023  Test loss = 2.6978  \n",
      "\n",
      "Epoch: 488  Training loss = 1.9023  Test loss = 2.6978  \n",
      "\n",
      "Epoch: 489  Training loss = 1.9023  Test loss = 2.6977  \n",
      "\n",
      "Epoch: 490  Training loss = 1.9023  Test loss = 2.6977  \n",
      "\n",
      "Epoch: 491  Training loss = 1.9023  Test loss = 2.6977  \n",
      "\n",
      "Epoch: 492  Training loss = 1.9022  Test loss = 2.6977  \n",
      "\n",
      "Epoch: 493  Training loss = 1.9022  Test loss = 2.6977  \n",
      "\n",
      "Epoch: 494  Training loss = 1.9022  Test loss = 2.6976  \n",
      "\n",
      "Epoch: 495  Training loss = 1.9022  Test loss = 2.6976  \n",
      "\n",
      "Epoch: 496  Training loss = 1.9022  Test loss = 2.6976  \n",
      "\n",
      "Epoch: 497  Training loss = 1.9022  Test loss = 2.6976  \n",
      "\n",
      "Epoch: 498  Training loss = 1.9021  Test loss = 2.6975  \n",
      "\n",
      "Epoch: 499  Training loss = 1.9021  Test loss = 2.6975  \n",
      "\n",
      "Epoch: 500  Training loss = 1.9021  Test loss = 2.6975  \n",
      "\n",
      "Epoch: 501  Training loss = 1.9021  Test loss = 2.6975  \n",
      "\n",
      "Epoch: 502  Training loss = 1.9021  Test loss = 2.6975  \n",
      "\n",
      "Epoch: 503  Training loss = 1.9021  Test loss = 2.6974  \n",
      "\n",
      "Epoch: 504  Training loss = 1.9020  Test loss = 2.6974  \n",
      "\n",
      "Epoch: 505  Training loss = 1.9020  Test loss = 2.6974  \n",
      "\n",
      "Epoch: 506  Training loss = 1.9020  Test loss = 2.6974  \n",
      "\n",
      "Epoch: 507  Training loss = 1.9020  Test loss = 2.6974  \n",
      "\n",
      "Epoch: 508  Training loss = 1.9020  Test loss = 2.6973  \n",
      "\n",
      "Epoch: 509  Training loss = 1.9020  Test loss = 2.6973  \n",
      "\n",
      "Epoch: 510  Training loss = 1.9019  Test loss = 2.6973  \n",
      "\n",
      "Epoch: 511  Training loss = 1.9019  Test loss = 2.6973  \n",
      "\n",
      "Epoch: 512  Training loss = 1.9019  Test loss = 2.6972  \n",
      "\n",
      "Epoch: 513  Training loss = 1.9019  Test loss = 2.6972  \n",
      "\n",
      "Epoch: 514  Training loss = 1.9019  Test loss = 2.6972  \n",
      "\n",
      "Epoch: 515  Training loss = 1.9019  Test loss = 2.6972  \n",
      "\n",
      "Epoch: 516  Training loss = 1.9018  Test loss = 2.6972  \n",
      "\n",
      "Epoch: 517  Training loss = 1.9018  Test loss = 2.6971  \n",
      "\n",
      "Epoch: 518  Training loss = 1.9018  Test loss = 2.6971  \n",
      "\n",
      "Epoch: 519  Training loss = 1.9018  Test loss = 2.6971  \n",
      "\n",
      "Epoch: 520  Training loss = 1.9018  Test loss = 2.6971  \n",
      "\n",
      "Epoch: 521  Training loss = 1.9017  Test loss = 2.6971  \n",
      "\n",
      "Epoch: 522  Training loss = 1.9017  Test loss = 2.6970  \n",
      "\n",
      "Epoch: 523  Training loss = 1.9017  Test loss = 2.6970  \n",
      "\n",
      "Epoch: 524  Training loss = 1.9017  Test loss = 2.6970  \n",
      "\n",
      "Epoch: 525  Training loss = 1.9017  Test loss = 2.6970  \n",
      "\n",
      "Epoch: 526  Training loss = 1.9017  Test loss = 2.6969  \n",
      "\n",
      "Epoch: 527  Training loss = 1.9016  Test loss = 2.6969  \n",
      "\n",
      "Epoch: 528  Training loss = 1.9016  Test loss = 2.6969  \n",
      "\n",
      "Epoch: 529  Training loss = 1.9016  Test loss = 2.6969  \n",
      "\n",
      "Epoch: 530  Training loss = 1.9016  Test loss = 2.6969  \n",
      "\n",
      "Epoch: 531  Training loss = 1.9016  Test loss = 2.6968  \n",
      "\n",
      "Epoch: 532  Training loss = 1.9016  Test loss = 2.6968  \n",
      "\n",
      "Epoch: 533  Training loss = 1.9015  Test loss = 2.6968  \n",
      "\n",
      "Epoch: 534  Training loss = 1.9015  Test loss = 2.6968  \n",
      "\n",
      "Epoch: 535  Training loss = 1.9015  Test loss = 2.6968  \n",
      "\n",
      "Epoch: 536  Training loss = 1.9015  Test loss = 2.6967  \n",
      "\n",
      "Epoch: 537  Training loss = 1.9015  Test loss = 2.6967  \n",
      "\n",
      "Epoch: 538  Training loss = 1.9015  Test loss = 2.6967  \n",
      "\n",
      "Epoch: 539  Training loss = 1.9014  Test loss = 2.6967  \n",
      "\n",
      "Epoch: 540  Training loss = 1.9014  Test loss = 2.6966  \n",
      "\n",
      "Epoch: 541  Training loss = 1.9014  Test loss = 2.6966  \n",
      "\n",
      "Epoch: 542  Training loss = 1.9014  Test loss = 2.6966  \n",
      "\n",
      "Epoch: 543  Training loss = 1.9014  Test loss = 2.6966  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2owLu5lZm/kHaUlhoXnKxaUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1ff5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXl4U1X6x78nbVJKS1tKWWTtCoWWAlIoq+ybrII6KoyA\nCoKKCK7gOKMzMuO48RMdEVREBEYUUaBikd1hp7QspUBLoQt7KXRfk5zfHyc3TdKsTdK06ft5Hp7Q\nm7uce3Pv977nfd/zHsY5B0EQBOE+yFzdAIIgCMKxkLATBEG4GSTsBEEQbgYJO0EQhJtBwk4QBOFm\nkLATBEG4GSTsBEEQbgYJO0EQhJtBwk4QBOFmeLrioEFBQTw4ONgVhyYIgmiwnDx58g7nvKWl9Vwi\n7MHBwUhMTHTFoQmCIBosjLEsa9YjVwxBEISbQcJOEAThZpCwEwRBuBkk7ARBEG4GCTtBEISbQcJO\nEAThZpCwEwRBuBkk7AThIAoKCvDtt9+6uhkEQcJOEI7ik08+waxZs3D16lVXN4Vo5DhE2BljAYyx\nzYyxC4yx84yx/o7YL9G4OHPmDObNmweVSuXqptSK+Ph4AEBZWZmLW0I0dhxlsX8CIIFzHgmgB4Dz\nDtov0YjYunUrVq1ahawsq0ZN1ytu3LiBEydOAACqqqpc3BqisWO3sDPG/AE8AOBrAOCcV3LO8+3d\nL9H4uHXrFgAgMzPTtQ2pBb/++qv2/yTshKtxhMUeAiAXwDeMsWTG2FeMMR8H7JdoZNy+fRsAcOXK\nFRe3xHYkNwxAwk64HkcIuyeA+wGs5Jz3AlAC4A3DlRhjcxljiYyxxNzcXAcclnA3GqrFXl5ejl27\ndiEsLAwACTvhehwh7FcBXOWcH9P8vRlC6PXgnK/mnMdyzmNbtrRYTphohEjC3tAs9n379qG0tBRT\np04FQMJOuB67hZ1zfhNADmOsi2bRCACp9u6XaHw0VIt9+/bt8PHxwejRowEAlZWVLm4R0dhx1EQb\nCwBsYIwpAFwGMNtB+yUaCZWVlcjPFzH3hmSxc84RHx+PUaNGwdfXFwBZ7ITrcUi6I+f8lMbNEsM5\nn8I5v+eI/RKNBylw2r59e1y/fh3l5eUubpF1nDlzBjk5OZg4cSLkcjkAEnbC9dDIU6JeILlh4uLi\nAADZ2dmubI7VSNkwDz74IAk7UW8gYSfqBZLFLgl7Q3HHbN++HX379kWbNm2gUCgAkLATroeEnagX\nGFrsDSGAeuvWLRw/fhwTJkwAAK3FTsFTwtWQsBP1AknYe/bsCblc3iAs9u3bt4NzXkPYyWInXA0J\nO1EvuH37Npo2bQo/Pz906tSpQVjsGzduRHh4OHr27AmAhJ2oP5CwE/WCW7duoXXr1gCA4ODgem+x\nX716Ffv378eMGTPAGANAwk7UH0jYiXqBrrCHhITUe2H/73//C845pk+frl1GwVOivkDCTtQLbt++\njVatWgEQwp6bm4uSkhKXtunKlSt49dVXUVFRUeO7DRs2IC4uDuHh4dplFoOnSiWQmOiUthKELiTs\nRL3A0BUDOCEz5sIFYOZM4NQpq1bfvHkzPvzwQ3z88cd6y1NSUnD69Gk9ax2wwhXzySdAnz5AKlXc\nIJwLCTvhclQqFXJzc/VcMYAThH39emDdOqB3b+CFF4B75gdIS+6gd999V2+6uw0bNsDDwwN/+tOf\n9Nb38PAAYELYOQdWrRL///13O06CqDWVlcBXXwFGemDuBgm7K+EcSEoCtm0DvvgC+OtfgU8/dX2b\n6pi8vDyo1WqtK0ay2B3uZ09OBjp3Bp57Dli5Uvx/7VqTq2dmZqJ9+/ZQq9V45ZVXAABqtRobN27E\n6NGjte2VYIxBLpcbF/YDB4D0dIAxYPduR54VYS07dwJz5oiek5tDwu5KFi8W1uPkycD8+cA//gG8\n+CJw8qRr2vP110BoKHD5cp0eVhp1KlnsrVu3RpMmTRwv7KdOAXFx4uWZlITK0FBg9mxwndmPdLly\n5Qr69u2LN954A5s2bcL+/ftx8OBBZGdn13DDSJgU9tWrgYAA4Qravx+oBwHWe/fu4euvv4Zarba8\n8vXr4mW4YAFw6ZJ1B8jKAsaPF9s6ijt3ar/txYvi8/33gaIix7SnnkLC7iouXhQC88QTwIkTwLVr\nQF4e4OsLLF9e9+2prAT+9jcgM1O8aIqL6+zQ0uAkSdgZYwgODq7piikrA376SQjMu+8CixaJl6E1\nInn7thCYXr3E3z16YEG3bjgPoGr+fLFvHTjnyMzMRHBwMF577TUEBwdjwYIF+Pbbb+Hj44MpU6YY\nPYxCoagp7HfuiHY/+SQwYQJQUgIcO2Z0e6dSUaEVt6KiIowZMwbPPPOMdq7WGlRVAR99BPTrB7Rr\nV93T6dlTvKgs9e527gR27BA9UUfwv/8BrVoBhw/Xbvv0dEChEM/ZihWOaVN9hXNe5/969+7NGz1T\np3Lu68v5zZv6yxcu5NzTk/Nr1+q2PevWcQ5w/sornMtknE+bxrlaXSeH3rBhAwfAU1NTtcvGjRvH\ne/Xqpb/i22+LNkr/fH3F58svWz7Izp1i3b17Oeec3759m3t5efFh0r7++le91W/cuMEB8E8//ZRz\nzvmWLVs4AA6AT58+3eRhWrZsyefNm6e/8KOPxDHOnuU8L49zxsS51BWZmZwvXcp5q1acA7x8924+\nZMgQ7fmsXbvW+Hb/93+i3b17c/7uu5yfO8d5Tg7nI0eK5ePHc37jhunjLlok1pPJOE9Jsf88/vIX\nsb8nn6zd9kOHct6/P+cTJ3IeEMD5vXv2t6mOAZDIrdBYEnZXcPiwuPTvvFPzu4wM8eAvXVp37VGr\nOY+J4bxbN/F/SYjefbdODr98+XIOgOfl5WmXzZ8/nzdv3ly/jRERnA8ezPn165yXl4vlzz8v2vrT\nT+YP8t57Yr27dznnnP/jH//QCtv5++/nXKHgPC1Nu/qRI0c4AL59+3bN4dV81KhRHAD/7bffTB6m\nbdu2/Omnn9Zvd2SkEBSJ2FjOBw2ycFUcQHo655MmCWGVyTifNImrW7TgR1q35owx/u2333JPT0++\nZMmSmtuq1Zx37855nz41v1OpOF+xgvMmTcTL4vZt48cfN47z0FDO/f05nzDB/vMZNkz8ht7enBcU\n2L59u3bipZCcbPRl3hAgYa+vqNWcDxzIeZs2nBcVGV/noYc4DwzkvKTEscf+/nsh3tnZ+st//13c\nCmvWVLdxxgzxgtEIW204cOAAnzhxIq+qqjK73htvvME9PT25WqeH8P7773MAPD8/Xyw4cUK08auv\n9DcuL+e8b1/O/fz0hLkGjz3GeadOnHPOKyoqeJs2bfjo0aO5v78/f2PmTLH9mDHaXsrGjRs5AJ6i\nY2lmZWXxv//971ypVJo8TKdOnfiTuhblH3+Idn/zje4Ji15ZYaG5y2IfO3YIqzQgQBgJmZlcqVTy\nzd26cQ7w/2p6DF26dOFTp06tub10vb/4wvQxdu0S62zZYvz7kBBx3f/9b7He/v21P5/KSs6bNuW8\nXz+xr9Wrbdu+uFjfWJk2jfNmzTi/c6f2bXIBJOz1lV9+EZd91SrT6xw4YPmhqg2zZon99uih/1IZ\nPZrz++6rtoI557y0lPP77xeCZ8ois8CCBQs4AJ6RkWF2vdmzZ/O2bdvqLfvhhx84AH7q1Cmx4KWX\nhFWtsbj1yMwUL8KYGNFuY3TpwvnkyZxzzr/77jut5d2nTx8+atQoYYECnP/4I+ec83/+858cAC8y\n9fI1QXh4OH/88cerF8yYISxW3Zf07t3iWPHxNu3bKtRqIV6Mcd6zJ+dXrmi/2rBhA28F8CpPT86f\nfZZzzvmkSZN4t27dau5n/nxhkUsvVmMUF4vjGOt5lpZWu5xKSzlv315Y/7V170kvGsk46dfPtu1P\nnRLb//CD+DslRbTvjTdq1x4XUefCDsADQDKAeEvrNlphr6oS3fLISPF/U6jVQlQjI0W311GH79WL\nlwUFiW755Mli39IN/69/1dwgNVWs+8ortTresGHDOAC+a9cus+uNHz++hj/9xIkTHAD/+eefOVcq\nRQ9nyhTTO9mxQ5zHU0/V/E4SoLff5mq1mt9///08MjKSq1Qq/sQTT/BOnTqJ36NnT9FdLy/nc+fO\n5UFBQTafc7du3fjDDz8s/sjL49zLi/PnntNfqaxMiOZLL9m8f7OUlorYDcD59Ok1enyPPvoob9Om\nDVc/84w4/q1b/NVXX+UKhUK/F1JaKl5GM2ZYPmZYGOfS+epy+nS1EHPO+dq14u9Nm2p3bpK/PyeH\n8w8/FP8/d8767X/4QWyTnFy97PHHRS+gloaLK7BW2B2ZFbMQwHkH7q/hs24dMHIkMHiwSLPr3l2M\nfnzvPcDTzHSzjImMjwsXHDeYRa2GKiUFX+bloerDD4GtW4ElS0TWg48P8OyzNbfp2hWYMQP47LNa\npaylpKQAsJyPrjvqVEIapHTlyhWRHnjzpsggMsW4ccAbbwBr1gCa42o5c0aESHv2xKFDh5CUlISF\nCxdCJpOhc+fOyM7ORrlSKba/dg04dw5XrlzRtsEW5HJ5dUmBdetEJsqcOforNWkCDBoE7Nlj8/7N\nsnYtsGWL+E2/+w5o2lT7VVVVFRISEjB+/Hiwl18GysuBzz9HZGQkKisr9TOQtmwBCgqAp5+2fMyY\nGODs2ZrLL1wQn5GR4nPGDHH/L10qMrBs5dAhoGNHoH17sS9PT+Cbb6zfPi1NfOqUgMCLLwKlpcDB\ng7a3p57jEGFnjLUHMB7AV47YX61Rq0U9DieRn5+vFSuzlJQAs2aJnOXr10WKVWCgGBDz9tvApEmW\n9/Hoo8B99zku9TE7G15VVTjLOe4+/rjIm3//fWDDBuCZZ4DmzY1v97e/iWv6z3/adLjbt28jNzcX\nAHDZQl68MWEPDAyEr6+vEJyNG4FmzUSqoDleegmQyYBNm/SXSyUEevXCJ598gubNm+PPf/4zACAi\nIgKcc9HGmBix3rlz2lRHW9HmsavVwOefA/37i/RAQ0aMEIJ486bNxzDJb7+JcQiLFwvjQIeDBw+i\nsLBQ1I6PjAQmTgT+8x901ZzjRSnHG6gez/DAA5aP2b27SCM0SBfFhQuiDRER4m8PD+Cdd4CMDOCP\nP2w7L86FsA8cKP5u3VrcC+vW6ae6FhcDv/5qPA0zPR1o21akE0tER1e31c1wlMX+fwBeA2DFSAcn\n8u67QFAQsHmzU3a/ZMkS9OnTB/fMDUU/fx7o21fcdH/7m3h49+wRD93WrWKZwUNnFIUCmD1bWOyl\npfY3/tw58QEgv6BAjL4bOVI8cC+9ZHq70FBhua1eLQacWInuC9CcsHPO9QqASTDGEBISgquXLokc\n8KlTAW9v8wdt3RoYOhT44Qf9hzs5GWjeHFlqNbZs2YK5c+fCx8cHgBB2AEhLSxPWnFwOnpKCrKys\nWlvsVVVV4jdPTweef974iiNHis+9e20+hlEqKsS+xo41+nV8fDwUCgVGSsd9+WXgzh10T04GoCPs\nly8D+/YBTz0lXpKW6N5dvMTOG3TWL1wAOnXS6zVg2DDxaWsOf1aWMJAkYQdE+27fFnnygMhx79FD\nCH5CQs19pKUJw0oXX1+Rn6/7UnMT7BZ2xtgEALc552aHSzLG5jLGEhljiZIl53B27BBdyEceAebN\nq2lF2AHnHFu3bkV5eTl+/PFH4yvt3g3ExgK5uWJwxttvC+HUcPHiRaw1M4S9BlFR4tMBIzArkpIA\naIQ9Px+Qy4H4ePEAWrJM//IX8ZD/4x/m18vJAZYtA379FZc0D2+PHj3MCnthYSEqKipqWOyAKC3Q\nISVF/Kbm3DC6/OlP4iE+fbp62alTQK9e+HXHDqjVajzzzDParyRhT09PF9ekc2eUJyejsrLSPov9\nP/8BWrYEHn7Y+Iq9eolekqPKCxw6JHqKZoR92LBh8JUs1gceAGJj4btqFcIDAnBBslq/+Ub81jNn\nWnfc7t3F55kz+ssvXKh2w0gEBIhlx48b31dOjhgcd+NGzXMD9IV93DigTRtRiuPll4EhQ8RyT08h\n8oakp1f3HnSJjHRLi90RQdN/AbgKIBPATQClANab28YpwdPycpE1sWgR56+9JgIl0dG2BVjMcPLk\nSQ6Ay2QyPshYDrJKxXnXrpx37mxycNGjjz7KAfCrV69ad9CjR8V5bN1qR8sFtx98kF/V5G0nJCTY\nvoOFCzn38DCfUvjKK1x3AFGahwff360b7x4QYHKTixcvcgD8u+++q/Hdiy++yH/28ODqVq3MB5s5\n5/fu3eOvvvoqnzZkCFd7eFRnO1RViUDh4sV82bJlHAAv183+4WJQ0Zw5c8Qfjz7KS9u2tZivboqR\nI0fyh3r3FkFnY/nhukybxnmHDo4ZCPbaa5zL5UZTaKVrLA220qLJ0KpijB8JDBSD1Nq3F/nn1qJU\naq+vFpVKBCWNBYeffJLz1q2Nn7M0fuKFF/SXz58vUhMN00yl5xwQAeqiIpH6Oniw/np374p1Pvig\n5jGfe06khNbRYDx7QV0FTznnSzjn7TnnwQAeA7CXcz7D3v3aTHKyCMoMHgz8+9+iO3b7tkkLxlbi\n4+NxH4BPH3oIBw8erBkQ/Pln4Px53Jw/X/jyDKioqMBvv/0GANghdR8tIQV6MjLsaLmGc+dwTvNf\ns64kUyxZAnh5iV6IKY4cEW6o/fuxsmNH3A4IwMC0NBzNz0f5668Li9IAqZyAoSsGALq0aYOxKhXK\nJk40GWyuqqrCihUrEBYWhg8++AA/HTiA8oEDhZ+dc9HNLi8HevVCYWEhFAoFvLy89PYREREhXDEA\nEBWFJjduwBuotcU+4do18YexgLQuI0cKK9URFmNCggjI6vqQNfyqqYUzfvx4/S8mTwbOnMHO6Gi0\nz88XJQ+uXhVuDmvx8AC6ddMPoF69KtyHhhY7IJIIbt0S523IgQPic/VqEcSWOHRIlDXQ6f0CEBU6\nJ04U7sr//Eec+8CBokSHbgXH9HTxaeiKAUQb8/OFVrgR7lMr5uhR8amZ5R5jxgCvvy5uoLw8u3cf\nHx+PL1u2xPwtWzAAwPr166u/5BxYtgzXfX0RsXSpcHUYcODAARQVFUEmk2kfNIsEBgL+/vYLu1oN\nv2vXtMJurH0Wad1a+Iv/+1/jhZgqK8UkEoMHgz/wAF6/dw//fewx7FqxAtsANHn/ffFgrVghfOY7\ndgD79qFU4zKp4YrhHONSUtAEQIoU1DTg0qVLiIqKwsKFC9GrVy+89dZbAIC8kSOF+yoxUbzwAaBn\nTxQWFsLPz6/Gfjp37ixcMQDQrRsY54gE0KlTJ/PXZMUK4S7TCQZ6y2SYcueO8PVa2l4S2q1bza9n\nievXhSvEjBsmKirKeMyge3ekTJ+Ojmo1ihMShECaqINjku7d9YXdMCNGl759xaehn12lEtdx1Cjh\ns//Xv8TyggKxb103jESHDqIy6qhR1csGDRIvco3rEUB1RowxV0yXLvpttoXbt8XL0ZFFzhyEQ4Wd\nc76fc24hdcFJHD0q0qF0rWXph5Qe2lpy8+ZNJJ44gaGlpWCc43tvb2xau1ZyRQlrKTkZfykuRnFZ\nGX744Yca+9i6dSuaNm2KJ598Ert37zY6K08NGAPCwqyvpmeKzEx4KZXI11ybWgk7ADz0kHiJ7d9f\n87vkZGElDRiAnJwcFBUVITo6Gq3j4vA4gP3LlolA1cKFwu88fjwwfDjGLFiA9wC0Dgys3pdaDSxa\nhJCNG/EdgP+ZSI9bs2YNrly5gvj4eOzatQuDBg0CAFzr00f4yzdtEv51Ly8gMhIFBQVGhT0iIgLX\nr19HcXGxNq4x0N8f3qaCtSqVSJVbuFAE9kaMAL78EgAw+PZtBCqVpoOmunToIGIyv/xieV1zSCmx\nY8bU+KqgoAB//PGHyIYxQZcuXcABpDZvLgp9mUvFNUZMjMjukWJn5oQ9Jkb8HobCfuaMsJxnzhRJ\nA19+KSz/o0fFPWdM2I0hrSf55QEh7DKZSAQwRGpjbQKoP/8sXiw//WT7tk7GvSz2fv30lzlI2Hfs\n2IE+AHxKSoA5c9ChrAyzLl/GsWPHAM7B//EPXJfL8UeHDujSpQu+/fZbve0559i2bRvGjBmDhx9+\nGCUlJTggdTstERZmv8WuyYiR9+wJLy+v2rliACFCvr4ia8IQqeJe//7ajJjo6GiEah6mk15e4je6\ndEkENo8eBfbtQ+L99+N1AK2nTRMZGZWVIk/5k0+Al17CG23a4IyxPGkASUlJiIqKErnZjGlF+y7n\nwOjRIjsmKUlYlJ6eKCwshL+/f439SAHUS5cuAeHhqGIMfTVZMzUoLhYW7aefiqBddrYQ9rlzgRdf\nxIOXLyNTLq/OerHEQw8Jkbt2DZWVlTh69Gi1wWAtCQkikGikZ7Nz504olUqLwg4YpDzaghRAlX6n\nCxdEoNSIew0KhQgcGwZQpedhyBCR665Wi/Eehw4JUZZ64pZo3Vq4MHVz09PTRe/JwAUHQOTFe3vX\nzmKXMpqsfZbrEPcQ9hs3hOVkKOwhIeKmsFPY4+Pj8bifH7hMBrz3HiqffhqLARx8/33gwAGwI0ew\nrKoKyz74AE8//TQOHz5c7bMFkJycjKtXr2LSpEkYNmwYmjRpYr07JixMlNK1Iz+/RFOW1b9/fwQE\nBNTaYr+UlYW01q2hMpbJceSIeHjuuw/nNC+SqKgoBAQEoHnz5iIzRiYT5xMTIx7UoUPxdd++eKpZ\nM7D0dJHvPWSIcPf861/Axx8jpmdPnNbNcNHAOcfJkydx//33a5dJwl5YWCiyY3JyxEOnKdVrzhUD\nVGfGXPb0RDdjKal37ohskh07RI76hx8Kd1l8vBhQ9umn6JyXh+98fa1LFQSq3R7btuG7775D//79\n8dFHH1m3LSB6D7t2CTeMkTbHx8cjMDAQ/QyfDR3CwsLg4eHhWGGPjDSd1hsXJ+Yc0L2n9+8X90b7\n9iJLS7Laf/5ZpDE2a2Z9ewYNEi8E6QVpLNVRQiYT7hhbz12trhb2P/5wyQQ15nAPYZe6dYY3r5eX\ncM/YIezl5eX4/fffMVWhABswAAgMhGL5cuQ1bYopW7ei8s03cZsxXOjfH48++ihmzJgBmUyGdevW\nafexdetWyGQyTJgwAU2bNsXw4cPx66+/WmeZhYWJB8BYsMlKio8eRQ6Azn362CXsq1atwuqMDHik\npeGyblcXEMI+YAAAkcPerl07NNcMegoNDTWZ8njr1i0c79hRuExiYoQl9/XXYhQoY+jRowdSU1Nr\nTBB99epV3LlzB71799Yuk6zxgoIC4fv08hIPoGaAkClhlyakTk9Ph1KpxGmlEsHGJtL+/HPRzu3b\nxQAvCU9P4OOPgTVrkNq2Lb5v0sTMVTSga1fRs/zlF20v7tVXX8X3339v3faJicDdu0bdMCqVCjt2\n7MC4cePgaca9olAoEBoaWnthb91ajB8xFHZT9O0rgqsaAwBqtRDHoUOr13nzTbE8JcV6N4zEwIHi\nJZyWJgQ3Pd20sANC2G212FNSql/0ubk18/hdjHsI+9GjwqcqTaKgS0SEXcJ+4MAB+JWUoOOdO9XB\nrmbNcPnNNxGuVkNx+DA+4BwffPYZGGO47777MGbMGKxbt047M83WrVsxcOBABAUFARDZCRkZGXpW\nvUnCwsSnHe4Y2YULOAdhQTdv3rzWwp6amoqzLVoAAP41ejR27twpvsjJEf7Q/v0BCGGPlkb1QZQH\nMCfsrVq1Etb+gQM1sjJiYmJQVVVVQ3ROamaZMmmx+/mJXGfAorD7+Pigbdu2SEtLw7Vr13COcwQW\nFNQcGLZjh7A2H3zQ+AWaPRufTpqEXFt6V4wJd8zevTh94AAefPBBPPDAA5g5cyb2G4tlGJKQIPah\nG0DUcPz4ceTl5Zl1w0h06dKlOpfdVhirDqAWFIgetDlhl9wqkkF29qyYf1bKRQfE/SDdB7YKuybW\ngoMHRQZOUZHxwKlEZKToFZeXW38MqRzEO++ITyvdMbV+edqI+wh7r16iBochERHCr1vLrlJ8fDym\naGafh066WO/XXsMqb29kAih98kk9gZk5cyZycnKwb98+ZGVl4fTp05ikU0ZASjuzyh1jJuXx1q1b\n+N1SLRmVCv7XryNDoUC7du0QEBBQax/7+fPn0WLECKj8/DC2SRM8+OCD+Pjjj4W1DgD9+0OlUiE1\nNVVP2ENDQ5GZmWl0Crbbt29XZ8R4eIgyCjr06NEDAGq4Y5KSkiCTybTfA4Cvry8YY0LYARHgHDDA\noisGqM6MyczMxDkAjHN9Ky43V/QmTIm6BpNT45ljyhRAqURUdjZGjBiBX375BeHh4ZgyZYrlEhY7\ndwoLWPPC1UV6+T1gRWmALl26ID09HSqVyra2S3TvLixwyXI1J+yhoaK9kp9deoHpCjsgUmvnzrV4\nzWvQpYvY/6FD5lMddddXq21LUti7V2jLkCEiKcCCsJeWlmLx4sXo2rUrtm3bZv1xaknDF3alUuSt\nmvIhRkQIK6IWcyVyzhEfH48/t2ghMhh0xMrT0xOXFyxAH39//PX99/W2mzx5Mvz9/bF27Vrtjzh5\n8mTt9506dUJUVJR1wt6unXApGBH2jz/+GGPGjMF1c+lWV65AoVKhsGNHMMZq7YopLS1FZmYmIqOi\n4DF8OB7y98eUKVPw8ssv48aWLSIApRllWl5eXkPYKysrjbbTWJ0YXbp06QKFQmFU2Lt27YqmOkPW\npQBqQUGBWDBsmHi4Ndkt5oQ9IiIC6enpuHLlijYtVOsqAERJCM71Xu7GqJWwx8WhLCAAUwAMHDgQ\nzZs3x2+//QYfHx+MGzcOJcbcQoBwwRw7ZtQNAwjXkq+vL+4zeFkao0uXLqioqEB2drZtbZfo3l2M\nU9CM1TAr7IyJl5FksR84IOJhHTvqr3fffcCqVaL3ZQuMCSv/4EHzqY4StmbGKJWizSNGiGMNGSL+\nNmE8HjhwADExMVi+fDnmzZuHYVJpBSfS8IU9JUV0mc0JO2DUHZOdnY3PP/8cGzduxM6dO5GYmIgr\nV66goKAAnHOkpqbiemYmYu/dEw+0QTDo3XffxcXLl2sIU5MmTfDYY4/hp59+woYNG9C1a1dt5oXE\n+PHj8ceJd9UcAAAgAElEQVQff1Rbl6aQycRNb0TYJWsuPj7e5OZcs45MI7TmhL2kpARnTWSgXLx4\nEZxzdOvWDRg2DLIrV/Dt3/+OoKAgFCQkAJoUQ92MGAkpM8bQHVNWVoaioiKjg5MkPD09ERUVhTMG\nQ9YNA6cSfn5+Rq9pRUUFKisrzQp7bm4uTp06hQwAXC7XF/YdO0TmibGCXjrUSthlMiR36IBxAHp1\n7QoA6NixI1asWIGrV6+a/E2wY4ewNM0Ie3h4OJgVtYkiNeJWa1eBlJHzww8i5mAstVCXuDhxfQsL\nhSjq+tcdwaBB4pk/eFC4ac2NKZCseWtdUSdOCPfO8OHi7yFDRLqngcaoVCosWLAAQ4cOBecce/fu\nxeeff45mtgSCa0nDF3ZpYFIthP3vf/87nn/+eUyfPh1jx45Fnz59EBoaioCAAMjlcvTr1w9DAMgr\nKoxWFpTL5QjUzb/WYdasWSgrK8OxY8f03DAS48ePh1KpxK5duyyfo4lc9tTUVAAw27Ur0lyfAE1g\ns3nz5rh3757RwO3KlSvRu3dvo8J/XtPF7tq1q/aG9j1xAksXLUJoQQGudugAQLxsGGNiPQ3SwBhD\nYb+tGe1nzmIHhDtG12K/ceMGbt68qRc4lfD396+22HWQxN6cKwYAdu3ahdbt24N17gxori+USuHy\nePBBi9ku0mTWtqYsfl9ejmYAFDp1TiSxNVn2+PPPxf1t4t5PT0/Xnpcl7E55jIoShs+FC9piambp\n21dYuN9+K3oehm4Ye5H88j/+KJ4fw1Gruvj4iB65tecuZcNIlrfUdgN3TEJCAj777DPMmzcPZ86c\nqRNLXcI9hL1VK9OFrEJCxI9qRNhPnjyJYcOG4cKFCzh06BC2bt2KNWvW4MMPP8Trr7+O6dOn458D\nBgjfvY0/SlxcnPah0nXDSAwYMAABAQHWuWOkXHYdsSgtLUVWVha8vLywZ88ek931kuPHkQ2gS58+\nAITFrlQqUWqkYmR2djaqqqq0vlldUlNT4eHhIXoeUVGiwNW+fZjXpw8UAL7QWNQpKSkIDQ3VVk8E\nhPUpk8lqCLtUTsAaYb9165Z2fWOBUwlTFrslYZd6VKmpqaKUQFRUtcV+5IgYPGOFr1cul4NzbpOv\nuqSkBF9lZKBcodAbrCSVNDAq7CdPinY9/7zRl01VVRWuXLlSo6doipYtWyJAtxiYrfj4VFvp5tww\nEtIIVCm109HC3ru3cGGWlJj3r0vYUgxszx6RgqlJhkDnziIzyEDY9+/fDy8vLyxfvlzveagL3EPY\n+/UznTMrlwvRNxD28vJypKSkoF+/fujSpQsGDBiASZMmYfbs2Xj55ZexbNkyfLFyJWJv3RIWqm75\nUStgjOHVV1/FgAED0Fe6iXXw9PTE2LFjsWPHDsvWXViYuEF16llIrpHZs2ejvLwcu01UCfS4eFGb\nEQMIYQeMjz6VLOjExMQa350/fx7h4eFQKBTiWg8bBuzdC2/NkP3VZ89i//79NTJiAGHFdujQoYZA\nmasTo0uMppsvWe1JSUlgjKGnEbeIv7+/UWGXrHhTwh4aGqp1WYSEhIj6J1euCDffr78K94KRzBND\n5BpL1RZ3zPHjx1GmVuNuv36ivIDmpeDj44NWrVoZF/ZPPxViOmuW0X1euXIFKpXKamFnjKFLly72\nZW1I+ezWCHuLFuK+zsoSz2ct6vKYxcur+uVhjbBLKY+WnsWyMjEYb8SI6mUm/Oz79+9HXFwcmtiS\n/uogGraw370ruk9mBl8AMJrymJKSAqVSadTq05KWJixlCwEzUzzzzDM4dOgQPEx0AwcPHoxbt27h\nmm7BI2MYSXmU3DDPPvss/P39jbtjVCo0v3ULV7y90bJlSwDmhV0qp3xCM6BJl/Pnz+u5VzBsmEhN\nXL8e6tBQeN53H5YuXYq0tLQawg4Yz2W3xRUDQOtnP3nyJDp37mzUV6kXPNXBksXepEkTbW0YrcUu\nZcb8+qsoLmdFEK82wn5IMybAb+ZMkX2j444JCQnRn90IEOt8/70Yfm9kJC0Abe0ba4UdQN0KO1Cd\n9uhoa11CcsdYcw0iI4Xf3NLEJ4cPi9IZkn9dYsgQ8TxoXsIFBQVISkrCUEfHDqykYQu7lC5lrbDr\nvE2l7ryen/bCBTEwZu5cUc/kkUfE8loKuyUMLVGTGEl5PH/+PLrIZIj+/Xc8OHYstm/fXrP7f/ky\n5CoVinUCR9KgIWMpj5LQGgp7VVUV0tPT9YVdurHPnoVs4EAsXboUR44cgVKpNCrsxnLZd+/eDT8/\nP4tZGy1atEC7du30LHZj/nXAsivGWEkBCUkEtRY7ILI8UlKsvgdqK+xRUVHw/dOfRM9QZwaokJCQ\nmhb7V18JcTFTj0YaI2Gtjx0QPv3r16+jqKjI6m30iI0Vn5oXsVqtxhEpFdYYkkVtpfhVVVVh06ZN\n1ru5pHvURBE5PawtBrZ3r3DtGqaQGvjZDx06BLVaTcJuFSqVsNB//FFM/rB0qfAvSjeUKSIiRI0P\nTdcfEOLQvHnz6tKs2dnCCv3oIzGyMDVVWGgvv2y5Sl8t6a6xcAwzPmoQHCy6ewYW+4qmTeH5+ut4\ns6wMubm5OG5Qf0Otyabw0LmxLVnsHh4eyM7O1oo8IGqoKJVKkREjERFRXXCtf38888wzaN++PQCY\ntNhv3ryp9e1nZ2fjxx9/xJw5c4R7xwJSAPX27du4evWqyZ5WbYOn4pSEsAcHB4vzk8uFywOwWtil\nc7FW2FUqFQ4fPiwKmPn4iGkTN2/WTvkWHByM7OzsajFTKoGVK4UrQPf3MCA9PR0BAQFoYSS/3RTS\n/XhYqvtjKxMnCt+/xkW2bt06DBgwAPuM1RYCRP7+2LGWpzzUsGnTJjz22GNGi+wZZeRIUZfIkuEH\nWJ/yuGePeCEZ9ha7dRM+d42w79+/HwqFwmwpB2fSsIR9zhzxAzz6qCgQVFkpxN1S+pDUFdPJLJHS\n5RhjIuVqwgThTz11SoycS00VqVIffui00/H390dwcLBlYffyElF7HWG/lpKCYaWlQIsWiNq2DU8w\nhu3bt1dvU1iIio8/hhJAC2kkHkwLu1qtxp07dzBAkz2j62fXy4iRYKzaIurfH02aNMH777+Pnj17\nGrUSpZRHya3w2WefgXOOBQsWmD93DTExMTh//jyOarJ8TAm7n58fysrKagirNcIunV9YWJh2NiXc\nuiUC8JJFZwHJYjcsgWCKc+fOobCwEAMlt8Fjj4kxF5rMi5CQEFRVVVW767ZuFSN9LVy39PR0RERE\nWJXqKDFq1CgEBgbiG1smidaFMUDnd1mzZg0AmJ5xrFMn0SOSgpAWSNBMeWdYZM9se6yx1gExXsTH\nx7TFXlIi3DCJifr+dd1jPfCAnrDHxcXVrBB696517bGThiXsTz4ppu46eVJY4CkplqdrA2qkPFZW\nVuLs2bNCHJRKUTAqNVVYStJ0dHVETEyMZVcMoFflsbKyEj0zMiBXq0Xv4oEHsIYxXJa68JmZwMCB\n8DpyBPMBdNHp0Zhyxdy7dw8qlQpjxowBY0zPHSP58yMNfafPPANMm6YduPX4448jOTnZqAWum8te\nXFyM1atXY9q0aZZrnmvo0aMHlEolNmzYAADoZax8BKpdLYbuGGuE/amnnkJCQgI6SgNlJIvYyBgG\nU9jqipH861phHztW+M01tWKkVFGtO+azz4QgWrByJWG3BS8vL0yfPh0///wz8uycw+DSpUv43//+\nB4VCgZ9//tnoqGNbUKvV2LlzJ+RyOXbt2mU5LmUrjNUsBpaWBjz+uHjBN2smfPYqlensqCFDgMxM\nFCcn4+TJkzXdMFu3it63NSnOdtKwhH3oUJEFcP/9xssHmKJTJ5HVoBH2c+fOobKyEr3vv18MO09I\nEN1bK7IeHE1MTAwuXryIckt1KnRy2S9duoTH1GoUtmkjupmbN6PC3x8fXb6MmytXAnFxUGdn4/WY\nGHzNmJ4LRRI+Q4tdCpyGhoYiMjJST9jPnz+PTp061UzZGjJEvAytqN+tK+xr165FQUEBFi1aZHE7\nCSmA+ssvvyAsLEzb8zBEr16MDoWFhfD09DSbodC0aVOM0R3sI73kbRjSXhthb9OmTfUkGF5eonbM\nli1ARYW+sJ8+LYbfP/ec2bzs8vJyZGdn2+Rfl3j66adRWVmJjRs32rytLuvWrYNMJsO7776Lmzdv\nantatSUpKQl37tzBX/7yF6jVav2JbmqJUqnEN998U9270s2M+fZboTMJCSIo/Le/id/kyhVtTSQA\nuKtrgY8fD3h7w3PUKPQz9K+vWCF+165dtTEIZ9KwhL22eHqK7rRG2JM0s6sMzcgQgv7aa8LN4wJi\nYmKgVqu1VrFJwsJENkRRETIPHsQQAMWTJglLo2VLFHz3HfwBtHnuORTLZBgok+GzCxewcuVKvYCh\nXC6Hj49PDWGXfOotW7ZEnz59kJiYqE3DrJERUwuCgoLg4+ODS5cu4ZNPPkFcXBz66zwgloiIiICX\nl5d4IZsInALmhd3Pz88m1wQeeURknhhmQJjBVmE/ePAgBg4cqN+uP/1JuAc1vQfGGLIyMkRQPzBQ\n9JTMkJGRAc65zRY7IF6gvXv3xtdff217XXgNarUa3377LUaPHo1nn30WCoUCP9k5GUVCQgIYY5g/\nfz4GDRqEtboT3dSSP/74A0899VR1JdbISJF+OX26MCBjY4VX4KefhLA/9JBeWuaZM2cQFBSEzZs3\niwVhYcCRIyhWqXAAwKDjx4WFv2iRmJRl8mQxl4GF9F5HYLewM8Y6MMb2McZSGWPnGGMLHdEwh6OT\n8njy5EkENWuGVitXiqHH0jRcLsAwlc8kOimPii1bIAMQoJMV0WH8eCzu1AnfyeXodPMmKkJCcPLk\nSTxrZN5NY2UFJIu9VatW6NOnD27duoWrV69CrVbjwoULdgs7YwyhoaFYv349Ll26hMWLF9u0vaen\npzYoay5FVa90rw7m6sSYpFs3YO1a4xM0mMCW4Om1a9eQlZWlnflJy4gRIs/7+++hUCjQvn17dIuP\nF1lgK1cKcTdDbVIddXnqqadw+vRprQEkcffuXfznP/+xmJWyb98+ZGdnY9asWfDz88PIkSOxZcsW\nu4Q4ISEBsbGxaNmyJWbOnIkLFy4YTcu1hTua+lHamEKXLsJa37QJ+PvfRaC0XTuT2ycnJ4NzjsWL\nF1cPEOzRA4+GhuJgixZQLFkintv/+z8h7Js32zweprY4wmJXAniZc94NQD8AzzPGTIfrXYVOlcek\npCS8dt99YNeuAX/9q/WTIjiBsLAweHt725TyGH7sGE4pFGhqEBhq/9RTmKVSYd7SpTh69Kh+FosO\nUlkBXSRhb9myJWI1PvkTJ04gKysLZWVlJvdlC6Ghobh37x46duyIqVOn2ry99BK0x2J3NrZY7Mc0\nRbCkgLXOTkS67bZtQEkJRgQFYcrp08KSf/RRi/u1V9ifeOIJNGnSBF9//bV2WVlZGSZOnIgXXngB\ne6Uh9SZYu3Yt/P39tSOup02bhszMTJw6dcrsdhkZGejTpw8yDOoi3bt3D0eOHNG6yR555BF4e3tj\n7dq1tTi7aiTjRjsxzqhRwBNPiADoW2+ZL0MAzYxbAHJycvDee+8BAIqKivDH6dPYM2+eyLC7exdY\nvlyIu4X9ORK7FY1zfoNznqT5fxGA8wBMv+acyJdffolBgwYZH4UZEQGUlECZk4OUU6cw+9Yt0dWy\ndgozJ+Hh4YHo6GjrLfbt2xGcn4+j0t86LF26FDk5OVi2bJnZFEJjFrvkigkKCkLPnj3h6emJEydO\nGM+IqSWSn33BggVmJ34wxeDBg+Hj42NW2B1qsdcCW7JibmoGwwTrdO+1PPaYyNLasgXvZGbiLmNi\nomkrSEtL05YIqA0BAQGYNm0aNm7ciLKyMqhUKsyYMQNHjhwBYwwHdaedM6CwsBA//fQTHn/8cW08\nY9KkSfDw8LDojjl48CASExO1k5JL7NmzB2q1GmM1k3X7+/tj6tSp+O9//2s5NmUG6RlgjImXRGAg\nsGFDdT13C2RkZCA4OBjTp0/HBx98gMuXL+PQoUNQqVQYOmwYsHixKEXx0ku1bmNtcaipyhgLBtAL\nwDHzazqeqqoqvP322zh06BBGjRqFyZMna9+oALSZMdl79mBCRQWCCgqAJUusznZwJlJmjNmuqp8f\nEBQEvn49VABuGqmx7enpiba6k3mbwJQrpnnz5pDL5WjSpAm6d++OxMREre/fEcL+wAMPICIiAs9Y\n8BGb4sknn0ROTo42s8cYpix2UxNZOxpbLHbpNzA6aGrwYFG2dv58dLx3D8+o1ajw9bWqDbXJiDHk\nqaeeQkFBAbZs2YKXX34ZW7ZswUcffYSePXuaFfYffvgBZWVlmKVT6iAoKAhDhgzBli1bzB5TKhn8\n/fff61W0TEhIgL+/P+J05j2dOXMm8vPz9VN8bSQ/Px+enp548MEHsW7dOptr0V+6dAnh4eH497//\nDU9PTyxevBj79++HXC6vjh+5yBvgsKMyxnwB/ATgJc55jaF/jLG5jLFExlii1O13JNu3b8f169ex\nadMm/POf/8TevXvRrVs3vP3220IwNTf6jT/+wBIAFaGh1fNNupgePXogLy9Pa8GZJCwMTKXCbgDt\nLQ3KMoOxyTZu376tLTsAQBtATU1NRevWrU1WsbSFKVOmIC0trdaWpEwmMyvqgHlXjLlRp47CVmH3\n9vaGlzEfvoeHcLuUlCB98GDEA1bXSneEsA8dOhQhISFYuHAhPvnkEyxcuBCLFi3CoEGDcOzYMZPn\nt3btWnTt2rVGfaSpU6fi/Pnz2h6gMbKzsxEQEIBmzZpprXbOORISEjBq1Ci9Xt7w4cPRvn17u9wx\n+fn5CAgIwOzZs3Ht2jWT9ZZMIQl7u3bt8NZbb2Hr1q346quv0LdvX715AlyBQ4SdMSaHEPUNnHOj\nr2XO+WrOeSznPFZXQBzF559/jo4dO2LatGlYsmQJ0tLSMG3aNLzzzjsi6t2xI6BQoFN8PHoAkP/l\nLy71retidWkBjftlA2CXz9vY9Hi5ubl6xbhiY2ORn5+P3377zSHWel3h7e0NT09Pl7tirBV2sy+5\nF18Enn4at994A4CZ8r06FBcX4/r167VKddRFJpNh9uzZyMvLw9SpU7UTbA8aNAglJSVG79X09HQc\nOnQIs2bNqpF99NBDDwGAWas9KysLnTt3xiuvvIKtW7fi+PHjOHfuHK5du6Z1w0h4eHjgz3/+M3bu\n3IkbN27U6hzv3buH5s2bY8KECTYPzLp79y7u3bunnS/3pZdeQkREBPLy8lxWRkAXR2TFMABfAzjP\nOf/Y/ibZzsWLF7Fnzx48++yz2oJb9913H9avX4+hQ4fi+eefR1pGBhAaivZ37uCmlxdkM2a4oqlG\nsbq0QO/eKPP2xs+wzzUSEBCAgoICvUEjxix2QPiBG5KwS7MouSp4aktWjEVhDw0FvvoKHTX3hzXC\nLrkf7bXYAWDRokX44osvsH79eu1zJQ2kMuaO2aQZIDd9+vQa37Vt2xb9+/c3K+zZ2dno2LEjXnrp\nJQQFBeHNN9/UjjYdY2QykdmzZ0OlUmlHuNqKdP2lgVm//PKL1dNGSgHeMI2x5eXlhRUrVkAmk2Gc\nNNeuC3GEyToQwJ8BDGeMndL8s3GSQvv44osvIJfL8fTTT+st9/DwwPr167UzGik1wbv/9etneSKA\nOiQwMBDt27e3LOwLF+KVhx6CT+vWFl0S5ggICADnXK/YU25urp6wR0VFaYNfjsiIqUsM68VUVlai\nvLy83gVPLQq7hrZt20Iul1sl7PZmxOji6+uLZ599Vm9YfLt27RASEmJU2Ddv3owBAwagnYkUwalT\npyIpKQlZWVk1vuOca4W9WbNmWLJkCXbv3o3ly5cjOjpaW4dIl4iICIwcORKrVq2q1Vytutd/1qxZ\nqKiowPeaEb+WkF6gksUOAGPHjsXdu3erRxG7EEdkxRzknDPOeQznvKfm3w5HNM4aSkpK8M0332Da\ntGlGy7+2a9cO33zzDZKTk7Hh0iVcAVBZj6x1iR49elgWdg8PnMzIsFtoDcsKSHVidF0xcrlcW++8\nIVnsQM0Kj9ILrMG5YjR4eHigY8eONcv3GkESdl3BcTSDBg3CwYMH9YL9ly5dwunTp/Hwww+b3G7w\n4MEAjLsc8/LyUFZWpi0xMX/+fLRt2xbXr1+v4YbRZf78+cjJybFuwhoDdK9/r169EBMTY7U7RrLY\nQw2mAKyLOI411A8nsx18//33KCgowHPPPWdynYkTJ+LFF1/ErLQ0dAbQw0UV18whFbmqqKgwuQ7n\n3CGjQA0Lgd29exdqtRqGsQ/JHdPQhd2aOjGOwhnCDpgo32uEtLQ0tG3bFr5WZtDUhkGDBuHWrVt6\n+eZSKuO0adNMbif1ItJNzD8MQFunx9vbG3/9618BiGkkTTFp0iS0bdsWK1eutPEs9K8/YwyzZ8/G\niRMnLI8Ch3iRtW3b1uVBUlM0aGHnnOPzzz9HdHR0zdF7BkiVB5v4+tYsZlUPiImJgVKpNDs12Y0b\nN1BYWGi3xW4o7LqjTnV54YUX8P7771s1y319wtAV05iE3REZMZaQnjVdd8zmzZvRp0+f6gJqRggM\nDERgYKBRYZfcM7rbz507F4mJiWaDkZ6enpgzZw527txZo96/JaTgqYT0Utq5c6fFbaWMmPpKgxb2\nEydOICkpCfPnz7dYA8TLyws7d+7E3r17azU4xtlImTHm3DGOyimXxERyxejWidGlc+fOePXVV22r\nr1IPcKXFbm3wlHNus7Dn5uaiuLjY7Hp1IeyRkZEIDAzUCntWVhYSExPNumEkIiIi9MeXaDC02AFh\nRZsbjCYxZ84cyGQyrFq1ytpTQHl5OSoqKvSuf4cOHRAREWFxZC0gXDEk7E5i2bJl8PX1xQwrfeZS\nHZT6SOfOneHl5WVW2B01ClSyUixZ7A2V+mCxWwqeSjXjrfXJSlUezfnZ8/PzkZub63Rhl8lkGDhw\noFbYrXHDSISHh5t0xXh7e9s0MYhEu3btMGnSJKxZs8bqkajSvW/4Yh0+fDgOHDgApVJpctvi4mLc\nvHlTmxFTH2mwwr5161Zs27YNb731Vp08sM7G09MTUVFRZnPZz5w5g8DAQLRp08auY5lyxThjfIEr\naAg+dlPCYooaddmNIAmmvTns1jBo0CBcvHgRubm52Lx5M3r27GmV0EVERCAnJ6eGAGdnZ6NTp061\n7h3Onz8fd+7cqa60aAFzwl5UVKSdOtMYUmyBLHYHU1xcjAULFiA6Otqmmt71HUuTbiQlJVXP+mQH\nUvla6eaWXDG1sZbqI35+fqisrNQGoiXrvT6NPLVV2KV6MuaEXerR1YWwSyl9P/74I44cOWKVGwYQ\nws45r+EPz8rKMuuft8SIESMQHh5udRDV1PWX/Pnm3DEk7E7inXfeQU5ODlatWqV9kNyBXr16aef0\nNKSyshIpKSlmS9Zai0wmg5+fn9bHnpubi8DAQLe5loaFwNzBYm/VqhWaNm1qVtiPHj2KZs2aoYuV\n0/jZQ2xsLLy8vPD2228DgE3CDtTMjJFy2GuLTCbDvHnzcPjwYbNlCySke99wPEirVq3QvXt3s8Iu\nxQjIFeNATp8+jeXLl2POnDk1y502cKQiR1I5V11SU1NRWVnpEGEH9MsKGI46begY1ospLCyETCar\nk9Q0xhg8PT0dLuyMMQQHB5v1sR8+fBj9+vXTjhJ1Jl5eXujTpw9yc3MRFRVl9ctEsnJ1hb28vBy3\nbt2yS9gB4EHNTFe68/Wawtz1Hz58OA4ePGgy9fjSpUsICgqqNznrxmhQwq5WqzFv3jwEBgZq6x+7\nEz179oRCocDx48drfCdNemBqrk9b0a3waFgnpqFjzGK3efYkO5DL5RaDp7YKO2A+5bGwsBBnz56t\nU2NHSnu01loHhEHRokULPWGXeqjWzn9rivDwcCgUCqSkpFhc15Kwl5eXm5zOr75nxAANTNi//PJL\nHD16FB999JFDqg3WN7y8vNCzZ0+jFntycjJ8fX0ddkPpVnhsDBZ7XQbY5XK5wy12oFrYjZV3Pn78\nONRqdZ0K+4QJE+Dt7Y3HH3/cpu0MUx6N5bDXBrlcjsjISLuF/YEHHoBMJjPpjqnvOexAAxP2iooK\njB8/3ur0xoZIXFwcEhMTa9S+SEpKQq9evSBzUEVKXVeMYZ2Yho4k4oYWe11hi7Db0p0PCQlBYWGh\n0UJVhw8fBmNMr2a5sxk4cCCKiops9ulHREToWezGcthrS1RUFM6dO2dxvXv37qFJkyZGJzcPCAhA\n7969jQp7RUUFcnJy6rV/HWhgwv7iiy9i+/btDW7AjC307dsXJSUlejenSqXCqVOnHOaGAapdMSqV\nCnl5eW7piqnvFrspYTGFVAXUWAGuw4cPIzo6us79vrXx54eHhyMnJwdlZWUAhLAzxkwWD7OF6Oho\nZGVl6RW4M4alwWHDhw/H0aNHq+cy1SD1mMhidzDuLOqA8QBqWloaSktLHRY4BaqF3VSdmIaMq10x\nCoXCKmG3dcKRoUOHonnz5vjxxx/1lqvVahw5cqTBJBNImTFSymN2djbatGljfMIRG5EmPLdU78Ua\nYVcqlTVeosaqOtZHGpywuzvh4eEIDAzUC6AmJycDgMOFXZqUAXCfUadAw3HF2CrscrkcDz30ELZt\n26aXsZGamorCwsIGJ+ySO0YanOQIoqKiAMCin93S9R84cCDkcnkNdwwJO1ErGGPo27evnsWelJQE\nLy8vhxYvk/J3pYfLnSx2Ly8veHl5udQVY01WTG2mCHzkkUdQWFiI33//Xbvs8OHDANBghN0w5dHe\nwUm6hISEwNvb225h9/HxQb9+/WoIe0ZGBvz8/Or9YD4S9npIXFwczp07py34lJSUhJiYGIcOIJJu\nancUdkBY7ZLFXlBQUKe+Z2dZ7IAYYWnojjl8+DBatmxZ7wN6EgEBAQgKCkJ6erreBBuOQCaTWRVA\nNRq8gbEAABJvSURBVKzsaIzhw4cjKSlJL1gtZcTUd5cwCXs9JC4uDmq1GomJieCcIzk52aFuGKBa\n2NPS0gC4lysGEAHUwsJCKJVKlJaWuoUrRtr3lClTsHXrVq075vDhwxg4cGC9FxtdpJTH3NxcVFRU\nOEzYAeGOsddiB8SAJ7VajbFjx2rjAQ0h1RFw3GTWYxljFxljlxhjbzhin40ZqQLlsWPHkJmZifz8\nfIdmxAA1hb2+dy1tRSoEVpezJ0k4U9gBfXdMbm4u0tPTG4wbRkJKeZRSHR3lYwdEAPXGjRu4e/eu\n0e+tLZnct29fbN68GWlpaejVqxc2bNiAzMzMBtEzcsRk1h4A/gNgHIBuAB5njDWsSTLrGUFBQQgL\nC8Px48e1I04dbbHr+thbtGhRL2vU24NUurcu68RIWMqKsbUWuyG67pgjR44AaDj+dYnw8HBcvXpV\nO7GMoy12ACbdMaWlpVAqlVZd/2nTpuHUqVOIiorCjBkzoFQqG43F3hfAJc75Zc55JYDvAUx2wH4b\nNXFxcTh27BiSk5Ph4eGhzWF2FNJN7W6DkyQki90Vwm4peCrVYq+tsCsUCq07Zt++fZDL5VZNSFGf\nkDJj9u3bB8Cxwi6lPJpyx9g66rdTp044cOAAli5diqZNm9bpILDa4ghhbwcgR+fvq5plhB3ExcXh\n2rVr2L59O6KiomwayGINuje1uwq7qyx2S66Y2pQTMERyx6xevRq9e/d2+P3hbCRh37NnD3x8fCwG\nMm2hffv28PPzM2mxm6rsaA65XI5ly5ahuLhY2yOoz9RZ8JQxNpcxlsgYS5QmdiBMI1kFZ86ccbh/\nHRDpXJL7xd0Cp0B18NRdhX3EiBEICAhAaWlpg3PDANUpj1lZWXZNsGEMxpjZAKo917+hBKgdIezX\nAHTQ+bu9ZpkenPPVnPNYznmsO1qIjkaq9Ag43r8OiBtUurHd8feQXDFSymN9EnapTfYIu+SOARqe\nfx0QL17pvnOkG0YiOjoaKSkpRgumOeLFWt9xhLCfABDBGAthjCkAPAZgmwP226iRKj0CzhF2oPrG\ndleLXaVS4ebNmwDqV/DUUcIyb948dO/eXTvrT0NDcsc4S9jz8vK0s4PpQsJuBZxzJYAXAOwEcB7A\nD5xzy+XVCIv069cPMpkMPXr0cMr+3d1iB6prfden4GltKjsaIy4uDmfOnGmwqarOFHZzpQVq42Nv\naDjEx84538E578w5D+OcL3PEPglg6dKlSEhIQLNmzZyyf+nGdmdhz8nJAWMMvr6+dXbsuvCxuwPO\nttgB4ymPjnqx1mdo5Gk9pnXr1hg1apTT9u/urhhACHuzZs0cVsfeGkjYrUMSdmmibkfSqlUrBAUF\nGbXY8/Pz4ePj4zZz/BqDhL0R01hcMXXphgGsE3YvL68Gl6LoaCZPnoxVq1Y5JfhrLjPGnsFhDQUS\n9kaM5IpxZ4v9+vXrdS7s1gRP3V1YrMHLywtz58512uTb0dHROHfuXI3MmMZw/UnYGzE9evRAeHh4\ngw2+mUMSc5VKVS8tdncXlvpAVFQUCgsLtQF0CWsqOzZ0SNgbMU888QTS09OdZjG5El0xd4WwW8qK\nIWF3PqZKCzSG60/CTrglrhZ2tVoNtVpt9PvGICz1ARJ2gnAzPD090bRpUwCuEXYAJt0xjUFY6gPN\nmzdHu3btSNgJwp2QAqiuCJ4CJOz1Aam0gIRarUZBQYHbX38SdsJtkQS9Plns9tZiJ2wjOjoaqamp\nUKlUAICioiKo1WoKnhJEQ8XVwm4sgFpeXo7KykoS9joiOjoa5eXlyMjIANB4BoeRsBNui+SKqeuh\n4+Ys9sYiLPUFwwBqY7n+JOyE2+Jqi52E3fV069YNjDESdoJwF1wVPCVhrz80bdoUYWFhJOwE4S64\nymI3lxXTWISlPqGbGdMYSvYCJOyEG+NqV4yx4CkJe90THR2NtLQ0VFRUNJrrT8JOuC3kiiEAIewq\nlQoXLlzQXv+6vifqGhJ2wm0ZPXo0pk+fjrZt29bpcUnY6xe6mTH5+fnw8/Nzy/pIutgl7IyxDxhj\nFxhjZxhjPzPG6G4l6g3du3fH+vXr4enpWafHtSTsVIu9buncuTPkcjlSUlIaRWVHwH6LfReAaM55\nDIA0AEvsbxJBNGwsBU/JWq9b5HI5IiMjtRZ7Y7j+dgk75/x3zWTWAHAUQHv7m0QQDRtLFntjEJb6\nRnR0NM6ePdtorr8jfexPAfjNgfsjiAaJpawYd55Eub4SHR2NrKwsZGdnk7ADAGNsN2Msxci/yTrr\nvAlACWCDmf3MZYwlMsYSc3NzHdN6gqiHkMVe/5ACqJmZmY3i+luMKnHOR5r7njE2C8AEACO44eSC\n+vtZDWA1AMTGxppcjyAaOpaEPTg4uI5bREjCDrj/4CTA/qyYsQBeAzCJc17qmCYRRMOGgqf1j+Dg\nYPj4+ABoHKmm9vrYPwPQDMAuxtgpxtgXDmgTQTRoTFnsVIvddchkMkRFRQFoHMJuV4Iv5zzcUQ0h\nCHfBVPCUarG7lujoaBw/frxRXH8aeUoQDsaUxU6jTl2L5GdvDNefhJ0gHAwJe/0kLi4OANCpUycX\nt8T51O1Ya4JoBJgKnhYUFAAgYXcVAwYMwOXLlxESEuLqpjgdstgJwsGQxV5/aQyiDpCwE4TDkclk\nkMlkNYKnJOxEXUHCThBOQC6Xm3TFuHstcML1kLAThBMwJuxFRUUAgGbNmrmiSUQjgoSdIJyAOWH3\n9fV1RZOIRgQJO0E4AYVCYVTYfXx8IJPRY0c4F7rDCMIJyOXyGsHToqIicsMQdQIJO0E4AVOuGBJ2\noi4gYScIJ0DCTrgSEnaCcAIk7IQrIWEnCCdgKnhKwk7UBSTsBOEEyGInXAkJO0E4AcqKIVwJCTtB\nOAGy2AlX4hBhZ4y9zBjjjLEgR+yPIBo6hsKuVCpRVlZGwk7UCXYLO2OsA4DRALLtbw5BuAeGwdPi\n4mIAVCeGqBscYbEvB/AaAO6AfRGEW2BosVMBMKIusUvYGWOTAVzjnJ92UHsIwi0wDJ6SsBN1icWp\n8RhjuwG0MfLVmwCWQrhhLMIYmwtgLgB07NjRhiYSRMODLHbClVgUds75SGPLGWPdAYQAOM0YA4D2\nAJIYY3055zeN7Gc1gNUAEBsbS24bwq0hYSdcSa0ns+acnwXQSvqbMZYJIJZzfscB7SKIBg0JO+FK\nKI+dIJyAYVYMCTtRl9TaYjeEcx7sqH0RREOHgqeEKyGLnSCcALliCFdCwk4QTsCYsMtkMnh7e7uw\nVURjgYSdIJyAXC6HUqkE5yIBTKoTo8kgIwinQsJOEE5AoVAAEDViACoARtQtJOwE4QTkcjkAaN0x\nJOxEXULCThBOQBJ2KTOGhJ2oS0jYCcIJkMVOuBISdoJwAiTshCshYScIJyAFT0nYCVdAwk4QToAs\ndsKVkLAThBOg4CnhSkjYCcIJ6FrsFRUVqKqqImEn6gwSdoJwArrCTnViiLqGhJ0gnIBu8JSEnahr\nSNgJwgmQxU64EhJ2gnACusFTEnairnHYRBsEQVSja7FLhcBI2Im6wm6LnTG2gDF2gTF2jjH2viMa\nRRANHXLFEK7ELoudMTYMwGQAPTjnFYyxVpa2IYjGAAk74UrstdjnA3iPc14BAJzz2/Y3iSAaPpQV\nQ7gSe4W9M4DBjLFjjLEDjLE+jmgUQTR0yGInXIlFVwxjbDeANka+elOzfSCAfgD6APiBMRbKpfnA\n9PczF8BcAOjYsaM9bSaIeo9hVoxCodBa8QThbCwKO+d8pKnvGGPzAWzRCPlxxpgaQBCAXCP7WQ1g\nNQDExsbWEH6CcCcMLXay1om6xF5XzC8AhgEAY6wzAAWAO/Y2iiAaOiTshCuxN499DYA1jLEUAJUA\nZhpzwxBEY8MweErCTtQldgk757wSwAwHtYUg3Aay2AlXQiUFCMIJGAZPSdiJuoSEnSCcgIeHBwCy\n2AnXQMJOEE6AMQa5XE7CTrgEEnaCcBIKhYKEnXAJJOwE4STkcjkqKytRXFxMwk7UKSTsBOEk5HI5\nCgoKoFarSdiJOoWEnSCchFwux927dwFQnRiibiFhJwgnIZfLce/ePQAk7ETdQsJOEE5CoVCQxU64\nBBJ2gnAS5IohXAUJO0E4Cblcjry8PAAk7ETdQsJOEE5CLpfTRNaESyBhJwgnIdWLAUjYibqFhJ0g\nnAQJO+EqSNgJwknoToXn6+vrwpYQjQ0SdoJwEpLF3rRpU221R4KoC0jYCcJJSMJObhiirrFL2Blj\nPRljRxljpxhjiYyxvo5qGEE0dEjYCVdhr8X+PoB3OOc9AfxV8zdBECBhJ1yHvcLOAfhp/u8P4Lqd\n+yMIt0EKnpKwE3WNXZNZA3gJwE7G2IcQL4kB9jeJINwDstgJV2FR2BljuwG0MfLVmwBGAFjEOf+J\nMfYogK8BjDSxn7kA5gJAx44da91ggmgokLATrsKisHPOjQo1ADDG1gFYqPnzRwBfmdnPagCrASA2\nNpbb1kyCaHiQsBOuwl4f+3UAQzT/Hw4g3c79EYTbQMJOuAp7fexzAHzCGPMEUA6Nq4UgCAqeEq7D\nLmHnnB8E0NtBbSEIt4IsdsJV0MhTgnASJOyEqyBhJwgnQcJOuAoSdoJwEiTshKsgYScIJ0HCTrgK\nEnaCcBKUFUO4ChJ2gnASJOyEqyBhJwgnMW7cOLz55psICwtzdVOIRgbjvO5H98fGxvLExMQ6Py5B\nEERDhjF2knMea2k9stgJgiDcDBJ2giAIN4OEnSAIws0gYScIgnAzSNgJgiDcDBJ2giAIN4OEnSAI\nws0gYScIgnAzXDJAiTGWCyCrlpsHAbjjwOY4GmqffVD77IPaZz/1uY2dOOctLa3kEmG3B8ZYojUj\nr1wFtc8+qH32Qe2zn4bQRkuQK4YgCMLNIGEnCIJwMxqisK92dQMsQO2zD2qffVD77KchtNEsDc7H\nThAEQZinIVrsBEEQhBkalLAzxsYyxi4yxi4xxt6oB+1Zwxi7zRhL0VkWyBjbxRhL13w2d2H7OjDG\n9jHGUhlj5xhjC+tTGxljTRhjxxljpzXte0ezPIQxdkzzO29ijClc0T6ddnowxpIZY/H1rX2Msf9v\n32xCrCrDOP7701TUFE5lyNAEUyTKLHJUMCWJMgqVcNUiaeFCaOMiIYiGoH2b0kW0KWoTBtmXuOhr\natXCUptqapo+aMARdSISoSCy/i3e99LhIuHVxXnu5fnBy33f572LH+e597nnPOfcBUlfS5qRdLTG\nQuS3uoxIOijpO0lzkjZF8ZO0qh63zjgnaW8Uv8uhbwq7pCuAF4BtwASwU9JEu1a8Cmztij0FTNte\nCUzXdVucB56wPQFsBPbUYxbF8U9gi+01wCSwVdJG4Fngedt3AL8Bu1vy6/A4MNdYR/O7z/Zk4xG9\nKPkF2A+8Z3s1sIZyHEP42Z6vx20SWA/8Abwdxe+ysN0XA9gEvN9YTwFTAbzGgdnGeh4YrfNRYL5t\nx4bbu8ADER2Ba4HjwF2UP4cMXSjvLXiNUb7cW4DDgIL5LQDLu2Ih8gssA36m3suL5tfl9CDwaVS/\nXkffnLEDtwAnGuvFGovGCtun6vw0sKJNmQ6SxoG1wBECOdY2xwywBHwI/ASctX2+vqXtPO8DngT+\nqeubiOVn4ANJxyQ9VmNR8nsb8AvwSm1lvSRpOJBfk0eAA3Ue0a8n+qmw9x0uP/mtP3Yk6TrgTWCv\n7XPNvbYdbf/tcik8BmwAVrfl0o2kh4Al28fadvkfNtteR2lR7pF0T3Oz5fwOAeuAF22vBX6nq63R\n9ucPoN4j2QG80b0Xwe9S6KfCfhK4tbEeq7FonJE0ClBfl9qUkXQlpai/ZvutGg7lCGD7LPAJpbUx\nImmobrWZ57uBHZIWgNcp7Zj9xPHD9sn6ukTpD28gTn4XgUXbR+r6IKXQR/HrsA04bvtMXUfz65l+\nKuyfAyvrEwlXUS6dDrXsdCEOAbvqfBelr90KkgS8DMzZfq6xFcJR0s2SRur8Gkr/f45S4B9u28/2\nlO0x2+OUz9vHth+N4idpWNL1nTmlTzxLkPzaPg2ckLSqhu4HviWIX4Od/NeGgXh+vdN2k7/HGxzb\nge8pfdinA/gcAE4Bf1HOTnZTerDTwA/AR8CNLfptplxGfgXM1LE9iiNwJ/BF9ZsFnqnx24HPgB8p\nl8dXB8j1vcDhSH7V48s6vul8J6Lkt7pMAkdrjt8BbgjmNwz8CixrxML4XerIf54mSZIMGP3UikmS\nJEkugizsSZIkA0YW9iRJkgEjC3uSJMmAkYU9SZJkwMjCniRJMmBkYU+SJBkwsrAnSZIMGP8Cz9Ah\npjxgNKUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xca30ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.69658335948 \n",
      "Fixed scheme MAE:  1.85468553331\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.9014  Test loss = 1.7128  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.8983  Test loss = 1.2725  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.8832  Test loss = 1.9337  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.8933  Test loss = 1.8845  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.7946  Test loss = 0.1809  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.7560  Test loss = 0.6709  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.7327  Test loss = 0.3092  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.7332  Test loss = 0.2683  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.6778  Test loss = 0.5008  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.6764  Test loss = 0.0316  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.6315  Test loss = 0.0617  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.6274  Test loss = 0.8613  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.5965  Test loss = 0.1302  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.5965  Test loss = 1.6233  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.5982  Test loss = 2.8216  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.6332  Test loss = 4.0896  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.6840  Test loss = 0.4660  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.6817  Test loss = 0.4917  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.6599  Test loss = 0.2436  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.4590  Test loss = 0.1315  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.4347  Test loss = 0.4118  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.4311  Test loss = 4.4199  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.5095  Test loss = 0.8979  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.4941  Test loss = 2.4176  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.5127  Test loss = 0.0198  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.5095  Test loss = 0.5979  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.5096  Test loss = 0.7615  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.5098  Test loss = 1.0242  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.4958  Test loss = 0.9681  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.4811  Test loss = 0.1411  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.4594  Test loss = 3.3054  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.4832  Test loss = 0.9181  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.4719  Test loss = 1.7628  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.4861  Test loss = 0.0071  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.4267  Test loss = 0.2602  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.4256  Test loss = 4.8728  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.4419  Test loss = 0.1230  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.3840  Test loss = 0.9768  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.3883  Test loss = 1.3261  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.3980  Test loss = 2.5905  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.4098  Test loss = 1.4255  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.4206  Test loss = 2.5285  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.4543  Test loss = 3.4514  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.5160  Test loss = 12.3668  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.1452  Test loss = 6.2798  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2819  Test loss = 1.0802  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2845  Test loss = 0.8629  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2864  Test loss = 0.9411  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.2328  Test loss = 1.4072  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.2378  Test loss = 2.7651  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.2607  Test loss = 1.7359  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.2678  Test loss = 0.2673  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.2340  Test loss = 0.9709  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.2372  Test loss = 1.1592  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.2400  Test loss = 0.8716  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.2419  Test loss = 1.1834  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.2329  Test loss = 0.7545  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.2336  Test loss = 1.9310  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.2462  Test loss = 0.5033  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.2465  Test loss = 0.6368  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.2408  Test loss = 1.1479  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.2445  Test loss = 2.9052  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.2731  Test loss = 1.2948  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.2666  Test loss = 1.3561  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.2595  Test loss = 0.4550  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.2593  Test loss = 1.4507  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.2592  Test loss = 1.6978  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.2661  Test loss = 3.1584  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.2875  Test loss = 6.0568  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.4045  Test loss = 0.5527  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.4053  Test loss = 0.6297  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.4036  Test loss = 1.8169  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.4036  Test loss = 2.0297  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.4153  Test loss = 0.1364  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.4113  Test loss = 0.3490  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.4079  Test loss = 0.8945  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.3519  Test loss = 1.1279  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXlclPX2xz/fgWERRERcckGQRRNSTBRTMzMzNXezLG3x\nmqalqf3K0rLde9vL7rUyLbXUMs1y62ppLtctRdxQFNAE3HFjURZhzu+P7zzDzDAbzAwzDOf9evFS\nnvXMwzOf5zznnO/5CiICwzAM4zmoXG0AwzAM41hY2BmGYTwMFnaGYRgPg4WdYRjGw2BhZxiG8TBY\n2BmGYTwMFnaGYRgPg4WdYRjGw2BhZxiG8TC8XXHS0NBQCg8Pd8WpGYZhaiz79++/TEQNrW3nEmEP\nDw9HUlKSK07NMAxTYxFCZNqyHYdiGIZhPAwWdoZhGA+DhZ1hGMbDYGFnGIbxMFjYGYZhPAwWdoZh\nGA+DhZ1hGMbDYGFnGAeRm5uLxYsXu9oMhmFhZxhHMWfOHDz11FM4c+aMq01hajkOEXYhRLAQYqUQ\n4rgQIlUIcZcjjsvULg4fPowJEyagrKzM1aZUiXXr1gEACgsLXWwJU9txlMc+B8AGImoDoD2AVAcd\nl6lFrF69GvPmzUNmpk2jpt2K8+fPY9++fQCAW7duudgaprZjt7ALIeoB6AHgGwAgohIium7vcZna\nx8WLFwEAp0+fdq0hVWD9+vW6/7OwM67GER57BIAcAAuFEAeEEAuEEAEOOC5Ty7h06RIA4O+//3ax\nJZVHCcMALOyM63GEsHsDuBPAl0TUAcANAK8YbySEGC+ESBJCJOXk5DjgtIynUVM99qKiIvzxxx+I\njIwEwMLOuB5HCPsZAGeI6C/t7yshhd4AIvqaiBKIKKFhQ6vthJlaiCLsNc1j37JlC27evIlhw4YB\nYGFnXI/dwk5EFwBkCyFaaxfdB+CYvcdlah811WNfu3YtAgIC0KdPHwBASUmJiy1iajuOmmhjMoCl\nQggfAKcAjHHQcZlaQklJCa5flzn3muSxExHWrVuH+++/H4GBgQDYY2dcj0PKHYnooDbM0o6IhhDR\nNUccl6k9KInT5s2b49y5cygqKnKxRbZx+PBhZGdnY+DAgVCr1QBY2BnXwyNPGbdACcMkJiYCALKy\nslxpjs0o1TD9+/dnYWfcBhZ2xi1QPHZF2GtKOGbt2rXo3LkzmjRpAh8fHwAs7IzrYWFn3AJjj70m\nJFAvXryIvXv3YsCAAQCg89g5ecq4GhZ2xi1QhD0+Ph5qtbpGeOxr164FEVUQdvbYGVfDws64BZcu\nXUKdOnUQFBSEli1b1giPfdmyZYiKikJ8fDwAFnbGfWBhZ9yCixcvonHjxgCA8PBwt/fYz5w5g61b\nt2L06NEQQgBgYWfcBxZ2xi3QF/aIiAi3F/YffvgBRIRRo0bplnHylHEXWNgZt+DSpUto1KgRACns\nOTk5uHHjhktt+vvvv/HSSy+huLi4wrqlS5ciMTERUVFRumWcPGXcBRZ2xi0wDsUArq+MWblyJT76\n6CN88sknBstTUlJw6NAhA28d4FAM4z6wsDMup6ysDDk5OQahGMD1wq6Eg959912D6e6WLl0KLy8v\nPPLIIwbbe3l5AWBhZ1wPCzvjcq5cuQKNRqMLxSgeu6vj7KdPn0bz5s2h0Wjw4osvAgA0Gg2WLVuG\nPn366OxVEEJArVazsDMuh4WdcTnKqFPFY2/cuDH8/PycLuwXLlzA3LlzQUQm1//999/o3LkzXnnl\nFSxfvhxbt27Fjh07kJWVVSEMo1CThP3atWv45ptvoNFoXG0K42BY2BmXowxOUoRdCIHw8HCnh2Je\ne+01TJo0CRkZGRXWERFOnz6N8PBwTJ8+HeHh4Zg8eTIWL16MgIAADBkyxOQxfXx8aoSw5+fn44EH\nHsDTTz+tm6uV8RxY2F0JEVBa6morXI4i7PqhDWeXPObk5GDJkiUAgPT0dJM2FRUVISIiAv7+/vjk\nk0+QkpKCb7/9FkOGDEFAgOnZH9VqtdtXxRQWFmLgwIE6QT9+/LiLLWIcDQu7K/nXv4AWLYBaPlWg\ncSgGgNM99nnz5unKGNPS0iqsV86txPuHDBmC+++/HwAwevRos8d191BMSUkJRowYge3bt2Px4sXw\n9vbGiRMnXG0W42BY2F1FURHw6afAhQvAyy+72hqnsH37dgwaNAilVt5KLl68CG9vb9SvX1+3LCIi\nAteuXUNubq7D7SopKcHcuXPRp08f1KtXz6THrrwtKBU6QggsWLAAb7/9tk7gTeHOwl5WVoYnnngC\n69evx5dffoknnngCkZGRLOweCAu7q1i2DLh8Gbj3XmDhQmDHDldb5HBWrlyJtWvXWu2tfvHiRTRq\n1Eg3NB9wbi37Tz/9hAsXLmDatGmIiYkxKezKeVu2bKlbFhYWhlmzZunKGk3hzsK+fPlyLF++HO+9\n9x6eeeYZAEDr1q05FOOBOEzYhRBeQogDQoh1jjqmx0IEfPYZ0K4dsHYtEBYGTJwIOFkQrl69ii1b\ntjj1HPqkpKQAAE6dOmVxu0uXLhmEYYByT9nRcXYiwqeffoo2bdqgT58+iI6ONhuKCQ0N1U13Zyvu\nnDxdvXo1mjRpgpdeekm3rHXr1sjIyEBZWZkLLWMcjSM99ikAUh14PM9l61bgyBFgyhQgIAD4/HMg\nJUX+60Q+/vhj9OnTx+QQeWegCLs1cdYfdargLGHfuXMnkpOTMWXKFKhUKsTExCArK6vCVHx///23\nzobK4K7J01u3bmHDhg148MEHoVKVf+3btGmDkpISlw8GYxyLQ4RdCNEcwIMAFjjieFVGo3Fqlcn1\n69d1YmUXc+YAoaHAY4/J3wcNAgYMAN54A8jOtv/4Zjh06BBKS0t1k0Y7k0uXLiFHmxS25rGbEvaQ\nkBAEBgY6XHDmzJmD+vXr4/HHHwcAREdHg4gq2KiUOlYWdw3F7NixA3l5ebre8QqtW7cGAI6zexiO\n8tg/AzAdgGtHOrz7rhTMlSudcvgZM2agU6dOuHbNjrm6T54E1qwBJkwA/PzkMiGkt67RyJBMQYFj\nDDZCeShZFPbcXCAtDfjf/4Cffwb++MOucwGWhZ2IDBqAKQghHF7ymJmZiVWrVmH8+PG6csXo6GgA\nhpUxGo0GmZmZVfbY3VHY161bBx8fH/Tu3dtgOQu7Z2K3sAshBgC4RET7rWw3XgiRJIRIynFWed9v\nv0lhGjFCCmdhocMOTURYvXo1ioqKsGLFiiod48SJEzj67LOAl5cUcH0iIoB//hNYvx6IigK+/NKh\nMff8/HxkZmYCMCHsRMCff8pEbnAw0Lo10KMH8NBDQJ8+wK5dlT6fIuzt27e3KOx5eXkoLi6u4LED\nJkoeb90CkpOlvVVg/fr10Gg0ePrpp3XLFGFPT08Hrl0Ddu3C+fPnUVJS4lEe+7p163DvvfdWyBmE\nhoYiJCSEE6gehiM89m4ABgkhTgP4EUAvIcQS442I6GsiSiCihIYNGzrgtEYUFwMHDgDTpgHTpwPz\n5gGdOwPHjjnk8AcOHMD58+ehUqnw/fffm96ICMjPNys8/5wxA81//x03BwwAmjatuMHUqcDu3UBM\nDPDss0DbtlLoHcAx7XUIBFCQnQ1cvQpcuQJs3AjcfTdw333SU3/7bWDJEuD334F9+6SdU6fKt4lK\nkJKSgtDQUHTp0sWi12086lQfxWPXDfn/+GOgY0fg4YdlRZEe169fx/Tp09GnTx+zMe46R45gDYCW\nBw/q/kbBwcFoGBqKoA0bgNtvB7p1w7mdO3XnryzumDxNS0tDWlpahTCMQuvWrdlj9zSIyGE/AHoC\nWGdtu44dO5LD2b2bCCBatUr+vmEDUaNGRC1aOOTwb731FgkhaNq0aQSATp06VWGbkhdflDZ4exM1\nbkwUG0uUmEjUoQOVtW1L2UIQAfTLjBmWT6bREK1bR9SmDZGvL1FRkd32L1iwgMZLOav406IF0dy5\nRIWFFXf87ju5zeLFlTrfXXfdRffccw998MEHBICuX79ucrvt27cTANq4cWOFdZ9++ikBoAsXLsgF\nCQnyuqrV8t81a6ikpITmzJlDISEhBIAAUGZmZsUTaTSU3aRJ+Wdu357o55+JMjPpf/Xry2WRkUQA\n/e/ZZwkApaamVuozExH169ePEhISKr2fM/nkk0/M3rNERGPGjKEmTZpUs1VMVQCQRDZosefUse/Z\nI//VznKPBx6QA3+ys6Vnaifr1q1Dly5dMHXqVADQDUfXcfo08Mkn2KxSoej554HBg2VIo149oFkz\n5ISEYDsRXhMCi6y9RQgBPPggMGuWfBM5edJu+1NSUjAYQCaAnSNGyATunDnADz8AGRnyDUGJ+esz\napR885kxw+bYPxEhJSUFcXFxaNWqFQDz1S2mRp0q3HHHHQCAI0eOAGfPAklJspJo3z6gcWNg0CD8\n1qAB/jtlCu5q1w6zZs0CIMM7Ffj5ZzS/cAFTAwOBxYuBmzeB4cOB8HB0ysvD20FBsjLJzw9eBw8C\nMKxhtxV3DMWsW7cOsbGxZt9AWrdujQsXLjhlMBjjGhwq7ES0lYhMv+85mz17ZD24fohDGz+FiQEo\nleHChQvYt28fBgwYgLCwMPTs2RPfffedQVfAi+PHo1SjwZMaDb5r3VqGgn7+WYY61q7F2+3aYVyd\nOjj75JPYtGmTbSWHMTHyXwe8Jh87fBg9VCr8BuB/d94JPP+8/Bk5EtBO6WYSlUrW3J87B7z/vk3n\nys7ORn5+PuLi4nRiYi7ObikU065dOwCymgdr1siFgwcD7dsDe/di61134YH8fPwXwNqdOzF19WpM\nBZBnnNwuLQVeew1n6tXD+oYNgSeekCG6JUuAyZPxzdSpeCMvDwWlpUB8PBqcPIkmTZrA39/fps+r\nTwVhLyysck7AEeTm5mL79u1mwzBALUug1pKyTs/y2Lt0MVzmIGH/7bffAACPBgcDTzyBMQ89hIyM\nDPz1118AgLKkJDT+4w98ExSEwNatsXjxYoP9iQhr1qzBAw88gIceegg3btzAtm3brJ9YEXYTA2gq\nizh0CIEaDXZ5e1e+queuu2Rp5kcfAdoErCWUxKktHvvFixchhEBoaGiFdQ0bNsRtt92Gw4cPA6tX\ny6Ty7bfLlb6+eC8oCD3vuAP4/XeIadPgW1SETwE0f+89QzFdvBg4cQKLo6NRNzhYLvP2lm8jc+ag\nofYtLyMjA+jUCS0uX0ZkFRKngJGw//ADUKeOHKsQEwP06gU895zMb5igpKQEe/bsMdtGuCps3LgR\npaWlpoX98mVg0SJ03bYNnwBoOHUq8OijZu2r8WzZIosU1q51tSVOxzOE/fx5KTjGwt6qlfQ47RT2\ndevWoUWLFgifPx/4/ns8tnQpGvj66pKo5594ApcBNP3sM4wdOxa7du0yKJ87cOAAzpw5g0GDBuHe\ne++Fn58f1tuSFA0KApo0sdtjv3LlCmK14ahDwcFVq2N/7z1oABzp3990qEOPo0ePAgBiY2MRHByM\n+vXrm/XYL126hAYNGsDb29vk+vbt2yMjOVlW7QweLMNUkA/L/fv3o21CAnD//cD77yPzl1/wLwBh\nv/0GzJwpD1BUBLz5JpCYiN/9/REUFFThHDHaB2h6ejrQqRP8y8pwV0iI9WtiAl3yVKORiWglEX7n\nnUBJCTB/PtC9u8kH5Pfff4+77roLH3/8cZXObYp169YhJCQEXfS/G2lpsiorLAwYMwaNPvsMYwEE\nHT8OrFghiw9cQXY2MHSofDt0Boqgz57t0reoasGWQLyjfxyePP3lF5n82rWr4rqICKKRI6t86MLC\nQgoICKB/PvSQPMeQIUQqFR1t2JCa169P15YvJwJoTkQEaTQaOnfuHKlUKnr11Vd1x3j99ddJpVJR\nTk4OERH179+fIiMjSaPRWDfgnnuIunWrsv1ERNu2baPVABU0a0atW7emhx9+uErH+aNLFyKAHoiM\npLS0tIobnD9P9MEHtDI+nj6qW5do1iyiefMo4c47qW/fviaPOXToUIqNjTV7zpdffpke9fKS1377\ndt3yrKwsAkD/+c9/dMvOnDlDAOhojx5y+3/9i+jjj+X///yT4uPjaeDAgRXOUVBQQABo9uzZdOvw\nYSKAVgwYUIkrU87YsWOpWbNmRL/+Ks+7bJnhBlu2ENWrR3TbbUQHDhisevzxx3UJ4B9++KFK59en\ntLSUGjRoQKNGjZILzpwhGjyYSAgiHx+isWOlDTdvUnR0ND300ENE06dLu7dssfv8lebtt+W5FXsd\nTdu2RH5+rvt8DgA2Jk89Q9hffllWSpiq6ujTh8iO823YsIEA0N8DBsib4to1oqVLSaNS0SaATvj7\n00mAknfv1u3Tr18/atGiBZWVlRERUfv27enuu+/WrZ87dy4BoOPHj1s3YNw4otDQKttPRPTFv/9N\nVwHKf/RR6tKlC/Xp06dKx3m8Vy8qBehDf38KDg6mDRs2GG7w9NMmq27WRkdTTHS0yWN27dqV7r33\nXrPnXLp0KS0B6FZwMNGtW7rlv/zyCwGgXXoP87y8PAJAH77/PtFjj8nz+/vLe4CIWrVqVS5yRjRt\n2pSefPJJOn3qFOUBlNKzp62XxYAJEyZQw9BQWQ0VEWFgs46UFKLmzYnq1iX6/Xfd4oiICOrfvz/1\n6NGDfHx8aIud4rNr167yh0RODtHttxMFBsoHrlJppGXAgAEUFxdHdOOGtDsmxvT3qTLk5MgHRW6u\nbdt37EikUsm/286d1rffu5fopZfkd9Ia2dnyuO+8IyuqHnjANpscjE3feQvULmG/5x6izp1Nr3vu\nOaKgIFlCWAUmTZpEwX5+pAkOlmKhpXThQirTCtc8IxH48ccfCQBt2rSJTp8+LcXmww9165VlH3/8\nsXUDPvpI/pmuXKmw6sKFCybLBI2ZPWIEEUCa776jvn37UqdOnayf1wQRERF0sEkTKmnWjNrfcQep\nVKryz3D9OlGdOlQ2ZgwF+vrSiy+8IK/55MlEAM3w8tI96PSJioqikRbeqFIOHKCrAGV0726wfNas\nWaRSqejGjRu6ZRqNhoQQNGvWLKKSEqIBA6RQJCUREVFoaChNnDjR5Hl69uxJXbt2pa1bt9IWgK63\nbl3Zy0NERJMnT6b+gYHybzZ3rvkNz5whatdOOiSpqXTu3DndPXH16lVq27Yt1atXj44cOVIlO4iI\n/v3vfxMAOnf8uCwV9fMj2rrV5Lb/93//R76+vlRaWiofNoB8ANjDe+/J4zz5pPVts7LKz9msmbTX\nxP2i23b06HLn4ZlnrB//22/ltocOyTc5gCg5uVIfxx5u3LhB06ZNIyEErV69usrHqT3CfusWUZ06\nRM8/b3r9Z5/Jj3nxYqUPrdFoKDw8nD648055jE2bDNYvGTiQvvLxoQvnzhksLywspHr16tHo0aPp\n888/JwAVQhexsbHUq1cv60asXSvPrfdGoDB9+nQCQGfPnrV4iDmtWsljZGXRyJEjKdqM92yJGzdu\nkBCCfh4+nAigm7/9RsOGDSMAtGfPHqL//IcIoMxVqwgALVy4UO5YVkbpCQlEAF356KMKx61bty5N\nmTLF7HlLtSKzaPBgg+UPPvigyRBOvXr16HnlXrh1i+jkSd06Hx8fevnll02eZ9y4cdSwYUNauHAh\nfQCQRq0mKi62clUq8sILL9AGLy+ihg2Jbt60vPHFi/LefewxWrFiRfm1JKLMzExq2rQpNW/enAoK\nCiptBxHR888/Tw0CAkjTsyeRl5e8l8zw9ddfG9a6P/64fOikpFTp3EQknS1vb3nvrVxpeVvt/UOp\nqURLlsj/f/ON4TY3bkjh9/eX4zteeYVowgQZWtJeN7OMHEnUpIl0Nq5fl87eI49U/bNVgq1bt1Jk\nZCQBoIkTJ1JeXl6Vj1V7hP3AATIZy1RYv16u37GjwqrMzEyaO3cuLV26lDZs2ED79u2jU6dO0fXr\n10mj0VBKSgoBoOzbbydq2bKCB1FSUkJXTHjSRETPPPMM+fv7U2JiIt1+++0V1k+fPp28vb0p19pr\n6okT0v5Fiyqs6t+/PwGgefPmmd1do9HQGrWacurWJSJtqKBhQ5PbFhQU0OHDh02uS05OJgC0askS\nGUJ48knKy8uj0NBQeqBPHzkYKyGBVmmFfd++fbp9/1i/njYApPHyItLzVm7evKmLbZvl+eepUAga\naPQQbNKkCT3++OMVNm/RogU99dRTFZYXFRVZPJcykGrKlCn0sOIJ7t9vuFFpqfTyLLz9fTZmjNzX\n0mfSZ/p0IpWK/vnEE+Tn50fFeg+TlStXEgDabeKhbgtD7r+ftgQFSXuWLLG4rTJQ7L///a9ccOkS\nUYMGRF26EKWlVf6NV/HA335bhlgaNCAycoAMuP9+IuUtSaMhuusuOcBQ+X789htReLg85siRRH//\nLZfn5UkPPz7edNiLSP7dGjQgeuKJ8mUvvyzf5tLTK/e5KkFpaSlNmjSJAFCrVq3ozz//tPuYtUfY\nv/xSfgwzo+ooLU2uVzxIPcaOHatLVhn/eHl5UWBgIIUBpBGC6M03K2XW7t27dccy5SVu27aNANBK\na55MSYn0embOrLAqPDycANCDDz5odvez2dmUA9AxbahqxowZ5O3tbTJx++GHH5JaraZrJmKWS5cu\nJQCUkpIik24BAUT5+fTBBx9QN0UIFyygt99+m4QQBl5meno6BQB0KSJCfpmGDSPato1O//03AaAF\nCxaYNl6jIWrZkg40b06NGzfWLVbCFp999lmFXeLi4mjo0KEVll+6dIkA0L///W+Tp/r1118JALVt\n25a6KiNUv/rKcKM335TLx441G38+FBtLeQBpzDzwTRhGVKcO/RYSQvfcc4/BKsWxWGbOaTFFSYkc\ntfzYY3RDO9KZzHxmfS5evFjxmi5dSrpwR4sWMqSyZIn1NxGi8jflEyekF+7nR9S/v+kHxLVr8h6f\nPr182b59cv+nnyZ6+GH5/zZtTIeSVqyQ603cDwbH0n+4nT8vvf7x461/liqybt06AkATJkyo8luX\nMbVH2J98Uj7ZzXkUJSXyNdSEMMbHx9O9995Lx48fp507d9Lq1avp22+/pY8++ohmzpxJzzzzDG3v\n3Vu+6p0+XSmzNBoNxcTEVEjwKdy6dYuCg4NpzJgx1g8WE0M0fLjBIiU04uvrS35+fmZvnJ3z5hEB\nlKr90rz//vsEwOT2kydP1uUGjHn11VfJy8tLepTbt8tbZ/FiKigooBW+vpTv5UVUUEAPP/wwRUZG\nGuxbXFxMKpWKZr/4ovSUQkKIALoRFUXTAUodPZrohReIxowhevRRGVabPVsXC/3j4YcJKG8tsHbt\nWgJA2/WqZBS6du1K9913X4XlGRkZBIAWm2mNcPToUd2DuHu3btLDGzu2fIO8PKL69YnCwuRnT0gg\n0m9dUFpK9NtvVCYEfQDQLXPeowmKp02jUoA+MRIZ/Wodm9iwQSbaAdLUr0/zhKB5+l6qBTQaDQUH\nB9OECRMMV6SlSefpoYfkNQHkv6++SmQpBNijB1FcXPnvn39u+mFJJN+2TSVMlbcfX1+Z9DTXWkOj\nIerbV75JmrJp9mwyGY6dMEFWB1l6k7CDF198kXx9fanQ3iS0HrVH2Fu3Jho0yPI2UVFEI0YYLCos\nLCRvb2+aYalvS1mZfP27//4qmTZ//nzq2rWrTEiZYOTIkdS4cWPrZY8DBxLdcYfBIiU0MmHCBAJA\nv/76q8ldNw8bRgTQ5b17iYho3rx5BIDOnDlTYdtHHnmEANB7771XYd2wYcOotf6rcqtWRL16EeXk\n0C0vL/ocoC1btlDbtm1psFE8nIioZcuWNHr0aPnLzZtECxZQbsuW5R5hnTrylbpVK/kFVZb7+tL/\ntPFnJVGs9O0xFavs16+fyeTw/v37CQD98ssvJq9TYWEhCSEIgAzxPPCA7CejoCSx9+yR5bV160oR\n/fZbokmTZKUFQAWBgXQbQDdt8Wq1/G/VKioA6IyJSpxGjRrR008/bf0g27bJ2HO7dkRr1tCJI0cI\nAC0yEcIzR2JiosUKJSorkx7z0KHS2fH2lo6VsZNw4YJc/8Ybhvv27i3/zseOGW7/yCPy+hl/T3Jy\nZBzdVGmtMRkZ8gFgKm7eowdRhw4Vl6eny7+pvp0OJCEhgXr06OHQY9oq7DV7gNLVq3LwjvHAJGOi\noysMUkpJSUFpaSnuvPPO8oVEwKlTwP79ckDMp5/KIcj/+EeVzHv66aexc+dOs3Nk3n333bh48SLO\nnj1r+UAxMdJ+vQ6LSrfGZ8aPR7169bBGGXJvRN3kZJxVqdAgIQGA7GYImO7JrrRT3rdvX4V1qamp\nuF0Z9SkE8OSTciTfW2/Bu6wMq0JDMXPmTKSlpSEuLq7C/q1atSofpOTvD4wdixWvvYYGADLT0oAb\nN4AzZ2RfnLw82cvl77+BjAzcfu+9ACBHoALYv38/YmJiULdu3QrnCQoKMtnzRBlUZWqAEgD4+fnp\nesOEh4cDCQmyd8zNm3KQ08cfyw6YiYnAkCGyX03DhvLeWLBADjr66ScsmDkT54FK9YvZevQo5gJo\nun17hcFoERER1icbSUqSE7W0bAls2gQMHIh07QAopS2xLVjt8qhSAffcA6xaVd5faPFiOQBMn19/\nld+lYcMM9120CAgMlNdP+RsVF8t22wMHynbW+oSGAv/6V/kIcktERspBacuXA/rdV/PzZdvpPn0q\n7hMVBfTtC3z9tcOnpczNzUVycjJ69uzp0OPaSs0W9r175b+2CjuRbtH+/bJ9fMeOHeWC0lLZfzwy\nUn6p77sPePFFoFEjeSM6AYNeKJZo3VqKi97sSqmpqRgnBNoPHoxJnTtj7dq1FeetJELkmTNIbdhQ\nN2Kzfv36AGCyrYDSkMtY2G/duoX09PRyYQdkvxUi4D//Abp3x/A33sDu3btRWlpqUtgjIiIqjD7d\ntHkzSoOCcJupZlv+/kB4ONC8ORo0aIBmzZrprlNycnL5382IoKAgkyNjlWX16tUzuR9QLoIRERFA\np05AWRlw8KAUr/Pny0ezAvJvsnevFNJLl+TkLiNGQGgn8KiMsO/cuRPrWreG8POTk8XoYXWykaNH\npTg1aCCzxCq4AAAgAElEQVQnRdG2xFZGPiujam2hTZs2OHfuHPLz861v3KqVbCI3bpx0gA4cKF+3\nahUQFQVNbCx2795dvrxZMzmy9dQpYPRo6ahs3SrFd/Bgq6e8desWli9fbn5+1ldekW0b/vEP2aMJ\nkMcvLZVNAU3x3HPyb/vrr9Y/cyXYuXMnNBoNC7tNlJVJj2bFCuC11+QXTaWSQmyJ6GjpEV64oFuU\nnJyM+vXrS++MSA6xXrVKdjFcvVreEAcPAsePm+566ACU7oWKJ2oWE83Ajh07hik+PhDZ2Xhz2zZ0\nzsnBXuVBp0WTmoqQ0lJcjo3VLbPmsXt5eSErK0sn8oDsoVJaWoq2bduWbxweLr03AJgwAU8//TSa\nN28OAGY99gsXLuDmzZsAgKysLKxYsQLjxo2Dj6UmZFrat2+PQ4cO4dKlSzhz5ozhm5Ye9erVq5LH\nDpQLe3h4uBR2QPYgev996alr3xx0BAZKB0DvzUH5LLYKe1lZGXbt2oW2PXtKkVm2TL4NaAkPD0dW\nVpZpMcvMlO0UfHzkA0Z7/QHZHiE4OBgNGjSwyQ6g/H7cVZmJVd5/X3rW48fL7+e1a/Jtd/hwfPf9\n9+jatavhBOo9esgHwbp1wFtvSUENCJDX0QrLly/HyJEj8dNPP5newMcH+OUXIDZWdu5MSpICX6cO\n0LWr6X369ZP38ty5tn9mG9i6dSt8fHwMWzlUJ7bEaxz9U+UYu5JMAWRCNDaW6LXXrO+3YYPcZ9s2\n3aKOHTuWJ9lee02u12sDUF2Eh4dbHKBDRDKDD8gElJb7lNr0l16iWx060C2AVvbvL1eWlhJt304F\nffsSAbT8nXd0+6WlpREA+v777w1OUVZWRl5eXnT33XcTAFq/fr1u3c8//0wAKEk70EfHb78R3Xef\nrkJk2bJlFB8fb1Cyp7Bs2TICQEePHiUiopdeeolUKhWdtjEp/corr5C3tzetXr2aAJgtHXv77bcJ\nAJWUlBgsV0b7XjAacamPMqBH18/9tttkYh4wKNO0xIIFCwyPYYVDhw4RAPruu++Irl6VydnISJms\npfKcSIXj3bolW00EBZmsNe/du3elB6IVFRVRSEgIPVLZ+u4ffyRdVcqiRfL/e/fq7qUKg8I0mvLv\ncmCgrJKygVGjRhEAesDaqNFz52RurGFDmbdRvhfmeP99aYsdg8GM6dSpk8Foc0cBj0yebtkiyxb3\n76/ccOeTJ0kpxyOSVRo+Pj700ksvyVIwpYStiqNT7WHQoEEm69wN0Ghksm7SJCKS9r+kDL0+dYoo\nP5/+0laa0KBBciAGQKU+PvQFQLv0qg1ycnIIAH2u95AgIrp8+TIBoHfffZeEEPSmXnnnO++8Y7aS\nxlb27NlDAGjt2rWUn59P9erVoxFGCW1L/PDDDwSAHtZWyJgqySQimjNnDgGgy5cvGyz/17/+RbCS\n1Lxx44Zhm4RBg+Q1jYszPwrSiMWLFxMAysjIsGn7L774ggDQSWUg1fbtsiRUW83y+++/EwDaalzm\n98470jajB7RCy5Yt6TG9kdK2MnnyZPLx8alw/Syi0RD16ydLYLt0IWrRgtK1DoSPjw81adKk4qjj\nwkI5gAmQk7lYoaysjEJDQ0mtVpNKpTKZ/DfgxAldhRDNmWN525wcmXg1MyrZLL//Los3jAZ+5ebm\nkkqlkiOgHYytwl6zQjE9ewJPPSU75VUmPBIWBqjVugTq0aNHUVJSgoGA7Ek+aBDw1Ve6OHR10q5d\nO5w4cQJFRUXmNxJCxnS1oZiMjAwM1WhwJTxctiENDMSemTOxAEDZn38C3brh+ldfYXCXLnhOCLTV\nC8UoMWbjUIySOG3VqhXatGljEGdPTU1Fy5YtdRNAVwWlfe+pU6ewaNEi5ObmYtq0aTbv3759ewDA\nr7/+isjISF1IyRgl1GIcZ8/Ly4O3tzf8LNw3derUwQP6sVglxDdjhgz52YBarQZgeyhm586daNKk\nSfkkGHffLcOM330HLFumW24QZ9+7VyYsR46UrYeNKCoqQlZWVqXi6wpjx45FSUkJli1bZvtOQgBf\nfCHfpffsAYYNw3fffw+VSoV3330XFy5cwB5lIhwFPz8ZNnnxRcMkqxmSk5Nx+fJlvPbaa9BoNBUn\nujEmJkZOK9mvn8ydmaC0tBQLFy5ESVCQvJbffy8T97aweTMwaBAoPV2GfbStvQHXx9cB1DCP3R5a\nt9a98imvy0UxMbLjWyVK0xzNTz/9RABov/EoR2Mee0yOfiWi9dra9DPPPqtbrdRpf/rJJ/TLL79Q\naGgo+fn50Vcm6oYDAgLohRdeMFimDJj6448/6IknnjAow+zQoYPZ7oy2otFoKCAggCZPnkxRUVGU\nmJhYqf1v3bpFvr6+Oq/dHErY6ODBgwbLn3vuOQoJCamc0WfOyBroStSkK60BzI3gNaZly5Y03GiM\ngi7MUrcuFaemkhCCXn/9dbkuP1+W77ZoYbb5lTKwaenSpTbbrU/Hjh2pffv2tnUf1UdbElr2v/9R\nWFgY9e3bl3Jzc8nHx6fC/VZZ3nnnHRJC0KVLl6h79+7Upk2byttnxObNmwkAzZ8/XzYUs3EwF23Z\nQuTvTzejoigaoKsREbIeXjtqd/r06aRWqw36GDkKVJfHLoRoIYTYIoQ4JoQ4KoSYYu8xnYJSMghZ\nETOgTh34pqUB//d/sgLDRSieqNUEauvWQFYWUFgIr9WrAQD1x43TrY6MjERsbCzeePNNDB06FC1a\ntMD+/fvxzDPPVDhUsIme7IrH3qhRI3Tq1AkXL17EmTNnoNFocPz4ccOKmCoghECrVq2wZMkSZGRk\n4IUXXqjU/t7e3rqkrLnEKVD+RmKcQM3Ly7OYODVJs2YyQW+mV7wpKpM8PXv2LDIzM9G9e3fDFd7e\nwNKlgEoFn1GjMC04GN5//SWrb154QZaEfv89YOatJV17n1em1FGff/zjHzh06BCSk5MNll+9ehVz\n5841X5XywgvA0aPYUlyMrKwsPPXUUwgKCkLv3r2xatUqGfutIhs2bEBCQgIaNmyIJ598EsePHzdZ\nllsZLmsnRF+4cKFMlickyDePixfldJq5ubLcVX8i9+3b5bSVERFY8/zzSAfQo7gYZbffLqvnNm7E\n1q1bkZiYiDp16thlnz04IhRTCuD/iKgtgC4AnhNCtLWyT/UTHS1rbzUaJCcn4xV/f5nNf+wxl5oV\nGRkJf39/20oeiYCMDITt24dUtRp14uMNNnn44YdRUFCAmTNnYs+ePYZVLHrUr1+/QrmjIuwNGzZE\ngjYEsW/fPmRmZqKwsNDssSpDq1atcO3aNYSFhWGYDa/fxigPQXOljoDlUEylhb0KVCYUo8zA1dVU\nxUbLlsDChcCxY/j42jXM2rhRzvM6f76cCEOpSDKBvcL+2GOPwc/PD998841uWWFhIQYOHIhJkybh\nzz//NL2jEEDbtli0aBHq1auHwdoSxuHDh+P06dM4qJ1L1hwnT55Ep06dcNJojt9r165h9+7dujDZ\niBEj4O/vj0WLFlXp8ykozo1uYpxJk4DUVDm5TWiofHAGBMj6en9/WVLau7cM7f75J1K0lWMp587h\n/fvuA9q0AQ0YgOV792JVaioQHy9nHxsyRFbdvfMO8M03cryGk7Fb2InoPBEla/+fDyAVQDN7j1sV\n5s+fj+7du2PTpk0VV0ZHA4WFKM3KQt6BA7jryhVgwgSnlTLaipeXF+Li4mwvedy2Da1zcrDfRO33\nzJkzkZ2djdmzZ1ssITTlsSvljaGhoYiPj4e3tzf27duH1NRUALDbYwfK4+yTJ082O2OSJe6++24E\nBARYFHaHeuxVQBH2kpISq9te0Jbfhpubhm/oUCAvD9OHDMETDRrIuWdnz5YzM1kgLS0NDRs2NJuH\nsEZwcDCGDx+OZcuWobCwEGVlZRg9ejR2794NIQR27Nhhdt+8vDz8/PPPePTRR3X5jEGDBsHLyws/\n//yzxfPu2LEDSUlJuknJFTZv3gyNRoO+ffsCkH/jYcOG4YcffrCcm7KC8h0QQsiHxKhR8k1o7lxZ\no//xx8B77wFvvAFMniynDXz2WVnO2bgxTp48ifDwcIwaNQpvz52L0wsW4PSgQdgKQHPHHbKMMjBQ\n1u2vWAG8/jrw9NPy4eFsbInX2PoDIBxAFoAgS9s5I8ZeUlJCTZs21fX7GDRoEKXrd27btIkIoJML\nFtCnAJV5eVnudVGNjB07lho0aGA5ZpifTwSQRtvh7n0be4CYYsCAAdTBaIj1pEmTqH79+rrfO3To\nQL1796YPP/yQAJjtYlkZfvnlF4qOjjZb0WKNsrIyunr1qsVtzp8/TwDoiy++MFh+5513Un9rZW8O\nYOvWrQSANm/ebHXb2bNny1yPuR4oWt544w0SQljdTuGee+6hrl272rStOZT485IlS2jKlCkEgD75\n5BPq0KGDxXbT8+fPJ6C8/bBCr169rFZ/KaWqQgiDHMXYsWOpXr16Bv13lGqhn376qYqfsLwh3oMP\nPkjNmjUz2/rDHJ06daLevXvTmTNnKCAggAYPHkwvv/yy+fh6UZHsOWVH7B3VXRUjhAgE8DOAqURU\nIbUshBgvhEgSQiQpr/2OZO3atTh37hyWL1+Of/7zn/jzzz/Rtm1bvPnmm/Kho30tvfL77/gHgPz+\n/YGmTR1uR1Vo3749rly5ovPgTBIYCDRrBnH6NI4DCDGOy1aC4ODgCqGYS5cuoaF21CIAdOrUCUlJ\nSTh27BgaN26MkCrOAarPkCFDkJaWVmVPUqVS6UbOmsNSKMbSqFNHUZlQzPXr1+Hv7w9fX1+L20VE\nRICIkJWVZZMN6enpVQ7DKPTs2RMRERGYMmUK5syZgylTpmDatGno3r07/vrrL7Ofb9GiRbj99tvR\nuXNng+XDhg1Damqq7g3QFFlZWQgODkbdunV1XjsRYcOGDbj//vsN3vJ69eqF5s2b2xWOuX79OoKD\ngzFmzBicPXvW9Ju+BTIyMhAVFYVmzZph1qxZWL16NRYsWIDOnTubjq/7+soQWzXE3h0i7EIINaSo\nLyWiVaa2IaKviSiBiBL0BcRRfPHFFwgLC8Pw4cMxY8YMpKWlYfjw4Xjrrbfw3XffyVF5fn64fc0a\nBAEI1B8e7mIq1VoAwErAoISxstSvX99k8rRRo0a63xMSEnD9+nX897//dUgYprrw9/eHt7e3y0Mx\ntgq7LQ85kyWPZigoKMC5c+eqVOqoj0qlwpgxY3DlyhUMGzZMN8F29+7dcePGDZP3anp6Onbu3Imn\nnnoKwqh0eOjQoQCAVatMygMAIDMzEzExMXjxxRexevVq7N27F0ePHsXZs2d1YRgFLy8vPP7449i4\ncSPOnz9fpc947do11K9fHwMGDEBISIhMotrI1atXce3aNURFRQEApk6diujoaFy5csW1ZY5aHFEV\nIwB8AyCViD6x36TKc+LECWzevBnPPPOMruHWbbfdhiVLlqBnz5547rnnkJaRAURGIrCoCEfq1oWX\nq4b6mqCyrQV+hn0x7+DgYOTm5kKjl+035bEDMg5ck4RdCGGyX0x1CXtlqmKcIewZGRkAqp441Wfa\ntGn46quvsGTJEt33qlu3bgBgMs6+fPlyAMAoE7X1TZs2xV133WVR2LOyshAWFoapU6ciNDQUr776\nKjZs2AAAhuMLtIwZMwZlZWX49ttvK//hUH79fX19MWrUKPz6668meyiZQknwRkZGAgB8fX3x+eef\nQ6VSoV+/flWyx5E4wmPvBuBxAL2EEAe1P/0dcFyb+eqrr6BWqzF27FiD5V5eXliyZAn8/PwwcuRI\nlGqTd0nam9NdCAkJQfPmza0L+5NPYmNsLM43amQ1JGGJ4OBgEJFBs6ecnBwDYY+NjdUlvxxREVOd\nGPeLKSkpQVFRkdslT20V9qZNm0KtVtsk7PZWxOgTGBiIZ555Bv565cDNmjVDRESESWFfuXIlunbt\nimbNTNdODBs2DMnJycjUdp7URwk1hYWFoW7dupgxYwY2bdqETz/9FHFxcbo+RPpER0ejd+/emDdv\nnvkSTAvoX/+nnnoKxcXF+PHHH23aV3mAKh47APTt2xdXr17VPfxciSOqYnYQkSCidkQUr/35zfqe\njuHGjRtYuHAhhg8fjsaNG1dY36xZMyxcuBAHDhzA/JMnkQzAe8SI6jLPZtq3b29d2Lt0wRuBgXaF\nYYCKHR41Gg0uX75sEIpRq9WI15ZT1iSPHajY4VF5gNXUUIyXlxfCwsKst+9FubDrC46j6d69O3bs\n2GFQl56RkYFDhw7hITOjPAFZ1QSYDjleuXIFhYWFutbJEydORNOmTXHu3LkKYRh9Jk6ciOzsbKxf\nv77Sn0P/+nfo0AHt2rWzORyjeOxKpZdCdeRxbKFmtRQwwY8//ojc3Fw8++yzZrcZOHAgnn/+eTx7\n7Bg6AuhglNhxB9q1a4fU1FQUFxeb3YaIDPuiVxHjDo9Xr16FRqOBce5DCcfUdGG3pbOjo3CGsAM2\ntO/VkpaWhqZNmyIwMNCm41aF7t274+LFiwb15kop4/Dhw83up7xFpBvNjQBAlxgOCwsDIHMlr7/+\nOgDgwQcfNHvMQYMGoWnTpvjyyy8r+SkMr78QAmPGjMG+fft0cx1YIiMjA02bNnXpICRL1GhhJyJ8\n8cUXiIuLqzh6z4gPPvgA8fHxCAwMRJs2barJQttp164dSktLcfz4cbPbnD9/Hnl5eXaHRoyFXX/U\nqT6TJk3CBx98gNtuu82u81U3xqGY2iTsjqiIsYbyXdMPx6xcuRKdOnXSCbMpQkJCEBISYlLYlfCM\n/v7jx49HUlKSxWSkt7c3xo0bh40bN1bo928NJXmqoDyUNiq93C2gVMS4KzVa2Pft24fk5GRMnDix\nQhbeGF9fX2zcuBF//vlnlQbHOBulMsZSOEbxJBzlsSuhGGVwkrHHHhMTg5deesnqtXU3XOmx25o8\nJaJKC3tOTg4KCgosblcdwt6mTRuEhITohD0zMxNJSUkWwzAK0dHRuvi0PsYeOyC9aEuD0RTGjRsH\nlUqFefPm2foRUFRUhOLiYoPr36JFC0RHR5sfWavHyZMnWdidxezZsxEYGIjRo0fbtL3SB8UdiYmJ\nga+vr0Vhd9QoUMVLseax11TcwWO3ljwtLCzErVu3bI7JKpUxluLs169fR05OjtOFXaVSoVu3bjph\ntyUMoxAVFWU2FOPv71+piUEUmjVrhkGDBuHbb7+1eSSqcu8bP1h79eqFbdu2obS01Oy+BQUFuHDh\ngq4ixh2pscK+evVqrFmzBrNmzaqWL6yz8fb2RmxsrMVa9sOHDyMkJARNmjSx61zmQjHOGF/gCmpC\njN2csJjDlpJHRTDtrWG3he7du+PEiRPIycnBypUrER8fb5PQRUdHIzs7u4IAZ2VloWXLllV+O5w4\ncSIuX76MlStX2rS9JWHPz8/XTZ1pCiW3wB67gykoKMDkyZMRFxdXqZ7e7k67du0sCntycjLuvPNO\nu0MjQUFBEELobm4lFFMVb8kdCQoKQklJiS4RrXjv7jTytLLCrvSTsSTsyhtddQi7UtK3YsUK7N69\n26YwDCCFnYgqxMMzMzMtxuetcd999yEqKsrmJKq566/E8y2FY1jYncRbb72F7OxszJs3T/dF8gQ6\ndOigm9PTmJKSEqSkpFhsWWsrKpUKQUFBuhh7Tk4OQkJCPOZaGjcC8wSPvVGjRqhTp45FYd+zZw/q\n1q2L1toRys4kISEBvr6+ePPNNwGgUsIOVKyMUWrYq4pKpcKECROwa9cui20LFJR733g8SKNGjXDH\nHXdYFHYlR8ChGAdy6NAhfPrppxg3bpzpdqc1mMTERADl7Vz1OXbsGEpKShwi7IBhWwHjUac1HeN+\nMXl5eVCpVNVSmiaEgLe3t8OFXQiB8PBwizH2Xbt2oUuXLrpRos7E19cXnTp1Qk5ODmJjY21+mChe\nrr6wFxUV4eLFi3YJOwD07y/HRSYlJVnd1tL179WrF3bs2GG29DgjIwOhoaFuU7Nuihol7BqNBhMm\nTEBISAjee+89V5vjcOLj4+Hj44O9e/dWWKdMetChQweHnEu/da9xn5iajimPXQk/VQdqtdpq8rSy\nwg5YLnnMy8vDkSNHqtXZUcoebfXWAelQNGjQwEDYlTfUliZaUVeGqKgo+Pj4ICUlxeq21oS9qKio\n4nR+Wty9IgaoYcI+f/587NmzBx9//LFDug26G76+voiPjzfpsR84cACBgYEOu6H0OzzWBo+9OhPs\narXa4R47UC7s+iM+Ffbu3QuNRlOtwj5gwAD4+/vj0UcfrdR+xiWPpmrYq4JarUabNm3sFvYePXpA\npVKZDce4ew07UMOEvbi4GA8++KDN5Y01kcTERCQlJVXofZGcnIwOHTpAZeOkytbQD8UY94mp6Sgi\nbuyxVxeVEfbKvM5HREQgLy/PZKOqXbt2QQihC+dVB926dUN+fn6lY/rR0dEGHrupGvaqEhsbi6NH\nj1rd7tq1a/Dz8zM5uXlwcDA6duxoUtiLi4uRnZ3t1vF1oIYJ+/PPP4+1a9fWuAEzlaFz5864ceOG\nwc1ZVlaGgwcPOiwMA5SHYsrKynDlyhWPDMW4u8duTljMoXQBNdWAa9euXYiLi6v2uG9V4vlRUVHI\nzs5GYWEhACnsQgizzcMqQ1xcHDIzMw0a3JnC2uCwXr16Yc+ePbhx44bBcuWNiT12B+PJog6YTqCm\npaXh5s2bDkucAuXCbq5PTE3G1aEYHx8fm4S9shOO9OzZE/Xr18eKFSsMlms0GuzevbvGFBMolTFK\nyWNWVhaaNGlidcIRW1AmPLfW78UWYS8tLa3wEDXV1dEdqXHC7ulERUUhJCTEIIF64MABAHC4sCuT\nMgCeM+oUqDmhmMoKu1qtxtChQ7FmzRqDio1jx44hLy+vxgm7Eo5RBic5glht51NrcXZr179bt25Q\nq9UVwjEs7EyVEEKgc+fOBh57cnIyfH19Hdq8TKnfVb5cnuSx+/r6wtfX16WhGFuqYqoyReCIESOQ\nl5eH33//Xbds165dAFBjhN245NHewUn6REREwN/f325hDwgIQJcuXSoI+8mTJxEUFOT2g/lY2N2Q\nxMREHD16VNfwKTk5Ge3atXPoACLlpvZEYQek16547Lm5udUae3aWxw7IEZbG4Zhdu3ahYcOGbp/Q\nUwgODkZoaCjS09MNJthwBCqVyqYEqnFnR1P06tULycnJBslqpSLG3UPCLOxuSGJiIjQaDZKSkkBE\nOHDggEPDMEC5sKelpQHwrFAMIBOoeXl5KC0txc2bNz0iFKMce8iQIVi9erUuHLNr1y5069bN7cVG\nH6XkMScnB8XFxQ4TdkCGY+z12AE54Emj0aBv3766fEBNKHUEHDeZdV8hxAkhRIYQ4hVHHLM2o3Sg\n/Ouvv3D69Glcv37doRUxQEVhd/dXy8qiNAKrztmTFJwp7IBhOCYnJwfp6ek1JgyjoJQ8KqWOjoqx\nAzKBev78eVy9etXkeltbJnfu3BkrV65EWloaOnTogKVLl+L06dM14s3IEZNZewGYC6AfgLYAHhVC\n1KxJMt2M0NBQREZGYu/evboRp4722PVj7A0aNHDLHvX2oLTurc4+MQrWqmIq24vdGP1wzO7duwHU\nnPi6QlRUFM6cOaObWMbRHjsAs+GYmzdvorS01KbrP3z4cBw8eBCxsbEYPXo0SktLa43H3hlABhGd\nIqISAD8CGOyA49ZqEhMT8ddff+HAgQPw8vLS1TA7CuWm9rTBSQqKx+4KYbeWPFV6sVdV2H18fHTh\nmC1btkCtVts0IYU7oVTGbNmyBYBjhV0peTQXjqnsqN+WLVti27ZtmDlzJurUqVOtg8CqiiOEvRmA\nbL3fz2iXMXaQmJiIs2fPYu3atYiNja3UQBZb0L+pPVXYXeWxWwvFVKWdgDFKOObrr79Gx44dHX5/\nOBtF2Ddv3oyAgACriczK0Lx5cwQFBZn12M11drSEWq3G7NmzUVBQoHsjcGeqLXkqhBgvhEgSQiQp\nEzsw5lG8gsOHDzs8vg7Ici4l/OJpiVOgPHnqqcJ+3333ITg4GDdv3qxxYRigvOQxMzPTrgk2TCGE\nsJhAtef615QEtSOE/SyAFnq/N9cuM4CIviaiBCJK8EQP0dEonR4Bx8fXAXmDKje2J/49lFCMUvLo\nTsKu2GSPsCvhGKDmxdcB+eBV7jtHhmEU4uLikJKSYrJhmiMerO6OI4R9H4BoIUSEEMIHwEgAaxxw\n3FqN0ukRcI6wA+U3tqd67GVlZbhw4QIA90qeOkpYJkyYgDvuuEM3609NQwnHOEvYr1y5opsdTB8W\ndhsgolIAkwBsBJAK4Ccist5ejbFKly5doFKp0L59e6cc39M9dqC817c7JU+r0tnRFImJiTh8+HCN\nLVV1prBbai1QlRh7TcMhMXYi+o2IYogokohmO+KYDDBz5kxs2LABdevWdcrxlRvbk4U9OzsbQggE\nBgZW27mrI8buCTjbYwdMlzw66sHqzvDIUzemcePGuP/++512fE8PxQBS2OvWreuwPva2wMJuG4qw\nKxN1O5JGjRohNDTUpMd+/fp1BAQEeMwcv6ZgYa/F1JZQTHWGYQDbhN3X17fGlSg6msGDB2PevHlO\nSf5aqoyxZ3BYTYGFvRajhGI82WM/d+5ctQu7LclTTxcWW/D19cX48eOdNvl2XFwcjh49WqEypjZc\nfxb2Wkz79u0RFRVVY5NvllDEvKyszC09dk8XFncgNjYWeXl5ugS6gi2dHWs6LOy1mMceewzp6elO\n85hcib6Yu0LYrVXFsLA7H3OtBWrD9WdhZzwSVwu7RqOBRqMxub42CIs7wMLOMB6Gt7c36tSpA8A1\nwg7AbDimNgiLO1C/fn00a9aMhZ1hPAklgeqK5CnAwu4OKK0FFDQaDXJzcz3++rOwMx6LIuju5LHb\n24udqRxxcXE4duwYysrKAAD5+fnQaDScPGWYmoqrhd1UArWoqAglJSUs7NVEXFwcioqKcPLkSQC1\nZ8ZoNNcAAA1DSURBVHAYCzvjsSihmOoeOm7JY68twuIuGCdQa8v1Z2FnPBZXe+ws7K6nbdu2EEKw\nsDOMp+Cq5CkLu/tQp04dREZGsrAzjKfgKo/dUlVMbREWd0K/MqY2tOwFWNgZD8bVoRhTyVMW9uon\nLi4OaWlpKC4urjXXn4Wd8Vg4FMMAUtjLyspw/Phx3fWv7nuiumFhZzyWPn36YNSoUWjatGm1npeF\n3b3Qr4y5fv06goKCPLI/kj52CbsQ4kMhxHEhxGEhxC9CCL5bGbfhjjvuwJIlS+Dt7V2t57Um7NyL\nvXqJiYmBWq1GSkpKrejsCNjvsf8BII6I2gFIAzDDfpMYpmZjLXnK3nr1olar0aZNG53HXhuuv13C\nTkS/ayezBoA9AJrbbxLD1Gyseey1QVjcjbi4OBw5cqTWXH9Hxtj/AeC/Djwew9RIrFXFePIkyu5K\nXFwcMjMzkZWVxcIOAEKITUKIFBM/g/W2eRVAKYClFo4zXgiRJIRIysnJcYz1DOOGsMfufigJ1NOn\nT9eK6281q0REvS2tF0I8BWAAgPvIeHJBw+N8DeBrAEhISDC7HcPUdKwJe3h4eDVbxCjCDnj+4CTA\n/qqYvgCmAxhERDcdYxLD1Gw4eep+hIeHIyAgAEDtKDW1N8b+HwB1AfwhhDgohPjKATYxTI3GnMfO\nvdhdh0qlQmxsLIDaIex2FfgSUZSjDGEYT8Fc8pR7sbuWuLg47N27t1Zcfx55yjAOxpzHzqNOXYsS\nZ68N15+FnWEcDAu7e5KYmAgAaNmypYstcT7VO9aaYWoB5pKnubm5AFjYXUXXrl1x6tQpREREuNoU\np8MeO8M4GPbY3ZfaIOoACzvDOByVSgWVSlUhecrCzlQXLOwM4wTUarXZUIyn9wJnXA8LO8M4AVPC\nnp+fDwCoW7euK0xiahEs7AzjBCwJe2BgoCtMYmoRLOwM4wR8fHxMCntAQABUKv7aMc6F7zCGcQJq\ntbpC8jQ/P5/DMEy1wMLOME7AXCiGhZ2pDljYGcYJsLAzroSFnWGcAAs740pY2BnGCZhLnrKwM9UB\nCzvDOAH22BlXwsLOME6Aq2IYV8LCzjBOgD12xpU4RNiFEP8nhCAhRKgjjscwNR1jYS8tLUVhYSEL\nO1Mt2C3sQogWAPoAyLLfHIbxDIyTpwUFBQC4TwxTPTjCY/8UwHQA5IBjMYxHYOyxcwMwpjqxS9iF\nEIMBnCWiQw6yh2E8AuPkKQs7U51YnRpPCLEJQBMTq14FMBMyDGMVIcR4AOMBICwsrBImMkzNgz12\nxpVYFXYi6m1quRDiDgARAA4JIQCgOYBkIURnIrpg4jhfA/gaABISEjhsw3g0LOyMK6nyZNZEdARA\nI+V3IcRpAAlEdNkBdjFMjYaFnXElXMfOME7AuCqGhZ2pTqrssRtDROGOOhbD1HQ4ecq4EvbYGcYJ\ncCiGcSUs7AzjBEwJu0qlgr+/vwutYmoLLOwM4wTUajVKS0tBJAvAlD4x2goyhnEqLOwM4wR8fHwA\nyB4xADcAY6oXFnaGcQJqtRoAdOEYFnamOmFhZxgnoAi7UhnDws5UJyzsDOME2GNnXAkLO8M4ARZ2\nxpWwsDOME1CSpyzsjCtgYWcYJ8AeO+NKWNgZxglw8pRxJSzsDOME9D324uJi3Lp1i4WdqTZY2BnG\nCegLO/eJYaobFnaGcQL6yVMWdqa6YWFnGCfAHjvjSljYGcYJ6CdPWdiZ6sZhE20wDFOOvseuNAJj\nYWeqC7s9diHEZCHEcSHEUSHEB44wimFqOhyKYVyJXR67EOJeAIMBtCeiYiFEI2v7MExtgIWdcSX2\neuwTAbxHRMUAQESX7DeJYWo+XBXDuBJ7hT0GwN1CiL+EENuEEJ0cYRTD1HTYY2dcidVQjBBiE4Am\nJla9qt0/BEAXAJ0A/CSEaEXKfGCGxxkPYDwAhIWF2WMzw7g9xlUxPj4+Oi+eYZyNVWEnot7m1gkh\nJgJYpRXyvUIIDYBQADkmjvM1gK8BICEhoYLwM4wnYeyxs7fOVCf2hmJ+BXAvAAghYgD4ALhsr1EM\nU9NhYWdcib117N8C+FYIkQKgBMCTpsIwDFPbME6esrAz1Yldwk5EJQBGO8gWhvEY2GNnXAm3FGAY\nJ2CcPGVhZ6oTFnaGcQJeXl4A2GNnXAMLO8M4ASEE1Go1CzvjEljYGcZJ+Pj4sLAzLoGFnWGchFqt\nRklJCQoKCljYmWqFhZ1hnIRarUZubi40Gg0LO1OtsLAzjJNQq9W4evUqAO4Tw1QvLOwM4yTUajWu\nXbsGgIWdqV5Y2BnGSfj4+LDHzrgEFnaGcRIcimFcBQs7wzgJtVqNK1euAGBhZ6oXFnaGcRJqtZon\nsmZcAgs7wzgJpV8MwMLOVC8s7AzjJFjYGVfBws4wTkJ/KrzAwEAXWsLUNljYGcZJKB57nTp1dN0e\nGaY6YGFnGCehCDuHYZjqxi5hF0LECyH2CCEOCiGShBCdHWUYw9R0WNgZV2Gvx/4BgLeIKB7A69rf\nGYYBCzvjOuwVdgIQpP1/PQDn7Dwew3gMSvKUhZ2pbuyazBrAVAAbhRAfQT4kutpvEsN4BuyxM67C\nqrALITYBaGJi1asA7gMwjYh+FkI8DOAbAL3NHGc8gPEAEBYWVmWDGaamwMLOuAqrwk5EJoUaAIQQ\n3wGYov11BYAFFo7zNYCvASAhIYEqZybD1DxY2BlXYW+M/RyAe7T/7wUg3c7jMYzHwMLOuAp7Y+zj\nAMwRQngDKII21MIwDCdPGddhl7AT0Q4AHR1kC8N4FOyxM66CR54yjJNgYWdcBQs7wzgJFnbGVbCw\nM4yTYGFnXAULO8M4CRZ2xlWwsDOMk+CqGMZVsLAzjJNgYWdcBQs7wziJfv364dVXX0VkZKSrTWFq\nGYKo+kf3JyQkUFJSUrWfl2EYpiYjhNhPRAnWtmOPnWEYxsNgYWcYhvEwWNgZhmE8DBZ2hmEYD4OF\nnWEYxsNgYWcYhvEwWNgZhmE8DBZ2hmEYD8MlA5SEEDkAMqu4eyiAyw40x9GwffbB9tkH22c/7mxj\nSyJqaG0jlwi7PQghkmwZeeUq2D77YPvsg+2zn5pgozU4FMMwDONhsLAzDMN4GDVR2L92tQFWYPvs\ng+2zD7bPfmqCjRapcTF2hmEYxjI10WNnGIZhLFCjhF0I0VcIcUIIkSGEeMUN7PlWCHFJCJGityxE\nCPGHECJd+299F9rXQgixRQhxTAhxVAgxxZ1sFEL4CSH2CiEOae17S7s8Qgjxl/bvvFwI4eMK+/Ts\n9BJCHBBCrHM3+4QQp4UQR4QQB4UQSdplbvH31doSLIRYKYQ4LoRIFULc5S72CSFaa6+b8pMnhJjq\nLvbZQ40RdiGEF4C5APoBaAvgUSFEW9dahUUA+hotewXAZiKKBrBZ+7urKAXwf0TUFkAXAM9pr5m7\n2FgMoBcRtQcQD6CvEKILgPcBfEpEUQCuARjrIvsUpgBI1fvd3ey7l4ji9Ur03OXvCwBzAGwgojYA\n2kNeR7ewj4hOaK9bPICOAG4C+MVd7LMLIqoRPwDuArBR7/cZAGa4gV3hAFL0fj8B4Dbt/28DcMLV\nNurZthrA/e5oI4A6AJIBJEIODvE29Xd3gV3NIb/cvQCsAyDczL7TAEKNlrnF3xdAPQB/Q5vLczf7\njGzqA2Cnu9pX2Z8a47EDaAYgW+/3M9pl7kZjIjqv/f8FAI1daYyCECIcQAcAf8GNbNSGOQ4CuATg\nDwAngf9v395do4qiKA7/FvhAohgVCyGCCqKVaIo0BhGsDJLKQrFIIdjYWAki+CeIVjaKlUTwgQQr\n8VH7iC+iAbUQTNBEhCBY+VgW5wQvQcRJc85c9geXufecKRbsmZ3cPTPM2f6Rn1K6zueAk8CvfL2O\nuvIZuCNpXNKxvFZLfTcDn4HLeZR1UVJPRfmaDgGj+bzGfB3ppsbedZz+5Bf/2pGklcAN4ITtr829\n0hlt/3S6Fe4DBoDtpbIsJOkAMGt7vHSWfxi03U8aUR6XtKe5Wbi+S4B+4ILtXcA3Fow1Sr/+APJn\nJMPAtYV7NeRbjG5q7NPAxsZ1X16rzYykDQD5cbZkGElLSU39iu2bebmqjAC254AHpNFGr6Qleatk\nnXcDw5LeA1dJ45jz1JMP29P5cZY0Hx6gnvpOAVO2H+br66RGX0u+efuBp7Zn8nVt+TrWTY39MbA1\nfyNhGenWaaxwpr8ZA0by+Qhprl2EJAGXgEnbZxtbVWSUtF5Sbz5fQZr/T5Ia/MHS+Wyfst1nexPp\n9Xbf9pFa8knqkbRq/pw0J56gkvra/gR8kLQtL+0DXlNJvobD/BnDQH35Old6yN/hBxxDwBvSHPZ0\nBXlGgY/Ad9J/J0dJM9h7wFvgLrC2YL5B0m3kS+B5PoZqyQjsAJ7lfBPAmby+BXgEvCPdHi+voNZ7\ngds15cs5XuTj1fx7opb65iw7gSe5xreANZXl6wG+AKsba9XkW+wRvzwNIYSW6aZRTAghhP8QjT2E\nEFomGnsIIbRMNPYQQmiZaOwhhNAy0dhDCKFlorGHEELLRGMPIYSW+Q0ufeoLt5fVVAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd2eef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.36828635809 \n",
      "Updating scheme MAE:  1.52818422796\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
