{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/3_cells/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 750\n",
    "learning_rate = 1e-5\n",
    "batch_size = 5\n",
    "early_stop_iters = 15\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 12 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell]*3, state_is_tuple = True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 12 \n",
      "Learning rate = 1e-05 \n",
      "Epochs = 750 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 15 \n",
      "Learning rate = 1e-05\n",
      "Fold: 1  Epoch: 1  Training loss = 3.1081  Validation loss = 3.1251  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.1074  Validation loss = 3.1236  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.1066  Validation loss = 3.1220  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.1062  Validation loss = 3.1211  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.1054  Validation loss = 3.1194  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.1050  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.1044  Validation loss = 3.1174  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.1040  Validation loss = 3.1164  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.1034  Validation loss = 3.1153  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.1027  Validation loss = 3.1138  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.1020  Validation loss = 3.1122  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.1013  Validation loss = 3.1108  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.1007  Validation loss = 3.1096  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.1002  Validation loss = 3.1085  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.0994  Validation loss = 3.1069  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.0988  Validation loss = 3.1055  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.0982  Validation loss = 3.1045  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.0974  Validation loss = 3.1026  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.0970  Validation loss = 3.1018  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.0963  Validation loss = 3.1004  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.0957  Validation loss = 3.0991  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.0950  Validation loss = 3.0977  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.0946  Validation loss = 3.0966  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.0940  Validation loss = 3.0953  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.0935  Validation loss = 3.0944  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.0930  Validation loss = 3.0933  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.0927  Validation loss = 3.0926  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.0920  Validation loss = 3.0912  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.0915  Validation loss = 3.0901  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.0910  Validation loss = 3.0888  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.0903  Validation loss = 3.0874  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.0897  Validation loss = 3.0861  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.0891  Validation loss = 3.0848  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.0886  Validation loss = 3.0837  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.0879  Validation loss = 3.0822  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.0873  Validation loss = 3.0810  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.0867  Validation loss = 3.0797  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.0863  Validation loss = 3.0788  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.0857  Validation loss = 3.0776  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.0850  Validation loss = 3.0760  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.0844  Validation loss = 3.0748  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.0839  Validation loss = 3.0738  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.0834  Validation loss = 3.0726  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.0826  Validation loss = 3.0709  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.0820  Validation loss = 3.0698  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.0814  Validation loss = 3.0684  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.0807  Validation loss = 3.0670  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.0802  Validation loss = 3.0658  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.0795  Validation loss = 3.0642  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.0789  Validation loss = 3.0630  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.0785  Validation loss = 3.0620  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.0779  Validation loss = 3.0609  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.0775  Validation loss = 3.0599  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.0769  Validation loss = 3.0586  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.0761  Validation loss = 3.0569  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.0755  Validation loss = 3.0557  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.0750  Validation loss = 3.0546  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.0744  Validation loss = 3.0533  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.0739  Validation loss = 3.0522  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.0728  Validation loss = 3.0499  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.0724  Validation loss = 3.0489  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.0719  Validation loss = 3.0479  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.0715  Validation loss = 3.0469  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.0709  Validation loss = 3.0456  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.0705  Validation loss = 3.0448  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.0699  Validation loss = 3.0436  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.0694  Validation loss = 3.0424  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.0686  Validation loss = 3.0407  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.0680  Validation loss = 3.0393  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.0675  Validation loss = 3.0383  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.0670  Validation loss = 3.0372  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.0662  Validation loss = 3.0355  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.0656  Validation loss = 3.0341  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.0650  Validation loss = 3.0328  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.0645  Validation loss = 3.0316  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.0639  Validation loss = 3.0305  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.0635  Validation loss = 3.0294  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.0629  Validation loss = 3.0282  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.0626  Validation loss = 3.0275  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.0620  Validation loss = 3.0264  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.0616  Validation loss = 3.0254  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.0612  Validation loss = 3.0245  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.0608  Validation loss = 3.0237  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.0601  Validation loss = 3.0221  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.0597  Validation loss = 3.0211  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.0592  Validation loss = 3.0202  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.0586  Validation loss = 3.0188  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.0581  Validation loss = 3.0176  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.0576  Validation loss = 3.0166  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.0571  Validation loss = 3.0155  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.0563  Validation loss = 3.0137  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.0558  Validation loss = 3.0125  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.0554  Validation loss = 3.0116  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.0551  Validation loss = 3.0109  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.0542  Validation loss = 3.0091  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.0539  Validation loss = 3.0082  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.0532  Validation loss = 3.0067  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.0526  Validation loss = 3.0055  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.0519  Validation loss = 3.0039  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.0513  Validation loss = 3.0027  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.0509  Validation loss = 3.0016  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.0504  Validation loss = 3.0006  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.0498  Validation loss = 2.9992  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.0491  Validation loss = 2.9977  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.0485  Validation loss = 2.9964  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.0479  Validation loss = 2.9950  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.0474  Validation loss = 2.9938  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.0469  Validation loss = 2.9929  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.0464  Validation loss = 2.9917  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.0461  Validation loss = 2.9911  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.0456  Validation loss = 2.9899  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.0451  Validation loss = 2.9887  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.0445  Validation loss = 2.9875  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.0439  Validation loss = 2.9861  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.0432  Validation loss = 2.9846  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.0426  Validation loss = 2.9833  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.0421  Validation loss = 2.9821  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.0417  Validation loss = 2.9811  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.0411  Validation loss = 2.9798  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.0405  Validation loss = 2.9784  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.0399  Validation loss = 2.9772  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.0393  Validation loss = 2.9759  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.0389  Validation loss = 2.9749  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.0384  Validation loss = 2.9737  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.0378  Validation loss = 2.9725  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.0375  Validation loss = 2.9716  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.0370  Validation loss = 2.9705  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.0364  Validation loss = 2.9692  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.0356  Validation loss = 2.9674  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.0350  Validation loss = 2.9661  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.0345  Validation loss = 2.9650  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.0342  Validation loss = 2.9641  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.0337  Validation loss = 2.9629  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.0331  Validation loss = 2.9617  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.0326  Validation loss = 2.9605  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.0318  Validation loss = 2.9588  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.0313  Validation loss = 2.9576  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.0310  Validation loss = 2.9568  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.0304  Validation loss = 2.9556  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.0298  Validation loss = 2.9541  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.0293  Validation loss = 2.9530  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.0288  Validation loss = 2.9519  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.0285  Validation loss = 2.9512  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.0280  Validation loss = 2.9500  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.0273  Validation loss = 2.9486  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.0269  Validation loss = 2.9477  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.0265  Validation loss = 2.9466  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.0261  Validation loss = 2.9457  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.0255  Validation loss = 2.9445  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.0251  Validation loss = 2.9435  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.0248  Validation loss = 2.9427  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.0244  Validation loss = 2.9418  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.0237  Validation loss = 2.9402  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.0229  Validation loss = 2.9384  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.0226  Validation loss = 2.9377  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.0222  Validation loss = 2.9368  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.0218  Validation loss = 2.9358  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.0213  Validation loss = 2.9348  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.0210  Validation loss = 2.9340  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.0204  Validation loss = 2.9327  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.0199  Validation loss = 2.9314  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.0194  Validation loss = 2.9302  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.0189  Validation loss = 2.9292  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.0185  Validation loss = 2.9282  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.0181  Validation loss = 2.9273  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.0175  Validation loss = 2.9258  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.0169  Validation loss = 2.9245  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.0165  Validation loss = 2.9236  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.0161  Validation loss = 2.9226  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.0157  Validation loss = 2.9218  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.0152  Validation loss = 2.9204  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.0146  Validation loss = 2.9192  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.0141  Validation loss = 2.9180  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.0138  Validation loss = 2.9172  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.0133  Validation loss = 2.9160  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.0129  Validation loss = 2.9152  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.0124  Validation loss = 2.9140  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.0119  Validation loss = 2.9129  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.0115  Validation loss = 2.9119  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.0109  Validation loss = 2.9105  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.0103  Validation loss = 2.9091  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.0099  Validation loss = 2.9082  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.0094  Validation loss = 2.9070  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.0090  Validation loss = 2.9061  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.0087  Validation loss = 2.9053  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.0081  Validation loss = 2.9039  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.0078  Validation loss = 2.9031  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.0073  Validation loss = 2.9021  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.0069  Validation loss = 2.9012  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.0063  Validation loss = 2.8996  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.0061  Validation loss = 2.8991  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.0056  Validation loss = 2.8981  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.0051  Validation loss = 2.8968  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.0048  Validation loss = 2.8961  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.0042  Validation loss = 2.8946  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.0037  Validation loss = 2.8934  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.0033  Validation loss = 2.8926  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.0028  Validation loss = 2.8915  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.0020  Validation loss = 2.8896  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.0014  Validation loss = 2.8880  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.0008  Validation loss = 2.8868  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.0004  Validation loss = 2.8857  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.0000  Validation loss = 2.8849  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 2.9996  Validation loss = 2.8838  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 2.9992  Validation loss = 2.8828  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 2.9988  Validation loss = 2.8819  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 2.9983  Validation loss = 2.8807  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 2.9981  Validation loss = 2.8803  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 2.9976  Validation loss = 2.8790  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 2.9969  Validation loss = 2.8775  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 2.9965  Validation loss = 2.8765  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 2.9960  Validation loss = 2.8753  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 2.9956  Validation loss = 2.8742  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 2.9950  Validation loss = 2.8729  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 2.9947  Validation loss = 2.8722  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 2.9941  Validation loss = 2.8708  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 2.9936  Validation loss = 2.8696  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 2.9932  Validation loss = 2.8685  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 2.9927  Validation loss = 2.8673  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 2.9922  Validation loss = 2.8663  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 2.9919  Validation loss = 2.8654  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 2.9914  Validation loss = 2.8644  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 2.9911  Validation loss = 2.8635  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 2.9903  Validation loss = 2.8618  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 2.9899  Validation loss = 2.8607  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 2.9896  Validation loss = 2.8600  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 2.9891  Validation loss = 2.8588  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 2.9887  Validation loss = 2.8578  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 2.9882  Validation loss = 2.8566  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 2.9878  Validation loss = 2.8555  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 2.9874  Validation loss = 2.8547  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 2.9872  Validation loss = 2.8540  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 2.9868  Validation loss = 2.8531  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 2.9864  Validation loss = 2.8521  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 2.9859  Validation loss = 2.8508  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 2.9853  Validation loss = 2.8496  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 2.9847  Validation loss = 2.8480  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 2.9843  Validation loss = 2.8471  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 2.9839  Validation loss = 2.8460  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 2.9835  Validation loss = 2.8451  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 2.9831  Validation loss = 2.8440  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 2.9827  Validation loss = 2.8431  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 2.9823  Validation loss = 2.8421  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 2.9821  Validation loss = 2.8416  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 2.9815  Validation loss = 2.8402  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 2.9812  Validation loss = 2.8395  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 2.9807  Validation loss = 2.8382  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 2.9803  Validation loss = 2.8371  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 2.9799  Validation loss = 2.8363  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 2.9794  Validation loss = 2.8349  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 2.9788  Validation loss = 2.8337  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 2.9785  Validation loss = 2.8327  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 2.9782  Validation loss = 2.8322  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 2.9778  Validation loss = 2.8310  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 2.9774  Validation loss = 2.8301  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 2.9768  Validation loss = 2.8288  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 2.9766  Validation loss = 2.8282  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 2.9760  Validation loss = 2.8268  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 2.9756  Validation loss = 2.8257  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 2.9753  Validation loss = 2.8250  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 2.9747  Validation loss = 2.8237  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 2.9743  Validation loss = 2.8226  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 2.9741  Validation loss = 2.8220  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 2.9736  Validation loss = 2.8209  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 2.9732  Validation loss = 2.8198  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 2.9728  Validation loss = 2.8188  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 2.9724  Validation loss = 2.8179  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 2.9721  Validation loss = 2.8172  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 2.9715  Validation loss = 2.8157  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 2.9712  Validation loss = 2.8150  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 2.9708  Validation loss = 2.8139  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 2.9705  Validation loss = 2.8131  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 2.9702  Validation loss = 2.8124  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 2.9697  Validation loss = 2.8112  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 2.9693  Validation loss = 2.8101  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 2.9687  Validation loss = 2.8088  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 2.9684  Validation loss = 2.8080  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 2.9680  Validation loss = 2.8071  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 2.9678  Validation loss = 2.8063  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 2.9673  Validation loss = 2.8052  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 2.9668  Validation loss = 2.8038  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 2.9663  Validation loss = 2.8027  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 2.9659  Validation loss = 2.8017  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 2.9656  Validation loss = 2.8010  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 2.9653  Validation loss = 2.8002  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 2.9648  Validation loss = 2.7990  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 2.9645  Validation loss = 2.7981  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 2.9642  Validation loss = 2.7974  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 2.9639  Validation loss = 2.7967  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 2.9637  Validation loss = 2.7960  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 2.9635  Validation loss = 2.7955  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 2.9633  Validation loss = 2.7950  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 2.9627  Validation loss = 2.7936  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 2.9623  Validation loss = 2.7925  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 2.9620  Validation loss = 2.7917  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 2.9613  Validation loss = 2.7901  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 2.9609  Validation loss = 2.7889  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 2.9605  Validation loss = 2.7879  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 2.9603  Validation loss = 2.7874  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 2.9597  Validation loss = 2.7861  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 2.9594  Validation loss = 2.7852  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 2.9591  Validation loss = 2.7844  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 2.9587  Validation loss = 2.7834  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 2.9582  Validation loss = 2.7823  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 2.9579  Validation loss = 2.7816  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 2.9576  Validation loss = 2.7808  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 2.9572  Validation loss = 2.7797  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 2.9568  Validation loss = 2.7787  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 2.9565  Validation loss = 2.7777  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 2.9560  Validation loss = 2.7765  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 2.9555  Validation loss = 2.7751  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 2.9552  Validation loss = 2.7744  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 2.9546  Validation loss = 2.7730  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 2.9542  Validation loss = 2.7718  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 2.9539  Validation loss = 2.7711  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 2.9535  Validation loss = 2.7701  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 2.9530  Validation loss = 2.7689  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 2.9527  Validation loss = 2.7680  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 2.9524  Validation loss = 2.7674  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 2.9520  Validation loss = 2.7663  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 2.9516  Validation loss = 2.7653  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 2.9512  Validation loss = 2.7642  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 2.9509  Validation loss = 2.7633  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 2.9505  Validation loss = 2.7623  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 2.9501  Validation loss = 2.7614  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 2.9497  Validation loss = 2.7603  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 2.9494  Validation loss = 2.7596  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 2.9491  Validation loss = 2.7589  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 2.9487  Validation loss = 2.7578  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 2.9484  Validation loss = 2.7570  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 2.9479  Validation loss = 2.7556  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 2.9474  Validation loss = 2.7544  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 2.9470  Validation loss = 2.7534  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 2.9466  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 2.9461  Validation loss = 2.7511  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 2.9457  Validation loss = 2.7499  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 2.9453  Validation loss = 2.7489  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 2.9450  Validation loss = 2.7481  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 2.9444  Validation loss = 2.7466  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 2.9439  Validation loss = 2.7454  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 2.9435  Validation loss = 2.7443  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 2.9432  Validation loss = 2.7435  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 2.9426  Validation loss = 2.7419  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 2.9421  Validation loss = 2.7408  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 2.9417  Validation loss = 2.7396  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 2.9414  Validation loss = 2.7389  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 2.9411  Validation loss = 2.7380  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 2.9407  Validation loss = 2.7370  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 2.9403  Validation loss = 2.7361  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 2.9399  Validation loss = 2.7349  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 2.9396  Validation loss = 2.7342  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 2.9394  Validation loss = 2.7336  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 2.9390  Validation loss = 2.7326  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 2.9386  Validation loss = 2.7316  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 2.9382  Validation loss = 2.7305  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 2.9378  Validation loss = 2.7295  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 2.9376  Validation loss = 2.7288  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 2.9373  Validation loss = 2.7282  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 2.9370  Validation loss = 2.7272  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 2.9367  Validation loss = 2.7265  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 2.9363  Validation loss = 2.7254  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 2.9358  Validation loss = 2.7243  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 2.9354  Validation loss = 2.7232  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 2.9350  Validation loss = 2.7221  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 2.9346  Validation loss = 2.7210  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 2.9344  Validation loss = 2.7207  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 2.9340  Validation loss = 2.7196  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 2.9336  Validation loss = 2.7185  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 2.9332  Validation loss = 2.7174  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 2.9327  Validation loss = 2.7162  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 2.9324  Validation loss = 2.7152  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 2.9320  Validation loss = 2.7142  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 2.9318  Validation loss = 2.7137  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 2.9314  Validation loss = 2.7126  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 2.9310  Validation loss = 2.7117  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 2.9306  Validation loss = 2.7104  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 2.9303  Validation loss = 2.7096  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 2.9298  Validation loss = 2.7082  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 2.9295  Validation loss = 2.7075  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 2.9292  Validation loss = 2.7067  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 2.9289  Validation loss = 2.7059  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 2.9284  Validation loss = 2.7046  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 2.9281  Validation loss = 2.7037  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 2.9278  Validation loss = 2.7031  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 2.9276  Validation loss = 2.7024  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 2.9273  Validation loss = 2.7017  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 2.9271  Validation loss = 2.7010  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 2.9266  Validation loss = 2.6998  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 2.9262  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 2.9258  Validation loss = 2.6976  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 2.9255  Validation loss = 2.6968  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 2.9252  Validation loss = 2.6961  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 2.9249  Validation loss = 2.6951  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 2.9245  Validation loss = 2.6941  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 2.9242  Validation loss = 2.6933  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 2.9240  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 2.9238  Validation loss = 2.6922  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 2.9234  Validation loss = 2.6912  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 2.9233  Validation loss = 2.6908  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 2.9230  Validation loss = 2.6900  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 2.9227  Validation loss = 2.6892  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 2.9222  Validation loss = 2.6879  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 2.9219  Validation loss = 2.6872  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 2.9216  Validation loss = 2.6864  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 2.9212  Validation loss = 2.6854  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 2.9208  Validation loss = 2.6843  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 2.9205  Validation loss = 2.6833  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 2.9202  Validation loss = 2.6826  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 2.9200  Validation loss = 2.6820  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 2.9197  Validation loss = 2.6811  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 2.9191  Validation loss = 2.6797  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 2.9188  Validation loss = 2.6788  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 2.9185  Validation loss = 2.6780  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 2.9182  Validation loss = 2.6770  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 2.9178  Validation loss = 2.6760  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 2.9174  Validation loss = 2.6749  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 2.9170  Validation loss = 2.6740  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 2.9168  Validation loss = 2.6734  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 2.9164  Validation loss = 2.6721  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 2.9159  Validation loss = 2.6709  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 2.9158  Validation loss = 2.6705  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 2.9155  Validation loss = 2.6698  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 2.9150  Validation loss = 2.6685  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 2.9147  Validation loss = 2.6677  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 2.9144  Validation loss = 2.6667  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 2.9140  Validation loss = 2.6659  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 2.9138  Validation loss = 2.6651  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 2.9136  Validation loss = 2.6647  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 2.9133  Validation loss = 2.6637  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 2.9129  Validation loss = 2.6627  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 2.9125  Validation loss = 2.6616  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 2.9122  Validation loss = 2.6607  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 2.9119  Validation loss = 2.6599  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 2.9116  Validation loss = 2.6590  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 2.9113  Validation loss = 2.6582  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 2.9111  Validation loss = 2.6575  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 2.9108  Validation loss = 2.6568  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 2.9104  Validation loss = 2.6558  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 2.9102  Validation loss = 2.6552  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 2.9099  Validation loss = 2.6543  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 2.9095  Validation loss = 2.6533  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 2.9092  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 2.9090  Validation loss = 2.6518  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 2.9087  Validation loss = 2.6510  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 2.9084  Validation loss = 2.6500  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 2.9079  Validation loss = 2.6487  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 2.9076  Validation loss = 2.6478  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 2.9073  Validation loss = 2.6469  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 2.9069  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 2.9066  Validation loss = 2.6451  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 2.9063  Validation loss = 2.6443  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 2.9059  Validation loss = 2.6430  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 2.9057  Validation loss = 2.6426  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 2.9054  Validation loss = 2.6418  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 2.9050  Validation loss = 2.6406  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 2.9048  Validation loss = 2.6401  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 2.9046  Validation loss = 2.6394  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 2.9043  Validation loss = 2.6388  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 2.9042  Validation loss = 2.6383  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 2.9039  Validation loss = 2.6375  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 2.9037  Validation loss = 2.6369  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 2.9034  Validation loss = 2.6362  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 2.9032  Validation loss = 2.6355  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 2.9028  Validation loss = 2.6346  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 2.9026  Validation loss = 2.6339  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 2.9023  Validation loss = 2.6329  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 2.9021  Validation loss = 2.6324  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 2.9016  Validation loss = 2.6312  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 2.9012  Validation loss = 2.6300  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 2.9011  Validation loss = 2.6297  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 2.9008  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 2.9005  Validation loss = 2.6279  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 2.9002  Validation loss = 2.6272  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 2.8999  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 2.8996  Validation loss = 2.6253  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 2.8993  Validation loss = 2.6246  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 2.8990  Validation loss = 2.6237  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 2.8987  Validation loss = 2.6228  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 2.8984  Validation loss = 2.6220  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 2.8981  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 2.8979  Validation loss = 2.6207  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 2.8978  Validation loss = 2.6203  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 2.8975  Validation loss = 2.6193  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 2.8972  Validation loss = 2.6185  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 2.8969  Validation loss = 2.6177  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 2.8965  Validation loss = 2.6165  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 2.8962  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 2.8960  Validation loss = 2.6153  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 2.8956  Validation loss = 2.6141  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 2.8953  Validation loss = 2.6132  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 2.8950  Validation loss = 2.6124  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 2.8948  Validation loss = 2.6117  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 2.8944  Validation loss = 2.6106  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 2.8940  Validation loss = 2.6094  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 2.8936  Validation loss = 2.6083  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 2.8932  Validation loss = 2.6071  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 2.8929  Validation loss = 2.6063  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 2.8927  Validation loss = 2.6057  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 2.8924  Validation loss = 2.6049  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 2.8920  Validation loss = 2.6037  \n",
      "\n",
      "Fold: 1  Epoch: 501  Training loss = 2.8918  Validation loss = 2.6031  \n",
      "\n",
      "Fold: 1  Epoch: 502  Training loss = 2.8915  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 1  Epoch: 503  Training loss = 2.8912  Validation loss = 2.6014  \n",
      "\n",
      "Fold: 1  Epoch: 504  Training loss = 2.8909  Validation loss = 2.6004  \n",
      "\n",
      "Fold: 1  Epoch: 505  Training loss = 2.8906  Validation loss = 2.5996  \n",
      "\n",
      "Fold: 1  Epoch: 506  Training loss = 2.8904  Validation loss = 2.5992  \n",
      "\n",
      "Fold: 1  Epoch: 507  Training loss = 2.8902  Validation loss = 2.5985  \n",
      "\n",
      "Fold: 1  Epoch: 508  Training loss = 2.8899  Validation loss = 2.5976  \n",
      "\n",
      "Fold: 1  Epoch: 509  Training loss = 2.8898  Validation loss = 2.5973  \n",
      "\n",
      "Fold: 1  Epoch: 510  Training loss = 2.8896  Validation loss = 2.5966  \n",
      "\n",
      "Fold: 1  Epoch: 511  Training loss = 2.8893  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 1  Epoch: 512  Training loss = 2.8891  Validation loss = 2.5952  \n",
      "\n",
      "Fold: 1  Epoch: 513  Training loss = 2.8887  Validation loss = 2.5942  \n",
      "\n",
      "Fold: 1  Epoch: 514  Training loss = 2.8883  Validation loss = 2.5929  \n",
      "\n",
      "Fold: 1  Epoch: 515  Training loss = 2.8877  Validation loss = 2.5914  \n",
      "\n",
      "Fold: 1  Epoch: 516  Training loss = 2.8873  Validation loss = 2.5902  \n",
      "\n",
      "Fold: 1  Epoch: 517  Training loss = 2.8872  Validation loss = 2.5899  \n",
      "\n",
      "Fold: 1  Epoch: 518  Training loss = 2.8870  Validation loss = 2.5893  \n",
      "\n",
      "Fold: 1  Epoch: 519  Training loss = 2.8867  Validation loss = 2.5886  \n",
      "\n",
      "Fold: 1  Epoch: 520  Training loss = 2.8865  Validation loss = 2.5878  \n",
      "\n",
      "Fold: 1  Epoch: 521  Training loss = 2.8862  Validation loss = 2.5870  \n",
      "\n",
      "Fold: 1  Epoch: 522  Training loss = 2.8859  Validation loss = 2.5861  \n",
      "\n",
      "Fold: 1  Epoch: 523  Training loss = 2.8856  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 1  Epoch: 524  Training loss = 2.8854  Validation loss = 2.5847  \n",
      "\n",
      "Fold: 1  Epoch: 525  Training loss = 2.8853  Validation loss = 2.5842  \n",
      "\n",
      "Fold: 1  Epoch: 526  Training loss = 2.8850  Validation loss = 2.5836  \n",
      "\n",
      "Fold: 1  Epoch: 527  Training loss = 2.8849  Validation loss = 2.5831  \n",
      "\n",
      "Fold: 1  Epoch: 528  Training loss = 2.8845  Validation loss = 2.5820  \n",
      "\n",
      "Fold: 1  Epoch: 529  Training loss = 2.8841  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 1  Epoch: 530  Training loss = 2.8837  Validation loss = 2.5796  \n",
      "\n",
      "Fold: 1  Epoch: 531  Training loss = 2.8834  Validation loss = 2.5787  \n",
      "\n",
      "Fold: 1  Epoch: 532  Training loss = 2.8832  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 1  Epoch: 533  Training loss = 2.8829  Validation loss = 2.5773  \n",
      "\n",
      "Fold: 1  Epoch: 534  Training loss = 2.8824  Validation loss = 2.5759  \n",
      "\n",
      "Fold: 1  Epoch: 535  Training loss = 2.8820  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 1  Epoch: 536  Training loss = 2.8818  Validation loss = 2.5741  \n",
      "\n",
      "Fold: 1  Epoch: 537  Training loss = 2.8814  Validation loss = 2.5731  \n",
      "\n",
      "Fold: 1  Epoch: 538  Training loss = 2.8813  Validation loss = 2.5726  \n",
      "\n",
      "Fold: 1  Epoch: 539  Training loss = 2.8809  Validation loss = 2.5714  \n",
      "\n",
      "Fold: 1  Epoch: 540  Training loss = 2.8806  Validation loss = 2.5705  \n",
      "\n",
      "Fold: 1  Epoch: 541  Training loss = 2.8803  Validation loss = 2.5697  \n",
      "\n",
      "Fold: 1  Epoch: 542  Training loss = 2.8798  Validation loss = 2.5684  \n",
      "\n",
      "Fold: 1  Epoch: 543  Training loss = 2.8797  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 1  Epoch: 544  Training loss = 2.8793  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 1  Epoch: 545  Training loss = 2.8790  Validation loss = 2.5659  \n",
      "\n",
      "Fold: 1  Epoch: 546  Training loss = 2.8787  Validation loss = 2.5650  \n",
      "\n",
      "Fold: 1  Epoch: 547  Training loss = 2.8784  Validation loss = 2.5642  \n",
      "\n",
      "Fold: 1  Epoch: 548  Training loss = 2.8782  Validation loss = 2.5634  \n",
      "\n",
      "Fold: 1  Epoch: 549  Training loss = 2.8777  Validation loss = 2.5620  \n",
      "\n",
      "Fold: 1  Epoch: 550  Training loss = 2.8774  Validation loss = 2.5612  \n",
      "\n",
      "Fold: 1  Epoch: 551  Training loss = 2.8772  Validation loss = 2.5604  \n",
      "\n",
      "Fold: 1  Epoch: 552  Training loss = 2.8768  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 1  Epoch: 553  Training loss = 2.8765  Validation loss = 2.5583  \n",
      "\n",
      "Fold: 1  Epoch: 554  Training loss = 2.8762  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 1  Epoch: 555  Training loss = 2.8757  Validation loss = 2.5561  \n",
      "\n",
      "Fold: 1  Epoch: 556  Training loss = 2.8755  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 1  Epoch: 557  Training loss = 2.8752  Validation loss = 2.5546  \n",
      "\n",
      "Fold: 1  Epoch: 558  Training loss = 2.8748  Validation loss = 2.5535  \n",
      "\n",
      "Fold: 1  Epoch: 559  Training loss = 2.8746  Validation loss = 2.5529  \n",
      "\n",
      "Fold: 1  Epoch: 560  Training loss = 2.8744  Validation loss = 2.5521  \n",
      "\n",
      "Fold: 1  Epoch: 561  Training loss = 2.8742  Validation loss = 2.5516  \n",
      "\n",
      "Fold: 1  Epoch: 562  Training loss = 2.8739  Validation loss = 2.5507  \n",
      "\n",
      "Fold: 1  Epoch: 563  Training loss = 2.8738  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 1  Epoch: 564  Training loss = 2.8736  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 1  Epoch: 565  Training loss = 2.8732  Validation loss = 2.5487  \n",
      "\n",
      "Fold: 1  Epoch: 566  Training loss = 2.8729  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 1  Epoch: 567  Training loss = 2.8726  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 1  Epoch: 568  Training loss = 2.8723  Validation loss = 2.5458  \n",
      "\n",
      "Fold: 1  Epoch: 569  Training loss = 2.8720  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 1  Epoch: 570  Training loss = 2.8716  Validation loss = 2.5439  \n",
      "\n",
      "Fold: 1  Epoch: 571  Training loss = 2.8714  Validation loss = 2.5431  \n",
      "\n",
      "Fold: 1  Epoch: 572  Training loss = 2.8710  Validation loss = 2.5420  \n",
      "\n",
      "Fold: 1  Epoch: 573  Training loss = 2.8709  Validation loss = 2.5416  \n",
      "\n",
      "Fold: 1  Epoch: 574  Training loss = 2.8707  Validation loss = 2.5410  \n",
      "\n",
      "Fold: 1  Epoch: 575  Training loss = 2.8704  Validation loss = 2.5402  \n",
      "\n",
      "Fold: 1  Epoch: 576  Training loss = 2.8701  Validation loss = 2.5391  \n",
      "\n",
      "Fold: 1  Epoch: 577  Training loss = 2.8698  Validation loss = 2.5384  \n",
      "\n",
      "Fold: 1  Epoch: 578  Training loss = 2.8695  Validation loss = 2.5376  \n",
      "\n",
      "Fold: 1  Epoch: 579  Training loss = 2.8691  Validation loss = 2.5362  \n",
      "\n",
      "Fold: 1  Epoch: 580  Training loss = 2.8690  Validation loss = 2.5358  \n",
      "\n",
      "Fold: 1  Epoch: 581  Training loss = 2.8688  Validation loss = 2.5352  \n",
      "\n",
      "Fold: 1  Epoch: 582  Training loss = 2.8686  Validation loss = 2.5346  \n",
      "\n",
      "Fold: 1  Epoch: 583  Training loss = 2.8685  Validation loss = 2.5343  \n",
      "\n",
      "Fold: 1  Epoch: 584  Training loss = 2.8680  Validation loss = 2.5329  \n",
      "\n",
      "Fold: 1  Epoch: 585  Training loss = 2.8677  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 1  Epoch: 586  Training loss = 2.8673  Validation loss = 2.5309  \n",
      "\n",
      "Fold: 1  Epoch: 587  Training loss = 2.8669  Validation loss = 2.5296  \n",
      "\n",
      "Fold: 1  Epoch: 588  Training loss = 2.8667  Validation loss = 2.5290  \n",
      "\n",
      "Fold: 1  Epoch: 589  Training loss = 2.8666  Validation loss = 2.5285  \n",
      "\n",
      "Fold: 1  Epoch: 590  Training loss = 2.8664  Validation loss = 2.5279  \n",
      "\n",
      "Fold: 1  Epoch: 591  Training loss = 2.8660  Validation loss = 2.5267  \n",
      "\n",
      "Fold: 1  Epoch: 592  Training loss = 2.8658  Validation loss = 2.5261  \n",
      "\n",
      "Fold: 1  Epoch: 593  Training loss = 2.8656  Validation loss = 2.5255  \n",
      "\n",
      "Fold: 1  Epoch: 594  Training loss = 2.8654  Validation loss = 2.5248  \n",
      "\n",
      "Fold: 1  Epoch: 595  Training loss = 2.8651  Validation loss = 2.5239  \n",
      "\n",
      "Fold: 1  Epoch: 596  Training loss = 2.8649  Validation loss = 2.5234  \n",
      "\n",
      "Fold: 1  Epoch: 597  Training loss = 2.8648  Validation loss = 2.5230  \n",
      "\n",
      "Fold: 1  Epoch: 598  Training loss = 2.8646  Validation loss = 2.5224  \n",
      "\n",
      "Fold: 1  Epoch: 599  Training loss = 2.8642  Validation loss = 2.5212  \n",
      "\n",
      "Fold: 1  Epoch: 600  Training loss = 2.8639  Validation loss = 2.5204  \n",
      "\n",
      "Fold: 1  Epoch: 601  Training loss = 2.8636  Validation loss = 2.5195  \n",
      "\n",
      "Fold: 1  Epoch: 602  Training loss = 2.8635  Validation loss = 2.5190  \n",
      "\n",
      "Fold: 1  Epoch: 603  Training loss = 2.8633  Validation loss = 2.5185  \n",
      "\n",
      "Fold: 1  Epoch: 604  Training loss = 2.8630  Validation loss = 2.5175  \n",
      "\n",
      "Fold: 1  Epoch: 605  Training loss = 2.8628  Validation loss = 2.5168  \n",
      "\n",
      "Fold: 1  Epoch: 606  Training loss = 2.8626  Validation loss = 2.5162  \n",
      "\n",
      "Fold: 1  Epoch: 607  Training loss = 2.8622  Validation loss = 2.5151  \n",
      "\n",
      "Fold: 1  Epoch: 608  Training loss = 2.8619  Validation loss = 2.5143  \n",
      "\n",
      "Fold: 1  Epoch: 609  Training loss = 2.8617  Validation loss = 2.5135  \n",
      "\n",
      "Fold: 1  Epoch: 610  Training loss = 2.8612  Validation loss = 2.5121  \n",
      "\n",
      "Fold: 1  Epoch: 611  Training loss = 2.8610  Validation loss = 2.5114  \n",
      "\n",
      "Fold: 1  Epoch: 612  Training loss = 2.8608  Validation loss = 2.5107  \n",
      "\n",
      "Fold: 1  Epoch: 613  Training loss = 2.8605  Validation loss = 2.5098  \n",
      "\n",
      "Fold: 1  Epoch: 614  Training loss = 2.8603  Validation loss = 2.5092  \n",
      "\n",
      "Fold: 1  Epoch: 615  Training loss = 2.8602  Validation loss = 2.5088  \n",
      "\n",
      "Fold: 1  Epoch: 616  Training loss = 2.8599  Validation loss = 2.5081  \n",
      "\n",
      "Fold: 1  Epoch: 617  Training loss = 2.8597  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 1  Epoch: 618  Training loss = 2.8592  Validation loss = 2.5058  \n",
      "\n",
      "Fold: 1  Epoch: 619  Training loss = 2.8589  Validation loss = 2.5050  \n",
      "\n",
      "Fold: 1  Epoch: 620  Training loss = 2.8585  Validation loss = 2.5038  \n",
      "\n",
      "Fold: 1  Epoch: 621  Training loss = 2.8584  Validation loss = 2.5034  \n",
      "\n",
      "Fold: 1  Epoch: 622  Training loss = 2.8580  Validation loss = 2.5022  \n",
      "\n",
      "Fold: 1  Epoch: 623  Training loss = 2.8579  Validation loss = 2.5017  \n",
      "\n",
      "Fold: 1  Epoch: 624  Training loss = 2.8576  Validation loss = 2.5010  \n",
      "\n",
      "Fold: 1  Epoch: 625  Training loss = 2.8574  Validation loss = 2.5002  \n",
      "\n",
      "Fold: 1  Epoch: 626  Training loss = 2.8571  Validation loss = 2.4993  \n",
      "\n",
      "Fold: 1  Epoch: 627  Training loss = 2.8568  Validation loss = 2.4984  \n",
      "\n",
      "Fold: 1  Epoch: 628  Training loss = 2.8565  Validation loss = 2.4973  \n",
      "\n",
      "Fold: 1  Epoch: 629  Training loss = 2.8562  Validation loss = 2.4966  \n",
      "\n",
      "Fold: 1  Epoch: 630  Training loss = 2.8560  Validation loss = 2.4959  \n",
      "\n",
      "Fold: 1  Epoch: 631  Training loss = 2.8558  Validation loss = 2.4951  \n",
      "\n",
      "Fold: 1  Epoch: 632  Training loss = 2.8556  Validation loss = 2.4946  \n",
      "\n",
      "Fold: 1  Epoch: 633  Training loss = 2.8554  Validation loss = 2.4940  \n",
      "\n",
      "Fold: 1  Epoch: 634  Training loss = 2.8551  Validation loss = 2.4931  \n",
      "\n",
      "Fold: 1  Epoch: 635  Training loss = 2.8545  Validation loss = 2.4912  \n",
      "\n",
      "Fold: 1  Epoch: 636  Training loss = 2.8543  Validation loss = 2.4905  \n",
      "\n",
      "Fold: 1  Epoch: 637  Training loss = 2.8541  Validation loss = 2.4899  \n",
      "\n",
      "Fold: 1  Epoch: 638  Training loss = 2.8540  Validation loss = 2.4894  \n",
      "\n",
      "Fold: 1  Epoch: 639  Training loss = 2.8537  Validation loss = 2.4886  \n",
      "\n",
      "Fold: 1  Epoch: 640  Training loss = 2.8535  Validation loss = 2.4879  \n",
      "\n",
      "Fold: 1  Epoch: 641  Training loss = 2.8530  Validation loss = 2.4865  \n",
      "\n",
      "Fold: 1  Epoch: 642  Training loss = 2.8529  Validation loss = 2.4859  \n",
      "\n",
      "Fold: 1  Epoch: 643  Training loss = 2.8528  Validation loss = 2.4856  \n",
      "\n",
      "Fold: 1  Epoch: 644  Training loss = 2.8525  Validation loss = 2.4850  \n",
      "\n",
      "Fold: 1  Epoch: 645  Training loss = 2.8522  Validation loss = 2.4838  \n",
      "\n",
      "Fold: 1  Epoch: 646  Training loss = 2.8520  Validation loss = 2.4833  \n",
      "\n",
      "Fold: 1  Epoch: 647  Training loss = 2.8518  Validation loss = 2.4826  \n",
      "\n",
      "Fold: 1  Epoch: 648  Training loss = 2.8514  Validation loss = 2.4814  \n",
      "\n",
      "Fold: 1  Epoch: 649  Training loss = 2.8512  Validation loss = 2.4806  \n",
      "\n",
      "Fold: 1  Epoch: 650  Training loss = 2.8509  Validation loss = 2.4797  \n",
      "\n",
      "Fold: 1  Epoch: 651  Training loss = 2.8507  Validation loss = 2.4790  \n",
      "\n",
      "Fold: 1  Epoch: 652  Training loss = 2.8505  Validation loss = 2.4785  \n",
      "\n",
      "Fold: 1  Epoch: 653  Training loss = 2.8502  Validation loss = 2.4774  \n",
      "\n",
      "Fold: 1  Epoch: 654  Training loss = 2.8499  Validation loss = 2.4767  \n",
      "\n",
      "Fold: 1  Epoch: 655  Training loss = 2.8498  Validation loss = 2.4762  \n",
      "\n",
      "Fold: 1  Epoch: 656  Training loss = 2.8495  Validation loss = 2.4755  \n",
      "\n",
      "Fold: 1  Epoch: 657  Training loss = 2.8492  Validation loss = 2.4745  \n",
      "\n",
      "Fold: 1  Epoch: 658  Training loss = 2.8490  Validation loss = 2.4736  \n",
      "\n",
      "Fold: 1  Epoch: 659  Training loss = 2.8487  Validation loss = 2.4729  \n",
      "\n",
      "Fold: 1  Epoch: 660  Training loss = 2.8484  Validation loss = 2.4718  \n",
      "\n",
      "Fold: 1  Epoch: 661  Training loss = 2.8482  Validation loss = 2.4710  \n",
      "\n",
      "Fold: 1  Epoch: 662  Training loss = 2.8480  Validation loss = 2.4704  \n",
      "\n",
      "Fold: 1  Epoch: 663  Training loss = 2.8478  Validation loss = 2.4697  \n",
      "\n",
      "Fold: 1  Epoch: 664  Training loss = 2.8475  Validation loss = 2.4690  \n",
      "\n",
      "Fold: 1  Epoch: 665  Training loss = 2.8473  Validation loss = 2.4684  \n",
      "\n",
      "Fold: 1  Epoch: 666  Training loss = 2.8471  Validation loss = 2.4676  \n",
      "\n",
      "Fold: 1  Epoch: 667  Training loss = 2.8469  Validation loss = 2.4668  \n",
      "\n",
      "Fold: 1  Epoch: 668  Training loss = 2.8468  Validation loss = 2.4666  \n",
      "\n",
      "Fold: 1  Epoch: 669  Training loss = 2.8466  Validation loss = 2.4658  \n",
      "\n",
      "Fold: 1  Epoch: 670  Training loss = 2.8464  Validation loss = 2.4652  \n",
      "\n",
      "Fold: 1  Epoch: 671  Training loss = 2.8461  Validation loss = 2.4645  \n",
      "\n",
      "Fold: 1  Epoch: 672  Training loss = 2.8458  Validation loss = 2.4634  \n",
      "\n",
      "Fold: 1  Epoch: 673  Training loss = 2.8456  Validation loss = 2.4626  \n",
      "\n",
      "Fold: 1  Epoch: 674  Training loss = 2.8453  Validation loss = 2.4617  \n",
      "\n",
      "Fold: 1  Epoch: 675  Training loss = 2.8451  Validation loss = 2.4611  \n",
      "\n",
      "Fold: 1  Epoch: 676  Training loss = 2.8448  Validation loss = 2.4603  \n",
      "\n",
      "Fold: 1  Epoch: 677  Training loss = 2.8445  Validation loss = 2.4592  \n",
      "\n",
      "Fold: 1  Epoch: 678  Training loss = 2.8443  Validation loss = 2.4584  \n",
      "\n",
      "Fold: 1  Epoch: 679  Training loss = 2.8441  Validation loss = 2.4579  \n",
      "\n",
      "Fold: 1  Epoch: 680  Training loss = 2.8438  Validation loss = 2.4568  \n",
      "\n",
      "Fold: 1  Epoch: 681  Training loss = 2.8437  Validation loss = 2.4565  \n",
      "\n",
      "Fold: 1  Epoch: 682  Training loss = 2.8434  Validation loss = 2.4557  \n",
      "\n",
      "Fold: 1  Epoch: 683  Training loss = 2.8433  Validation loss = 2.4551  \n",
      "\n",
      "Fold: 1  Epoch: 684  Training loss = 2.8430  Validation loss = 2.4543  \n",
      "\n",
      "Fold: 1  Epoch: 685  Training loss = 2.8428  Validation loss = 2.4536  \n",
      "\n",
      "Fold: 1  Epoch: 686  Training loss = 2.8426  Validation loss = 2.4529  \n",
      "\n",
      "Fold: 1  Epoch: 687  Training loss = 2.8424  Validation loss = 2.4523  \n",
      "\n",
      "Fold: 1  Epoch: 688  Training loss = 2.8422  Validation loss = 2.4517  \n",
      "\n",
      "Fold: 1  Epoch: 689  Training loss = 2.8418  Validation loss = 2.4505  \n",
      "\n",
      "Fold: 1  Epoch: 690  Training loss = 2.8417  Validation loss = 2.4499  \n",
      "\n",
      "Fold: 1  Epoch: 691  Training loss = 2.8415  Validation loss = 2.4494  \n",
      "\n",
      "Fold: 1  Epoch: 692  Training loss = 2.8413  Validation loss = 2.4487  \n",
      "\n",
      "Fold: 1  Epoch: 693  Training loss = 2.8411  Validation loss = 2.4481  \n",
      "\n",
      "Fold: 1  Epoch: 694  Training loss = 2.8409  Validation loss = 2.4474  \n",
      "\n",
      "Fold: 1  Epoch: 695  Training loss = 2.8407  Validation loss = 2.4469  \n",
      "\n",
      "Fold: 1  Epoch: 696  Training loss = 2.8404  Validation loss = 2.4459  \n",
      "\n",
      "Fold: 1  Epoch: 697  Training loss = 2.8401  Validation loss = 2.4449  \n",
      "\n",
      "Fold: 1  Epoch: 698  Training loss = 2.8399  Validation loss = 2.4443  \n",
      "\n",
      "Fold: 1  Epoch: 699  Training loss = 2.8396  Validation loss = 2.4432  \n",
      "\n",
      "Fold: 1  Epoch: 700  Training loss = 2.8394  Validation loss = 2.4427  \n",
      "\n",
      "Fold: 1  Epoch: 701  Training loss = 2.8392  Validation loss = 2.4420  \n",
      "\n",
      "Fold: 1  Epoch: 702  Training loss = 2.8389  Validation loss = 2.4410  \n",
      "\n",
      "Fold: 1  Epoch: 703  Training loss = 2.8388  Validation loss = 2.4405  \n",
      "\n",
      "Fold: 1  Epoch: 704  Training loss = 2.8385  Validation loss = 2.4396  \n",
      "\n",
      "Fold: 1  Epoch: 705  Training loss = 2.8382  Validation loss = 2.4385  \n",
      "\n",
      "Fold: 1  Epoch: 706  Training loss = 2.8381  Validation loss = 2.4382  \n",
      "\n",
      "Fold: 1  Epoch: 707  Training loss = 2.8378  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 1  Epoch: 708  Training loss = 2.8373  Validation loss = 2.4357  \n",
      "\n",
      "Fold: 1  Epoch: 709  Training loss = 2.8370  Validation loss = 2.4348  \n",
      "\n",
      "Fold: 1  Epoch: 710  Training loss = 2.8369  Validation loss = 2.4343  \n",
      "\n",
      "Fold: 1  Epoch: 711  Training loss = 2.8365  Validation loss = 2.4331  \n",
      "\n",
      "Fold: 1  Epoch: 712  Training loss = 2.8362  Validation loss = 2.4321  \n",
      "\n",
      "Fold: 1  Epoch: 713  Training loss = 2.8361  Validation loss = 2.4318  \n",
      "\n",
      "Fold: 1  Epoch: 714  Training loss = 2.8359  Validation loss = 2.4310  \n",
      "\n",
      "Fold: 1  Epoch: 715  Training loss = 2.8357  Validation loss = 2.4302  \n",
      "\n",
      "Fold: 1  Epoch: 716  Training loss = 2.8354  Validation loss = 2.4293  \n",
      "\n",
      "Fold: 1  Epoch: 717  Training loss = 2.8351  Validation loss = 2.4284  \n",
      "\n",
      "Fold: 1  Epoch: 718  Training loss = 2.8349  Validation loss = 2.4276  \n",
      "\n",
      "Fold: 1  Epoch: 719  Training loss = 2.8346  Validation loss = 2.4268  \n",
      "\n",
      "Fold: 1  Epoch: 720  Training loss = 2.8345  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 1  Epoch: 721  Training loss = 2.8342  Validation loss = 2.4256  \n",
      "\n",
      "Fold: 1  Epoch: 722  Training loss = 2.8340  Validation loss = 2.4246  \n",
      "\n",
      "Fold: 1  Epoch: 723  Training loss = 2.8336  Validation loss = 2.4235  \n",
      "\n",
      "Fold: 1  Epoch: 724  Training loss = 2.8335  Validation loss = 2.4229  \n",
      "\n",
      "Fold: 1  Epoch: 725  Training loss = 2.8332  Validation loss = 2.4221  \n",
      "\n",
      "Fold: 1  Epoch: 726  Training loss = 2.8329  Validation loss = 2.4208  \n",
      "\n",
      "Fold: 1  Epoch: 727  Training loss = 2.8327  Validation loss = 2.4204  \n",
      "\n",
      "Fold: 1  Epoch: 728  Training loss = 2.8326  Validation loss = 2.4201  \n",
      "\n",
      "Fold: 1  Epoch: 729  Training loss = 2.8324  Validation loss = 2.4193  \n",
      "\n",
      "Fold: 1  Epoch: 730  Training loss = 2.8323  Validation loss = 2.4188  \n",
      "\n",
      "Fold: 1  Epoch: 731  Training loss = 2.8320  Validation loss = 2.4180  \n",
      "\n",
      "Fold: 1  Epoch: 732  Training loss = 2.8319  Validation loss = 2.4176  \n",
      "\n",
      "Fold: 1  Epoch: 733  Training loss = 2.8317  Validation loss = 2.4169  \n",
      "\n",
      "Fold: 1  Epoch: 734  Training loss = 2.8314  Validation loss = 2.4159  \n",
      "\n",
      "Fold: 1  Epoch: 735  Training loss = 2.8313  Validation loss = 2.4157  \n",
      "\n",
      "Fold: 1  Epoch: 736  Training loss = 2.8312  Validation loss = 2.4153  \n",
      "\n",
      "Fold: 1  Epoch: 737  Training loss = 2.8308  Validation loss = 2.4140  \n",
      "\n",
      "Fold: 1  Epoch: 738  Training loss = 2.8307  Validation loss = 2.4134  \n",
      "\n",
      "Fold: 1  Epoch: 739  Training loss = 2.8303  Validation loss = 2.4123  \n",
      "\n",
      "Fold: 1  Epoch: 740  Training loss = 2.8301  Validation loss = 2.4114  \n",
      "\n",
      "Fold: 1  Epoch: 741  Training loss = 2.8299  Validation loss = 2.4107  \n",
      "\n",
      "Fold: 1  Epoch: 742  Training loss = 2.8297  Validation loss = 2.4102  \n",
      "\n",
      "Fold: 1  Epoch: 743  Training loss = 2.8296  Validation loss = 2.4099  \n",
      "\n",
      "Fold: 1  Epoch: 744  Training loss = 2.8296  Validation loss = 2.4097  \n",
      "\n",
      "Fold: 1  Epoch: 745  Training loss = 2.8293  Validation loss = 2.4088  \n",
      "\n",
      "Fold: 1  Epoch: 746  Training loss = 2.8290  Validation loss = 2.4078  \n",
      "\n",
      "Fold: 1  Epoch: 747  Training loss = 2.8287  Validation loss = 2.4069  \n",
      "\n",
      "Fold: 1  Epoch: 748  Training loss = 2.8286  Validation loss = 2.4064  \n",
      "\n",
      "Fold: 1  Epoch: 749  Training loss = 2.8284  Validation loss = 2.4057  \n",
      "\n",
      "Fold: 1  Epoch: 750  Training loss = 2.8280  Validation loss = 2.4044  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 750  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.7434  Validation loss = 2.7210  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.7432  Validation loss = 2.7205  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.7429  Validation loss = 2.7198  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.7427  Validation loss = 2.7191  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.7423  Validation loss = 2.7181  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.7421  Validation loss = 2.7176  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.7418  Validation loss = 2.7168  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.7415  Validation loss = 2.7164  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.7412  Validation loss = 2.7156  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.7409  Validation loss = 2.7150  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.7406  Validation loss = 2.7143  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.7402  Validation loss = 2.7134  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.7399  Validation loss = 2.7126  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.7397  Validation loss = 2.7120  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.7395  Validation loss = 2.7114  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.7392  Validation loss = 2.7106  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.7389  Validation loss = 2.7099  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.7386  Validation loss = 2.7093  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.7384  Validation loss = 2.7089  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.7382  Validation loss = 2.7084  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.7380  Validation loss = 2.7078  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.7378  Validation loss = 2.7072  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.7375  Validation loss = 2.7065  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.7370  Validation loss = 2.7054  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.7368  Validation loss = 2.7050  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.7365  Validation loss = 2.7043  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.7363  Validation loss = 2.7036  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.7362  Validation loss = 2.7033  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.7361  Validation loss = 2.7031  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.7359  Validation loss = 2.7025  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.7356  Validation loss = 2.7020  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.7355  Validation loss = 2.7017  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.7353  Validation loss = 2.7012  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.7351  Validation loss = 2.7006  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.7350  Validation loss = 2.7002  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.7348  Validation loss = 2.6996  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.7344  Validation loss = 2.6989  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.7343  Validation loss = 2.6984  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.7341  Validation loss = 2.6979  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.7339  Validation loss = 2.6974  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.7338  Validation loss = 2.6970  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.7335  Validation loss = 2.6964  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.7333  Validation loss = 2.6958  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.7330  Validation loss = 2.6952  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.7329  Validation loss = 2.6948  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.7326  Validation loss = 2.6940  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.7322  Validation loss = 2.6931  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.7320  Validation loss = 2.6928  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.7318  Validation loss = 2.6922  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.7314  Validation loss = 2.6911  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.7311  Validation loss = 2.6903  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.7307  Validation loss = 2.6896  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.7306  Validation loss = 2.6892  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.7303  Validation loss = 2.6883  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.7300  Validation loss = 2.6875  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.7298  Validation loss = 2.6870  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.7296  Validation loss = 2.6866  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.7293  Validation loss = 2.6857  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.7291  Validation loss = 2.6852  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.7290  Validation loss = 2.6849  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.7288  Validation loss = 2.6844  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.7286  Validation loss = 2.6838  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.7283  Validation loss = 2.6831  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.7282  Validation loss = 2.6828  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.7280  Validation loss = 2.6824  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.7278  Validation loss = 2.6818  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.7277  Validation loss = 2.6815  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.7275  Validation loss = 2.6809  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.7273  Validation loss = 2.6804  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.7270  Validation loss = 2.6795  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.7267  Validation loss = 2.6788  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.7264  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.7262  Validation loss = 2.6775  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.7260  Validation loss = 2.6769  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.7259  Validation loss = 2.6766  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.7256  Validation loss = 2.6757  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.7254  Validation loss = 2.6751  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.7251  Validation loss = 2.6743  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.7249  Validation loss = 2.6739  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.7248  Validation loss = 2.6735  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.7246  Validation loss = 2.6729  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.7243  Validation loss = 2.6720  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.7242  Validation loss = 2.6717  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.7240  Validation loss = 2.6713  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.7239  Validation loss = 2.6707  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.7237  Validation loss = 2.6703  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.7234  Validation loss = 2.6696  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.7232  Validation loss = 2.6690  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.7229  Validation loss = 2.6683  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.7227  Validation loss = 2.6678  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.7224  Validation loss = 2.6671  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.7221  Validation loss = 2.6663  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.7219  Validation loss = 2.6657  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.7217  Validation loss = 2.6650  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.7216  Validation loss = 2.6648  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.7214  Validation loss = 2.6643  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.7212  Validation loss = 2.6636  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.7209  Validation loss = 2.6630  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.7206  Validation loss = 2.6621  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.7203  Validation loss = 2.6614  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.7201  Validation loss = 2.6611  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.7199  Validation loss = 2.6605  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.7198  Validation loss = 2.6601  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.7197  Validation loss = 2.6598  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.7195  Validation loss = 2.6593  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.7193  Validation loss = 2.6589  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.7191  Validation loss = 2.6582  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.7189  Validation loss = 2.6576  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.7187  Validation loss = 2.6569  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.7185  Validation loss = 2.6564  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.7182  Validation loss = 2.6558  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.7180  Validation loss = 2.6552  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.7179  Validation loss = 2.6549  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.7177  Validation loss = 2.6543  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.7175  Validation loss = 2.6536  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.7171  Validation loss = 2.6526  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.7169  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.7166  Validation loss = 2.6515  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.7165  Validation loss = 2.6509  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.7162  Validation loss = 2.6503  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.7160  Validation loss = 2.6498  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.7156  Validation loss = 2.6489  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.7155  Validation loss = 2.6482  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.7152  Validation loss = 2.6474  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.7151  Validation loss = 2.6469  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.7148  Validation loss = 2.6461  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.7146  Validation loss = 2.6455  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.7142  Validation loss = 2.6446  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.7138  Validation loss = 2.6434  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.7135  Validation loss = 2.6428  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.7132  Validation loss = 2.6421  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.7130  Validation loss = 2.6415  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.7127  Validation loss = 2.6408  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.7125  Validation loss = 2.6400  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.7122  Validation loss = 2.6393  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.7119  Validation loss = 2.6387  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.7117  Validation loss = 2.6381  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.7114  Validation loss = 2.6376  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.7113  Validation loss = 2.6371  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.7110  Validation loss = 2.6363  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.7107  Validation loss = 2.6355  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.7103  Validation loss = 2.6347  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.7101  Validation loss = 2.6340  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.7099  Validation loss = 2.6334  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.7097  Validation loss = 2.6328  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.7095  Validation loss = 2.6323  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.7094  Validation loss = 2.6322  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.7093  Validation loss = 2.6316  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.7090  Validation loss = 2.6309  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.7089  Validation loss = 2.6303  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.7086  Validation loss = 2.6296  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.7084  Validation loss = 2.6290  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.7082  Validation loss = 2.6283  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.7081  Validation loss = 2.6279  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.7080  Validation loss = 2.6277  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.7078  Validation loss = 2.6270  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.7076  Validation loss = 2.6266  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.7073  Validation loss = 2.6258  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.7072  Validation loss = 2.6256  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.7071  Validation loss = 2.6251  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.7069  Validation loss = 2.6247  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.7066  Validation loss = 2.6240  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.7065  Validation loss = 2.6236  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.7062  Validation loss = 2.6227  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.7059  Validation loss = 2.6220  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.7057  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.7054  Validation loss = 2.6205  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.7053  Validation loss = 2.6203  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.7051  Validation loss = 2.6198  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.7050  Validation loss = 2.6194  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.7048  Validation loss = 2.6188  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.7046  Validation loss = 2.6184  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.7043  Validation loss = 2.6175  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.7041  Validation loss = 2.6169  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.7038  Validation loss = 2.6163  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.7036  Validation loss = 2.6155  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.7034  Validation loss = 2.6149  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.7033  Validation loss = 2.6145  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.7030  Validation loss = 2.6138  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.7028  Validation loss = 2.6131  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.7026  Validation loss = 2.6124  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.7024  Validation loss = 2.6119  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.7021  Validation loss = 2.6111  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.7019  Validation loss = 2.6104  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.7017  Validation loss = 2.6097  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.7014  Validation loss = 2.6089  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.7012  Validation loss = 2.6085  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.7010  Validation loss = 2.6079  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.7008  Validation loss = 2.6073  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.7008  Validation loss = 2.6071  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.7006  Validation loss = 2.6064  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.7003  Validation loss = 2.6058  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.7000  Validation loss = 2.6048  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.6999  Validation loss = 2.6045  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.6997  Validation loss = 2.6041  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.6995  Validation loss = 2.6036  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.6994  Validation loss = 2.6033  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.6993  Validation loss = 2.6028  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.6990  Validation loss = 2.6021  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.6987  Validation loss = 2.6012  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.6986  Validation loss = 2.6010  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.6983  Validation loss = 2.6002  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.6981  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.6979  Validation loss = 2.5991  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.6977  Validation loss = 2.5985  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.6975  Validation loss = 2.5979  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.6973  Validation loss = 2.5973  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.6971  Validation loss = 2.5967  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.6968  Validation loss = 2.5960  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.6967  Validation loss = 2.5956  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.6964  Validation loss = 2.5949  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.6962  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.6960  Validation loss = 2.5936  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.6959  Validation loss = 2.5933  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.6956  Validation loss = 2.5924  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.6954  Validation loss = 2.5917  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.6952  Validation loss = 2.5912  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.6950  Validation loss = 2.5905  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.6949  Validation loss = 2.5902  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.6947  Validation loss = 2.5895  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.6947  Validation loss = 2.5894  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.6945  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.6944  Validation loss = 2.5884  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.6942  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.6941  Validation loss = 2.5877  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.6940  Validation loss = 2.5873  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.6939  Validation loss = 2.5870  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.6938  Validation loss = 2.5868  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.6937  Validation loss = 2.5864  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.6935  Validation loss = 2.5860  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.6934  Validation loss = 2.5856  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.6931  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.6930  Validation loss = 2.5846  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.6928  Validation loss = 2.5839  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.6926  Validation loss = 2.5833  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.6924  Validation loss = 2.5830  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.6923  Validation loss = 2.5826  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.6920  Validation loss = 2.5818  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.6918  Validation loss = 2.5813  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.6916  Validation loss = 2.5807  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.6914  Validation loss = 2.5801  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.6913  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.6911  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.6908  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.6905  Validation loss = 2.5777  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.6905  Validation loss = 2.5776  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.6905  Validation loss = 2.5774  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.6903  Validation loss = 2.5771  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.6903  Validation loss = 2.5767  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.6901  Validation loss = 2.5761  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.6899  Validation loss = 2.5756  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.6898  Validation loss = 2.5751  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.6895  Validation loss = 2.5744  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.6894  Validation loss = 2.5737  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.6891  Validation loss = 2.5729  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.6889  Validation loss = 2.5724  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.6887  Validation loss = 2.5718  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.6885  Validation loss = 2.5713  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.6883  Validation loss = 2.5707  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.6881  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.6880  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.6877  Validation loss = 2.5693  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.6875  Validation loss = 2.5685  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.6873  Validation loss = 2.5682  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.6870  Validation loss = 2.5674  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.6868  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.6866  Validation loss = 2.5660  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.6864  Validation loss = 2.5655  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.6861  Validation loss = 2.5648  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.6859  Validation loss = 2.5641  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.6857  Validation loss = 2.5636  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.6855  Validation loss = 2.5630  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.6854  Validation loss = 2.5625  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.6853  Validation loss = 2.5623  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.6851  Validation loss = 2.5619  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.6850  Validation loss = 2.5615  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.6849  Validation loss = 2.5612  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.6848  Validation loss = 2.5604  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.6847  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.6846  Validation loss = 2.5598  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.6843  Validation loss = 2.5591  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.6843  Validation loss = 2.5590  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.6842  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.6841  Validation loss = 2.5583  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.6839  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.6837  Validation loss = 2.5569  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.6835  Validation loss = 2.5564  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.6834  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.6832  Validation loss = 2.5553  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.6829  Validation loss = 2.5545  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.6828  Validation loss = 2.5541  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.6827  Validation loss = 2.5538  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.6824  Validation loss = 2.5532  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.6823  Validation loss = 2.5527  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.6821  Validation loss = 2.5521  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.6818  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.6817  Validation loss = 2.5509  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.6814  Validation loss = 2.5503  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.6812  Validation loss = 2.5498  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.6811  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.6809  Validation loss = 2.5486  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.6809  Validation loss = 2.5486  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.6806  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.6804  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.6803  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.6803  Validation loss = 2.5466  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.6800  Validation loss = 2.5459  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.6799  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.6797  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.6796  Validation loss = 2.5446  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.6795  Validation loss = 2.5442  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.6792  Validation loss = 2.5434  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.6789  Validation loss = 2.5424  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.6786  Validation loss = 2.5417  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.6786  Validation loss = 2.5415  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.6785  Validation loss = 2.5412  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.6783  Validation loss = 2.5407  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.6780  Validation loss = 2.5399  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.6778  Validation loss = 2.5393  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.6777  Validation loss = 2.5390  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.6776  Validation loss = 2.5387  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.6774  Validation loss = 2.5379  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.6773  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.6772  Validation loss = 2.5374  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.6770  Validation loss = 2.5369  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.6769  Validation loss = 2.5365  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.6768  Validation loss = 2.5362  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.6765  Validation loss = 2.5356  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.6763  Validation loss = 2.5350  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.6762  Validation loss = 2.5347  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.6761  Validation loss = 2.5343  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.6759  Validation loss = 2.5338  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.6758  Validation loss = 2.5336  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.6757  Validation loss = 2.5330  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.6755  Validation loss = 2.5326  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.6753  Validation loss = 2.5321  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.6752  Validation loss = 2.5317  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.6751  Validation loss = 2.5314  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.6749  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.6746  Validation loss = 2.5299  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.6744  Validation loss = 2.5295  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.6744  Validation loss = 2.5291  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.6742  Validation loss = 2.5288  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.6739  Validation loss = 2.5280  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.6737  Validation loss = 2.5273  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.6735  Validation loss = 2.5266  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.6732  Validation loss = 2.5258  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.6732  Validation loss = 2.5255  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.6730  Validation loss = 2.5249  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.6729  Validation loss = 2.5246  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.6728  Validation loss = 2.5242  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.6725  Validation loss = 2.5236  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.6725  Validation loss = 2.5233  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.6724  Validation loss = 2.5230  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.6722  Validation loss = 2.5225  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.6719  Validation loss = 2.5217  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.6719  Validation loss = 2.5214  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.6716  Validation loss = 2.5207  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.6715  Validation loss = 2.5202  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.6713  Validation loss = 2.5198  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.6712  Validation loss = 2.5194  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.6711  Validation loss = 2.5189  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.6710  Validation loss = 2.5186  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.6708  Validation loss = 2.5179  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.6708  Validation loss = 2.5177  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.6706  Validation loss = 2.5171  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.6705  Validation loss = 2.5167  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.6703  Validation loss = 2.5158  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.6702  Validation loss = 2.5155  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.6702  Validation loss = 2.5154  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.6699  Validation loss = 2.5146  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.6698  Validation loss = 2.5143  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.6696  Validation loss = 2.5136  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.6695  Validation loss = 2.5133  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.6692  Validation loss = 2.5125  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.6691  Validation loss = 2.5119  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.6689  Validation loss = 2.5114  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.6687  Validation loss = 2.5109  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.6685  Validation loss = 2.5104  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.6683  Validation loss = 2.5096  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.6682  Validation loss = 2.5092  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.6681  Validation loss = 2.5088  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.6680  Validation loss = 2.5086  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.6678  Validation loss = 2.5078  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.6676  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.6675  Validation loss = 2.5068  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.6673  Validation loss = 2.5062  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.6671  Validation loss = 2.5056  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.6669  Validation loss = 2.5052  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.6667  Validation loss = 2.5044  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.6665  Validation loss = 2.5037  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.6662  Validation loss = 2.5027  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.6661  Validation loss = 2.5023  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.6659  Validation loss = 2.5017  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.6658  Validation loss = 2.5012  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.6656  Validation loss = 2.5006  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.6654  Validation loss = 2.5000  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.6653  Validation loss = 2.4997  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.6652  Validation loss = 2.4992  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.6650  Validation loss = 2.4987  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.6648  Validation loss = 2.4980  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.6647  Validation loss = 2.4978  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.6646  Validation loss = 2.4973  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.6644  Validation loss = 2.4968  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.6644  Validation loss = 2.4967  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.6641  Validation loss = 2.4958  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.6640  Validation loss = 2.4955  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.6639  Validation loss = 2.4951  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.6637  Validation loss = 2.4947  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.6635  Validation loss = 2.4941  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.6634  Validation loss = 2.4936  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.6633  Validation loss = 2.4932  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.6631  Validation loss = 2.4928  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.6630  Validation loss = 2.4921  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.6628  Validation loss = 2.4917  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.6626  Validation loss = 2.4910  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.6624  Validation loss = 2.4904  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.6623  Validation loss = 2.4899  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.6620  Validation loss = 2.4892  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.6620  Validation loss = 2.4889  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.6617  Validation loss = 2.4882  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.6616  Validation loss = 2.4877  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.6614  Validation loss = 2.4873  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.6614  Validation loss = 2.4871  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.6613  Validation loss = 2.4868  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.6613  Validation loss = 2.4868  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.6612  Validation loss = 2.4865  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.6611  Validation loss = 2.4861  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.6610  Validation loss = 2.4855  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.6610  Validation loss = 2.4855  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.6609  Validation loss = 2.4850  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.6607  Validation loss = 2.4846  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.6606  Validation loss = 2.4842  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.6605  Validation loss = 2.4839  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.6604  Validation loss = 2.4834  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.6603  Validation loss = 2.4831  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.6602  Validation loss = 2.4826  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.6602  Validation loss = 2.4824  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.6601  Validation loss = 2.4821  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.6599  Validation loss = 2.4816  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.6598  Validation loss = 2.4813  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.6597  Validation loss = 2.4810  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.6597  Validation loss = 2.4809  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.6595  Validation loss = 2.4803  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.6593  Validation loss = 2.4797  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.6593  Validation loss = 2.4794  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.6592  Validation loss = 2.4790  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.6590  Validation loss = 2.4785  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.6589  Validation loss = 2.4781  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.6588  Validation loss = 2.4779  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.6586  Validation loss = 2.4771  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.6585  Validation loss = 2.4765  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.6583  Validation loss = 2.4760  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.6581  Validation loss = 2.4754  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.6580  Validation loss = 2.4751  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.6579  Validation loss = 2.4747  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.6577  Validation loss = 2.4741  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.6577  Validation loss = 2.4740  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.6575  Validation loss = 2.4732  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.6575  Validation loss = 2.4730  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.6574  Validation loss = 2.4727  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.6573  Validation loss = 2.4724  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.6572  Validation loss = 2.4721  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.6570  Validation loss = 2.4716  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.6569  Validation loss = 2.4710  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.6569  Validation loss = 2.4709  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.6566  Validation loss = 2.4700  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.6565  Validation loss = 2.4696  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.6563  Validation loss = 2.4690  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.6561  Validation loss = 2.4685  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.6561  Validation loss = 2.4682  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.6560  Validation loss = 2.4679  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.6560  Validation loss = 2.4678  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.6559  Validation loss = 2.4673  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.6558  Validation loss = 2.4671  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.6558  Validation loss = 2.4670  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.6555  Validation loss = 2.4663  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.6554  Validation loss = 2.4659  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.6554  Validation loss = 2.4655  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.6552  Validation loss = 2.4651  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.6552  Validation loss = 2.4646  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.6550  Validation loss = 2.4641  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.6549  Validation loss = 2.4636  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.6547  Validation loss = 2.4630  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.6547  Validation loss = 2.4626  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.6546  Validation loss = 2.4621  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.6545  Validation loss = 2.4618  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.6544  Validation loss = 2.4615  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.6543  Validation loss = 2.4610  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.6543  Validation loss = 2.4609  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.6542  Validation loss = 2.4606  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.6541  Validation loss = 2.4603  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.6540  Validation loss = 2.4597  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.6539  Validation loss = 2.4593  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.6536  Validation loss = 2.4583  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.6535  Validation loss = 2.4580  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.6534  Validation loss = 2.4575  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.6532  Validation loss = 2.4569  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.6531  Validation loss = 2.4567  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.6530  Validation loss = 2.4563  \n",
      "\n",
      "Fold: 2  Epoch: 501  Training loss = 2.6529  Validation loss = 2.4557  \n",
      "\n",
      "Fold: 2  Epoch: 502  Training loss = 2.6527  Validation loss = 2.4551  \n",
      "\n",
      "Fold: 2  Epoch: 503  Training loss = 2.6525  Validation loss = 2.4545  \n",
      "\n",
      "Fold: 2  Epoch: 504  Training loss = 2.6525  Validation loss = 2.4543  \n",
      "\n",
      "Fold: 2  Epoch: 505  Training loss = 2.6524  Validation loss = 2.4541  \n",
      "\n",
      "Fold: 2  Epoch: 506  Training loss = 2.6524  Validation loss = 2.4538  \n",
      "\n",
      "Fold: 2  Epoch: 507  Training loss = 2.6523  Validation loss = 2.4535  \n",
      "\n",
      "Fold: 2  Epoch: 508  Training loss = 2.6522  Validation loss = 2.4531  \n",
      "\n",
      "Fold: 2  Epoch: 509  Training loss = 2.6521  Validation loss = 2.4528  \n",
      "\n",
      "Fold: 2  Epoch: 510  Training loss = 2.6520  Validation loss = 2.4525  \n",
      "\n",
      "Fold: 2  Epoch: 511  Training loss = 2.6519  Validation loss = 2.4521  \n",
      "\n",
      "Fold: 2  Epoch: 512  Training loss = 2.6519  Validation loss = 2.4519  \n",
      "\n",
      "Fold: 2  Epoch: 513  Training loss = 2.6517  Validation loss = 2.4513  \n",
      "\n",
      "Fold: 2  Epoch: 514  Training loss = 2.6517  Validation loss = 2.4512  \n",
      "\n",
      "Fold: 2  Epoch: 515  Training loss = 2.6515  Validation loss = 2.4505  \n",
      "\n",
      "Fold: 2  Epoch: 516  Training loss = 2.6514  Validation loss = 2.4502  \n",
      "\n",
      "Fold: 2  Epoch: 517  Training loss = 2.6513  Validation loss = 2.4498  \n",
      "\n",
      "Fold: 2  Epoch: 518  Training loss = 2.6512  Validation loss = 2.4494  \n",
      "\n",
      "Fold: 2  Epoch: 519  Training loss = 2.6511  Validation loss = 2.4491  \n",
      "\n",
      "Fold: 2  Epoch: 520  Training loss = 2.6509  Validation loss = 2.4486  \n",
      "\n",
      "Fold: 2  Epoch: 521  Training loss = 2.6508  Validation loss = 2.4484  \n",
      "\n",
      "Fold: 2  Epoch: 522  Training loss = 2.6508  Validation loss = 2.4483  \n",
      "\n",
      "Fold: 2  Epoch: 523  Training loss = 2.6508  Validation loss = 2.4481  \n",
      "\n",
      "Fold: 2  Epoch: 524  Training loss = 2.6508  Validation loss = 2.4479  \n",
      "\n",
      "Fold: 2  Epoch: 525  Training loss = 2.6507  Validation loss = 2.4477  \n",
      "\n",
      "Fold: 2  Epoch: 526  Training loss = 2.6504  Validation loss = 2.4468  \n",
      "\n",
      "Fold: 2  Epoch: 527  Training loss = 2.6503  Validation loss = 2.4465  \n",
      "\n",
      "Fold: 2  Epoch: 528  Training loss = 2.6502  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 2  Epoch: 529  Training loss = 2.6500  Validation loss = 2.4453  \n",
      "\n",
      "Fold: 2  Epoch: 530  Training loss = 2.6499  Validation loss = 2.4449  \n",
      "\n",
      "Fold: 2  Epoch: 531  Training loss = 2.6499  Validation loss = 2.4446  \n",
      "\n",
      "Fold: 2  Epoch: 532  Training loss = 2.6497  Validation loss = 2.4441  \n",
      "\n",
      "Fold: 2  Epoch: 533  Training loss = 2.6495  Validation loss = 2.4435  \n",
      "\n",
      "Fold: 2  Epoch: 534  Training loss = 2.6494  Validation loss = 2.4429  \n",
      "\n",
      "Fold: 2  Epoch: 535  Training loss = 2.6493  Validation loss = 2.4425  \n",
      "\n",
      "Fold: 2  Epoch: 536  Training loss = 2.6492  Validation loss = 2.4420  \n",
      "\n",
      "Fold: 2  Epoch: 537  Training loss = 2.6490  Validation loss = 2.4414  \n",
      "\n",
      "Fold: 2  Epoch: 538  Training loss = 2.6489  Validation loss = 2.4411  \n",
      "\n",
      "Fold: 2  Epoch: 539  Training loss = 2.6488  Validation loss = 2.4406  \n",
      "\n",
      "Fold: 2  Epoch: 540  Training loss = 2.6488  Validation loss = 2.4405  \n",
      "\n",
      "Fold: 2  Epoch: 541  Training loss = 2.6487  Validation loss = 2.4401  \n",
      "\n",
      "Fold: 2  Epoch: 542  Training loss = 2.6487  Validation loss = 2.4400  \n",
      "\n",
      "Fold: 2  Epoch: 543  Training loss = 2.6487  Validation loss = 2.4398  \n",
      "\n",
      "Fold: 2  Epoch: 544  Training loss = 2.6486  Validation loss = 2.4393  \n",
      "\n",
      "Fold: 2  Epoch: 545  Training loss = 2.6485  Validation loss = 2.4392  \n",
      "\n",
      "Fold: 2  Epoch: 546  Training loss = 2.6484  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 2  Epoch: 547  Training loss = 2.6483  Validation loss = 2.4384  \n",
      "\n",
      "Fold: 2  Epoch: 548  Training loss = 2.6481  Validation loss = 2.4378  \n",
      "\n",
      "Fold: 2  Epoch: 549  Training loss = 2.6480  Validation loss = 2.4375  \n",
      "\n",
      "Fold: 2  Epoch: 550  Training loss = 2.6480  Validation loss = 2.4374  \n",
      "\n",
      "Fold: 2  Epoch: 551  Training loss = 2.6479  Validation loss = 2.4370  \n",
      "\n",
      "Fold: 2  Epoch: 552  Training loss = 2.6478  Validation loss = 2.4365  \n",
      "\n",
      "Fold: 2  Epoch: 553  Training loss = 2.6476  Validation loss = 2.4361  \n",
      "\n",
      "Fold: 2  Epoch: 554  Training loss = 2.6474  Validation loss = 2.4355  \n",
      "\n",
      "Fold: 2  Epoch: 555  Training loss = 2.6473  Validation loss = 2.4349  \n",
      "\n",
      "Fold: 2  Epoch: 556  Training loss = 2.6471  Validation loss = 2.4344  \n",
      "\n",
      "Fold: 2  Epoch: 557  Training loss = 2.6470  Validation loss = 2.4340  \n",
      "\n",
      "Fold: 2  Epoch: 558  Training loss = 2.6469  Validation loss = 2.4337  \n",
      "\n",
      "Fold: 2  Epoch: 559  Training loss = 2.6468  Validation loss = 2.4332  \n",
      "\n",
      "Fold: 2  Epoch: 560  Training loss = 2.6467  Validation loss = 2.4327  \n",
      "\n",
      "Fold: 2  Epoch: 561  Training loss = 2.6465  Validation loss = 2.4320  \n",
      "\n",
      "Fold: 2  Epoch: 562  Training loss = 2.6465  Validation loss = 2.4318  \n",
      "\n",
      "Fold: 2  Epoch: 563  Training loss = 2.6463  Validation loss = 2.4313  \n",
      "\n",
      "Fold: 2  Epoch: 564  Training loss = 2.6462  Validation loss = 2.4308  \n",
      "\n",
      "Fold: 2  Epoch: 565  Training loss = 2.6460  Validation loss = 2.4303  \n",
      "\n",
      "Fold: 2  Epoch: 566  Training loss = 2.6460  Validation loss = 2.4299  \n",
      "\n",
      "Fold: 2  Epoch: 567  Training loss = 2.6458  Validation loss = 2.4294  \n",
      "\n",
      "Fold: 2  Epoch: 568  Training loss = 2.6457  Validation loss = 2.4291  \n",
      "\n",
      "Fold: 2  Epoch: 569  Training loss = 2.6457  Validation loss = 2.4288  \n",
      "\n",
      "Fold: 2  Epoch: 570  Training loss = 2.6456  Validation loss = 2.4285  \n",
      "\n",
      "Fold: 2  Epoch: 571  Training loss = 2.6455  Validation loss = 2.4280  \n",
      "\n",
      "Fold: 2  Epoch: 572  Training loss = 2.6453  Validation loss = 2.4275  \n",
      "\n",
      "Fold: 2  Epoch: 573  Training loss = 2.6451  Validation loss = 2.4269  \n",
      "\n",
      "Fold: 2  Epoch: 574  Training loss = 2.6451  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 2  Epoch: 575  Training loss = 2.6448  Validation loss = 2.4257  \n",
      "\n",
      "Fold: 2  Epoch: 576  Training loss = 2.6447  Validation loss = 2.4254  \n",
      "\n",
      "Fold: 2  Epoch: 577  Training loss = 2.6447  Validation loss = 2.4251  \n",
      "\n",
      "Fold: 2  Epoch: 578  Training loss = 2.6445  Validation loss = 2.4246  \n",
      "\n",
      "Fold: 2  Epoch: 579  Training loss = 2.6444  Validation loss = 2.4241  \n",
      "\n",
      "Fold: 2  Epoch: 580  Training loss = 2.6443  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 2  Epoch: 581  Training loss = 2.6441  Validation loss = 2.4231  \n",
      "\n",
      "Fold: 2  Epoch: 582  Training loss = 2.6441  Validation loss = 2.4229  \n",
      "\n",
      "Fold: 2  Epoch: 583  Training loss = 2.6440  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 2  Epoch: 584  Training loss = 2.6440  Validation loss = 2.4224  \n",
      "\n",
      "Fold: 2  Epoch: 585  Training loss = 2.6439  Validation loss = 2.4221  \n",
      "\n",
      "Fold: 2  Epoch: 586  Training loss = 2.6438  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 2  Epoch: 587  Training loss = 2.6437  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 2  Epoch: 588  Training loss = 2.6435  Validation loss = 2.4207  \n",
      "\n",
      "Fold: 2  Epoch: 589  Training loss = 2.6434  Validation loss = 2.4204  \n",
      "\n",
      "Fold: 2  Epoch: 590  Training loss = 2.6432  Validation loss = 2.4197  \n",
      "\n",
      "Fold: 2  Epoch: 591  Training loss = 2.6431  Validation loss = 2.4193  \n",
      "\n",
      "Fold: 2  Epoch: 592  Training loss = 2.6430  Validation loss = 2.4189  \n",
      "\n",
      "Fold: 2  Epoch: 593  Training loss = 2.6428  Validation loss = 2.4184  \n",
      "\n",
      "Fold: 2  Epoch: 594  Training loss = 2.6427  Validation loss = 2.4180  \n",
      "\n",
      "Fold: 2  Epoch: 595  Training loss = 2.6427  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 2  Epoch: 596  Training loss = 2.6427  Validation loss = 2.4175  \n",
      "\n",
      "Fold: 2  Epoch: 597  Training loss = 2.6426  Validation loss = 2.4174  \n",
      "\n",
      "Fold: 2  Epoch: 598  Training loss = 2.6425  Validation loss = 2.4169  \n",
      "\n",
      "Fold: 2  Epoch: 599  Training loss = 2.6424  Validation loss = 2.4166  \n",
      "\n",
      "Fold: 2  Epoch: 600  Training loss = 2.6423  Validation loss = 2.4163  \n",
      "\n",
      "Fold: 2  Epoch: 601  Training loss = 2.6423  Validation loss = 2.4159  \n",
      "\n",
      "Fold: 2  Epoch: 602  Training loss = 2.6421  Validation loss = 2.4153  \n",
      "\n",
      "Fold: 2  Epoch: 603  Training loss = 2.6420  Validation loss = 2.4150  \n",
      "\n",
      "Fold: 2  Epoch: 604  Training loss = 2.6419  Validation loss = 2.4145  \n",
      "\n",
      "Fold: 2  Epoch: 605  Training loss = 2.6417  Validation loss = 2.4139  \n",
      "\n",
      "Fold: 2  Epoch: 606  Training loss = 2.6417  Validation loss = 2.4136  \n",
      "\n",
      "Fold: 2  Epoch: 607  Training loss = 2.6416  Validation loss = 2.4134  \n",
      "\n",
      "Fold: 2  Epoch: 608  Training loss = 2.6416  Validation loss = 2.4132  \n",
      "\n",
      "Fold: 2  Epoch: 609  Training loss = 2.6415  Validation loss = 2.4127  \n",
      "\n",
      "Fold: 2  Epoch: 610  Training loss = 2.6413  Validation loss = 2.4123  \n",
      "\n",
      "Fold: 2  Epoch: 611  Training loss = 2.6413  Validation loss = 2.4121  \n",
      "\n",
      "Fold: 2  Epoch: 612  Training loss = 2.6412  Validation loss = 2.4116  \n",
      "\n",
      "Fold: 2  Epoch: 613  Training loss = 2.6411  Validation loss = 2.4113  \n",
      "\n",
      "Fold: 2  Epoch: 614  Training loss = 2.6410  Validation loss = 2.4106  \n",
      "\n",
      "Fold: 2  Epoch: 615  Training loss = 2.6409  Validation loss = 2.4101  \n",
      "\n",
      "Fold: 2  Epoch: 616  Training loss = 2.6407  Validation loss = 2.4096  \n",
      "\n",
      "Fold: 2  Epoch: 617  Training loss = 2.6406  Validation loss = 2.4091  \n",
      "\n",
      "Fold: 2  Epoch: 618  Training loss = 2.6405  Validation loss = 2.4088  \n",
      "\n",
      "Fold: 2  Epoch: 619  Training loss = 2.6404  Validation loss = 2.4085  \n",
      "\n",
      "Fold: 2  Epoch: 620  Training loss = 2.6403  Validation loss = 2.4083  \n",
      "\n",
      "Fold: 2  Epoch: 621  Training loss = 2.6402  Validation loss = 2.4078  \n",
      "\n",
      "Fold: 2  Epoch: 622  Training loss = 2.6402  Validation loss = 2.4075  \n",
      "\n",
      "Fold: 2  Epoch: 623  Training loss = 2.6401  Validation loss = 2.4073  \n",
      "\n",
      "Fold: 2  Epoch: 624  Training loss = 2.6400  Validation loss = 2.4069  \n",
      "\n",
      "Fold: 2  Epoch: 625  Training loss = 2.6400  Validation loss = 2.4067  \n",
      "\n",
      "Fold: 2  Epoch: 626  Training loss = 2.6400  Validation loss = 2.4066  \n",
      "\n",
      "Fold: 2  Epoch: 627  Training loss = 2.6399  Validation loss = 2.4061  \n",
      "\n",
      "Fold: 2  Epoch: 628  Training loss = 2.6398  Validation loss = 2.4058  \n",
      "\n",
      "Fold: 2  Epoch: 629  Training loss = 2.6395  Validation loss = 2.4050  \n",
      "\n",
      "Fold: 2  Epoch: 630  Training loss = 2.6395  Validation loss = 2.4046  \n",
      "\n",
      "Fold: 2  Epoch: 631  Training loss = 2.6394  Validation loss = 2.4043  \n",
      "\n",
      "Fold: 2  Epoch: 632  Training loss = 2.6392  Validation loss = 2.4037  \n",
      "\n",
      "Fold: 2  Epoch: 633  Training loss = 2.6392  Validation loss = 2.4035  \n",
      "\n",
      "Fold: 2  Epoch: 634  Training loss = 2.6392  Validation loss = 2.4036  \n",
      "\n",
      "Fold: 2  Epoch: 635  Training loss = 2.6392  Validation loss = 2.4033  \n",
      "\n",
      "Fold: 2  Epoch: 636  Training loss = 2.6391  Validation loss = 2.4032  \n",
      "\n",
      "Fold: 2  Epoch: 637  Training loss = 2.6390  Validation loss = 2.4028  \n",
      "\n",
      "Fold: 2  Epoch: 638  Training loss = 2.6390  Validation loss = 2.4024  \n",
      "\n",
      "Fold: 2  Epoch: 639  Training loss = 2.6389  Validation loss = 2.4023  \n",
      "\n",
      "Fold: 2  Epoch: 640  Training loss = 2.6389  Validation loss = 2.4020  \n",
      "\n",
      "Fold: 2  Epoch: 641  Training loss = 2.6386  Validation loss = 2.4011  \n",
      "\n",
      "Fold: 2  Epoch: 642  Training loss = 2.6385  Validation loss = 2.4004  \n",
      "\n",
      "Fold: 2  Epoch: 643  Training loss = 2.6383  Validation loss = 2.3998  \n",
      "\n",
      "Fold: 2  Epoch: 644  Training loss = 2.6383  Validation loss = 2.3996  \n",
      "\n",
      "Fold: 2  Epoch: 645  Training loss = 2.6382  Validation loss = 2.3993  \n",
      "\n",
      "Fold: 2  Epoch: 646  Training loss = 2.6382  Validation loss = 2.3990  \n",
      "\n",
      "Fold: 2  Epoch: 647  Training loss = 2.6380  Validation loss = 2.3983  \n",
      "\n",
      "Fold: 2  Epoch: 648  Training loss = 2.6380  Validation loss = 2.3980  \n",
      "\n",
      "Fold: 2  Epoch: 649  Training loss = 2.6377  Validation loss = 2.3970  \n",
      "\n",
      "Fold: 2  Epoch: 650  Training loss = 2.6376  Validation loss = 2.3967  \n",
      "\n",
      "Fold: 2  Epoch: 651  Training loss = 2.6375  Validation loss = 2.3962  \n",
      "\n",
      "Fold: 2  Epoch: 652  Training loss = 2.6374  Validation loss = 2.3959  \n",
      "\n",
      "Fold: 2  Epoch: 653  Training loss = 2.6373  Validation loss = 2.3955  \n",
      "\n",
      "Fold: 2  Epoch: 654  Training loss = 2.6372  Validation loss = 2.3950  \n",
      "\n",
      "Fold: 2  Epoch: 655  Training loss = 2.6371  Validation loss = 2.3947  \n",
      "\n",
      "Fold: 2  Epoch: 656  Training loss = 2.6371  Validation loss = 2.3944  \n",
      "\n",
      "Fold: 2  Epoch: 657  Training loss = 2.6369  Validation loss = 2.3938  \n",
      "\n",
      "Fold: 2  Epoch: 658  Training loss = 2.6369  Validation loss = 2.3937  \n",
      "\n",
      "Fold: 2  Epoch: 659  Training loss = 2.6368  Validation loss = 2.3934  \n",
      "\n",
      "Fold: 2  Epoch: 660  Training loss = 2.6367  Validation loss = 2.3928  \n",
      "\n",
      "Fold: 2  Epoch: 661  Training loss = 2.6367  Validation loss = 2.3927  \n",
      "\n",
      "Fold: 2  Epoch: 662  Training loss = 2.6366  Validation loss = 2.3922  \n",
      "\n",
      "Fold: 2  Epoch: 663  Training loss = 2.6364  Validation loss = 2.3917  \n",
      "\n",
      "Fold: 2  Epoch: 664  Training loss = 2.6363  Validation loss = 2.3912  \n",
      "\n",
      "Fold: 2  Epoch: 665  Training loss = 2.6362  Validation loss = 2.3911  \n",
      "\n",
      "Fold: 2  Epoch: 666  Training loss = 2.6362  Validation loss = 2.3910  \n",
      "\n",
      "Fold: 2  Epoch: 667  Training loss = 2.6361  Validation loss = 2.3906  \n",
      "\n",
      "Fold: 2  Epoch: 668  Training loss = 2.6361  Validation loss = 2.3902  \n",
      "\n",
      "Fold: 2  Epoch: 669  Training loss = 2.6360  Validation loss = 2.3898  \n",
      "\n",
      "Fold: 2  Epoch: 670  Training loss = 2.6359  Validation loss = 2.3894  \n",
      "\n",
      "Fold: 2  Epoch: 671  Training loss = 2.6359  Validation loss = 2.3891  \n",
      "\n",
      "Fold: 2  Epoch: 672  Training loss = 2.6358  Validation loss = 2.3887  \n",
      "\n",
      "Fold: 2  Epoch: 673  Training loss = 2.6356  Validation loss = 2.3882  \n",
      "\n",
      "Fold: 2  Epoch: 674  Training loss = 2.6355  Validation loss = 2.3877  \n",
      "\n",
      "Fold: 2  Epoch: 675  Training loss = 2.6354  Validation loss = 2.3873  \n",
      "\n",
      "Fold: 2  Epoch: 676  Training loss = 2.6352  Validation loss = 2.3868  \n",
      "\n",
      "Fold: 2  Epoch: 677  Training loss = 2.6352  Validation loss = 2.3864  \n",
      "\n",
      "Fold: 2  Epoch: 678  Training loss = 2.6351  Validation loss = 2.3862  \n",
      "\n",
      "Fold: 2  Epoch: 679  Training loss = 2.6351  Validation loss = 2.3859  \n",
      "\n",
      "Fold: 2  Epoch: 680  Training loss = 2.6349  Validation loss = 2.3853  \n",
      "\n",
      "Fold: 2  Epoch: 681  Training loss = 2.6349  Validation loss = 2.3851  \n",
      "\n",
      "Fold: 2  Epoch: 682  Training loss = 2.6348  Validation loss = 2.3847  \n",
      "\n",
      "Fold: 2  Epoch: 683  Training loss = 2.6346  Validation loss = 2.3843  \n",
      "\n",
      "Fold: 2  Epoch: 684  Training loss = 2.6346  Validation loss = 2.3839  \n",
      "\n",
      "Fold: 2  Epoch: 685  Training loss = 2.6345  Validation loss = 2.3834  \n",
      "\n",
      "Fold: 2  Epoch: 686  Training loss = 2.6344  Validation loss = 2.3830  \n",
      "\n",
      "Fold: 2  Epoch: 687  Training loss = 2.6342  Validation loss = 2.3824  \n",
      "\n",
      "Fold: 2  Epoch: 688  Training loss = 2.6340  Validation loss = 2.3816  \n",
      "\n",
      "Fold: 2  Epoch: 689  Training loss = 2.6338  Validation loss = 2.3811  \n",
      "\n",
      "Fold: 2  Epoch: 690  Training loss = 2.6338  Validation loss = 2.3809  \n",
      "\n",
      "Fold: 2  Epoch: 691  Training loss = 2.6337  Validation loss = 2.3805  \n",
      "\n",
      "Fold: 2  Epoch: 692  Training loss = 2.6337  Validation loss = 2.3803  \n",
      "\n",
      "Fold: 2  Epoch: 693  Training loss = 2.6336  Validation loss = 2.3798  \n",
      "\n",
      "Fold: 2  Epoch: 694  Training loss = 2.6334  Validation loss = 2.3792  \n",
      "\n",
      "Fold: 2  Epoch: 695  Training loss = 2.6333  Validation loss = 2.3788  \n",
      "\n",
      "Fold: 2  Epoch: 696  Training loss = 2.6331  Validation loss = 2.3780  \n",
      "\n",
      "Fold: 2  Epoch: 697  Training loss = 2.6330  Validation loss = 2.3775  \n",
      "\n",
      "Fold: 2  Epoch: 698  Training loss = 2.6329  Validation loss = 2.3772  \n",
      "\n",
      "Fold: 2  Epoch: 699  Training loss = 2.6329  Validation loss = 2.3770  \n",
      "\n",
      "Fold: 2  Epoch: 700  Training loss = 2.6328  Validation loss = 2.3768  \n",
      "\n",
      "Fold: 2  Epoch: 701  Training loss = 2.6328  Validation loss = 2.3768  \n",
      "\n",
      "Fold: 2  Epoch: 702  Training loss = 2.6328  Validation loss = 2.3766  \n",
      "\n",
      "Fold: 2  Epoch: 703  Training loss = 2.6326  Validation loss = 2.3758  \n",
      "\n",
      "Fold: 2  Epoch: 704  Training loss = 2.6324  Validation loss = 2.3753  \n",
      "\n",
      "Fold: 2  Epoch: 705  Training loss = 2.6323  Validation loss = 2.3749  \n",
      "\n",
      "Fold: 2  Epoch: 706  Training loss = 2.6323  Validation loss = 2.3748  \n",
      "\n",
      "Fold: 2  Epoch: 707  Training loss = 2.6322  Validation loss = 2.3745  \n",
      "\n",
      "Fold: 2  Epoch: 708  Training loss = 2.6321  Validation loss = 2.3742  \n",
      "\n",
      "Fold: 2  Epoch: 709  Training loss = 2.6320  Validation loss = 2.3737  \n",
      "\n",
      "Fold: 2  Epoch: 710  Training loss = 2.6320  Validation loss = 2.3737  \n",
      "\n",
      "Fold: 2  Epoch: 711  Training loss = 2.6319  Validation loss = 2.3732  \n",
      "\n",
      "Fold: 2  Epoch: 712  Training loss = 2.6318  Validation loss = 2.3730  \n",
      "\n",
      "Fold: 2  Epoch: 713  Training loss = 2.6319  Validation loss = 2.3731  \n",
      "\n",
      "Fold: 2  Epoch: 714  Training loss = 2.6317  Validation loss = 2.3727  \n",
      "\n",
      "Fold: 2  Epoch: 715  Training loss = 2.6318  Validation loss = 2.3727  \n",
      "\n",
      "Fold: 2  Epoch: 716  Training loss = 2.6318  Validation loss = 2.3726  \n",
      "\n",
      "Fold: 2  Epoch: 717  Training loss = 2.6316  Validation loss = 2.3722  \n",
      "\n",
      "Fold: 2  Epoch: 718  Training loss = 2.6316  Validation loss = 2.3721  \n",
      "\n",
      "Fold: 2  Epoch: 719  Training loss = 2.6314  Validation loss = 2.3713  \n",
      "\n",
      "Fold: 2  Epoch: 720  Training loss = 2.6314  Validation loss = 2.3710  \n",
      "\n",
      "Fold: 2  Epoch: 721  Training loss = 2.6312  Validation loss = 2.3704  \n",
      "\n",
      "Fold: 2  Epoch: 722  Training loss = 2.6311  Validation loss = 2.3700  \n",
      "\n",
      "Fold: 2  Epoch: 723  Training loss = 2.6310  Validation loss = 2.3695  \n",
      "\n",
      "Fold: 2  Epoch: 724  Training loss = 2.6309  Validation loss = 2.3689  \n",
      "\n",
      "Fold: 2  Epoch: 725  Training loss = 2.6308  Validation loss = 2.3685  \n",
      "\n",
      "Fold: 2  Epoch: 726  Training loss = 2.6307  Validation loss = 2.3682  \n",
      "\n",
      "Fold: 2  Epoch: 727  Training loss = 2.6306  Validation loss = 2.3677  \n",
      "\n",
      "Fold: 2  Epoch: 728  Training loss = 2.6305  Validation loss = 2.3676  \n",
      "\n",
      "Fold: 2  Epoch: 729  Training loss = 2.6305  Validation loss = 2.3673  \n",
      "\n",
      "Fold: 2  Epoch: 730  Training loss = 2.6304  Validation loss = 2.3672  \n",
      "\n",
      "Fold: 2  Epoch: 731  Training loss = 2.6303  Validation loss = 2.3668  \n",
      "\n",
      "Fold: 2  Epoch: 732  Training loss = 2.6302  Validation loss = 2.3664  \n",
      "\n",
      "Fold: 2  Epoch: 733  Training loss = 2.6300  Validation loss = 2.3656  \n",
      "\n",
      "Fold: 2  Epoch: 734  Training loss = 2.6300  Validation loss = 2.3653  \n",
      "\n",
      "Fold: 2  Epoch: 735  Training loss = 2.6298  Validation loss = 2.3648  \n",
      "\n",
      "Fold: 2  Epoch: 736  Training loss = 2.6297  Validation loss = 2.3645  \n",
      "\n",
      "Fold: 2  Epoch: 737  Training loss = 2.6296  Validation loss = 2.3638  \n",
      "\n",
      "Fold: 2  Epoch: 738  Training loss = 2.6294  Validation loss = 2.3629  \n",
      "\n",
      "Fold: 2  Epoch: 739  Training loss = 2.6293  Validation loss = 2.3623  \n",
      "\n",
      "Fold: 2  Epoch: 740  Training loss = 2.6292  Validation loss = 2.3621  \n",
      "\n",
      "Fold: 2  Epoch: 741  Training loss = 2.6291  Validation loss = 2.3615  \n",
      "\n",
      "Fold: 2  Epoch: 742  Training loss = 2.6290  Validation loss = 2.3612  \n",
      "\n",
      "Fold: 2  Epoch: 743  Training loss = 2.6289  Validation loss = 2.3608  \n",
      "\n",
      "Fold: 2  Epoch: 744  Training loss = 2.6287  Validation loss = 2.3603  \n",
      "\n",
      "Fold: 2  Epoch: 745  Training loss = 2.6287  Validation loss = 2.3600  \n",
      "\n",
      "Fold: 2  Epoch: 746  Training loss = 2.6286  Validation loss = 2.3595  \n",
      "\n",
      "Fold: 2  Epoch: 747  Training loss = 2.6285  Validation loss = 2.3590  \n",
      "\n",
      "Fold: 2  Epoch: 748  Training loss = 2.6284  Validation loss = 2.3588  \n",
      "\n",
      "Fold: 2  Epoch: 749  Training loss = 2.6283  Validation loss = 2.3584  \n",
      "\n",
      "Fold: 2  Epoch: 750  Training loss = 2.6283  Validation loss = 2.3583  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 750  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.5941  Validation loss = 3.2921  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.5940  Validation loss = 3.2918  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.5940  Validation loss = 3.2916  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.5939  Validation loss = 3.2911  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.5939  Validation loss = 3.2910  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.5937  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.5935  Validation loss = 3.2890  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.5933  Validation loss = 3.2878  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.5932  Validation loss = 3.2869  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.5931  Validation loss = 3.2864  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.5929  Validation loss = 3.2855  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.5929  Validation loss = 3.2856  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.5929  Validation loss = 3.2855  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.5928  Validation loss = 3.2846  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.5927  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.5925  Validation loss = 3.2830  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.5925  Validation loss = 3.2829  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.5923  Validation loss = 3.2818  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.5922  Validation loss = 3.2815  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.5922  Validation loss = 3.2812  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.5921  Validation loss = 3.2812  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.5920  Validation loss = 3.2805  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.5919  Validation loss = 3.2797  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.5918  Validation loss = 3.2793  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.5918  Validation loss = 3.2790  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.5918  Validation loss = 3.2790  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.5917  Validation loss = 3.2785  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.5916  Validation loss = 3.2782  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.5916  Validation loss = 3.2779  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.5915  Validation loss = 3.2775  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.5914  Validation loss = 3.2768  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.5912  Validation loss = 3.2761  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.5911  Validation loss = 3.2754  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.5911  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.5910  Validation loss = 3.2746  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.5908  Validation loss = 3.2738  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.5908  Validation loss = 3.2732  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.5907  Validation loss = 3.2725  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.5906  Validation loss = 3.2720  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.5904  Validation loss = 3.2711  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.5903  Validation loss = 3.2702  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.5902  Validation loss = 3.2697  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.5901  Validation loss = 3.2690  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.5899  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.5898  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.5897  Validation loss = 3.2667  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.5896  Validation loss = 3.2662  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.5895  Validation loss = 3.2658  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.5895  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.5893  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.5893  Validation loss = 3.2643  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.5891  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.5890  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.5889  Validation loss = 3.2619  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.5889  Validation loss = 3.2621  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.5888  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.5887  Validation loss = 3.2609  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.5885  Validation loss = 3.2602  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.5884  Validation loss = 3.2597  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.5883  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.5883  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.5882  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.5881  Validation loss = 3.2576  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.5881  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.5880  Validation loss = 3.2571  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.5878  Validation loss = 3.2561  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.5878  Validation loss = 3.2556  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.5877  Validation loss = 3.2555  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.5876  Validation loss = 3.2548  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.5876  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.5875  Validation loss = 3.2540  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.5874  Validation loss = 3.2532  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.5873  Validation loss = 3.2525  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.5871  Validation loss = 3.2514  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.5870  Validation loss = 3.2508  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.5869  Validation loss = 3.2503  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.5868  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.5866  Validation loss = 3.2486  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.5865  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.5864  Validation loss = 3.2474  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.5863  Validation loss = 3.2470  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.5863  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.5861  Validation loss = 3.2456  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.5860  Validation loss = 3.2449  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.5860  Validation loss = 3.2448  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.5859  Validation loss = 3.2447  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.5859  Validation loss = 3.2444  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.5858  Validation loss = 3.2438  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.5857  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.5857  Validation loss = 3.2432  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.5856  Validation loss = 3.2430  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.5855  Validation loss = 3.2422  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.5854  Validation loss = 3.2420  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.5853  Validation loss = 3.2413  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.5852  Validation loss = 3.2406  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.5850  Validation loss = 3.2396  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.5849  Validation loss = 3.2391  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.5848  Validation loss = 3.2386  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.5847  Validation loss = 3.2377  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.5847  Validation loss = 3.2376  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.5847  Validation loss = 3.2376  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.5846  Validation loss = 3.2375  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.5846  Validation loss = 3.2372  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.5844  Validation loss = 3.2362  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.5843  Validation loss = 3.2360  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.5843  Validation loss = 3.2355  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.5842  Validation loss = 3.2349  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.5841  Validation loss = 3.2346  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.5841  Validation loss = 3.2344  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.5841  Validation loss = 3.2343  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.5840  Validation loss = 3.2341  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.5839  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.5839  Validation loss = 3.2333  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.5837  Validation loss = 3.2325  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.5837  Validation loss = 3.2321  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.5835  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.5835  Validation loss = 3.2312  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.5835  Validation loss = 3.2312  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.5834  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.5833  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.5832  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.5832  Validation loss = 3.2292  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.5831  Validation loss = 3.2288  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.5830  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.5829  Validation loss = 3.2276  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.5828  Validation loss = 3.2267  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.5827  Validation loss = 3.2263  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.5826  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.5825  Validation loss = 3.2254  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.5824  Validation loss = 3.2248  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.5824  Validation loss = 3.2245  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.5824  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.5823  Validation loss = 3.2243  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.5823  Validation loss = 3.2242  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.5821  Validation loss = 3.2232  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.5821  Validation loss = 3.2229  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.5819  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.5818  Validation loss = 3.2215  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.5817  Validation loss = 3.2208  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.5817  Validation loss = 3.2205  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.5816  Validation loss = 3.2199  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.5816  Validation loss = 3.2199  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.5815  Validation loss = 3.2195  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.5814  Validation loss = 3.2191  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.5814  Validation loss = 3.2190  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.5814  Validation loss = 3.2189  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.5813  Validation loss = 3.2187  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.5812  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.5811  Validation loss = 3.2177  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.5811  Validation loss = 3.2177  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.5811  Validation loss = 3.2173  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.5810  Validation loss = 3.2166  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.5809  Validation loss = 3.2162  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.5808  Validation loss = 3.2159  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.5808  Validation loss = 3.2158  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.5808  Validation loss = 3.2156  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.5807  Validation loss = 3.2154  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.5807  Validation loss = 3.2151  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.5806  Validation loss = 3.2143  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.5805  Validation loss = 3.2138  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.5804  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.5804  Validation loss = 3.2130  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.5803  Validation loss = 3.2126  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.5802  Validation loss = 3.2122  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.5802  Validation loss = 3.2119  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.5801  Validation loss = 3.2115  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.5800  Validation loss = 3.2107  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.5799  Validation loss = 3.2105  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.5799  Validation loss = 3.2101  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.5798  Validation loss = 3.2096  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.5798  Validation loss = 3.2097  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.5797  Validation loss = 3.2092  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.5796  Validation loss = 3.2088  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.5796  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.5795  Validation loss = 3.2080  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.5795  Validation loss = 3.2081  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.5793  Validation loss = 3.2073  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.5792  Validation loss = 3.2066  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.5792  Validation loss = 3.2064  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.5791  Validation loss = 3.2060  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.5790  Validation loss = 3.2054  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.5789  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.5788  Validation loss = 3.2046  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.5788  Validation loss = 3.2043  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.5787  Validation loss = 3.2039  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.5786  Validation loss = 3.2036  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.5786  Validation loss = 3.2033  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.5785  Validation loss = 3.2027  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.5784  Validation loss = 3.2021  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.5783  Validation loss = 3.2016  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.5783  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.5781  Validation loss = 3.2006  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.5780  Validation loss = 3.2001  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.5780  Validation loss = 3.1998  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.5779  Validation loss = 3.1996  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.5779  Validation loss = 3.1993  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.5779  Validation loss = 3.1994  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.5778  Validation loss = 3.1988  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.5777  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.5777  Validation loss = 3.1981  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.5775  Validation loss = 3.1972  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.5775  Validation loss = 3.1969  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.5774  Validation loss = 3.1962  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.5773  Validation loss = 3.1962  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.5773  Validation loss = 3.1958  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.5772  Validation loss = 3.1955  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.5772  Validation loss = 3.1951  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.5771  Validation loss = 3.1951  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.5771  Validation loss = 3.1953  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.5771  Validation loss = 3.1950  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.5770  Validation loss = 3.1946  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.5770  Validation loss = 3.1944  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.5768  Validation loss = 3.1936  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.5768  Validation loss = 3.1934  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.5767  Validation loss = 3.1931  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.5767  Validation loss = 3.1927  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.5766  Validation loss = 3.1922  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.5765  Validation loss = 3.1918  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.5764  Validation loss = 3.1915  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.5763  Validation loss = 3.1908  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.5763  Validation loss = 3.1906  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.5762  Validation loss = 3.1902  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.5762  Validation loss = 3.1901  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.5761  Validation loss = 3.1898  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.5761  Validation loss = 3.1895  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.5759  Validation loss = 3.1887  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.5759  Validation loss = 3.1884  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.5759  Validation loss = 3.1883  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.5758  Validation loss = 3.1880  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.5758  Validation loss = 3.1878  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.5757  Validation loss = 3.1875  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.5756  Validation loss = 3.1872  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.5756  Validation loss = 3.1867  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.5755  Validation loss = 3.1858  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.5754  Validation loss = 3.1853  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.5753  Validation loss = 3.1849  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.5752  Validation loss = 3.1845  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.5751  Validation loss = 3.1838  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.5751  Validation loss = 3.1834  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.5750  Validation loss = 3.1827  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.5749  Validation loss = 3.1824  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.5748  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.5747  Validation loss = 3.1812  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.5746  Validation loss = 3.1804  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.5745  Validation loss = 3.1800  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.5745  Validation loss = 3.1797  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.5744  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.5744  Validation loss = 3.1792  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.5743  Validation loss = 3.1789  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.5742  Validation loss = 3.1785  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.5742  Validation loss = 3.1780  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.5741  Validation loss = 3.1777  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.5740  Validation loss = 3.1773  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.5739  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.5739  Validation loss = 3.1763  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.5738  Validation loss = 3.1759  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.5737  Validation loss = 3.1752  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.5736  Validation loss = 3.1750  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.5736  Validation loss = 3.1748  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.5736  Validation loss = 3.1747  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.5735  Validation loss = 3.1742  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.5734  Validation loss = 3.1740  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.5733  Validation loss = 3.1736  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.5733  Validation loss = 3.1736  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.5732  Validation loss = 3.1731  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.5732  Validation loss = 3.1730  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.5732  Validation loss = 3.1729  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.5731  Validation loss = 3.1727  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.5731  Validation loss = 3.1724  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.5730  Validation loss = 3.1719  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.5729  Validation loss = 3.1713  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.5729  Validation loss = 3.1711  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.5728  Validation loss = 3.1710  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.5727  Validation loss = 3.1702  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.5726  Validation loss = 3.1695  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.5725  Validation loss = 3.1688  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.5725  Validation loss = 3.1685  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.5724  Validation loss = 3.1684  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.5724  Validation loss = 3.1680  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.5723  Validation loss = 3.1676  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.5723  Validation loss = 3.1675  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.5723  Validation loss = 3.1673  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.5722  Validation loss = 3.1672  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.5721  Validation loss = 3.1664  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.5721  Validation loss = 3.1663  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.5720  Validation loss = 3.1660  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.5720  Validation loss = 3.1657  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.5719  Validation loss = 3.1655  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.5719  Validation loss = 3.1654  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.5718  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.5718  Validation loss = 3.1649  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.5717  Validation loss = 3.1642  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.5717  Validation loss = 3.1643  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.5716  Validation loss = 3.1641  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.5716  Validation loss = 3.1640  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.5715  Validation loss = 3.1637  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.5714  Validation loss = 3.1632  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.5714  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.5713  Validation loss = 3.1625  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.5712  Validation loss = 3.1620  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.5712  Validation loss = 3.1617  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.5711  Validation loss = 3.1611  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.5710  Validation loss = 3.1603  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.5710  Validation loss = 3.1600  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.5709  Validation loss = 3.1594  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.5708  Validation loss = 3.1593  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.5708  Validation loss = 3.1589  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.5707  Validation loss = 3.1585  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.5707  Validation loss = 3.1584  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.5706  Validation loss = 3.1581  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.5706  Validation loss = 3.1578  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.5705  Validation loss = 3.1574  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.5704  Validation loss = 3.1569  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.5704  Validation loss = 3.1570  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.5704  Validation loss = 3.1565  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.5703  Validation loss = 3.1563  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.5703  Validation loss = 3.1557  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.5702  Validation loss = 3.1554  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.5702  Validation loss = 3.1555  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.5701  Validation loss = 3.1550  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.5701  Validation loss = 3.1547  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.5700  Validation loss = 3.1543  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.5699  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.5699  Validation loss = 3.1539  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.5698  Validation loss = 3.1534  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.5698  Validation loss = 3.1531  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.5697  Validation loss = 3.1527  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.5697  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.5697  Validation loss = 3.1523  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.5696  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.5697  Validation loss = 3.1528  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.5696  Validation loss = 3.1525  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.5696  Validation loss = 3.1521  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.5695  Validation loss = 3.1521  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.5695  Validation loss = 3.1519  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.5694  Validation loss = 3.1515  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.5694  Validation loss = 3.1513  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.5693  Validation loss = 3.1505  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.5692  Validation loss = 3.1503  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.5692  Validation loss = 3.1500  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.5691  Validation loss = 3.1495  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.5690  Validation loss = 3.1490  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.5690  Validation loss = 3.1488  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.5689  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.5688  Validation loss = 3.1476  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.5688  Validation loss = 3.1475  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.5688  Validation loss = 3.1474  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.5687  Validation loss = 3.1468  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.5686  Validation loss = 3.1464  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.5686  Validation loss = 3.1464  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.5685  Validation loss = 3.1460  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.5685  Validation loss = 3.1458  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.5684  Validation loss = 3.1453  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.5684  Validation loss = 3.1451  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.5683  Validation loss = 3.1446  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.5682  Validation loss = 3.1442  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.5682  Validation loss = 3.1441  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.5682  Validation loss = 3.1441  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.5681  Validation loss = 3.1442  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.5680  Validation loss = 3.1436  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.5680  Validation loss = 3.1435  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.5680  Validation loss = 3.1432  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.5679  Validation loss = 3.1428  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.5679  Validation loss = 3.1427  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.5679  Validation loss = 3.1424  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.5678  Validation loss = 3.1419  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.5677  Validation loss = 3.1414  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.5676  Validation loss = 3.1411  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.5675  Validation loss = 3.1405  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.5675  Validation loss = 3.1402  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.5674  Validation loss = 3.1397  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.5674  Validation loss = 3.1394  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.5673  Validation loss = 3.1392  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.5673  Validation loss = 3.1391  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.5672  Validation loss = 3.1389  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.5672  Validation loss = 3.1385  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.5671  Validation loss = 3.1380  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.5671  Validation loss = 3.1378  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.5670  Validation loss = 3.1376  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.5669  Validation loss = 3.1367  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.5668  Validation loss = 3.1362  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.5668  Validation loss = 3.1361  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.5667  Validation loss = 3.1360  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.5667  Validation loss = 3.1354  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.5666  Validation loss = 3.1348  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.5665  Validation loss = 3.1345  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.5664  Validation loss = 3.1341  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.5664  Validation loss = 3.1341  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.5663  Validation loss = 3.1336  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.5663  Validation loss = 3.1329  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.5662  Validation loss = 3.1329  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.5662  Validation loss = 3.1324  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.5661  Validation loss = 3.1322  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.5661  Validation loss = 3.1322  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.5660  Validation loss = 3.1320  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.5660  Validation loss = 3.1317  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.5660  Validation loss = 3.1316  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.5659  Validation loss = 3.1315  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.5659  Validation loss = 3.1309  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.5657  Validation loss = 3.1299  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.5657  Validation loss = 3.1295  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.5656  Validation loss = 3.1296  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.5656  Validation loss = 3.1291  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.5655  Validation loss = 3.1291  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.5655  Validation loss = 3.1286  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.5654  Validation loss = 3.1284  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.5654  Validation loss = 3.1284  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.5653  Validation loss = 3.1279  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.5653  Validation loss = 3.1278  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.5652  Validation loss = 3.1276  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.5651  Validation loss = 3.1269  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.5651  Validation loss = 3.1269  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.5651  Validation loss = 3.1265  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.5650  Validation loss = 3.1261  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.5649  Validation loss = 3.1257  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.5649  Validation loss = 3.1253  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.5648  Validation loss = 3.1249  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.5647  Validation loss = 3.1244  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.5647  Validation loss = 3.1243  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.5647  Validation loss = 3.1239  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.5646  Validation loss = 3.1235  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.5645  Validation loss = 3.1232  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.5645  Validation loss = 3.1229  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.5644  Validation loss = 3.1226  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.5643  Validation loss = 3.1220  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.5643  Validation loss = 3.1216  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.5642  Validation loss = 3.1214  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.5642  Validation loss = 3.1211  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.5641  Validation loss = 3.1207  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.5641  Validation loss = 3.1207  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.5641  Validation loss = 3.1207  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.5640  Validation loss = 3.1203  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.5640  Validation loss = 3.1202  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.5639  Validation loss = 3.1198  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.5639  Validation loss = 3.1192  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.5638  Validation loss = 3.1191  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.5638  Validation loss = 3.1188  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.5637  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.5637  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.5636  Validation loss = 3.1180  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.5636  Validation loss = 3.1179  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.5635  Validation loss = 3.1178  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.5635  Validation loss = 3.1176  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.5635  Validation loss = 3.1177  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.5634  Validation loss = 3.1174  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.5634  Validation loss = 3.1171  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.5633  Validation loss = 3.1166  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.5632  Validation loss = 3.1164  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.5632  Validation loss = 3.1161  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.5631  Validation loss = 3.1160  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.5631  Validation loss = 3.1160  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.5630  Validation loss = 3.1159  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.5630  Validation loss = 3.1159  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.5630  Validation loss = 3.1157  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.5629  Validation loss = 3.1156  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.5629  Validation loss = 3.1153  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.5629  Validation loss = 3.1153  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.5628  Validation loss = 3.1150  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.5628  Validation loss = 3.1146  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.5627  Validation loss = 3.1142  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.5627  Validation loss = 3.1142  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.5626  Validation loss = 3.1141  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.5626  Validation loss = 3.1138  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.5626  Validation loss = 3.1136  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.5625  Validation loss = 3.1130  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.5625  Validation loss = 3.1129  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.5624  Validation loss = 3.1128  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.5624  Validation loss = 3.1126  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.5624  Validation loss = 3.1127  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.5623  Validation loss = 3.1123  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.5622  Validation loss = 3.1121  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.5622  Validation loss = 3.1118  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.5621  Validation loss = 3.1116  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.5621  Validation loss = 3.1113  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.5620  Validation loss = 3.1109  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.5620  Validation loss = 3.1108  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.5619  Validation loss = 3.1105  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.5618  Validation loss = 3.1104  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.5618  Validation loss = 3.1101  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.5617  Validation loss = 3.1098  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.5617  Validation loss = 3.1094  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.5616  Validation loss = 3.1091  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.5616  Validation loss = 3.1092  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.5616  Validation loss = 3.1093  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.5616  Validation loss = 3.1092  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.5615  Validation loss = 3.1090  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.5615  Validation loss = 3.1087  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.5614  Validation loss = 3.1085  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.5614  Validation loss = 3.1082  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.5614  Validation loss = 3.1085  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.5614  Validation loss = 3.1082  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.5613  Validation loss = 3.1079  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.5613  Validation loss = 3.1078  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.5612  Validation loss = 3.1072  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.5611  Validation loss = 3.1068  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.5611  Validation loss = 3.1066  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.5610  Validation loss = 3.1064  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.5610  Validation loss = 3.1059  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.5610  Validation loss = 3.1058  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.5609  Validation loss = 3.1057  \n",
      "\n",
      "Fold: 3  Epoch: 501  Training loss = 1.5608  Validation loss = 3.1051  \n",
      "\n",
      "Fold: 3  Epoch: 502  Training loss = 1.5608  Validation loss = 3.1047  \n",
      "\n",
      "Fold: 3  Epoch: 503  Training loss = 1.5608  Validation loss = 3.1045  \n",
      "\n",
      "Fold: 3  Epoch: 504  Training loss = 1.5607  Validation loss = 3.1042  \n",
      "\n",
      "Fold: 3  Epoch: 505  Training loss = 1.5607  Validation loss = 3.1040  \n",
      "\n",
      "Fold: 3  Epoch: 506  Training loss = 1.5606  Validation loss = 3.1036  \n",
      "\n",
      "Fold: 3  Epoch: 507  Training loss = 1.5605  Validation loss = 3.1033  \n",
      "\n",
      "Fold: 3  Epoch: 508  Training loss = 1.5605  Validation loss = 3.1030  \n",
      "\n",
      "Fold: 3  Epoch: 509  Training loss = 1.5604  Validation loss = 3.1028  \n",
      "\n",
      "Fold: 3  Epoch: 510  Training loss = 1.5604  Validation loss = 3.1025  \n",
      "\n",
      "Fold: 3  Epoch: 511  Training loss = 1.5603  Validation loss = 3.1023  \n",
      "\n",
      "Fold: 3  Epoch: 512  Training loss = 1.5603  Validation loss = 3.1019  \n",
      "\n",
      "Fold: 3  Epoch: 513  Training loss = 1.5602  Validation loss = 3.1018  \n",
      "\n",
      "Fold: 3  Epoch: 514  Training loss = 1.5602  Validation loss = 3.1014  \n",
      "\n",
      "Fold: 3  Epoch: 515  Training loss = 1.5601  Validation loss = 3.1014  \n",
      "\n",
      "Fold: 3  Epoch: 516  Training loss = 1.5601  Validation loss = 3.1011  \n",
      "\n",
      "Fold: 3  Epoch: 517  Training loss = 1.5600  Validation loss = 3.1007  \n",
      "\n",
      "Fold: 3  Epoch: 518  Training loss = 1.5600  Validation loss = 3.1006  \n",
      "\n",
      "Fold: 3  Epoch: 519  Training loss = 1.5599  Validation loss = 3.1004  \n",
      "\n",
      "Fold: 3  Epoch: 520  Training loss = 1.5599  Validation loss = 3.1001  \n",
      "\n",
      "Fold: 3  Epoch: 521  Training loss = 1.5598  Validation loss = 3.1002  \n",
      "\n",
      "Fold: 3  Epoch: 522  Training loss = 1.5598  Validation loss = 3.0998  \n",
      "\n",
      "Fold: 3  Epoch: 523  Training loss = 1.5597  Validation loss = 3.0993  \n",
      "\n",
      "Fold: 3  Epoch: 524  Training loss = 1.5596  Validation loss = 3.0988  \n",
      "\n",
      "Fold: 3  Epoch: 525  Training loss = 1.5596  Validation loss = 3.0990  \n",
      "\n",
      "Fold: 3  Epoch: 526  Training loss = 1.5596  Validation loss = 3.0990  \n",
      "\n",
      "Fold: 3  Epoch: 527  Training loss = 1.5596  Validation loss = 3.0991  \n",
      "\n",
      "Fold: 3  Epoch: 528  Training loss = 1.5595  Validation loss = 3.0988  \n",
      "\n",
      "Fold: 3  Epoch: 529  Training loss = 1.5595  Validation loss = 3.0986  \n",
      "\n",
      "Fold: 3  Epoch: 530  Training loss = 1.5594  Validation loss = 3.0983  \n",
      "\n",
      "Fold: 3  Epoch: 531  Training loss = 1.5594  Validation loss = 3.0981  \n",
      "\n",
      "Fold: 3  Epoch: 532  Training loss = 1.5594  Validation loss = 3.0981  \n",
      "\n",
      "Fold: 3  Epoch: 533  Training loss = 1.5593  Validation loss = 3.0974  \n",
      "\n",
      "Fold: 3  Epoch: 534  Training loss = 1.5592  Validation loss = 3.0972  \n",
      "\n",
      "Fold: 3  Epoch: 535  Training loss = 1.5592  Validation loss = 3.0975  \n",
      "\n",
      "Fold: 3  Epoch: 536  Training loss = 1.5592  Validation loss = 3.0972  \n",
      "\n",
      "Fold: 3  Epoch: 537  Training loss = 1.5591  Validation loss = 3.0964  \n",
      "\n",
      "Fold: 3  Epoch: 538  Training loss = 1.5590  Validation loss = 3.0958  \n",
      "\n",
      "Fold: 3  Epoch: 539  Training loss = 1.5589  Validation loss = 3.0952  \n",
      "\n",
      "Fold: 3  Epoch: 540  Training loss = 1.5589  Validation loss = 3.0950  \n",
      "\n",
      "Fold: 3  Epoch: 541  Training loss = 1.5588  Validation loss = 3.0950  \n",
      "\n",
      "Fold: 3  Epoch: 542  Training loss = 1.5588  Validation loss = 3.0950  \n",
      "\n",
      "Fold: 3  Epoch: 543  Training loss = 1.5588  Validation loss = 3.0952  \n",
      "\n",
      "Fold: 3  Epoch: 544  Training loss = 1.5587  Validation loss = 3.0948  \n",
      "\n",
      "Fold: 3  Epoch: 545  Training loss = 1.5587  Validation loss = 3.0944  \n",
      "\n",
      "Fold: 3  Epoch: 546  Training loss = 1.5586  Validation loss = 3.0941  \n",
      "\n",
      "Fold: 3  Epoch: 547  Training loss = 1.5586  Validation loss = 3.0936  \n",
      "\n",
      "Fold: 3  Epoch: 548  Training loss = 1.5585  Validation loss = 3.0931  \n",
      "\n",
      "Fold: 3  Epoch: 549  Training loss = 1.5585  Validation loss = 3.0930  \n",
      "\n",
      "Fold: 3  Epoch: 550  Training loss = 1.5584  Validation loss = 3.0930  \n",
      "\n",
      "Fold: 3  Epoch: 551  Training loss = 1.5584  Validation loss = 3.0930  \n",
      "\n",
      "Fold: 3  Epoch: 552  Training loss = 1.5583  Validation loss = 3.0927  \n",
      "\n",
      "Fold: 3  Epoch: 553  Training loss = 1.5583  Validation loss = 3.0923  \n",
      "\n",
      "Fold: 3  Epoch: 554  Training loss = 1.5582  Validation loss = 3.0918  \n",
      "\n",
      "Fold: 3  Epoch: 555  Training loss = 1.5581  Validation loss = 3.0911  \n",
      "\n",
      "Fold: 3  Epoch: 556  Training loss = 1.5581  Validation loss = 3.0910  \n",
      "\n",
      "Fold: 3  Epoch: 557  Training loss = 1.5580  Validation loss = 3.0907  \n",
      "\n",
      "Fold: 3  Epoch: 558  Training loss = 1.5580  Validation loss = 3.0902  \n",
      "\n",
      "Fold: 3  Epoch: 559  Training loss = 1.5579  Validation loss = 3.0900  \n",
      "\n",
      "Fold: 3  Epoch: 560  Training loss = 1.5579  Validation loss = 3.0898  \n",
      "\n",
      "Fold: 3  Epoch: 561  Training loss = 1.5578  Validation loss = 3.0896  \n",
      "\n",
      "Fold: 3  Epoch: 562  Training loss = 1.5578  Validation loss = 3.0895  \n",
      "\n",
      "Fold: 3  Epoch: 563  Training loss = 1.5578  Validation loss = 3.0892  \n",
      "\n",
      "Fold: 3  Epoch: 564  Training loss = 1.5577  Validation loss = 3.0889  \n",
      "\n",
      "Fold: 3  Epoch: 565  Training loss = 1.5576  Validation loss = 3.0885  \n",
      "\n",
      "Fold: 3  Epoch: 566  Training loss = 1.5576  Validation loss = 3.0884  \n",
      "\n",
      "Fold: 3  Epoch: 567  Training loss = 1.5576  Validation loss = 3.0882  \n",
      "\n",
      "Fold: 3  Epoch: 568  Training loss = 1.5575  Validation loss = 3.0880  \n",
      "\n",
      "Fold: 3  Epoch: 569  Training loss = 1.5575  Validation loss = 3.0877  \n",
      "\n",
      "Fold: 3  Epoch: 570  Training loss = 1.5574  Validation loss = 3.0873  \n",
      "\n",
      "Fold: 3  Epoch: 571  Training loss = 1.5573  Validation loss = 3.0868  \n",
      "\n",
      "Fold: 3  Epoch: 572  Training loss = 1.5573  Validation loss = 3.0867  \n",
      "\n",
      "Fold: 3  Epoch: 573  Training loss = 1.5573  Validation loss = 3.0864  \n",
      "\n",
      "Fold: 3  Epoch: 574  Training loss = 1.5572  Validation loss = 3.0863  \n",
      "\n",
      "Fold: 3  Epoch: 575  Training loss = 1.5572  Validation loss = 3.0864  \n",
      "\n",
      "Fold: 3  Epoch: 576  Training loss = 1.5572  Validation loss = 3.0863  \n",
      "\n",
      "Fold: 3  Epoch: 577  Training loss = 1.5571  Validation loss = 3.0863  \n",
      "\n",
      "Fold: 3  Epoch: 578  Training loss = 1.5571  Validation loss = 3.0860  \n",
      "\n",
      "Fold: 3  Epoch: 579  Training loss = 1.5570  Validation loss = 3.0854  \n",
      "\n",
      "Fold: 3  Epoch: 580  Training loss = 1.5570  Validation loss = 3.0854  \n",
      "\n",
      "Fold: 3  Epoch: 581  Training loss = 1.5569  Validation loss = 3.0853  \n",
      "\n",
      "Fold: 3  Epoch: 582  Training loss = 1.5569  Validation loss = 3.0850  \n",
      "\n",
      "Fold: 3  Epoch: 583  Training loss = 1.5568  Validation loss = 3.0848  \n",
      "\n",
      "Fold: 3  Epoch: 584  Training loss = 1.5568  Validation loss = 3.0848  \n",
      "\n",
      "Fold: 3  Epoch: 585  Training loss = 1.5568  Validation loss = 3.0842  \n",
      "\n",
      "Fold: 3  Epoch: 586  Training loss = 1.5567  Validation loss = 3.0843  \n",
      "\n",
      "Fold: 3  Epoch: 587  Training loss = 1.5567  Validation loss = 3.0840  \n",
      "\n",
      "Fold: 3  Epoch: 588  Training loss = 1.5566  Validation loss = 3.0837  \n",
      "\n",
      "Fold: 3  Epoch: 589  Training loss = 1.5565  Validation loss = 3.0834  \n",
      "\n",
      "Fold: 3  Epoch: 590  Training loss = 1.5565  Validation loss = 3.0833  \n",
      "\n",
      "Fold: 3  Epoch: 591  Training loss = 1.5565  Validation loss = 3.0835  \n",
      "\n",
      "Fold: 3  Epoch: 592  Training loss = 1.5564  Validation loss = 3.0831  \n",
      "\n",
      "Fold: 3  Epoch: 593  Training loss = 1.5564  Validation loss = 3.0830  \n",
      "\n",
      "Fold: 3  Epoch: 594  Training loss = 1.5564  Validation loss = 3.0832  \n",
      "\n",
      "Fold: 3  Epoch: 595  Training loss = 1.5563  Validation loss = 3.0831  \n",
      "\n",
      "Fold: 3  Epoch: 596  Training loss = 1.5563  Validation loss = 3.0827  \n",
      "\n",
      "Fold: 3  Epoch: 597  Training loss = 1.5562  Validation loss = 3.0821  \n",
      "\n",
      "Fold: 3  Epoch: 598  Training loss = 1.5562  Validation loss = 3.0822  \n",
      "\n",
      "Fold: 3  Epoch: 599  Training loss = 1.5561  Validation loss = 3.0818  \n",
      "\n",
      "Fold: 3  Epoch: 600  Training loss = 1.5561  Validation loss = 3.0815  \n",
      "\n",
      "Fold: 3  Epoch: 601  Training loss = 1.5560  Validation loss = 3.0814  \n",
      "\n",
      "Fold: 3  Epoch: 602  Training loss = 1.5560  Validation loss = 3.0814  \n",
      "\n",
      "Fold: 3  Epoch: 603  Training loss = 1.5560  Validation loss = 3.0814  \n",
      "\n",
      "Fold: 3  Epoch: 604  Training loss = 1.5559  Validation loss = 3.0809  \n",
      "\n",
      "Fold: 3  Epoch: 605  Training loss = 1.5558  Validation loss = 3.0808  \n",
      "\n",
      "Fold: 3  Epoch: 606  Training loss = 1.5558  Validation loss = 3.0805  \n",
      "\n",
      "Fold: 3  Epoch: 607  Training loss = 1.5557  Validation loss = 3.0800  \n",
      "\n",
      "Fold: 3  Epoch: 608  Training loss = 1.5557  Validation loss = 3.0798  \n",
      "\n",
      "Fold: 3  Epoch: 609  Training loss = 1.5556  Validation loss = 3.0792  \n",
      "\n",
      "Fold: 3  Epoch: 610  Training loss = 1.5555  Validation loss = 3.0787  \n",
      "\n",
      "Fold: 3  Epoch: 611  Training loss = 1.5555  Validation loss = 3.0784  \n",
      "\n",
      "Fold: 3  Epoch: 612  Training loss = 1.5554  Validation loss = 3.0785  \n",
      "\n",
      "Fold: 3  Epoch: 613  Training loss = 1.5554  Validation loss = 3.0784  \n",
      "\n",
      "Fold: 3  Epoch: 614  Training loss = 1.5553  Validation loss = 3.0777  \n",
      "\n",
      "Fold: 3  Epoch: 615  Training loss = 1.5553  Validation loss = 3.0776  \n",
      "\n",
      "Fold: 3  Epoch: 616  Training loss = 1.5552  Validation loss = 3.0770  \n",
      "\n",
      "Fold: 3  Epoch: 617  Training loss = 1.5552  Validation loss = 3.0769  \n",
      "\n",
      "Fold: 3  Epoch: 618  Training loss = 1.5551  Validation loss = 3.0764  \n",
      "\n",
      "Fold: 3  Epoch: 619  Training loss = 1.5550  Validation loss = 3.0761  \n",
      "\n",
      "Fold: 3  Epoch: 620  Training loss = 1.5550  Validation loss = 3.0755  \n",
      "\n",
      "Fold: 3  Epoch: 621  Training loss = 1.5549  Validation loss = 3.0751  \n",
      "\n",
      "Fold: 3  Epoch: 622  Training loss = 1.5549  Validation loss = 3.0751  \n",
      "\n",
      "Fold: 3  Epoch: 623  Training loss = 1.5548  Validation loss = 3.0749  \n",
      "\n",
      "Fold: 3  Epoch: 624  Training loss = 1.5548  Validation loss = 3.0744  \n",
      "\n",
      "Fold: 3  Epoch: 625  Training loss = 1.5548  Validation loss = 3.0743  \n",
      "\n",
      "Fold: 3  Epoch: 626  Training loss = 1.5547  Validation loss = 3.0739  \n",
      "\n",
      "Fold: 3  Epoch: 627  Training loss = 1.5547  Validation loss = 3.0739  \n",
      "\n",
      "Fold: 3  Epoch: 628  Training loss = 1.5546  Validation loss = 3.0737  \n",
      "\n",
      "Fold: 3  Epoch: 629  Training loss = 1.5546  Validation loss = 3.0735  \n",
      "\n",
      "Fold: 3  Epoch: 630  Training loss = 1.5545  Validation loss = 3.0733  \n",
      "\n",
      "Fold: 3  Epoch: 631  Training loss = 1.5545  Validation loss = 3.0729  \n",
      "\n",
      "Fold: 3  Epoch: 632  Training loss = 1.5544  Validation loss = 3.0730  \n",
      "\n",
      "Fold: 3  Epoch: 633  Training loss = 1.5543  Validation loss = 3.0723  \n",
      "\n",
      "Fold: 3  Epoch: 634  Training loss = 1.5543  Validation loss = 3.0723  \n",
      "\n",
      "Fold: 3  Epoch: 635  Training loss = 1.5542  Validation loss = 3.0721  \n",
      "\n",
      "Fold: 3  Epoch: 636  Training loss = 1.5542  Validation loss = 3.0716  \n",
      "\n",
      "Fold: 3  Epoch: 637  Training loss = 1.5541  Validation loss = 3.0712  \n",
      "\n",
      "Fold: 3  Epoch: 638  Training loss = 1.5541  Validation loss = 3.0714  \n",
      "\n",
      "Fold: 3  Epoch: 639  Training loss = 1.5541  Validation loss = 3.0715  \n",
      "\n",
      "Fold: 3  Epoch: 640  Training loss = 1.5541  Validation loss = 3.0715  \n",
      "\n",
      "Fold: 3  Epoch: 641  Training loss = 1.5540  Validation loss = 3.0706  \n",
      "\n",
      "Fold: 3  Epoch: 642  Training loss = 1.5539  Validation loss = 3.0702  \n",
      "\n",
      "Fold: 3  Epoch: 643  Training loss = 1.5538  Validation loss = 3.0700  \n",
      "\n",
      "Fold: 3  Epoch: 644  Training loss = 1.5538  Validation loss = 3.0698  \n",
      "\n",
      "Fold: 3  Epoch: 645  Training loss = 1.5537  Validation loss = 3.0695  \n",
      "\n",
      "Fold: 3  Epoch: 646  Training loss = 1.5537  Validation loss = 3.0691  \n",
      "\n",
      "Fold: 3  Epoch: 647  Training loss = 1.5536  Validation loss = 3.0686  \n",
      "\n",
      "Fold: 3  Epoch: 648  Training loss = 1.5536  Validation loss = 3.0684  \n",
      "\n",
      "Fold: 3  Epoch: 649  Training loss = 1.5535  Validation loss = 3.0681  \n",
      "\n",
      "Fold: 3  Epoch: 650  Training loss = 1.5535  Validation loss = 3.0678  \n",
      "\n",
      "Fold: 3  Epoch: 651  Training loss = 1.5534  Validation loss = 3.0676  \n",
      "\n",
      "Fold: 3  Epoch: 652  Training loss = 1.5533  Validation loss = 3.0672  \n",
      "\n",
      "Fold: 3  Epoch: 653  Training loss = 1.5533  Validation loss = 3.0671  \n",
      "\n",
      "Fold: 3  Epoch: 654  Training loss = 1.5532  Validation loss = 3.0668  \n",
      "\n",
      "Fold: 3  Epoch: 655  Training loss = 1.5532  Validation loss = 3.0664  \n",
      "\n",
      "Fold: 3  Epoch: 656  Training loss = 1.5531  Validation loss = 3.0664  \n",
      "\n",
      "Fold: 3  Epoch: 657  Training loss = 1.5531  Validation loss = 3.0659  \n",
      "\n",
      "Fold: 3  Epoch: 658  Training loss = 1.5530  Validation loss = 3.0656  \n",
      "\n",
      "Fold: 3  Epoch: 659  Training loss = 1.5530  Validation loss = 3.0655  \n",
      "\n",
      "Fold: 3  Epoch: 660  Training loss = 1.5529  Validation loss = 3.0654  \n",
      "\n",
      "Fold: 3  Epoch: 661  Training loss = 1.5529  Validation loss = 3.0653  \n",
      "\n",
      "Fold: 3  Epoch: 662  Training loss = 1.5528  Validation loss = 3.0649  \n",
      "\n",
      "Fold: 3  Epoch: 663  Training loss = 1.5528  Validation loss = 3.0647  \n",
      "\n",
      "Fold: 3  Epoch: 664  Training loss = 1.5528  Validation loss = 3.0649  \n",
      "\n",
      "Fold: 3  Epoch: 665  Training loss = 1.5528  Validation loss = 3.0649  \n",
      "\n",
      "Fold: 3  Epoch: 666  Training loss = 1.5528  Validation loss = 3.0650  \n",
      "\n",
      "Fold: 3  Epoch: 667  Training loss = 1.5527  Validation loss = 3.0649  \n",
      "\n",
      "Fold: 3  Epoch: 668  Training loss = 1.5527  Validation loss = 3.0648  \n",
      "\n",
      "Fold: 3  Epoch: 669  Training loss = 1.5527  Validation loss = 3.0646  \n",
      "\n",
      "Fold: 3  Epoch: 670  Training loss = 1.5526  Validation loss = 3.0639  \n",
      "\n",
      "Fold: 3  Epoch: 671  Training loss = 1.5525  Validation loss = 3.0634  \n",
      "\n",
      "Fold: 3  Epoch: 672  Training loss = 1.5525  Validation loss = 3.0630  \n",
      "\n",
      "Fold: 3  Epoch: 673  Training loss = 1.5524  Validation loss = 3.0629  \n",
      "\n",
      "Fold: 3  Epoch: 674  Training loss = 1.5524  Validation loss = 3.0627  \n",
      "\n",
      "Fold: 3  Epoch: 675  Training loss = 1.5523  Validation loss = 3.0622  \n",
      "\n",
      "Fold: 3  Epoch: 676  Training loss = 1.5523  Validation loss = 3.0624  \n",
      "\n",
      "Fold: 3  Epoch: 677  Training loss = 1.5522  Validation loss = 3.0620  \n",
      "\n",
      "Fold: 3  Epoch: 678  Training loss = 1.5522  Validation loss = 3.0617  \n",
      "\n",
      "Fold: 3  Epoch: 679  Training loss = 1.5521  Validation loss = 3.0615  \n",
      "\n",
      "Fold: 3  Epoch: 680  Training loss = 1.5521  Validation loss = 3.0612  \n",
      "\n",
      "Fold: 3  Epoch: 681  Training loss = 1.5521  Validation loss = 3.0609  \n",
      "\n",
      "Fold: 3  Epoch: 682  Training loss = 1.5520  Validation loss = 3.0605  \n",
      "\n",
      "Fold: 3  Epoch: 683  Training loss = 1.5520  Validation loss = 3.0604  \n",
      "\n",
      "Fold: 3  Epoch: 684  Training loss = 1.5519  Validation loss = 3.0603  \n",
      "\n",
      "Fold: 3  Epoch: 685  Training loss = 1.5519  Validation loss = 3.0600  \n",
      "\n",
      "Fold: 3  Epoch: 686  Training loss = 1.5518  Validation loss = 3.0598  \n",
      "\n",
      "Fold: 3  Epoch: 687  Training loss = 1.5518  Validation loss = 3.0595  \n",
      "\n",
      "Fold: 3  Epoch: 688  Training loss = 1.5517  Validation loss = 3.0595  \n",
      "\n",
      "Fold: 3  Epoch: 689  Training loss = 1.5517  Validation loss = 3.0593  \n",
      "\n",
      "Fold: 3  Epoch: 690  Training loss = 1.5516  Validation loss = 3.0588  \n",
      "\n",
      "Fold: 3  Epoch: 691  Training loss = 1.5516  Validation loss = 3.0585  \n",
      "\n",
      "Fold: 3  Epoch: 692  Training loss = 1.5515  Validation loss = 3.0583  \n",
      "\n",
      "Fold: 3  Epoch: 693  Training loss = 1.5515  Validation loss = 3.0579  \n",
      "\n",
      "Fold: 3  Epoch: 694  Training loss = 1.5514  Validation loss = 3.0579  \n",
      "\n",
      "Fold: 3  Epoch: 695  Training loss = 1.5514  Validation loss = 3.0576  \n",
      "\n",
      "Fold: 3  Epoch: 696  Training loss = 1.5513  Validation loss = 3.0573  \n",
      "\n",
      "Fold: 3  Epoch: 697  Training loss = 1.5513  Validation loss = 3.0572  \n",
      "\n",
      "Fold: 3  Epoch: 698  Training loss = 1.5513  Validation loss = 3.0571  \n",
      "\n",
      "Fold: 3  Epoch: 699  Training loss = 1.5512  Validation loss = 3.0571  \n",
      "\n",
      "Fold: 3  Epoch: 700  Training loss = 1.5512  Validation loss = 3.0570  \n",
      "\n",
      "Fold: 3  Epoch: 701  Training loss = 1.5512  Validation loss = 3.0569  \n",
      "\n",
      "Fold: 3  Epoch: 702  Training loss = 1.5512  Validation loss = 3.0569  \n",
      "\n",
      "Fold: 3  Epoch: 703  Training loss = 1.5511  Validation loss = 3.0564  \n",
      "\n",
      "Fold: 3  Epoch: 704  Training loss = 1.5510  Validation loss = 3.0561  \n",
      "\n",
      "Fold: 3  Epoch: 705  Training loss = 1.5510  Validation loss = 3.0561  \n",
      "\n",
      "Fold: 3  Epoch: 706  Training loss = 1.5509  Validation loss = 3.0555  \n",
      "\n",
      "Fold: 3  Epoch: 707  Training loss = 1.5509  Validation loss = 3.0556  \n",
      "\n",
      "Fold: 3  Epoch: 708  Training loss = 1.5508  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 3  Epoch: 709  Training loss = 1.5508  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 3  Epoch: 710  Training loss = 1.5508  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 3  Epoch: 711  Training loss = 1.5507  Validation loss = 3.0549  \n",
      "\n",
      "Fold: 3  Epoch: 712  Training loss = 1.5507  Validation loss = 3.0552  \n",
      "\n",
      "Fold: 3  Epoch: 713  Training loss = 1.5507  Validation loss = 3.0552  \n",
      "\n",
      "Fold: 3  Epoch: 714  Training loss = 1.5507  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 3  Epoch: 715  Training loss = 1.5506  Validation loss = 3.0550  \n",
      "\n",
      "Fold: 3  Epoch: 716  Training loss = 1.5506  Validation loss = 3.0548  \n",
      "\n",
      "Fold: 3  Epoch: 717  Training loss = 1.5506  Validation loss = 3.0548  \n",
      "\n",
      "Fold: 3  Epoch: 718  Training loss = 1.5505  Validation loss = 3.0546  \n",
      "\n",
      "Fold: 3  Epoch: 719  Training loss = 1.5505  Validation loss = 3.0542  \n",
      "\n",
      "Fold: 3  Epoch: 720  Training loss = 1.5504  Validation loss = 3.0542  \n",
      "\n",
      "Fold: 3  Epoch: 721  Training loss = 1.5504  Validation loss = 3.0542  \n",
      "\n",
      "Fold: 3  Epoch: 722  Training loss = 1.5503  Validation loss = 3.0538  \n",
      "\n",
      "Fold: 3  Epoch: 723  Training loss = 1.5503  Validation loss = 3.0535  \n",
      "\n",
      "Fold: 3  Epoch: 724  Training loss = 1.5502  Validation loss = 3.0533  \n",
      "\n",
      "Fold: 3  Epoch: 725  Training loss = 1.5502  Validation loss = 3.0530  \n",
      "\n",
      "Fold: 3  Epoch: 726  Training loss = 1.5501  Validation loss = 3.0527  \n",
      "\n",
      "Fold: 3  Epoch: 727  Training loss = 1.5501  Validation loss = 3.0523  \n",
      "\n",
      "Fold: 3  Epoch: 728  Training loss = 1.5500  Validation loss = 3.0520  \n",
      "\n",
      "Fold: 3  Epoch: 729  Training loss = 1.5500  Validation loss = 3.0514  \n",
      "\n",
      "Fold: 3  Epoch: 730  Training loss = 1.5499  Validation loss = 3.0510  \n",
      "\n",
      "Fold: 3  Epoch: 731  Training loss = 1.5499  Validation loss = 3.0509  \n",
      "\n",
      "Fold: 3  Epoch: 732  Training loss = 1.5498  Validation loss = 3.0510  \n",
      "\n",
      "Fold: 3  Epoch: 733  Training loss = 1.5498  Validation loss = 3.0505  \n",
      "\n",
      "Fold: 3  Epoch: 734  Training loss = 1.5497  Validation loss = 3.0504  \n",
      "\n",
      "Fold: 3  Epoch: 735  Training loss = 1.5497  Validation loss = 3.0499  \n",
      "\n",
      "Fold: 3  Epoch: 736  Training loss = 1.5497  Validation loss = 3.0499  \n",
      "\n",
      "Fold: 3  Epoch: 737  Training loss = 1.5496  Validation loss = 3.0497  \n",
      "\n",
      "Fold: 3  Epoch: 738  Training loss = 1.5496  Validation loss = 3.0498  \n",
      "\n",
      "Fold: 3  Epoch: 739  Training loss = 1.5495  Validation loss = 3.0496  \n",
      "\n",
      "Fold: 3  Epoch: 740  Training loss = 1.5495  Validation loss = 3.0493  \n",
      "\n",
      "Fold: 3  Epoch: 741  Training loss = 1.5494  Validation loss = 3.0492  \n",
      "\n",
      "Fold: 3  Epoch: 742  Training loss = 1.5493  Validation loss = 3.0487  \n",
      "\n",
      "Fold: 3  Epoch: 743  Training loss = 1.5493  Validation loss = 3.0487  \n",
      "\n",
      "Fold: 3  Epoch: 744  Training loss = 1.5493  Validation loss = 3.0486  \n",
      "\n",
      "Fold: 3  Epoch: 745  Training loss = 1.5492  Validation loss = 3.0481  \n",
      "\n",
      "Fold: 3  Epoch: 746  Training loss = 1.5491  Validation loss = 3.0478  \n",
      "\n",
      "Fold: 3  Epoch: 747  Training loss = 1.5491  Validation loss = 3.0476  \n",
      "\n",
      "Fold: 3  Epoch: 748  Training loss = 1.5490  Validation loss = 3.0472  \n",
      "\n",
      "Fold: 3  Epoch: 749  Training loss = 1.5490  Validation loss = 3.0469  \n",
      "\n",
      "Fold: 3  Epoch: 750  Training loss = 1.5489  Validation loss = 3.0463  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 750  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.6237  Validation loss = 4.3426  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.6236  Validation loss = 4.3421  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.6236  Validation loss = 4.3418  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.6235  Validation loss = 4.3413  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.6234  Validation loss = 4.3409  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.6233  Validation loss = 4.3406  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.6233  Validation loss = 4.3404  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.6232  Validation loss = 4.3400  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.6231  Validation loss = 4.3394  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.6229  Validation loss = 4.3387  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.6228  Validation loss = 4.3381  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.6227  Validation loss = 4.3379  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.6227  Validation loss = 4.3379  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.6227  Validation loss = 4.3377  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.6226  Validation loss = 4.3375  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.6226  Validation loss = 4.3372  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.6224  Validation loss = 4.3367  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.6224  Validation loss = 4.3362  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.6222  Validation loss = 4.3355  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.6221  Validation loss = 4.3350  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.6219  Validation loss = 4.3339  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.6218  Validation loss = 4.3334  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.6217  Validation loss = 4.3331  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.6216  Validation loss = 4.3326  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.6216  Validation loss = 4.3324  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.6214  Validation loss = 4.3317  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.6214  Validation loss = 4.3315  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.6214  Validation loss = 4.3313  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.6212  Validation loss = 4.3305  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.6211  Validation loss = 4.3300  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.6210  Validation loss = 4.3297  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.6209  Validation loss = 4.3289  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.6208  Validation loss = 4.3286  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.6207  Validation loss = 4.3280  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.6206  Validation loss = 4.3277  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.6206  Validation loss = 4.3274  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.6205  Validation loss = 4.3272  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.6204  Validation loss = 4.3269  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.6203  Validation loss = 4.3263  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.6203  Validation loss = 4.3259  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.6201  Validation loss = 4.3251  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.6201  Validation loss = 4.3250  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.6200  Validation loss = 4.3245  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.6199  Validation loss = 4.3238  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.6198  Validation loss = 4.3233  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.6197  Validation loss = 4.3230  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.6197  Validation loss = 4.3228  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.6196  Validation loss = 4.3223  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.6195  Validation loss = 4.3220  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.6194  Validation loss = 4.3216  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.6193  Validation loss = 4.3209  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.6193  Validation loss = 4.3206  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.6191  Validation loss = 4.3197  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.6190  Validation loss = 4.3194  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.6189  Validation loss = 4.3189  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.6188  Validation loss = 4.3185  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.6188  Validation loss = 4.3181  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.6186  Validation loss = 4.3175  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.6185  Validation loss = 4.3170  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.6184  Validation loss = 4.3166  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.6184  Validation loss = 4.3161  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.6183  Validation loss = 4.3155  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.6182  Validation loss = 4.3152  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.6181  Validation loss = 4.3149  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.6180  Validation loss = 4.3140  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.6179  Validation loss = 4.3137  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.6178  Validation loss = 4.3132  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.6177  Validation loss = 4.3126  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.6177  Validation loss = 4.3123  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.6175  Validation loss = 4.3117  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.6175  Validation loss = 4.3113  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.6174  Validation loss = 4.3108  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.6173  Validation loss = 4.3105  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.6173  Validation loss = 4.3102  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.6172  Validation loss = 4.3098  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.6172  Validation loss = 4.3097  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.6171  Validation loss = 4.3094  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.6171  Validation loss = 4.3092  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.6170  Validation loss = 4.3089  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.6169  Validation loss = 4.3082  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.6168  Validation loss = 4.3076  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.6167  Validation loss = 4.3071  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.6166  Validation loss = 4.3068  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.6164  Validation loss = 4.3059  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.6164  Validation loss = 4.3054  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.6162  Validation loss = 4.3046  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.6161  Validation loss = 4.3040  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.6160  Validation loss = 4.3033  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.6159  Validation loss = 4.3029  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.6158  Validation loss = 4.3022  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.6157  Validation loss = 4.3022  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.6157  Validation loss = 4.3018  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.6156  Validation loss = 4.3014  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.6155  Validation loss = 4.3010  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.6154  Validation loss = 4.3005  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.6153  Validation loss = 4.2998  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.6152  Validation loss = 4.2996  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.6152  Validation loss = 4.2992  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.6151  Validation loss = 4.2991  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.6151  Validation loss = 4.2987  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.6149  Validation loss = 4.2981  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.6149  Validation loss = 4.2978  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.6148  Validation loss = 4.2977  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.6148  Validation loss = 4.2977  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.6147  Validation loss = 4.2973  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.6147  Validation loss = 4.2970  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.6146  Validation loss = 4.2964  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.6146  Validation loss = 4.2964  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.6145  Validation loss = 4.2958  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.6143  Validation loss = 4.2950  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.6142  Validation loss = 4.2944  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.6142  Validation loss = 4.2942  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.6141  Validation loss = 4.2936  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.6140  Validation loss = 4.2933  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.6139  Validation loss = 4.2930  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.6138  Validation loss = 4.2927  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.6138  Validation loss = 4.2926  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.6137  Validation loss = 4.2920  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.6136  Validation loss = 4.2916  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.6136  Validation loss = 4.2913  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.6135  Validation loss = 4.2910  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.6134  Validation loss = 4.2902  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.6133  Validation loss = 4.2900  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.6131  Validation loss = 4.2889  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.6130  Validation loss = 4.2884  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.6129  Validation loss = 4.2879  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.6128  Validation loss = 4.2875  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.6128  Validation loss = 4.2874  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.6128  Validation loss = 4.2872  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.6127  Validation loss = 4.2870  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.6126  Validation loss = 4.2865  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.6126  Validation loss = 4.2865  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.6125  Validation loss = 4.2861  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.6124  Validation loss = 4.2857  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.6123  Validation loss = 4.2853  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.6123  Validation loss = 4.2849  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.6122  Validation loss = 4.2845  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.6121  Validation loss = 4.2843  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.6121  Validation loss = 4.2842  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.6119  Validation loss = 4.2835  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.6119  Validation loss = 4.2833  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.6118  Validation loss = 4.2828  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.6116  Validation loss = 4.2820  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.6116  Validation loss = 4.2818  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.6115  Validation loss = 4.2812  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.6114  Validation loss = 4.2809  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.6114  Validation loss = 4.2805  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.6112  Validation loss = 4.2800  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.6112  Validation loss = 4.2798  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.6110  Validation loss = 4.2788  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.6109  Validation loss = 4.2782  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.6109  Validation loss = 4.2781  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.6108  Validation loss = 4.2777  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.6108  Validation loss = 4.2776  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.6107  Validation loss = 4.2777  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.6106  Validation loss = 4.2771  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.6105  Validation loss = 4.2767  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.6105  Validation loss = 4.2761  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.6104  Validation loss = 4.2755  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.6103  Validation loss = 4.2754  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.6102  Validation loss = 4.2746  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.6101  Validation loss = 4.2741  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.6100  Validation loss = 4.2738  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.6099  Validation loss = 4.2732  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.6098  Validation loss = 4.2728  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.6097  Validation loss = 4.2725  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.6097  Validation loss = 4.2721  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.6096  Validation loss = 4.2718  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.6095  Validation loss = 4.2712  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.6094  Validation loss = 4.2708  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.6093  Validation loss = 4.2704  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.6092  Validation loss = 4.2701  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.6092  Validation loss = 4.2700  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.6091  Validation loss = 4.2696  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.6090  Validation loss = 4.2692  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.6090  Validation loss = 4.2691  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.6089  Validation loss = 4.2686  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.6089  Validation loss = 4.2684  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.6087  Validation loss = 4.2678  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.6086  Validation loss = 4.2674  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.6085  Validation loss = 4.2669  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.6084  Validation loss = 4.2664  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.6083  Validation loss = 4.2657  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.6082  Validation loss = 4.2652  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.6081  Validation loss = 4.2648  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.6080  Validation loss = 4.2638  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.6079  Validation loss = 4.2637  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.6079  Validation loss = 4.2632  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.6078  Validation loss = 4.2628  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.6077  Validation loss = 4.2621  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.6075  Validation loss = 4.2616  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.6075  Validation loss = 4.2615  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.6074  Validation loss = 4.2609  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.6074  Validation loss = 4.2607  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.6072  Validation loss = 4.2598  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.6072  Validation loss = 4.2600  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.6071  Validation loss = 4.2593  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.6070  Validation loss = 4.2589  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.6070  Validation loss = 4.2589  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.6070  Validation loss = 4.2589  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.6069  Validation loss = 4.2584  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.6067  Validation loss = 4.2577  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.6066  Validation loss = 4.2571  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.6066  Validation loss = 4.2572  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.6066  Validation loss = 4.2568  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.6065  Validation loss = 4.2564  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.6064  Validation loss = 4.2558  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.6063  Validation loss = 4.2555  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.6063  Validation loss = 4.2554  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.6062  Validation loss = 4.2552  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.6061  Validation loss = 4.2550  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.6060  Validation loss = 4.2545  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.6060  Validation loss = 4.2541  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.6059  Validation loss = 4.2537  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.6058  Validation loss = 4.2533  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.6057  Validation loss = 4.2531  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.6056  Validation loss = 4.2524  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.6055  Validation loss = 4.2519  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.6055  Validation loss = 4.2519  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.6055  Validation loss = 4.2518  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.6054  Validation loss = 4.2517  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.6053  Validation loss = 4.2513  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.6053  Validation loss = 4.2508  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.6051  Validation loss = 4.2498  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.6050  Validation loss = 4.2494  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.6049  Validation loss = 4.2487  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.6047  Validation loss = 4.2480  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.6047  Validation loss = 4.2477  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.6046  Validation loss = 4.2476  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.6045  Validation loss = 4.2469  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.6044  Validation loss = 4.2466  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.6043  Validation loss = 4.2460  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.6043  Validation loss = 4.2457  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.6042  Validation loss = 4.2453  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.6040  Validation loss = 4.2445  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.6040  Validation loss = 4.2444  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.6040  Validation loss = 4.2444  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.6040  Validation loss = 4.2444  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.6039  Validation loss = 4.2438  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.6038  Validation loss = 4.2437  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.6038  Validation loss = 4.2435  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.6037  Validation loss = 4.2430  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.6036  Validation loss = 4.2430  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.6035  Validation loss = 4.2426  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.6034  Validation loss = 4.2419  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.6033  Validation loss = 4.2412  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.6032  Validation loss = 4.2406  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.6031  Validation loss = 4.2402  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.6030  Validation loss = 4.2401  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.6029  Validation loss = 4.2391  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.6028  Validation loss = 4.2386  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.6027  Validation loss = 4.2384  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.6027  Validation loss = 4.2380  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.6025  Validation loss = 4.2375  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.6025  Validation loss = 4.2370  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.6023  Validation loss = 4.2365  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.6022  Validation loss = 4.2357  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.6021  Validation loss = 4.2351  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.6020  Validation loss = 4.2349  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.6019  Validation loss = 4.2344  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.6018  Validation loss = 4.2339  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.6018  Validation loss = 4.2336  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.6017  Validation loss = 4.2330  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.6016  Validation loss = 4.2325  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.6015  Validation loss = 4.2321  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.6014  Validation loss = 4.2317  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.6013  Validation loss = 4.2311  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.6012  Validation loss = 4.2308  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.6011  Validation loss = 4.2303  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.6011  Validation loss = 4.2302  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.6010  Validation loss = 4.2299  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.6008  Validation loss = 4.2292  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.6008  Validation loss = 4.2289  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.6007  Validation loss = 4.2284  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.6006  Validation loss = 4.2282  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.6005  Validation loss = 4.2276  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.6004  Validation loss = 4.2269  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.6003  Validation loss = 4.2264  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.6002  Validation loss = 4.2259  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.6001  Validation loss = 4.2253  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.5999  Validation loss = 4.2246  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.5998  Validation loss = 4.2242  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.5998  Validation loss = 4.2241  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.5996  Validation loss = 4.2233  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.5995  Validation loss = 4.2227  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.5995  Validation loss = 4.2224  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.5994  Validation loss = 4.2223  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.5994  Validation loss = 4.2218  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.5993  Validation loss = 4.2215  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.5993  Validation loss = 4.2213  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.5992  Validation loss = 4.2208  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.5991  Validation loss = 4.2205  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.5990  Validation loss = 4.2200  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.5989  Validation loss = 4.2195  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.5989  Validation loss = 4.2196  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.5988  Validation loss = 4.2192  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.5987  Validation loss = 4.2186  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.5986  Validation loss = 4.2180  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.5984  Validation loss = 4.2172  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.5984  Validation loss = 4.2168  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.5984  Validation loss = 4.2169  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.5983  Validation loss = 4.2166  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.5982  Validation loss = 4.2163  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.5981  Validation loss = 4.2160  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.5981  Validation loss = 4.2156  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.5980  Validation loss = 4.2152  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.5979  Validation loss = 4.2149  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.5978  Validation loss = 4.2143  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.5977  Validation loss = 4.2139  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.5977  Validation loss = 4.2137  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.5976  Validation loss = 4.2135  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.5975  Validation loss = 4.2133  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.5975  Validation loss = 4.2131  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.5974  Validation loss = 4.2126  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.5973  Validation loss = 4.2122  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.5973  Validation loss = 4.2119  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.5972  Validation loss = 4.2113  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.5970  Validation loss = 4.2105  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.5969  Validation loss = 4.2102  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.5969  Validation loss = 4.2101  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.5968  Validation loss = 4.2097  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.5967  Validation loss = 4.2094  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.5966  Validation loss = 4.2090  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.5965  Validation loss = 4.2083  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.5964  Validation loss = 4.2083  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.5963  Validation loss = 4.2076  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.5962  Validation loss = 4.2072  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.5962  Validation loss = 4.2073  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.5961  Validation loss = 4.2071  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.5961  Validation loss = 4.2070  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.5960  Validation loss = 4.2065  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.5960  Validation loss = 4.2065  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.5959  Validation loss = 4.2062  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.5958  Validation loss = 4.2059  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.5957  Validation loss = 4.2053  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.5957  Validation loss = 4.2051  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.5955  Validation loss = 4.2043  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.5955  Validation loss = 4.2041  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.5954  Validation loss = 4.2038  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.5952  Validation loss = 4.2029  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.5952  Validation loss = 4.2026  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.5951  Validation loss = 4.2022  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.5950  Validation loss = 4.2021  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.5949  Validation loss = 4.2016  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.5948  Validation loss = 4.2007  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.5947  Validation loss = 4.2003  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.5946  Validation loss = 4.2001  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.5946  Validation loss = 4.1999  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.5945  Validation loss = 4.1995  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.5944  Validation loss = 4.1993  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.5943  Validation loss = 4.1989  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.5943  Validation loss = 4.1988  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.5941  Validation loss = 4.1980  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.5941  Validation loss = 4.1981  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.5941  Validation loss = 4.1980  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.5940  Validation loss = 4.1976  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.5939  Validation loss = 4.1976  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.5938  Validation loss = 4.1971  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.5937  Validation loss = 4.1964  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.5936  Validation loss = 4.1962  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.5935  Validation loss = 4.1956  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.5934  Validation loss = 4.1950  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.5933  Validation loss = 4.1948  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.5932  Validation loss = 4.1944  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.5931  Validation loss = 4.1938  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.5931  Validation loss = 4.1938  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.5930  Validation loss = 4.1938  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.5930  Validation loss = 4.1936  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.5929  Validation loss = 4.1934  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.5929  Validation loss = 4.1932  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.5928  Validation loss = 4.1926  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.5927  Validation loss = 4.1923  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.5927  Validation loss = 4.1922  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.5926  Validation loss = 4.1921  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.5925  Validation loss = 4.1915  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.5924  Validation loss = 4.1910  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.5923  Validation loss = 4.1905  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.5921  Validation loss = 4.1898  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.5921  Validation loss = 4.1894  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.5919  Validation loss = 4.1886  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.5919  Validation loss = 4.1885  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.5918  Validation loss = 4.1881  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.5917  Validation loss = 4.1880  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.5916  Validation loss = 4.1873  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.5915  Validation loss = 4.1867  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.5914  Validation loss = 4.1867  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.5913  Validation loss = 4.1858  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.5911  Validation loss = 4.1852  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.5910  Validation loss = 4.1847  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.5909  Validation loss = 4.1840  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.5908  Validation loss = 4.1839  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.5907  Validation loss = 4.1833  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.5906  Validation loss = 4.1826  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.5905  Validation loss = 4.1823  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.5904  Validation loss = 4.1820  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.5903  Validation loss = 4.1814  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.5902  Validation loss = 4.1808  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.5901  Validation loss = 4.1804  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.5901  Validation loss = 4.1803  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.5899  Validation loss = 4.1793  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.5898  Validation loss = 4.1788  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.5897  Validation loss = 4.1785  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.5897  Validation loss = 4.1782  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.5896  Validation loss = 4.1778  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.5895  Validation loss = 4.1775  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.5895  Validation loss = 4.1773  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.5894  Validation loss = 4.1770  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.5892  Validation loss = 4.1759  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.5891  Validation loss = 4.1752  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.5890  Validation loss = 4.1746  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.5889  Validation loss = 4.1744  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.5888  Validation loss = 4.1740  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.5888  Validation loss = 4.1740  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.5887  Validation loss = 4.1736  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.5886  Validation loss = 4.1732  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.5886  Validation loss = 4.1729  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.5885  Validation loss = 4.1723  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.5884  Validation loss = 4.1721  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.5884  Validation loss = 4.1719  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.5882  Validation loss = 4.1712  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.5882  Validation loss = 4.1711  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.5882  Validation loss = 4.1711  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.5880  Validation loss = 4.1704  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.5879  Validation loss = 4.1701  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.5879  Validation loss = 4.1697  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.5877  Validation loss = 4.1690  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.5875  Validation loss = 4.1682  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.5875  Validation loss = 4.1679  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.5873  Validation loss = 4.1674  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.5872  Validation loss = 4.1668  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.5871  Validation loss = 4.1664  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.5871  Validation loss = 4.1663  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.5870  Validation loss = 4.1661  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.5870  Validation loss = 4.1658  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.5869  Validation loss = 4.1653  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.5868  Validation loss = 4.1650  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.5867  Validation loss = 4.1645  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.5866  Validation loss = 4.1642  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.5864  Validation loss = 4.1633  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.5863  Validation loss = 4.1629  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.5863  Validation loss = 4.1629  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.5862  Validation loss = 4.1626  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.5862  Validation loss = 4.1625  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.5861  Validation loss = 4.1622  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.5860  Validation loss = 4.1619  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.5859  Validation loss = 4.1616  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.5858  Validation loss = 4.1610  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.5859  Validation loss = 4.1613  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.5858  Validation loss = 4.1611  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.5858  Validation loss = 4.1611  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.5857  Validation loss = 4.1609  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.5856  Validation loss = 4.1606  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.5856  Validation loss = 4.1604  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.5855  Validation loss = 4.1602  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.5855  Validation loss = 4.1602  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.5855  Validation loss = 4.1602  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.5855  Validation loss = 4.1603  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.5853  Validation loss = 4.1597  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.5852  Validation loss = 4.1592  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.5852  Validation loss = 4.1590  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.5851  Validation loss = 4.1589  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.5851  Validation loss = 4.1586  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.5850  Validation loss = 4.1585  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.5849  Validation loss = 4.1581  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.5848  Validation loss = 4.1580  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.5847  Validation loss = 4.1575  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.5846  Validation loss = 4.1567  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.5845  Validation loss = 4.1566  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.5844  Validation loss = 4.1564  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.5844  Validation loss = 4.1561  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.5842  Validation loss = 4.1553  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.5840  Validation loss = 4.1548  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.5839  Validation loss = 4.1543  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.5838  Validation loss = 4.1537  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.5837  Validation loss = 4.1531  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.5836  Validation loss = 4.1528  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.5835  Validation loss = 4.1523  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.5834  Validation loss = 4.1517  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.5833  Validation loss = 4.1511  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.5832  Validation loss = 4.1507  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.5831  Validation loss = 4.1505  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.5830  Validation loss = 4.1500  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.5829  Validation loss = 4.1497  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.5828  Validation loss = 4.1494  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.5827  Validation loss = 4.1491  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.5826  Validation loss = 4.1484  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.5825  Validation loss = 4.1483  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.5825  Validation loss = 4.1480  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.5824  Validation loss = 4.1479  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.5824  Validation loss = 4.1477  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.5823  Validation loss = 4.1478  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.5822  Validation loss = 4.1473  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.5821  Validation loss = 4.1470  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.5821  Validation loss = 4.1468  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.5820  Validation loss = 4.1462  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.5818  Validation loss = 4.1455  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.5817  Validation loss = 4.1451  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.5816  Validation loss = 4.1449  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.5816  Validation loss = 4.1449  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.5815  Validation loss = 4.1445  \n",
      "\n",
      "Fold: 4  Epoch: 501  Training loss = 1.5814  Validation loss = 4.1440  \n",
      "\n",
      "Fold: 4  Epoch: 502  Training loss = 1.5814  Validation loss = 4.1440  \n",
      "\n",
      "Fold: 4  Epoch: 503  Training loss = 1.5814  Validation loss = 4.1439  \n",
      "\n",
      "Fold: 4  Epoch: 504  Training loss = 1.5813  Validation loss = 4.1436  \n",
      "\n",
      "Fold: 4  Epoch: 505  Training loss = 1.5813  Validation loss = 4.1439  \n",
      "\n",
      "Fold: 4  Epoch: 506  Training loss = 1.5812  Validation loss = 4.1435  \n",
      "\n",
      "Fold: 4  Epoch: 507  Training loss = 1.5812  Validation loss = 4.1438  \n",
      "\n",
      "Fold: 4  Epoch: 508  Training loss = 1.5812  Validation loss = 4.1437  \n",
      "\n",
      "Fold: 4  Epoch: 509  Training loss = 1.5810  Validation loss = 4.1432  \n",
      "\n",
      "Fold: 4  Epoch: 510  Training loss = 1.5809  Validation loss = 4.1427  \n",
      "\n",
      "Fold: 4  Epoch: 511  Training loss = 1.5809  Validation loss = 4.1423  \n",
      "\n",
      "Fold: 4  Epoch: 512  Training loss = 1.5809  Validation loss = 4.1427  \n",
      "\n",
      "Fold: 4  Epoch: 513  Training loss = 1.5807  Validation loss = 4.1418  \n",
      "\n",
      "Fold: 4  Epoch: 514  Training loss = 1.5806  Validation loss = 4.1413  \n",
      "\n",
      "Fold: 4  Epoch: 515  Training loss = 1.5805  Validation loss = 4.1411  \n",
      "\n",
      "Fold: 4  Epoch: 516  Training loss = 1.5805  Validation loss = 4.1407  \n",
      "\n",
      "Fold: 4  Epoch: 517  Training loss = 1.5804  Validation loss = 4.1405  \n",
      "\n",
      "Fold: 4  Epoch: 518  Training loss = 1.5803  Validation loss = 4.1401  \n",
      "\n",
      "Fold: 4  Epoch: 519  Training loss = 1.5802  Validation loss = 4.1400  \n",
      "\n",
      "Fold: 4  Epoch: 520  Training loss = 1.5802  Validation loss = 4.1399  \n",
      "\n",
      "Fold: 4  Epoch: 521  Training loss = 1.5801  Validation loss = 4.1395  \n",
      "\n",
      "Fold: 4  Epoch: 522  Training loss = 1.5800  Validation loss = 4.1393  \n",
      "\n",
      "Fold: 4  Epoch: 523  Training loss = 1.5799  Validation loss = 4.1390  \n",
      "\n",
      "Fold: 4  Epoch: 524  Training loss = 1.5798  Validation loss = 4.1386  \n",
      "\n",
      "Fold: 4  Epoch: 525  Training loss = 1.5797  Validation loss = 4.1382  \n",
      "\n",
      "Fold: 4  Epoch: 526  Training loss = 1.5796  Validation loss = 4.1379  \n",
      "\n",
      "Fold: 4  Epoch: 527  Training loss = 1.5795  Validation loss = 4.1373  \n",
      "\n",
      "Fold: 4  Epoch: 528  Training loss = 1.5794  Validation loss = 4.1369  \n",
      "\n",
      "Fold: 4  Epoch: 529  Training loss = 1.5794  Validation loss = 4.1369  \n",
      "\n",
      "Fold: 4  Epoch: 530  Training loss = 1.5793  Validation loss = 4.1367  \n",
      "\n",
      "Fold: 4  Epoch: 531  Training loss = 1.5792  Validation loss = 4.1363  \n",
      "\n",
      "Fold: 4  Epoch: 532  Training loss = 1.5791  Validation loss = 4.1359  \n",
      "\n",
      "Fold: 4  Epoch: 533  Training loss = 1.5791  Validation loss = 4.1360  \n",
      "\n",
      "Fold: 4  Epoch: 534  Training loss = 1.5790  Validation loss = 4.1357  \n",
      "\n",
      "Fold: 4  Epoch: 535  Training loss = 1.5789  Validation loss = 4.1356  \n",
      "\n",
      "Fold: 4  Epoch: 536  Training loss = 1.5789  Validation loss = 4.1356  \n",
      "\n",
      "Fold: 4  Epoch: 537  Training loss = 1.5788  Validation loss = 4.1349  \n",
      "\n",
      "Fold: 4  Epoch: 538  Training loss = 1.5787  Validation loss = 4.1346  \n",
      "\n",
      "Fold: 4  Epoch: 539  Training loss = 1.5786  Validation loss = 4.1342  \n",
      "\n",
      "Fold: 4  Epoch: 540  Training loss = 1.5785  Validation loss = 4.1337  \n",
      "\n",
      "Fold: 4  Epoch: 541  Training loss = 1.5785  Validation loss = 4.1335  \n",
      "\n",
      "Fold: 4  Epoch: 542  Training loss = 1.5785  Validation loss = 4.1336  \n",
      "\n",
      "Fold: 4  Epoch: 543  Training loss = 1.5784  Validation loss = 4.1333  \n",
      "\n",
      "Fold: 4  Epoch: 544  Training loss = 1.5784  Validation loss = 4.1333  \n",
      "\n",
      "Fold: 4  Epoch: 545  Training loss = 1.5783  Validation loss = 4.1332  \n",
      "\n",
      "Fold: 4  Epoch: 546  Training loss = 1.5783  Validation loss = 4.1330  \n",
      "\n",
      "Fold: 4  Epoch: 547  Training loss = 1.5782  Validation loss = 4.1326  \n",
      "\n",
      "Fold: 4  Epoch: 548  Training loss = 1.5781  Validation loss = 4.1320  \n",
      "\n",
      "Fold: 4  Epoch: 549  Training loss = 1.5780  Validation loss = 4.1318  \n",
      "\n",
      "Fold: 4  Epoch: 550  Training loss = 1.5779  Validation loss = 4.1316  \n",
      "\n",
      "Fold: 4  Epoch: 551  Training loss = 1.5779  Validation loss = 4.1312  \n",
      "\n",
      "Fold: 4  Epoch: 552  Training loss = 1.5778  Validation loss = 4.1310  \n",
      "\n",
      "Fold: 4  Epoch: 553  Training loss = 1.5778  Validation loss = 4.1309  \n",
      "\n",
      "Fold: 4  Epoch: 554  Training loss = 1.5777  Validation loss = 4.1307  \n",
      "\n",
      "Fold: 4  Epoch: 555  Training loss = 1.5776  Validation loss = 4.1308  \n",
      "\n",
      "Fold: 4  Epoch: 556  Training loss = 1.5775  Validation loss = 4.1302  \n",
      "\n",
      "Fold: 4  Epoch: 557  Training loss = 1.5775  Validation loss = 4.1303  \n",
      "\n",
      "Fold: 4  Epoch: 558  Training loss = 1.5775  Validation loss = 4.1301  \n",
      "\n",
      "Fold: 4  Epoch: 559  Training loss = 1.5774  Validation loss = 4.1297  \n",
      "\n",
      "Fold: 4  Epoch: 560  Training loss = 1.5773  Validation loss = 4.1297  \n",
      "\n",
      "Fold: 4  Epoch: 561  Training loss = 1.5773  Validation loss = 4.1294  \n",
      "\n",
      "Fold: 4  Epoch: 562  Training loss = 1.5772  Validation loss = 4.1293  \n",
      "\n",
      "Fold: 4  Epoch: 563  Training loss = 1.5772  Validation loss = 4.1294  \n",
      "\n",
      "Fold: 4  Epoch: 564  Training loss = 1.5771  Validation loss = 4.1292  \n",
      "\n",
      "Fold: 4  Epoch: 565  Training loss = 1.5771  Validation loss = 4.1289  \n",
      "\n",
      "Fold: 4  Epoch: 566  Training loss = 1.5770  Validation loss = 4.1285  \n",
      "\n",
      "Fold: 4  Epoch: 567  Training loss = 1.5770  Validation loss = 4.1285  \n",
      "\n",
      "Fold: 4  Epoch: 568  Training loss = 1.5770  Validation loss = 4.1286  \n",
      "\n",
      "Fold: 4  Epoch: 569  Training loss = 1.5768  Validation loss = 4.1279  \n",
      "\n",
      "Fold: 4  Epoch: 570  Training loss = 1.5768  Validation loss = 4.1276  \n",
      "\n",
      "Fold: 4  Epoch: 571  Training loss = 1.5768  Validation loss = 4.1276  \n",
      "\n",
      "Fold: 4  Epoch: 572  Training loss = 1.5767  Validation loss = 4.1271  \n",
      "\n",
      "Fold: 4  Epoch: 573  Training loss = 1.5766  Validation loss = 4.1267  \n",
      "\n",
      "Fold: 4  Epoch: 574  Training loss = 1.5764  Validation loss = 4.1260  \n",
      "\n",
      "Fold: 4  Epoch: 575  Training loss = 1.5763  Validation loss = 4.1256  \n",
      "\n",
      "Fold: 4  Epoch: 576  Training loss = 1.5763  Validation loss = 4.1253  \n",
      "\n",
      "Fold: 4  Epoch: 577  Training loss = 1.5762  Validation loss = 4.1251  \n",
      "\n",
      "Fold: 4  Epoch: 578  Training loss = 1.5762  Validation loss = 4.1249  \n",
      "\n",
      "Fold: 4  Epoch: 579  Training loss = 1.5761  Validation loss = 4.1249  \n",
      "\n",
      "Fold: 4  Epoch: 580  Training loss = 1.5760  Validation loss = 4.1243  \n",
      "\n",
      "Fold: 4  Epoch: 581  Training loss = 1.5760  Validation loss = 4.1243  \n",
      "\n",
      "Fold: 4  Epoch: 582  Training loss = 1.5759  Validation loss = 4.1236  \n",
      "\n",
      "Fold: 4  Epoch: 583  Training loss = 1.5758  Validation loss = 4.1233  \n",
      "\n",
      "Fold: 4  Epoch: 584  Training loss = 1.5757  Validation loss = 4.1230  \n",
      "\n",
      "Fold: 4  Epoch: 585  Training loss = 1.5756  Validation loss = 4.1228  \n",
      "\n",
      "Fold: 4  Epoch: 586  Training loss = 1.5755  Validation loss = 4.1221  \n",
      "\n",
      "Fold: 4  Epoch: 587  Training loss = 1.5754  Validation loss = 4.1217  \n",
      "\n",
      "Fold: 4  Epoch: 588  Training loss = 1.5753  Validation loss = 4.1213  \n",
      "\n",
      "Fold: 4  Epoch: 589  Training loss = 1.5753  Validation loss = 4.1214  \n",
      "\n",
      "Fold: 4  Epoch: 590  Training loss = 1.5752  Validation loss = 4.1208  \n",
      "\n",
      "Fold: 4  Epoch: 591  Training loss = 1.5752  Validation loss = 4.1209  \n",
      "\n",
      "Fold: 4  Epoch: 592  Training loss = 1.5751  Validation loss = 4.1206  \n",
      "\n",
      "Fold: 4  Epoch: 593  Training loss = 1.5751  Validation loss = 4.1205  \n",
      "\n",
      "Fold: 4  Epoch: 594  Training loss = 1.5750  Validation loss = 4.1199  \n",
      "\n",
      "Fold: 4  Epoch: 595  Training loss = 1.5749  Validation loss = 4.1202  \n",
      "\n",
      "Fold: 4  Epoch: 596  Training loss = 1.5749  Validation loss = 4.1201  \n",
      "\n",
      "Fold: 4  Epoch: 597  Training loss = 1.5749  Validation loss = 4.1200  \n",
      "\n",
      "Fold: 4  Epoch: 598  Training loss = 1.5746  Validation loss = 4.1190  \n",
      "\n",
      "Fold: 4  Epoch: 599  Training loss = 1.5746  Validation loss = 4.1188  \n",
      "\n",
      "Fold: 4  Epoch: 600  Training loss = 1.5746  Validation loss = 4.1189  \n",
      "\n",
      "Fold: 4  Epoch: 601  Training loss = 1.5745  Validation loss = 4.1188  \n",
      "\n",
      "Fold: 4  Epoch: 602  Training loss = 1.5744  Validation loss = 4.1184  \n",
      "\n",
      "Fold: 4  Epoch: 603  Training loss = 1.5744  Validation loss = 4.1181  \n",
      "\n",
      "Fold: 4  Epoch: 604  Training loss = 1.5743  Validation loss = 4.1177  \n",
      "\n",
      "Fold: 4  Epoch: 605  Training loss = 1.5742  Validation loss = 4.1177  \n",
      "\n",
      "Fold: 4  Epoch: 606  Training loss = 1.5742  Validation loss = 4.1174  \n",
      "\n",
      "Fold: 4  Epoch: 607  Training loss = 1.5742  Validation loss = 4.1177  \n",
      "\n",
      "Fold: 4  Epoch: 608  Training loss = 1.5741  Validation loss = 4.1170  \n",
      "\n",
      "Fold: 4  Epoch: 609  Training loss = 1.5740  Validation loss = 4.1165  \n",
      "\n",
      "Fold: 4  Epoch: 610  Training loss = 1.5739  Validation loss = 4.1162  \n",
      "\n",
      "Fold: 4  Epoch: 611  Training loss = 1.5739  Validation loss = 4.1161  \n",
      "\n",
      "Fold: 4  Epoch: 612  Training loss = 1.5738  Validation loss = 4.1156  \n",
      "\n",
      "Fold: 4  Epoch: 613  Training loss = 1.5737  Validation loss = 4.1152  \n",
      "\n",
      "Fold: 4  Epoch: 614  Training loss = 1.5736  Validation loss = 4.1148  \n",
      "\n",
      "Fold: 4  Epoch: 615  Training loss = 1.5735  Validation loss = 4.1146  \n",
      "\n",
      "Fold: 4  Epoch: 616  Training loss = 1.5735  Validation loss = 4.1143  \n",
      "\n",
      "Fold: 4  Epoch: 617  Training loss = 1.5735  Validation loss = 4.1144  \n",
      "\n",
      "Fold: 4  Epoch: 618  Training loss = 1.5733  Validation loss = 4.1138  \n",
      "\n",
      "Fold: 4  Epoch: 619  Training loss = 1.5732  Validation loss = 4.1133  \n",
      "\n",
      "Fold: 4  Epoch: 620  Training loss = 1.5732  Validation loss = 4.1134  \n",
      "\n",
      "Fold: 4  Epoch: 621  Training loss = 1.5731  Validation loss = 4.1135  \n",
      "\n",
      "Fold: 4  Epoch: 622  Training loss = 1.5731  Validation loss = 4.1131  \n",
      "\n",
      "Fold: 4  Epoch: 623  Training loss = 1.5730  Validation loss = 4.1130  \n",
      "\n",
      "Fold: 4  Epoch: 624  Training loss = 1.5730  Validation loss = 4.1130  \n",
      "\n",
      "Fold: 4  Epoch: 625  Training loss = 1.5730  Validation loss = 4.1129  \n",
      "\n",
      "Fold: 4  Epoch: 626  Training loss = 1.5729  Validation loss = 4.1124  \n",
      "\n",
      "Fold: 4  Epoch: 627  Training loss = 1.5728  Validation loss = 4.1118  \n",
      "\n",
      "Fold: 4  Epoch: 628  Training loss = 1.5728  Validation loss = 4.1117  \n",
      "\n",
      "Fold: 4  Epoch: 629  Training loss = 1.5727  Validation loss = 4.1112  \n",
      "\n",
      "Fold: 4  Epoch: 630  Training loss = 1.5726  Validation loss = 4.1108  \n",
      "\n",
      "Fold: 4  Epoch: 631  Training loss = 1.5725  Validation loss = 4.1107  \n",
      "\n",
      "Fold: 4  Epoch: 632  Training loss = 1.5724  Validation loss = 4.1099  \n",
      "\n",
      "Fold: 4  Epoch: 633  Training loss = 1.5723  Validation loss = 4.1094  \n",
      "\n",
      "Fold: 4  Epoch: 634  Training loss = 1.5722  Validation loss = 4.1092  \n",
      "\n",
      "Fold: 4  Epoch: 635  Training loss = 1.5722  Validation loss = 4.1094  \n",
      "\n",
      "Fold: 4  Epoch: 636  Training loss = 1.5722  Validation loss = 4.1090  \n",
      "\n",
      "Fold: 4  Epoch: 637  Training loss = 1.5721  Validation loss = 4.1086  \n",
      "\n",
      "Fold: 4  Epoch: 638  Training loss = 1.5721  Validation loss = 4.1086  \n",
      "\n",
      "Fold: 4  Epoch: 639  Training loss = 1.5721  Validation loss = 4.1085  \n",
      "\n",
      "Fold: 4  Epoch: 640  Training loss = 1.5721  Validation loss = 4.1086  \n",
      "\n",
      "Fold: 4  Epoch: 641  Training loss = 1.5720  Validation loss = 4.1083  \n",
      "\n",
      "Fold: 4  Epoch: 642  Training loss = 1.5719  Validation loss = 4.1080  \n",
      "\n",
      "Fold: 4  Epoch: 643  Training loss = 1.5718  Validation loss = 4.1076  \n",
      "\n",
      "Fold: 4  Epoch: 644  Training loss = 1.5718  Validation loss = 4.1075  \n",
      "\n",
      "Fold: 4  Epoch: 645  Training loss = 1.5717  Validation loss = 4.1074  \n",
      "\n",
      "Fold: 4  Epoch: 646  Training loss = 1.5717  Validation loss = 4.1074  \n",
      "\n",
      "Fold: 4  Epoch: 647  Training loss = 1.5716  Validation loss = 4.1071  \n",
      "\n",
      "Fold: 4  Epoch: 648  Training loss = 1.5715  Validation loss = 4.1069  \n",
      "\n",
      "Fold: 4  Epoch: 649  Training loss = 1.5715  Validation loss = 4.1066  \n",
      "\n",
      "Fold: 4  Epoch: 650  Training loss = 1.5714  Validation loss = 4.1065  \n",
      "\n",
      "Fold: 4  Epoch: 651  Training loss = 1.5713  Validation loss = 4.1064  \n",
      "\n",
      "Fold: 4  Epoch: 652  Training loss = 1.5713  Validation loss = 4.1061  \n",
      "\n",
      "Fold: 4  Epoch: 653  Training loss = 1.5712  Validation loss = 4.1061  \n",
      "\n",
      "Fold: 4  Epoch: 654  Training loss = 1.5712  Validation loss = 4.1060  \n",
      "\n",
      "Fold: 4  Epoch: 655  Training loss = 1.5712  Validation loss = 4.1060  \n",
      "\n",
      "Fold: 4  Epoch: 656  Training loss = 1.5711  Validation loss = 4.1059  \n",
      "\n",
      "Fold: 4  Epoch: 657  Training loss = 1.5711  Validation loss = 4.1059  \n",
      "\n",
      "Fold: 4  Epoch: 658  Training loss = 1.5710  Validation loss = 4.1058  \n",
      "\n",
      "Fold: 4  Epoch: 659  Training loss = 1.5710  Validation loss = 4.1052  \n",
      "\n",
      "Fold: 4  Epoch: 660  Training loss = 1.5709  Validation loss = 4.1049  \n",
      "\n",
      "Fold: 4  Epoch: 661  Training loss = 1.5708  Validation loss = 4.1046  \n",
      "\n",
      "Fold: 4  Epoch: 662  Training loss = 1.5707  Validation loss = 4.1043  \n",
      "\n",
      "Fold: 4  Epoch: 663  Training loss = 1.5707  Validation loss = 4.1046  \n",
      "\n",
      "Fold: 4  Epoch: 664  Training loss = 1.5707  Validation loss = 4.1045  \n",
      "\n",
      "Fold: 4  Epoch: 665  Training loss = 1.5706  Validation loss = 4.1043  \n",
      "\n",
      "Fold: 4  Epoch: 666  Training loss = 1.5706  Validation loss = 4.1042  \n",
      "\n",
      "Fold: 4  Epoch: 667  Training loss = 1.5705  Validation loss = 4.1041  \n",
      "\n",
      "Fold: 4  Epoch: 668  Training loss = 1.5705  Validation loss = 4.1042  \n",
      "\n",
      "Fold: 4  Epoch: 669  Training loss = 1.5704  Validation loss = 4.1036  \n",
      "\n",
      "Fold: 4  Epoch: 670  Training loss = 1.5704  Validation loss = 4.1035  \n",
      "\n",
      "Fold: 4  Epoch: 671  Training loss = 1.5703  Validation loss = 4.1031  \n",
      "\n",
      "Fold: 4  Epoch: 672  Training loss = 1.5703  Validation loss = 4.1029  \n",
      "\n",
      "Fold: 4  Epoch: 673  Training loss = 1.5702  Validation loss = 4.1023  \n",
      "\n",
      "Fold: 4  Epoch: 674  Training loss = 1.5702  Validation loss = 4.1023  \n",
      "\n",
      "Fold: 4  Epoch: 675  Training loss = 1.5701  Validation loss = 4.1020  \n",
      "\n",
      "Fold: 4  Epoch: 676  Training loss = 1.5700  Validation loss = 4.1018  \n",
      "\n",
      "Fold: 4  Epoch: 677  Training loss = 1.5700  Validation loss = 4.1017  \n",
      "\n",
      "Fold: 4  Epoch: 678  Training loss = 1.5700  Validation loss = 4.1017  \n",
      "\n",
      "Fold: 4  Epoch: 679  Training loss = 1.5699  Validation loss = 4.1013  \n",
      "\n",
      "Fold: 4  Epoch: 680  Training loss = 1.5698  Validation loss = 4.1010  \n",
      "\n",
      "Fold: 4  Epoch: 681  Training loss = 1.5697  Validation loss = 4.1007  \n",
      "\n",
      "Fold: 4  Epoch: 682  Training loss = 1.5697  Validation loss = 4.1007  \n",
      "\n",
      "Fold: 4  Epoch: 683  Training loss = 1.5696  Validation loss = 4.1004  \n",
      "\n",
      "Fold: 4  Epoch: 684  Training loss = 1.5696  Validation loss = 4.1003  \n",
      "\n",
      "Fold: 4  Epoch: 685  Training loss = 1.5695  Validation loss = 4.1004  \n",
      "\n",
      "Fold: 4  Epoch: 686  Training loss = 1.5695  Validation loss = 4.1000  \n",
      "\n",
      "Fold: 4  Epoch: 687  Training loss = 1.5694  Validation loss = 4.1000  \n",
      "\n",
      "Fold: 4  Epoch: 688  Training loss = 1.5694  Validation loss = 4.0999  \n",
      "\n",
      "Fold: 4  Epoch: 689  Training loss = 1.5693  Validation loss = 4.0999  \n",
      "\n",
      "Fold: 4  Epoch: 690  Training loss = 1.5693  Validation loss = 4.0995  \n",
      "\n",
      "Fold: 4  Epoch: 691  Training loss = 1.5692  Validation loss = 4.0994  \n",
      "\n",
      "Fold: 4  Epoch: 692  Training loss = 1.5692  Validation loss = 4.0993  \n",
      "\n",
      "Fold: 4  Epoch: 693  Training loss = 1.5691  Validation loss = 4.0990  \n",
      "\n",
      "Fold: 4  Epoch: 694  Training loss = 1.5691  Validation loss = 4.0986  \n",
      "\n",
      "Fold: 4  Epoch: 695  Training loss = 1.5690  Validation loss = 4.0980  \n",
      "\n",
      "Fold: 4  Epoch: 696  Training loss = 1.5689  Validation loss = 4.0980  \n",
      "\n",
      "Fold: 4  Epoch: 697  Training loss = 1.5688  Validation loss = 4.0974  \n",
      "\n",
      "Fold: 4  Epoch: 698  Training loss = 1.5687  Validation loss = 4.0970  \n",
      "\n",
      "Fold: 4  Epoch: 699  Training loss = 1.5686  Validation loss = 4.0970  \n",
      "\n",
      "Fold: 4  Epoch: 700  Training loss = 1.5686  Validation loss = 4.0968  \n",
      "\n",
      "Fold: 4  Epoch: 701  Training loss = 1.5685  Validation loss = 4.0964  \n",
      "\n",
      "Fold: 4  Epoch: 702  Training loss = 1.5684  Validation loss = 4.0960  \n",
      "\n",
      "Fold: 4  Epoch: 703  Training loss = 1.5684  Validation loss = 4.0960  \n",
      "\n",
      "Fold: 4  Epoch: 704  Training loss = 1.5684  Validation loss = 4.0958  \n",
      "\n",
      "Fold: 4  Epoch: 705  Training loss = 1.5684  Validation loss = 4.0960  \n",
      "\n",
      "Fold: 4  Epoch: 706  Training loss = 1.5683  Validation loss = 4.0961  \n",
      "\n",
      "Fold: 4  Epoch: 707  Training loss = 1.5683  Validation loss = 4.0960  \n",
      "\n",
      "Fold: 4  Epoch: 708  Training loss = 1.5682  Validation loss = 4.0957  \n",
      "\n",
      "Fold: 4  Epoch: 709  Training loss = 1.5682  Validation loss = 4.0954  \n",
      "\n",
      "Fold: 4  Epoch: 710  Training loss = 1.5681  Validation loss = 4.0955  \n",
      "\n",
      "Fold: 4  Epoch: 711  Training loss = 1.5681  Validation loss = 4.0952  \n",
      "\n",
      "Fold: 4  Epoch: 712  Training loss = 1.5681  Validation loss = 4.0954  \n",
      "\n",
      "Fold: 4  Epoch: 713  Training loss = 1.5680  Validation loss = 4.0950  \n",
      "\n",
      "Fold: 4  Epoch: 714  Training loss = 1.5680  Validation loss = 4.0949  \n",
      "\n",
      "Fold: 4  Epoch: 715  Training loss = 1.5679  Validation loss = 4.0946  \n",
      "\n",
      "Fold: 4  Epoch: 716  Training loss = 1.5679  Validation loss = 4.0946  \n",
      "\n",
      "Fold: 4  Epoch: 717  Training loss = 1.5678  Validation loss = 4.0944  \n",
      "\n",
      "Fold: 4  Epoch: 718  Training loss = 1.5677  Validation loss = 4.0937  \n",
      "\n",
      "Fold: 4  Epoch: 719  Training loss = 1.5677  Validation loss = 4.0938  \n",
      "\n",
      "Fold: 4  Epoch: 720  Training loss = 1.5677  Validation loss = 4.0936  \n",
      "\n",
      "Fold: 4  Epoch: 721  Training loss = 1.5676  Validation loss = 4.0937  \n",
      "\n",
      "Fold: 4  Epoch: 722  Training loss = 1.5676  Validation loss = 4.0936  \n",
      "\n",
      "Fold: 4  Epoch: 723  Training loss = 1.5676  Validation loss = 4.0934  \n",
      "\n",
      "Fold: 4  Epoch: 724  Training loss = 1.5675  Validation loss = 4.0934  \n",
      "\n",
      "Fold: 4  Epoch: 725  Training loss = 1.5675  Validation loss = 4.0932  \n",
      "\n",
      "Fold: 4  Epoch: 726  Training loss = 1.5674  Validation loss = 4.0932  \n",
      "\n",
      "Fold: 4  Epoch: 727  Training loss = 1.5674  Validation loss = 4.0927  \n",
      "\n",
      "Fold: 4  Epoch: 728  Training loss = 1.5673  Validation loss = 4.0922  \n",
      "\n",
      "Fold: 4  Epoch: 729  Training loss = 1.5673  Validation loss = 4.0922  \n",
      "\n",
      "Fold: 4  Epoch: 730  Training loss = 1.5672  Validation loss = 4.0918  \n",
      "\n",
      "Fold: 4  Epoch: 731  Training loss = 1.5672  Validation loss = 4.0915  \n",
      "\n",
      "Fold: 4  Epoch: 732  Training loss = 1.5671  Validation loss = 4.0913  \n",
      "\n",
      "Fold: 4  Epoch: 733  Training loss = 1.5671  Validation loss = 4.0911  \n",
      "\n",
      "Fold: 4  Epoch: 734  Training loss = 1.5671  Validation loss = 4.0914  \n",
      "\n",
      "Fold: 4  Epoch: 735  Training loss = 1.5669  Validation loss = 4.0907  \n",
      "\n",
      "Fold: 4  Epoch: 736  Training loss = 1.5669  Validation loss = 4.0907  \n",
      "\n",
      "Fold: 4  Epoch: 737  Training loss = 1.5668  Validation loss = 4.0903  \n",
      "\n",
      "Fold: 4  Epoch: 738  Training loss = 1.5668  Validation loss = 4.0901  \n",
      "\n",
      "Fold: 4  Epoch: 739  Training loss = 1.5668  Validation loss = 4.0905  \n",
      "\n",
      "Fold: 4  Epoch: 740  Training loss = 1.5668  Validation loss = 4.0904  \n",
      "\n",
      "Fold: 4  Epoch: 741  Training loss = 1.5667  Validation loss = 4.0901  \n",
      "\n",
      "Fold: 4  Epoch: 742  Training loss = 1.5666  Validation loss = 4.0897  \n",
      "\n",
      "Fold: 4  Epoch: 743  Training loss = 1.5666  Validation loss = 4.0898  \n",
      "\n",
      "Fold: 4  Epoch: 744  Training loss = 1.5665  Validation loss = 4.0893  \n",
      "\n",
      "Fold: 4  Epoch: 745  Training loss = 1.5665  Validation loss = 4.0889  \n",
      "\n",
      "Fold: 4  Epoch: 746  Training loss = 1.5664  Validation loss = 4.0888  \n",
      "\n",
      "Fold: 4  Epoch: 747  Training loss = 1.5664  Validation loss = 4.0886  \n",
      "\n",
      "Fold: 4  Epoch: 748  Training loss = 1.5663  Validation loss = 4.0884  \n",
      "\n",
      "Fold: 4  Epoch: 749  Training loss = 1.5663  Validation loss = 4.0883  \n",
      "\n",
      "Fold: 4  Epoch: 750  Training loss = 1.5662  Validation loss = 4.0880  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 750  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.8145  Validation loss = 3.8669  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.8143  Validation loss = 3.8660  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.8142  Validation loss = 3.8656  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.8140  Validation loss = 3.8648  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.8139  Validation loss = 3.8644  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.8138  Validation loss = 3.8641  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.8137  Validation loss = 3.8640  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.8135  Validation loss = 3.8632  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.8135  Validation loss = 3.8629  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.8132  Validation loss = 3.8618  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.8131  Validation loss = 3.8618  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.8130  Validation loss = 3.8613  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.8128  Validation loss = 3.8605  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.8125  Validation loss = 3.8592  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.8124  Validation loss = 3.8586  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.8122  Validation loss = 3.8579  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.8120  Validation loss = 3.8571  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.8118  Validation loss = 3.8565  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.8116  Validation loss = 3.8558  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.8114  Validation loss = 3.8552  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.8112  Validation loss = 3.8540  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.8110  Validation loss = 3.8533  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.8109  Validation loss = 3.8533  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.8108  Validation loss = 3.8526  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.8105  Validation loss = 3.8510  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.8103  Validation loss = 3.8500  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.8103  Validation loss = 3.8499  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.8101  Validation loss = 3.8494  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.8100  Validation loss = 3.8493  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.8099  Validation loss = 3.8485  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.8097  Validation loss = 3.8480  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.8095  Validation loss = 3.8472  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.8094  Validation loss = 3.8465  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.8092  Validation loss = 3.8456  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.8091  Validation loss = 3.8450  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.8089  Validation loss = 3.8442  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.8086  Validation loss = 3.8429  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.8084  Validation loss = 3.8423  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.8083  Validation loss = 3.8422  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.8082  Validation loss = 3.8415  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.8079  Validation loss = 3.8408  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.8076  Validation loss = 3.8393  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.8074  Validation loss = 3.8384  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.8073  Validation loss = 3.8378  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.8072  Validation loss = 3.8375  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.8069  Validation loss = 3.8368  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.8068  Validation loss = 3.8363  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.8067  Validation loss = 3.8364  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.8066  Validation loss = 3.8357  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.8064  Validation loss = 3.8352  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.8064  Validation loss = 3.8352  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.8063  Validation loss = 3.8349  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.8061  Validation loss = 3.8334  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.8060  Validation loss = 3.8336  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.8058  Validation loss = 3.8328  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.8058  Validation loss = 3.8331  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.8057  Validation loss = 3.8326  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.8055  Validation loss = 3.8320  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.8054  Validation loss = 3.8313  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.8051  Validation loss = 3.8300  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.8049  Validation loss = 3.8290  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.8049  Validation loss = 3.8290  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.8048  Validation loss = 3.8290  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.8048  Validation loss = 3.8287  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.8046  Validation loss = 3.8276  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.8043  Validation loss = 3.8263  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.8041  Validation loss = 3.8253  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.8040  Validation loss = 3.8250  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.8039  Validation loss = 3.8241  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.8038  Validation loss = 3.8237  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.8037  Validation loss = 3.8232  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.8036  Validation loss = 3.8229  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.8034  Validation loss = 3.8218  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.8032  Validation loss = 3.8213  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.8030  Validation loss = 3.8203  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.8028  Validation loss = 3.8197  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.8027  Validation loss = 3.8194  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 1.8027  Validation loss = 3.8197  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 1.8025  Validation loss = 3.8189  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 1.8024  Validation loss = 3.8184  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 1.8022  Validation loss = 3.8172  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 1.8020  Validation loss = 3.8165  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 1.8019  Validation loss = 3.8158  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 1.8018  Validation loss = 3.8154  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 1.8016  Validation loss = 3.8147  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 1.8015  Validation loss = 3.8145  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 1.8014  Validation loss = 3.8142  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 1.8012  Validation loss = 3.8128  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 1.8010  Validation loss = 3.8125  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 1.8009  Validation loss = 3.8122  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 1.8008  Validation loss = 3.8120  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 1.8007  Validation loss = 3.8112  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 1.8006  Validation loss = 3.8108  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 1.8004  Validation loss = 3.8104  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 1.8003  Validation loss = 3.8098  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 1.8003  Validation loss = 3.8102  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 1.8002  Validation loss = 3.8099  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 1.8001  Validation loss = 3.8097  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 1.8000  Validation loss = 3.8089  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 1.7998  Validation loss = 3.8082  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 1.7997  Validation loss = 3.8079  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 1.7996  Validation loss = 3.8080  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 1.7996  Validation loss = 3.8080  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 1.7994  Validation loss = 3.8072  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 1.7993  Validation loss = 3.8071  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 1.7992  Validation loss = 3.8070  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 1.7991  Validation loss = 3.8062  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 1.7989  Validation loss = 3.8055  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 1.7988  Validation loss = 3.8045  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 1.7986  Validation loss = 3.8039  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 1.7985  Validation loss = 3.8035  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 1.7983  Validation loss = 3.8027  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 1.7982  Validation loss = 3.8022  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 1.7980  Validation loss = 3.8015  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 1.7979  Validation loss = 3.8012  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 1.7978  Validation loss = 3.8006  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 1.7976  Validation loss = 3.7992  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 1.7975  Validation loss = 3.7991  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 1.7974  Validation loss = 3.7990  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 1.7972  Validation loss = 3.7980  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 1.7971  Validation loss = 3.7977  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 1.7969  Validation loss = 3.7967  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 1.7968  Validation loss = 3.7965  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 1.7967  Validation loss = 3.7957  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 1.7965  Validation loss = 3.7950  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 1.7964  Validation loss = 3.7949  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 1.7963  Validation loss = 3.7944  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 1.7962  Validation loss = 3.7944  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 1.7961  Validation loss = 3.7947  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 1.7960  Validation loss = 3.7942  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 1.7959  Validation loss = 3.7934  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 1.7958  Validation loss = 3.7928  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 1.7956  Validation loss = 3.7927  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 1.7955  Validation loss = 3.7921  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 1.7954  Validation loss = 3.7913  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 1.7954  Validation loss = 3.7916  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 1.7952  Validation loss = 3.7908  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 1.7952  Validation loss = 3.7908  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 1.7951  Validation loss = 3.7901  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 1.7949  Validation loss = 3.7889  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 1.7946  Validation loss = 3.7878  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 1.7945  Validation loss = 3.7875  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 1.7944  Validation loss = 3.7871  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 1.7942  Validation loss = 3.7865  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 1.7942  Validation loss = 3.7865  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 1.7940  Validation loss = 3.7858  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 1.7940  Validation loss = 3.7859  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 1.7938  Validation loss = 3.7852  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 1.7937  Validation loss = 3.7846  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 1.7935  Validation loss = 3.7839  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 1.7934  Validation loss = 3.7835  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 1.7932  Validation loss = 3.7825  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 1.7930  Validation loss = 3.7820  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 1.7929  Validation loss = 3.7813  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 1.7928  Validation loss = 3.7806  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 1.7927  Validation loss = 3.7802  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 1.7925  Validation loss = 3.7798  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 1.7925  Validation loss = 3.7798  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 1.7923  Validation loss = 3.7789  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 1.7921  Validation loss = 3.7775  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 1.7920  Validation loss = 3.7775  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 1.7919  Validation loss = 3.7770  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 1.7917  Validation loss = 3.7759  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 1.7917  Validation loss = 3.7764  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 1.7916  Validation loss = 3.7759  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 1.7914  Validation loss = 3.7756  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 1.7912  Validation loss = 3.7752  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 1.7911  Validation loss = 3.7746  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 1.7910  Validation loss = 3.7741  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 1.7908  Validation loss = 3.7732  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 1.7907  Validation loss = 3.7727  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 1.7906  Validation loss = 3.7722  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 1.7904  Validation loss = 3.7716  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 1.7904  Validation loss = 3.7716  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 1.7902  Validation loss = 3.7707  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 1.7901  Validation loss = 3.7705  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 1.7900  Validation loss = 3.7702  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 1.7899  Validation loss = 3.7695  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 1.7898  Validation loss = 3.7688  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 1.7896  Validation loss = 3.7680  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 1.7895  Validation loss = 3.7680  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 1.7895  Validation loss = 3.7680  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 1.7894  Validation loss = 3.7681  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 1.7893  Validation loss = 3.7676  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 1.7891  Validation loss = 3.7664  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 1.7889  Validation loss = 3.7652  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 1.7888  Validation loss = 3.7652  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 1.7887  Validation loss = 3.7652  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 1.7885  Validation loss = 3.7643  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 1.7884  Validation loss = 3.7637  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 1.7882  Validation loss = 3.7632  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 1.7881  Validation loss = 3.7624  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 1.7880  Validation loss = 3.7618  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 1.7879  Validation loss = 3.7618  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 1.7877  Validation loss = 3.7604  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 1.7875  Validation loss = 3.7589  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 1.7872  Validation loss = 3.7576  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 1.7871  Validation loss = 3.7577  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 1.7870  Validation loss = 3.7575  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 1.7870  Validation loss = 3.7579  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 1.7868  Validation loss = 3.7575  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 1.7868  Validation loss = 3.7575  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 1.7868  Validation loss = 3.7576  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 1.7866  Validation loss = 3.7568  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 1.7865  Validation loss = 3.7568  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 1.7863  Validation loss = 3.7559  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 1.7862  Validation loss = 3.7553  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 1.7861  Validation loss = 3.7548  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 1.7860  Validation loss = 3.7543  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 1.7859  Validation loss = 3.7538  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 1.7857  Validation loss = 3.7533  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 1.7856  Validation loss = 3.7527  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 1.7854  Validation loss = 3.7517  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 1.7853  Validation loss = 3.7514  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 1.7852  Validation loss = 3.7507  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 1.7851  Validation loss = 3.7503  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 1.7850  Validation loss = 3.7498  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 1.7849  Validation loss = 3.7496  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 1.7849  Validation loss = 3.7500  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 1.7849  Validation loss = 3.7504  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 1.7846  Validation loss = 3.7487  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 1.7845  Validation loss = 3.7479  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 1.7845  Validation loss = 3.7484  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 1.7844  Validation loss = 3.7480  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 1.7841  Validation loss = 3.7463  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 1.7841  Validation loss = 3.7462  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 1.7840  Validation loss = 3.7458  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 1.7839  Validation loss = 3.7456  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 1.7838  Validation loss = 3.7454  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 1.7836  Validation loss = 3.7440  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 1.7835  Validation loss = 3.7429  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 1.7833  Validation loss = 3.7421  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 1.7833  Validation loss = 3.7425  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 1.7831  Validation loss = 3.7422  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 1.7831  Validation loss = 3.7421  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 1.7831  Validation loss = 3.7427  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 1.7829  Validation loss = 3.7421  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 1.7828  Validation loss = 3.7417  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 1.7827  Validation loss = 3.7408  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 1.7826  Validation loss = 3.7403  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 1.7824  Validation loss = 3.7393  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 1.7823  Validation loss = 3.7386  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 1.7823  Validation loss = 3.7386  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 1.7822  Validation loss = 3.7384  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 1.7822  Validation loss = 3.7385  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 1.7821  Validation loss = 3.7384  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 1.7820  Validation loss = 3.7380  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 1.7819  Validation loss = 3.7375  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 1.7817  Validation loss = 3.7358  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 1.7816  Validation loss = 3.7357  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 1.7815  Validation loss = 3.7357  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 1.7814  Validation loss = 3.7351  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 1.7813  Validation loss = 3.7347  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 1.7812  Validation loss = 3.7341  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 1.7812  Validation loss = 3.7342  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 1.7811  Validation loss = 3.7335  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 1.7810  Validation loss = 3.7327  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 1.7808  Validation loss = 3.7324  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 1.7807  Validation loss = 3.7319  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 1.7807  Validation loss = 3.7322  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 1.7806  Validation loss = 3.7320  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 1.7806  Validation loss = 3.7315  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 1.7805  Validation loss = 3.7314  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 1.7804  Validation loss = 3.7310  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 1.7803  Validation loss = 3.7306  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 1.7801  Validation loss = 3.7291  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 1.7800  Validation loss = 3.7293  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 1.7799  Validation loss = 3.7284  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 1.7798  Validation loss = 3.7278  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 1.7797  Validation loss = 3.7275  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 1.7796  Validation loss = 3.7272  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 1.7794  Validation loss = 3.7263  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 1.7794  Validation loss = 3.7263  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 1.7792  Validation loss = 3.7259  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 1.7791  Validation loss = 3.7254  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 1.7790  Validation loss = 3.7257  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 1.7789  Validation loss = 3.7248  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 1.7788  Validation loss = 3.7245  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 1.7787  Validation loss = 3.7235  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 1.7785  Validation loss = 3.7228  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 1.7785  Validation loss = 3.7229  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 1.7784  Validation loss = 3.7226  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 1.7783  Validation loss = 3.7224  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 1.7781  Validation loss = 3.7214  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 1.7780  Validation loss = 3.7208  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 1.7779  Validation loss = 3.7207  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 1.7778  Validation loss = 3.7203  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 1.7778  Validation loss = 3.7206  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 1.7777  Validation loss = 3.7199  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 1.7776  Validation loss = 3.7198  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 1.7775  Validation loss = 3.7198  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 1.7775  Validation loss = 3.7197  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 1.7774  Validation loss = 3.7193  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 1.7773  Validation loss = 3.7188  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 1.7772  Validation loss = 3.7185  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 1.7771  Validation loss = 3.7179  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 1.7770  Validation loss = 3.7175  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 1.7769  Validation loss = 3.7168  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 1.7768  Validation loss = 3.7164  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 1.7767  Validation loss = 3.7158  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 1.7766  Validation loss = 3.7153  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 1.7765  Validation loss = 3.7148  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 1.7764  Validation loss = 3.7147  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 1.7762  Validation loss = 3.7140  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 1.7762  Validation loss = 3.7139  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 1.7761  Validation loss = 3.7135  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 1.7759  Validation loss = 3.7131  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 1.7759  Validation loss = 3.7131  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 1.7758  Validation loss = 3.7128  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 1.7757  Validation loss = 3.7124  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 1.7756  Validation loss = 3.7114  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 1.7754  Validation loss = 3.7107  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 1.7754  Validation loss = 3.7110  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 1.7753  Validation loss = 3.7110  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 1.7751  Validation loss = 3.7103  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 1.7750  Validation loss = 3.7097  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 1.7749  Validation loss = 3.7088  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 1.7747  Validation loss = 3.7078  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 1.7747  Validation loss = 3.7078  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 1.7746  Validation loss = 3.7076  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 1.7745  Validation loss = 3.7069  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 1.7744  Validation loss = 3.7066  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 1.7743  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 1.7742  Validation loss = 3.7055  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 1.7741  Validation loss = 3.7050  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 1.7740  Validation loss = 3.7048  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 1.7740  Validation loss = 3.7048  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 1.7738  Validation loss = 3.7043  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 1.7737  Validation loss = 3.7043  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 1.7737  Validation loss = 3.7042  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 1.7736  Validation loss = 3.7041  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 1.7735  Validation loss = 3.7032  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 1.7734  Validation loss = 3.7032  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 1.7733  Validation loss = 3.7025  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 1.7733  Validation loss = 3.7026  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 1.7732  Validation loss = 3.7021  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 1.7730  Validation loss = 3.7010  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 1.7729  Validation loss = 3.7009  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 1.7728  Validation loss = 3.7003  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 1.7727  Validation loss = 3.6992  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 1.7726  Validation loss = 3.6987  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 1.7725  Validation loss = 3.6985  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 1.7724  Validation loss = 3.6977  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 1.7723  Validation loss = 3.6972  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 1.7722  Validation loss = 3.6962  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 1.7721  Validation loss = 3.6958  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 1.7719  Validation loss = 3.6955  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 1.7719  Validation loss = 3.6954  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 1.7718  Validation loss = 3.6953  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 1.7718  Validation loss = 3.6947  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 1.7716  Validation loss = 3.6940  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 1.7715  Validation loss = 3.6934  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 1.7714  Validation loss = 3.6924  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 1.7713  Validation loss = 3.6924  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 1.7712  Validation loss = 3.6912  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 1.7711  Validation loss = 3.6908  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 1.7710  Validation loss = 3.6906  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 1.7710  Validation loss = 3.6907  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 1.7708  Validation loss = 3.6900  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 1.7707  Validation loss = 3.6898  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 1.7707  Validation loss = 3.6893  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 1.7706  Validation loss = 3.6884  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 1.7705  Validation loss = 3.6880  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 1.7704  Validation loss = 3.6879  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 1.7703  Validation loss = 3.6871  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 1.7702  Validation loss = 3.6872  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 1.7702  Validation loss = 3.6869  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 1.7701  Validation loss = 3.6865  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 1.7700  Validation loss = 3.6859  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 1.7699  Validation loss = 3.6859  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 1.7699  Validation loss = 3.6859  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 1.7698  Validation loss = 3.6854  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 1.7697  Validation loss = 3.6844  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 1.7696  Validation loss = 3.6839  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 1.7694  Validation loss = 3.6834  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 1.7692  Validation loss = 3.6819  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 1.7691  Validation loss = 3.6810  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 1.7690  Validation loss = 3.6809  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 1.7689  Validation loss = 3.6802  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 1.7689  Validation loss = 3.6804  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 1.7688  Validation loss = 3.6804  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 1.7687  Validation loss = 3.6796  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 1.7686  Validation loss = 3.6793  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 1.7685  Validation loss = 3.6781  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 1.7683  Validation loss = 3.6775  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 1.7683  Validation loss = 3.6776  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 1.7682  Validation loss = 3.6770  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 1.7680  Validation loss = 3.6760  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 1.7680  Validation loss = 3.6755  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 1.7679  Validation loss = 3.6752  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 1.7678  Validation loss = 3.6752  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 1.7678  Validation loss = 3.6752  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 1.7677  Validation loss = 3.6748  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 1.7675  Validation loss = 3.6740  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 1.7675  Validation loss = 3.6738  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 1.7674  Validation loss = 3.6727  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 1.7672  Validation loss = 3.6721  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 1.7671  Validation loss = 3.6721  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 1.7670  Validation loss = 3.6720  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 1.7669  Validation loss = 3.6713  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 1.7668  Validation loss = 3.6708  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 1.7667  Validation loss = 3.6706  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 1.7666  Validation loss = 3.6699  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 1.7665  Validation loss = 3.6700  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 1.7663  Validation loss = 3.6688  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 1.7662  Validation loss = 3.6680  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 1.7661  Validation loss = 3.6664  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 1.7659  Validation loss = 3.6658  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 1.7659  Validation loss = 3.6654  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 1.7657  Validation loss = 3.6648  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 1.7657  Validation loss = 3.6647  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 1.7656  Validation loss = 3.6653  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 1.7655  Validation loss = 3.6649  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 1.7655  Validation loss = 3.6652  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 1.7654  Validation loss = 3.6654  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 1.7654  Validation loss = 3.6651  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 1.7653  Validation loss = 3.6649  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 1.7652  Validation loss = 3.6644  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 1.7651  Validation loss = 3.6631  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 1.7650  Validation loss = 3.6622  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 1.7649  Validation loss = 3.6617  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 1.7648  Validation loss = 3.6607  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 1.7647  Validation loss = 3.6601  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 1.7646  Validation loss = 3.6589  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 1.7645  Validation loss = 3.6590  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 1.7644  Validation loss = 3.6588  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 1.7643  Validation loss = 3.6581  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 1.7642  Validation loss = 3.6571  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 1.7641  Validation loss = 3.6570  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 1.7639  Validation loss = 3.6562  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 1.7639  Validation loss = 3.6558  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 1.7638  Validation loss = 3.6558  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 1.7637  Validation loss = 3.6560  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 1.7636  Validation loss = 3.6553  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 1.7635  Validation loss = 3.6543  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 1.7634  Validation loss = 3.6541  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 1.7633  Validation loss = 3.6537  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 1.7632  Validation loss = 3.6534  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 1.7631  Validation loss = 3.6530  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 1.7631  Validation loss = 3.6531  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 1.7630  Validation loss = 3.6528  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 1.7629  Validation loss = 3.6521  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 1.7628  Validation loss = 3.6518  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 1.7627  Validation loss = 3.6514  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 1.7626  Validation loss = 3.6507  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 1.7625  Validation loss = 3.6503  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 1.7624  Validation loss = 3.6495  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 1.7622  Validation loss = 3.6486  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 1.7622  Validation loss = 3.6479  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 1.7621  Validation loss = 3.6482  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 1.7620  Validation loss = 3.6480  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 1.7620  Validation loss = 3.6480  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 1.7619  Validation loss = 3.6475  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 1.7618  Validation loss = 3.6470  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 1.7616  Validation loss = 3.6462  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 1.7616  Validation loss = 3.6466  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 1.7615  Validation loss = 3.6459  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 1.7614  Validation loss = 3.6455  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 1.7614  Validation loss = 3.6457  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 1.7614  Validation loss = 3.6452  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 1.7612  Validation loss = 3.6449  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 1.7612  Validation loss = 3.6454  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 1.7611  Validation loss = 3.6451  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 1.7611  Validation loss = 3.6450  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 1.7610  Validation loss = 3.6440  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 1.7609  Validation loss = 3.6439  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 1.7608  Validation loss = 3.6433  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 1.7607  Validation loss = 3.6436  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 1.7607  Validation loss = 3.6436  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 1.7606  Validation loss = 3.6431  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 1.7605  Validation loss = 3.6432  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 1.7604  Validation loss = 3.6429  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 1.7603  Validation loss = 3.6422  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 1.7603  Validation loss = 3.6420  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 1.7602  Validation loss = 3.6411  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 1.7601  Validation loss = 3.6407  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 1.7600  Validation loss = 3.6414  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 1.7600  Validation loss = 3.6415  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 1.7598  Validation loss = 3.6405  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 1.7597  Validation loss = 3.6398  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 1.7596  Validation loss = 3.6395  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 1.7595  Validation loss = 3.6388  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 1.7594  Validation loss = 3.6382  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 1.7593  Validation loss = 3.6376  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 1.7593  Validation loss = 3.6372  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 1.7592  Validation loss = 3.6370  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 1.7591  Validation loss = 3.6367  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 1.7590  Validation loss = 3.6368  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 1.7589  Validation loss = 3.6362  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 1.7589  Validation loss = 3.6360  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 1.7587  Validation loss = 3.6351  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 1.7587  Validation loss = 3.6355  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 1.7586  Validation loss = 3.6349  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 1.7585  Validation loss = 3.6344  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 1.7585  Validation loss = 3.6345  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 1.7584  Validation loss = 3.6339  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 1.7582  Validation loss = 3.6329  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 1.7582  Validation loss = 3.6330  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 1.7581  Validation loss = 3.6324  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 1.7580  Validation loss = 3.6323  \n",
      "\n",
      "Fold: 5  Epoch: 501  Training loss = 1.7578  Validation loss = 3.6320  \n",
      "\n",
      "Fold: 5  Epoch: 502  Training loss = 1.7578  Validation loss = 3.6325  \n",
      "\n",
      "Fold: 5  Epoch: 503  Training loss = 1.7577  Validation loss = 3.6316  \n",
      "\n",
      "Fold: 5  Epoch: 504  Training loss = 1.7576  Validation loss = 3.6314  \n",
      "\n",
      "Fold: 5  Epoch: 505  Training loss = 1.7575  Validation loss = 3.6310  \n",
      "\n",
      "Fold: 5  Epoch: 506  Training loss = 1.7574  Validation loss = 3.6309  \n",
      "\n",
      "Fold: 5  Epoch: 507  Training loss = 1.7573  Validation loss = 3.6300  \n",
      "\n",
      "Fold: 5  Epoch: 508  Training loss = 1.7572  Validation loss = 3.6283  \n",
      "\n",
      "Fold: 5  Epoch: 509  Training loss = 1.7570  Validation loss = 3.6266  \n",
      "\n",
      "Fold: 5  Epoch: 510  Training loss = 1.7570  Validation loss = 3.6269  \n",
      "\n",
      "Fold: 5  Epoch: 511  Training loss = 1.7569  Validation loss = 3.6268  \n",
      "\n",
      "Fold: 5  Epoch: 512  Training loss = 1.7568  Validation loss = 3.6263  \n",
      "\n",
      "Fold: 5  Epoch: 513  Training loss = 1.7568  Validation loss = 3.6263  \n",
      "\n",
      "Fold: 5  Epoch: 514  Training loss = 1.7567  Validation loss = 3.6257  \n",
      "\n",
      "Fold: 5  Epoch: 515  Training loss = 1.7566  Validation loss = 3.6256  \n",
      "\n",
      "Fold: 5  Epoch: 516  Training loss = 1.7565  Validation loss = 3.6253  \n",
      "\n",
      "Fold: 5  Epoch: 517  Training loss = 1.7565  Validation loss = 3.6252  \n",
      "\n",
      "Fold: 5  Epoch: 518  Training loss = 1.7564  Validation loss = 3.6247  \n",
      "\n",
      "Fold: 5  Epoch: 519  Training loss = 1.7563  Validation loss = 3.6236  \n",
      "\n",
      "Fold: 5  Epoch: 520  Training loss = 1.7563  Validation loss = 3.6241  \n",
      "\n",
      "Fold: 5  Epoch: 521  Training loss = 1.7562  Validation loss = 3.6237  \n",
      "\n",
      "Fold: 5  Epoch: 522  Training loss = 1.7561  Validation loss = 3.6231  \n",
      "\n",
      "Fold: 5  Epoch: 523  Training loss = 1.7559  Validation loss = 3.6216  \n",
      "\n",
      "Fold: 5  Epoch: 524  Training loss = 1.7559  Validation loss = 3.6210  \n",
      "\n",
      "Fold: 5  Epoch: 525  Training loss = 1.7558  Validation loss = 3.6214  \n",
      "\n",
      "Fold: 5  Epoch: 526  Training loss = 1.7557  Validation loss = 3.6210  \n",
      "\n",
      "Fold: 5  Epoch: 527  Training loss = 1.7556  Validation loss = 3.6199  \n",
      "\n",
      "Fold: 5  Epoch: 528  Training loss = 1.7556  Validation loss = 3.6204  \n",
      "\n",
      "Fold: 5  Epoch: 529  Training loss = 1.7554  Validation loss = 3.6191  \n",
      "\n",
      "Fold: 5  Epoch: 530  Training loss = 1.7554  Validation loss = 3.6190  \n",
      "\n",
      "Fold: 5  Epoch: 531  Training loss = 1.7553  Validation loss = 3.6191  \n",
      "\n",
      "Fold: 5  Epoch: 532  Training loss = 1.7553  Validation loss = 3.6187  \n",
      "\n",
      "Fold: 5  Epoch: 533  Training loss = 1.7552  Validation loss = 3.6182  \n",
      "\n",
      "Fold: 5  Epoch: 534  Training loss = 1.7551  Validation loss = 3.6185  \n",
      "\n",
      "Fold: 5  Epoch: 535  Training loss = 1.7551  Validation loss = 3.6186  \n",
      "\n",
      "Fold: 5  Epoch: 536  Training loss = 1.7550  Validation loss = 3.6184  \n",
      "\n",
      "Fold: 5  Epoch: 537  Training loss = 1.7548  Validation loss = 3.6178  \n",
      "\n",
      "Fold: 5  Epoch: 538  Training loss = 1.7547  Validation loss = 3.6179  \n",
      "\n",
      "Fold: 5  Epoch: 539  Training loss = 1.7547  Validation loss = 3.6180  \n",
      "\n",
      "Fold: 5  Epoch: 540  Training loss = 1.7547  Validation loss = 3.6179  \n",
      "\n",
      "Fold: 5  Epoch: 541  Training loss = 1.7546  Validation loss = 3.6175  \n",
      "\n",
      "Fold: 5  Epoch: 542  Training loss = 1.7545  Validation loss = 3.6168  \n",
      "\n",
      "Fold: 5  Epoch: 543  Training loss = 1.7544  Validation loss = 3.6161  \n",
      "\n",
      "Fold: 5  Epoch: 544  Training loss = 1.7543  Validation loss = 3.6157  \n",
      "\n",
      "Fold: 5  Epoch: 545  Training loss = 1.7542  Validation loss = 3.6147  \n",
      "\n",
      "Fold: 5  Epoch: 546  Training loss = 1.7541  Validation loss = 3.6146  \n",
      "\n",
      "Fold: 5  Epoch: 547  Training loss = 1.7540  Validation loss = 3.6137  \n",
      "\n",
      "Fold: 5  Epoch: 548  Training loss = 1.7539  Validation loss = 3.6139  \n",
      "\n",
      "Fold: 5  Epoch: 549  Training loss = 1.7539  Validation loss = 3.6136  \n",
      "\n",
      "Fold: 5  Epoch: 550  Training loss = 1.7538  Validation loss = 3.6130  \n",
      "\n",
      "Fold: 5  Epoch: 551  Training loss = 1.7537  Validation loss = 3.6122  \n",
      "\n",
      "Fold: 5  Epoch: 552  Training loss = 1.7536  Validation loss = 3.6115  \n",
      "\n",
      "Fold: 5  Epoch: 553  Training loss = 1.7535  Validation loss = 3.6110  \n",
      "\n",
      "Fold: 5  Epoch: 554  Training loss = 1.7534  Validation loss = 3.6100  \n",
      "\n",
      "Fold: 5  Epoch: 555  Training loss = 1.7533  Validation loss = 3.6095  \n",
      "\n",
      "Fold: 5  Epoch: 556  Training loss = 1.7533  Validation loss = 3.6095  \n",
      "\n",
      "Fold: 5  Epoch: 557  Training loss = 1.7531  Validation loss = 3.6079  \n",
      "\n",
      "Fold: 5  Epoch: 558  Training loss = 1.7530  Validation loss = 3.6081  \n",
      "\n",
      "Fold: 5  Epoch: 559  Training loss = 1.7529  Validation loss = 3.6081  \n",
      "\n",
      "Fold: 5  Epoch: 560  Training loss = 1.7529  Validation loss = 3.6077  \n",
      "\n",
      "Fold: 5  Epoch: 561  Training loss = 1.7527  Validation loss = 3.6064  \n",
      "\n",
      "Fold: 5  Epoch: 562  Training loss = 1.7527  Validation loss = 3.6060  \n",
      "\n",
      "Fold: 5  Epoch: 563  Training loss = 1.7526  Validation loss = 3.6056  \n",
      "\n",
      "Fold: 5  Epoch: 564  Training loss = 1.7524  Validation loss = 3.6044  \n",
      "\n",
      "Fold: 5  Epoch: 565  Training loss = 1.7524  Validation loss = 3.6047  \n",
      "\n",
      "Fold: 5  Epoch: 566  Training loss = 1.7524  Validation loss = 3.6048  \n",
      "\n",
      "Fold: 5  Epoch: 567  Training loss = 1.7523  Validation loss = 3.6044  \n",
      "\n",
      "Fold: 5  Epoch: 568  Training loss = 1.7522  Validation loss = 3.6045  \n",
      "\n",
      "Fold: 5  Epoch: 569  Training loss = 1.7521  Validation loss = 3.6041  \n",
      "\n",
      "Fold: 5  Epoch: 570  Training loss = 1.7520  Validation loss = 3.6038  \n",
      "\n",
      "Fold: 5  Epoch: 571  Training loss = 1.7519  Validation loss = 3.6037  \n",
      "\n",
      "Fold: 5  Epoch: 572  Training loss = 1.7518  Validation loss = 3.6021  \n",
      "\n",
      "Fold: 5  Epoch: 573  Training loss = 1.7517  Validation loss = 3.6015  \n",
      "\n",
      "Fold: 5  Epoch: 574  Training loss = 1.7516  Validation loss = 3.6019  \n",
      "\n",
      "Fold: 5  Epoch: 575  Training loss = 1.7516  Validation loss = 3.6019  \n",
      "\n",
      "Fold: 5  Epoch: 576  Training loss = 1.7515  Validation loss = 3.6021  \n",
      "\n",
      "Fold: 5  Epoch: 577  Training loss = 1.7514  Validation loss = 3.6019  \n",
      "\n",
      "Fold: 5  Epoch: 578  Training loss = 1.7514  Validation loss = 3.6018  \n",
      "\n",
      "Fold: 5  Epoch: 579  Training loss = 1.7513  Validation loss = 3.6012  \n",
      "\n",
      "Fold: 5  Epoch: 580  Training loss = 1.7512  Validation loss = 3.6009  \n",
      "\n",
      "Fold: 5  Epoch: 581  Training loss = 1.7512  Validation loss = 3.6009  \n",
      "\n",
      "Fold: 5  Epoch: 582  Training loss = 1.7511  Validation loss = 3.6001  \n",
      "\n",
      "Fold: 5  Epoch: 583  Training loss = 1.7510  Validation loss = 3.6001  \n",
      "\n",
      "Fold: 5  Epoch: 584  Training loss = 1.7509  Validation loss = 3.6003  \n",
      "\n",
      "Fold: 5  Epoch: 585  Training loss = 1.7508  Validation loss = 3.5999  \n",
      "\n",
      "Fold: 5  Epoch: 586  Training loss = 1.7508  Validation loss = 3.5998  \n",
      "\n",
      "Fold: 5  Epoch: 587  Training loss = 1.7507  Validation loss = 3.5992  \n",
      "\n",
      "Fold: 5  Epoch: 588  Training loss = 1.7507  Validation loss = 3.5992  \n",
      "\n",
      "Fold: 5  Epoch: 589  Training loss = 1.7506  Validation loss = 3.5987  \n",
      "\n",
      "Fold: 5  Epoch: 590  Training loss = 1.7505  Validation loss = 3.5983  \n",
      "\n",
      "Fold: 5  Epoch: 591  Training loss = 1.7504  Validation loss = 3.5979  \n",
      "\n",
      "Fold: 5  Epoch: 592  Training loss = 1.7503  Validation loss = 3.5973  \n",
      "\n",
      "Fold: 5  Epoch: 593  Training loss = 1.7502  Validation loss = 3.5969  \n",
      "\n",
      "Fold: 5  Epoch: 594  Training loss = 1.7502  Validation loss = 3.5968  \n",
      "\n",
      "Fold: 5  Epoch: 595  Training loss = 1.7500  Validation loss = 3.5964  \n",
      "\n",
      "Fold: 5  Epoch: 596  Training loss = 1.7499  Validation loss = 3.5950  \n",
      "\n",
      "Fold: 5  Epoch: 597  Training loss = 1.7499  Validation loss = 3.5946  \n",
      "\n",
      "Fold: 5  Epoch: 598  Training loss = 1.7498  Validation loss = 3.5951  \n",
      "\n",
      "Fold: 5  Epoch: 599  Training loss = 1.7498  Validation loss = 3.5940  \n",
      "\n",
      "Fold: 5  Epoch: 600  Training loss = 1.7497  Validation loss = 3.5935  \n",
      "\n",
      "Fold: 5  Epoch: 601  Training loss = 1.7496  Validation loss = 3.5934  \n",
      "\n",
      "Fold: 5  Epoch: 602  Training loss = 1.7496  Validation loss = 3.5927  \n",
      "\n",
      "Fold: 5  Epoch: 603  Training loss = 1.7495  Validation loss = 3.5927  \n",
      "\n",
      "Fold: 5  Epoch: 604  Training loss = 1.7494  Validation loss = 3.5924  \n",
      "\n",
      "Fold: 5  Epoch: 605  Training loss = 1.7494  Validation loss = 3.5917  \n",
      "\n",
      "Fold: 5  Epoch: 606  Training loss = 1.7493  Validation loss = 3.5919  \n",
      "\n",
      "Fold: 5  Epoch: 607  Training loss = 1.7493  Validation loss = 3.5918  \n",
      "\n",
      "Fold: 5  Epoch: 608  Training loss = 1.7491  Validation loss = 3.5909  \n",
      "\n",
      "Fold: 5  Epoch: 609  Training loss = 1.7491  Validation loss = 3.5910  \n",
      "\n",
      "Fold: 5  Epoch: 610  Training loss = 1.7491  Validation loss = 3.5915  \n",
      "\n",
      "Fold: 5  Epoch: 611  Training loss = 1.7490  Validation loss = 3.5914  \n",
      "\n",
      "Fold: 5  Epoch: 612  Training loss = 1.7488  Validation loss = 3.5900  \n",
      "\n",
      "Fold: 5  Epoch: 613  Training loss = 1.7488  Validation loss = 3.5902  \n",
      "\n",
      "Fold: 5  Epoch: 614  Training loss = 1.7487  Validation loss = 3.5900  \n",
      "\n",
      "Fold: 5  Epoch: 615  Training loss = 1.7486  Validation loss = 3.5893  \n",
      "\n",
      "Fold: 5  Epoch: 616  Training loss = 1.7485  Validation loss = 3.5890  \n",
      "\n",
      "Fold: 5  Epoch: 617  Training loss = 1.7485  Validation loss = 3.5880  \n",
      "\n",
      "Fold: 5  Epoch: 618  Training loss = 1.7484  Validation loss = 3.5878  \n",
      "\n",
      "Fold: 5  Epoch: 619  Training loss = 1.7482  Validation loss = 3.5867  \n",
      "\n",
      "Fold: 5  Epoch: 620  Training loss = 1.7481  Validation loss = 3.5857  \n",
      "\n",
      "Fold: 5  Epoch: 621  Training loss = 1.7481  Validation loss = 3.5850  \n",
      "\n",
      "Fold: 5  Epoch: 622  Training loss = 1.7480  Validation loss = 3.5853  \n",
      "\n",
      "Fold: 5  Epoch: 623  Training loss = 1.7479  Validation loss = 3.5847  \n",
      "\n",
      "Fold: 5  Epoch: 624  Training loss = 1.7478  Validation loss = 3.5839  \n",
      "\n",
      "Fold: 5  Epoch: 625  Training loss = 1.7478  Validation loss = 3.5840  \n",
      "\n",
      "Fold: 5  Epoch: 626  Training loss = 1.7478  Validation loss = 3.5849  \n",
      "\n",
      "Fold: 5  Epoch: 627  Training loss = 1.7477  Validation loss = 3.5842  \n",
      "\n",
      "Fold: 5  Epoch: 628  Training loss = 1.7475  Validation loss = 3.5835  \n",
      "\n",
      "Fold: 5  Epoch: 629  Training loss = 1.7475  Validation loss = 3.5842  \n",
      "\n",
      "Fold: 5  Epoch: 630  Training loss = 1.7475  Validation loss = 3.5839  \n",
      "\n",
      "Fold: 5  Epoch: 631  Training loss = 1.7474  Validation loss = 3.5829  \n",
      "\n",
      "Fold: 5  Epoch: 632  Training loss = 1.7473  Validation loss = 3.5825  \n",
      "\n",
      "Fold: 5  Epoch: 633  Training loss = 1.7472  Validation loss = 3.5817  \n",
      "\n",
      "Fold: 5  Epoch: 634  Training loss = 1.7472  Validation loss = 3.5815  \n",
      "\n",
      "Fold: 5  Epoch: 635  Training loss = 1.7471  Validation loss = 3.5817  \n",
      "\n",
      "Fold: 5  Epoch: 636  Training loss = 1.7470  Validation loss = 3.5810  \n",
      "\n",
      "Fold: 5  Epoch: 637  Training loss = 1.7469  Validation loss = 3.5810  \n",
      "\n",
      "Fold: 5  Epoch: 638  Training loss = 1.7468  Validation loss = 3.5805  \n",
      "\n",
      "Fold: 5  Epoch: 639  Training loss = 1.7467  Validation loss = 3.5803  \n",
      "\n",
      "Fold: 5  Epoch: 640  Training loss = 1.7466  Validation loss = 3.5794  \n",
      "\n",
      "Fold: 5  Epoch: 641  Training loss = 1.7466  Validation loss = 3.5794  \n",
      "\n",
      "Fold: 5  Epoch: 642  Training loss = 1.7466  Validation loss = 3.5800  \n",
      "\n",
      "Fold: 5  Epoch: 643  Training loss = 1.7464  Validation loss = 3.5790  \n",
      "\n",
      "Fold: 5  Epoch: 644  Training loss = 1.7464  Validation loss = 3.5790  \n",
      "\n",
      "Fold: 5  Epoch: 645  Training loss = 1.7463  Validation loss = 3.5777  \n",
      "\n",
      "Fold: 5  Epoch: 646  Training loss = 1.7462  Validation loss = 3.5773  \n",
      "\n",
      "Fold: 5  Epoch: 647  Training loss = 1.7460  Validation loss = 3.5753  \n",
      "\n",
      "Fold: 5  Epoch: 648  Training loss = 1.7459  Validation loss = 3.5747  \n",
      "\n",
      "Fold: 5  Epoch: 649  Training loss = 1.7458  Validation loss = 3.5742  \n",
      "\n",
      "Fold: 5  Epoch: 650  Training loss = 1.7458  Validation loss = 3.5740  \n",
      "\n",
      "Fold: 5  Epoch: 651  Training loss = 1.7458  Validation loss = 3.5739  \n",
      "\n",
      "Fold: 5  Epoch: 652  Training loss = 1.7457  Validation loss = 3.5738  \n",
      "\n",
      "Fold: 5  Epoch: 653  Training loss = 1.7456  Validation loss = 3.5737  \n",
      "\n",
      "Fold: 5  Epoch: 654  Training loss = 1.7456  Validation loss = 3.5737  \n",
      "\n",
      "Fold: 5  Epoch: 655  Training loss = 1.7455  Validation loss = 3.5740  \n",
      "\n",
      "Fold: 5  Epoch: 656  Training loss = 1.7454  Validation loss = 3.5733  \n",
      "\n",
      "Fold: 5  Epoch: 657  Training loss = 1.7453  Validation loss = 3.5723  \n",
      "\n",
      "Fold: 5  Epoch: 658  Training loss = 1.7452  Validation loss = 3.5719  \n",
      "\n",
      "Fold: 5  Epoch: 659  Training loss = 1.7451  Validation loss = 3.5722  \n",
      "\n",
      "Fold: 5  Epoch: 660  Training loss = 1.7450  Validation loss = 3.5714  \n",
      "\n",
      "Fold: 5  Epoch: 661  Training loss = 1.7450  Validation loss = 3.5706  \n",
      "\n",
      "Fold: 5  Epoch: 662  Training loss = 1.7449  Validation loss = 3.5708  \n",
      "\n",
      "Fold: 5  Epoch: 663  Training loss = 1.7449  Validation loss = 3.5705  \n",
      "\n",
      "Fold: 5  Epoch: 664  Training loss = 1.7449  Validation loss = 3.5709  \n",
      "\n",
      "Fold: 5  Epoch: 665  Training loss = 1.7448  Validation loss = 3.5709  \n",
      "\n",
      "Fold: 5  Epoch: 666  Training loss = 1.7447  Validation loss = 3.5703  \n",
      "\n",
      "Fold: 5  Epoch: 667  Training loss = 1.7447  Validation loss = 3.5698  \n",
      "\n",
      "Fold: 5  Epoch: 668  Training loss = 1.7446  Validation loss = 3.5703  \n",
      "\n",
      "Fold: 5  Epoch: 669  Training loss = 1.7445  Validation loss = 3.5701  \n",
      "\n",
      "Fold: 5  Epoch: 670  Training loss = 1.7445  Validation loss = 3.5693  \n",
      "\n",
      "Fold: 5  Epoch: 671  Training loss = 1.7444  Validation loss = 3.5695  \n",
      "\n",
      "Fold: 5  Epoch: 672  Training loss = 1.7443  Validation loss = 3.5695  \n",
      "\n",
      "Fold: 5  Epoch: 673  Training loss = 1.7443  Validation loss = 3.5692  \n",
      "\n",
      "Fold: 5  Epoch: 674  Training loss = 1.7442  Validation loss = 3.5685  \n",
      "\n",
      "Fold: 5  Epoch: 675  Training loss = 1.7442  Validation loss = 3.5686  \n",
      "\n",
      "Fold: 5  Epoch: 676  Training loss = 1.7441  Validation loss = 3.5687  \n",
      "\n",
      "Fold: 5  Epoch: 677  Training loss = 1.7440  Validation loss = 3.5682  \n",
      "\n",
      "Fold: 5  Epoch: 678  Training loss = 1.7439  Validation loss = 3.5674  \n",
      "\n",
      "Fold: 5  Epoch: 679  Training loss = 1.7439  Validation loss = 3.5677  \n",
      "\n",
      "Fold: 5  Epoch: 680  Training loss = 1.7438  Validation loss = 3.5680  \n",
      "\n",
      "Fold: 5  Epoch: 681  Training loss = 1.7438  Validation loss = 3.5681  \n",
      "\n",
      "Fold: 5  Epoch: 682  Training loss = 1.7437  Validation loss = 3.5687  \n",
      "\n",
      "Fold: 5  Epoch: 683  Training loss = 1.7436  Validation loss = 3.5673  \n",
      "\n",
      "Fold: 5  Epoch: 684  Training loss = 1.7436  Validation loss = 3.5667  \n",
      "\n",
      "Fold: 5  Epoch: 685  Training loss = 1.7435  Validation loss = 3.5661  \n",
      "\n",
      "Fold: 5  Epoch: 686  Training loss = 1.7434  Validation loss = 3.5659  \n",
      "\n",
      "Fold: 5  Epoch: 687  Training loss = 1.7434  Validation loss = 3.5656  \n",
      "\n",
      "Fold: 5  Epoch: 688  Training loss = 1.7433  Validation loss = 3.5653  \n",
      "\n",
      "Fold: 5  Epoch: 689  Training loss = 1.7432  Validation loss = 3.5654  \n",
      "\n",
      "Fold: 5  Epoch: 690  Training loss = 1.7432  Validation loss = 3.5651  \n",
      "\n",
      "Fold: 5  Epoch: 691  Training loss = 1.7431  Validation loss = 3.5645  \n",
      "\n",
      "Fold: 5  Epoch: 692  Training loss = 1.7430  Validation loss = 3.5642  \n",
      "\n",
      "Fold: 5  Epoch: 693  Training loss = 1.7430  Validation loss = 3.5634  \n",
      "\n",
      "Fold: 5  Epoch: 694  Training loss = 1.7428  Validation loss = 3.5622  \n",
      "\n",
      "Fold: 5  Epoch: 695  Training loss = 1.7428  Validation loss = 3.5625  \n",
      "\n",
      "Fold: 5  Epoch: 696  Training loss = 1.7427  Validation loss = 3.5627  \n",
      "\n",
      "Fold: 5  Epoch: 697  Training loss = 1.7427  Validation loss = 3.5627  \n",
      "\n",
      "Fold: 5  Epoch: 698  Training loss = 1.7425  Validation loss = 3.5619  \n",
      "\n",
      "Fold: 5  Epoch: 699  Training loss = 1.7425  Validation loss = 3.5620  \n",
      "\n",
      "Fold: 5  Epoch: 700  Training loss = 1.7423  Validation loss = 3.5603  \n",
      "\n",
      "Fold: 5  Epoch: 701  Training loss = 1.7423  Validation loss = 3.5599  \n",
      "\n",
      "Fold: 5  Epoch: 702  Training loss = 1.7422  Validation loss = 3.5604  \n",
      "\n",
      "Fold: 5  Epoch: 703  Training loss = 1.7421  Validation loss = 3.5586  \n",
      "\n",
      "Fold: 5  Epoch: 704  Training loss = 1.7420  Validation loss = 3.5586  \n",
      "\n",
      "Fold: 5  Epoch: 705  Training loss = 1.7419  Validation loss = 3.5576  \n",
      "\n",
      "Fold: 5  Epoch: 706  Training loss = 1.7419  Validation loss = 3.5575  \n",
      "\n",
      "Fold: 5  Epoch: 707  Training loss = 1.7417  Validation loss = 3.5564  \n",
      "\n",
      "Fold: 5  Epoch: 708  Training loss = 1.7416  Validation loss = 3.5554  \n",
      "\n",
      "Fold: 5  Epoch: 709  Training loss = 1.7416  Validation loss = 3.5555  \n",
      "\n",
      "Fold: 5  Epoch: 710  Training loss = 1.7415  Validation loss = 3.5555  \n",
      "\n",
      "Fold: 5  Epoch: 711  Training loss = 1.7415  Validation loss = 3.5550  \n",
      "\n",
      "Fold: 5  Epoch: 712  Training loss = 1.7414  Validation loss = 3.5548  \n",
      "\n",
      "Fold: 5  Epoch: 713  Training loss = 1.7413  Validation loss = 3.5537  \n",
      "\n",
      "Fold: 5  Epoch: 714  Training loss = 1.7412  Validation loss = 3.5535  \n",
      "\n",
      "Fold: 5  Epoch: 715  Training loss = 1.7411  Validation loss = 3.5525  \n",
      "\n",
      "Fold: 5  Epoch: 716  Training loss = 1.7410  Validation loss = 3.5516  \n",
      "\n",
      "Fold: 5  Epoch: 717  Training loss = 1.7410  Validation loss = 3.5514  \n",
      "\n",
      "Fold: 5  Epoch: 718  Training loss = 1.7409  Validation loss = 3.5508  \n",
      "\n",
      "Fold: 5  Epoch: 719  Training loss = 1.7408  Validation loss = 3.5510  \n",
      "\n",
      "Fold: 5  Epoch: 720  Training loss = 1.7408  Validation loss = 3.5508  \n",
      "\n",
      "Fold: 5  Epoch: 721  Training loss = 1.7407  Validation loss = 3.5501  \n",
      "\n",
      "Fold: 5  Epoch: 722  Training loss = 1.7406  Validation loss = 3.5502  \n",
      "\n",
      "Fold: 5  Epoch: 723  Training loss = 1.7406  Validation loss = 3.5494  \n",
      "\n",
      "Fold: 5  Epoch: 724  Training loss = 1.7405  Validation loss = 3.5501  \n",
      "\n",
      "Fold: 5  Epoch: 725  Training loss = 1.7405  Validation loss = 3.5502  \n",
      "\n",
      "Fold: 5  Epoch: 726  Training loss = 1.7404  Validation loss = 3.5507  \n",
      "\n",
      "Fold: 5  Epoch: 727  Training loss = 1.7404  Validation loss = 3.5507  \n",
      "\n",
      "Fold: 5  Epoch: 728  Training loss = 1.7403  Validation loss = 3.5503  \n",
      "\n",
      "Fold: 5  Epoch: 729  Training loss = 1.7403  Validation loss = 3.5509  \n",
      "\n",
      "Fold: 5  Epoch: 730  Training loss = 1.7402  Validation loss = 3.5508  \n",
      "\n",
      "Fold: 5  Epoch: 731  Training loss = 1.7401  Validation loss = 3.5498  \n",
      "\n",
      "Fold: 5  Epoch: 732  Training loss = 1.7401  Validation loss = 3.5494  \n",
      "\n",
      "Fold: 5  Epoch: 733  Training loss = 1.7400  Validation loss = 3.5494  \n",
      "\n",
      "Fold: 5  Epoch: 734  Training loss = 1.7400  Validation loss = 3.5505  \n",
      "\n",
      "Fold: 5  Epoch: 735  Training loss = 1.7399  Validation loss = 3.5500  \n",
      "\n",
      "Fold: 5  Epoch: 736  Training loss = 1.7398  Validation loss = 3.5494  \n",
      "\n",
      "Fold: 5  Epoch: 737  Training loss = 1.7398  Validation loss = 3.5493  \n",
      "\n",
      "Fold: 5  Epoch: 738  Training loss = 1.7397  Validation loss = 3.5488  \n",
      "\n",
      "Fold: 5  Epoch: 739  Training loss = 1.7396  Validation loss = 3.5486  \n",
      "\n",
      "Fold: 5  Epoch: 740  Training loss = 1.7395  Validation loss = 3.5476  \n",
      "\n",
      "Fold: 5  Epoch: 741  Training loss = 1.7394  Validation loss = 3.5471  \n",
      "\n",
      "Fold: 5  Epoch: 742  Training loss = 1.7394  Validation loss = 3.5471  \n",
      "\n",
      "Fold: 5  Epoch: 743  Training loss = 1.7393  Validation loss = 3.5472  \n",
      "\n",
      "Fold: 5  Epoch: 744  Training loss = 1.7393  Validation loss = 3.5467  \n",
      "\n",
      "Fold: 5  Epoch: 745  Training loss = 1.7392  Validation loss = 3.5467  \n",
      "\n",
      "Fold: 5  Epoch: 746  Training loss = 1.7391  Validation loss = 3.5461  \n",
      "\n",
      "Fold: 5  Epoch: 747  Training loss = 1.7391  Validation loss = 3.5466  \n",
      "\n",
      "Fold: 5  Epoch: 748  Training loss = 1.7390  Validation loss = 3.5463  \n",
      "\n",
      "Fold: 5  Epoch: 749  Training loss = 1.7390  Validation loss = 3.5460  \n",
      "\n",
      "Fold: 5  Epoch: 750  Training loss = 1.7389  Validation loss = 3.5452  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 750  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.9228  Validation loss = 1.4139  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.9223  Validation loss = 1.4133  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.9219  Validation loss = 1.4129  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.9212  Validation loss = 1.4117  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.9209  Validation loss = 1.4114  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.9207  Validation loss = 1.4111  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.9201  Validation loss = 1.4101  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.9198  Validation loss = 1.4096  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.9196  Validation loss = 1.4092  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.9192  Validation loss = 1.4089  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.9190  Validation loss = 1.4084  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.9184  Validation loss = 1.4073  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.9181  Validation loss = 1.4069  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.9175  Validation loss = 1.4058  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 1.9171  Validation loss = 1.4050  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 1.9166  Validation loss = 1.4040  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 1.9163  Validation loss = 1.4034  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 1.9160  Validation loss = 1.4029  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 1.9157  Validation loss = 1.4023  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 1.9154  Validation loss = 1.4017  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 1.9148  Validation loss = 1.4008  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 1.9144  Validation loss = 1.4001  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 1.9139  Validation loss = 1.3993  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 1.9135  Validation loss = 1.3985  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 1.9131  Validation loss = 1.3977  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 1.9130  Validation loss = 1.3975  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 1.9126  Validation loss = 1.3966  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 1.9123  Validation loss = 1.3962  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 1.9119  Validation loss = 1.3956  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 1.9115  Validation loss = 1.3947  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 1.9112  Validation loss = 1.3944  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 1.9110  Validation loss = 1.3940  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 1.9105  Validation loss = 1.3929  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 1.9102  Validation loss = 1.3925  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 1.9099  Validation loss = 1.3918  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 1.9096  Validation loss = 1.3910  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 1.9091  Validation loss = 1.3900  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 1.9089  Validation loss = 1.3897  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 1.9087  Validation loss = 1.3892  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 1.9084  Validation loss = 1.3888  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 1.9082  Validation loss = 1.3884  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 1.9079  Validation loss = 1.3879  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 1.9075  Validation loss = 1.3870  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 1.9072  Validation loss = 1.3863  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 1.9070  Validation loss = 1.3860  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 1.9067  Validation loss = 1.3855  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 1.9064  Validation loss = 1.3849  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 1.9063  Validation loss = 1.3845  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 1.9059  Validation loss = 1.3839  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 1.9056  Validation loss = 1.3835  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 1.9052  Validation loss = 1.3829  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 1.9050  Validation loss = 1.3826  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 1.9046  Validation loss = 1.3821  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 1.9041  Validation loss = 1.3812  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 1.9039  Validation loss = 1.3808  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 1.9036  Validation loss = 1.3804  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 1.9034  Validation loss = 1.3799  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 1.9031  Validation loss = 1.3794  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 1.9029  Validation loss = 1.3789  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 1.9026  Validation loss = 1.3781  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 1.9023  Validation loss = 1.3774  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 1.9019  Validation loss = 1.3767  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 1.9016  Validation loss = 1.3761  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 1.9013  Validation loss = 1.3754  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 1.9010  Validation loss = 1.3745  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 1.9005  Validation loss = 1.3732  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 1.9002  Validation loss = 1.3727  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 1.8999  Validation loss = 1.3721  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 1.8996  Validation loss = 1.3712  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 1.8993  Validation loss = 1.3710  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 1.8989  Validation loss = 1.3701  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 1.8988  Validation loss = 1.3701  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 1.8985  Validation loss = 1.3697  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 1.8983  Validation loss = 1.3693  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 1.8982  Validation loss = 1.3691  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 1.8981  Validation loss = 1.3691  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 1.8979  Validation loss = 1.3685  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 1.8976  Validation loss = 1.3680  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 1.8974  Validation loss = 1.3674  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 1.8971  Validation loss = 1.3671  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 1.8968  Validation loss = 1.3663  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 1.8964  Validation loss = 1.3658  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 1.8962  Validation loss = 1.3651  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 1.8959  Validation loss = 1.3644  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 1.8955  Validation loss = 1.3634  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 1.8953  Validation loss = 1.3631  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 1.8950  Validation loss = 1.3623  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 1.8947  Validation loss = 1.3618  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 1.8944  Validation loss = 1.3612  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 1.8940  Validation loss = 1.3603  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 1.8934  Validation loss = 1.3589  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 1.8930  Validation loss = 1.3580  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 1.8929  Validation loss = 1.3578  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 1.8927  Validation loss = 1.3574  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 1.8923  Validation loss = 1.3568  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 1.8922  Validation loss = 1.3564  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 1.8920  Validation loss = 1.3563  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 1.8918  Validation loss = 1.3559  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 1.8915  Validation loss = 1.3551  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 1.8914  Validation loss = 1.3549  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 1.8911  Validation loss = 1.3542  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 1.8909  Validation loss = 1.3538  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 1.8907  Validation loss = 1.3535  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 1.8906  Validation loss = 1.3534  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 1.8902  Validation loss = 1.3528  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 1.8900  Validation loss = 1.3523  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 1.8898  Validation loss = 1.3518  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 1.8896  Validation loss = 1.3512  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 1.8894  Validation loss = 1.3511  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 1.8893  Validation loss = 1.3509  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 1.8890  Validation loss = 1.3503  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 1.8889  Validation loss = 1.3499  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 1.8886  Validation loss = 1.3493  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 1.8884  Validation loss = 1.3491  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 1.8882  Validation loss = 1.3488  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 1.8879  Validation loss = 1.3481  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 1.8877  Validation loss = 1.3476  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 1.8874  Validation loss = 1.3469  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 1.8872  Validation loss = 1.3467  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 1.8870  Validation loss = 1.3465  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 1.8867  Validation loss = 1.3457  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 1.8865  Validation loss = 1.3449  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 1.8863  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 1.8860  Validation loss = 1.3440  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 1.8857  Validation loss = 1.3434  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 1.8854  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 1.8852  Validation loss = 1.3425  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 1.8849  Validation loss = 1.3418  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 1.8846  Validation loss = 1.3411  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 1.8843  Validation loss = 1.3405  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 1.8840  Validation loss = 1.3399  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 1.8840  Validation loss = 1.3398  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 1.8837  Validation loss = 1.3392  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 1.8835  Validation loss = 1.3387  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 1.8833  Validation loss = 1.3385  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 1.8830  Validation loss = 1.3374  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 1.8828  Validation loss = 1.3372  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 1.8825  Validation loss = 1.3365  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 1.8824  Validation loss = 1.3363  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 1.8821  Validation loss = 1.3356  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 1.8819  Validation loss = 1.3351  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 1.8817  Validation loss = 1.3345  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 1.8814  Validation loss = 1.3339  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 1.8811  Validation loss = 1.3333  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 1.8809  Validation loss = 1.3327  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 1.8807  Validation loss = 1.3323  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 1.8803  Validation loss = 1.3315  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 1.8801  Validation loss = 1.3313  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 1.8800  Validation loss = 1.3311  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 1.8797  Validation loss = 1.3306  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 1.8793  Validation loss = 1.3294  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 1.8790  Validation loss = 1.3286  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 1.8788  Validation loss = 1.3283  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 1.8786  Validation loss = 1.3279  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 1.8784  Validation loss = 1.3276  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 1.8784  Validation loss = 1.3276  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 1.8782  Validation loss = 1.3272  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 1.8780  Validation loss = 1.3266  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 1.8778  Validation loss = 1.3262  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 1.8776  Validation loss = 1.3257  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 1.8774  Validation loss = 1.3254  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 1.8772  Validation loss = 1.3250  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 1.8770  Validation loss = 1.3246  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 1.8769  Validation loss = 1.3243  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 1.8766  Validation loss = 1.3237  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 1.8764  Validation loss = 1.3233  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 1.8762  Validation loss = 1.3230  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 1.8761  Validation loss = 1.3226  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 1.8760  Validation loss = 1.3225  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 1.8757  Validation loss = 1.3219  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 1.8756  Validation loss = 1.3215  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 1.8753  Validation loss = 1.3210  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 1.8751  Validation loss = 1.3208  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 1.8749  Validation loss = 1.3205  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 1.8746  Validation loss = 1.3196  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 1.8745  Validation loss = 1.3193  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 1.8743  Validation loss = 1.3190  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 1.8742  Validation loss = 1.3186  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 1.8739  Validation loss = 1.3181  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 1.8737  Validation loss = 1.3174  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 1.8735  Validation loss = 1.3171  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 1.8732  Validation loss = 1.3164  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 1.8730  Validation loss = 1.3160  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 1.8728  Validation loss = 1.3153  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 1.8726  Validation loss = 1.3147  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 1.8723  Validation loss = 1.3138  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 1.8721  Validation loss = 1.3133  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 1.8719  Validation loss = 1.3132  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 1.8718  Validation loss = 1.3130  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 1.8717  Validation loss = 1.3128  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 1.8716  Validation loss = 1.3124  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 1.8714  Validation loss = 1.3120  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 1.8712  Validation loss = 1.3116  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 1.8710  Validation loss = 1.3110  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 1.8708  Validation loss = 1.3106  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 1.8707  Validation loss = 1.3105  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 1.8705  Validation loss = 1.3100  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 1.8702  Validation loss = 1.3094  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 1.8700  Validation loss = 1.3088  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 1.8699  Validation loss = 1.3086  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 1.8698  Validation loss = 1.3089  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 1.8696  Validation loss = 1.3081  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 1.8694  Validation loss = 1.3074  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 1.8691  Validation loss = 1.3067  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 1.8690  Validation loss = 1.3065  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 1.8688  Validation loss = 1.3059  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 1.8688  Validation loss = 1.3059  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 1.8686  Validation loss = 1.3056  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 1.8684  Validation loss = 1.3053  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 1.8682  Validation loss = 1.3046  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 1.8680  Validation loss = 1.3044  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 1.8678  Validation loss = 1.3040  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 1.8675  Validation loss = 1.3029  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 1.8673  Validation loss = 1.3025  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 1.8672  Validation loss = 1.3022  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 1.8669  Validation loss = 1.3016  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 1.8667  Validation loss = 1.3010  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 1.8666  Validation loss = 1.3009  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 1.8663  Validation loss = 1.3001  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 1.8661  Validation loss = 1.2995  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 1.8659  Validation loss = 1.2990  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 1.8658  Validation loss = 1.2989  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 1.8656  Validation loss = 1.2984  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 1.8655  Validation loss = 1.2981  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 1.8652  Validation loss = 1.2973  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 1.8650  Validation loss = 1.2967  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 1.8649  Validation loss = 1.2965  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 1.8647  Validation loss = 1.2959  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 1.8645  Validation loss = 1.2953  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 1.8644  Validation loss = 1.2952  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 1.8643  Validation loss = 1.2951  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 1.8641  Validation loss = 1.2946  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 1.8638  Validation loss = 1.2942  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 1.8637  Validation loss = 1.2938  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 1.8635  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 1.8633  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 1.8631  Validation loss = 1.2924  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 1.8630  Validation loss = 1.2920  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 1.8629  Validation loss = 1.2920  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 1.8627  Validation loss = 1.2916  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 1.8625  Validation loss = 1.2912  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 1.8624  Validation loss = 1.2911  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 1.8622  Validation loss = 1.2904  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 1.8621  Validation loss = 1.2903  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 1.8619  Validation loss = 1.2899  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 1.8617  Validation loss = 1.2897  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 1.8616  Validation loss = 1.2896  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 1.8614  Validation loss = 1.2891  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 1.8613  Validation loss = 1.2889  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 1.8612  Validation loss = 1.2888  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 1.8610  Validation loss = 1.2884  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 1.8609  Validation loss = 1.2882  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 1.8607  Validation loss = 1.2880  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 1.8605  Validation loss = 1.2874  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 1.8605  Validation loss = 1.2875  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 1.8603  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 1.8602  Validation loss = 1.2869  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 1.8601  Validation loss = 1.2865  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 1.8600  Validation loss = 1.2865  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 1.8598  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 1.8596  Validation loss = 1.2856  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 1.8595  Validation loss = 1.2853  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 1.8593  Validation loss = 1.2848  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 1.8591  Validation loss = 1.2843  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 1.8590  Validation loss = 1.2842  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 1.8588  Validation loss = 1.2838  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 1.8586  Validation loss = 1.2831  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 1.8585  Validation loss = 1.2831  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 1.8582  Validation loss = 1.2823  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 1.8581  Validation loss = 1.2819  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 1.8578  Validation loss = 1.2810  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 1.8576  Validation loss = 1.2806  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 1.8575  Validation loss = 1.2803  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 1.8571  Validation loss = 1.2792  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 1.8569  Validation loss = 1.2786  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 1.8567  Validation loss = 1.2779  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 1.8564  Validation loss = 1.2773  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 1.8562  Validation loss = 1.2767  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 1.8561  Validation loss = 1.2762  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 1.8559  Validation loss = 1.2759  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 1.8557  Validation loss = 1.2753  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 1.8555  Validation loss = 1.2748  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 1.8554  Validation loss = 1.2747  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 1.8553  Validation loss = 1.2743  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 1.8551  Validation loss = 1.2738  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 1.8549  Validation loss = 1.2735  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 1.8547  Validation loss = 1.2727  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 1.8545  Validation loss = 1.2722  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 1.8544  Validation loss = 1.2720  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 1.8543  Validation loss = 1.2719  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 1.8540  Validation loss = 1.2712  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 1.8539  Validation loss = 1.2711  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 1.8538  Validation loss = 1.2708  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 1.8536  Validation loss = 1.2703  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 1.8535  Validation loss = 1.2701  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 1.8534  Validation loss = 1.2698  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 1.8532  Validation loss = 1.2692  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 1.8530  Validation loss = 1.2690  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 1.8527  Validation loss = 1.2681  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 1.8525  Validation loss = 1.2675  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 1.8524  Validation loss = 1.2674  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 1.8523  Validation loss = 1.2670  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 1.8521  Validation loss = 1.2669  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 1.8519  Validation loss = 1.2662  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 1.8517  Validation loss = 1.2654  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 1.8516  Validation loss = 1.2654  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 1.8515  Validation loss = 1.2650  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 1.8514  Validation loss = 1.2646  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 1.8512  Validation loss = 1.2644  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 1.8511  Validation loss = 1.2640  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 1.8508  Validation loss = 1.2632  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 1.8508  Validation loss = 1.2633  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 1.8507  Validation loss = 1.2632  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 1.8505  Validation loss = 1.2627  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 1.8502  Validation loss = 1.2619  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 1.8500  Validation loss = 1.2612  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 1.8498  Validation loss = 1.2606  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 1.8496  Validation loss = 1.2599  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 1.8494  Validation loss = 1.2596  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 1.8492  Validation loss = 1.2590  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 1.8490  Validation loss = 1.2583  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 1.8488  Validation loss = 1.2583  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 1.8487  Validation loss = 1.2579  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 1.8485  Validation loss = 1.2572  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 1.8483  Validation loss = 1.2569  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 1.8481  Validation loss = 1.2562  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 1.8479  Validation loss = 1.2556  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 1.8476  Validation loss = 1.2550  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 1.8474  Validation loss = 1.2543  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 1.8472  Validation loss = 1.2537  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 1.8470  Validation loss = 1.2532  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 1.8468  Validation loss = 1.2526  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 1.8468  Validation loss = 1.2525  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 1.8464  Validation loss = 1.2516  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 1.8463  Validation loss = 1.2513  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 1.8461  Validation loss = 1.2509  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 1.8459  Validation loss = 1.2503  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 1.8458  Validation loss = 1.2497  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 1.8455  Validation loss = 1.2491  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 1.8453  Validation loss = 1.2485  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 1.8451  Validation loss = 1.2479  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 1.8450  Validation loss = 1.2478  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 1.8449  Validation loss = 1.2475  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 1.8446  Validation loss = 1.2467  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 1.8444  Validation loss = 1.2465  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 1.8444  Validation loss = 1.2464  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 1.8442  Validation loss = 1.2461  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 1.8442  Validation loss = 1.2459  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 1.8440  Validation loss = 1.2455  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 1.8439  Validation loss = 1.2451  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 1.8438  Validation loss = 1.2450  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 1.8437  Validation loss = 1.2449  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 1.8435  Validation loss = 1.2442  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 1.8432  Validation loss = 1.2433  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 1.8431  Validation loss = 1.2430  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 1.8429  Validation loss = 1.2426  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 1.8427  Validation loss = 1.2420  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 1.8425  Validation loss = 1.2415  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 1.8424  Validation loss = 1.2412  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 1.8422  Validation loss = 1.2405  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 1.8421  Validation loss = 1.2404  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 1.8419  Validation loss = 1.2401  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 1.8417  Validation loss = 1.2394  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 1.8416  Validation loss = 1.2391  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 1.8414  Validation loss = 1.2384  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 1.8412  Validation loss = 1.2382  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 1.8411  Validation loss = 1.2377  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 1.8410  Validation loss = 1.2375  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 1.8408  Validation loss = 1.2371  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 1.8406  Validation loss = 1.2366  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 1.8404  Validation loss = 1.2359  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 1.8402  Validation loss = 1.2355  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 1.8402  Validation loss = 1.2356  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 1.8401  Validation loss = 1.2354  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 1.8400  Validation loss = 1.2350  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 1.8398  Validation loss = 1.2348  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 1.8397  Validation loss = 1.2345  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 1.8396  Validation loss = 1.2341  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 1.8394  Validation loss = 1.2338  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 1.8393  Validation loss = 1.2335  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 1.8391  Validation loss = 1.2330  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 1.8390  Validation loss = 1.2326  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 1.8388  Validation loss = 1.2320  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 1.8386  Validation loss = 1.2316  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 1.8385  Validation loss = 1.2313  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 1.8383  Validation loss = 1.2310  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 1.8382  Validation loss = 1.2308  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 1.8380  Validation loss = 1.2304  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 1.8379  Validation loss = 1.2303  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 1.8377  Validation loss = 1.2298  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 1.8377  Validation loss = 1.2297  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 1.8376  Validation loss = 1.2295  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 1.8373  Validation loss = 1.2286  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 1.8371  Validation loss = 1.2280  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 1.8370  Validation loss = 1.2277  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 1.8368  Validation loss = 1.2274  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 1.8366  Validation loss = 1.2267  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 1.8364  Validation loss = 1.2263  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 1.8363  Validation loss = 1.2259  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 1.8362  Validation loss = 1.2260  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 1.8360  Validation loss = 1.2250  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 1.8359  Validation loss = 1.2250  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 1.8358  Validation loss = 1.2247  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 1.8357  Validation loss = 1.2244  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 1.8354  Validation loss = 1.2236  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 1.8352  Validation loss = 1.2230  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 1.8350  Validation loss = 1.2224  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 1.8349  Validation loss = 1.2220  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 1.8348  Validation loss = 1.2220  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 1.8347  Validation loss = 1.2218  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 1.8345  Validation loss = 1.2213  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 1.8343  Validation loss = 1.2207  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 1.8341  Validation loss = 1.2201  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 1.8340  Validation loss = 1.2199  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 1.8339  Validation loss = 1.2198  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 1.8338  Validation loss = 1.2196  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 1.8336  Validation loss = 1.2190  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 1.8335  Validation loss = 1.2192  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 1.8334  Validation loss = 1.2187  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 1.8332  Validation loss = 1.2183  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 1.8330  Validation loss = 1.2176  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 1.8330  Validation loss = 1.2177  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 1.8328  Validation loss = 1.2171  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 1.8327  Validation loss = 1.2169  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 1.8326  Validation loss = 1.2168  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 1.8324  Validation loss = 1.2165  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 1.8323  Validation loss = 1.2160  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 1.8321  Validation loss = 1.2155  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 1.8318  Validation loss = 1.2145  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 1.8317  Validation loss = 1.2146  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 1.8316  Validation loss = 1.2145  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 1.8316  Validation loss = 1.2147  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 1.8315  Validation loss = 1.2144  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 1.8313  Validation loss = 1.2139  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 1.8312  Validation loss = 1.2135  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 1.8311  Validation loss = 1.2137  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 1.8309  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 1.8308  Validation loss = 1.2128  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 1.8307  Validation loss = 1.2126  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 1.8305  Validation loss = 1.2122  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 1.8303  Validation loss = 1.2115  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 1.8302  Validation loss = 1.2112  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 1.8300  Validation loss = 1.2111  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 1.8299  Validation loss = 1.2105  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 1.8297  Validation loss = 1.2103  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 1.8295  Validation loss = 1.2097  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 1.8294  Validation loss = 1.2096  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 1.8292  Validation loss = 1.2091  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 1.8290  Validation loss = 1.2085  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 1.8288  Validation loss = 1.2077  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 1.8287  Validation loss = 1.2074  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 1.8285  Validation loss = 1.2067  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 1.8283  Validation loss = 1.2062  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 1.8281  Validation loss = 1.2055  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 1.8280  Validation loss = 1.2053  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 1.8278  Validation loss = 1.2046  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 1.8276  Validation loss = 1.2038  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 1.8275  Validation loss = 1.2034  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 1.8273  Validation loss = 1.2032  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 1.8272  Validation loss = 1.2027  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 1.8270  Validation loss = 1.2022  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 1.8268  Validation loss = 1.2017  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 1.8267  Validation loss = 1.2013  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 1.8265  Validation loss = 1.2006  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 1.8263  Validation loss = 1.2002  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 1.8262  Validation loss = 1.2000  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 1.8261  Validation loss = 1.1997  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 1.8258  Validation loss = 1.1992  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 1.8258  Validation loss = 1.1990  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 1.8256  Validation loss = 1.1985  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 1.8255  Validation loss = 1.1983  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 1.8253  Validation loss = 1.1978  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 1.8252  Validation loss = 1.1976  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 1.8250  Validation loss = 1.1973  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 1.8249  Validation loss = 1.1968  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 1.8248  Validation loss = 1.1968  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 1.8247  Validation loss = 1.1965  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 1.8245  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 1.8244  Validation loss = 1.1959  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 1.8243  Validation loss = 1.1957  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 1.8241  Validation loss = 1.1954  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 1.8239  Validation loss = 1.1947  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 1.8237  Validation loss = 1.1943  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 1.8237  Validation loss = 1.1943  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 1.8235  Validation loss = 1.1936  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 1.8233  Validation loss = 1.1930  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 1.8231  Validation loss = 1.1928  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 1.8231  Validation loss = 1.1928  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 1.8229  Validation loss = 1.1922  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 1.8228  Validation loss = 1.1921  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 1.8227  Validation loss = 1.1919  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 1.8225  Validation loss = 1.1914  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 1.8223  Validation loss = 1.1908  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 1.8220  Validation loss = 1.1899  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 1.8218  Validation loss = 1.1893  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 1.8217  Validation loss = 1.1891  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 1.8215  Validation loss = 1.1885  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 1.8213  Validation loss = 1.1880  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 1.8213  Validation loss = 1.1882  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 1.8212  Validation loss = 1.1883  \n",
      "\n",
      "Fold: 6  Epoch: 501  Training loss = 1.8211  Validation loss = 1.1879  \n",
      "\n",
      "Fold: 6  Epoch: 502  Training loss = 1.8209  Validation loss = 1.1874  \n",
      "\n",
      "Fold: 6  Epoch: 503  Training loss = 1.8208  Validation loss = 1.1869  \n",
      "\n",
      "Fold: 6  Epoch: 504  Training loss = 1.8207  Validation loss = 1.1868  \n",
      "\n",
      "Fold: 6  Epoch: 505  Training loss = 1.8205  Validation loss = 1.1863  \n",
      "\n",
      "Fold: 6  Epoch: 506  Training loss = 1.8204  Validation loss = 1.1859  \n",
      "\n",
      "Fold: 6  Epoch: 507  Training loss = 1.8203  Validation loss = 1.1860  \n",
      "\n",
      "Fold: 6  Epoch: 508  Training loss = 1.8201  Validation loss = 1.1854  \n",
      "\n",
      "Fold: 6  Epoch: 509  Training loss = 1.8200  Validation loss = 1.1853  \n",
      "\n",
      "Fold: 6  Epoch: 510  Training loss = 1.8199  Validation loss = 1.1849  \n",
      "\n",
      "Fold: 6  Epoch: 511  Training loss = 1.8197  Validation loss = 1.1844  \n",
      "\n",
      "Fold: 6  Epoch: 512  Training loss = 1.8196  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 6  Epoch: 513  Training loss = 1.8194  Validation loss = 1.1836  \n",
      "\n",
      "Fold: 6  Epoch: 514  Training loss = 1.8192  Validation loss = 1.1831  \n",
      "\n",
      "Fold: 6  Epoch: 515  Training loss = 1.8190  Validation loss = 1.1827  \n",
      "\n",
      "Fold: 6  Epoch: 516  Training loss = 1.8189  Validation loss = 1.1822  \n",
      "\n",
      "Fold: 6  Epoch: 517  Training loss = 1.8187  Validation loss = 1.1819  \n",
      "\n",
      "Fold: 6  Epoch: 518  Training loss = 1.8187  Validation loss = 1.1818  \n",
      "\n",
      "Fold: 6  Epoch: 519  Training loss = 1.8185  Validation loss = 1.1816  \n",
      "\n",
      "Fold: 6  Epoch: 520  Training loss = 1.8184  Validation loss = 1.1815  \n",
      "\n",
      "Fold: 6  Epoch: 521  Training loss = 1.8182  Validation loss = 1.1811  \n",
      "\n",
      "Fold: 6  Epoch: 522  Training loss = 1.8182  Validation loss = 1.1811  \n",
      "\n",
      "Fold: 6  Epoch: 523  Training loss = 1.8180  Validation loss = 1.1808  \n",
      "\n",
      "Fold: 6  Epoch: 524  Training loss = 1.8179  Validation loss = 1.1806  \n",
      "\n",
      "Fold: 6  Epoch: 525  Training loss = 1.8178  Validation loss = 1.1806  \n",
      "\n",
      "Fold: 6  Epoch: 526  Training loss = 1.8177  Validation loss = 1.1804  \n",
      "\n",
      "Fold: 6  Epoch: 527  Training loss = 1.8176  Validation loss = 1.1802  \n",
      "\n",
      "Fold: 6  Epoch: 528  Training loss = 1.8174  Validation loss = 1.1796  \n",
      "\n",
      "Fold: 6  Epoch: 529  Training loss = 1.8173  Validation loss = 1.1793  \n",
      "\n",
      "Fold: 6  Epoch: 530  Training loss = 1.8172  Validation loss = 1.1793  \n",
      "\n",
      "Fold: 6  Epoch: 531  Training loss = 1.8171  Validation loss = 1.1792  \n",
      "\n",
      "Fold: 6  Epoch: 532  Training loss = 1.8169  Validation loss = 1.1791  \n",
      "\n",
      "Fold: 6  Epoch: 533  Training loss = 1.8168  Validation loss = 1.1786  \n",
      "\n",
      "Fold: 6  Epoch: 534  Training loss = 1.8166  Validation loss = 1.1783  \n",
      "\n",
      "Fold: 6  Epoch: 535  Training loss = 1.8165  Validation loss = 1.1780  \n",
      "\n",
      "Fold: 6  Epoch: 536  Training loss = 1.8163  Validation loss = 1.1771  \n",
      "\n",
      "Fold: 6  Epoch: 537  Training loss = 1.8161  Validation loss = 1.1768  \n",
      "\n",
      "Fold: 6  Epoch: 538  Training loss = 1.8160  Validation loss = 1.1763  \n",
      "\n",
      "Fold: 6  Epoch: 539  Training loss = 1.8158  Validation loss = 1.1759  \n",
      "\n",
      "Fold: 6  Epoch: 540  Training loss = 1.8158  Validation loss = 1.1760  \n",
      "\n",
      "Fold: 6  Epoch: 541  Training loss = 1.8157  Validation loss = 1.1761  \n",
      "\n",
      "Fold: 6  Epoch: 542  Training loss = 1.8156  Validation loss = 1.1759  \n",
      "\n",
      "Fold: 6  Epoch: 543  Training loss = 1.8155  Validation loss = 1.1758  \n",
      "\n",
      "Fold: 6  Epoch: 544  Training loss = 1.8154  Validation loss = 1.1756  \n",
      "\n",
      "Fold: 6  Epoch: 545  Training loss = 1.8152  Validation loss = 1.1752  \n",
      "\n",
      "Fold: 6  Epoch: 546  Training loss = 1.8151  Validation loss = 1.1748  \n",
      "\n",
      "Fold: 6  Epoch: 547  Training loss = 1.8149  Validation loss = 1.1743  \n",
      "\n",
      "Fold: 6  Epoch: 548  Training loss = 1.8148  Validation loss = 1.1743  \n",
      "\n",
      "Fold: 6  Epoch: 549  Training loss = 1.8147  Validation loss = 1.1740  \n",
      "\n",
      "Fold: 6  Epoch: 550  Training loss = 1.8146  Validation loss = 1.1741  \n",
      "\n",
      "Fold: 6  Epoch: 551  Training loss = 1.8144  Validation loss = 1.1735  \n",
      "\n",
      "Fold: 6  Epoch: 552  Training loss = 1.8143  Validation loss = 1.1728  \n",
      "\n",
      "Fold: 6  Epoch: 553  Training loss = 1.8141  Validation loss = 1.1726  \n",
      "\n",
      "Fold: 6  Epoch: 554  Training loss = 1.8140  Validation loss = 1.1721  \n",
      "\n",
      "Fold: 6  Epoch: 555  Training loss = 1.8138  Validation loss = 1.1719  \n",
      "\n",
      "Fold: 6  Epoch: 556  Training loss = 1.8137  Validation loss = 1.1717  \n",
      "\n",
      "Fold: 6  Epoch: 557  Training loss = 1.8136  Validation loss = 1.1714  \n",
      "\n",
      "Fold: 6  Epoch: 558  Training loss = 1.8135  Validation loss = 1.1711  \n",
      "\n",
      "Fold: 6  Epoch: 559  Training loss = 1.8134  Validation loss = 1.1713  \n",
      "\n",
      "Fold: 6  Epoch: 560  Training loss = 1.8132  Validation loss = 1.1707  \n",
      "\n",
      "Fold: 6  Epoch: 561  Training loss = 1.8131  Validation loss = 1.1707  \n",
      "\n",
      "Fold: 6  Epoch: 562  Training loss = 1.8129  Validation loss = 1.1701  \n",
      "\n",
      "Fold: 6  Epoch: 563  Training loss = 1.8128  Validation loss = 1.1699  \n",
      "\n",
      "Fold: 6  Epoch: 564  Training loss = 1.8127  Validation loss = 1.1695  \n",
      "\n",
      "Fold: 6  Epoch: 565  Training loss = 1.8125  Validation loss = 1.1688  \n",
      "\n",
      "Fold: 6  Epoch: 566  Training loss = 1.8124  Validation loss = 1.1689  \n",
      "\n",
      "Fold: 6  Epoch: 567  Training loss = 1.8123  Validation loss = 1.1689  \n",
      "\n",
      "Fold: 6  Epoch: 568  Training loss = 1.8122  Validation loss = 1.1689  \n",
      "\n",
      "Fold: 6  Epoch: 569  Training loss = 1.8121  Validation loss = 1.1685  \n",
      "\n",
      "Fold: 6  Epoch: 570  Training loss = 1.8119  Validation loss = 1.1679  \n",
      "\n",
      "Fold: 6  Epoch: 571  Training loss = 1.8118  Validation loss = 1.1676  \n",
      "\n",
      "Fold: 6  Epoch: 572  Training loss = 1.8116  Validation loss = 1.1670  \n",
      "\n",
      "Fold: 6  Epoch: 573  Training loss = 1.8114  Validation loss = 1.1664  \n",
      "\n",
      "Fold: 6  Epoch: 574  Training loss = 1.8112  Validation loss = 1.1657  \n",
      "\n",
      "Fold: 6  Epoch: 575  Training loss = 1.8110  Validation loss = 1.1653  \n",
      "\n",
      "Fold: 6  Epoch: 576  Training loss = 1.8109  Validation loss = 1.1651  \n",
      "\n",
      "Fold: 6  Epoch: 577  Training loss = 1.8108  Validation loss = 1.1646  \n",
      "\n",
      "Fold: 6  Epoch: 578  Training loss = 1.8107  Validation loss = 1.1647  \n",
      "\n",
      "Fold: 6  Epoch: 579  Training loss = 1.8105  Validation loss = 1.1643  \n",
      "\n",
      "Fold: 6  Epoch: 580  Training loss = 1.8103  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 6  Epoch: 581  Training loss = 1.8103  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 6  Epoch: 582  Training loss = 1.8101  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 6  Epoch: 583  Training loss = 1.8100  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 6  Epoch: 584  Training loss = 1.8098  Validation loss = 1.1623  \n",
      "\n",
      "Fold: 6  Epoch: 585  Training loss = 1.8097  Validation loss = 1.1624  \n",
      "\n",
      "Fold: 6  Epoch: 586  Training loss = 1.8096  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 6  Epoch: 587  Training loss = 1.8094  Validation loss = 1.1612  \n",
      "\n",
      "Fold: 6  Epoch: 588  Training loss = 1.8092  Validation loss = 1.1608  \n",
      "\n",
      "Fold: 6  Epoch: 589  Training loss = 1.8091  Validation loss = 1.1604  \n",
      "\n",
      "Fold: 6  Epoch: 590  Training loss = 1.8090  Validation loss = 1.1602  \n",
      "\n",
      "Fold: 6  Epoch: 591  Training loss = 1.8088  Validation loss = 1.1598  \n",
      "\n",
      "Fold: 6  Epoch: 592  Training loss = 1.8087  Validation loss = 1.1595  \n",
      "\n",
      "Fold: 6  Epoch: 593  Training loss = 1.8085  Validation loss = 1.1591  \n",
      "\n",
      "Fold: 6  Epoch: 594  Training loss = 1.8084  Validation loss = 1.1588  \n",
      "\n",
      "Fold: 6  Epoch: 595  Training loss = 1.8082  Validation loss = 1.1582  \n",
      "\n",
      "Fold: 6  Epoch: 596  Training loss = 1.8080  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 6  Epoch: 597  Training loss = 1.8079  Validation loss = 1.1575  \n",
      "\n",
      "Fold: 6  Epoch: 598  Training loss = 1.8078  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 6  Epoch: 599  Training loss = 1.8076  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 6  Epoch: 600  Training loss = 1.8074  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 6  Epoch: 601  Training loss = 1.8073  Validation loss = 1.1561  \n",
      "\n",
      "Fold: 6  Epoch: 602  Training loss = 1.8072  Validation loss = 1.1558  \n",
      "\n",
      "Fold: 6  Epoch: 603  Training loss = 1.8070  Validation loss = 1.1552  \n",
      "\n",
      "Fold: 6  Epoch: 604  Training loss = 1.8068  Validation loss = 1.1547  \n",
      "\n",
      "Fold: 6  Epoch: 605  Training loss = 1.8066  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 6  Epoch: 606  Training loss = 1.8064  Validation loss = 1.1535  \n",
      "\n",
      "Fold: 6  Epoch: 607  Training loss = 1.8063  Validation loss = 1.1532  \n",
      "\n",
      "Fold: 6  Epoch: 608  Training loss = 1.8062  Validation loss = 1.1531  \n",
      "\n",
      "Fold: 6  Epoch: 609  Training loss = 1.8060  Validation loss = 1.1526  \n",
      "\n",
      "Fold: 6  Epoch: 610  Training loss = 1.8059  Validation loss = 1.1527  \n",
      "\n",
      "Fold: 6  Epoch: 611  Training loss = 1.8058  Validation loss = 1.1523  \n",
      "\n",
      "Fold: 6  Epoch: 612  Training loss = 1.8057  Validation loss = 1.1522  \n",
      "\n",
      "Fold: 6  Epoch: 613  Training loss = 1.8055  Validation loss = 1.1518  \n",
      "\n",
      "Fold: 6  Epoch: 614  Training loss = 1.8054  Validation loss = 1.1515  \n",
      "\n",
      "Fold: 6  Epoch: 615  Training loss = 1.8052  Validation loss = 1.1511  \n",
      "\n",
      "Fold: 6  Epoch: 616  Training loss = 1.8052  Validation loss = 1.1511  \n",
      "\n",
      "Fold: 6  Epoch: 617  Training loss = 1.8050  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 6  Epoch: 618  Training loss = 1.8049  Validation loss = 1.1505  \n",
      "\n",
      "Fold: 6  Epoch: 619  Training loss = 1.8048  Validation loss = 1.1504  \n",
      "\n",
      "Fold: 6  Epoch: 620  Training loss = 1.8046  Validation loss = 1.1500  \n",
      "\n",
      "Fold: 6  Epoch: 621  Training loss = 1.8045  Validation loss = 1.1497  \n",
      "\n",
      "Fold: 6  Epoch: 622  Training loss = 1.8043  Validation loss = 1.1493  \n",
      "\n",
      "Fold: 6  Epoch: 623  Training loss = 1.8042  Validation loss = 1.1491  \n",
      "\n",
      "Fold: 6  Epoch: 624  Training loss = 1.8041  Validation loss = 1.1486  \n",
      "\n",
      "Fold: 6  Epoch: 625  Training loss = 1.8039  Validation loss = 1.1480  \n",
      "\n",
      "Fold: 6  Epoch: 626  Training loss = 1.8038  Validation loss = 1.1476  \n",
      "\n",
      "Fold: 6  Epoch: 627  Training loss = 1.8037  Validation loss = 1.1473  \n",
      "\n",
      "Fold: 6  Epoch: 628  Training loss = 1.8035  Validation loss = 1.1468  \n",
      "\n",
      "Fold: 6  Epoch: 629  Training loss = 1.8033  Validation loss = 1.1463  \n",
      "\n",
      "Fold: 6  Epoch: 630  Training loss = 1.8031  Validation loss = 1.1458  \n",
      "\n",
      "Fold: 6  Epoch: 631  Training loss = 1.8030  Validation loss = 1.1459  \n",
      "\n",
      "Fold: 6  Epoch: 632  Training loss = 1.8028  Validation loss = 1.1452  \n",
      "\n",
      "Fold: 6  Epoch: 633  Training loss = 1.8026  Validation loss = 1.1447  \n",
      "\n",
      "Fold: 6  Epoch: 634  Training loss = 1.8025  Validation loss = 1.1443  \n",
      "\n",
      "Fold: 6  Epoch: 635  Training loss = 1.8024  Validation loss = 1.1445  \n",
      "\n",
      "Fold: 6  Epoch: 636  Training loss = 1.8023  Validation loss = 1.1444  \n",
      "\n",
      "Fold: 6  Epoch: 637  Training loss = 1.8021  Validation loss = 1.1437  \n",
      "\n",
      "Fold: 6  Epoch: 638  Training loss = 1.8020  Validation loss = 1.1432  \n",
      "\n",
      "Fold: 6  Epoch: 639  Training loss = 1.8019  Validation loss = 1.1431  \n",
      "\n",
      "Fold: 6  Epoch: 640  Training loss = 1.8016  Validation loss = 1.1421  \n",
      "\n",
      "Fold: 6  Epoch: 641  Training loss = 1.8016  Validation loss = 1.1420  \n",
      "\n",
      "Fold: 6  Epoch: 642  Training loss = 1.8014  Validation loss = 1.1414  \n",
      "\n",
      "Fold: 6  Epoch: 643  Training loss = 1.8013  Validation loss = 1.1411  \n",
      "\n",
      "Fold: 6  Epoch: 644  Training loss = 1.8012  Validation loss = 1.1411  \n",
      "\n",
      "Fold: 6  Epoch: 645  Training loss = 1.8011  Validation loss = 1.1406  \n",
      "\n",
      "Fold: 6  Epoch: 646  Training loss = 1.8009  Validation loss = 1.1404  \n",
      "\n",
      "Fold: 6  Epoch: 647  Training loss = 1.8008  Validation loss = 1.1403  \n",
      "\n",
      "Fold: 6  Epoch: 648  Training loss = 1.8007  Validation loss = 1.1399  \n",
      "\n",
      "Fold: 6  Epoch: 649  Training loss = 1.8005  Validation loss = 1.1396  \n",
      "\n",
      "Fold: 6  Epoch: 650  Training loss = 1.8004  Validation loss = 1.1392  \n",
      "\n",
      "Fold: 6  Epoch: 651  Training loss = 1.8002  Validation loss = 1.1385  \n",
      "\n",
      "Fold: 6  Epoch: 652  Training loss = 1.8000  Validation loss = 1.1382  \n",
      "\n",
      "Fold: 6  Epoch: 653  Training loss = 1.7999  Validation loss = 1.1378  \n",
      "\n",
      "Fold: 6  Epoch: 654  Training loss = 1.7996  Validation loss = 1.1369  \n",
      "\n",
      "Fold: 6  Epoch: 655  Training loss = 1.7994  Validation loss = 1.1362  \n",
      "\n",
      "Fold: 6  Epoch: 656  Training loss = 1.7992  Validation loss = 1.1357  \n",
      "\n",
      "Fold: 6  Epoch: 657  Training loss = 1.7991  Validation loss = 1.1356  \n",
      "\n",
      "Fold: 6  Epoch: 658  Training loss = 1.7990  Validation loss = 1.1353  \n",
      "\n",
      "Fold: 6  Epoch: 659  Training loss = 1.7989  Validation loss = 1.1352  \n",
      "\n",
      "Fold: 6  Epoch: 660  Training loss = 1.7988  Validation loss = 1.1351  \n",
      "\n",
      "Fold: 6  Epoch: 661  Training loss = 1.7987  Validation loss = 1.1350  \n",
      "\n",
      "Fold: 6  Epoch: 662  Training loss = 1.7987  Validation loss = 1.1352  \n",
      "\n",
      "Fold: 6  Epoch: 663  Training loss = 1.7986  Validation loss = 1.1352  \n",
      "\n",
      "Fold: 6  Epoch: 664  Training loss = 1.7984  Validation loss = 1.1346  \n",
      "\n",
      "Fold: 6  Epoch: 665  Training loss = 1.7983  Validation loss = 1.1343  \n",
      "\n",
      "Fold: 6  Epoch: 666  Training loss = 1.7981  Validation loss = 1.1336  \n",
      "\n",
      "Fold: 6  Epoch: 667  Training loss = 1.7979  Validation loss = 1.1333  \n",
      "\n",
      "Fold: 6  Epoch: 668  Training loss = 1.7978  Validation loss = 1.1334  \n",
      "\n",
      "Fold: 6  Epoch: 669  Training loss = 1.7976  Validation loss = 1.1326  \n",
      "\n",
      "Fold: 6  Epoch: 670  Training loss = 1.7975  Validation loss = 1.1324  \n",
      "\n",
      "Fold: 6  Epoch: 671  Training loss = 1.7974  Validation loss = 1.1321  \n",
      "\n",
      "Fold: 6  Epoch: 672  Training loss = 1.7972  Validation loss = 1.1316  \n",
      "\n",
      "Fold: 6  Epoch: 673  Training loss = 1.7971  Validation loss = 1.1312  \n",
      "\n",
      "Fold: 6  Epoch: 674  Training loss = 1.7969  Validation loss = 1.1307  \n",
      "\n",
      "Fold: 6  Epoch: 675  Training loss = 1.7967  Validation loss = 1.1303  \n",
      "\n",
      "Fold: 6  Epoch: 676  Training loss = 1.7967  Validation loss = 1.1303  \n",
      "\n",
      "Fold: 6  Epoch: 677  Training loss = 1.7965  Validation loss = 1.1298  \n",
      "\n",
      "Fold: 6  Epoch: 678  Training loss = 1.7963  Validation loss = 1.1291  \n",
      "\n",
      "Fold: 6  Epoch: 679  Training loss = 1.7962  Validation loss = 1.1290  \n",
      "\n",
      "Fold: 6  Epoch: 680  Training loss = 1.7960  Validation loss = 1.1288  \n",
      "\n",
      "Fold: 6  Epoch: 681  Training loss = 1.7959  Validation loss = 1.1284  \n",
      "\n",
      "Fold: 6  Epoch: 682  Training loss = 1.7957  Validation loss = 1.1278  \n",
      "\n",
      "Fold: 6  Epoch: 683  Training loss = 1.7956  Validation loss = 1.1275  \n",
      "\n",
      "Fold: 6  Epoch: 684  Training loss = 1.7955  Validation loss = 1.1270  \n",
      "\n",
      "Fold: 6  Epoch: 685  Training loss = 1.7954  Validation loss = 1.1271  \n",
      "\n",
      "Fold: 6  Epoch: 686  Training loss = 1.7952  Validation loss = 1.1263  \n",
      "\n",
      "Fold: 6  Epoch: 687  Training loss = 1.7951  Validation loss = 1.1261  \n",
      "\n",
      "Fold: 6  Epoch: 688  Training loss = 1.7949  Validation loss = 1.1256  \n",
      "\n",
      "Fold: 6  Epoch: 689  Training loss = 1.7947  Validation loss = 1.1251  \n",
      "\n",
      "Fold: 6  Epoch: 690  Training loss = 1.7946  Validation loss = 1.1249  \n",
      "\n",
      "Fold: 6  Epoch: 691  Training loss = 1.7945  Validation loss = 1.1245  \n",
      "\n",
      "Fold: 6  Epoch: 692  Training loss = 1.7944  Validation loss = 1.1243  \n",
      "\n",
      "Fold: 6  Epoch: 693  Training loss = 1.7942  Validation loss = 1.1237  \n",
      "\n",
      "Fold: 6  Epoch: 694  Training loss = 1.7941  Validation loss = 1.1234  \n",
      "\n",
      "Fold: 6  Epoch: 695  Training loss = 1.7939  Validation loss = 1.1229  \n",
      "\n",
      "Fold: 6  Epoch: 696  Training loss = 1.7938  Validation loss = 1.1226  \n",
      "\n",
      "Fold: 6  Epoch: 697  Training loss = 1.7937  Validation loss = 1.1223  \n",
      "\n",
      "Fold: 6  Epoch: 698  Training loss = 1.7935  Validation loss = 1.1217  \n",
      "\n",
      "Fold: 6  Epoch: 699  Training loss = 1.7934  Validation loss = 1.1217  \n",
      "\n",
      "Fold: 6  Epoch: 700  Training loss = 1.7933  Validation loss = 1.1214  \n",
      "\n",
      "Fold: 6  Epoch: 701  Training loss = 1.7931  Validation loss = 1.1210  \n",
      "\n",
      "Fold: 6  Epoch: 702  Training loss = 1.7929  Validation loss = 1.1207  \n",
      "\n",
      "Fold: 6  Epoch: 703  Training loss = 1.7928  Validation loss = 1.1204  \n",
      "\n",
      "Fold: 6  Epoch: 704  Training loss = 1.7927  Validation loss = 1.1205  \n",
      "\n",
      "Fold: 6  Epoch: 705  Training loss = 1.7926  Validation loss = 1.1201  \n",
      "\n",
      "Fold: 6  Epoch: 706  Training loss = 1.7925  Validation loss = 1.1201  \n",
      "\n",
      "Fold: 6  Epoch: 707  Training loss = 1.7924  Validation loss = 1.1201  \n",
      "\n",
      "Fold: 6  Epoch: 708  Training loss = 1.7924  Validation loss = 1.1201  \n",
      "\n",
      "Fold: 6  Epoch: 709  Training loss = 1.7923  Validation loss = 1.1200  \n",
      "\n",
      "Fold: 6  Epoch: 710  Training loss = 1.7921  Validation loss = 1.1198  \n",
      "\n",
      "Fold: 6  Epoch: 711  Training loss = 1.7920  Validation loss = 1.1194  \n",
      "\n",
      "Fold: 6  Epoch: 712  Training loss = 1.7919  Validation loss = 1.1195  \n",
      "\n",
      "Fold: 6  Epoch: 713  Training loss = 1.7918  Validation loss = 1.1197  \n",
      "\n",
      "Fold: 6  Epoch: 714  Training loss = 1.7917  Validation loss = 1.1196  \n",
      "\n",
      "Fold: 6  Epoch: 715  Training loss = 1.7916  Validation loss = 1.1196  \n",
      "\n",
      "Fold: 6  Epoch: 716  Training loss = 1.7914  Validation loss = 1.1186  \n",
      "\n",
      "Fold: 6  Epoch: 717  Training loss = 1.7913  Validation loss = 1.1182  \n",
      "\n",
      "Fold: 6  Epoch: 718  Training loss = 1.7912  Validation loss = 1.1179  \n",
      "\n",
      "Fold: 6  Epoch: 719  Training loss = 1.7910  Validation loss = 1.1175  \n",
      "\n",
      "Fold: 6  Epoch: 720  Training loss = 1.7909  Validation loss = 1.1172  \n",
      "\n",
      "Fold: 6  Epoch: 721  Training loss = 1.7907  Validation loss = 1.1167  \n",
      "\n",
      "Fold: 6  Epoch: 722  Training loss = 1.7906  Validation loss = 1.1166  \n",
      "\n",
      "Fold: 6  Epoch: 723  Training loss = 1.7904  Validation loss = 1.1161  \n",
      "\n",
      "Fold: 6  Epoch: 724  Training loss = 1.7903  Validation loss = 1.1163  \n",
      "\n",
      "Fold: 6  Epoch: 725  Training loss = 1.7902  Validation loss = 1.1159  \n",
      "\n",
      "Fold: 6  Epoch: 726  Training loss = 1.7901  Validation loss = 1.1160  \n",
      "\n",
      "Fold: 6  Epoch: 727  Training loss = 1.7900  Validation loss = 1.1160  \n",
      "\n",
      "Fold: 6  Epoch: 728  Training loss = 1.7899  Validation loss = 1.1161  \n",
      "\n",
      "Fold: 6  Epoch: 729  Training loss = 1.7898  Validation loss = 1.1156  \n",
      "\n",
      "Fold: 6  Epoch: 730  Training loss = 1.7896  Validation loss = 1.1151  \n",
      "\n",
      "Fold: 6  Epoch: 731  Training loss = 1.7895  Validation loss = 1.1148  \n",
      "\n",
      "Fold: 6  Epoch: 732  Training loss = 1.7893  Validation loss = 1.1146  \n",
      "\n",
      "Fold: 6  Epoch: 733  Training loss = 1.7892  Validation loss = 1.1141  \n",
      "\n",
      "Fold: 6  Epoch: 734  Training loss = 1.7891  Validation loss = 1.1139  \n",
      "\n",
      "Fold: 6  Epoch: 735  Training loss = 1.7890  Validation loss = 1.1138  \n",
      "\n",
      "Fold: 6  Epoch: 736  Training loss = 1.7888  Validation loss = 1.1133  \n",
      "\n",
      "Fold: 6  Epoch: 737  Training loss = 1.7887  Validation loss = 1.1129  \n",
      "\n",
      "Fold: 6  Epoch: 738  Training loss = 1.7885  Validation loss = 1.1123  \n",
      "\n",
      "Fold: 6  Epoch: 739  Training loss = 1.7884  Validation loss = 1.1119  \n",
      "\n",
      "Fold: 6  Epoch: 740  Training loss = 1.7882  Validation loss = 1.1114  \n",
      "\n",
      "Fold: 6  Epoch: 741  Training loss = 1.7880  Validation loss = 1.1109  \n",
      "\n",
      "Fold: 6  Epoch: 742  Training loss = 1.7878  Validation loss = 1.1103  \n",
      "\n",
      "Fold: 6  Epoch: 743  Training loss = 1.7877  Validation loss = 1.1101  \n",
      "\n",
      "Fold: 6  Epoch: 744  Training loss = 1.7875  Validation loss = 1.1097  \n",
      "\n",
      "Fold: 6  Epoch: 745  Training loss = 1.7874  Validation loss = 1.1094  \n",
      "\n",
      "Fold: 6  Epoch: 746  Training loss = 1.7873  Validation loss = 1.1094  \n",
      "\n",
      "Fold: 6  Epoch: 747  Training loss = 1.7872  Validation loss = 1.1094  \n",
      "\n",
      "Fold: 6  Epoch: 748  Training loss = 1.7870  Validation loss = 1.1091  \n",
      "\n",
      "Fold: 6  Epoch: 749  Training loss = 1.7869  Validation loss = 1.1085  \n",
      "\n",
      "Fold: 6  Epoch: 750  Training loss = 1.7868  Validation loss = 1.1085  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 749  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.7135  Validation loss = 1.0151  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.7133  Validation loss = 1.0148  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.7132  Validation loss = 1.0145  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.7129  Validation loss = 1.0139  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.7129  Validation loss = 1.0140  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.7126  Validation loss = 1.0134  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.7124  Validation loss = 1.0129  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.7123  Validation loss = 1.0125  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.7119  Validation loss = 1.0115  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.7118  Validation loss = 1.0113  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.7116  Validation loss = 1.0111  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.7115  Validation loss = 1.0109  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.7113  Validation loss = 1.0106  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.7111  Validation loss = 1.0102  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.7110  Validation loss = 1.0104  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.7109  Validation loss = 1.0102  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.7107  Validation loss = 1.0097  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.7106  Validation loss = 1.0095  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.7104  Validation loss = 1.0091  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.7102  Validation loss = 1.0087  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.7100  Validation loss = 1.0082  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.7097  Validation loss = 1.0073  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 1.7095  Validation loss = 1.0067  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 1.7093  Validation loss = 1.0064  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 1.7092  Validation loss = 1.0062  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 1.7090  Validation loss = 1.0060  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 1.7089  Validation loss = 1.0058  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 1.7087  Validation loss = 1.0055  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 1.7086  Validation loss = 1.0052  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 1.7083  Validation loss = 1.0047  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 1.7082  Validation loss = 1.0047  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 1.7079  Validation loss = 1.0041  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 1.7077  Validation loss = 1.0034  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 1.7075  Validation loss = 1.0027  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 1.7073  Validation loss = 1.0025  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 1.7072  Validation loss = 1.0025  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 1.7071  Validation loss = 1.0023  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 1.7069  Validation loss = 1.0018  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 1.7067  Validation loss = 1.0015  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 1.7067  Validation loss = 1.0017  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 1.7065  Validation loss = 1.0014  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 1.7063  Validation loss = 1.0010  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 1.7061  Validation loss = 1.0007  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 1.7059  Validation loss = 1.0004  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 1.7058  Validation loss = 1.0001  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 1.7056  Validation loss = 1.0000  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 1.7054  Validation loss = 0.9995  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 1.7052  Validation loss = 0.9990  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 1.7050  Validation loss = 0.9987  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 1.7048  Validation loss = 0.9983  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 1.7046  Validation loss = 0.9977  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 1.7044  Validation loss = 0.9975  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 1.7042  Validation loss = 0.9970  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 1.7040  Validation loss = 0.9966  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 1.7038  Validation loss = 0.9964  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 1.7036  Validation loss = 0.9956  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 1.7033  Validation loss = 0.9950  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 1.7032  Validation loss = 0.9949  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 1.7030  Validation loss = 0.9947  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 1.7029  Validation loss = 0.9945  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 1.7027  Validation loss = 0.9942  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 1.7025  Validation loss = 0.9937  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 1.7022  Validation loss = 0.9930  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 1.7021  Validation loss = 0.9931  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 1.7020  Validation loss = 0.9927  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 1.7018  Validation loss = 0.9921  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 1.7016  Validation loss = 0.9919  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 1.7015  Validation loss = 0.9917  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 1.7013  Validation loss = 0.9913  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 1.7011  Validation loss = 0.9909  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 1.7009  Validation loss = 0.9905  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 1.7006  Validation loss = 0.9896  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 1.7004  Validation loss = 0.9892  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 1.7001  Validation loss = 0.9884  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 1.7000  Validation loss = 0.9883  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 1.6998  Validation loss = 0.9880  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 1.6997  Validation loss = 0.9876  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 1.6995  Validation loss = 0.9873  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 1.6993  Validation loss = 0.9868  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 1.6991  Validation loss = 0.9864  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 1.6989  Validation loss = 0.9858  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 1.6988  Validation loss = 0.9858  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 1.6986  Validation loss = 0.9855  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 1.6984  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 1.6982  Validation loss = 0.9847  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 1.6979  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 1.6978  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 1.6976  Validation loss = 0.9833  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 1.6973  Validation loss = 0.9827  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 1.6972  Validation loss = 0.9826  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 1.6970  Validation loss = 0.9820  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 1.6968  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 1.6966  Validation loss = 0.9812  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 1.6963  Validation loss = 0.9806  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 1.6961  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 1.6958  Validation loss = 0.9794  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 1.6957  Validation loss = 0.9790  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 1.6955  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 1.6954  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 1.6954  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 1.6951  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 1.6949  Validation loss = 0.9776  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 1.6949  Validation loss = 0.9778  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 1.6946  Validation loss = 0.9773  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 1.6945  Validation loss = 0.9772  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 1.6943  Validation loss = 0.9770  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 1.6941  Validation loss = 0.9766  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 1.6939  Validation loss = 0.9759  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 1.6937  Validation loss = 0.9754  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 1.6935  Validation loss = 0.9752  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 1.6934  Validation loss = 0.9752  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 1.6933  Validation loss = 0.9747  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 1.6932  Validation loss = 0.9747  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 1.6930  Validation loss = 0.9744  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 1.6927  Validation loss = 0.9736  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 1.6926  Validation loss = 0.9735  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 1.6925  Validation loss = 0.9734  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 1.6923  Validation loss = 0.9730  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 1.6922  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 1.6921  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 1.6919  Validation loss = 0.9727  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 1.6919  Validation loss = 0.9731  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 1.6918  Validation loss = 0.9730  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 1.6916  Validation loss = 0.9726  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 1.6914  Validation loss = 0.9721  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 1.6912  Validation loss = 0.9717  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 1.6911  Validation loss = 0.9715  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 1.6909  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 1.6908  Validation loss = 0.9711  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 1.6907  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 1.6905  Validation loss = 0.9704  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 1.6903  Validation loss = 0.9700  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 1.6901  Validation loss = 0.9694  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 1.6900  Validation loss = 0.9693  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 1.6898  Validation loss = 0.9690  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 1.6896  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 1.6895  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 1.6894  Validation loss = 0.9682  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 1.6891  Validation loss = 0.9677  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 1.6889  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 1.6888  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 1.6887  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 1.6885  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 1.6883  Validation loss = 0.9658  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 1.6881  Validation loss = 0.9655  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 1.6879  Validation loss = 0.9652  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 1.6877  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 1.6874  Validation loss = 0.9637  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 1.6872  Validation loss = 0.9633  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 1.6871  Validation loss = 0.9632  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 1.6869  Validation loss = 0.9627  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 1.6867  Validation loss = 0.9625  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 1.6865  Validation loss = 0.9622  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 1.6863  Validation loss = 0.9619  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 1.6862  Validation loss = 0.9616  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 1.6860  Validation loss = 0.9610  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 1.6858  Validation loss = 0.9609  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 1.6856  Validation loss = 0.9604  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 1.6855  Validation loss = 0.9603  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 1.6852  Validation loss = 0.9595  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 1.6850  Validation loss = 0.9591  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 1.6848  Validation loss = 0.9586  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 1.6847  Validation loss = 0.9584  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 1.6846  Validation loss = 0.9585  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 1.6844  Validation loss = 0.9583  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 1.6842  Validation loss = 0.9577  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 1.6840  Validation loss = 0.9572  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 1.6839  Validation loss = 0.9571  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 1.6838  Validation loss = 0.9571  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 1.6836  Validation loss = 0.9568  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 1.6834  Validation loss = 0.9564  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 1.6833  Validation loss = 0.9561  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 1.6832  Validation loss = 0.9562  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 1.6831  Validation loss = 0.9561  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 1.6829  Validation loss = 0.9557  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 1.6827  Validation loss = 0.9558  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 1.6826  Validation loss = 0.9554  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 1.6824  Validation loss = 0.9549  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 1.6822  Validation loss = 0.9549  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 1.6820  Validation loss = 0.9545  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 1.6818  Validation loss = 0.9539  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 1.6817  Validation loss = 0.9538  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 1.6815  Validation loss = 0.9535  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 1.6814  Validation loss = 0.9535  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 1.6812  Validation loss = 0.9531  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 1.6810  Validation loss = 0.9527  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 1.6809  Validation loss = 0.9526  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 1.6806  Validation loss = 0.9520  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 1.6804  Validation loss = 0.9516  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 1.6803  Validation loss = 0.9514  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 1.6801  Validation loss = 0.9510  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 1.6798  Validation loss = 0.9504  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 1.6797  Validation loss = 0.9502  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 1.6795  Validation loss = 0.9498  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 1.6795  Validation loss = 0.9501  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 1.6793  Validation loss = 0.9500  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 1.6791  Validation loss = 0.9496  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 1.6789  Validation loss = 0.9492  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 1.6787  Validation loss = 0.9487  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 1.6786  Validation loss = 0.9486  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 1.6785  Validation loss = 0.9482  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 1.6784  Validation loss = 0.9480  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 1.6782  Validation loss = 0.9477  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 1.6780  Validation loss = 0.9472  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 1.6779  Validation loss = 0.9472  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 1.6777  Validation loss = 0.9465  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 1.6776  Validation loss = 0.9464  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 1.6773  Validation loss = 0.9459  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 1.6771  Validation loss = 0.9455  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 1.6770  Validation loss = 0.9454  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 1.6769  Validation loss = 0.9455  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 1.6768  Validation loss = 0.9455  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 1.6766  Validation loss = 0.9452  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 1.6764  Validation loss = 0.9449  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 1.6763  Validation loss = 0.9445  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 1.6761  Validation loss = 0.9443  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 1.6759  Validation loss = 0.9435  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 1.6757  Validation loss = 0.9429  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 1.6755  Validation loss = 0.9428  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 1.6753  Validation loss = 0.9424  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 1.6752  Validation loss = 0.9420  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 1.6749  Validation loss = 0.9414  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 1.6747  Validation loss = 0.9408  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 1.6745  Validation loss = 0.9406  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 1.6743  Validation loss = 0.9402  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 1.6742  Validation loss = 0.9399  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 1.6741  Validation loss = 0.9400  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 1.6739  Validation loss = 0.9399  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 1.6737  Validation loss = 0.9394  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 1.6736  Validation loss = 0.9395  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 1.6734  Validation loss = 0.9393  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 1.6733  Validation loss = 0.9389  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 1.6730  Validation loss = 0.9384  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 1.6730  Validation loss = 0.9386  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 1.6728  Validation loss = 0.9382  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 1.6726  Validation loss = 0.9379  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 1.6725  Validation loss = 0.9379  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 1.6723  Validation loss = 0.9373  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 1.6721  Validation loss = 0.9370  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 1.6719  Validation loss = 0.9365  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 1.6717  Validation loss = 0.9361  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 1.6716  Validation loss = 0.9357  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 1.6713  Validation loss = 0.9349  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 1.6711  Validation loss = 0.9347  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 1.6710  Validation loss = 0.9345  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 1.6708  Validation loss = 0.9343  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 1.6707  Validation loss = 0.9339  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 1.6705  Validation loss = 0.9333  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 1.6703  Validation loss = 0.9331  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 1.6701  Validation loss = 0.9328  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 1.6700  Validation loss = 0.9324  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 1.6697  Validation loss = 0.9316  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 1.6695  Validation loss = 0.9312  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 1.6693  Validation loss = 0.9307  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 1.6692  Validation loss = 0.9306  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 1.6690  Validation loss = 0.9305  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 1.6688  Validation loss = 0.9298  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 1.6687  Validation loss = 0.9297  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 1.6686  Validation loss = 0.9295  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 1.6683  Validation loss = 0.9290  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 1.6682  Validation loss = 0.9289  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 1.6681  Validation loss = 0.9291  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 1.6680  Validation loss = 0.9287  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 1.6678  Validation loss = 0.9282  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 1.6677  Validation loss = 0.9282  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 1.6675  Validation loss = 0.9276  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 1.6673  Validation loss = 0.9270  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 1.6672  Validation loss = 0.9270  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 1.6670  Validation loss = 0.9265  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 1.6667  Validation loss = 0.9259  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 1.6666  Validation loss = 0.9256  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 1.6664  Validation loss = 0.9250  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 1.6664  Validation loss = 0.9252  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 1.6663  Validation loss = 0.9252  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 1.6660  Validation loss = 0.9244  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 1.6658  Validation loss = 0.9243  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 1.6656  Validation loss = 0.9239  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 1.6655  Validation loss = 0.9238  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 1.6653  Validation loss = 0.9235  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 1.6652  Validation loss = 0.9234  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 1.6652  Validation loss = 0.9238  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 1.6650  Validation loss = 0.9236  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 1.6648  Validation loss = 0.9235  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 1.6648  Validation loss = 0.9237  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 1.6647  Validation loss = 0.9236  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 1.6644  Validation loss = 0.9228  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 1.6643  Validation loss = 0.9225  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 1.6642  Validation loss = 0.9226  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 1.6642  Validation loss = 0.9229  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 1.6640  Validation loss = 0.9226  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 1.6639  Validation loss = 0.9225  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 1.6637  Validation loss = 0.9221  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 1.6636  Validation loss = 0.9216  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 1.6634  Validation loss = 0.9215  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 1.6634  Validation loss = 0.9216  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 1.6633  Validation loss = 0.9217  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 1.6631  Validation loss = 0.9213  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 1.6629  Validation loss = 0.9209  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 1.6628  Validation loss = 0.9208  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 1.6627  Validation loss = 0.9207  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 1.6625  Validation loss = 0.9202  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 1.6622  Validation loss = 0.9197  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 1.6621  Validation loss = 0.9196  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 1.6620  Validation loss = 0.9191  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 1.6617  Validation loss = 0.9184  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 1.6615  Validation loss = 0.9179  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 1.6614  Validation loss = 0.9176  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 1.6613  Validation loss = 0.9177  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 1.6611  Validation loss = 0.9175  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 1.6610  Validation loss = 0.9175  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 1.6609  Validation loss = 0.9173  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 1.6607  Validation loss = 0.9169  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 1.6606  Validation loss = 0.9165  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 1.6605  Validation loss = 0.9165  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 1.6604  Validation loss = 0.9167  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 1.6601  Validation loss = 0.9161  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 1.6599  Validation loss = 0.9155  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 1.6598  Validation loss = 0.9157  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 1.6596  Validation loss = 0.9154  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 1.6595  Validation loss = 0.9152  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 1.6594  Validation loss = 0.9149  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 1.6593  Validation loss = 0.9150  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 1.6591  Validation loss = 0.9145  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 1.6590  Validation loss = 0.9144  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 1.6588  Validation loss = 0.9142  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 1.6586  Validation loss = 0.9137  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 1.6585  Validation loss = 0.9137  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 1.6584  Validation loss = 0.9137  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 1.6582  Validation loss = 0.9133  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 1.6581  Validation loss = 0.9132  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 1.6579  Validation loss = 0.9128  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 1.6578  Validation loss = 0.9126  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 1.6576  Validation loss = 0.9121  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 1.6574  Validation loss = 0.9120  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 1.6573  Validation loss = 0.9121  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 1.6572  Validation loss = 0.9118  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 1.6570  Validation loss = 0.9113  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 1.6568  Validation loss = 0.9110  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 1.6567  Validation loss = 0.9109  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 1.6565  Validation loss = 0.9106  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 1.6563  Validation loss = 0.9101  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 1.6561  Validation loss = 0.9093  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 1.6559  Validation loss = 0.9093  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 1.6558  Validation loss = 0.9093  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 1.6557  Validation loss = 0.9092  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 1.6556  Validation loss = 0.9091  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 1.6555  Validation loss = 0.9090  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 1.6553  Validation loss = 0.9089  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 1.6552  Validation loss = 0.9088  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 1.6550  Validation loss = 0.9088  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 1.6548  Validation loss = 0.9084  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 1.6547  Validation loss = 0.9083  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 1.6545  Validation loss = 0.9081  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 1.6544  Validation loss = 0.9081  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 1.6542  Validation loss = 0.9079  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 1.6541  Validation loss = 0.9073  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 1.6539  Validation loss = 0.9068  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 1.6537  Validation loss = 0.9068  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 1.6536  Validation loss = 0.9066  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 1.6536  Validation loss = 0.9070  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 1.6534  Validation loss = 0.9064  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 1.6532  Validation loss = 0.9061  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 1.6531  Validation loss = 0.9061  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 1.6530  Validation loss = 0.9061  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 1.6528  Validation loss = 0.9059  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 1.6527  Validation loss = 0.9061  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 1.6526  Validation loss = 0.9058  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 1.6525  Validation loss = 0.9060  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 1.6522  Validation loss = 0.9054  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 1.6520  Validation loss = 0.9049  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 1.6519  Validation loss = 0.9050  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 1.6519  Validation loss = 0.9049  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 1.6517  Validation loss = 0.9045  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 1.6515  Validation loss = 0.9039  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 1.6514  Validation loss = 0.9040  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 1.6513  Validation loss = 0.9041  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 1.6511  Validation loss = 0.9039  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 1.6509  Validation loss = 0.9034  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 1.6508  Validation loss = 0.9032  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 1.6506  Validation loss = 0.9030  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 1.6504  Validation loss = 0.9025  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 1.6502  Validation loss = 0.9022  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 1.6501  Validation loss = 0.9021  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 1.6499  Validation loss = 0.9020  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 1.6497  Validation loss = 0.9010  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 1.6494  Validation loss = 0.9005  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 1.6492  Validation loss = 0.9001  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 1.6491  Validation loss = 0.9000  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 1.6489  Validation loss = 0.8998  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 1.6488  Validation loss = 0.8995  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 1.6485  Validation loss = 0.8986  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 1.6484  Validation loss = 0.8989  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 1.6482  Validation loss = 0.8988  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 1.6481  Validation loss = 0.8985  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 1.6479  Validation loss = 0.8982  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 1.6478  Validation loss = 0.8983  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 1.6477  Validation loss = 0.8982  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 1.6475  Validation loss = 0.8977  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 1.6472  Validation loss = 0.8971  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 1.6471  Validation loss = 0.8972  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 1.6469  Validation loss = 0.8968  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 1.6468  Validation loss = 0.8968  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 1.6466  Validation loss = 0.8966  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 1.6466  Validation loss = 0.8966  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 1.6464  Validation loss = 0.8961  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 1.6462  Validation loss = 0.8959  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 1.6461  Validation loss = 0.8961  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 1.6461  Validation loss = 0.8962  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 1.6459  Validation loss = 0.8961  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 1.6458  Validation loss = 0.8964  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 1.6457  Validation loss = 0.8963  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 1.6456  Validation loss = 0.8959  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 1.6455  Validation loss = 0.8956  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 1.6454  Validation loss = 0.8957  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 1.6453  Validation loss = 0.8956  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 1.6451  Validation loss = 0.8956  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 1.6450  Validation loss = 0.8954  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 1.6448  Validation loss = 0.8953  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 1.6446  Validation loss = 0.8948  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 1.6445  Validation loss = 0.8945  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 1.6444  Validation loss = 0.8945  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 1.6442  Validation loss = 0.8941  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 1.6440  Validation loss = 0.8938  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 1.6439  Validation loss = 0.8940  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 1.6437  Validation loss = 0.8939  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 1.6436  Validation loss = 0.8937  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 1.6435  Validation loss = 0.8933  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 1.6433  Validation loss = 0.8929  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 1.6431  Validation loss = 0.8923  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 1.6429  Validation loss = 0.8920  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 1.6428  Validation loss = 0.8916  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 1.6426  Validation loss = 0.8913  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 1.6424  Validation loss = 0.8910  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 1.6423  Validation loss = 0.8910  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 1.6422  Validation loss = 0.8907  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 1.6420  Validation loss = 0.8905  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 1.6419  Validation loss = 0.8903  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 1.6418  Validation loss = 0.8904  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 1.6415  Validation loss = 0.8898  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 1.6414  Validation loss = 0.8899  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 1.6412  Validation loss = 0.8894  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 1.6410  Validation loss = 0.8890  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 1.6408  Validation loss = 0.8889  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 1.6406  Validation loss = 0.8885  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 1.6404  Validation loss = 0.8885  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 1.6404  Validation loss = 0.8886  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 1.6402  Validation loss = 0.8882  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 1.6401  Validation loss = 0.8879  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 1.6399  Validation loss = 0.8875  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 1.6398  Validation loss = 0.8873  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 1.6396  Validation loss = 0.8870  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 1.6395  Validation loss = 0.8866  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 1.6393  Validation loss = 0.8866  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 1.6392  Validation loss = 0.8863  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 1.6390  Validation loss = 0.8857  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 1.6388  Validation loss = 0.8853  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 1.6387  Validation loss = 0.8854  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 1.6385  Validation loss = 0.8856  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 1.6384  Validation loss = 0.8856  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 1.6382  Validation loss = 0.8853  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 1.6380  Validation loss = 0.8847  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 1.6378  Validation loss = 0.8842  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 1.6377  Validation loss = 0.8838  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 1.6375  Validation loss = 0.8836  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 1.6373  Validation loss = 0.8830  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 1.6371  Validation loss = 0.8827  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 1.6370  Validation loss = 0.8826  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 1.6368  Validation loss = 0.8823  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 1.6367  Validation loss = 0.8821  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 1.6366  Validation loss = 0.8817  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 1.6364  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 1.6363  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 1.6362  Validation loss = 0.8818  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 1.6360  Validation loss = 0.8814  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 1.6359  Validation loss = 0.8813  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 1.6358  Validation loss = 0.8813  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 1.6357  Validation loss = 0.8816  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 1.6356  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 1.6354  Validation loss = 0.8816  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 1.6353  Validation loss = 0.8817  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 1.6352  Validation loss = 0.8816  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 1.6350  Validation loss = 0.8812  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 1.6348  Validation loss = 0.8804  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 1.6346  Validation loss = 0.8800  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 1.6345  Validation loss = 0.8798  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 1.6343  Validation loss = 0.8799  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 1.6342  Validation loss = 0.8799  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 1.6341  Validation loss = 0.8798  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 1.6339  Validation loss = 0.8792  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 1.6338  Validation loss = 0.8789  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 1.6337  Validation loss = 0.8787  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 1.6336  Validation loss = 0.8787  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 1.6334  Validation loss = 0.8785  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 1.6334  Validation loss = 0.8791  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 1.6333  Validation loss = 0.8790  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 1.6331  Validation loss = 0.8788  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 1.6329  Validation loss = 0.8786  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 1.6328  Validation loss = 0.8783  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 1.6327  Validation loss = 0.8785  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 1.6326  Validation loss = 0.8788  \n",
      "\n",
      "Fold: 7  Epoch: 501  Training loss = 1.6325  Validation loss = 0.8789  \n",
      "\n",
      "Fold: 7  Epoch: 502  Training loss = 1.6325  Validation loss = 0.8792  \n",
      "\n",
      "Fold: 7  Epoch: 503  Training loss = 1.6323  Validation loss = 0.8787  \n",
      "\n",
      "Fold: 7  Epoch: 504  Training loss = 1.6322  Validation loss = 0.8789  \n",
      "\n",
      "Fold: 7  Epoch: 505  Training loss = 1.6320  Validation loss = 0.8787  \n",
      "\n",
      "Fold: 7  Epoch: 506  Training loss = 1.6319  Validation loss = 0.8786  \n",
      "\n",
      "Fold: 7  Epoch: 507  Training loss = 1.6318  Validation loss = 0.8781  \n",
      "\n",
      "Fold: 7  Epoch: 508  Training loss = 1.6316  Validation loss = 0.8779  \n",
      "\n",
      "Fold: 7  Epoch: 509  Training loss = 1.6316  Validation loss = 0.8780  \n",
      "\n",
      "Fold: 7  Epoch: 510  Training loss = 1.6314  Validation loss = 0.8779  \n",
      "\n",
      "Fold: 7  Epoch: 511  Training loss = 1.6313  Validation loss = 0.8782  \n",
      "\n",
      "Fold: 7  Epoch: 512  Training loss = 1.6312  Validation loss = 0.8785  \n",
      "\n",
      "Fold: 7  Epoch: 513  Training loss = 1.6312  Validation loss = 0.8789  \n",
      "\n",
      "Fold: 7  Epoch: 514  Training loss = 1.6310  Validation loss = 0.8786  \n",
      "\n",
      "Fold: 7  Epoch: 515  Training loss = 1.6308  Validation loss = 0.8782  \n",
      "\n",
      "Fold: 7  Epoch: 516  Training loss = 1.6307  Validation loss = 0.8782  \n",
      "\n",
      "Fold: 7  Epoch: 517  Training loss = 1.6306  Validation loss = 0.8783  \n",
      "\n",
      "Fold: 7  Epoch: 518  Training loss = 1.6305  Validation loss = 0.8783  \n",
      "\n",
      "Fold: 7  Epoch: 519  Training loss = 1.6303  Validation loss = 0.8779  \n",
      "\n",
      "Fold: 7  Epoch: 520  Training loss = 1.6301  Validation loss = 0.8776  \n",
      "\n",
      "Fold: 7  Epoch: 521  Training loss = 1.6300  Validation loss = 0.8776  \n",
      "\n",
      "Fold: 7  Epoch: 522  Training loss = 1.6298  Validation loss = 0.8769  \n",
      "\n",
      "Fold: 7  Epoch: 523  Training loss = 1.6297  Validation loss = 0.8768  \n",
      "\n",
      "Fold: 7  Epoch: 524  Training loss = 1.6294  Validation loss = 0.8765  \n",
      "\n",
      "Fold: 7  Epoch: 525  Training loss = 1.6293  Validation loss = 0.8764  \n",
      "\n",
      "Fold: 7  Epoch: 526  Training loss = 1.6290  Validation loss = 0.8758  \n",
      "\n",
      "Fold: 7  Epoch: 527  Training loss = 1.6289  Validation loss = 0.8756  \n",
      "\n",
      "Fold: 7  Epoch: 528  Training loss = 1.6288  Validation loss = 0.8756  \n",
      "\n",
      "Fold: 7  Epoch: 529  Training loss = 1.6286  Validation loss = 0.8755  \n",
      "\n",
      "Fold: 7  Epoch: 530  Training loss = 1.6285  Validation loss = 0.8756  \n",
      "\n",
      "Fold: 7  Epoch: 531  Training loss = 1.6284  Validation loss = 0.8758  \n",
      "\n",
      "Fold: 7  Epoch: 532  Training loss = 1.6283  Validation loss = 0.8759  \n",
      "\n",
      "Fold: 7  Epoch: 533  Training loss = 1.6282  Validation loss = 0.8760  \n",
      "\n",
      "Fold: 7  Epoch: 534  Training loss = 1.6281  Validation loss = 0.8759  \n",
      "\n",
      "Fold: 7  Epoch: 535  Training loss = 1.6279  Validation loss = 0.8758  \n",
      "\n",
      "Fold: 7  Epoch: 536  Training loss = 1.6278  Validation loss = 0.8759  \n",
      "\n",
      "Fold: 7  Epoch: 537  Training loss = 1.6277  Validation loss = 0.8757  \n",
      "\n",
      "Fold: 7  Epoch: 538  Training loss = 1.6275  Validation loss = 0.8752  \n",
      "\n",
      "Fold: 7  Epoch: 539  Training loss = 1.6274  Validation loss = 0.8754  \n",
      "\n",
      "Fold: 7  Epoch: 540  Training loss = 1.6274  Validation loss = 0.8757  \n",
      "\n",
      "Fold: 7  Epoch: 541  Training loss = 1.6272  Validation loss = 0.8752  \n",
      "\n",
      "Fold: 7  Epoch: 542  Training loss = 1.6271  Validation loss = 0.8753  \n",
      "\n",
      "Fold: 7  Epoch: 543  Training loss = 1.6269  Validation loss = 0.8744  \n",
      "\n",
      "Fold: 7  Epoch: 544  Training loss = 1.6268  Validation loss = 0.8742  \n",
      "\n",
      "Fold: 7  Epoch: 545  Training loss = 1.6267  Validation loss = 0.8740  \n",
      "\n",
      "Fold: 7  Epoch: 546  Training loss = 1.6265  Validation loss = 0.8736  \n",
      "\n",
      "Fold: 7  Epoch: 547  Training loss = 1.6264  Validation loss = 0.8736  \n",
      "\n",
      "Fold: 7  Epoch: 548  Training loss = 1.6263  Validation loss = 0.8736  \n",
      "\n",
      "Fold: 7  Epoch: 549  Training loss = 1.6262  Validation loss = 0.8739  \n",
      "\n",
      "Fold: 7  Epoch: 550  Training loss = 1.6261  Validation loss = 0.8741  \n",
      "\n",
      "Fold: 7  Epoch: 551  Training loss = 1.6260  Validation loss = 0.8743  \n",
      "\n",
      "Fold: 7  Epoch: 552  Training loss = 1.6259  Validation loss = 0.8743  \n",
      "\n",
      "Fold: 7  Epoch: 553  Training loss = 1.6257  Validation loss = 0.8744  \n",
      "\n",
      "Fold: 7  Epoch: 554  Training loss = 1.6256  Validation loss = 0.8743  \n",
      "\n",
      "Fold: 7  Epoch: 555  Training loss = 1.6254  Validation loss = 0.8742  \n",
      "\n",
      "Fold: 7  Epoch: 556  Training loss = 1.6253  Validation loss = 0.8742  \n",
      "\n",
      "Fold: 7  Epoch: 557  Training loss = 1.6252  Validation loss = 0.8743  \n",
      "\n",
      "Fold: 7  Epoch: 558  Training loss = 1.6250  Validation loss = 0.8738  \n",
      "\n",
      "Fold: 7  Epoch: 559  Training loss = 1.6250  Validation loss = 0.8739  \n",
      "\n",
      "Fold: 7  Epoch: 560  Training loss = 1.6248  Validation loss = 0.8737  \n",
      "\n",
      "Fold: 7  Epoch: 561  Training loss = 1.6246  Validation loss = 0.8733  \n",
      "\n",
      "Fold: 7  Epoch: 562  Training loss = 1.6244  Validation loss = 0.8732  \n",
      "\n",
      "Fold: 7  Epoch: 563  Training loss = 1.6243  Validation loss = 0.8734  \n",
      "\n",
      "Fold: 7  Epoch: 564  Training loss = 1.6241  Validation loss = 0.8732  \n",
      "\n",
      "Fold: 7  Epoch: 565  Training loss = 1.6241  Validation loss = 0.8737  \n",
      "\n",
      "Fold: 7  Epoch: 566  Training loss = 1.6240  Validation loss = 0.8735  \n",
      "\n",
      "Fold: 7  Epoch: 567  Training loss = 1.6238  Validation loss = 0.8731  \n",
      "\n",
      "Fold: 7  Epoch: 568  Training loss = 1.6237  Validation loss = 0.8732  \n",
      "\n",
      "Fold: 7  Epoch: 569  Training loss = 1.6236  Validation loss = 0.8733  \n",
      "\n",
      "Fold: 7  Epoch: 570  Training loss = 1.6234  Validation loss = 0.8727  \n",
      "\n",
      "Fold: 7  Epoch: 571  Training loss = 1.6233  Validation loss = 0.8729  \n",
      "\n",
      "Fold: 7  Epoch: 572  Training loss = 1.6230  Validation loss = 0.8722  \n",
      "\n",
      "Fold: 7  Epoch: 573  Training loss = 1.6230  Validation loss = 0.8726  \n",
      "\n",
      "Fold: 7  Epoch: 574  Training loss = 1.6228  Validation loss = 0.8722  \n",
      "\n",
      "Fold: 7  Epoch: 575  Training loss = 1.6227  Validation loss = 0.8725  \n",
      "\n",
      "Fold: 7  Epoch: 576  Training loss = 1.6226  Validation loss = 0.8723  \n",
      "\n",
      "Fold: 7  Epoch: 577  Training loss = 1.6225  Validation loss = 0.8723  \n",
      "\n",
      "Fold: 7  Epoch: 578  Training loss = 1.6223  Validation loss = 0.8719  \n",
      "\n",
      "Fold: 7  Epoch: 579  Training loss = 1.6222  Validation loss = 0.8718  \n",
      "\n",
      "Fold: 7  Epoch: 580  Training loss = 1.6220  Validation loss = 0.8714  \n",
      "\n",
      "Fold: 7  Epoch: 581  Training loss = 1.6219  Validation loss = 0.8714  \n",
      "\n",
      "Fold: 7  Epoch: 582  Training loss = 1.6217  Validation loss = 0.8712  \n",
      "\n",
      "Fold: 7  Epoch: 583  Training loss = 1.6216  Validation loss = 0.8708  \n",
      "\n",
      "Fold: 7  Epoch: 584  Training loss = 1.6214  Validation loss = 0.8707  \n",
      "\n",
      "Fold: 7  Epoch: 585  Training loss = 1.6213  Validation loss = 0.8705  \n",
      "\n",
      "Fold: 7  Epoch: 586  Training loss = 1.6211  Validation loss = 0.8701  \n",
      "\n",
      "Fold: 7  Epoch: 587  Training loss = 1.6210  Validation loss = 0.8699  \n",
      "\n",
      "Fold: 7  Epoch: 588  Training loss = 1.6209  Validation loss = 0.8700  \n",
      "\n",
      "Fold: 7  Epoch: 589  Training loss = 1.6207  Validation loss = 0.8697  \n",
      "\n",
      "Fold: 7  Epoch: 590  Training loss = 1.6206  Validation loss = 0.8695  \n",
      "\n",
      "Fold: 7  Epoch: 591  Training loss = 1.6205  Validation loss = 0.8695  \n",
      "\n",
      "Fold: 7  Epoch: 592  Training loss = 1.6203  Validation loss = 0.8692  \n",
      "\n",
      "Fold: 7  Epoch: 593  Training loss = 1.6202  Validation loss = 0.8693  \n",
      "\n",
      "Fold: 7  Epoch: 594  Training loss = 1.6201  Validation loss = 0.8694  \n",
      "\n",
      "Fold: 7  Epoch: 595  Training loss = 1.6200  Validation loss = 0.8692  \n",
      "\n",
      "Fold: 7  Epoch: 596  Training loss = 1.6199  Validation loss = 0.8691  \n",
      "\n",
      "Fold: 7  Epoch: 597  Training loss = 1.6197  Validation loss = 0.8689  \n",
      "\n",
      "Fold: 7  Epoch: 598  Training loss = 1.6196  Validation loss = 0.8685  \n",
      "\n",
      "Fold: 7  Epoch: 599  Training loss = 1.6194  Validation loss = 0.8682  \n",
      "\n",
      "Fold: 7  Epoch: 600  Training loss = 1.6192  Validation loss = 0.8675  \n",
      "\n",
      "Fold: 7  Epoch: 601  Training loss = 1.6191  Validation loss = 0.8673  \n",
      "\n",
      "Fold: 7  Epoch: 602  Training loss = 1.6189  Validation loss = 0.8671  \n",
      "\n",
      "Fold: 7  Epoch: 603  Training loss = 1.6188  Validation loss = 0.8672  \n",
      "\n",
      "Fold: 7  Epoch: 604  Training loss = 1.6187  Validation loss = 0.8673  \n",
      "\n",
      "Fold: 7  Epoch: 605  Training loss = 1.6186  Validation loss = 0.8671  \n",
      "\n",
      "Fold: 7  Epoch: 606  Training loss = 1.6184  Validation loss = 0.8672  \n",
      "\n",
      "Fold: 7  Epoch: 607  Training loss = 1.6183  Validation loss = 0.8672  \n",
      "\n",
      "Fold: 7  Epoch: 608  Training loss = 1.6182  Validation loss = 0.8674  \n",
      "\n",
      "Fold: 7  Epoch: 609  Training loss = 1.6181  Validation loss = 0.8671  \n",
      "\n",
      "Fold: 7  Epoch: 610  Training loss = 1.6180  Validation loss = 0.8670  \n",
      "\n",
      "Fold: 7  Epoch: 611  Training loss = 1.6179  Validation loss = 0.8670  \n",
      "\n",
      "Fold: 7  Epoch: 612  Training loss = 1.6178  Validation loss = 0.8670  \n",
      "\n",
      "Fold: 7  Epoch: 613  Training loss = 1.6177  Validation loss = 0.8671  \n",
      "\n",
      "Fold: 7  Epoch: 614  Training loss = 1.6176  Validation loss = 0.8675  \n",
      "\n",
      "Fold: 7  Epoch: 615  Training loss = 1.6175  Validation loss = 0.8672  \n",
      "\n",
      "Fold: 7  Epoch: 616  Training loss = 1.6173  Validation loss = 0.8668  \n",
      "\n",
      "Fold: 7  Epoch: 617  Training loss = 1.6172  Validation loss = 0.8669  \n",
      "\n",
      "Fold: 7  Epoch: 618  Training loss = 1.6171  Validation loss = 0.8669  \n",
      "\n",
      "Fold: 7  Epoch: 619  Training loss = 1.6170  Validation loss = 0.8670  \n",
      "\n",
      "Fold: 7  Epoch: 620  Training loss = 1.6169  Validation loss = 0.8669  \n",
      "\n",
      "Fold: 7  Epoch: 621  Training loss = 1.6167  Validation loss = 0.8667  \n",
      "\n",
      "Fold: 7  Epoch: 622  Training loss = 1.6166  Validation loss = 0.8669  \n",
      "\n",
      "Fold: 7  Epoch: 623  Training loss = 1.6165  Validation loss = 0.8668  \n",
      "\n",
      "Fold: 7  Epoch: 624  Training loss = 1.6163  Validation loss = 0.8670  \n",
      "\n",
      "Fold: 7  Epoch: 625  Training loss = 1.6162  Validation loss = 0.8667  \n",
      "\n",
      "Fold: 7  Epoch: 626  Training loss = 1.6160  Validation loss = 0.8668  \n",
      "\n",
      "Fold: 7  Epoch: 627  Training loss = 1.6159  Validation loss = 0.8666  \n",
      "\n",
      "Fold: 7  Epoch: 628  Training loss = 1.6158  Validation loss = 0.8665  \n",
      "\n",
      "Fold: 7  Epoch: 629  Training loss = 1.6157  Validation loss = 0.8668  \n",
      "\n",
      "Fold: 7  Epoch: 630  Training loss = 1.6156  Validation loss = 0.8670  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 628  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.5756  Validation loss = 5.8987  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.5755  Validation loss = 5.8983  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.5754  Validation loss = 5.8980  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.5752  Validation loss = 5.8972  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.5751  Validation loss = 5.8968  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.5749  Validation loss = 5.8963  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.5748  Validation loss = 5.8960  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.5745  Validation loss = 5.8952  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.5744  Validation loss = 5.8951  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.5743  Validation loss = 5.8950  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.5741  Validation loss = 5.8945  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.5739  Validation loss = 5.8936  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.5737  Validation loss = 5.8929  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.5735  Validation loss = 5.8925  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.5733  Validation loss = 5.8918  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.5731  Validation loss = 5.8911  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.5729  Validation loss = 5.8902  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.5728  Validation loss = 5.8901  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.5727  Validation loss = 5.8899  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 1.5725  Validation loss = 5.8896  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 1.5724  Validation loss = 5.8890  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 1.5723  Validation loss = 5.8892  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 1.5722  Validation loss = 5.8888  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 1.5719  Validation loss = 5.8880  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 1.5718  Validation loss = 5.8877  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 1.5716  Validation loss = 5.8871  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 1.5715  Validation loss = 5.8870  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 1.5714  Validation loss = 5.8863  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 1.5712  Validation loss = 5.8861  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 1.5711  Validation loss = 5.8861  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 1.5710  Validation loss = 5.8858  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 1.5709  Validation loss = 5.8856  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 1.5707  Validation loss = 5.8849  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 1.5705  Validation loss = 5.8842  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 1.5704  Validation loss = 5.8840  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 1.5703  Validation loss = 5.8840  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 1.5702  Validation loss = 5.8836  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 1.5699  Validation loss = 5.8831  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 1.5698  Validation loss = 5.8825  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 1.5696  Validation loss = 5.8821  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 1.5695  Validation loss = 5.8819  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 1.5693  Validation loss = 5.8815  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 1.5692  Validation loss = 5.8813  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 1.5692  Validation loss = 5.8813  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 1.5690  Validation loss = 5.8810  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 1.5689  Validation loss = 5.8806  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 1.5688  Validation loss = 5.8809  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 1.5687  Validation loss = 5.8806  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 1.5684  Validation loss = 5.8795  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 1.5682  Validation loss = 5.8790  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 1.5681  Validation loss = 5.8786  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 1.5679  Validation loss = 5.8785  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 1.5678  Validation loss = 5.8783  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 1.5677  Validation loss = 5.8781  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 1.5676  Validation loss = 5.8778  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 1.5675  Validation loss = 5.8777  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 1.5674  Validation loss = 5.8777  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 1.5673  Validation loss = 5.8776  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 1.5672  Validation loss = 5.8772  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 1.5670  Validation loss = 5.8767  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 1.5669  Validation loss = 5.8767  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 1.5667  Validation loss = 5.8763  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 1.5666  Validation loss = 5.8758  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 1.5664  Validation loss = 5.8759  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 1.5663  Validation loss = 5.8754  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 1.5663  Validation loss = 5.8757  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 1.5661  Validation loss = 5.8756  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 1.5659  Validation loss = 5.8751  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 1.5658  Validation loss = 5.8748  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 1.5657  Validation loss = 5.8743  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 1.5655  Validation loss = 5.8739  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 1.5654  Validation loss = 5.8734  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 1.5652  Validation loss = 5.8726  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 1.5650  Validation loss = 5.8718  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 1.5649  Validation loss = 5.8718  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 1.5647  Validation loss = 5.8711  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 1.5645  Validation loss = 5.8704  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 1.5643  Validation loss = 5.8701  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 1.5642  Validation loss = 5.8699  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 1.5640  Validation loss = 5.8695  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 1.5639  Validation loss = 5.8696  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 1.5637  Validation loss = 5.8687  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 1.5635  Validation loss = 5.8685  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 1.5634  Validation loss = 5.8681  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 1.5633  Validation loss = 5.8678  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 1.5631  Validation loss = 5.8670  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 1.5630  Validation loss = 5.8670  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 1.5629  Validation loss = 5.8668  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 1.5628  Validation loss = 5.8669  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 1.5628  Validation loss = 5.8671  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 1.5626  Validation loss = 5.8665  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 1.5625  Validation loss = 5.8665  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 1.5624  Validation loss = 5.8661  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 1.5622  Validation loss = 5.8657  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 1.5620  Validation loss = 5.8649  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 1.5619  Validation loss = 5.8644  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 1.5617  Validation loss = 5.8639  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 1.5615  Validation loss = 5.8630  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 1.5614  Validation loss = 5.8628  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 1.5612  Validation loss = 5.8622  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 1.5611  Validation loss = 5.8621  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 1.5611  Validation loss = 5.8625  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 1.5610  Validation loss = 5.8625  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 1.5609  Validation loss = 5.8621  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 1.5608  Validation loss = 5.8618  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 1.5606  Validation loss = 5.8613  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 1.5604  Validation loss = 5.8608  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 1.5603  Validation loss = 5.8604  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 1.5601  Validation loss = 5.8603  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 1.5600  Validation loss = 5.8599  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 1.5599  Validation loss = 5.8598  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 1.5598  Validation loss = 5.8599  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 1.5597  Validation loss = 5.8598  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 1.5596  Validation loss = 5.8602  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 1.5594  Validation loss = 5.8593  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 1.5593  Validation loss = 5.8592  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 1.5592  Validation loss = 5.8593  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 1.5590  Validation loss = 5.8584  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 1.5589  Validation loss = 5.8582  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 1.5588  Validation loss = 5.8581  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 1.5587  Validation loss = 5.8581  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 1.5586  Validation loss = 5.8577  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 1.5585  Validation loss = 5.8573  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 1.5584  Validation loss = 5.8571  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 1.5583  Validation loss = 5.8569  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 1.5581  Validation loss = 5.8562  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 1.5579  Validation loss = 5.8557  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 1.5578  Validation loss = 5.8553  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 1.5577  Validation loss = 5.8553  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 1.5575  Validation loss = 5.8546  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 1.5573  Validation loss = 5.8541  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 1.5573  Validation loss = 5.8542  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 1.5571  Validation loss = 5.8538  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 1.5570  Validation loss = 5.8540  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 1.5568  Validation loss = 5.8530  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 1.5567  Validation loss = 5.8528  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 1.5566  Validation loss = 5.8529  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 1.5564  Validation loss = 5.8524  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 1.5563  Validation loss = 5.8519  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 1.5561  Validation loss = 5.8512  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 1.5560  Validation loss = 5.8513  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 1.5558  Validation loss = 5.8505  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 1.5557  Validation loss = 5.8504  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 1.5555  Validation loss = 5.8498  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 1.5554  Validation loss = 5.8493  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 1.5552  Validation loss = 5.8490  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 1.5551  Validation loss = 5.8486  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 1.5549  Validation loss = 5.8478  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 1.5548  Validation loss = 5.8481  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 1.5547  Validation loss = 5.8475  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 1.5545  Validation loss = 5.8473  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 1.5545  Validation loss = 5.8471  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 1.5543  Validation loss = 5.8463  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 1.5542  Validation loss = 5.8463  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 1.5540  Validation loss = 5.8456  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 1.5538  Validation loss = 5.8450  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 1.5537  Validation loss = 5.8448  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 1.5535  Validation loss = 5.8443  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 1.5534  Validation loss = 5.8439  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 1.5533  Validation loss = 5.8435  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 1.5532  Validation loss = 5.8438  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 1.5531  Validation loss = 5.8436  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 1.5529  Validation loss = 5.8429  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 1.5527  Validation loss = 5.8422  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 1.5525  Validation loss = 5.8418  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 1.5524  Validation loss = 5.8413  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 1.5522  Validation loss = 5.8412  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 1.5521  Validation loss = 5.8406  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 1.5519  Validation loss = 5.8405  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 1.5519  Validation loss = 5.8405  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 1.5518  Validation loss = 5.8404  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 1.5516  Validation loss = 5.8400  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 1.5514  Validation loss = 5.8394  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 1.5512  Validation loss = 5.8391  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 1.5511  Validation loss = 5.8391  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 1.5510  Validation loss = 5.8392  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 1.5509  Validation loss = 5.8388  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 1.5507  Validation loss = 5.8384  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 1.5506  Validation loss = 5.8384  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 1.5505  Validation loss = 5.8382  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 1.5504  Validation loss = 5.8385  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 1.5502  Validation loss = 5.8384  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 1.5501  Validation loss = 5.8380  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 1.5500  Validation loss = 5.8380  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 1.5499  Validation loss = 5.8377  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 1.5497  Validation loss = 5.8372  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 1.5495  Validation loss = 5.8363  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 1.5493  Validation loss = 5.8357  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 1.5491  Validation loss = 5.8348  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 1.5490  Validation loss = 5.8350  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 1.5490  Validation loss = 5.8353  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 1.5488  Validation loss = 5.8348  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 1.5487  Validation loss = 5.8343  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 1.5485  Validation loss = 5.8342  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 1.5484  Validation loss = 5.8340  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 1.5483  Validation loss = 5.8338  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 1.5481  Validation loss = 5.8331  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 1.5480  Validation loss = 5.8329  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 1.5479  Validation loss = 5.8330  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 1.5478  Validation loss = 5.8327  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 1.5477  Validation loss = 5.8331  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 1.5476  Validation loss = 5.8327  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 1.5474  Validation loss = 5.8321  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 1.5472  Validation loss = 5.8312  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 1.5471  Validation loss = 5.8309  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 1.5470  Validation loss = 5.8306  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 1.5468  Validation loss = 5.8306  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 1.5467  Validation loss = 5.8303  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 1.5466  Validation loss = 5.8301  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 1.5465  Validation loss = 5.8298  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 1.5463  Validation loss = 5.8292  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 1.5461  Validation loss = 5.8290  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 1.5460  Validation loss = 5.8287  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 1.5458  Validation loss = 5.8278  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 1.5457  Validation loss = 5.8276  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 1.5455  Validation loss = 5.8271  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 1.5454  Validation loss = 5.8268  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 1.5452  Validation loss = 5.8264  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 1.5451  Validation loss = 5.8261  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 1.5450  Validation loss = 5.8262  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 1.5448  Validation loss = 5.8256  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 1.5447  Validation loss = 5.8253  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 1.5445  Validation loss = 5.8250  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 1.5444  Validation loss = 5.8251  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 1.5442  Validation loss = 5.8247  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 1.5441  Validation loss = 5.8245  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 1.5439  Validation loss = 5.8239  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 1.5437  Validation loss = 5.8236  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 1.5436  Validation loss = 5.8229  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 1.5435  Validation loss = 5.8229  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 1.5433  Validation loss = 5.8225  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 1.5432  Validation loss = 5.8223  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 1.5431  Validation loss = 5.8224  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 1.5430  Validation loss = 5.8225  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 1.5428  Validation loss = 5.8220  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 1.5427  Validation loss = 5.8214  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 1.5425  Validation loss = 5.8208  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 1.5424  Validation loss = 5.8206  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 1.5422  Validation loss = 5.8204  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 1.5421  Validation loss = 5.8200  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 1.5420  Validation loss = 5.8198  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 1.5419  Validation loss = 5.8197  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 1.5418  Validation loss = 5.8196  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 1.5416  Validation loss = 5.8192  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 1.5415  Validation loss = 5.8193  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 1.5414  Validation loss = 5.8194  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 1.5412  Validation loss = 5.8190  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 1.5411  Validation loss = 5.8191  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 1.5410  Validation loss = 5.8185  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 1.5409  Validation loss = 5.8181  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 1.5407  Validation loss = 5.8179  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 1.5406  Validation loss = 5.8180  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 1.5405  Validation loss = 5.8175  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 1.5403  Validation loss = 5.8167  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 1.5402  Validation loss = 5.8169  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 1.5401  Validation loss = 5.8166  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 1.5399  Validation loss = 5.8155  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 1.5398  Validation loss = 5.8156  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 1.5396  Validation loss = 5.8151  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 1.5395  Validation loss = 5.8144  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 1.5394  Validation loss = 5.8146  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 1.5392  Validation loss = 5.8141  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 1.5391  Validation loss = 5.8140  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 1.5390  Validation loss = 5.8139  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 1.5389  Validation loss = 5.8138  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 1.5388  Validation loss = 5.8132  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 1.5386  Validation loss = 5.8125  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 1.5385  Validation loss = 5.8125  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 1.5384  Validation loss = 5.8120  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 1.5383  Validation loss = 5.8122  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 1.5382  Validation loss = 5.8120  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 1.5381  Validation loss = 5.8117  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 1.5379  Validation loss = 5.8115  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 1.5378  Validation loss = 5.8116  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 1.5377  Validation loss = 5.8116  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 1.5376  Validation loss = 5.8113  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 1.5375  Validation loss = 5.8113  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 1.5375  Validation loss = 5.8113  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 1.5373  Validation loss = 5.8112  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 1.5372  Validation loss = 5.8109  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 1.5371  Validation loss = 5.8101  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 1.5368  Validation loss = 5.8089  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 1.5367  Validation loss = 5.8087  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 1.5365  Validation loss = 5.8086  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 1.5364  Validation loss = 5.8085  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 1.5363  Validation loss = 5.8080  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 1.5361  Validation loss = 5.8080  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 1.5360  Validation loss = 5.8075  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 1.5358  Validation loss = 5.8064  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 1.5357  Validation loss = 5.8065  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 1.5356  Validation loss = 5.8065  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 1.5354  Validation loss = 5.8058  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 1.5353  Validation loss = 5.8054  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 1.5351  Validation loss = 5.8047  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 1.5349  Validation loss = 5.8044  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 1.5347  Validation loss = 5.8039  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 1.5346  Validation loss = 5.8040  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 1.5344  Validation loss = 5.8033  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 1.5343  Validation loss = 5.8026  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 1.5342  Validation loss = 5.8020  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 1.5340  Validation loss = 5.8022  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 1.5338  Validation loss = 5.8015  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 1.5337  Validation loss = 5.8019  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 1.5337  Validation loss = 5.8020  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 1.5336  Validation loss = 5.8020  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 1.5334  Validation loss = 5.8017  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 1.5332  Validation loss = 5.8010  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 1.5331  Validation loss = 5.8009  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 1.5329  Validation loss = 5.8006  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 1.5328  Validation loss = 5.8002  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 1.5327  Validation loss = 5.7998  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 1.5326  Validation loss = 5.7996  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 1.5324  Validation loss = 5.7990  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 1.5323  Validation loss = 5.7990  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 1.5323  Validation loss = 5.7991  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 1.5321  Validation loss = 5.7985  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 1.5319  Validation loss = 5.7985  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 1.5319  Validation loss = 5.7989  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 1.5318  Validation loss = 5.7987  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 1.5316  Validation loss = 5.7985  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 1.5315  Validation loss = 5.7979  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 1.5313  Validation loss = 5.7975  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 1.5311  Validation loss = 5.7969  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 1.5310  Validation loss = 5.7968  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 1.5309  Validation loss = 5.7962  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 1.5307  Validation loss = 5.7959  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 1.5306  Validation loss = 5.7957  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 1.5305  Validation loss = 5.7954  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 1.5304  Validation loss = 5.7953  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 1.5303  Validation loss = 5.7954  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 1.5302  Validation loss = 5.7954  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 1.5301  Validation loss = 5.7951  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 1.5299  Validation loss = 5.7945  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 1.5297  Validation loss = 5.7940  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 1.5295  Validation loss = 5.7934  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 1.5293  Validation loss = 5.7927  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 1.5292  Validation loss = 5.7924  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 1.5291  Validation loss = 5.7926  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 1.5290  Validation loss = 5.7925  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 1.5289  Validation loss = 5.7922  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 1.5287  Validation loss = 5.7918  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 1.5287  Validation loss = 5.7917  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 1.5285  Validation loss = 5.7911  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 1.5284  Validation loss = 5.7911  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 1.5283  Validation loss = 5.7910  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 1.5281  Validation loss = 5.7909  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 1.5280  Validation loss = 5.7907  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 1.5278  Validation loss = 5.7907  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 1.5277  Validation loss = 5.7903  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 1.5277  Validation loss = 5.7908  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 1.5276  Validation loss = 5.7906  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 1.5274  Validation loss = 5.7905  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 1.5273  Validation loss = 5.7900  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 1.5272  Validation loss = 5.7897  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 1.5271  Validation loss = 5.7898  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 1.5270  Validation loss = 5.7893  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 1.5268  Validation loss = 5.7889  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 1.5267  Validation loss = 5.7888  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 1.5265  Validation loss = 5.7880  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 1.5263  Validation loss = 5.7872  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 1.5262  Validation loss = 5.7867  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 1.5260  Validation loss = 5.7863  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 1.5258  Validation loss = 5.7853  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 1.5257  Validation loss = 5.7850  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 1.5255  Validation loss = 5.7846  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 1.5254  Validation loss = 5.7839  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 1.5252  Validation loss = 5.7833  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 1.5251  Validation loss = 5.7830  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 1.5250  Validation loss = 5.7830  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 1.5249  Validation loss = 5.7828  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 1.5247  Validation loss = 5.7823  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 1.5247  Validation loss = 5.7824  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 1.5245  Validation loss = 5.7818  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 1.5244  Validation loss = 5.7815  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 1.5243  Validation loss = 5.7810  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 1.5241  Validation loss = 5.7808  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 1.5240  Validation loss = 5.7808  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 1.5239  Validation loss = 5.7803  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 1.5237  Validation loss = 5.7797  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 1.5236  Validation loss = 5.7793  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 1.5234  Validation loss = 5.7790  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 1.5232  Validation loss = 5.7787  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 1.5231  Validation loss = 5.7784  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 1.5230  Validation loss = 5.7779  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 1.5228  Validation loss = 5.7774  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 1.5227  Validation loss = 5.7772  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 1.5225  Validation loss = 5.7763  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 1.5223  Validation loss = 5.7756  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 1.5221  Validation loss = 5.7747  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 1.5220  Validation loss = 5.7748  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 1.5219  Validation loss = 5.7744  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 1.5217  Validation loss = 5.7740  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 1.5216  Validation loss = 5.7735  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 1.5215  Validation loss = 5.7734  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 1.5214  Validation loss = 5.7732  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 1.5212  Validation loss = 5.7728  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 1.5211  Validation loss = 5.7723  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 1.5210  Validation loss = 5.7720  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 1.5209  Validation loss = 5.7722  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 1.5208  Validation loss = 5.7721  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 1.5207  Validation loss = 5.7718  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 1.5206  Validation loss = 5.7720  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 1.5205  Validation loss = 5.7721  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 1.5203  Validation loss = 5.7715  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 1.5203  Validation loss = 5.7714  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 1.5201  Validation loss = 5.7709  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 1.5200  Validation loss = 5.7711  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 1.5199  Validation loss = 5.7710  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 1.5198  Validation loss = 5.7704  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 1.5196  Validation loss = 5.7697  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 1.5195  Validation loss = 5.7694  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 1.5193  Validation loss = 5.7684  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 1.5191  Validation loss = 5.7680  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 1.5190  Validation loss = 5.7677  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 1.5189  Validation loss = 5.7679  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 1.5187  Validation loss = 5.7673  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 1.5186  Validation loss = 5.7672  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 1.5185  Validation loss = 5.7677  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 1.5184  Validation loss = 5.7670  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 1.5182  Validation loss = 5.7662  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 1.5180  Validation loss = 5.7656  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 1.5179  Validation loss = 5.7656  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 1.5178  Validation loss = 5.7655  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 1.5176  Validation loss = 5.7651  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 1.5176  Validation loss = 5.7653  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 1.5175  Validation loss = 5.7654  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 1.5174  Validation loss = 5.7651  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 1.5172  Validation loss = 5.7650  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 1.5171  Validation loss = 5.7648  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 1.5170  Validation loss = 5.7645  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 1.5169  Validation loss = 5.7646  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 1.5167  Validation loss = 5.7638  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 1.5165  Validation loss = 5.7632  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 1.5164  Validation loss = 5.7632  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 1.5162  Validation loss = 5.7628  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 1.5161  Validation loss = 5.7626  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 1.5160  Validation loss = 5.7622  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 1.5159  Validation loss = 5.7620  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 1.5158  Validation loss = 5.7625  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 1.5157  Validation loss = 5.7622  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 1.5155  Validation loss = 5.7621  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 1.5154  Validation loss = 5.7624  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 1.5153  Validation loss = 5.7620  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 1.5152  Validation loss = 5.7617  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 1.5150  Validation loss = 5.7609  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 1.5148  Validation loss = 5.7604  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 1.5146  Validation loss = 5.7599  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 1.5145  Validation loss = 5.7597  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 1.5144  Validation loss = 5.7597  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 1.5143  Validation loss = 5.7591  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 1.5142  Validation loss = 5.7595  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 1.5140  Validation loss = 5.7594  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 1.5139  Validation loss = 5.7593  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 1.5138  Validation loss = 5.7588  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 1.5136  Validation loss = 5.7581  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 1.5135  Validation loss = 5.7576  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 1.5134  Validation loss = 5.7579  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 1.5133  Validation loss = 5.7575  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 1.5132  Validation loss = 5.7576  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 1.5132  Validation loss = 5.7581  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 1.5131  Validation loss = 5.7581  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 1.5129  Validation loss = 5.7578  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 1.5128  Validation loss = 5.7574  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 1.5126  Validation loss = 5.7575  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 1.5126  Validation loss = 5.7579  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 1.5124  Validation loss = 5.7579  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 1.5123  Validation loss = 5.7578  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 1.5123  Validation loss = 5.7582  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 1.5121  Validation loss = 5.7581  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 1.5120  Validation loss = 5.7579  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 1.5118  Validation loss = 5.7576  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 1.5117  Validation loss = 5.7572  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 1.5116  Validation loss = 5.7570  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 1.5115  Validation loss = 5.7569  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 1.5113  Validation loss = 5.7565  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 1.5112  Validation loss = 5.7561  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 1.5111  Validation loss = 5.7559  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 1.5110  Validation loss = 5.7552  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 1.5107  Validation loss = 5.7543  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 1.5106  Validation loss = 5.7541  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 1.5104  Validation loss = 5.7534  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 1.5104  Validation loss = 5.7538  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 1.5103  Validation loss = 5.7536  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 1.5102  Validation loss = 5.7530  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 1.5100  Validation loss = 5.7525  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 1.5099  Validation loss = 5.7522  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 1.5097  Validation loss = 5.7511  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 1.5095  Validation loss = 5.7506  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 1.5095  Validation loss = 5.7510  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 1.5094  Validation loss = 5.7509  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 1.5092  Validation loss = 5.7501  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 1.5090  Validation loss = 5.7496  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 1.5089  Validation loss = 5.7493  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 1.5088  Validation loss = 5.7495  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 1.5087  Validation loss = 5.7485  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 1.5086  Validation loss = 5.7487  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 1.5085  Validation loss = 5.7489  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 1.5083  Validation loss = 5.7487  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 1.5082  Validation loss = 5.7485  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 1.5080  Validation loss = 5.7478  \n",
      "\n",
      "Fold: 8  Epoch: 501  Training loss = 1.5079  Validation loss = 5.7478  \n",
      "\n",
      "Fold: 8  Epoch: 502  Training loss = 1.5078  Validation loss = 5.7473  \n",
      "\n",
      "Fold: 8  Epoch: 503  Training loss = 1.5077  Validation loss = 5.7476  \n",
      "\n",
      "Fold: 8  Epoch: 504  Training loss = 1.5075  Validation loss = 5.7470  \n",
      "\n",
      "Fold: 8  Epoch: 505  Training loss = 1.5073  Validation loss = 5.7466  \n",
      "\n",
      "Fold: 8  Epoch: 506  Training loss = 1.5072  Validation loss = 5.7463  \n",
      "\n",
      "Fold: 8  Epoch: 507  Training loss = 1.5071  Validation loss = 5.7462  \n",
      "\n",
      "Fold: 8  Epoch: 508  Training loss = 1.5070  Validation loss = 5.7463  \n",
      "\n",
      "Fold: 8  Epoch: 509  Training loss = 1.5069  Validation loss = 5.7461  \n",
      "\n",
      "Fold: 8  Epoch: 510  Training loss = 1.5068  Validation loss = 5.7468  \n",
      "\n",
      "Fold: 8  Epoch: 511  Training loss = 1.5067  Validation loss = 5.7469  \n",
      "\n",
      "Fold: 8  Epoch: 512  Training loss = 1.5066  Validation loss = 5.7469  \n",
      "\n",
      "Fold: 8  Epoch: 513  Training loss = 1.5065  Validation loss = 5.7464  \n",
      "\n",
      "Fold: 8  Epoch: 514  Training loss = 1.5064  Validation loss = 5.7463  \n",
      "\n",
      "Fold: 8  Epoch: 515  Training loss = 1.5063  Validation loss = 5.7461  \n",
      "\n",
      "Fold: 8  Epoch: 516  Training loss = 1.5061  Validation loss = 5.7453  \n",
      "\n",
      "Fold: 8  Epoch: 517  Training loss = 1.5060  Validation loss = 5.7450  \n",
      "\n",
      "Fold: 8  Epoch: 518  Training loss = 1.5059  Validation loss = 5.7454  \n",
      "\n",
      "Fold: 8  Epoch: 519  Training loss = 1.5058  Validation loss = 5.7459  \n",
      "\n",
      "Fold: 8  Epoch: 520  Training loss = 1.5057  Validation loss = 5.7457  \n",
      "\n",
      "Fold: 8  Epoch: 521  Training loss = 1.5056  Validation loss = 5.7456  \n",
      "\n",
      "Fold: 8  Epoch: 522  Training loss = 1.5055  Validation loss = 5.7452  \n",
      "\n",
      "Fold: 8  Epoch: 523  Training loss = 1.5054  Validation loss = 5.7451  \n",
      "\n",
      "Fold: 8  Epoch: 524  Training loss = 1.5052  Validation loss = 5.7445  \n",
      "\n",
      "Fold: 8  Epoch: 525  Training loss = 1.5050  Validation loss = 5.7440  \n",
      "\n",
      "Fold: 8  Epoch: 526  Training loss = 1.5049  Validation loss = 5.7435  \n",
      "\n",
      "Fold: 8  Epoch: 527  Training loss = 1.5048  Validation loss = 5.7437  \n",
      "\n",
      "Fold: 8  Epoch: 528  Training loss = 1.5046  Validation loss = 5.7435  \n",
      "\n",
      "Fold: 8  Epoch: 529  Training loss = 1.5045  Validation loss = 5.7430  \n",
      "\n",
      "Fold: 8  Epoch: 530  Training loss = 1.5044  Validation loss = 5.7425  \n",
      "\n",
      "Fold: 8  Epoch: 531  Training loss = 1.5043  Validation loss = 5.7421  \n",
      "\n",
      "Fold: 8  Epoch: 532  Training loss = 1.5042  Validation loss = 5.7421  \n",
      "\n",
      "Fold: 8  Epoch: 533  Training loss = 1.5040  Validation loss = 5.7419  \n",
      "\n",
      "Fold: 8  Epoch: 534  Training loss = 1.5039  Validation loss = 5.7414  \n",
      "\n",
      "Fold: 8  Epoch: 535  Training loss = 1.5038  Validation loss = 5.7418  \n",
      "\n",
      "Fold: 8  Epoch: 536  Training loss = 1.5037  Validation loss = 5.7421  \n",
      "\n",
      "Fold: 8  Epoch: 537  Training loss = 1.5036  Validation loss = 5.7415  \n",
      "\n",
      "Fold: 8  Epoch: 538  Training loss = 1.5034  Validation loss = 5.7409  \n",
      "\n",
      "Fold: 8  Epoch: 539  Training loss = 1.5033  Validation loss = 5.7406  \n",
      "\n",
      "Fold: 8  Epoch: 540  Training loss = 1.5031  Validation loss = 5.7402  \n",
      "\n",
      "Fold: 8  Epoch: 541  Training loss = 1.5030  Validation loss = 5.7403  \n",
      "\n",
      "Fold: 8  Epoch: 542  Training loss = 1.5029  Validation loss = 5.7397  \n",
      "\n",
      "Fold: 8  Epoch: 543  Training loss = 1.5028  Validation loss = 5.7400  \n",
      "\n",
      "Fold: 8  Epoch: 544  Training loss = 1.5027  Validation loss = 5.7398  \n",
      "\n",
      "Fold: 8  Epoch: 545  Training loss = 1.5025  Validation loss = 5.7392  \n",
      "\n",
      "Fold: 8  Epoch: 546  Training loss = 1.5024  Validation loss = 5.7391  \n",
      "\n",
      "Fold: 8  Epoch: 547  Training loss = 1.5023  Validation loss = 5.7391  \n",
      "\n",
      "Fold: 8  Epoch: 548  Training loss = 1.5021  Validation loss = 5.7386  \n",
      "\n",
      "Fold: 8  Epoch: 549  Training loss = 1.5020  Validation loss = 5.7390  \n",
      "\n",
      "Fold: 8  Epoch: 550  Training loss = 1.5019  Validation loss = 5.7386  \n",
      "\n",
      "Fold: 8  Epoch: 551  Training loss = 1.5018  Validation loss = 5.7377  \n",
      "\n",
      "Fold: 8  Epoch: 552  Training loss = 1.5016  Validation loss = 5.7376  \n",
      "\n",
      "Fold: 8  Epoch: 553  Training loss = 1.5015  Validation loss = 5.7371  \n",
      "\n",
      "Fold: 8  Epoch: 554  Training loss = 1.5013  Validation loss = 5.7368  \n",
      "\n",
      "Fold: 8  Epoch: 555  Training loss = 1.5012  Validation loss = 5.7365  \n",
      "\n",
      "Fold: 8  Epoch: 556  Training loss = 1.5010  Validation loss = 5.7361  \n",
      "\n",
      "Fold: 8  Epoch: 557  Training loss = 1.5009  Validation loss = 5.7361  \n",
      "\n",
      "Fold: 8  Epoch: 558  Training loss = 1.5008  Validation loss = 5.7361  \n",
      "\n",
      "Fold: 8  Epoch: 559  Training loss = 1.5007  Validation loss = 5.7357  \n",
      "\n",
      "Fold: 8  Epoch: 560  Training loss = 1.5006  Validation loss = 5.7357  \n",
      "\n",
      "Fold: 8  Epoch: 561  Training loss = 1.5004  Validation loss = 5.7353  \n",
      "\n",
      "Fold: 8  Epoch: 562  Training loss = 1.5003  Validation loss = 5.7350  \n",
      "\n",
      "Fold: 8  Epoch: 563  Training loss = 1.5002  Validation loss = 5.7344  \n",
      "\n",
      "Fold: 8  Epoch: 564  Training loss = 1.5000  Validation loss = 5.7333  \n",
      "\n",
      "Fold: 8  Epoch: 565  Training loss = 1.4999  Validation loss = 5.7337  \n",
      "\n",
      "Fold: 8  Epoch: 566  Training loss = 1.4997  Validation loss = 5.7329  \n",
      "\n",
      "Fold: 8  Epoch: 567  Training loss = 1.4996  Validation loss = 5.7334  \n",
      "\n",
      "Fold: 8  Epoch: 568  Training loss = 1.4994  Validation loss = 5.7328  \n",
      "\n",
      "Fold: 8  Epoch: 569  Training loss = 1.4993  Validation loss = 5.7328  \n",
      "\n",
      "Fold: 8  Epoch: 570  Training loss = 1.4993  Validation loss = 5.7328  \n",
      "\n",
      "Fold: 8  Epoch: 571  Training loss = 1.4992  Validation loss = 5.7328  \n",
      "\n",
      "Fold: 8  Epoch: 572  Training loss = 1.4991  Validation loss = 5.7333  \n",
      "\n",
      "Fold: 8  Epoch: 573  Training loss = 1.4989  Validation loss = 5.7326  \n",
      "\n",
      "Fold: 8  Epoch: 574  Training loss = 1.4988  Validation loss = 5.7319  \n",
      "\n",
      "Fold: 8  Epoch: 575  Training loss = 1.4986  Validation loss = 5.7318  \n",
      "\n",
      "Fold: 8  Epoch: 576  Training loss = 1.4985  Validation loss = 5.7316  \n",
      "\n",
      "Fold: 8  Epoch: 577  Training loss = 1.4984  Validation loss = 5.7320  \n",
      "\n",
      "Fold: 8  Epoch: 578  Training loss = 1.4983  Validation loss = 5.7313  \n",
      "\n",
      "Fold: 8  Epoch: 579  Training loss = 1.4981  Validation loss = 5.7304  \n",
      "\n",
      "Fold: 8  Epoch: 580  Training loss = 1.4980  Validation loss = 5.7300  \n",
      "\n",
      "Fold: 8  Epoch: 581  Training loss = 1.4979  Validation loss = 5.7301  \n",
      "\n",
      "Fold: 8  Epoch: 582  Training loss = 1.4978  Validation loss = 5.7301  \n",
      "\n",
      "Fold: 8  Epoch: 583  Training loss = 1.4977  Validation loss = 5.7301  \n",
      "\n",
      "Fold: 8  Epoch: 584  Training loss = 1.4976  Validation loss = 5.7298  \n",
      "\n",
      "Fold: 8  Epoch: 585  Training loss = 1.4974  Validation loss = 5.7294  \n",
      "\n",
      "Fold: 8  Epoch: 586  Training loss = 1.4973  Validation loss = 5.7288  \n",
      "\n",
      "Fold: 8  Epoch: 587  Training loss = 1.4972  Validation loss = 5.7289  \n",
      "\n",
      "Fold: 8  Epoch: 588  Training loss = 1.4970  Validation loss = 5.7279  \n",
      "\n",
      "Fold: 8  Epoch: 589  Training loss = 1.4969  Validation loss = 5.7277  \n",
      "\n",
      "Fold: 8  Epoch: 590  Training loss = 1.4969  Validation loss = 5.7274  \n",
      "\n",
      "Fold: 8  Epoch: 591  Training loss = 1.4968  Validation loss = 5.7275  \n",
      "\n",
      "Fold: 8  Epoch: 592  Training loss = 1.4968  Validation loss = 5.7283  \n",
      "\n",
      "Fold: 8  Epoch: 593  Training loss = 1.4967  Validation loss = 5.7289  \n",
      "\n",
      "Fold: 8  Epoch: 594  Training loss = 1.4966  Validation loss = 5.7287  \n",
      "\n",
      "Fold: 8  Epoch: 595  Training loss = 1.4965  Validation loss = 5.7298  \n",
      "\n",
      "Fold: 8  Epoch: 596  Training loss = 1.4964  Validation loss = 5.7295  \n",
      "\n",
      "Fold: 8  Epoch: 597  Training loss = 1.4962  Validation loss = 5.7291  \n",
      "\n",
      "Fold: 8  Epoch: 598  Training loss = 1.4961  Validation loss = 5.7289  \n",
      "\n",
      "Fold: 8  Epoch: 599  Training loss = 1.4960  Validation loss = 5.7283  \n",
      "\n",
      "Fold: 8  Epoch: 600  Training loss = 1.4958  Validation loss = 5.7284  \n",
      "\n",
      "Fold: 8  Epoch: 601  Training loss = 1.4957  Validation loss = 5.7291  \n",
      "\n",
      "Fold: 8  Epoch: 602  Training loss = 1.4956  Validation loss = 5.7292  \n",
      "\n",
      "Fold: 8  Epoch: 603  Training loss = 1.4955  Validation loss = 5.7287  \n",
      "\n",
      "Fold: 8  Epoch: 604  Training loss = 1.4954  Validation loss = 5.7286  \n",
      "\n",
      "Fold: 8  Epoch: 605  Training loss = 1.4953  Validation loss = 5.7284  \n",
      "\n",
      "Fold: 8  Epoch: 606  Training loss = 1.4951  Validation loss = 5.7281  \n",
      "\n",
      "Fold: 8  Epoch: 607  Training loss = 1.4951  Validation loss = 5.7280  \n",
      "\n",
      "Fold: 8  Epoch: 608  Training loss = 1.4949  Validation loss = 5.7274  \n",
      "\n",
      "Fold: 8  Epoch: 609  Training loss = 1.4947  Validation loss = 5.7263  \n",
      "\n",
      "Fold: 8  Epoch: 610  Training loss = 1.4946  Validation loss = 5.7255  \n",
      "\n",
      "Fold: 8  Epoch: 611  Training loss = 1.4944  Validation loss = 5.7250  \n",
      "\n",
      "Fold: 8  Epoch: 612  Training loss = 1.4943  Validation loss = 5.7246  \n",
      "\n",
      "Fold: 8  Epoch: 613  Training loss = 1.4942  Validation loss = 5.7244  \n",
      "\n",
      "Fold: 8  Epoch: 614  Training loss = 1.4940  Validation loss = 5.7237  \n",
      "\n",
      "Fold: 8  Epoch: 615  Training loss = 1.4939  Validation loss = 5.7233  \n",
      "\n",
      "Fold: 8  Epoch: 616  Training loss = 1.4938  Validation loss = 5.7235  \n",
      "\n",
      "Fold: 8  Epoch: 617  Training loss = 1.4936  Validation loss = 5.7231  \n",
      "\n",
      "Fold: 8  Epoch: 618  Training loss = 1.4935  Validation loss = 5.7232  \n",
      "\n",
      "Fold: 8  Epoch: 619  Training loss = 1.4934  Validation loss = 5.7233  \n",
      "\n",
      "Fold: 8  Epoch: 620  Training loss = 1.4933  Validation loss = 5.7230  \n",
      "\n",
      "Fold: 8  Epoch: 621  Training loss = 1.4932  Validation loss = 5.7233  \n",
      "\n",
      "Fold: 8  Epoch: 622  Training loss = 1.4931  Validation loss = 5.7233  \n",
      "\n",
      "Fold: 8  Epoch: 623  Training loss = 1.4930  Validation loss = 5.7234  \n",
      "\n",
      "Fold: 8  Epoch: 624  Training loss = 1.4929  Validation loss = 5.7226  \n",
      "\n",
      "Fold: 8  Epoch: 625  Training loss = 1.4927  Validation loss = 5.7228  \n",
      "\n",
      "Fold: 8  Epoch: 626  Training loss = 1.4926  Validation loss = 5.7226  \n",
      "\n",
      "Fold: 8  Epoch: 627  Training loss = 1.4925  Validation loss = 5.7224  \n",
      "\n",
      "Fold: 8  Epoch: 628  Training loss = 1.4923  Validation loss = 5.7222  \n",
      "\n",
      "Fold: 8  Epoch: 629  Training loss = 1.4922  Validation loss = 5.7219  \n",
      "\n",
      "Fold: 8  Epoch: 630  Training loss = 1.4921  Validation loss = 5.7210  \n",
      "\n",
      "Fold: 8  Epoch: 631  Training loss = 1.4920  Validation loss = 5.7215  \n",
      "\n",
      "Fold: 8  Epoch: 632  Training loss = 1.4919  Validation loss = 5.7213  \n",
      "\n",
      "Fold: 8  Epoch: 633  Training loss = 1.4918  Validation loss = 5.7212  \n",
      "\n",
      "Fold: 8  Epoch: 634  Training loss = 1.4917  Validation loss = 5.7215  \n",
      "\n",
      "Fold: 8  Epoch: 635  Training loss = 1.4916  Validation loss = 5.7223  \n",
      "\n",
      "Fold: 8  Epoch: 636  Training loss = 1.4915  Validation loss = 5.7223  \n",
      "\n",
      "Fold: 8  Epoch: 637  Training loss = 1.4914  Validation loss = 5.7221  \n",
      "\n",
      "Fold: 8  Epoch: 638  Training loss = 1.4913  Validation loss = 5.7221  \n",
      "\n",
      "Fold: 8  Epoch: 639  Training loss = 1.4911  Validation loss = 5.7219  \n",
      "\n",
      "Fold: 8  Epoch: 640  Training loss = 1.4910  Validation loss = 5.7217  \n",
      "\n",
      "Fold: 8  Epoch: 641  Training loss = 1.4910  Validation loss = 5.7217  \n",
      "\n",
      "Fold: 8  Epoch: 642  Training loss = 1.4909  Validation loss = 5.7213  \n",
      "\n",
      "Fold: 8  Epoch: 643  Training loss = 1.4907  Validation loss = 5.7207  \n",
      "\n",
      "Fold: 8  Epoch: 644  Training loss = 1.4906  Validation loss = 5.7207  \n",
      "\n",
      "Fold: 8  Epoch: 645  Training loss = 1.4905  Validation loss = 5.7207  \n",
      "\n",
      "Fold: 8  Epoch: 646  Training loss = 1.4903  Validation loss = 5.7206  \n",
      "\n",
      "Fold: 8  Epoch: 647  Training loss = 1.4902  Validation loss = 5.7208  \n",
      "\n",
      "Fold: 8  Epoch: 648  Training loss = 1.4901  Validation loss = 5.7207  \n",
      "\n",
      "Fold: 8  Epoch: 649  Training loss = 1.4899  Validation loss = 5.7194  \n",
      "\n",
      "Fold: 8  Epoch: 650  Training loss = 1.4898  Validation loss = 5.7194  \n",
      "\n",
      "Fold: 8  Epoch: 651  Training loss = 1.4897  Validation loss = 5.7192  \n",
      "\n",
      "Fold: 8  Epoch: 652  Training loss = 1.4896  Validation loss = 5.7189  \n",
      "\n",
      "Fold: 8  Epoch: 653  Training loss = 1.4895  Validation loss = 5.7188  \n",
      "\n",
      "Fold: 8  Epoch: 654  Training loss = 1.4894  Validation loss = 5.7191  \n",
      "\n",
      "Fold: 8  Epoch: 655  Training loss = 1.4893  Validation loss = 5.7190  \n",
      "\n",
      "Fold: 8  Epoch: 656  Training loss = 1.4891  Validation loss = 5.7187  \n",
      "\n",
      "Fold: 8  Epoch: 657  Training loss = 1.4890  Validation loss = 5.7185  \n",
      "\n",
      "Fold: 8  Epoch: 658  Training loss = 1.4889  Validation loss = 5.7185  \n",
      "\n",
      "Fold: 8  Epoch: 659  Training loss = 1.4888  Validation loss = 5.7185  \n",
      "\n",
      "Fold: 8  Epoch: 660  Training loss = 1.4887  Validation loss = 5.7181  \n",
      "\n",
      "Fold: 8  Epoch: 661  Training loss = 1.4886  Validation loss = 5.7182  \n",
      "\n",
      "Fold: 8  Epoch: 662  Training loss = 1.4885  Validation loss = 5.7180  \n",
      "\n",
      "Fold: 8  Epoch: 663  Training loss = 1.4883  Validation loss = 5.7178  \n",
      "\n",
      "Fold: 8  Epoch: 664  Training loss = 1.4882  Validation loss = 5.7177  \n",
      "\n",
      "Fold: 8  Epoch: 665  Training loss = 1.4881  Validation loss = 5.7170  \n",
      "\n",
      "Fold: 8  Epoch: 666  Training loss = 1.4880  Validation loss = 5.7173  \n",
      "\n",
      "Fold: 8  Epoch: 667  Training loss = 1.4878  Validation loss = 5.7169  \n",
      "\n",
      "Fold: 8  Epoch: 668  Training loss = 1.4878  Validation loss = 5.7172  \n",
      "\n",
      "Fold: 8  Epoch: 669  Training loss = 1.4876  Validation loss = 5.7169  \n",
      "\n",
      "Fold: 8  Epoch: 670  Training loss = 1.4875  Validation loss = 5.7166  \n",
      "\n",
      "Fold: 8  Epoch: 671  Training loss = 1.4874  Validation loss = 5.7160  \n",
      "\n",
      "Fold: 8  Epoch: 672  Training loss = 1.4873  Validation loss = 5.7160  \n",
      "\n",
      "Fold: 8  Epoch: 673  Training loss = 1.4872  Validation loss = 5.7160  \n",
      "\n",
      "Fold: 8  Epoch: 674  Training loss = 1.4870  Validation loss = 5.7152  \n",
      "\n",
      "Fold: 8  Epoch: 675  Training loss = 1.4869  Validation loss = 5.7147  \n",
      "\n",
      "Fold: 8  Epoch: 676  Training loss = 1.4868  Validation loss = 5.7141  \n",
      "\n",
      "Fold: 8  Epoch: 677  Training loss = 1.4866  Validation loss = 5.7137  \n",
      "\n",
      "Fold: 8  Epoch: 678  Training loss = 1.4865  Validation loss = 5.7139  \n",
      "\n",
      "Fold: 8  Epoch: 679  Training loss = 1.4863  Validation loss = 5.7133  \n",
      "\n",
      "Fold: 8  Epoch: 680  Training loss = 1.4862  Validation loss = 5.7130  \n",
      "\n",
      "Fold: 8  Epoch: 681  Training loss = 1.4861  Validation loss = 5.7125  \n",
      "\n",
      "Fold: 8  Epoch: 682  Training loss = 1.4860  Validation loss = 5.7132  \n",
      "\n",
      "Fold: 8  Epoch: 683  Training loss = 1.4858  Validation loss = 5.7130  \n",
      "\n",
      "Fold: 8  Epoch: 684  Training loss = 1.4858  Validation loss = 5.7129  \n",
      "\n",
      "Fold: 8  Epoch: 685  Training loss = 1.4856  Validation loss = 5.7124  \n",
      "\n",
      "Fold: 8  Epoch: 686  Training loss = 1.4855  Validation loss = 5.7124  \n",
      "\n",
      "Fold: 8  Epoch: 687  Training loss = 1.4854  Validation loss = 5.7123  \n",
      "\n",
      "Fold: 8  Epoch: 688  Training loss = 1.4852  Validation loss = 5.7116  \n",
      "\n",
      "Fold: 8  Epoch: 689  Training loss = 1.4851  Validation loss = 5.7116  \n",
      "\n",
      "Fold: 8  Epoch: 690  Training loss = 1.4850  Validation loss = 5.7111  \n",
      "\n",
      "Fold: 8  Epoch: 691  Training loss = 1.4848  Validation loss = 5.7107  \n",
      "\n",
      "Fold: 8  Epoch: 692  Training loss = 1.4847  Validation loss = 5.7103  \n",
      "\n",
      "Fold: 8  Epoch: 693  Training loss = 1.4845  Validation loss = 5.7098  \n",
      "\n",
      "Fold: 8  Epoch: 694  Training loss = 1.4844  Validation loss = 5.7089  \n",
      "\n",
      "Fold: 8  Epoch: 695  Training loss = 1.4843  Validation loss = 5.7084  \n",
      "\n",
      "Fold: 8  Epoch: 696  Training loss = 1.4841  Validation loss = 5.7075  \n",
      "\n",
      "Fold: 8  Epoch: 697  Training loss = 1.4840  Validation loss = 5.7077  \n",
      "\n",
      "Fold: 8  Epoch: 698  Training loss = 1.4838  Validation loss = 5.7077  \n",
      "\n",
      "Fold: 8  Epoch: 699  Training loss = 1.4837  Validation loss = 5.7075  \n",
      "\n",
      "Fold: 8  Epoch: 700  Training loss = 1.4836  Validation loss = 5.7074  \n",
      "\n",
      "Fold: 8  Epoch: 701  Training loss = 1.4834  Validation loss = 5.7066  \n",
      "\n",
      "Fold: 8  Epoch: 702  Training loss = 1.4833  Validation loss = 5.7064  \n",
      "\n",
      "Fold: 8  Epoch: 703  Training loss = 1.4832  Validation loss = 5.7061  \n",
      "\n",
      "Fold: 8  Epoch: 704  Training loss = 1.4831  Validation loss = 5.7056  \n",
      "\n",
      "Fold: 8  Epoch: 705  Training loss = 1.4829  Validation loss = 5.7049  \n",
      "\n",
      "Fold: 8  Epoch: 706  Training loss = 1.4828  Validation loss = 5.7050  \n",
      "\n",
      "Fold: 8  Epoch: 707  Training loss = 1.4827  Validation loss = 5.7050  \n",
      "\n",
      "Fold: 8  Epoch: 708  Training loss = 1.4826  Validation loss = 5.7046  \n",
      "\n",
      "Fold: 8  Epoch: 709  Training loss = 1.4825  Validation loss = 5.7044  \n",
      "\n",
      "Fold: 8  Epoch: 710  Training loss = 1.4824  Validation loss = 5.7038  \n",
      "\n",
      "Fold: 8  Epoch: 711  Training loss = 1.4822  Validation loss = 5.7033  \n",
      "\n",
      "Fold: 8  Epoch: 712  Training loss = 1.4821  Validation loss = 5.7023  \n",
      "\n",
      "Fold: 8  Epoch: 713  Training loss = 1.4819  Validation loss = 5.7019  \n",
      "\n",
      "Fold: 8  Epoch: 714  Training loss = 1.4818  Validation loss = 5.7015  \n",
      "\n",
      "Fold: 8  Epoch: 715  Training loss = 1.4817  Validation loss = 5.7011  \n",
      "\n",
      "Fold: 8  Epoch: 716  Training loss = 1.4816  Validation loss = 5.7013  \n",
      "\n",
      "Fold: 8  Epoch: 717  Training loss = 1.4815  Validation loss = 5.7017  \n",
      "\n",
      "Fold: 8  Epoch: 718  Training loss = 1.4813  Validation loss = 5.7013  \n",
      "\n",
      "Fold: 8  Epoch: 719  Training loss = 1.4812  Validation loss = 5.7011  \n",
      "\n",
      "Fold: 8  Epoch: 720  Training loss = 1.4811  Validation loss = 5.7008  \n",
      "\n",
      "Fold: 8  Epoch: 721  Training loss = 1.4810  Validation loss = 5.7008  \n",
      "\n",
      "Fold: 8  Epoch: 722  Training loss = 1.4808  Validation loss = 5.7004  \n",
      "\n",
      "Fold: 8  Epoch: 723  Training loss = 1.4807  Validation loss = 5.6993  \n",
      "\n",
      "Fold: 8  Epoch: 724  Training loss = 1.4806  Validation loss = 5.6991  \n",
      "\n",
      "Fold: 8  Epoch: 725  Training loss = 1.4804  Validation loss = 5.6986  \n",
      "\n",
      "Fold: 8  Epoch: 726  Training loss = 1.4803  Validation loss = 5.6982  \n",
      "\n",
      "Fold: 8  Epoch: 727  Training loss = 1.4802  Validation loss = 5.6984  \n",
      "\n",
      "Fold: 8  Epoch: 728  Training loss = 1.4800  Validation loss = 5.6975  \n",
      "\n",
      "Fold: 8  Epoch: 729  Training loss = 1.4799  Validation loss = 5.6976  \n",
      "\n",
      "Fold: 8  Epoch: 730  Training loss = 1.4798  Validation loss = 5.6973  \n",
      "\n",
      "Fold: 8  Epoch: 731  Training loss = 1.4797  Validation loss = 5.6965  \n",
      "\n",
      "Fold: 8  Epoch: 732  Training loss = 1.4796  Validation loss = 5.6968  \n",
      "\n",
      "Fold: 8  Epoch: 733  Training loss = 1.4795  Validation loss = 5.6964  \n",
      "\n",
      "Fold: 8  Epoch: 734  Training loss = 1.4794  Validation loss = 5.6961  \n",
      "\n",
      "Fold: 8  Epoch: 735  Training loss = 1.4793  Validation loss = 5.6960  \n",
      "\n",
      "Fold: 8  Epoch: 736  Training loss = 1.4792  Validation loss = 5.6960  \n",
      "\n",
      "Fold: 8  Epoch: 737  Training loss = 1.4791  Validation loss = 5.6958  \n",
      "\n",
      "Fold: 8  Epoch: 738  Training loss = 1.4790  Validation loss = 5.6957  \n",
      "\n",
      "Fold: 8  Epoch: 739  Training loss = 1.4788  Validation loss = 5.6954  \n",
      "\n",
      "Fold: 8  Epoch: 740  Training loss = 1.4787  Validation loss = 5.6948  \n",
      "\n",
      "Fold: 8  Epoch: 741  Training loss = 1.4785  Validation loss = 5.6944  \n",
      "\n",
      "Fold: 8  Epoch: 742  Training loss = 1.4784  Validation loss = 5.6939  \n",
      "\n",
      "Fold: 8  Epoch: 743  Training loss = 1.4783  Validation loss = 5.6933  \n",
      "\n",
      "Fold: 8  Epoch: 744  Training loss = 1.4781  Validation loss = 5.6931  \n",
      "\n",
      "Fold: 8  Epoch: 745  Training loss = 1.4780  Validation loss = 5.6926  \n",
      "\n",
      "Fold: 8  Epoch: 746  Training loss = 1.4779  Validation loss = 5.6922  \n",
      "\n",
      "Fold: 8  Epoch: 747  Training loss = 1.4777  Validation loss = 5.6919  \n",
      "\n",
      "Fold: 8  Epoch: 748  Training loss = 1.4776  Validation loss = 5.6917  \n",
      "\n",
      "Fold: 8  Epoch: 749  Training loss = 1.4776  Validation loss = 5.6916  \n",
      "\n",
      "Fold: 8  Epoch: 750  Training loss = 1.4774  Validation loss = 5.6913  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 750  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.0273  Validation loss = 9.0358  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.0269  Validation loss = 9.0341  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.0268  Validation loss = 9.0334  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.0265  Validation loss = 9.0325  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.0263  Validation loss = 9.0318  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.0260  Validation loss = 9.0304  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.0256  Validation loss = 9.0288  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.0254  Validation loss = 9.0277  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.0252  Validation loss = 9.0268  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.0249  Validation loss = 9.0255  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.0246  Validation loss = 9.0245  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.0246  Validation loss = 9.0244  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.0242  Validation loss = 9.0230  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.0239  Validation loss = 9.0216  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.0236  Validation loss = 9.0203  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.0231  Validation loss = 9.0179  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.0227  Validation loss = 9.0162  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.0225  Validation loss = 9.0152  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.0222  Validation loss = 9.0143  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.0222  Validation loss = 9.0137  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.0219  Validation loss = 9.0129  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.0214  Validation loss = 9.0106  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.0212  Validation loss = 9.0100  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.0209  Validation loss = 9.0083  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.0204  Validation loss = 9.0065  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.0203  Validation loss = 9.0058  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.0200  Validation loss = 9.0046  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.0199  Validation loss = 9.0042  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.0197  Validation loss = 9.0030  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.0194  Validation loss = 9.0010  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.0190  Validation loss = 8.9991  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.0188  Validation loss = 8.9981  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.0185  Validation loss = 8.9968  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.0182  Validation loss = 8.9955  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.0179  Validation loss = 8.9935  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.0177  Validation loss = 8.9921  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.0173  Validation loss = 8.9903  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.0171  Validation loss = 8.9893  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.0170  Validation loss = 8.9885  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.0168  Validation loss = 8.9876  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.0167  Validation loss = 8.9866  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.0164  Validation loss = 8.9848  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.0161  Validation loss = 8.9835  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.0161  Validation loss = 8.9833  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.0159  Validation loss = 8.9828  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.0157  Validation loss = 8.9812  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.0156  Validation loss = 8.9804  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.0153  Validation loss = 8.9793  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.0151  Validation loss = 8.9785  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.0149  Validation loss = 8.9772  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.0146  Validation loss = 8.9761  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.0142  Validation loss = 8.9739  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.0139  Validation loss = 8.9725  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.0137  Validation loss = 8.9711  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.0136  Validation loss = 8.9708  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.0133  Validation loss = 8.9699  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.0132  Validation loss = 8.9695  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.0130  Validation loss = 8.9686  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.0129  Validation loss = 8.9674  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.0126  Validation loss = 8.9659  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.0122  Validation loss = 8.9634  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.0120  Validation loss = 8.9623  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.0119  Validation loss = 8.9614  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.0117  Validation loss = 8.9602  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.0115  Validation loss = 8.9593  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.0113  Validation loss = 8.9583  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.0111  Validation loss = 8.9576  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.0109  Validation loss = 8.9566  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.0107  Validation loss = 8.9555  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.0105  Validation loss = 8.9545  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.0101  Validation loss = 8.9531  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.0097  Validation loss = 8.9503  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.0095  Validation loss = 8.9492  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.0093  Validation loss = 8.9482  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.0091  Validation loss = 8.9469  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.0089  Validation loss = 8.9458  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.0085  Validation loss = 8.9445  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.0082  Validation loss = 8.9430  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.0080  Validation loss = 8.9412  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.0077  Validation loss = 8.9395  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.0073  Validation loss = 8.9373  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.0072  Validation loss = 8.9367  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.0069  Validation loss = 8.9347  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.0067  Validation loss = 8.9339  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.0064  Validation loss = 8.9326  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.0063  Validation loss = 8.9323  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.0061  Validation loss = 8.9314  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.0060  Validation loss = 8.9309  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.0057  Validation loss = 8.9297  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.0055  Validation loss = 8.9285  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.0054  Validation loss = 8.9280  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.0051  Validation loss = 8.9264  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.0048  Validation loss = 8.9252  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.0045  Validation loss = 8.9235  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.0044  Validation loss = 8.9229  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.0043  Validation loss = 8.9225  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.0040  Validation loss = 8.9213  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.0038  Validation loss = 8.9203  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.0036  Validation loss = 8.9194  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.0035  Validation loss = 8.9191  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.0033  Validation loss = 8.9180  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.0030  Validation loss = 8.9170  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.0028  Validation loss = 8.9157  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.0026  Validation loss = 8.9148  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.0024  Validation loss = 8.9136  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.0023  Validation loss = 8.9133  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.0021  Validation loss = 8.9123  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.0018  Validation loss = 8.9105  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.0015  Validation loss = 8.9094  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.0014  Validation loss = 8.9090  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.0012  Validation loss = 8.9078  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.0010  Validation loss = 8.9066  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.0008  Validation loss = 8.9056  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.0005  Validation loss = 8.9045  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.0003  Validation loss = 8.9035  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.0003  Validation loss = 8.9032  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.0001  Validation loss = 8.9026  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 1.9999  Validation loss = 8.9017  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 1.9996  Validation loss = 8.8998  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 1.9993  Validation loss = 8.8985  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 1.9991  Validation loss = 8.8970  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 1.9989  Validation loss = 8.8961  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 1.9988  Validation loss = 8.8960  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 1.9987  Validation loss = 8.8954  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 1.9985  Validation loss = 8.8946  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 1.9983  Validation loss = 8.8934  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 1.9980  Validation loss = 8.8918  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 1.9979  Validation loss = 8.8911  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 1.9976  Validation loss = 8.8901  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 1.9975  Validation loss = 8.8891  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 1.9974  Validation loss = 8.8888  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 1.9972  Validation loss = 8.8882  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 1.9970  Validation loss = 8.8874  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 1.9969  Validation loss = 8.8866  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 1.9966  Validation loss = 8.8852  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 1.9964  Validation loss = 8.8845  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 1.9961  Validation loss = 8.8829  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 1.9961  Validation loss = 8.8829  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 1.9960  Validation loss = 8.8827  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 1.9958  Validation loss = 8.8816  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 1.9956  Validation loss = 8.8805  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 1.9953  Validation loss = 8.8793  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 1.9952  Validation loss = 8.8788  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 1.9949  Validation loss = 8.8771  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 1.9948  Validation loss = 8.8765  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 1.9945  Validation loss = 8.8753  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 1.9944  Validation loss = 8.8746  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 1.9942  Validation loss = 8.8738  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 1.9940  Validation loss = 8.8734  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 1.9939  Validation loss = 8.8727  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 1.9937  Validation loss = 8.8716  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 1.9933  Validation loss = 8.8697  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 1.9931  Validation loss = 8.8685  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 1.9928  Validation loss = 8.8669  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 1.9925  Validation loss = 8.8655  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 1.9924  Validation loss = 8.8652  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 1.9922  Validation loss = 8.8641  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 1.9920  Validation loss = 8.8631  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 1.9918  Validation loss = 8.8625  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 1.9917  Validation loss = 8.8616  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 1.9915  Validation loss = 8.8609  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 1.9912  Validation loss = 8.8593  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 1.9911  Validation loss = 8.8591  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 1.9910  Validation loss = 8.8584  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 1.9908  Validation loss = 8.8575  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 1.9907  Validation loss = 8.8571  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 1.9905  Validation loss = 8.8565  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 1.9904  Validation loss = 8.8561  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 1.9902  Validation loss = 8.8549  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 1.9901  Validation loss = 8.8542  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 1.9899  Validation loss = 8.8533  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 1.9898  Validation loss = 8.8527  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 1.9894  Validation loss = 8.8508  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 1.9892  Validation loss = 8.8498  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 1.9890  Validation loss = 8.8491  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 1.9888  Validation loss = 8.8479  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 1.9886  Validation loss = 8.8473  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 1.9883  Validation loss = 8.8456  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 1.9881  Validation loss = 8.8444  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 1.9880  Validation loss = 8.8438  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 1.9878  Validation loss = 8.8430  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 1.9876  Validation loss = 8.8419  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 1.9875  Validation loss = 8.8412  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 1.9873  Validation loss = 8.8406  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 1.9871  Validation loss = 8.8397  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 1.9868  Validation loss = 8.8382  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 1.9867  Validation loss = 8.8374  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 1.9864  Validation loss = 8.8364  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 1.9862  Validation loss = 8.8355  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 1.9862  Validation loss = 8.8352  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 1.9859  Validation loss = 8.8336  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 1.9857  Validation loss = 8.8327  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 1.9856  Validation loss = 8.8321  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 1.9854  Validation loss = 8.8315  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 1.9853  Validation loss = 8.8309  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 1.9851  Validation loss = 8.8301  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 1.9849  Validation loss = 8.8283  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 1.9847  Validation loss = 8.8274  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 1.9845  Validation loss = 8.8271  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 1.9843  Validation loss = 8.8256  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 1.9841  Validation loss = 8.8247  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 1.9839  Validation loss = 8.8236  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 1.9836  Validation loss = 8.8224  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 1.9833  Validation loss = 8.8210  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 1.9831  Validation loss = 8.8201  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 1.9830  Validation loss = 8.8198  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 1.9827  Validation loss = 8.8184  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 1.9825  Validation loss = 8.8173  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 1.9823  Validation loss = 8.8164  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 1.9821  Validation loss = 8.8156  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 1.9818  Validation loss = 8.8143  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 1.9815  Validation loss = 8.8127  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 1.9814  Validation loss = 8.8124  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 1.9813  Validation loss = 8.8118  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 1.9812  Validation loss = 8.8113  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 1.9810  Validation loss = 8.8109  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 1.9809  Validation loss = 8.8103  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 1.9807  Validation loss = 8.8094  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 1.9805  Validation loss = 8.8085  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 1.9803  Validation loss = 8.8074  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 1.9802  Validation loss = 8.8070  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 1.9799  Validation loss = 8.8054  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 1.9797  Validation loss = 8.8045  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 1.9795  Validation loss = 8.8036  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 1.9793  Validation loss = 8.8023  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 1.9791  Validation loss = 8.8013  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 1.9789  Validation loss = 8.8003  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 1.9787  Validation loss = 8.7998  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 1.9786  Validation loss = 8.7993  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 1.9785  Validation loss = 8.7987  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 1.9783  Validation loss = 8.7976  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 1.9780  Validation loss = 8.7962  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 1.9779  Validation loss = 8.7955  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 1.9776  Validation loss = 8.7943  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 1.9774  Validation loss = 8.7934  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 1.9773  Validation loss = 8.7926  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 1.9770  Validation loss = 8.7912  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 1.9769  Validation loss = 8.7908  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 1.9767  Validation loss = 8.7899  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 1.9765  Validation loss = 8.7889  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 1.9764  Validation loss = 8.7883  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 1.9762  Validation loss = 8.7875  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 1.9761  Validation loss = 8.7872  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 1.9759  Validation loss = 8.7862  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 1.9758  Validation loss = 8.7857  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 1.9757  Validation loss = 8.7852  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 1.9756  Validation loss = 8.7850  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 1.9753  Validation loss = 8.7838  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 1.9751  Validation loss = 8.7830  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 1.9749  Validation loss = 8.7820  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 1.9748  Validation loss = 8.7813  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 1.9745  Validation loss = 8.7798  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 1.9743  Validation loss = 8.7788  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 1.9743  Validation loss = 8.7789  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 1.9741  Validation loss = 8.7781  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 1.9739  Validation loss = 8.7767  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 1.9737  Validation loss = 8.7762  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 1.9736  Validation loss = 8.7758  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 1.9734  Validation loss = 8.7749  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 1.9733  Validation loss = 8.7740  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 1.9731  Validation loss = 8.7733  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 1.9729  Validation loss = 8.7725  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 1.9727  Validation loss = 8.7719  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 1.9725  Validation loss = 8.7708  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 1.9723  Validation loss = 8.7696  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 1.9723  Validation loss = 8.7696  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 1.9720  Validation loss = 8.7686  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 1.9719  Validation loss = 8.7680  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 1.9716  Validation loss = 8.7666  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 1.9715  Validation loss = 8.7658  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 1.9713  Validation loss = 8.7652  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 1.9712  Validation loss = 8.7644  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 1.9710  Validation loss = 8.7636  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 1.9708  Validation loss = 8.7626  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 1.9706  Validation loss = 8.7617  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 1.9704  Validation loss = 8.7607  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 1.9701  Validation loss = 8.7594  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 1.9700  Validation loss = 8.7593  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 1.9699  Validation loss = 8.7585  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 1.9696  Validation loss = 8.7574  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 1.9695  Validation loss = 8.7571  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 1.9693  Validation loss = 8.7564  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 1.9692  Validation loss = 8.7555  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 1.9690  Validation loss = 8.7544  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 1.9689  Validation loss = 8.7541  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 1.9687  Validation loss = 8.7536  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 1.9686  Validation loss = 8.7532  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 1.9683  Validation loss = 8.7517  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 1.9681  Validation loss = 8.7506  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 1.9680  Validation loss = 8.7500  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 1.9678  Validation loss = 8.7491  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 1.9677  Validation loss = 8.7485  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 1.9675  Validation loss = 8.7479  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 1.9674  Validation loss = 8.7473  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 1.9672  Validation loss = 8.7464  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 1.9671  Validation loss = 8.7458  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 1.9669  Validation loss = 8.7454  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 1.9668  Validation loss = 8.7449  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 1.9666  Validation loss = 8.7438  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 1.9664  Validation loss = 8.7428  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 1.9663  Validation loss = 8.7422  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 1.9661  Validation loss = 8.7414  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 1.9659  Validation loss = 8.7407  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 1.9657  Validation loss = 8.7398  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 1.9654  Validation loss = 8.7382  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 1.9652  Validation loss = 8.7373  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 1.9651  Validation loss = 8.7369  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 1.9650  Validation loss = 8.7363  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 1.9648  Validation loss = 8.7355  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 1.9646  Validation loss = 8.7342  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 1.9644  Validation loss = 8.7336  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 1.9643  Validation loss = 8.7329  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 1.9641  Validation loss = 8.7321  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 1.9640  Validation loss = 8.7317  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 1.9639  Validation loss = 8.7312  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 1.9637  Validation loss = 8.7300  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 1.9636  Validation loss = 8.7301  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 1.9634  Validation loss = 8.7292  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 1.9632  Validation loss = 8.7285  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 1.9630  Validation loss = 8.7270  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 1.9628  Validation loss = 8.7264  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 1.9625  Validation loss = 8.7247  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 1.9624  Validation loss = 8.7242  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 1.9623  Validation loss = 8.7237  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 1.9621  Validation loss = 8.7233  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 1.9620  Validation loss = 8.7224  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 1.9617  Validation loss = 8.7213  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 1.9615  Validation loss = 8.7203  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 1.9614  Validation loss = 8.7198  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 1.9612  Validation loss = 8.7188  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 1.9611  Validation loss = 8.7182  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 1.9608  Validation loss = 8.7170  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 1.9608  Validation loss = 8.7169  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 1.9606  Validation loss = 8.7165  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 1.9604  Validation loss = 8.7156  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 1.9603  Validation loss = 8.7152  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 1.9603  Validation loss = 8.7153  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 1.9601  Validation loss = 8.7142  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 1.9599  Validation loss = 8.7137  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 1.9598  Validation loss = 8.7135  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 1.9595  Validation loss = 8.7112  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 1.9592  Validation loss = 8.7101  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 1.9590  Validation loss = 8.7087  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 1.9589  Validation loss = 8.7083  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 1.9587  Validation loss = 8.7079  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 1.9584  Validation loss = 8.7061  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 1.9583  Validation loss = 8.7058  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 1.9582  Validation loss = 8.7054  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 1.9580  Validation loss = 8.7045  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 1.9578  Validation loss = 8.7035  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 1.9576  Validation loss = 8.7024  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 1.9574  Validation loss = 8.7014  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 1.9572  Validation loss = 8.7006  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 1.9571  Validation loss = 8.7000  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 1.9569  Validation loss = 8.6991  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 1.9567  Validation loss = 8.6986  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 1.9566  Validation loss = 8.6982  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 1.9564  Validation loss = 8.6973  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 1.9563  Validation loss = 8.6968  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 1.9560  Validation loss = 8.6951  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 1.9558  Validation loss = 8.6941  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 1.9557  Validation loss = 8.6936  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 1.9554  Validation loss = 8.6922  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 1.9554  Validation loss = 8.6922  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 1.9552  Validation loss = 8.6913  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 1.9550  Validation loss = 8.6904  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 1.9549  Validation loss = 8.6903  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 1.9548  Validation loss = 8.6897  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 1.9547  Validation loss = 8.6895  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 1.9545  Validation loss = 8.6890  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 1.9543  Validation loss = 8.6879  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 1.9542  Validation loss = 8.6877  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 1.9541  Validation loss = 8.6876  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 1.9540  Validation loss = 8.6869  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 1.9539  Validation loss = 8.6864  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 1.9536  Validation loss = 8.6851  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 1.9535  Validation loss = 8.6847  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 1.9534  Validation loss = 8.6842  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 1.9532  Validation loss = 8.6834  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 1.9530  Validation loss = 8.6822  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 1.9528  Validation loss = 8.6816  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 1.9527  Validation loss = 8.6811  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 1.9526  Validation loss = 8.6804  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 1.9524  Validation loss = 8.6798  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 1.9522  Validation loss = 8.6787  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 1.9521  Validation loss = 8.6782  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 1.9520  Validation loss = 8.6778  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 1.9518  Validation loss = 8.6770  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 1.9517  Validation loss = 8.6769  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 1.9515  Validation loss = 8.6761  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 1.9513  Validation loss = 8.6751  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 1.9512  Validation loss = 8.6749  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 1.9511  Validation loss = 8.6744  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 1.9509  Validation loss = 8.6736  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 1.9507  Validation loss = 8.6724  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 1.9506  Validation loss = 8.6721  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 1.9504  Validation loss = 8.6710  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 1.9503  Validation loss = 8.6704  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 1.9501  Validation loss = 8.6696  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 1.9499  Validation loss = 8.6686  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 1.9497  Validation loss = 8.6675  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 1.9495  Validation loss = 8.6669  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 1.9494  Validation loss = 8.6660  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 1.9492  Validation loss = 8.6656  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 1.9491  Validation loss = 8.6650  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 1.9488  Validation loss = 8.6635  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 1.9486  Validation loss = 8.6628  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 1.9485  Validation loss = 8.6622  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 1.9484  Validation loss = 8.6618  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 1.9482  Validation loss = 8.6611  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 1.9480  Validation loss = 8.6600  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 1.9479  Validation loss = 8.6598  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 1.9477  Validation loss = 8.6594  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 1.9476  Validation loss = 8.6587  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 1.9475  Validation loss = 8.6588  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 1.9474  Validation loss = 8.6582  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 1.9472  Validation loss = 8.6573  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 1.9470  Validation loss = 8.6567  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 1.9469  Validation loss = 8.6560  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 1.9466  Validation loss = 8.6548  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 1.9465  Validation loss = 8.6545  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 1.9464  Validation loss = 8.6541  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 1.9463  Validation loss = 8.6534  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 1.9461  Validation loss = 8.6530  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 1.9460  Validation loss = 8.6524  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 1.9457  Validation loss = 8.6512  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 1.9456  Validation loss = 8.6510  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 1.9456  Validation loss = 8.6511  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 1.9454  Validation loss = 8.6503  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 1.9452  Validation loss = 8.6492  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 1.9451  Validation loss = 8.6490  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 1.9449  Validation loss = 8.6479  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 1.9447  Validation loss = 8.6468  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 1.9444  Validation loss = 8.6455  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 1.9443  Validation loss = 8.6451  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 1.9442  Validation loss = 8.6441  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 1.9440  Validation loss = 8.6432  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 1.9439  Validation loss = 8.6432  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 1.9437  Validation loss = 8.6423  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 1.9436  Validation loss = 8.6421  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 1.9435  Validation loss = 8.6420  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 1.9434  Validation loss = 8.6413  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 1.9433  Validation loss = 8.6413  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 1.9431  Validation loss = 8.6406  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 1.9430  Validation loss = 8.6398  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 1.9428  Validation loss = 8.6390  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 1.9427  Validation loss = 8.6385  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 1.9426  Validation loss = 8.6384  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 1.9424  Validation loss = 8.6379  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 1.9422  Validation loss = 8.6370  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 1.9420  Validation loss = 8.6359  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 1.9419  Validation loss = 8.6351  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 1.9417  Validation loss = 8.6341  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 1.9414  Validation loss = 8.6326  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 1.9411  Validation loss = 8.6311  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 1.9410  Validation loss = 8.6303  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 1.9409  Validation loss = 8.6300  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 1.9407  Validation loss = 8.6295  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 1.9405  Validation loss = 8.6286  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 1.9403  Validation loss = 8.6279  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 1.9402  Validation loss = 8.6270  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 1.9400  Validation loss = 8.6259  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 1.9398  Validation loss = 8.6251  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 1.9397  Validation loss = 8.6246  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 1.9395  Validation loss = 8.6237  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 1.9393  Validation loss = 8.6231  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 1.9391  Validation loss = 8.6218  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 1.9389  Validation loss = 8.6210  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 1.9387  Validation loss = 8.6197  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 1.9385  Validation loss = 8.6186  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 1.9383  Validation loss = 8.6180  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 1.9382  Validation loss = 8.6171  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 1.9381  Validation loss = 8.6172  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 1.9379  Validation loss = 8.6166  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 1.9378  Validation loss = 8.6158  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 1.9376  Validation loss = 8.6154  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 1.9375  Validation loss = 8.6151  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 1.9373  Validation loss = 8.6136  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 1.9372  Validation loss = 8.6140  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 1.9371  Validation loss = 8.6131  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 1.9369  Validation loss = 8.6122  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 1.9368  Validation loss = 8.6121  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 1.9366  Validation loss = 8.6109  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 1.9364  Validation loss = 8.6104  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 1.9363  Validation loss = 8.6097  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 1.9362  Validation loss = 8.6095  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 1.9361  Validation loss = 8.6096  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 1.9360  Validation loss = 8.6086  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 1.9358  Validation loss = 8.6081  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 1.9357  Validation loss = 8.6073  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 1.9356  Validation loss = 8.6069  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 1.9355  Validation loss = 8.6065  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 1.9353  Validation loss = 8.6062  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 1.9352  Validation loss = 8.6055  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 1.9350  Validation loss = 8.6051  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 1.9349  Validation loss = 8.6050  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 1.9347  Validation loss = 8.6043  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 1.9346  Validation loss = 8.6038  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 1.9345  Validation loss = 8.6033  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 1.9344  Validation loss = 8.6034  \n",
      "\n",
      "Fold: 9  Epoch: 501  Training loss = 1.9342  Validation loss = 8.6023  \n",
      "\n",
      "Fold: 9  Epoch: 502  Training loss = 1.9340  Validation loss = 8.6013  \n",
      "\n",
      "Fold: 9  Epoch: 503  Training loss = 1.9339  Validation loss = 8.6004  \n",
      "\n",
      "Fold: 9  Epoch: 504  Training loss = 1.9337  Validation loss = 8.5998  \n",
      "\n",
      "Fold: 9  Epoch: 505  Training loss = 1.9336  Validation loss = 8.5993  \n",
      "\n",
      "Fold: 9  Epoch: 506  Training loss = 1.9335  Validation loss = 8.5994  \n",
      "\n",
      "Fold: 9  Epoch: 507  Training loss = 1.9333  Validation loss = 8.5987  \n",
      "\n",
      "Fold: 9  Epoch: 508  Training loss = 1.9332  Validation loss = 8.5984  \n",
      "\n",
      "Fold: 9  Epoch: 509  Training loss = 1.9331  Validation loss = 8.5984  \n",
      "\n",
      "Fold: 9  Epoch: 510  Training loss = 1.9330  Validation loss = 8.5983  \n",
      "\n",
      "Fold: 9  Epoch: 511  Training loss = 1.9329  Validation loss = 8.5973  \n",
      "\n",
      "Fold: 9  Epoch: 512  Training loss = 1.9328  Validation loss = 8.5971  \n",
      "\n",
      "Fold: 9  Epoch: 513  Training loss = 1.9326  Validation loss = 8.5968  \n",
      "\n",
      "Fold: 9  Epoch: 514  Training loss = 1.9325  Validation loss = 8.5962  \n",
      "\n",
      "Fold: 9  Epoch: 515  Training loss = 1.9322  Validation loss = 8.5949  \n",
      "\n",
      "Fold: 9  Epoch: 516  Training loss = 1.9320  Validation loss = 8.5940  \n",
      "\n",
      "Fold: 9  Epoch: 517  Training loss = 1.9319  Validation loss = 8.5932  \n",
      "\n",
      "Fold: 9  Epoch: 518  Training loss = 1.9318  Validation loss = 8.5930  \n",
      "\n",
      "Fold: 9  Epoch: 519  Training loss = 1.9317  Validation loss = 8.5924  \n",
      "\n",
      "Fold: 9  Epoch: 520  Training loss = 1.9315  Validation loss = 8.5920  \n",
      "\n",
      "Fold: 9  Epoch: 521  Training loss = 1.9313  Validation loss = 8.5910  \n",
      "\n",
      "Fold: 9  Epoch: 522  Training loss = 1.9312  Validation loss = 8.5904  \n",
      "\n",
      "Fold: 9  Epoch: 523  Training loss = 1.9310  Validation loss = 8.5898  \n",
      "\n",
      "Fold: 9  Epoch: 524  Training loss = 1.9308  Validation loss = 8.5885  \n",
      "\n",
      "Fold: 9  Epoch: 525  Training loss = 1.9306  Validation loss = 8.5875  \n",
      "\n",
      "Fold: 9  Epoch: 526  Training loss = 1.9305  Validation loss = 8.5870  \n",
      "\n",
      "Fold: 9  Epoch: 527  Training loss = 1.9302  Validation loss = 8.5856  \n",
      "\n",
      "Fold: 9  Epoch: 528  Training loss = 1.9301  Validation loss = 8.5852  \n",
      "\n",
      "Fold: 9  Epoch: 529  Training loss = 1.9300  Validation loss = 8.5847  \n",
      "\n",
      "Fold: 9  Epoch: 530  Training loss = 1.9298  Validation loss = 8.5841  \n",
      "\n",
      "Fold: 9  Epoch: 531  Training loss = 1.9297  Validation loss = 8.5838  \n",
      "\n",
      "Fold: 9  Epoch: 532  Training loss = 1.9296  Validation loss = 8.5833  \n",
      "\n",
      "Fold: 9  Epoch: 533  Training loss = 1.9295  Validation loss = 8.5830  \n",
      "\n",
      "Fold: 9  Epoch: 534  Training loss = 1.9293  Validation loss = 8.5823  \n",
      "\n",
      "Fold: 9  Epoch: 535  Training loss = 1.9291  Validation loss = 8.5818  \n",
      "\n",
      "Fold: 9  Epoch: 536  Training loss = 1.9290  Validation loss = 8.5810  \n",
      "\n",
      "Fold: 9  Epoch: 537  Training loss = 1.9288  Validation loss = 8.5803  \n",
      "\n",
      "Fold: 9  Epoch: 538  Training loss = 1.9287  Validation loss = 8.5801  \n",
      "\n",
      "Fold: 9  Epoch: 539  Training loss = 1.9287  Validation loss = 8.5804  \n",
      "\n",
      "Fold: 9  Epoch: 540  Training loss = 1.9286  Validation loss = 8.5801  \n",
      "\n",
      "Fold: 9  Epoch: 541  Training loss = 1.9284  Validation loss = 8.5794  \n",
      "\n",
      "Fold: 9  Epoch: 542  Training loss = 1.9282  Validation loss = 8.5784  \n",
      "\n",
      "Fold: 9  Epoch: 543  Training loss = 1.9281  Validation loss = 8.5777  \n",
      "\n",
      "Fold: 9  Epoch: 544  Training loss = 1.9280  Validation loss = 8.5772  \n",
      "\n",
      "Fold: 9  Epoch: 545  Training loss = 1.9278  Validation loss = 8.5766  \n",
      "\n",
      "Fold: 9  Epoch: 546  Training loss = 1.9277  Validation loss = 8.5759  \n",
      "\n",
      "Fold: 9  Epoch: 547  Training loss = 1.9276  Validation loss = 8.5757  \n",
      "\n",
      "Fold: 9  Epoch: 548  Training loss = 1.9273  Validation loss = 8.5741  \n",
      "\n",
      "Fold: 9  Epoch: 549  Training loss = 1.9272  Validation loss = 8.5735  \n",
      "\n",
      "Fold: 9  Epoch: 550  Training loss = 1.9270  Validation loss = 8.5732  \n",
      "\n",
      "Fold: 9  Epoch: 551  Training loss = 1.9269  Validation loss = 8.5731  \n",
      "\n",
      "Fold: 9  Epoch: 552  Training loss = 1.9269  Validation loss = 8.5730  \n",
      "\n",
      "Fold: 9  Epoch: 553  Training loss = 1.9267  Validation loss = 8.5726  \n",
      "\n",
      "Fold: 9  Epoch: 554  Training loss = 1.9266  Validation loss = 8.5721  \n",
      "\n",
      "Fold: 9  Epoch: 555  Training loss = 1.9264  Validation loss = 8.5710  \n",
      "\n",
      "Fold: 9  Epoch: 556  Training loss = 1.9262  Validation loss = 8.5703  \n",
      "\n",
      "Fold: 9  Epoch: 557  Training loss = 1.9261  Validation loss = 8.5698  \n",
      "\n",
      "Fold: 9  Epoch: 558  Training loss = 1.9260  Validation loss = 8.5696  \n",
      "\n",
      "Fold: 9  Epoch: 559  Training loss = 1.9259  Validation loss = 8.5695  \n",
      "\n",
      "Fold: 9  Epoch: 560  Training loss = 1.9257  Validation loss = 8.5688  \n",
      "\n",
      "Fold: 9  Epoch: 561  Training loss = 1.9256  Validation loss = 8.5685  \n",
      "\n",
      "Fold: 9  Epoch: 562  Training loss = 1.9253  Validation loss = 8.5670  \n",
      "\n",
      "Fold: 9  Epoch: 563  Training loss = 1.9252  Validation loss = 8.5664  \n",
      "\n",
      "Fold: 9  Epoch: 564  Training loss = 1.9251  Validation loss = 8.5658  \n",
      "\n",
      "Fold: 9  Epoch: 565  Training loss = 1.9249  Validation loss = 8.5653  \n",
      "\n",
      "Fold: 9  Epoch: 566  Training loss = 1.9248  Validation loss = 8.5647  \n",
      "\n",
      "Fold: 9  Epoch: 567  Training loss = 1.9246  Validation loss = 8.5642  \n",
      "\n",
      "Fold: 9  Epoch: 568  Training loss = 1.9245  Validation loss = 8.5639  \n",
      "\n",
      "Fold: 9  Epoch: 569  Training loss = 1.9244  Validation loss = 8.5637  \n",
      "\n",
      "Fold: 9  Epoch: 570  Training loss = 1.9242  Validation loss = 8.5627  \n",
      "\n",
      "Fold: 9  Epoch: 571  Training loss = 1.9241  Validation loss = 8.5623  \n",
      "\n",
      "Fold: 9  Epoch: 572  Training loss = 1.9239  Validation loss = 8.5617  \n",
      "\n",
      "Fold: 9  Epoch: 573  Training loss = 1.9238  Validation loss = 8.5612  \n",
      "\n",
      "Fold: 9  Epoch: 574  Training loss = 1.9237  Validation loss = 8.5609  \n",
      "\n",
      "Fold: 9  Epoch: 575  Training loss = 1.9235  Validation loss = 8.5605  \n",
      "\n",
      "Fold: 9  Epoch: 576  Training loss = 1.9235  Validation loss = 8.5605  \n",
      "\n",
      "Fold: 9  Epoch: 577  Training loss = 1.9234  Validation loss = 8.5604  \n",
      "\n",
      "Fold: 9  Epoch: 578  Training loss = 1.9233  Validation loss = 8.5601  \n",
      "\n",
      "Fold: 9  Epoch: 579  Training loss = 1.9232  Validation loss = 8.5600  \n",
      "\n",
      "Fold: 9  Epoch: 580  Training loss = 1.9230  Validation loss = 8.5596  \n",
      "\n",
      "Fold: 9  Epoch: 581  Training loss = 1.9229  Validation loss = 8.5589  \n",
      "\n",
      "Fold: 9  Epoch: 582  Training loss = 1.9228  Validation loss = 8.5586  \n",
      "\n",
      "Fold: 9  Epoch: 583  Training loss = 1.9227  Validation loss = 8.5583  \n",
      "\n",
      "Fold: 9  Epoch: 584  Training loss = 1.9225  Validation loss = 8.5578  \n",
      "\n",
      "Fold: 9  Epoch: 585  Training loss = 1.9224  Validation loss = 8.5576  \n",
      "\n",
      "Fold: 9  Epoch: 586  Training loss = 1.9223  Validation loss = 8.5570  \n",
      "\n",
      "Fold: 9  Epoch: 587  Training loss = 1.9221  Validation loss = 8.5566  \n",
      "\n",
      "Fold: 9  Epoch: 588  Training loss = 1.9220  Validation loss = 8.5561  \n",
      "\n",
      "Fold: 9  Epoch: 589  Training loss = 1.9219  Validation loss = 8.5557  \n",
      "\n",
      "Fold: 9  Epoch: 590  Training loss = 1.9218  Validation loss = 8.5556  \n",
      "\n",
      "Fold: 9  Epoch: 591  Training loss = 1.9216  Validation loss = 8.5546  \n",
      "\n",
      "Fold: 9  Epoch: 592  Training loss = 1.9214  Validation loss = 8.5540  \n",
      "\n",
      "Fold: 9  Epoch: 593  Training loss = 1.9213  Validation loss = 8.5537  \n",
      "\n",
      "Fold: 9  Epoch: 594  Training loss = 1.9212  Validation loss = 8.5535  \n",
      "\n",
      "Fold: 9  Epoch: 595  Training loss = 1.9210  Validation loss = 8.5522  \n",
      "\n",
      "Fold: 9  Epoch: 596  Training loss = 1.9209  Validation loss = 8.5516  \n",
      "\n",
      "Fold: 9  Epoch: 597  Training loss = 1.9207  Validation loss = 8.5512  \n",
      "\n",
      "Fold: 9  Epoch: 598  Training loss = 1.9206  Validation loss = 8.5504  \n",
      "\n",
      "Fold: 9  Epoch: 599  Training loss = 1.9204  Validation loss = 8.5493  \n",
      "\n",
      "Fold: 9  Epoch: 600  Training loss = 1.9202  Validation loss = 8.5484  \n",
      "\n",
      "Fold: 9  Epoch: 601  Training loss = 1.9201  Validation loss = 8.5479  \n",
      "\n",
      "Fold: 9  Epoch: 602  Training loss = 1.9198  Validation loss = 8.5464  \n",
      "\n",
      "Fold: 9  Epoch: 603  Training loss = 1.9196  Validation loss = 8.5456  \n",
      "\n",
      "Fold: 9  Epoch: 604  Training loss = 1.9195  Validation loss = 8.5450  \n",
      "\n",
      "Fold: 9  Epoch: 605  Training loss = 1.9194  Validation loss = 8.5447  \n",
      "\n",
      "Fold: 9  Epoch: 606  Training loss = 1.9192  Validation loss = 8.5440  \n",
      "\n",
      "Fold: 9  Epoch: 607  Training loss = 1.9191  Validation loss = 8.5439  \n",
      "\n",
      "Fold: 9  Epoch: 608  Training loss = 1.9189  Validation loss = 8.5427  \n",
      "\n",
      "Fold: 9  Epoch: 609  Training loss = 1.9187  Validation loss = 8.5417  \n",
      "\n",
      "Fold: 9  Epoch: 610  Training loss = 1.9186  Validation loss = 8.5413  \n",
      "\n",
      "Fold: 9  Epoch: 611  Training loss = 1.9185  Validation loss = 8.5407  \n",
      "\n",
      "Fold: 9  Epoch: 612  Training loss = 1.9184  Validation loss = 8.5406  \n",
      "\n",
      "Fold: 9  Epoch: 613  Training loss = 1.9182  Validation loss = 8.5395  \n",
      "\n",
      "Fold: 9  Epoch: 614  Training loss = 1.9179  Validation loss = 8.5383  \n",
      "\n",
      "Fold: 9  Epoch: 615  Training loss = 1.9177  Validation loss = 8.5369  \n",
      "\n",
      "Fold: 9  Epoch: 616  Training loss = 1.9175  Validation loss = 8.5362  \n",
      "\n",
      "Fold: 9  Epoch: 617  Training loss = 1.9174  Validation loss = 8.5357  \n",
      "\n",
      "Fold: 9  Epoch: 618  Training loss = 1.9173  Validation loss = 8.5357  \n",
      "\n",
      "Fold: 9  Epoch: 619  Training loss = 1.9172  Validation loss = 8.5350  \n",
      "\n",
      "Fold: 9  Epoch: 620  Training loss = 1.9170  Validation loss = 8.5343  \n",
      "\n",
      "Fold: 9  Epoch: 621  Training loss = 1.9169  Validation loss = 8.5340  \n",
      "\n",
      "Fold: 9  Epoch: 622  Training loss = 1.9168  Validation loss = 8.5334  \n",
      "\n",
      "Fold: 9  Epoch: 623  Training loss = 1.9166  Validation loss = 8.5327  \n",
      "\n",
      "Fold: 9  Epoch: 624  Training loss = 1.9165  Validation loss = 8.5328  \n",
      "\n",
      "Fold: 9  Epoch: 625  Training loss = 1.9163  Validation loss = 8.5320  \n",
      "\n",
      "Fold: 9  Epoch: 626  Training loss = 1.9163  Validation loss = 8.5320  \n",
      "\n",
      "Fold: 9  Epoch: 627  Training loss = 1.9161  Validation loss = 8.5313  \n",
      "\n",
      "Fold: 9  Epoch: 628  Training loss = 1.9159  Validation loss = 8.5307  \n",
      "\n",
      "Fold: 9  Epoch: 629  Training loss = 1.9158  Validation loss = 8.5300  \n",
      "\n",
      "Fold: 9  Epoch: 630  Training loss = 1.9157  Validation loss = 8.5296  \n",
      "\n",
      "Fold: 9  Epoch: 631  Training loss = 1.9156  Validation loss = 8.5294  \n",
      "\n",
      "Fold: 9  Epoch: 632  Training loss = 1.9155  Validation loss = 8.5292  \n",
      "\n",
      "Fold: 9  Epoch: 633  Training loss = 1.9153  Validation loss = 8.5283  \n",
      "\n",
      "Fold: 9  Epoch: 634  Training loss = 1.9152  Validation loss = 8.5281  \n",
      "\n",
      "Fold: 9  Epoch: 635  Training loss = 1.9150  Validation loss = 8.5274  \n",
      "\n",
      "Fold: 9  Epoch: 636  Training loss = 1.9149  Validation loss = 8.5266  \n",
      "\n",
      "Fold: 9  Epoch: 637  Training loss = 1.9147  Validation loss = 8.5260  \n",
      "\n",
      "Fold: 9  Epoch: 638  Training loss = 1.9146  Validation loss = 8.5251  \n",
      "\n",
      "Fold: 9  Epoch: 639  Training loss = 1.9145  Validation loss = 8.5251  \n",
      "\n",
      "Fold: 9  Epoch: 640  Training loss = 1.9144  Validation loss = 8.5246  \n",
      "\n",
      "Fold: 9  Epoch: 641  Training loss = 1.9142  Validation loss = 8.5236  \n",
      "\n",
      "Fold: 9  Epoch: 642  Training loss = 1.9140  Validation loss = 8.5228  \n",
      "\n",
      "Fold: 9  Epoch: 643  Training loss = 1.9140  Validation loss = 8.5227  \n",
      "\n",
      "Fold: 9  Epoch: 644  Training loss = 1.9138  Validation loss = 8.5217  \n",
      "\n",
      "Fold: 9  Epoch: 645  Training loss = 1.9136  Validation loss = 8.5209  \n",
      "\n",
      "Fold: 9  Epoch: 646  Training loss = 1.9135  Validation loss = 8.5206  \n",
      "\n",
      "Fold: 9  Epoch: 647  Training loss = 1.9133  Validation loss = 8.5197  \n",
      "\n",
      "Fold: 9  Epoch: 648  Training loss = 1.9132  Validation loss = 8.5196  \n",
      "\n",
      "Fold: 9  Epoch: 649  Training loss = 1.9131  Validation loss = 8.5193  \n",
      "\n",
      "Fold: 9  Epoch: 650  Training loss = 1.9129  Validation loss = 8.5185  \n",
      "\n",
      "Fold: 9  Epoch: 651  Training loss = 1.9127  Validation loss = 8.5178  \n",
      "\n",
      "Fold: 9  Epoch: 652  Training loss = 1.9127  Validation loss = 8.5180  \n",
      "\n",
      "Fold: 9  Epoch: 653  Training loss = 1.9126  Validation loss = 8.5177  \n",
      "\n",
      "Fold: 9  Epoch: 654  Training loss = 1.9125  Validation loss = 8.5172  \n",
      "\n",
      "Fold: 9  Epoch: 655  Training loss = 1.9123  Validation loss = 8.5164  \n",
      "\n",
      "Fold: 9  Epoch: 656  Training loss = 1.9121  Validation loss = 8.5159  \n",
      "\n",
      "Fold: 9  Epoch: 657  Training loss = 1.9120  Validation loss = 8.5153  \n",
      "\n",
      "Fold: 9  Epoch: 658  Training loss = 1.9119  Validation loss = 8.5151  \n",
      "\n",
      "Fold: 9  Epoch: 659  Training loss = 1.9118  Validation loss = 8.5149  \n",
      "\n",
      "Fold: 9  Epoch: 660  Training loss = 1.9116  Validation loss = 8.5140  \n",
      "\n",
      "Fold: 9  Epoch: 661  Training loss = 1.9114  Validation loss = 8.5136  \n",
      "\n",
      "Fold: 9  Epoch: 662  Training loss = 1.9114  Validation loss = 8.5137  \n",
      "\n",
      "Fold: 9  Epoch: 663  Training loss = 1.9112  Validation loss = 8.5127  \n",
      "\n",
      "Fold: 9  Epoch: 664  Training loss = 1.9111  Validation loss = 8.5127  \n",
      "\n",
      "Fold: 9  Epoch: 665  Training loss = 1.9108  Validation loss = 8.5113  \n",
      "\n",
      "Fold: 9  Epoch: 666  Training loss = 1.9107  Validation loss = 8.5106  \n",
      "\n",
      "Fold: 9  Epoch: 667  Training loss = 1.9106  Validation loss = 8.5103  \n",
      "\n",
      "Fold: 9  Epoch: 668  Training loss = 1.9104  Validation loss = 8.5096  \n",
      "\n",
      "Fold: 9  Epoch: 669  Training loss = 1.9103  Validation loss = 8.5093  \n",
      "\n",
      "Fold: 9  Epoch: 670  Training loss = 1.9102  Validation loss = 8.5090  \n",
      "\n",
      "Fold: 9  Epoch: 671  Training loss = 1.9100  Validation loss = 8.5079  \n",
      "\n",
      "Fold: 9  Epoch: 672  Training loss = 1.9098  Validation loss = 8.5072  \n",
      "\n",
      "Fold: 9  Epoch: 673  Training loss = 1.9097  Validation loss = 8.5071  \n",
      "\n",
      "Fold: 9  Epoch: 674  Training loss = 1.9096  Validation loss = 8.5069  \n",
      "\n",
      "Fold: 9  Epoch: 675  Training loss = 1.9095  Validation loss = 8.5064  \n",
      "\n",
      "Fold: 9  Epoch: 676  Training loss = 1.9093  Validation loss = 8.5054  \n",
      "\n",
      "Fold: 9  Epoch: 677  Training loss = 1.9093  Validation loss = 8.5054  \n",
      "\n",
      "Fold: 9  Epoch: 678  Training loss = 1.9091  Validation loss = 8.5047  \n",
      "\n",
      "Fold: 9  Epoch: 679  Training loss = 1.9089  Validation loss = 8.5040  \n",
      "\n",
      "Fold: 9  Epoch: 680  Training loss = 1.9088  Validation loss = 8.5031  \n",
      "\n",
      "Fold: 9  Epoch: 681  Training loss = 1.9086  Validation loss = 8.5030  \n",
      "\n",
      "Fold: 9  Epoch: 682  Training loss = 1.9084  Validation loss = 8.5017  \n",
      "\n",
      "Fold: 9  Epoch: 683  Training loss = 1.9083  Validation loss = 8.5013  \n",
      "\n",
      "Fold: 9  Epoch: 684  Training loss = 1.9081  Validation loss = 8.5006  \n",
      "\n",
      "Fold: 9  Epoch: 685  Training loss = 1.9080  Validation loss = 8.4996  \n",
      "\n",
      "Fold: 9  Epoch: 686  Training loss = 1.9079  Validation loss = 8.4994  \n",
      "\n",
      "Fold: 9  Epoch: 687  Training loss = 1.9078  Validation loss = 8.4989  \n",
      "\n",
      "Fold: 9  Epoch: 688  Training loss = 1.9076  Validation loss = 8.4983  \n",
      "\n",
      "Fold: 9  Epoch: 689  Training loss = 1.9074  Validation loss = 8.4976  \n",
      "\n",
      "Fold: 9  Epoch: 690  Training loss = 1.9073  Validation loss = 8.4971  \n",
      "\n",
      "Fold: 9  Epoch: 691  Training loss = 1.9072  Validation loss = 8.4969  \n",
      "\n",
      "Fold: 9  Epoch: 692  Training loss = 1.9070  Validation loss = 8.4961  \n",
      "\n",
      "Fold: 9  Epoch: 693  Training loss = 1.9069  Validation loss = 8.4954  \n",
      "\n",
      "Fold: 9  Epoch: 694  Training loss = 1.9067  Validation loss = 8.4948  \n",
      "\n",
      "Fold: 9  Epoch: 695  Training loss = 1.9067  Validation loss = 8.4951  \n",
      "\n",
      "Fold: 9  Epoch: 696  Training loss = 1.9065  Validation loss = 8.4941  \n",
      "\n",
      "Fold: 9  Epoch: 697  Training loss = 1.9064  Validation loss = 8.4937  \n",
      "\n",
      "Fold: 9  Epoch: 698  Training loss = 1.9062  Validation loss = 8.4932  \n",
      "\n",
      "Fold: 9  Epoch: 699  Training loss = 1.9061  Validation loss = 8.4928  \n",
      "\n",
      "Fold: 9  Epoch: 700  Training loss = 1.9060  Validation loss = 8.4925  \n",
      "\n",
      "Fold: 9  Epoch: 701  Training loss = 1.9059  Validation loss = 8.4916  \n",
      "\n",
      "Fold: 9  Epoch: 702  Training loss = 1.9057  Validation loss = 8.4907  \n",
      "\n",
      "Fold: 9  Epoch: 703  Training loss = 1.9056  Validation loss = 8.4904  \n",
      "\n",
      "Fold: 9  Epoch: 704  Training loss = 1.9055  Validation loss = 8.4903  \n",
      "\n",
      "Fold: 9  Epoch: 705  Training loss = 1.9053  Validation loss = 8.4900  \n",
      "\n",
      "Fold: 9  Epoch: 706  Training loss = 1.9052  Validation loss = 8.4895  \n",
      "\n",
      "Fold: 9  Epoch: 707  Training loss = 1.9051  Validation loss = 8.4891  \n",
      "\n",
      "Fold: 9  Epoch: 708  Training loss = 1.9049  Validation loss = 8.4884  \n",
      "\n",
      "Fold: 9  Epoch: 709  Training loss = 1.9047  Validation loss = 8.4877  \n",
      "\n",
      "Fold: 9  Epoch: 710  Training loss = 1.9046  Validation loss = 8.4868  \n",
      "\n",
      "Fold: 9  Epoch: 711  Training loss = 1.9044  Validation loss = 8.4862  \n",
      "\n",
      "Fold: 9  Epoch: 712  Training loss = 1.9043  Validation loss = 8.4858  \n",
      "\n",
      "Fold: 9  Epoch: 713  Training loss = 1.9041  Validation loss = 8.4852  \n",
      "\n",
      "Fold: 9  Epoch: 714  Training loss = 1.9039  Validation loss = 8.4846  \n",
      "\n",
      "Fold: 9  Epoch: 715  Training loss = 1.9038  Validation loss = 8.4838  \n",
      "\n",
      "Fold: 9  Epoch: 716  Training loss = 1.9037  Validation loss = 8.4834  \n",
      "\n",
      "Fold: 9  Epoch: 717  Training loss = 1.9036  Validation loss = 8.4832  \n",
      "\n",
      "Fold: 9  Epoch: 718  Training loss = 1.9035  Validation loss = 8.4827  \n",
      "\n",
      "Fold: 9  Epoch: 719  Training loss = 1.9033  Validation loss = 8.4820  \n",
      "\n",
      "Fold: 9  Epoch: 720  Training loss = 1.9032  Validation loss = 8.4819  \n",
      "\n",
      "Fold: 9  Epoch: 721  Training loss = 1.9031  Validation loss = 8.4819  \n",
      "\n",
      "Fold: 9  Epoch: 722  Training loss = 1.9029  Validation loss = 8.4806  \n",
      "\n",
      "Fold: 9  Epoch: 723  Training loss = 1.9029  Validation loss = 8.4805  \n",
      "\n",
      "Fold: 9  Epoch: 724  Training loss = 1.9027  Validation loss = 8.4800  \n",
      "\n",
      "Fold: 9  Epoch: 725  Training loss = 1.9026  Validation loss = 8.4799  \n",
      "\n",
      "Fold: 9  Epoch: 726  Training loss = 1.9025  Validation loss = 8.4793  \n",
      "\n",
      "Fold: 9  Epoch: 727  Training loss = 1.9024  Validation loss = 8.4792  \n",
      "\n",
      "Fold: 9  Epoch: 728  Training loss = 1.9022  Validation loss = 8.4784  \n",
      "\n",
      "Fold: 9  Epoch: 729  Training loss = 1.9021  Validation loss = 8.4780  \n",
      "\n",
      "Fold: 9  Epoch: 730  Training loss = 1.9020  Validation loss = 8.4778  \n",
      "\n",
      "Fold: 9  Epoch: 731  Training loss = 1.9018  Validation loss = 8.4767  \n",
      "\n",
      "Fold: 9  Epoch: 732  Training loss = 1.9017  Validation loss = 8.4764  \n",
      "\n",
      "Fold: 9  Epoch: 733  Training loss = 1.9015  Validation loss = 8.4760  \n",
      "\n",
      "Fold: 9  Epoch: 734  Training loss = 1.9014  Validation loss = 8.4753  \n",
      "\n",
      "Fold: 9  Epoch: 735  Training loss = 1.9012  Validation loss = 8.4745  \n",
      "\n",
      "Fold: 9  Epoch: 736  Training loss = 1.9011  Validation loss = 8.4745  \n",
      "\n",
      "Fold: 9  Epoch: 737  Training loss = 1.9010  Validation loss = 8.4738  \n",
      "\n",
      "Fold: 9  Epoch: 738  Training loss = 1.9009  Validation loss = 8.4735  \n",
      "\n",
      "Fold: 9  Epoch: 739  Training loss = 1.9007  Validation loss = 8.4732  \n",
      "\n",
      "Fold: 9  Epoch: 740  Training loss = 1.9006  Validation loss = 8.4726  \n",
      "\n",
      "Fold: 9  Epoch: 741  Training loss = 1.9005  Validation loss = 8.4727  \n",
      "\n",
      "Fold: 9  Epoch: 742  Training loss = 1.9004  Validation loss = 8.4725  \n",
      "\n",
      "Fold: 9  Epoch: 743  Training loss = 1.9003  Validation loss = 8.4725  \n",
      "\n",
      "Fold: 9  Epoch: 744  Training loss = 1.9002  Validation loss = 8.4721  \n",
      "\n",
      "Fold: 9  Epoch: 745  Training loss = 1.9001  Validation loss = 8.4713  \n",
      "\n",
      "Fold: 9  Epoch: 746  Training loss = 1.9000  Validation loss = 8.4711  \n",
      "\n",
      "Fold: 9  Epoch: 747  Training loss = 1.8999  Validation loss = 8.4709  \n",
      "\n",
      "Fold: 9  Epoch: 748  Training loss = 1.8997  Validation loss = 8.4702  \n",
      "\n",
      "Fold: 9  Epoch: 749  Training loss = 1.8997  Validation loss = 8.4702  \n",
      "\n",
      "Fold: 9  Epoch: 750  Training loss = 1.8996  Validation loss = 8.4702  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 748  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.7922  Validation loss = 4.1218  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.7916  Validation loss = 4.1193  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.7641  Validation loss = 3.8844  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.7633  Validation loss = 3.8834  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.7626  Validation loss = 3.8823  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.7615  Validation loss = 3.8807  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.7606  Validation loss = 3.8795  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.7592  Validation loss = 3.8782  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.7587  Validation loss = 3.8777  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.7581  Validation loss = 3.8763  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.7567  Validation loss = 3.8739  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.7559  Validation loss = 3.8725  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.7548  Validation loss = 3.8705  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.7536  Validation loss = 3.8680  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 2.7528  Validation loss = 3.8670  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.7522  Validation loss = 3.8658  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 2.7513  Validation loss = 3.8641  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 2.7507  Validation loss = 3.8632  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 2.7499  Validation loss = 3.8617  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.7492  Validation loss = 3.8603  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 2.7487  Validation loss = 3.8594  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 2.7480  Validation loss = 3.8580  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 2.7474  Validation loss = 3.8569  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 2.7467  Validation loss = 3.8552  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 2.7463  Validation loss = 3.8544  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 2.7455  Validation loss = 3.8529  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 2.7453  Validation loss = 3.8525  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 2.7448  Validation loss = 3.8514  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 2.7442  Validation loss = 3.8502  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 2.7438  Validation loss = 3.8493  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 2.7434  Validation loss = 3.8483  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 2.7427  Validation loss = 3.8470  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 2.7424  Validation loss = 3.8462  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 2.7418  Validation loss = 3.8449  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 2.7413  Validation loss = 3.8439  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 2.7408  Validation loss = 3.8427  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 2.7402  Validation loss = 3.8417  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 2.7399  Validation loss = 3.8409  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 2.7392  Validation loss = 3.8396  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 2.7387  Validation loss = 3.8384  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 2.7382  Validation loss = 3.8372  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 2.7373  Validation loss = 3.8352  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 2.7366  Validation loss = 3.8336  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 2.7361  Validation loss = 3.8324  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 2.7354  Validation loss = 3.8305  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 2.7349  Validation loss = 3.8296  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 2.7343  Validation loss = 3.8281  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 2.7338  Validation loss = 3.8269  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 2.7336  Validation loss = 3.8267  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 2.7331  Validation loss = 3.8258  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 2.7328  Validation loss = 3.8252  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 2.7320  Validation loss = 3.8230  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 2.7315  Validation loss = 3.8220  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 2.7309  Validation loss = 3.8205  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 2.7305  Validation loss = 3.8199  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 2.7302  Validation loss = 3.8192  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 2.7296  Validation loss = 3.8177  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 2.7291  Validation loss = 3.8166  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 2.7290  Validation loss = 3.8165  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 2.7283  Validation loss = 3.8148  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 2.7280  Validation loss = 3.8141  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 2.7277  Validation loss = 3.8134  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 2.7275  Validation loss = 3.8131  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 2.7271  Validation loss = 3.8123  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 2.7269  Validation loss = 3.8120  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 2.7259  Validation loss = 3.8096  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 2.7257  Validation loss = 3.8094  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 2.7253  Validation loss = 3.8086  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 2.7246  Validation loss = 3.8068  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 2.7242  Validation loss = 3.8057  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 2.7235  Validation loss = 3.8039  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 2.7231  Validation loss = 3.8030  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 2.7226  Validation loss = 3.8020  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 2.7224  Validation loss = 3.8017  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 2.7222  Validation loss = 3.8012  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 2.7218  Validation loss = 3.8004  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 2.7213  Validation loss = 3.7992  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 2.7209  Validation loss = 3.7982  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 2.7206  Validation loss = 3.7976  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 2.7203  Validation loss = 3.7970  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 2.7199  Validation loss = 3.7959  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 2.7194  Validation loss = 3.7948  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 2.7190  Validation loss = 3.7941  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 2.7184  Validation loss = 3.7926  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 2.7178  Validation loss = 3.7910  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 2.7172  Validation loss = 3.7896  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 2.7168  Validation loss = 3.7885  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 2.7163  Validation loss = 3.7876  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 2.7160  Validation loss = 3.7869  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 2.7157  Validation loss = 3.7862  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 2.7150  Validation loss = 3.7845  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 2.7142  Validation loss = 3.7826  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 2.7136  Validation loss = 3.7809  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 2.7132  Validation loss = 3.7801  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 2.7127  Validation loss = 3.7788  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 2.7122  Validation loss = 3.7777  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 2.7118  Validation loss = 3.7767  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 2.7113  Validation loss = 3.7755  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 2.7107  Validation loss = 3.7738  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 2.7103  Validation loss = 3.7729  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 2.7098  Validation loss = 3.7716  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 2.7094  Validation loss = 3.7708  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 2.7090  Validation loss = 3.7698  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 2.7084  Validation loss = 3.7684  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 2.7080  Validation loss = 3.7675  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 2.7076  Validation loss = 3.7667  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 2.7071  Validation loss = 3.7653  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 2.7071  Validation loss = 3.7657  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 2.7066  Validation loss = 3.7646  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 2.7060  Validation loss = 3.7631  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 2.7054  Validation loss = 3.7616  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 2.7048  Validation loss = 3.7602  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 2.7042  Validation loss = 3.7587  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 2.7037  Validation loss = 3.7576  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 2.7034  Validation loss = 3.7570  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 2.7027  Validation loss = 3.7549  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 2.7022  Validation loss = 3.7536  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 2.7021  Validation loss = 3.7535  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 2.7018  Validation loss = 3.7529  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 2.7012  Validation loss = 3.7516  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 2.7008  Validation loss = 3.7506  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 2.7002  Validation loss = 3.7488  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 2.6997  Validation loss = 3.7477  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 2.6994  Validation loss = 3.7471  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 2.6991  Validation loss = 3.7464  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 2.6983  Validation loss = 3.7444  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 2.6980  Validation loss = 3.7434  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 2.6970  Validation loss = 3.7408  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 2.6967  Validation loss = 3.7399  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 2.6961  Validation loss = 3.7384  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 2.6955  Validation loss = 3.7369  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 2.6952  Validation loss = 3.7363  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 2.6950  Validation loss = 3.7359  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 2.6948  Validation loss = 3.7355  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 2.6939  Validation loss = 3.7332  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 2.6937  Validation loss = 3.7326  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 2.6933  Validation loss = 3.7316  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 2.6926  Validation loss = 3.7298  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 2.6922  Validation loss = 3.7287  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 2.6918  Validation loss = 3.7279  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 2.6916  Validation loss = 3.7274  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 2.6912  Validation loss = 3.7264  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 2.6908  Validation loss = 3.7255  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 2.6906  Validation loss = 3.7252  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 2.6900  Validation loss = 3.7236  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 2.6896  Validation loss = 3.7229  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 2.6892  Validation loss = 3.7218  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 2.6889  Validation loss = 3.7210  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 2.6886  Validation loss = 3.7206  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 2.6883  Validation loss = 3.7200  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 2.6875  Validation loss = 3.7179  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 2.6871  Validation loss = 3.7168  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 2.6866  Validation loss = 3.7156  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 2.6861  Validation loss = 3.7146  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 2.6858  Validation loss = 3.7141  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 2.6855  Validation loss = 3.7133  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 2.6852  Validation loss = 3.7123  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 2.6846  Validation loss = 3.7109  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 2.6841  Validation loss = 3.7097  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 2.6838  Validation loss = 3.7089  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 2.6833  Validation loss = 3.7078  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 2.6830  Validation loss = 3.7071  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 2.6824  Validation loss = 3.7054  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 2.6819  Validation loss = 3.7042  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 2.6814  Validation loss = 3.7029  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 2.6810  Validation loss = 3.7022  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 2.6804  Validation loss = 3.7004  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 2.6802  Validation loss = 3.7000  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 2.6798  Validation loss = 3.6992  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 2.6794  Validation loss = 3.6983  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 2.6790  Validation loss = 3.6973  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 2.6787  Validation loss = 3.6965  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 2.6784  Validation loss = 3.6959  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 2.6778  Validation loss = 3.6945  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 2.6773  Validation loss = 3.6930  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 2.6771  Validation loss = 3.6926  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 2.6768  Validation loss = 3.6920  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 2.6764  Validation loss = 3.6907  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 2.6761  Validation loss = 3.6903  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 2.6758  Validation loss = 3.6895  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 2.6751  Validation loss = 3.6875  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 2.6747  Validation loss = 3.6863  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 2.6744  Validation loss = 3.6856  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 2.6739  Validation loss = 3.6843  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 2.6735  Validation loss = 3.6831  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 2.6730  Validation loss = 3.6816  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 2.6728  Validation loss = 3.6812  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 2.6723  Validation loss = 3.6798  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 2.6717  Validation loss = 3.6780  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 2.6715  Validation loss = 3.6774  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 2.6711  Validation loss = 3.6759  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 2.6710  Validation loss = 3.6761  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 2.6705  Validation loss = 3.6750  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 2.6704  Validation loss = 3.6747  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 2.6697  Validation loss = 3.6720  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 2.6693  Validation loss = 3.6708  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 2.6688  Validation loss = 3.6697  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 2.6686  Validation loss = 3.6696  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 2.6684  Validation loss = 3.6696  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 2.6682  Validation loss = 3.6691  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 2.6681  Validation loss = 3.6695  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 2.6678  Validation loss = 3.6676  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 2.6672  Validation loss = 3.6656  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 2.6668  Validation loss = 3.6633  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 2.6664  Validation loss = 3.6626  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 2.6660  Validation loss = 3.6611  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 2.6657  Validation loss = 3.6603  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 2.6653  Validation loss = 3.6585  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 2.6651  Validation loss = 3.6585  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 2.6648  Validation loss = 3.6573  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 2.6644  Validation loss = 3.6564  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 2.6641  Validation loss = 3.6561  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 2.6637  Validation loss = 3.6553  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 2.6633  Validation loss = 3.6534  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 2.6630  Validation loss = 3.6539  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 2.6627  Validation loss = 3.6532  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 2.6624  Validation loss = 3.6527  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 2.6619  Validation loss = 3.6505  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 2.6616  Validation loss = 3.6493  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 2.6613  Validation loss = 3.6474  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 2.6609  Validation loss = 3.6461  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 2.6606  Validation loss = 3.6452  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 2.6601  Validation loss = 3.6457  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 2.6599  Validation loss = 3.6449  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 2.6595  Validation loss = 3.6447  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 2.6592  Validation loss = 3.6431  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 2.6589  Validation loss = 3.6429  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 2.6585  Validation loss = 3.6420  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 2.6578  Validation loss = 3.6406  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 2.6575  Validation loss = 3.6394  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 2.6568  Validation loss = 3.6365  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 2.6564  Validation loss = 3.6355  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 2.6559  Validation loss = 3.6349  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 2.6556  Validation loss = 3.6335  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 2.6552  Validation loss = 3.6318  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 2.6549  Validation loss = 3.6300  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 2.6545  Validation loss = 3.6269  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 2.6543  Validation loss = 3.6241  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 2.6540  Validation loss = 3.6264  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 2.6537  Validation loss = 3.6252  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 2.6532  Validation loss = 3.6260  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 2.6529  Validation loss = 3.6254  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 2.6526  Validation loss = 3.6242  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 2.6522  Validation loss = 3.6221  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 2.6515  Validation loss = 3.6174  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 2.6514  Validation loss = 3.6170  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 2.6508  Validation loss = 3.6174  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 2.6502  Validation loss = 3.6183  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 2.6498  Validation loss = 3.6177  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 2.6491  Validation loss = 3.6152  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 2.6486  Validation loss = 3.6142  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 2.6480  Validation loss = 3.6124  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 2.6475  Validation loss = 3.6114  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 2.6470  Validation loss = 3.6106  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 2.6466  Validation loss = 3.6095  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 2.6461  Validation loss = 3.6054  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 2.6458  Validation loss = 3.6056  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 2.6455  Validation loss = 3.6054  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 2.6450  Validation loss = 3.6052  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 2.6447  Validation loss = 3.6050  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 2.6442  Validation loss = 3.6013  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 2.6439  Validation loss = 3.5996  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 2.6435  Validation loss = 3.5990  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 2.6432  Validation loss = 3.5999  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 2.6428  Validation loss = 3.6000  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 2.6422  Validation loss = 3.5987  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 2.6417  Validation loss = 3.5974  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 2.6411  Validation loss = 3.5940  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 2.6409  Validation loss = 3.5942  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 2.6404  Validation loss = 3.5914  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 2.6400  Validation loss = 3.5902  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 2.6395  Validation loss = 3.5881  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 2.6391  Validation loss = 3.5878  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 2.6386  Validation loss = 3.5872  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 2.6380  Validation loss = 3.5847  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 2.6377  Validation loss = 3.5832  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 2.6375  Validation loss = 3.5837  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 2.6373  Validation loss = 3.5835  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 2.6371  Validation loss = 3.5835  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 2.6368  Validation loss = 3.5815  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 2.6364  Validation loss = 3.5774  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 2.6360  Validation loss = 3.5776  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 2.6358  Validation loss = 3.5766  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 2.6354  Validation loss = 3.5737  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 2.6349  Validation loss = 3.5723  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 2.6346  Validation loss = 3.5714  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 2.6342  Validation loss = 3.5710  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 2.6340  Validation loss = 3.5708  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 2.6336  Validation loss = 3.5667  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 2.6334  Validation loss = 3.5690  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 2.6327  Validation loss = 3.5700  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 2.6323  Validation loss = 3.5684  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 2.6319  Validation loss = 3.5683  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 2.6314  Validation loss = 3.5668  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 2.6311  Validation loss = 3.5651  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 2.6308  Validation loss = 3.5644  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 2.6303  Validation loss = 3.5631  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 2.6301  Validation loss = 3.5646  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 2.6298  Validation loss = 3.5643  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 2.6296  Validation loss = 3.5638  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 2.6291  Validation loss = 3.5624  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 2.6288  Validation loss = 3.5623  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 2.6285  Validation loss = 3.5609  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 2.6280  Validation loss = 3.5599  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 2.6278  Validation loss = 3.5591  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 2.6274  Validation loss = 3.5571  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 2.6267  Validation loss = 3.5540  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 2.6263  Validation loss = 3.5533  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 2.6260  Validation loss = 3.5526  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 2.6258  Validation loss = 3.5507  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 2.6253  Validation loss = 3.5519  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 2.6250  Validation loss = 3.5502  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 2.6247  Validation loss = 3.5475  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 2.6244  Validation loss = 3.5483  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 2.6241  Validation loss = 3.5466  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 2.6237  Validation loss = 3.5455  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 2.6232  Validation loss = 3.5448  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 2.6227  Validation loss = 3.5455  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 2.6224  Validation loss = 3.5458  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 2.6220  Validation loss = 3.5448  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 2.6216  Validation loss = 3.5441  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 2.6215  Validation loss = 3.5447  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 2.6211  Validation loss = 3.5433  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 2.6206  Validation loss = 3.5408  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 2.6201  Validation loss = 3.5386  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 2.6197  Validation loss = 3.5374  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 2.6193  Validation loss = 3.5365  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 2.6187  Validation loss = 3.5351  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 2.6185  Validation loss = 3.5344  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 2.6179  Validation loss = 3.5325  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 2.6175  Validation loss = 3.5329  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 2.6173  Validation loss = 3.5318  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 2.6169  Validation loss = 3.5297  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 2.6166  Validation loss = 3.5285  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 2.6162  Validation loss = 3.5285  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 2.6159  Validation loss = 3.5281  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 2.6156  Validation loss = 3.5278  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 2.6153  Validation loss = 3.5262  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 2.6148  Validation loss = 3.5240  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 2.6145  Validation loss = 3.5231  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 2.6138  Validation loss = 3.5209  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 2.6136  Validation loss = 3.5212  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 2.6133  Validation loss = 3.5207  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 2.6127  Validation loss = 3.5184  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 2.6122  Validation loss = 3.5181  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 2.6117  Validation loss = 3.5159  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 2.6114  Validation loss = 3.5149  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 2.6109  Validation loss = 3.5118  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 2.6107  Validation loss = 3.5108  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 2.6103  Validation loss = 3.5101  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 2.6099  Validation loss = 3.5091  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 2.6094  Validation loss = 3.5077  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 2.6090  Validation loss = 3.5053  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 2.6088  Validation loss = 3.5031  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 2.6082  Validation loss = 3.4998  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 2.6078  Validation loss = 3.4991  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 2.6074  Validation loss = 3.4957  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 2.6069  Validation loss = 3.4972  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 2.6067  Validation loss = 3.4960  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 2.6064  Validation loss = 3.4931  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 2.6060  Validation loss = 3.4914  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 2.6058  Validation loss = 3.4933  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 2.6055  Validation loss = 3.4955  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 2.6050  Validation loss = 3.4935  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 2.6047  Validation loss = 3.4912  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 2.6044  Validation loss = 3.4907  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 2.6041  Validation loss = 3.4923  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 2.6038  Validation loss = 3.4918  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 2.6035  Validation loss = 3.4908  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 2.6031  Validation loss = 3.4882  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 2.6028  Validation loss = 3.4897  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 2.6025  Validation loss = 3.4875  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 2.6021  Validation loss = 3.4867  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 2.6018  Validation loss = 3.4861  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 2.6014  Validation loss = 3.4849  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 2.6013  Validation loss = 3.4849  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 2.6011  Validation loss = 3.4847  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 2.6007  Validation loss = 3.4831  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 2.6004  Validation loss = 3.4825  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 2.6000  Validation loss = 3.4821  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 2.5998  Validation loss = 3.4807  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 2.5993  Validation loss = 3.4790  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 2.5989  Validation loss = 3.4774  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 2.5986  Validation loss = 3.4779  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 2.5982  Validation loss = 3.4751  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 2.5977  Validation loss = 3.4728  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 2.5973  Validation loss = 3.4733  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 2.5971  Validation loss = 3.4743  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 2.5970  Validation loss = 3.4734  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 2.5967  Validation loss = 3.4729  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 2.5963  Validation loss = 3.4705  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 2.5959  Validation loss = 3.4677  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 2.5955  Validation loss = 3.4672  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 2.5952  Validation loss = 3.4657  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 2.5949  Validation loss = 3.4687  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 2.5946  Validation loss = 3.4685  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 2.5944  Validation loss = 3.4677  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 2.5939  Validation loss = 3.4675  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 2.5936  Validation loss = 3.4651  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 2.5930  Validation loss = 3.4633  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 2.5927  Validation loss = 3.4625  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 2.5924  Validation loss = 3.4614  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 2.5922  Validation loss = 3.4614  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 2.5920  Validation loss = 3.4609  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 2.5917  Validation loss = 3.4613  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 2.5912  Validation loss = 3.4600  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 2.5908  Validation loss = 3.4570  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 2.5905  Validation loss = 3.4563  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 2.5900  Validation loss = 3.4569  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 2.5899  Validation loss = 3.4563  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 2.5896  Validation loss = 3.4550  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 2.5892  Validation loss = 3.4540  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 2.5890  Validation loss = 3.4530  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 2.5886  Validation loss = 3.4534  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 2.5884  Validation loss = 3.4532  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 2.5882  Validation loss = 3.4530  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 2.5878  Validation loss = 3.4514  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 2.5875  Validation loss = 3.4506  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 2.5874  Validation loss = 3.4505  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 2.5870  Validation loss = 3.4495  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 2.5868  Validation loss = 3.4479  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 2.5865  Validation loss = 3.4473  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 2.5863  Validation loss = 3.4473  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 2.5859  Validation loss = 3.4470  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 2.5855  Validation loss = 3.4453  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 2.5851  Validation loss = 3.4446  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 2.5847  Validation loss = 3.4423  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 2.5845  Validation loss = 3.4415  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 2.5843  Validation loss = 3.4410  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 2.5840  Validation loss = 3.4408  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 2.5836  Validation loss = 3.4400  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 2.5832  Validation loss = 3.4383  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 2.5828  Validation loss = 3.4387  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 2.5826  Validation loss = 3.4391  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 2.5824  Validation loss = 3.4389  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 2.5820  Validation loss = 3.4388  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 2.5818  Validation loss = 3.4379  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 2.5815  Validation loss = 3.4380  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 2.5811  Validation loss = 3.4367  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 2.5810  Validation loss = 3.4359  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 2.5807  Validation loss = 3.4348  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 2.5802  Validation loss = 3.4318  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 2.5798  Validation loss = 3.4321  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 2.5797  Validation loss = 3.4320  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 2.5795  Validation loss = 3.4322  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 2.5791  Validation loss = 3.4302  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 2.5787  Validation loss = 3.4288  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 2.5782  Validation loss = 3.4260  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 2.5778  Validation loss = 3.4242  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 2.5774  Validation loss = 3.4222  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 2.5768  Validation loss = 3.4203  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 2.5764  Validation loss = 3.4187  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 2.5761  Validation loss = 3.4182  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 2.5757  Validation loss = 3.4181  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 2.5754  Validation loss = 3.4174  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 2.5749  Validation loss = 3.4163  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 2.5744  Validation loss = 3.4149  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 2.5741  Validation loss = 3.4153  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 2.5737  Validation loss = 3.4144  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 2.5733  Validation loss = 3.4128  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 2.5730  Validation loss = 3.4115  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 2.5727  Validation loss = 3.4102  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 2.5722  Validation loss = 3.4106  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 2.5720  Validation loss = 3.4103  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 2.5715  Validation loss = 3.4089  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 2.5712  Validation loss = 3.4092  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 2.5708  Validation loss = 3.4056  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 2.5705  Validation loss = 3.4049  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 2.5702  Validation loss = 3.4028  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 2.5698  Validation loss = 3.4029  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 2.5695  Validation loss = 3.4028  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 2.5693  Validation loss = 3.4028  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 2.5691  Validation loss = 3.4022  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 2.5689  Validation loss = 3.4024  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 2.5685  Validation loss = 3.4008  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 2.5681  Validation loss = 3.4006  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 2.5679  Validation loss = 3.4009  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 2.5675  Validation loss = 3.4002  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 2.5670  Validation loss = 3.3992  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 2.5668  Validation loss = 3.3983  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 2.5665  Validation loss = 3.3955  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 2.5662  Validation loss = 3.3948  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 2.5660  Validation loss = 3.3946  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 2.5657  Validation loss = 3.3934  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 2.5653  Validation loss = 3.3910  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 2.5650  Validation loss = 3.3909  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 2.5643  Validation loss = 3.3879  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 2.5639  Validation loss = 3.3874  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 2.5635  Validation loss = 3.3863  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 2.5632  Validation loss = 3.3846  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 2.5630  Validation loss = 3.3837  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 2.5626  Validation loss = 3.3813  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 2.5624  Validation loss = 3.3807  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 2.5619  Validation loss = 3.3785  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 2.5614  Validation loss = 3.3772  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 2.5613  Validation loss = 3.3770  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 2.5611  Validation loss = 3.3781  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 2.5609  Validation loss = 3.3792  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 2.5606  Validation loss = 3.3795  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 2.5599  Validation loss = 3.3765  \n",
      "\n",
      "Fold: 10  Epoch: 501  Training loss = 2.5595  Validation loss = 3.3762  \n",
      "\n",
      "Fold: 10  Epoch: 502  Training loss = 2.5592  Validation loss = 3.3759  \n",
      "\n",
      "Fold: 10  Epoch: 503  Training loss = 2.5589  Validation loss = 3.3750  \n",
      "\n",
      "Fold: 10  Epoch: 504  Training loss = 2.5584  Validation loss = 3.3744  \n",
      "\n",
      "Fold: 10  Epoch: 505  Training loss = 2.5582  Validation loss = 3.3731  \n",
      "\n",
      "Fold: 10  Epoch: 506  Training loss = 2.5578  Validation loss = 3.3724  \n",
      "\n",
      "Fold: 10  Epoch: 507  Training loss = 2.5574  Validation loss = 3.3713  \n",
      "\n",
      "Fold: 10  Epoch: 508  Training loss = 2.5571  Validation loss = 3.3703  \n",
      "\n",
      "Fold: 10  Epoch: 509  Training loss = 2.5567  Validation loss = 3.3690  \n",
      "\n",
      "Fold: 10  Epoch: 510  Training loss = 2.5564  Validation loss = 3.3688  \n",
      "\n",
      "Fold: 10  Epoch: 511  Training loss = 2.5560  Validation loss = 3.3678  \n",
      "\n",
      "Fold: 10  Epoch: 512  Training loss = 2.5557  Validation loss = 3.3668  \n",
      "\n",
      "Fold: 10  Epoch: 513  Training loss = 2.5553  Validation loss = 3.3655  \n",
      "\n",
      "Fold: 10  Epoch: 514  Training loss = 2.5551  Validation loss = 3.3658  \n",
      "\n",
      "Fold: 10  Epoch: 515  Training loss = 2.5546  Validation loss = 3.3640  \n",
      "\n",
      "Fold: 10  Epoch: 516  Training loss = 2.5542  Validation loss = 3.3621  \n",
      "\n",
      "Fold: 10  Epoch: 517  Training loss = 2.5538  Validation loss = 3.3598  \n",
      "\n",
      "Fold: 10  Epoch: 518  Training loss = 2.5536  Validation loss = 3.3604  \n",
      "\n",
      "Fold: 10  Epoch: 519  Training loss = 2.5534  Validation loss = 3.3608  \n",
      "\n",
      "Fold: 10  Epoch: 520  Training loss = 2.5532  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 10  Epoch: 521  Training loss = 2.5527  Validation loss = 3.3578  \n",
      "\n",
      "Fold: 10  Epoch: 522  Training loss = 2.5525  Validation loss = 3.3575  \n",
      "\n",
      "Fold: 10  Epoch: 523  Training loss = 2.5521  Validation loss = 3.3573  \n",
      "\n",
      "Fold: 10  Epoch: 524  Training loss = 2.5519  Validation loss = 3.3571  \n",
      "\n",
      "Fold: 10  Epoch: 525  Training loss = 2.5516  Validation loss = 3.3555  \n",
      "\n",
      "Fold: 10  Epoch: 526  Training loss = 2.5513  Validation loss = 3.3548  \n",
      "\n",
      "Fold: 10  Epoch: 527  Training loss = 2.5510  Validation loss = 3.3537  \n",
      "\n",
      "Fold: 10  Epoch: 528  Training loss = 2.5508  Validation loss = 3.3537  \n",
      "\n",
      "Fold: 10  Epoch: 529  Training loss = 2.5505  Validation loss = 3.3530  \n",
      "\n",
      "Fold: 10  Epoch: 530  Training loss = 2.5501  Validation loss = 3.3504  \n",
      "\n",
      "Fold: 10  Epoch: 531  Training loss = 2.5500  Validation loss = 3.3504  \n",
      "\n",
      "Fold: 10  Epoch: 532  Training loss = 2.5496  Validation loss = 3.3487  \n",
      "\n",
      "Fold: 10  Epoch: 533  Training loss = 2.5493  Validation loss = 3.3470  \n",
      "\n",
      "Fold: 10  Epoch: 534  Training loss = 2.5490  Validation loss = 3.3478  \n",
      "\n",
      "Fold: 10  Epoch: 535  Training loss = 2.5487  Validation loss = 3.3460  \n",
      "\n",
      "Fold: 10  Epoch: 536  Training loss = 2.5484  Validation loss = 3.3451  \n",
      "\n",
      "Fold: 10  Epoch: 537  Training loss = 2.5480  Validation loss = 3.3426  \n",
      "\n",
      "Fold: 10  Epoch: 538  Training loss = 2.5477  Validation loss = 3.3427  \n",
      "\n",
      "Fold: 10  Epoch: 539  Training loss = 2.5476  Validation loss = 3.3431  \n",
      "\n",
      "Fold: 10  Epoch: 540  Training loss = 2.5472  Validation loss = 3.3423  \n",
      "\n",
      "Fold: 10  Epoch: 541  Training loss = 2.5469  Validation loss = 3.3416  \n",
      "\n",
      "Fold: 10  Epoch: 542  Training loss = 2.5466  Validation loss = 3.3423  \n",
      "\n",
      "Fold: 10  Epoch: 543  Training loss = 2.5463  Validation loss = 3.3417  \n",
      "\n",
      "Fold: 10  Epoch: 544  Training loss = 2.5461  Validation loss = 3.3419  \n",
      "\n",
      "Fold: 10  Epoch: 545  Training loss = 2.5458  Validation loss = 3.3405  \n",
      "\n",
      "Fold: 10  Epoch: 546  Training loss = 2.5454  Validation loss = 3.3400  \n",
      "\n",
      "Fold: 10  Epoch: 547  Training loss = 2.5451  Validation loss = 3.3396  \n",
      "\n",
      "Fold: 10  Epoch: 548  Training loss = 2.5447  Validation loss = 3.3377  \n",
      "\n",
      "Fold: 10  Epoch: 549  Training loss = 2.5443  Validation loss = 3.3356  \n",
      "\n",
      "Fold: 10  Epoch: 550  Training loss = 2.5441  Validation loss = 3.3339  \n",
      "\n",
      "Fold: 10  Epoch: 551  Training loss = 2.5438  Validation loss = 3.3329  \n",
      "\n",
      "Fold: 10  Epoch: 552  Training loss = 2.5434  Validation loss = 3.3320  \n",
      "\n",
      "Fold: 10  Epoch: 553  Training loss = 2.5432  Validation loss = 3.3323  \n",
      "\n",
      "Fold: 10  Epoch: 554  Training loss = 2.5430  Validation loss = 3.3322  \n",
      "\n",
      "Fold: 10  Epoch: 555  Training loss = 2.5427  Validation loss = 3.3324  \n",
      "\n",
      "Fold: 10  Epoch: 556  Training loss = 2.5426  Validation loss = 3.3326  \n",
      "\n",
      "Fold: 10  Epoch: 557  Training loss = 2.5420  Validation loss = 3.3308  \n",
      "\n",
      "Fold: 10  Epoch: 558  Training loss = 2.5418  Validation loss = 3.3299  \n",
      "\n",
      "Fold: 10  Epoch: 559  Training loss = 2.5417  Validation loss = 3.3300  \n",
      "\n",
      "Fold: 10  Epoch: 560  Training loss = 2.5413  Validation loss = 3.3290  \n",
      "\n",
      "Fold: 10  Epoch: 561  Training loss = 2.5408  Validation loss = 3.3272  \n",
      "\n",
      "Fold: 10  Epoch: 562  Training loss = 2.5406  Validation loss = 3.3276  \n",
      "\n",
      "Fold: 10  Epoch: 563  Training loss = 2.5403  Validation loss = 3.3272  \n",
      "\n",
      "Fold: 10  Epoch: 564  Training loss = 2.5399  Validation loss = 3.3257  \n",
      "\n",
      "Fold: 10  Epoch: 565  Training loss = 2.5395  Validation loss = 3.3243  \n",
      "\n",
      "Fold: 10  Epoch: 566  Training loss = 2.5391  Validation loss = 3.3233  \n",
      "\n",
      "Fold: 10  Epoch: 567  Training loss = 2.5387  Validation loss = 3.3228  \n",
      "\n",
      "Fold: 10  Epoch: 568  Training loss = 2.5383  Validation loss = 3.3214  \n",
      "\n",
      "Fold: 10  Epoch: 569  Training loss = 2.5380  Validation loss = 3.3202  \n",
      "\n",
      "Fold: 10  Epoch: 570  Training loss = 2.5377  Validation loss = 3.3203  \n",
      "\n",
      "Fold: 10  Epoch: 571  Training loss = 2.5372  Validation loss = 3.3193  \n",
      "\n",
      "Fold: 10  Epoch: 572  Training loss = 2.5369  Validation loss = 3.3192  \n",
      "\n",
      "Fold: 10  Epoch: 573  Training loss = 2.5366  Validation loss = 3.3180  \n",
      "\n",
      "Fold: 10  Epoch: 574  Training loss = 2.5364  Validation loss = 3.3183  \n",
      "\n",
      "Fold: 10  Epoch: 575  Training loss = 2.5362  Validation loss = 3.3169  \n",
      "\n",
      "Fold: 10  Epoch: 576  Training loss = 2.5358  Validation loss = 3.3163  \n",
      "\n",
      "Fold: 10  Epoch: 577  Training loss = 2.5355  Validation loss = 3.3149  \n",
      "\n",
      "Fold: 10  Epoch: 578  Training loss = 2.5352  Validation loss = 3.3149  \n",
      "\n",
      "Fold: 10  Epoch: 579  Training loss = 2.5350  Validation loss = 3.3152  \n",
      "\n",
      "Fold: 10  Epoch: 580  Training loss = 2.5347  Validation loss = 3.3141  \n",
      "\n",
      "Fold: 10  Epoch: 581  Training loss = 2.5343  Validation loss = 3.3126  \n",
      "\n",
      "Fold: 10  Epoch: 582  Training loss = 2.5337  Validation loss = 3.3100  \n",
      "\n",
      "Fold: 10  Epoch: 583  Training loss = 2.5332  Validation loss = 3.3078  \n",
      "\n",
      "Fold: 10  Epoch: 584  Training loss = 2.5326  Validation loss = 3.3050  \n",
      "\n",
      "Fold: 10  Epoch: 585  Training loss = 2.5323  Validation loss = 3.3038  \n",
      "\n",
      "Fold: 10  Epoch: 586  Training loss = 2.5319  Validation loss = 3.3028  \n",
      "\n",
      "Fold: 10  Epoch: 587  Training loss = 2.5316  Validation loss = 3.3022  \n",
      "\n",
      "Fold: 10  Epoch: 588  Training loss = 2.5312  Validation loss = 3.3010  \n",
      "\n",
      "Fold: 10  Epoch: 589  Training loss = 2.5309  Validation loss = 3.3005  \n",
      "\n",
      "Fold: 10  Epoch: 590  Training loss = 2.5306  Validation loss = 3.3003  \n",
      "\n",
      "Fold: 10  Epoch: 591  Training loss = 2.5300  Validation loss = 3.2976  \n",
      "\n",
      "Fold: 10  Epoch: 592  Training loss = 2.5296  Validation loss = 3.2967  \n",
      "\n",
      "Fold: 10  Epoch: 593  Training loss = 2.5292  Validation loss = 3.2949  \n",
      "\n",
      "Fold: 10  Epoch: 594  Training loss = 2.5288  Validation loss = 3.2940  \n",
      "\n",
      "Fold: 10  Epoch: 595  Training loss = 2.5285  Validation loss = 3.2926  \n",
      "\n",
      "Fold: 10  Epoch: 596  Training loss = 2.5282  Validation loss = 3.2929  \n",
      "\n",
      "Fold: 10  Epoch: 597  Training loss = 2.5276  Validation loss = 3.2906  \n",
      "\n",
      "Fold: 10  Epoch: 598  Training loss = 2.5273  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 10  Epoch: 599  Training loss = 2.5268  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 10  Epoch: 600  Training loss = 2.5262  Validation loss = 3.2863  \n",
      "\n",
      "Fold: 10  Epoch: 601  Training loss = 2.5259  Validation loss = 3.2860  \n",
      "\n",
      "Fold: 10  Epoch: 602  Training loss = 2.5255  Validation loss = 3.2854  \n",
      "\n",
      "Fold: 10  Epoch: 603  Training loss = 2.5253  Validation loss = 3.2846  \n",
      "\n",
      "Fold: 10  Epoch: 604  Training loss = 2.5249  Validation loss = 3.2848  \n",
      "\n",
      "Fold: 10  Epoch: 605  Training loss = 2.5246  Validation loss = 3.2838  \n",
      "\n",
      "Fold: 10  Epoch: 606  Training loss = 2.5243  Validation loss = 3.2835  \n",
      "\n",
      "Fold: 10  Epoch: 607  Training loss = 2.5241  Validation loss = 3.2840  \n",
      "\n",
      "Fold: 10  Epoch: 608  Training loss = 2.5238  Validation loss = 3.2833  \n",
      "\n",
      "Fold: 10  Epoch: 609  Training loss = 2.5236  Validation loss = 3.2832  \n",
      "\n",
      "Fold: 10  Epoch: 610  Training loss = 2.5232  Validation loss = 3.2819  \n",
      "\n",
      "Fold: 10  Epoch: 611  Training loss = 2.5228  Validation loss = 3.2802  \n",
      "\n",
      "Fold: 10  Epoch: 612  Training loss = 2.5224  Validation loss = 3.2796  \n",
      "\n",
      "Fold: 10  Epoch: 613  Training loss = 2.5223  Validation loss = 3.2796  \n",
      "\n",
      "Fold: 10  Epoch: 614  Training loss = 2.5219  Validation loss = 3.2788  \n",
      "\n",
      "Fold: 10  Epoch: 615  Training loss = 2.5214  Validation loss = 3.2774  \n",
      "\n",
      "Fold: 10  Epoch: 616  Training loss = 2.5213  Validation loss = 3.2772  \n",
      "\n",
      "Fold: 10  Epoch: 617  Training loss = 2.5211  Validation loss = 3.2777  \n",
      "\n",
      "Fold: 10  Epoch: 618  Training loss = 2.5206  Validation loss = 3.2757  \n",
      "\n",
      "Fold: 10  Epoch: 619  Training loss = 2.5203  Validation loss = 3.2753  \n",
      "\n",
      "Fold: 10  Epoch: 620  Training loss = 2.5201  Validation loss = 3.2746  \n",
      "\n",
      "Fold: 10  Epoch: 621  Training loss = 2.5198  Validation loss = 3.2741  \n",
      "\n",
      "Fold: 10  Epoch: 622  Training loss = 2.5195  Validation loss = 3.2730  \n",
      "\n",
      "Fold: 10  Epoch: 623  Training loss = 2.5190  Validation loss = 3.2710  \n",
      "\n",
      "Fold: 10  Epoch: 624  Training loss = 2.5187  Validation loss = 3.2699  \n",
      "\n",
      "Fold: 10  Epoch: 625  Training loss = 2.5185  Validation loss = 3.2692  \n",
      "\n",
      "Fold: 10  Epoch: 626  Training loss = 2.5181  Validation loss = 3.2688  \n",
      "\n",
      "Fold: 10  Epoch: 627  Training loss = 2.5177  Validation loss = 3.2672  \n",
      "\n",
      "Fold: 10  Epoch: 628  Training loss = 2.5172  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 10  Epoch: 629  Training loss = 2.5168  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 10  Epoch: 630  Training loss = 2.5166  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 10  Epoch: 631  Training loss = 2.5162  Validation loss = 3.2618  \n",
      "\n",
      "Fold: 10  Epoch: 632  Training loss = 2.5159  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 10  Epoch: 633  Training loss = 2.5156  Validation loss = 3.2605  \n",
      "\n",
      "Fold: 10  Epoch: 634  Training loss = 2.5153  Validation loss = 3.2600  \n",
      "\n",
      "Fold: 10  Epoch: 635  Training loss = 2.5148  Validation loss = 3.2589  \n",
      "\n",
      "Fold: 10  Epoch: 636  Training loss = 2.5146  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 10  Epoch: 637  Training loss = 2.5143  Validation loss = 3.2577  \n",
      "\n",
      "Fold: 10  Epoch: 638  Training loss = 2.5139  Validation loss = 3.2562  \n",
      "\n",
      "Fold: 10  Epoch: 639  Training loss = 2.5136  Validation loss = 3.2558  \n",
      "\n",
      "Fold: 10  Epoch: 640  Training loss = 2.5134  Validation loss = 3.2557  \n",
      "\n",
      "Fold: 10  Epoch: 641  Training loss = 2.5131  Validation loss = 3.2552  \n",
      "\n",
      "Fold: 10  Epoch: 642  Training loss = 2.5129  Validation loss = 3.2555  \n",
      "\n",
      "Fold: 10  Epoch: 643  Training loss = 2.5127  Validation loss = 3.2549  \n",
      "\n",
      "Fold: 10  Epoch: 644  Training loss = 2.5125  Validation loss = 3.2539  \n",
      "\n",
      "Fold: 10  Epoch: 645  Training loss = 2.5123  Validation loss = 3.2540  \n",
      "\n",
      "Fold: 10  Epoch: 646  Training loss = 2.5121  Validation loss = 3.2540  \n",
      "\n",
      "Fold: 10  Epoch: 647  Training loss = 2.5118  Validation loss = 3.2530  \n",
      "\n",
      "Fold: 10  Epoch: 648  Training loss = 2.5117  Validation loss = 3.2534  \n",
      "\n",
      "Fold: 10  Epoch: 649  Training loss = 2.5113  Validation loss = 3.2521  \n",
      "\n",
      "Fold: 10  Epoch: 650  Training loss = 2.5108  Validation loss = 3.2504  \n",
      "\n",
      "Fold: 10  Epoch: 651  Training loss = 2.5104  Validation loss = 3.2493  \n",
      "\n",
      "Fold: 10  Epoch: 652  Training loss = 2.5101  Validation loss = 3.2488  \n",
      "\n",
      "Fold: 10  Epoch: 653  Training loss = 2.5099  Validation loss = 3.2487  \n",
      "\n",
      "Fold: 10  Epoch: 654  Training loss = 2.5096  Validation loss = 3.2482  \n",
      "\n",
      "Fold: 10  Epoch: 655  Training loss = 2.5092  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 10  Epoch: 656  Training loss = 2.5086  Validation loss = 3.2444  \n",
      "\n",
      "Fold: 10  Epoch: 657  Training loss = 2.5085  Validation loss = 3.2442  \n",
      "\n",
      "Fold: 10  Epoch: 658  Training loss = 2.5081  Validation loss = 3.2427  \n",
      "\n",
      "Fold: 10  Epoch: 659  Training loss = 2.5078  Validation loss = 3.2426  \n",
      "\n",
      "Fold: 10  Epoch: 660  Training loss = 2.5075  Validation loss = 3.2416  \n",
      "\n",
      "Fold: 10  Epoch: 661  Training loss = 2.5071  Validation loss = 3.2405  \n",
      "\n",
      "Fold: 10  Epoch: 662  Training loss = 2.5069  Validation loss = 3.2410  \n",
      "\n",
      "Fold: 10  Epoch: 663  Training loss = 2.5064  Validation loss = 3.2401  \n",
      "\n",
      "Fold: 10  Epoch: 664  Training loss = 2.5062  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 10  Epoch: 665  Training loss = 2.5060  Validation loss = 3.2401  \n",
      "\n",
      "Fold: 10  Epoch: 666  Training loss = 2.5057  Validation loss = 3.2395  \n",
      "\n",
      "Fold: 10  Epoch: 667  Training loss = 2.5054  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 10  Epoch: 668  Training loss = 2.5052  Validation loss = 3.2404  \n",
      "\n",
      "Fold: 10  Epoch: 669  Training loss = 2.5048  Validation loss = 3.2388  \n",
      "\n",
      "Fold: 10  Epoch: 670  Training loss = 2.5048  Validation loss = 3.2398  \n",
      "\n",
      "Fold: 10  Epoch: 671  Training loss = 2.5045  Validation loss = 3.2393  \n",
      "\n",
      "Fold: 10  Epoch: 672  Training loss = 2.5043  Validation loss = 3.2393  \n",
      "\n",
      "Fold: 10  Epoch: 673  Training loss = 2.5040  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 10  Epoch: 674  Training loss = 2.5035  Validation loss = 3.2357  \n",
      "\n",
      "Fold: 10  Epoch: 675  Training loss = 2.5033  Validation loss = 3.2350  \n",
      "\n",
      "Fold: 10  Epoch: 676  Training loss = 2.5030  Validation loss = 3.2347  \n",
      "\n",
      "Fold: 10  Epoch: 677  Training loss = 2.5026  Validation loss = 3.2321  \n",
      "\n",
      "Fold: 10  Epoch: 678  Training loss = 2.5022  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 10  Epoch: 679  Training loss = 2.5018  Validation loss = 3.2298  \n",
      "\n",
      "Fold: 10  Epoch: 680  Training loss = 2.5016  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 10  Epoch: 681  Training loss = 2.5013  Validation loss = 3.2290  \n",
      "\n",
      "Fold: 10  Epoch: 682  Training loss = 2.5009  Validation loss = 3.2281  \n",
      "\n",
      "Fold: 10  Epoch: 683  Training loss = 2.5006  Validation loss = 3.2265  \n",
      "\n",
      "Fold: 10  Epoch: 684  Training loss = 2.5004  Validation loss = 3.2257  \n",
      "\n",
      "Fold: 10  Epoch: 685  Training loss = 2.5002  Validation loss = 3.2254  \n",
      "\n",
      "Fold: 10  Epoch: 686  Training loss = 2.4998  Validation loss = 3.2232  \n",
      "\n",
      "Fold: 10  Epoch: 687  Training loss = 2.4994  Validation loss = 3.2204  \n",
      "\n",
      "Fold: 10  Epoch: 688  Training loss = 2.4991  Validation loss = 3.2198  \n",
      "\n",
      "Fold: 10  Epoch: 689  Training loss = 2.4989  Validation loss = 3.2197  \n",
      "\n",
      "Fold: 10  Epoch: 690  Training loss = 2.4984  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 10  Epoch: 691  Training loss = 2.4982  Validation loss = 3.2162  \n",
      "\n",
      "Fold: 10  Epoch: 692  Training loss = 2.4977  Validation loss = 3.2154  \n",
      "\n",
      "Fold: 10  Epoch: 693  Training loss = 2.4973  Validation loss = 3.2144  \n",
      "\n",
      "Fold: 10  Epoch: 694  Training loss = 2.4969  Validation loss = 3.2129  \n",
      "\n",
      "Fold: 10  Epoch: 695  Training loss = 2.4967  Validation loss = 3.2137  \n",
      "\n",
      "Fold: 10  Epoch: 696  Training loss = 2.4965  Validation loss = 3.2139  \n",
      "\n",
      "Fold: 10  Epoch: 697  Training loss = 2.4963  Validation loss = 3.2140  \n",
      "\n",
      "Fold: 10  Epoch: 698  Training loss = 2.4959  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 10  Epoch: 699  Training loss = 2.4955  Validation loss = 3.2125  \n",
      "\n",
      "Fold: 10  Epoch: 700  Training loss = 2.4953  Validation loss = 3.2119  \n",
      "\n",
      "Fold: 10  Epoch: 701  Training loss = 2.4949  Validation loss = 3.2115  \n",
      "\n",
      "Fold: 10  Epoch: 702  Training loss = 2.4946  Validation loss = 3.2118  \n",
      "\n",
      "Fold: 10  Epoch: 703  Training loss = 2.4944  Validation loss = 3.2109  \n",
      "\n",
      "Fold: 10  Epoch: 704  Training loss = 2.4940  Validation loss = 3.2112  \n",
      "\n",
      "Fold: 10  Epoch: 705  Training loss = 2.4938  Validation loss = 3.2106  \n",
      "\n",
      "Fold: 10  Epoch: 706  Training loss = 2.4935  Validation loss = 3.2101  \n",
      "\n",
      "Fold: 10  Epoch: 707  Training loss = 2.4932  Validation loss = 3.2080  \n",
      "\n",
      "Fold: 10  Epoch: 708  Training loss = 2.4928  Validation loss = 3.2070  \n",
      "\n",
      "Fold: 10  Epoch: 709  Training loss = 2.4926  Validation loss = 3.2072  \n",
      "\n",
      "Fold: 10  Epoch: 710  Training loss = 2.4922  Validation loss = 3.2060  \n",
      "\n",
      "Fold: 10  Epoch: 711  Training loss = 2.4919  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 10  Epoch: 712  Training loss = 2.4915  Validation loss = 3.2033  \n",
      "\n",
      "Fold: 10  Epoch: 713  Training loss = 2.4910  Validation loss = 3.2040  \n",
      "\n",
      "Fold: 10  Epoch: 714  Training loss = 2.4908  Validation loss = 3.2026  \n",
      "\n",
      "Fold: 10  Epoch: 715  Training loss = 2.4905  Validation loss = 3.2024  \n",
      "\n",
      "Fold: 10  Epoch: 716  Training loss = 2.4901  Validation loss = 3.2014  \n",
      "\n",
      "Fold: 10  Epoch: 717  Training loss = 2.4900  Validation loss = 3.2004  \n",
      "\n",
      "Fold: 10  Epoch: 718  Training loss = 2.4895  Validation loss = 3.1990  \n",
      "\n",
      "Fold: 10  Epoch: 719  Training loss = 2.4890  Validation loss = 3.1981  \n",
      "\n",
      "Fold: 10  Epoch: 720  Training loss = 2.4887  Validation loss = 3.1967  \n",
      "\n",
      "Fold: 10  Epoch: 721  Training loss = 2.4885  Validation loss = 3.1956  \n",
      "\n",
      "Fold: 10  Epoch: 722  Training loss = 2.4880  Validation loss = 3.1936  \n",
      "\n",
      "Fold: 10  Epoch: 723  Training loss = 2.4877  Validation loss = 3.1920  \n",
      "\n",
      "Fold: 10  Epoch: 724  Training loss = 2.4874  Validation loss = 3.1877  \n",
      "\n",
      "Fold: 10  Epoch: 725  Training loss = 2.4871  Validation loss = 3.1857  \n",
      "\n",
      "Fold: 10  Epoch: 726  Training loss = 2.4867  Validation loss = 3.1860  \n",
      "\n",
      "Fold: 10  Epoch: 727  Training loss = 2.4866  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 10  Epoch: 728  Training loss = 2.4863  Validation loss = 3.1866  \n",
      "\n",
      "Fold: 10  Epoch: 729  Training loss = 2.4858  Validation loss = 3.1815  \n",
      "\n",
      "Fold: 10  Epoch: 730  Training loss = 2.4853  Validation loss = 3.1812  \n",
      "\n",
      "Fold: 10  Epoch: 731  Training loss = 2.4850  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 10  Epoch: 732  Training loss = 2.4845  Validation loss = 3.1764  \n",
      "\n",
      "Fold: 10  Epoch: 733  Training loss = 2.4841  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 10  Epoch: 734  Training loss = 2.4838  Validation loss = 3.1798  \n",
      "\n",
      "Fold: 10  Epoch: 735  Training loss = 2.4836  Validation loss = 3.1770  \n",
      "\n",
      "Fold: 10  Epoch: 736  Training loss = 2.4834  Validation loss = 3.1780  \n",
      "\n",
      "Fold: 10  Epoch: 737  Training loss = 2.4833  Validation loss = 3.1771  \n",
      "\n",
      "Fold: 10  Epoch: 738  Training loss = 2.4830  Validation loss = 3.1777  \n",
      "\n",
      "Fold: 10  Epoch: 739  Training loss = 2.4826  Validation loss = 3.1782  \n",
      "\n",
      "Fold: 10  Epoch: 740  Training loss = 2.4824  Validation loss = 3.1776  \n",
      "\n",
      "Fold: 10  Epoch: 741  Training loss = 2.4820  Validation loss = 3.1754  \n",
      "\n",
      "Fold: 10  Epoch: 742  Training loss = 2.4817  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 10  Epoch: 743  Training loss = 2.4814  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 10  Epoch: 744  Training loss = 2.4810  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 10  Epoch: 745  Training loss = 2.4808  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 10  Epoch: 746  Training loss = 2.4805  Validation loss = 3.1765  \n",
      "\n",
      "Fold: 10  Epoch: 747  Training loss = 2.4804  Validation loss = 3.1763  \n",
      "\n",
      "Fold: 10  Epoch: 748  Training loss = 2.4802  Validation loss = 3.1744  \n",
      "\n",
      "Fold: 10  Epoch: 749  Training loss = 2.4800  Validation loss = 3.1755  \n",
      "\n",
      "Fold: 10  Epoch: 750  Training loss = 2.4798  Validation loss = 3.1727  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 750  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 2.5404  Validation loss = 1.2125  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 2.5399  Validation loss = 1.2117  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 2.5393  Validation loss = 1.2107  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 2.5389  Validation loss = 1.2104  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 2.5385  Validation loss = 1.2099  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 2.5382  Validation loss = 1.2097  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 2.5378  Validation loss = 1.2093  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 2.5377  Validation loss = 1.2094  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 2.5372  Validation loss = 1.2086  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 2.5368  Validation loss = 1.2081  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 2.5365  Validation loss = 1.2079  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 2.5360  Validation loss = 1.2072  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 2.5356  Validation loss = 1.2065  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 2.5350  Validation loss = 1.2057  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 2.5345  Validation loss = 1.2051  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 2.5340  Validation loss = 1.2045  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 2.5338  Validation loss = 1.2043  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 2.5332  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 2.5329  Validation loss = 1.2029  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 2.5327  Validation loss = 1.2028  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 2.5324  Validation loss = 1.2025  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 2.5322  Validation loss = 1.2026  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 2.5315  Validation loss = 1.2017  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 2.5311  Validation loss = 1.2012  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 2.5306  Validation loss = 1.2003  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 2.5299  Validation loss = 1.1993  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 2.5294  Validation loss = 1.1985  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 2.5288  Validation loss = 1.1976  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 2.5287  Validation loss = 1.1976  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 2.5286  Validation loss = 1.1976  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 2.5282  Validation loss = 1.1972  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 2.5281  Validation loss = 1.1974  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 2.5278  Validation loss = 1.1969  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 2.5276  Validation loss = 1.1968  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 2.5270  Validation loss = 1.1958  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 2.5266  Validation loss = 1.1954  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 2.5263  Validation loss = 1.1951  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 2.5261  Validation loss = 1.1949  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 2.5255  Validation loss = 1.1941  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 2.5249  Validation loss = 1.1931  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 2.5245  Validation loss = 1.1927  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 2.5241  Validation loss = 1.1922  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 2.5236  Validation loss = 1.1914  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 2.5232  Validation loss = 1.1907  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 2.5229  Validation loss = 1.1904  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 2.5226  Validation loss = 1.1900  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 2.5221  Validation loss = 1.1894  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 2.5219  Validation loss = 1.1893  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 2.5217  Validation loss = 1.1891  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 2.5213  Validation loss = 1.1885  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 2.5209  Validation loss = 1.1880  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 2.5208  Validation loss = 1.1879  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 2.5205  Validation loss = 1.1877  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 2.5201  Validation loss = 1.1874  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 2.5197  Validation loss = 1.1870  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 2.5191  Validation loss = 1.1860  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 2.5186  Validation loss = 1.1852  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 2.5181  Validation loss = 1.1847  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 2.5175  Validation loss = 1.1839  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 2.5173  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 2.5167  Validation loss = 1.1835  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 2.5164  Validation loss = 1.1831  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 2.5159  Validation loss = 1.1821  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 2.5155  Validation loss = 1.1817  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 2.5089  Validation loss = 1.1812  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 2.5083  Validation loss = 1.1803  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 2.5082  Validation loss = 1.1804  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 2.5079  Validation loss = 1.1801  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 2.5075  Validation loss = 1.1794  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 2.5071  Validation loss = 1.1792  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 2.5066  Validation loss = 1.1783  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 2.5060  Validation loss = 1.1774  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 2.5058  Validation loss = 1.1769  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 2.5054  Validation loss = 1.1765  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 2.5052  Validation loss = 1.1765  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 2.5049  Validation loss = 1.1764  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 2.5044  Validation loss = 1.1755  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 2.5041  Validation loss = 1.1754  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 2.5038  Validation loss = 1.1752  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 2.5035  Validation loss = 1.1748  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 2.5030  Validation loss = 1.1745  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 2.5024  Validation loss = 1.1737  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 2.5020  Validation loss = 1.1732  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 2.5016  Validation loss = 1.1726  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 2.5012  Validation loss = 1.1721  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 2.5007  Validation loss = 1.1716  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 2.5003  Validation loss = 1.1712  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 2.4999  Validation loss = 1.1703  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 2.4994  Validation loss = 1.1694  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 2.4990  Validation loss = 1.1691  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 2.4985  Validation loss = 1.1685  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 2.4983  Validation loss = 1.1687  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 2.4978  Validation loss = 1.1680  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 2.4975  Validation loss = 1.1678  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 2.4971  Validation loss = 1.1675  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 2.4967  Validation loss = 1.1669  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 2.4964  Validation loss = 1.1671  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 2.4959  Validation loss = 1.1668  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 2.4956  Validation loss = 1.1662  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 2.4950  Validation loss = 1.1654  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 2.4945  Validation loss = 1.1646  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 2.4940  Validation loss = 1.1640  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 2.4937  Validation loss = 1.1638  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 2.4935  Validation loss = 1.1638  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 2.4931  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 2.4925  Validation loss = 1.1624  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 2.4922  Validation loss = 1.1621  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 2.4918  Validation loss = 1.1614  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 2.4914  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 2.4910  Validation loss = 1.1606  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 2.4906  Validation loss = 1.1603  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 2.4902  Validation loss = 1.1596  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 2.4899  Validation loss = 1.1590  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 2.4896  Validation loss = 1.1591  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 2.4891  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 2.4887  Validation loss = 1.1585  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 2.4885  Validation loss = 1.1588  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 2.4881  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 2.4881  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 2.4878  Validation loss = 1.1594  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 2.4872  Validation loss = 1.1586  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 2.4868  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 2.4867  Validation loss = 1.1586  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 2.4863  Validation loss = 1.1583  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 2.4859  Validation loss = 1.1582  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 2.4856  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 2.4853  Validation loss = 1.1581  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 2.4846  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 2.4843  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 2.4840  Validation loss = 1.1571  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 2.4837  Validation loss = 1.1571  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 2.4832  Validation loss = 1.1566  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 2.4829  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 2.4827  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 2.4824  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 2.4818  Validation loss = 1.1561  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 2.4814  Validation loss = 1.1558  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 2.4810  Validation loss = 1.1555  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 2.4809  Validation loss = 1.1563  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 2.4805  Validation loss = 1.1565  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 2.4803  Validation loss = 1.1561  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 2.4798  Validation loss = 1.1554  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 2.4792  Validation loss = 1.1545  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 2.4790  Validation loss = 1.1552  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 2.4784  Validation loss = 1.1543  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 2.4782  Validation loss = 1.1542  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 2.4779  Validation loss = 1.1541  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 2.4775  Validation loss = 1.1534  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 2.4771  Validation loss = 1.1539  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 2.4767  Validation loss = 1.1529  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 2.4765  Validation loss = 1.1535  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 2.4762  Validation loss = 1.1532  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 2.4760  Validation loss = 1.1534  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 2.4758  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 2.4757  Validation loss = 1.1534  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 2.4752  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 2.4750  Validation loss = 1.1545  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 2.4746  Validation loss = 1.1541  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 2.4745  Validation loss = 1.1542  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 2.4743  Validation loss = 1.1546  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 150  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 2.4610  Validation loss = 2.0986  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.4607  Validation loss = 2.0966  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 2.4605  Validation loss = 2.1063  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.4602  Validation loss = 2.1125  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 2.4598  Validation loss = 2.1086  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.4596  Validation loss = 2.1158  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 2.4594  Validation loss = 2.1206  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 2.4591  Validation loss = 2.1199  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.4587  Validation loss = 2.1283  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 2.4585  Validation loss = 2.1274  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 2.4582  Validation loss = 2.1271  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 2.4579  Validation loss = 2.1329  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 2.4575  Validation loss = 2.1316  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 2.4572  Validation loss = 2.1344  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 2.4571  Validation loss = 2.1447  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 2.4568  Validation loss = 2.1466  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 2  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.4755  Validation loss = 3.9414  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.4745  Validation loss = 3.9395  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.4723  Validation loss = 3.9374  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.4706  Validation loss = 3.9355  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 2.4703  Validation loss = 3.9344  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 2.4698  Validation loss = 3.9332  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 2.4689  Validation loss = 3.9320  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 2.4679  Validation loss = 3.9298  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 2.4670  Validation loss = 3.9288  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 2.4667  Validation loss = 3.9277  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 2.4660  Validation loss = 3.9264  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 2.4641  Validation loss = 3.9239  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.4634  Validation loss = 3.9226  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.4632  Validation loss = 3.9220  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.4622  Validation loss = 3.9203  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.4617  Validation loss = 3.9189  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 2.4610  Validation loss = 3.9173  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 2.4603  Validation loss = 3.9154  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 2.4593  Validation loss = 3.9130  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 2.4589  Validation loss = 3.9118  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 2.4584  Validation loss = 3.9105  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.4579  Validation loss = 3.9090  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.4573  Validation loss = 3.9075  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 2.4567  Validation loss = 3.9059  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.4557  Validation loss = 3.9031  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 2.4549  Validation loss = 3.9010  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 2.4546  Validation loss = 3.9000  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 2.4541  Validation loss = 3.8984  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 2.4537  Validation loss = 3.8977  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 2.4533  Validation loss = 3.8966  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 2.4529  Validation loss = 3.8955  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 2.4524  Validation loss = 3.8940  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 2.4519  Validation loss = 3.8924  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 2.4510  Validation loss = 3.8899  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 2.4506  Validation loss = 3.8889  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 2.4502  Validation loss = 3.8879  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 2.4497  Validation loss = 3.8864  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 2.4492  Validation loss = 3.8848  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 2.4489  Validation loss = 3.8842  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 2.4481  Validation loss = 3.8815  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 2.4478  Validation loss = 3.8809  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 2.4473  Validation loss = 3.8794  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 2.4467  Validation loss = 3.8776  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 2.4463  Validation loss = 3.8762  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 2.4457  Validation loss = 3.8745  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 2.4451  Validation loss = 3.8726  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 2.4445  Validation loss = 3.8708  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 2.4442  Validation loss = 3.8699  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 2.4438  Validation loss = 3.8687  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 2.4433  Validation loss = 3.8671  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 2.4426  Validation loss = 3.8647  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 2.4420  Validation loss = 3.8628  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 2.4416  Validation loss = 3.8616  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 2.4413  Validation loss = 3.8609  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 2.4409  Validation loss = 3.8598  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 2.4406  Validation loss = 3.8589  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 2.4402  Validation loss = 3.8577  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 2.4398  Validation loss = 3.8564  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 2.4395  Validation loss = 3.8553  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 2.4388  Validation loss = 3.8532  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 2.4383  Validation loss = 3.8515  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 2.4380  Validation loss = 3.8506  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 2.4377  Validation loss = 3.8498  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 2.4370  Validation loss = 3.8477  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 2.4367  Validation loss = 3.8466  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 2.4364  Validation loss = 3.8460  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 2.4361  Validation loss = 3.8451  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 2.4355  Validation loss = 3.8432  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 2.4352  Validation loss = 3.8425  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 2.4348  Validation loss = 3.8414  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 2.4345  Validation loss = 3.8406  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 2.4340  Validation loss = 3.8389  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 2.4337  Validation loss = 3.8383  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 2.4333  Validation loss = 3.8367  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 2.4330  Validation loss = 3.8360  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 2.4328  Validation loss = 3.8358  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 2.4324  Validation loss = 3.8347  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 2.4319  Validation loss = 3.8330  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 2.4315  Validation loss = 3.8319  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 2.4313  Validation loss = 3.8313  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 2.4311  Validation loss = 3.8308  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 2.4307  Validation loss = 3.8297  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 2.4300  Validation loss = 3.8273  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 2.4296  Validation loss = 3.8258  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 2.4289  Validation loss = 3.8236  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 2.4284  Validation loss = 3.8220  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 2.4279  Validation loss = 3.8203  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 2.4274  Validation loss = 3.8188  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 2.4269  Validation loss = 3.8172  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 2.4263  Validation loss = 3.8153  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 2.4259  Validation loss = 3.8141  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 2.4253  Validation loss = 3.8124  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 2.4251  Validation loss = 3.8116  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 2.4248  Validation loss = 3.8108  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 2.4244  Validation loss = 3.8095  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 2.4239  Validation loss = 3.8075  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 2.4234  Validation loss = 3.8060  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 2.4228  Validation loss = 3.8044  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 2.4222  Validation loss = 3.8024  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 2.4218  Validation loss = 3.8009  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 2.4215  Validation loss = 3.8004  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 2.4212  Validation loss = 3.7994  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 2.4209  Validation loss = 3.7987  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 2.4205  Validation loss = 3.7976  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 2.4199  Validation loss = 3.7955  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 2.4195  Validation loss = 3.7940  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 2.4191  Validation loss = 3.7930  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 2.4187  Validation loss = 3.7917  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 2.4182  Validation loss = 3.7899  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 2.4177  Validation loss = 3.7886  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 2.4173  Validation loss = 3.7873  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 2.4169  Validation loss = 3.7861  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 2.4164  Validation loss = 3.7846  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 2.4159  Validation loss = 3.7828  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 2.4156  Validation loss = 3.7822  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 2.4152  Validation loss = 3.7807  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 2.4149  Validation loss = 3.7797  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 2.4146  Validation loss = 3.7788  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 2.4142  Validation loss = 3.7778  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 2.4139  Validation loss = 3.7766  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 2.4135  Validation loss = 3.7752  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 2.4133  Validation loss = 3.7742  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 2.4131  Validation loss = 3.7742  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 2.4126  Validation loss = 3.7730  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 2.4122  Validation loss = 3.7718  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 2.4118  Validation loss = 3.7707  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 2.4116  Validation loss = 3.7702  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 2.4111  Validation loss = 3.7684  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 2.4109  Validation loss = 3.7679  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 2.4106  Validation loss = 3.7674  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 2.4103  Validation loss = 3.7667  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 2.4100  Validation loss = 3.7657  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 2.4096  Validation loss = 3.7644  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 2.4092  Validation loss = 3.7631  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 2.4090  Validation loss = 3.7627  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 2.4083  Validation loss = 3.7599  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 2.4080  Validation loss = 3.7593  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 2.4074  Validation loss = 3.7571  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 2.4070  Validation loss = 3.7559  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 2.4068  Validation loss = 3.7556  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 2.4065  Validation loss = 3.7546  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 2.4060  Validation loss = 3.7533  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 2.4058  Validation loss = 3.7527  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 2.4056  Validation loss = 3.7522  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 2.4054  Validation loss = 3.7517  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 2.4051  Validation loss = 3.7506  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 2.4049  Validation loss = 3.7503  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 2.4046  Validation loss = 3.7495  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 2.4043  Validation loss = 3.7483  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 2.4037  Validation loss = 3.7463  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 2.4033  Validation loss = 3.7452  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 2.4027  Validation loss = 3.7432  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 2.4022  Validation loss = 3.7417  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 2.4016  Validation loss = 3.7396  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 2.4013  Validation loss = 3.7384  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 2.4009  Validation loss = 3.7369  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 2.4005  Validation loss = 3.7356  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 2.4000  Validation loss = 3.7339  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 2.3993  Validation loss = 3.7317  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 2.3990  Validation loss = 3.7307  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 2.3986  Validation loss = 3.7294  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 2.3981  Validation loss = 3.7276  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 2.3976  Validation loss = 3.7259  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 2.3972  Validation loss = 3.7244  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 2.3967  Validation loss = 3.7230  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 2.3963  Validation loss = 3.7215  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 2.3960  Validation loss = 3.7208  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 2.3955  Validation loss = 3.7186  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 2.3952  Validation loss = 3.7175  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 2.3948  Validation loss = 3.7164  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 2.3946  Validation loss = 3.7155  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 2.3942  Validation loss = 3.7143  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 2.3940  Validation loss = 3.7139  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 2.3936  Validation loss = 3.7126  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 2.3930  Validation loss = 3.7104  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 2.3924  Validation loss = 3.7082  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 2.3922  Validation loss = 3.7077  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 2.3919  Validation loss = 3.7065  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 2.3915  Validation loss = 3.7051  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 2.3910  Validation loss = 3.7038  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 2.3908  Validation loss = 3.7032  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 2.3904  Validation loss = 3.7015  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 2.3900  Validation loss = 3.6999  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 2.3896  Validation loss = 3.6989  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 2.3892  Validation loss = 3.6975  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 2.3890  Validation loss = 3.6968  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 2.3886  Validation loss = 3.6955  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 2.3884  Validation loss = 3.6951  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 2.3881  Validation loss = 3.6942  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 2.3877  Validation loss = 3.6928  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 2.3873  Validation loss = 3.6920  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 2.3871  Validation loss = 3.6913  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 2.3868  Validation loss = 3.6904  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 2.3865  Validation loss = 3.6895  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 2.3862  Validation loss = 3.6885  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 2.3860  Validation loss = 3.6878  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 2.3858  Validation loss = 3.6875  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 2.3853  Validation loss = 3.6854  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 2.3850  Validation loss = 3.6848  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 2.3849  Validation loss = 3.6845  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 2.3845  Validation loss = 3.6833  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 2.3841  Validation loss = 3.6821  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 2.3837  Validation loss = 3.6807  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 2.3832  Validation loss = 3.6791  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 2.3828  Validation loss = 3.6779  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 2.3824  Validation loss = 3.6763  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 2.3822  Validation loss = 3.6753  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 2.3818  Validation loss = 3.6740  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 2.3815  Validation loss = 3.6732  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 2.3812  Validation loss = 3.6724  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 2.3808  Validation loss = 3.6708  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 2.3805  Validation loss = 3.6700  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 2.3802  Validation loss = 3.6690  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 2.3800  Validation loss = 3.6686  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 2.3798  Validation loss = 3.6684  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 2.3795  Validation loss = 3.6677  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 2.3792  Validation loss = 3.6668  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 2.3790  Validation loss = 3.6663  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 2.3788  Validation loss = 3.6657  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 2.3784  Validation loss = 3.6645  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 2.3781  Validation loss = 3.6633  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 2.3777  Validation loss = 3.6620  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 2.3774  Validation loss = 3.6610  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 2.3770  Validation loss = 3.6597  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 2.3769  Validation loss = 3.6598  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 2.3765  Validation loss = 3.6581  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 2.3760  Validation loss = 3.6561  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 2.3757  Validation loss = 3.6553  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 2.3753  Validation loss = 3.6543  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 2.3749  Validation loss = 3.6532  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 2.3746  Validation loss = 3.6527  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 2.3743  Validation loss = 3.6520  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 2.3739  Validation loss = 3.6506  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 2.3736  Validation loss = 3.6494  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 2.3733  Validation loss = 3.6487  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 2.3732  Validation loss = 3.6484  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 2.3730  Validation loss = 3.6484  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 2.3728  Validation loss = 3.6479  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 2.3724  Validation loss = 3.6461  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 2.3721  Validation loss = 3.6455  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 2.3719  Validation loss = 3.6450  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 2.3715  Validation loss = 3.6438  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 2.3712  Validation loss = 3.6426  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 2.3710  Validation loss = 3.6421  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 2.3708  Validation loss = 3.6414  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 2.3704  Validation loss = 3.6399  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 2.3701  Validation loss = 3.6391  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 2.3697  Validation loss = 3.6375  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 2.3693  Validation loss = 3.6363  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 2.3690  Validation loss = 3.6350  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 2.3686  Validation loss = 3.6336  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 2.3682  Validation loss = 3.6322  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 2.3678  Validation loss = 3.6312  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 2.3675  Validation loss = 3.6295  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 2.3670  Validation loss = 3.6277  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 2.3666  Validation loss = 3.6258  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 2.3662  Validation loss = 3.6242  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 2.3661  Validation loss = 3.6236  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 2.3654  Validation loss = 3.6212  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 2.3653  Validation loss = 3.6207  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 2.3650  Validation loss = 3.6195  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 2.3646  Validation loss = 3.6179  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 2.3643  Validation loss = 3.6163  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 2.3640  Validation loss = 3.6154  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 2.3639  Validation loss = 3.6158  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 2.3635  Validation loss = 3.6142  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 2.3632  Validation loss = 3.6137  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 2.3630  Validation loss = 3.6130  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 2.3629  Validation loss = 3.6128  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 2.3623  Validation loss = 3.6109  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 2.3622  Validation loss = 3.6106  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 2.3619  Validation loss = 3.6093  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 2.3617  Validation loss = 3.6089  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 2.3615  Validation loss = 3.6081  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 2.3612  Validation loss = 3.6072  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 2.3608  Validation loss = 3.6060  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 2.3605  Validation loss = 3.6053  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 2.3600  Validation loss = 3.6039  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 2.3597  Validation loss = 3.6027  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 2.3594  Validation loss = 3.6022  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 2.3590  Validation loss = 3.6014  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 2.3590  Validation loss = 3.6022  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 2.3587  Validation loss = 3.6016  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 2.3583  Validation loss = 3.6004  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 2.3579  Validation loss = 3.5990  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 2.3577  Validation loss = 3.5981  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 2.3573  Validation loss = 3.5967  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 2.3568  Validation loss = 3.5949  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 2.3566  Validation loss = 3.5944  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 2.3564  Validation loss = 3.5937  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 2.3560  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 2.3557  Validation loss = 3.5917  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 2.3555  Validation loss = 3.5911  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 2.3551  Validation loss = 3.5899  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 2.3548  Validation loss = 3.5884  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 2.3544  Validation loss = 3.5869  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 2.3541  Validation loss = 3.5856  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 2.3538  Validation loss = 3.5850  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 2.3534  Validation loss = 3.5833  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 2.3530  Validation loss = 3.5820  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 2.3527  Validation loss = 3.5808  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 2.3523  Validation loss = 3.5795  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 2.3520  Validation loss = 3.5785  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 2.3517  Validation loss = 3.5774  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 2.3515  Validation loss = 3.5764  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 2.3511  Validation loss = 3.5757  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 2.3508  Validation loss = 3.5749  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 2.3507  Validation loss = 3.5746  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 2.3504  Validation loss = 3.5738  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 2.3501  Validation loss = 3.5730  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 2.3499  Validation loss = 3.5721  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 2.3494  Validation loss = 3.5706  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 2.3491  Validation loss = 3.5696  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 2.3490  Validation loss = 3.5697  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 2.3486  Validation loss = 3.5686  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 2.3483  Validation loss = 3.5677  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 2.3479  Validation loss = 3.5662  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 2.3477  Validation loss = 3.5662  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 2.3475  Validation loss = 3.5656  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 2.3471  Validation loss = 3.5649  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 2.3467  Validation loss = 3.5633  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 2.3465  Validation loss = 3.5630  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 2.3463  Validation loss = 3.5627  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 2.3458  Validation loss = 3.5610  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 2.3454  Validation loss = 3.5592  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 2.3451  Validation loss = 3.5583  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 2.3448  Validation loss = 3.5568  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 2.3445  Validation loss = 3.5557  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 2.3440  Validation loss = 3.5538  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 2.3438  Validation loss = 3.5526  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 2.3436  Validation loss = 3.5525  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 2.3431  Validation loss = 3.5506  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 2.3428  Validation loss = 3.5494  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 2.3424  Validation loss = 3.5480  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 2.3420  Validation loss = 3.5461  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 2.3418  Validation loss = 3.5450  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 2.3412  Validation loss = 3.5430  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 2.3410  Validation loss = 3.5418  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 2.3408  Validation loss = 3.5415  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 2.3405  Validation loss = 3.5405  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 2.3403  Validation loss = 3.5398  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 2.3400  Validation loss = 3.5388  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 2.3396  Validation loss = 3.5373  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 2.3393  Validation loss = 3.5357  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 2.3391  Validation loss = 3.5357  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 2.3388  Validation loss = 3.5348  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 2.3384  Validation loss = 3.5334  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 2.3383  Validation loss = 3.5336  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 2.3380  Validation loss = 3.5326  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 2.3377  Validation loss = 3.5313  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 2.3372  Validation loss = 3.5291  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 2.3369  Validation loss = 3.5274  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 2.3366  Validation loss = 3.5265  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 2.3365  Validation loss = 3.5263  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 2.3363  Validation loss = 3.5255  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 2.3360  Validation loss = 3.5246  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 2.3358  Validation loss = 3.5242  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 2.3355  Validation loss = 3.5231  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 2.3350  Validation loss = 3.5209  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 2.3347  Validation loss = 3.5204  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 2.3346  Validation loss = 3.5200  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 2.3342  Validation loss = 3.5185  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 2.3340  Validation loss = 3.5181  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 2.3337  Validation loss = 3.5176  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 2.3335  Validation loss = 3.5171  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 2.3331  Validation loss = 3.5158  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 2.3328  Validation loss = 3.5141  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 2.3324  Validation loss = 3.5131  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 2.3322  Validation loss = 3.5128  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 2.3319  Validation loss = 3.5117  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 2.3316  Validation loss = 3.5105  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 2.3314  Validation loss = 3.5095  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 2.3311  Validation loss = 3.5085  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 2.3310  Validation loss = 3.5075  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 2.3306  Validation loss = 3.5064  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 2.3303  Validation loss = 3.5055  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 2.3301  Validation loss = 3.5044  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 2.3299  Validation loss = 3.5036  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 2.3299  Validation loss = 3.5034  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 2.3297  Validation loss = 3.5032  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 2.3295  Validation loss = 3.5027  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 2.3293  Validation loss = 3.5022  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 2.3292  Validation loss = 3.5023  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 2.3288  Validation loss = 3.5009  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 2.3284  Validation loss = 3.4992  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 2.3282  Validation loss = 3.4989  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 2.3280  Validation loss = 3.4990  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 2.3277  Validation loss = 3.4982  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 2.3273  Validation loss = 3.4971  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 2.3272  Validation loss = 3.4974  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 2.3269  Validation loss = 3.4966  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 2.3267  Validation loss = 3.4956  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 2.3264  Validation loss = 3.4948  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 2.3261  Validation loss = 3.4936  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 2.3257  Validation loss = 3.4916  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 2.3257  Validation loss = 3.4912  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 2.3252  Validation loss = 3.4898  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 2.3248  Validation loss = 3.4886  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 2.3244  Validation loss = 3.4871  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 2.3241  Validation loss = 3.4866  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 2.3238  Validation loss = 3.4862  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 2.3235  Validation loss = 3.4853  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 2.3233  Validation loss = 3.4848  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 2.3231  Validation loss = 3.4844  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 2.3228  Validation loss = 3.4833  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 2.3225  Validation loss = 3.4829  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 2.3222  Validation loss = 3.4820  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 2.3218  Validation loss = 3.4809  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 2.3216  Validation loss = 3.4799  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 2.3212  Validation loss = 3.4782  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 2.3209  Validation loss = 3.4774  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 2.3207  Validation loss = 3.4770  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 2.3203  Validation loss = 3.4758  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 2.3200  Validation loss = 3.4748  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 2.3200  Validation loss = 3.4753  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 2.3198  Validation loss = 3.4748  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 2.3197  Validation loss = 3.4749  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 2.3193  Validation loss = 3.4737  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 2.3190  Validation loss = 3.4724  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 2.3190  Validation loss = 3.4725  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 2.3187  Validation loss = 3.4717  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 2.3184  Validation loss = 3.4705  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 2.3182  Validation loss = 3.4700  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 2.3179  Validation loss = 3.4684  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 2.3177  Validation loss = 3.4671  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 2.3175  Validation loss = 3.4671  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 2.3173  Validation loss = 3.4661  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 2.3170  Validation loss = 3.4654  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 2.3169  Validation loss = 3.4651  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 2.3164  Validation loss = 3.4634  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 2.3161  Validation loss = 3.4621  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 2.3156  Validation loss = 3.4604  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 2.3154  Validation loss = 3.4593  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 2.3150  Validation loss = 3.4577  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 2.3147  Validation loss = 3.4565  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 2.3143  Validation loss = 3.4551  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 2.3141  Validation loss = 3.4541  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 2.3139  Validation loss = 3.4540  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 2.3137  Validation loss = 3.4530  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 2.3135  Validation loss = 3.4520  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 2.3134  Validation loss = 3.4513  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 2.3130  Validation loss = 3.4499  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 2.3128  Validation loss = 3.4495  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 2.3125  Validation loss = 3.4484  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 2.3123  Validation loss = 3.4477  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 2.3121  Validation loss = 3.4465  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 2.3118  Validation loss = 3.4458  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 2.3115  Validation loss = 3.4448  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 2.3113  Validation loss = 3.4443  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 2.3110  Validation loss = 3.4432  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 2.3106  Validation loss = 3.4416  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 2.3104  Validation loss = 3.4414  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 2.3102  Validation loss = 3.4406  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 2.3099  Validation loss = 3.4393  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 2.3097  Validation loss = 3.4396  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 2.3093  Validation loss = 3.4378  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 2.3090  Validation loss = 3.4358  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 2.3087  Validation loss = 3.4347  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 2.3085  Validation loss = 3.4335  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 2.3081  Validation loss = 3.4324  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 2.3078  Validation loss = 3.4311  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 2.3075  Validation loss = 3.4297  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 2.3073  Validation loss = 3.4295  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 2.3071  Validation loss = 3.4294  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 2.3068  Validation loss = 3.4290  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 2.3066  Validation loss = 3.4282  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 2.3063  Validation loss = 3.4276  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 2.3061  Validation loss = 3.4260  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 2.3058  Validation loss = 3.4251  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 2.3055  Validation loss = 3.4244  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 2.3052  Validation loss = 3.4239  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 2.3050  Validation loss = 3.4233  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 2.3047  Validation loss = 3.4220  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 2.3044  Validation loss = 3.4209  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 2.3042  Validation loss = 3.4205  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 2.3040  Validation loss = 3.4200  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 2.3037  Validation loss = 3.4196  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 2.3033  Validation loss = 3.4176  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 2.3030  Validation loss = 3.4161  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 2.3027  Validation loss = 3.4149  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 2.3025  Validation loss = 3.4145  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 2.3024  Validation loss = 3.4143  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 2.3022  Validation loss = 3.4137  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 2.3021  Validation loss = 3.4137  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 2.3017  Validation loss = 3.4120  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 2.3015  Validation loss = 3.4115  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 2.3012  Validation loss = 3.4107  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 2.3011  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 2.3008  Validation loss = 3.4095  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 2.3006  Validation loss = 3.4090  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 2.3004  Validation loss = 3.4085  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 2.3002  Validation loss = 3.4076  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 2.2999  Validation loss = 3.4065  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 2.2996  Validation loss = 3.4054  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 2.2995  Validation loss = 3.4048  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 2.2991  Validation loss = 3.4031  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 2.2990  Validation loss = 3.4026  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 2.2987  Validation loss = 3.4017  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 2.2986  Validation loss = 3.4011  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 2.2983  Validation loss = 3.4005  \n",
      "\n",
      "Fold: 13  Epoch: 501  Training loss = 2.2981  Validation loss = 3.3993  \n",
      "\n",
      "Fold: 13  Epoch: 502  Training loss = 2.2978  Validation loss = 3.3984  \n",
      "\n",
      "Fold: 13  Epoch: 503  Training loss = 2.2976  Validation loss = 3.3979  \n",
      "\n",
      "Fold: 13  Epoch: 504  Training loss = 2.2974  Validation loss = 3.3971  \n",
      "\n",
      "Fold: 13  Epoch: 505  Training loss = 2.2972  Validation loss = 3.3964  \n",
      "\n",
      "Fold: 13  Epoch: 506  Training loss = 2.2970  Validation loss = 3.3958  \n",
      "\n",
      "Fold: 13  Epoch: 507  Training loss = 2.2968  Validation loss = 3.3950  \n",
      "\n",
      "Fold: 13  Epoch: 508  Training loss = 2.2964  Validation loss = 3.3932  \n",
      "\n",
      "Fold: 13  Epoch: 509  Training loss = 2.2961  Validation loss = 3.3915  \n",
      "\n",
      "Fold: 13  Epoch: 510  Training loss = 2.2958  Validation loss = 3.3902  \n",
      "\n",
      "Fold: 13  Epoch: 511  Training loss = 2.2954  Validation loss = 3.3886  \n",
      "\n",
      "Fold: 13  Epoch: 512  Training loss = 2.2953  Validation loss = 3.3880  \n",
      "\n",
      "Fold: 13  Epoch: 513  Training loss = 2.2951  Validation loss = 3.3870  \n",
      "\n",
      "Fold: 13  Epoch: 514  Training loss = 2.2949  Validation loss = 3.3859  \n",
      "\n",
      "Fold: 13  Epoch: 515  Training loss = 2.2947  Validation loss = 3.3857  \n",
      "\n",
      "Fold: 13  Epoch: 516  Training loss = 2.2944  Validation loss = 3.3847  \n",
      "\n",
      "Fold: 13  Epoch: 517  Training loss = 2.2941  Validation loss = 3.3831  \n",
      "\n",
      "Fold: 13  Epoch: 518  Training loss = 2.2938  Validation loss = 3.3821  \n",
      "\n",
      "Fold: 13  Epoch: 519  Training loss = 2.2933  Validation loss = 3.3797  \n",
      "\n",
      "Fold: 13  Epoch: 520  Training loss = 2.2930  Validation loss = 3.3790  \n",
      "\n",
      "Fold: 13  Epoch: 521  Training loss = 2.2927  Validation loss = 3.3782  \n",
      "\n",
      "Fold: 13  Epoch: 522  Training loss = 2.2924  Validation loss = 3.3778  \n",
      "\n",
      "Fold: 13  Epoch: 523  Training loss = 2.2923  Validation loss = 3.3777  \n",
      "\n",
      "Fold: 13  Epoch: 524  Training loss = 2.2920  Validation loss = 3.3768  \n",
      "\n",
      "Fold: 13  Epoch: 525  Training loss = 2.2918  Validation loss = 3.3752  \n",
      "\n",
      "Fold: 13  Epoch: 526  Training loss = 2.2917  Validation loss = 3.3754  \n",
      "\n",
      "Fold: 13  Epoch: 527  Training loss = 2.2916  Validation loss = 3.3742  \n",
      "\n",
      "Fold: 13  Epoch: 528  Training loss = 2.2914  Validation loss = 3.3737  \n",
      "\n",
      "Fold: 13  Epoch: 529  Training loss = 2.2910  Validation loss = 3.3718  \n",
      "\n",
      "Fold: 13  Epoch: 530  Training loss = 2.2908  Validation loss = 3.3710  \n",
      "\n",
      "Fold: 13  Epoch: 531  Training loss = 2.2905  Validation loss = 3.3695  \n",
      "\n",
      "Fold: 13  Epoch: 532  Training loss = 2.2902  Validation loss = 3.3689  \n",
      "\n",
      "Fold: 13  Epoch: 533  Training loss = 2.2898  Validation loss = 3.3671  \n",
      "\n",
      "Fold: 13  Epoch: 534  Training loss = 2.2896  Validation loss = 3.3658  \n",
      "\n",
      "Fold: 13  Epoch: 535  Training loss = 2.2893  Validation loss = 3.3655  \n",
      "\n",
      "Fold: 13  Epoch: 536  Training loss = 2.2891  Validation loss = 3.3646  \n",
      "\n",
      "Fold: 13  Epoch: 537  Training loss = 2.2889  Validation loss = 3.3639  \n",
      "\n",
      "Fold: 13  Epoch: 538  Training loss = 2.2888  Validation loss = 3.3626  \n",
      "\n",
      "Fold: 13  Epoch: 539  Training loss = 2.2885  Validation loss = 3.3618  \n",
      "\n",
      "Fold: 13  Epoch: 540  Training loss = 2.2883  Validation loss = 3.3610  \n",
      "\n",
      "Fold: 13  Epoch: 541  Training loss = 2.2881  Validation loss = 3.3609  \n",
      "\n",
      "Fold: 13  Epoch: 542  Training loss = 2.2878  Validation loss = 3.3598  \n",
      "\n",
      "Fold: 13  Epoch: 543  Training loss = 2.2876  Validation loss = 3.3589  \n",
      "\n",
      "Fold: 13  Epoch: 544  Training loss = 2.2873  Validation loss = 3.3574  \n",
      "\n",
      "Fold: 13  Epoch: 545  Training loss = 2.2869  Validation loss = 3.3558  \n",
      "\n",
      "Fold: 13  Epoch: 546  Training loss = 2.2865  Validation loss = 3.3538  \n",
      "\n",
      "Fold: 13  Epoch: 547  Training loss = 2.2863  Validation loss = 3.3531  \n",
      "\n",
      "Fold: 13  Epoch: 548  Training loss = 2.2861  Validation loss = 3.3532  \n",
      "\n",
      "Fold: 13  Epoch: 549  Training loss = 2.2858  Validation loss = 3.3517  \n",
      "\n",
      "Fold: 13  Epoch: 550  Training loss = 2.2855  Validation loss = 3.3516  \n",
      "\n",
      "Fold: 13  Epoch: 551  Training loss = 2.2852  Validation loss = 3.3511  \n",
      "\n",
      "Fold: 13  Epoch: 552  Training loss = 2.2850  Validation loss = 3.3506  \n",
      "\n",
      "Fold: 13  Epoch: 553  Training loss = 2.2847  Validation loss = 3.3492  \n",
      "\n",
      "Fold: 13  Epoch: 554  Training loss = 2.2846  Validation loss = 3.3489  \n",
      "\n",
      "Fold: 13  Epoch: 555  Training loss = 2.2844  Validation loss = 3.3487  \n",
      "\n",
      "Fold: 13  Epoch: 556  Training loss = 2.2842  Validation loss = 3.3470  \n",
      "\n",
      "Fold: 13  Epoch: 557  Training loss = 2.2840  Validation loss = 3.3464  \n",
      "\n",
      "Fold: 13  Epoch: 558  Training loss = 2.2838  Validation loss = 3.3462  \n",
      "\n",
      "Fold: 13  Epoch: 559  Training loss = 2.2835  Validation loss = 3.3450  \n",
      "\n",
      "Fold: 13  Epoch: 560  Training loss = 2.2831  Validation loss = 3.3436  \n",
      "\n",
      "Fold: 13  Epoch: 561  Training loss = 2.2830  Validation loss = 3.3436  \n",
      "\n",
      "Fold: 13  Epoch: 562  Training loss = 2.2828  Validation loss = 3.3431  \n",
      "\n",
      "Fold: 13  Epoch: 563  Training loss = 2.2825  Validation loss = 3.3416  \n",
      "\n",
      "Fold: 13  Epoch: 564  Training loss = 2.2822  Validation loss = 3.3412  \n",
      "\n",
      "Fold: 13  Epoch: 565  Training loss = 2.2819  Validation loss = 3.3404  \n",
      "\n",
      "Fold: 13  Epoch: 566  Training loss = 2.2817  Validation loss = 3.3405  \n",
      "\n",
      "Fold: 13  Epoch: 567  Training loss = 2.2816  Validation loss = 3.3404  \n",
      "\n",
      "Fold: 13  Epoch: 568  Training loss = 2.2814  Validation loss = 3.3402  \n",
      "\n",
      "Fold: 13  Epoch: 569  Training loss = 2.2813  Validation loss = 3.3399  \n",
      "\n",
      "Fold: 13  Epoch: 570  Training loss = 2.2812  Validation loss = 3.3399  \n",
      "\n",
      "Fold: 13  Epoch: 571  Training loss = 2.2811  Validation loss = 3.3399  \n",
      "\n",
      "Fold: 13  Epoch: 572  Training loss = 2.2808  Validation loss = 3.3386  \n",
      "\n",
      "Fold: 13  Epoch: 573  Training loss = 2.2806  Validation loss = 3.3384  \n",
      "\n",
      "Fold: 13  Epoch: 574  Training loss = 2.2806  Validation loss = 3.3386  \n",
      "\n",
      "Fold: 13  Epoch: 575  Training loss = 2.2804  Validation loss = 3.3373  \n",
      "\n",
      "Fold: 13  Epoch: 576  Training loss = 2.2802  Validation loss = 3.3368  \n",
      "\n",
      "Fold: 13  Epoch: 577  Training loss = 2.2800  Validation loss = 3.3360  \n",
      "\n",
      "Fold: 13  Epoch: 578  Training loss = 2.2798  Validation loss = 3.3357  \n",
      "\n",
      "Fold: 13  Epoch: 579  Training loss = 2.2796  Validation loss = 3.3341  \n",
      "\n",
      "Fold: 13  Epoch: 580  Training loss = 2.2794  Validation loss = 3.3338  \n",
      "\n",
      "Fold: 13  Epoch: 581  Training loss = 2.2792  Validation loss = 3.3337  \n",
      "\n",
      "Fold: 13  Epoch: 582  Training loss = 2.2790  Validation loss = 3.3331  \n",
      "\n",
      "Fold: 13  Epoch: 583  Training loss = 2.2789  Validation loss = 3.3322  \n",
      "\n",
      "Fold: 13  Epoch: 584  Training loss = 2.2785  Validation loss = 3.3311  \n",
      "\n",
      "Fold: 13  Epoch: 585  Training loss = 2.2783  Validation loss = 3.3311  \n",
      "\n",
      "Fold: 13  Epoch: 586  Training loss = 2.2781  Validation loss = 3.3301  \n",
      "\n",
      "Fold: 13  Epoch: 587  Training loss = 2.2781  Validation loss = 3.3307  \n",
      "\n",
      "Fold: 13  Epoch: 588  Training loss = 2.2778  Validation loss = 3.3292  \n",
      "\n",
      "Fold: 13  Epoch: 589  Training loss = 2.2776  Validation loss = 3.3287  \n",
      "\n",
      "Fold: 13  Epoch: 590  Training loss = 2.2773  Validation loss = 3.3276  \n",
      "\n",
      "Fold: 13  Epoch: 591  Training loss = 2.2769  Validation loss = 3.3262  \n",
      "\n",
      "Fold: 13  Epoch: 592  Training loss = 2.2768  Validation loss = 3.3261  \n",
      "\n",
      "Fold: 13  Epoch: 593  Training loss = 2.2768  Validation loss = 3.3266  \n",
      "\n",
      "Fold: 13  Epoch: 594  Training loss = 2.2764  Validation loss = 3.3246  \n",
      "\n",
      "Fold: 13  Epoch: 595  Training loss = 2.2761  Validation loss = 3.3239  \n",
      "\n",
      "Fold: 13  Epoch: 596  Training loss = 2.2758  Validation loss = 3.3224  \n",
      "\n",
      "Fold: 13  Epoch: 597  Training loss = 2.2756  Validation loss = 3.3221  \n",
      "\n",
      "Fold: 13  Epoch: 598  Training loss = 2.2754  Validation loss = 3.3217  \n",
      "\n",
      "Fold: 13  Epoch: 599  Training loss = 2.2752  Validation loss = 3.3213  \n",
      "\n",
      "Fold: 13  Epoch: 600  Training loss = 2.2751  Validation loss = 3.3207  \n",
      "\n",
      "Fold: 13  Epoch: 601  Training loss = 2.2749  Validation loss = 3.3200  \n",
      "\n",
      "Fold: 13  Epoch: 602  Training loss = 2.2746  Validation loss = 3.3191  \n",
      "\n",
      "Fold: 13  Epoch: 603  Training loss = 2.2745  Validation loss = 3.3189  \n",
      "\n",
      "Fold: 13  Epoch: 604  Training loss = 2.2741  Validation loss = 3.3174  \n",
      "\n",
      "Fold: 13  Epoch: 605  Training loss = 2.2739  Validation loss = 3.3169  \n",
      "\n",
      "Fold: 13  Epoch: 606  Training loss = 2.2737  Validation loss = 3.3161  \n",
      "\n",
      "Fold: 13  Epoch: 607  Training loss = 2.2735  Validation loss = 3.3156  \n",
      "\n",
      "Fold: 13  Epoch: 608  Training loss = 2.2733  Validation loss = 3.3150  \n",
      "\n",
      "Fold: 13  Epoch: 609  Training loss = 2.2731  Validation loss = 3.3145  \n",
      "\n",
      "Fold: 13  Epoch: 610  Training loss = 2.2728  Validation loss = 3.3133  \n",
      "\n",
      "Fold: 13  Epoch: 611  Training loss = 2.2727  Validation loss = 3.3127  \n",
      "\n",
      "Fold: 13  Epoch: 612  Training loss = 2.2725  Validation loss = 3.3123  \n",
      "\n",
      "Fold: 13  Epoch: 613  Training loss = 2.2724  Validation loss = 3.3121  \n",
      "\n",
      "Fold: 13  Epoch: 614  Training loss = 2.2722  Validation loss = 3.3120  \n",
      "\n",
      "Fold: 13  Epoch: 615  Training loss = 2.2721  Validation loss = 3.3113  \n",
      "\n",
      "Fold: 13  Epoch: 616  Training loss = 2.2719  Validation loss = 3.3110  \n",
      "\n",
      "Fold: 13  Epoch: 617  Training loss = 2.2715  Validation loss = 3.3092  \n",
      "\n",
      "Fold: 13  Epoch: 618  Training loss = 2.2712  Validation loss = 3.3081  \n",
      "\n",
      "Fold: 13  Epoch: 619  Training loss = 2.2710  Validation loss = 3.3078  \n",
      "\n",
      "Fold: 13  Epoch: 620  Training loss = 2.2707  Validation loss = 3.3065  \n",
      "\n",
      "Fold: 13  Epoch: 621  Training loss = 2.2706  Validation loss = 3.3062  \n",
      "\n",
      "Fold: 13  Epoch: 622  Training loss = 2.2703  Validation loss = 3.3054  \n",
      "\n",
      "Fold: 13  Epoch: 623  Training loss = 2.2700  Validation loss = 3.3034  \n",
      "\n",
      "Fold: 13  Epoch: 624  Training loss = 2.2698  Validation loss = 3.3029  \n",
      "\n",
      "Fold: 13  Epoch: 625  Training loss = 2.2697  Validation loss = 3.3023  \n",
      "\n",
      "Fold: 13  Epoch: 626  Training loss = 2.2694  Validation loss = 3.3013  \n",
      "\n",
      "Fold: 13  Epoch: 627  Training loss = 2.2691  Validation loss = 3.3000  \n",
      "\n",
      "Fold: 13  Epoch: 628  Training loss = 2.2689  Validation loss = 3.2995  \n",
      "\n",
      "Fold: 13  Epoch: 629  Training loss = 2.2687  Validation loss = 3.2992  \n",
      "\n",
      "Fold: 13  Epoch: 630  Training loss = 2.2684  Validation loss = 3.2976  \n",
      "\n",
      "Fold: 13  Epoch: 631  Training loss = 2.2683  Validation loss = 3.2966  \n",
      "\n",
      "Fold: 13  Epoch: 632  Training loss = 2.2681  Validation loss = 3.2954  \n",
      "\n",
      "Fold: 13  Epoch: 633  Training loss = 2.2678  Validation loss = 3.2940  \n",
      "\n",
      "Fold: 13  Epoch: 634  Training loss = 2.2676  Validation loss = 3.2932  \n",
      "\n",
      "Fold: 13  Epoch: 635  Training loss = 2.2674  Validation loss = 3.2927  \n",
      "\n",
      "Fold: 13  Epoch: 636  Training loss = 2.2672  Validation loss = 3.2911  \n",
      "\n",
      "Fold: 13  Epoch: 637  Training loss = 2.2671  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 13  Epoch: 638  Training loss = 2.2668  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 13  Epoch: 639  Training loss = 2.2667  Validation loss = 3.2890  \n",
      "\n",
      "Fold: 13  Epoch: 640  Training loss = 2.2663  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 13  Epoch: 641  Training loss = 2.2660  Validation loss = 3.2888  \n",
      "\n",
      "Fold: 13  Epoch: 642  Training loss = 2.2655  Validation loss = 3.2876  \n",
      "\n",
      "Fold: 13  Epoch: 643  Training loss = 2.2651  Validation loss = 3.2864  \n",
      "\n",
      "Fold: 13  Epoch: 644  Training loss = 2.2646  Validation loss = 3.2865  \n",
      "\n",
      "Fold: 13  Epoch: 645  Training loss = 2.2642  Validation loss = 3.2859  \n",
      "\n",
      "Fold: 13  Epoch: 646  Training loss = 2.2639  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 13  Epoch: 647  Training loss = 2.2637  Validation loss = 3.2849  \n",
      "\n",
      "Fold: 13  Epoch: 648  Training loss = 2.2634  Validation loss = 3.2840  \n",
      "\n",
      "Fold: 13  Epoch: 649  Training loss = 2.2632  Validation loss = 3.2830  \n",
      "\n",
      "Fold: 13  Epoch: 650  Training loss = 2.2631  Validation loss = 3.2826  \n",
      "\n",
      "Fold: 13  Epoch: 651  Training loss = 2.2628  Validation loss = 3.2815  \n",
      "\n",
      "Fold: 13  Epoch: 652  Training loss = 2.2625  Validation loss = 3.2804  \n",
      "\n",
      "Fold: 13  Epoch: 653  Training loss = 2.2622  Validation loss = 3.2800  \n",
      "\n",
      "Fold: 13  Epoch: 654  Training loss = 2.2621  Validation loss = 3.2803  \n",
      "\n",
      "Fold: 13  Epoch: 655  Training loss = 2.2618  Validation loss = 3.2794  \n",
      "\n",
      "Fold: 13  Epoch: 656  Training loss = 2.2615  Validation loss = 3.2778  \n",
      "\n",
      "Fold: 13  Epoch: 657  Training loss = 2.2613  Validation loss = 3.2762  \n",
      "\n",
      "Fold: 13  Epoch: 658  Training loss = 2.2611  Validation loss = 3.2753  \n",
      "\n",
      "Fold: 13  Epoch: 659  Training loss = 2.2610  Validation loss = 3.2753  \n",
      "\n",
      "Fold: 13  Epoch: 660  Training loss = 2.2607  Validation loss = 3.2742  \n",
      "\n",
      "Fold: 13  Epoch: 661  Training loss = 2.2605  Validation loss = 3.2744  \n",
      "\n",
      "Fold: 13  Epoch: 662  Training loss = 2.2602  Validation loss = 3.2735  \n",
      "\n",
      "Fold: 13  Epoch: 663  Training loss = 2.2599  Validation loss = 3.2727  \n",
      "\n",
      "Fold: 13  Epoch: 664  Training loss = 2.2597  Validation loss = 3.2720  \n",
      "\n",
      "Fold: 13  Epoch: 665  Training loss = 2.2594  Validation loss = 3.2712  \n",
      "\n",
      "Fold: 13  Epoch: 666  Training loss = 2.2591  Validation loss = 3.2701  \n",
      "\n",
      "Fold: 13  Epoch: 667  Training loss = 2.2590  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 13  Epoch: 668  Training loss = 2.2589  Validation loss = 3.2705  \n",
      "\n",
      "Fold: 13  Epoch: 669  Training loss = 2.2590  Validation loss = 3.2714  \n",
      "\n",
      "Fold: 13  Epoch: 670  Training loss = 2.2588  Validation loss = 3.2710  \n",
      "\n",
      "Fold: 13  Epoch: 671  Training loss = 2.2585  Validation loss = 3.2698  \n",
      "\n",
      "Fold: 13  Epoch: 672  Training loss = 2.2583  Validation loss = 3.2691  \n",
      "\n",
      "Fold: 13  Epoch: 673  Training loss = 2.2580  Validation loss = 3.2676  \n",
      "\n",
      "Fold: 13  Epoch: 674  Training loss = 2.2579  Validation loss = 3.2677  \n",
      "\n",
      "Fold: 13  Epoch: 675  Training loss = 2.2577  Validation loss = 3.2675  \n",
      "\n",
      "Fold: 13  Epoch: 676  Training loss = 2.2576  Validation loss = 3.2670  \n",
      "\n",
      "Fold: 13  Epoch: 677  Training loss = 2.2572  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 13  Epoch: 678  Training loss = 2.2571  Validation loss = 3.2648  \n",
      "\n",
      "Fold: 13  Epoch: 679  Training loss = 2.2569  Validation loss = 3.2644  \n",
      "\n",
      "Fold: 13  Epoch: 680  Training loss = 2.2567  Validation loss = 3.2640  \n",
      "\n",
      "Fold: 13  Epoch: 681  Training loss = 2.2566  Validation loss = 3.2638  \n",
      "\n",
      "Fold: 13  Epoch: 682  Training loss = 2.2563  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 13  Epoch: 683  Training loss = 2.2561  Validation loss = 3.2613  \n",
      "\n",
      "Fold: 13  Epoch: 684  Training loss = 2.2559  Validation loss = 3.2606  \n",
      "\n",
      "Fold: 13  Epoch: 685  Training loss = 2.2558  Validation loss = 3.2603  \n",
      "\n",
      "Fold: 13  Epoch: 686  Training loss = 2.2557  Validation loss = 3.2603  \n",
      "\n",
      "Fold: 13  Epoch: 687  Training loss = 2.2555  Validation loss = 3.2593  \n",
      "\n",
      "Fold: 13  Epoch: 688  Training loss = 2.2551  Validation loss = 3.2577  \n",
      "\n",
      "Fold: 13  Epoch: 689  Training loss = 2.2548  Validation loss = 3.2561  \n",
      "\n",
      "Fold: 13  Epoch: 690  Training loss = 2.2546  Validation loss = 3.2556  \n",
      "\n",
      "Fold: 13  Epoch: 691  Training loss = 2.2544  Validation loss = 3.2545  \n",
      "\n",
      "Fold: 13  Epoch: 692  Training loss = 2.2541  Validation loss = 3.2533  \n",
      "\n",
      "Fold: 13  Epoch: 693  Training loss = 2.2539  Validation loss = 3.2529  \n",
      "\n",
      "Fold: 13  Epoch: 694  Training loss = 2.2537  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 13  Epoch: 695  Training loss = 2.2536  Validation loss = 3.2521  \n",
      "\n",
      "Fold: 13  Epoch: 696  Training loss = 2.2534  Validation loss = 3.2512  \n",
      "\n",
      "Fold: 13  Epoch: 697  Training loss = 2.2532  Validation loss = 3.2505  \n",
      "\n",
      "Fold: 13  Epoch: 698  Training loss = 2.2530  Validation loss = 3.2497  \n",
      "\n",
      "Fold: 13  Epoch: 699  Training loss = 2.2527  Validation loss = 3.2488  \n",
      "\n",
      "Fold: 13  Epoch: 700  Training loss = 2.2525  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 13  Epoch: 701  Training loss = 2.2522  Validation loss = 3.2472  \n",
      "\n",
      "Fold: 13  Epoch: 702  Training loss = 2.2520  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 13  Epoch: 703  Training loss = 2.2518  Validation loss = 3.2453  \n",
      "\n",
      "Fold: 13  Epoch: 704  Training loss = 2.2514  Validation loss = 3.2432  \n",
      "\n",
      "Fold: 13  Epoch: 705  Training loss = 2.2512  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 13  Epoch: 706  Training loss = 2.2510  Validation loss = 3.2415  \n",
      "\n",
      "Fold: 13  Epoch: 707  Training loss = 2.2507  Validation loss = 3.2398  \n",
      "\n",
      "Fold: 13  Epoch: 708  Training loss = 2.2505  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 13  Epoch: 709  Training loss = 2.2504  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 13  Epoch: 710  Training loss = 2.2502  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 13  Epoch: 711  Training loss = 2.2500  Validation loss = 3.2389  \n",
      "\n",
      "Fold: 13  Epoch: 712  Training loss = 2.2500  Validation loss = 3.2393  \n",
      "\n",
      "Fold: 13  Epoch: 713  Training loss = 2.2498  Validation loss = 3.2388  \n",
      "\n",
      "Fold: 13  Epoch: 714  Training loss = 2.2497  Validation loss = 3.2383  \n",
      "\n",
      "Fold: 13  Epoch: 715  Training loss = 2.2495  Validation loss = 3.2381  \n",
      "\n",
      "Fold: 13  Epoch: 716  Training loss = 2.2493  Validation loss = 3.2372  \n",
      "\n",
      "Fold: 13  Epoch: 717  Training loss = 2.2489  Validation loss = 3.2359  \n",
      "\n",
      "Fold: 13  Epoch: 718  Training loss = 2.2486  Validation loss = 3.2339  \n",
      "\n",
      "Fold: 13  Epoch: 719  Training loss = 2.2485  Validation loss = 3.2341  \n",
      "\n",
      "Fold: 13  Epoch: 720  Training loss = 2.2483  Validation loss = 3.2334  \n",
      "\n",
      "Fold: 13  Epoch: 721  Training loss = 2.2479  Validation loss = 3.2314  \n",
      "\n",
      "Fold: 13  Epoch: 722  Training loss = 2.2477  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 13  Epoch: 723  Training loss = 2.2474  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 13  Epoch: 724  Training loss = 2.2472  Validation loss = 3.2290  \n",
      "\n",
      "Fold: 13  Epoch: 725  Training loss = 2.2470  Validation loss = 3.2286  \n",
      "\n",
      "Fold: 13  Epoch: 726  Training loss = 2.2468  Validation loss = 3.2281  \n",
      "\n",
      "Fold: 13  Epoch: 727  Training loss = 2.2465  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 13  Epoch: 728  Training loss = 2.2461  Validation loss = 3.2251  \n",
      "\n",
      "Fold: 13  Epoch: 729  Training loss = 2.2460  Validation loss = 3.2248  \n",
      "\n",
      "Fold: 13  Epoch: 730  Training loss = 2.2456  Validation loss = 3.2229  \n",
      "\n",
      "Fold: 13  Epoch: 731  Training loss = 2.2454  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 13  Epoch: 732  Training loss = 2.2452  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 13  Epoch: 733  Training loss = 2.2452  Validation loss = 3.2216  \n",
      "\n",
      "Fold: 13  Epoch: 734  Training loss = 2.2448  Validation loss = 3.2200  \n",
      "\n",
      "Fold: 13  Epoch: 735  Training loss = 2.2446  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 13  Epoch: 736  Training loss = 2.2444  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 13  Epoch: 737  Training loss = 2.2442  Validation loss = 3.2177  \n",
      "\n",
      "Fold: 13  Epoch: 738  Training loss = 2.2441  Validation loss = 3.2178  \n",
      "\n",
      "Fold: 13  Epoch: 739  Training loss = 2.2438  Validation loss = 3.2155  \n",
      "\n",
      "Fold: 13  Epoch: 740  Training loss = 2.2435  Validation loss = 3.2140  \n",
      "\n",
      "Fold: 13  Epoch: 741  Training loss = 2.2433  Validation loss = 3.2135  \n",
      "\n",
      "Fold: 13  Epoch: 742  Training loss = 2.2432  Validation loss = 3.2117  \n",
      "\n",
      "Fold: 13  Epoch: 743  Training loss = 2.2427  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 13  Epoch: 744  Training loss = 2.2427  Validation loss = 3.2092  \n",
      "\n",
      "Fold: 13  Epoch: 745  Training loss = 2.2424  Validation loss = 3.2088  \n",
      "\n",
      "Fold: 13  Epoch: 746  Training loss = 2.2422  Validation loss = 3.2084  \n",
      "\n",
      "Fold: 13  Epoch: 747  Training loss = 2.2420  Validation loss = 3.2082  \n",
      "\n",
      "Fold: 13  Epoch: 748  Training loss = 2.2416  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 13  Epoch: 749  Training loss = 2.2415  Validation loss = 3.2058  \n",
      "\n",
      "Fold: 13  Epoch: 750  Training loss = 2.2412  Validation loss = 3.2041  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 750  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.3565  Validation loss = 7.1257  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.3562  Validation loss = 7.1249  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.3559  Validation loss = 7.1237  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.3555  Validation loss = 7.1219  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.3551  Validation loss = 7.1203  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.3546  Validation loss = 7.1186  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.3545  Validation loss = 7.1185  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.3542  Validation loss = 7.1173  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.3540  Validation loss = 7.1166  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.3535  Validation loss = 7.1149  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.3533  Validation loss = 7.1140  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.3530  Validation loss = 7.1129  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.3525  Validation loss = 7.1115  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.3523  Validation loss = 7.1106  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.3519  Validation loss = 7.1092  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.3516  Validation loss = 7.1084  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.3512  Validation loss = 7.1071  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 2.3511  Validation loss = 7.1065  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.3508  Validation loss = 7.1059  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.3505  Validation loss = 7.1045  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.3500  Validation loss = 7.1030  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 2.3498  Validation loss = 7.1020  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 2.3497  Validation loss = 7.1014  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 2.3494  Validation loss = 7.1003  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 2.3491  Validation loss = 7.0996  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 2.3488  Validation loss = 7.0987  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 2.3486  Validation loss = 7.0980  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 2.3486  Validation loss = 7.0978  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 2.3482  Validation loss = 7.0963  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.3477  Validation loss = 7.0945  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 2.3473  Validation loss = 7.0931  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 2.3472  Validation loss = 7.0930  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 2.3469  Validation loss = 7.0919  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 2.3465  Validation loss = 7.0902  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 2.3459  Validation loss = 7.0881  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 2.3458  Validation loss = 7.0875  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 2.3459  Validation loss = 7.0871  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 2.3452  Validation loss = 7.0855  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 2.3448  Validation loss = 7.0844  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 2.3446  Validation loss = 7.0834  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 2.3442  Validation loss = 7.0823  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 2.3441  Validation loss = 7.0816  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 2.3436  Validation loss = 7.0800  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 2.3434  Validation loss = 7.0795  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 2.3433  Validation loss = 7.0790  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 2.3431  Validation loss = 7.0779  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 2.3426  Validation loss = 7.0761  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 2.3422  Validation loss = 7.0748  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 2.3420  Validation loss = 7.0740  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 2.3415  Validation loss = 7.0727  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 2.3410  Validation loss = 7.0708  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 2.3407  Validation loss = 7.0693  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 2.3406  Validation loss = 7.0686  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 2.3400  Validation loss = 7.0669  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 2.3398  Validation loss = 7.0662  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 2.3397  Validation loss = 7.0655  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 2.3392  Validation loss = 7.0637  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 2.3389  Validation loss = 7.0629  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 2.3385  Validation loss = 7.0617  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 2.3383  Validation loss = 7.0605  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 2.3381  Validation loss = 7.0603  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 2.3381  Validation loss = 7.0603  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 2.3377  Validation loss = 7.0586  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 2.3374  Validation loss = 7.0575  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 2.3371  Validation loss = 7.0565  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 2.3368  Validation loss = 7.0556  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 2.3366  Validation loss = 7.0546  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 2.3362  Validation loss = 7.0533  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 2.3358  Validation loss = 7.0522  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 2.3355  Validation loss = 7.0509  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 2.3352  Validation loss = 7.0499  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 2.3349  Validation loss = 7.0486  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 2.3347  Validation loss = 7.0481  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 2.3344  Validation loss = 7.0472  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 2.3341  Validation loss = 7.0458  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 2.3338  Validation loss = 7.0449  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 2.3334  Validation loss = 7.0435  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 2.3331  Validation loss = 7.0423  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 2.3327  Validation loss = 7.0405  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 2.3325  Validation loss = 7.0397  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 2.3323  Validation loss = 7.0391  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 2.3322  Validation loss = 7.0387  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 2.3319  Validation loss = 7.0374  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 2.3314  Validation loss = 7.0353  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 2.3309  Validation loss = 7.0338  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 2.3306  Validation loss = 7.0328  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 2.3302  Validation loss = 7.0312  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 2.3299  Validation loss = 7.0299  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 2.3296  Validation loss = 7.0286  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 2.3293  Validation loss = 7.0272  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 2.3288  Validation loss = 7.0252  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 2.3285  Validation loss = 7.0242  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 2.3282  Validation loss = 7.0229  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 2.3278  Validation loss = 7.0215  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 2.3274  Validation loss = 7.0197  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 2.3271  Validation loss = 7.0186  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 2.3268  Validation loss = 7.0173  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 2.3266  Validation loss = 7.0167  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 2.3262  Validation loss = 7.0152  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 2.3259  Validation loss = 7.0140  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 2.3254  Validation loss = 7.0125  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 2.3250  Validation loss = 7.0114  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 2.3247  Validation loss = 7.0101  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 2.3245  Validation loss = 7.0091  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 2.3243  Validation loss = 7.0077  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 2.3240  Validation loss = 7.0058  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 2.3237  Validation loss = 7.0055  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 2.3235  Validation loss = 7.0053  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 2.3232  Validation loss = 7.0044  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 2.3231  Validation loss = 7.0039  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 2.3230  Validation loss = 7.0040  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 2.3228  Validation loss = 7.0031  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 2.3225  Validation loss = 7.0022  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 2.3221  Validation loss = 7.0007  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 2.3222  Validation loss = 7.0002  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 2.3219  Validation loss = 6.9992  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 2.3218  Validation loss = 6.9975  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 2.3214  Validation loss = 6.9961  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 2.3212  Validation loss = 6.9958  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 2.3208  Validation loss = 6.9945  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 2.3206  Validation loss = 6.9944  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 2.3202  Validation loss = 6.9931  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 2.3197  Validation loss = 6.9918  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 2.3196  Validation loss = 6.9916  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 2.3193  Validation loss = 6.9901  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 2.3191  Validation loss = 6.9893  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 2.3187  Validation loss = 6.9875  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 2.3185  Validation loss = 6.9868  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 2.3180  Validation loss = 6.9849  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 2.3180  Validation loss = 6.9842  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 2.3177  Validation loss = 6.9835  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 2.3175  Validation loss = 6.9826  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 2.3172  Validation loss = 6.9816  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 2.3169  Validation loss = 6.9806  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 2.3166  Validation loss = 6.9793  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 2.3163  Validation loss = 6.9788  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 2.3161  Validation loss = 6.9780  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 2.3158  Validation loss = 6.9766  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 2.3157  Validation loss = 6.9761  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 2.3154  Validation loss = 6.9759  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 2.3152  Validation loss = 6.9747  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 2.3149  Validation loss = 6.9731  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 2.3146  Validation loss = 6.9716  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 2.3144  Validation loss = 6.9703  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 2.3141  Validation loss = 6.9689  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 2.3140  Validation loss = 6.9679  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 2.3139  Validation loss = 6.9668  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 2.3136  Validation loss = 6.9657  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 2.3134  Validation loss = 6.9647  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 2.3132  Validation loss = 6.9632  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 2.3130  Validation loss = 6.9611  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 2.3127  Validation loss = 6.9594  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 2.3123  Validation loss = 6.9591  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 2.3119  Validation loss = 6.9580  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 2.3115  Validation loss = 6.9567  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 2.3111  Validation loss = 6.9557  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 2.3108  Validation loss = 6.9540  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 2.3105  Validation loss = 6.9527  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 2.3102  Validation loss = 6.9514  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 2.3098  Validation loss = 6.9504  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 2.3096  Validation loss = 6.9494  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 2.3093  Validation loss = 6.9472  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 2.3090  Validation loss = 6.9455  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 2.3086  Validation loss = 6.9441  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 2.3083  Validation loss = 6.9429  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 2.3081  Validation loss = 6.9423  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 2.3078  Validation loss = 6.9417  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 2.3077  Validation loss = 6.9412  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 2.3075  Validation loss = 6.9407  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 2.3072  Validation loss = 6.9392  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 2.3071  Validation loss = 6.9380  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 2.3068  Validation loss = 6.9367  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 2.3065  Validation loss = 6.9363  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 2.3060  Validation loss = 6.9348  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 2.3058  Validation loss = 6.9339  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 2.3057  Validation loss = 6.9332  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 2.3052  Validation loss = 6.9314  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 2.3051  Validation loss = 6.9307  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 2.3047  Validation loss = 6.9295  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 2.3045  Validation loss = 6.9285  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 2.3042  Validation loss = 6.9279  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 2.3041  Validation loss = 6.9277  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 2.3040  Validation loss = 6.9274  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 2.3039  Validation loss = 6.9274  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 2.3037  Validation loss = 6.9264  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 2.3036  Validation loss = 6.9257  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 2.3032  Validation loss = 6.9244  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 2.3024  Validation loss = 6.9229  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 2.3023  Validation loss = 6.9225  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 2.3021  Validation loss = 6.9218  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 2.3019  Validation loss = 6.9208  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 2.3015  Validation loss = 6.9192  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 2.3013  Validation loss = 6.9186  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 2.3012  Validation loss = 6.9180  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 2.3011  Validation loss = 6.9173  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 2.3008  Validation loss = 6.9162  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 2.3004  Validation loss = 6.9150  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 2.3002  Validation loss = 6.9132  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 2.2999  Validation loss = 6.9123  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 2.2995  Validation loss = 6.9115  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 2.2995  Validation loss = 6.9112  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 2.2992  Validation loss = 6.9104  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 2.2991  Validation loss = 6.9089  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 2.2988  Validation loss = 6.9078  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 2.2986  Validation loss = 6.9073  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 2.2983  Validation loss = 6.9075  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 2.2981  Validation loss = 6.9054  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 2.2979  Validation loss = 6.9045  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 2.2976  Validation loss = 6.9044  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 2.2975  Validation loss = 6.9033  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 2.2976  Validation loss = 6.9026  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 2.2971  Validation loss = 6.9021  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 2.2967  Validation loss = 6.9009  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 2.2963  Validation loss = 6.9003  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 2.2959  Validation loss = 6.8989  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 2.2956  Validation loss = 6.8969  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 2.2953  Validation loss = 6.8958  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 2.2950  Validation loss = 6.8950  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 2.2948  Validation loss = 6.8945  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 2.2945  Validation loss = 6.8933  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 2.2941  Validation loss = 6.8914  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 2.2938  Validation loss = 6.8911  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 2.2934  Validation loss = 6.8898  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 2.2934  Validation loss = 6.8901  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 2.2932  Validation loss = 6.8901  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 2.2926  Validation loss = 6.8884  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 2.2924  Validation loss = 6.8871  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 2.2921  Validation loss = 6.8861  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 2.2919  Validation loss = 6.8854  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 2.2916  Validation loss = 6.8838  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 2.2913  Validation loss = 6.8827  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 2.2910  Validation loss = 6.8810  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 2.2906  Validation loss = 6.8801  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 2.2903  Validation loss = 6.8791  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 2.2901  Validation loss = 6.8792  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 2.2897  Validation loss = 6.8778  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 2.2894  Validation loss = 6.8764  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 2.2893  Validation loss = 6.8755  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 2.2890  Validation loss = 6.8734  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 2.2886  Validation loss = 6.8718  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 2.2885  Validation loss = 6.8719  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 2.2886  Validation loss = 6.8718  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 2.2882  Validation loss = 6.8713  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 2.2880  Validation loss = 6.8704  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 2.2878  Validation loss = 6.8696  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 2.2872  Validation loss = 6.8685  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 2.2870  Validation loss = 6.8671  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 2.2868  Validation loss = 6.8665  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 2.2866  Validation loss = 6.8653  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 2.2862  Validation loss = 6.8645  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 2.2860  Validation loss = 6.8637  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 2.2859  Validation loss = 6.8639  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 2.2856  Validation loss = 6.8630  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 2.2856  Validation loss = 6.8625  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 2.2852  Validation loss = 6.8616  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 2.2850  Validation loss = 6.8610  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 2.2848  Validation loss = 6.8605  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 2.2844  Validation loss = 6.8592  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 2.2843  Validation loss = 6.8594  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 2.2842  Validation loss = 6.8588  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 2.2841  Validation loss = 6.8580  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 2.2838  Validation loss = 6.8557  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 2.2839  Validation loss = 6.8554  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 2.2830  Validation loss = 6.8538  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 2.2829  Validation loss = 6.8534  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 2.2826  Validation loss = 6.8526  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 2.2823  Validation loss = 6.8516  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 2.2820  Validation loss = 6.8504  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 2.2818  Validation loss = 6.8500  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 2.2814  Validation loss = 6.8490  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 2.2811  Validation loss = 6.8477  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 2.2807  Validation loss = 6.8461  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 2.2804  Validation loss = 6.8452  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 2.2804  Validation loss = 6.8447  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 2.2800  Validation loss = 6.8437  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 2.2798  Validation loss = 6.8436  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 2.2794  Validation loss = 6.8416  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 2.2794  Validation loss = 6.8420  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 2.2791  Validation loss = 6.8405  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 2.2790  Validation loss = 6.8407  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 2.2789  Validation loss = 6.8401  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 2.2786  Validation loss = 6.8389  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 2.2784  Validation loss = 6.8387  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 2.2780  Validation loss = 6.8374  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 2.2779  Validation loss = 6.8372  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 2.2781  Validation loss = 6.8369  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 2.2775  Validation loss = 6.8366  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 2.2773  Validation loss = 6.8360  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 2.2772  Validation loss = 6.8354  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 2.2771  Validation loss = 6.8349  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 2.2769  Validation loss = 6.8338  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 2.2767  Validation loss = 6.8330  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 2.2763  Validation loss = 6.8320  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 2.2762  Validation loss = 6.8312  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 2.2758  Validation loss = 6.8296  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 2.2756  Validation loss = 6.8291  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 2.2753  Validation loss = 6.8277  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 2.2750  Validation loss = 6.8268  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 2.2748  Validation loss = 6.8256  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 2.2743  Validation loss = 6.8239  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 2.2740  Validation loss = 6.8229  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 2.2738  Validation loss = 6.8220  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 2.2734  Validation loss = 6.8202  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 2.2731  Validation loss = 6.8190  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 2.2728  Validation loss = 6.8179  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 2.2723  Validation loss = 6.8161  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 2.2721  Validation loss = 6.8150  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 2.2721  Validation loss = 6.8151  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 2.2718  Validation loss = 6.8135  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 2.2714  Validation loss = 6.8121  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 2.2714  Validation loss = 6.8115  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 2.2712  Validation loss = 6.8104  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 2.2709  Validation loss = 6.8107  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 2.2706  Validation loss = 6.8088  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 2.2705  Validation loss = 6.8081  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 2.2701  Validation loss = 6.8073  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 2.2699  Validation loss = 6.8068  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 2.2699  Validation loss = 6.8053  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 2.2696  Validation loss = 6.8047  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 2.2693  Validation loss = 6.8028  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 2.2691  Validation loss = 6.8027  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 2.2689  Validation loss = 6.8021  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 2.2689  Validation loss = 6.8015  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 2.2683  Validation loss = 6.7998  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 2.2684  Validation loss = 6.7993  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 2.2682  Validation loss = 6.7985  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 2.2680  Validation loss = 6.7982  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 2.2679  Validation loss = 6.7971  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 2.2676  Validation loss = 6.7964  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 2.2677  Validation loss = 6.7962  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 2.2678  Validation loss = 6.7950  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 2.2678  Validation loss = 6.7952  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 2.2677  Validation loss = 6.7947  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 2.2674  Validation loss = 6.7941  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 2.2672  Validation loss = 6.7931  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 2.2667  Validation loss = 6.7917  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 2.2663  Validation loss = 6.7906  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 2.2658  Validation loss = 6.7900  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 2.2653  Validation loss = 6.7892  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 2.2650  Validation loss = 6.7874  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 2.2647  Validation loss = 6.7860  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 2.2646  Validation loss = 6.7865  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 2.2645  Validation loss = 6.7862  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 2.2644  Validation loss = 6.7855  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 2.2643  Validation loss = 6.7850  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 2.2638  Validation loss = 6.7836  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 2.2636  Validation loss = 6.7828  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 2.2633  Validation loss = 6.7813  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 2.2629  Validation loss = 6.7795  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 2.2626  Validation loss = 6.7780  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 2.2627  Validation loss = 6.7782  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 2.2627  Validation loss = 6.7779  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 2.2637  Validation loss = 6.7778  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 2.2621  Validation loss = 6.7764  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 2.2618  Validation loss = 6.7758  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 2.2618  Validation loss = 6.7758  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 2.2618  Validation loss = 6.7753  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 2.2614  Validation loss = 6.7741  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 2.2611  Validation loss = 6.7739  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 2.2608  Validation loss = 6.7730  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 2.2605  Validation loss = 6.7716  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 2.2604  Validation loss = 6.7718  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 2.2602  Validation loss = 6.7713  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 2.2600  Validation loss = 6.7704  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 2.2598  Validation loss = 6.7697  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 2.2597  Validation loss = 6.7689  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 2.2594  Validation loss = 6.7683  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 2.2591  Validation loss = 6.7673  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 2.2587  Validation loss = 6.7652  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 2.2584  Validation loss = 6.7636  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 2.2583  Validation loss = 6.7628  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 2.2580  Validation loss = 6.7624  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 2.2579  Validation loss = 6.7618  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 2.2576  Validation loss = 6.7606  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 2.2575  Validation loss = 6.7589  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 2.2574  Validation loss = 6.7583  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 2.2572  Validation loss = 6.7566  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 2.2568  Validation loss = 6.7564  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 2.2565  Validation loss = 6.7554  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 2.2563  Validation loss = 6.7545  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 2.2559  Validation loss = 6.7527  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 2.2555  Validation loss = 6.7511  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 2.2554  Validation loss = 6.7499  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 2.2551  Validation loss = 6.7489  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 2.2551  Validation loss = 6.7488  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 2.2551  Validation loss = 6.7487  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 2.2548  Validation loss = 6.7482  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 2.2547  Validation loss = 6.7476  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 2.2547  Validation loss = 6.7468  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 2.2545  Validation loss = 6.7460  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 2.2544  Validation loss = 6.7450  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 2.2544  Validation loss = 6.7434  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 2.2541  Validation loss = 6.7424  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 2.2538  Validation loss = 6.7417  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 2.2539  Validation loss = 6.7403  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 2.2538  Validation loss = 6.7389  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 2.2539  Validation loss = 6.7382  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 2.2535  Validation loss = 6.7377  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 2.2533  Validation loss = 6.7366  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 2.2531  Validation loss = 6.7360  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 2.2527  Validation loss = 6.7359  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 2.2524  Validation loss = 6.7350  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 2.2516  Validation loss = 6.7340  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 2.2512  Validation loss = 6.7331  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 2.2508  Validation loss = 6.7319  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 2.2506  Validation loss = 6.7313  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 2.2506  Validation loss = 6.7306  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 2.2504  Validation loss = 6.7294  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 2.2502  Validation loss = 6.7284  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 2.2501  Validation loss = 6.7279  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 2.2500  Validation loss = 6.7279  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 2.2498  Validation loss = 6.7272  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 2.2498  Validation loss = 6.7275  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 2.2494  Validation loss = 6.7276  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 2.2491  Validation loss = 6.7262  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 2.2488  Validation loss = 6.7244  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 2.2487  Validation loss = 6.7229  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 2.2484  Validation loss = 6.7226  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 2.2482  Validation loss = 6.7219  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 2.2481  Validation loss = 6.7217  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 2.2476  Validation loss = 6.7207  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 2.2472  Validation loss = 6.7202  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 2.2470  Validation loss = 6.7198  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 2.2468  Validation loss = 6.7198  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 2.2463  Validation loss = 6.7185  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 2.2461  Validation loss = 6.7182  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 2.2457  Validation loss = 6.7163  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 2.2456  Validation loss = 6.7155  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 2.2454  Validation loss = 6.7157  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 2.2455  Validation loss = 6.7151  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 2.2453  Validation loss = 6.7150  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 2.2450  Validation loss = 6.7148  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 2.2448  Validation loss = 6.7134  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 2.2444  Validation loss = 6.7124  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 2.2441  Validation loss = 6.7118  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 2.2438  Validation loss = 6.7111  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 2.2436  Validation loss = 6.7103  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 2.2434  Validation loss = 6.7097  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 2.2432  Validation loss = 6.7096  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 2.2430  Validation loss = 6.7089  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 2.2426  Validation loss = 6.7069  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 2.2422  Validation loss = 6.7052  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 2.2418  Validation loss = 6.7043  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 2.2416  Validation loss = 6.7034  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 2.2414  Validation loss = 6.7034  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 2.2412  Validation loss = 6.7028  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 2.2412  Validation loss = 6.7021  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 2.2411  Validation loss = 6.7004  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 2.2408  Validation loss = 6.7000  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 2.2407  Validation loss = 6.6984  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 2.2403  Validation loss = 6.6989  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 2.2401  Validation loss = 6.6976  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 2.2399  Validation loss = 6.6973  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 2.2398  Validation loss = 6.6965  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 2.2395  Validation loss = 6.6956  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 2.2393  Validation loss = 6.6949  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 2.2391  Validation loss = 6.6929  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 2.2387  Validation loss = 6.6921  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 2.2386  Validation loss = 6.6916  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 2.2382  Validation loss = 6.6908  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 2.2380  Validation loss = 6.6901  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 2.2376  Validation loss = 6.6892  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 2.2374  Validation loss = 6.6888  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 2.2372  Validation loss = 6.6878  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 2.2368  Validation loss = 6.6867  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 2.2368  Validation loss = 6.6860  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 2.2367  Validation loss = 6.6857  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 2.2363  Validation loss = 6.6840  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 2.2362  Validation loss = 6.6838  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 2.2358  Validation loss = 6.6824  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 2.2356  Validation loss = 6.6818  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 2.2355  Validation loss = 6.6822  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 2.2355  Validation loss = 6.6811  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 2.2351  Validation loss = 6.6804  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 2.2348  Validation loss = 6.6797  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 2.2345  Validation loss = 6.6785  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 2.2343  Validation loss = 6.6779  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 2.2344  Validation loss = 6.6774  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 2.2345  Validation loss = 6.6776  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 2.2342  Validation loss = 6.6779  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 2.2343  Validation loss = 6.6770  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 2.2339  Validation loss = 6.6757  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 2.2331  Validation loss = 6.6750  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 2.2332  Validation loss = 6.6751  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 2.2326  Validation loss = 6.6734  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 2.2326  Validation loss = 6.6727  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 2.2322  Validation loss = 6.6718  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 2.2322  Validation loss = 6.6726  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 2.2322  Validation loss = 6.6717  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 2.2322  Validation loss = 6.6719  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 2.2316  Validation loss = 6.6717  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 2.2315  Validation loss = 6.6713  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 2.2311  Validation loss = 6.6700  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 2.2309  Validation loss = 6.6692  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 2.2307  Validation loss = 6.6681  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 2.2304  Validation loss = 6.6668  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 2.2303  Validation loss = 6.6667  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 2.2301  Validation loss = 6.6663  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 2.2299  Validation loss = 6.6658  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 2.2296  Validation loss = 6.6653  \n",
      "\n",
      "Fold: 14  Epoch: 501  Training loss = 2.2296  Validation loss = 6.6651  \n",
      "\n",
      "Fold: 14  Epoch: 502  Training loss = 2.2295  Validation loss = 6.6647  \n",
      "\n",
      "Fold: 14  Epoch: 503  Training loss = 2.2292  Validation loss = 6.6637  \n",
      "\n",
      "Fold: 14  Epoch: 504  Training loss = 2.2287  Validation loss = 6.6626  \n",
      "\n",
      "Fold: 14  Epoch: 505  Training loss = 2.2287  Validation loss = 6.6623  \n",
      "\n",
      "Fold: 14  Epoch: 506  Training loss = 2.2285  Validation loss = 6.6612  \n",
      "\n",
      "Fold: 14  Epoch: 507  Training loss = 2.2279  Validation loss = 6.6589  \n",
      "\n",
      "Fold: 14  Epoch: 508  Training loss = 2.2276  Validation loss = 6.6581  \n",
      "\n",
      "Fold: 14  Epoch: 509  Training loss = 2.2273  Validation loss = 6.6572  \n",
      "\n",
      "Fold: 14  Epoch: 510  Training loss = 2.2269  Validation loss = 6.6554  \n",
      "\n",
      "Fold: 14  Epoch: 511  Training loss = 2.2266  Validation loss = 6.6538  \n",
      "\n",
      "Fold: 14  Epoch: 512  Training loss = 2.2264  Validation loss = 6.6531  \n",
      "\n",
      "Fold: 14  Epoch: 513  Training loss = 2.2261  Validation loss = 6.6521  \n",
      "\n",
      "Fold: 14  Epoch: 514  Training loss = 2.2258  Validation loss = 6.6509  \n",
      "\n",
      "Fold: 14  Epoch: 515  Training loss = 2.2258  Validation loss = 6.6505  \n",
      "\n",
      "Fold: 14  Epoch: 516  Training loss = 2.2255  Validation loss = 6.6491  \n",
      "\n",
      "Fold: 14  Epoch: 517  Training loss = 2.2253  Validation loss = 6.6489  \n",
      "\n",
      "Fold: 14  Epoch: 518  Training loss = 2.2252  Validation loss = 6.6492  \n",
      "\n",
      "Fold: 14  Epoch: 519  Training loss = 2.2248  Validation loss = 6.6480  \n",
      "\n",
      "Fold: 14  Epoch: 520  Training loss = 2.2245  Validation loss = 6.6471  \n",
      "\n",
      "Fold: 14  Epoch: 521  Training loss = 2.2243  Validation loss = 6.6473  \n",
      "\n",
      "Fold: 14  Epoch: 522  Training loss = 2.2241  Validation loss = 6.6454  \n",
      "\n",
      "Fold: 14  Epoch: 523  Training loss = 2.2238  Validation loss = 6.6443  \n",
      "\n",
      "Fold: 14  Epoch: 524  Training loss = 2.2238  Validation loss = 6.6435  \n",
      "\n",
      "Fold: 14  Epoch: 525  Training loss = 2.2235  Validation loss = 6.6427  \n",
      "\n",
      "Fold: 14  Epoch: 526  Training loss = 2.2234  Validation loss = 6.6419  \n",
      "\n",
      "Fold: 14  Epoch: 527  Training loss = 2.2231  Validation loss = 6.6408  \n",
      "\n",
      "Fold: 14  Epoch: 528  Training loss = 2.2228  Validation loss = 6.6397  \n",
      "\n",
      "Fold: 14  Epoch: 529  Training loss = 2.2226  Validation loss = 6.6391  \n",
      "\n",
      "Fold: 14  Epoch: 530  Training loss = 2.2225  Validation loss = 6.6381  \n",
      "\n",
      "Fold: 14  Epoch: 531  Training loss = 2.2223  Validation loss = 6.6370  \n",
      "\n",
      "Fold: 14  Epoch: 532  Training loss = 2.2220  Validation loss = 6.6355  \n",
      "\n",
      "Fold: 14  Epoch: 533  Training loss = 2.2216  Validation loss = 6.6342  \n",
      "\n",
      "Fold: 14  Epoch: 534  Training loss = 2.2212  Validation loss = 6.6328  \n",
      "\n",
      "Fold: 14  Epoch: 535  Training loss = 2.2210  Validation loss = 6.6321  \n",
      "\n",
      "Fold: 14  Epoch: 536  Training loss = 2.2210  Validation loss = 6.6318  \n",
      "\n",
      "Fold: 14  Epoch: 537  Training loss = 2.2209  Validation loss = 6.6310  \n",
      "\n",
      "Fold: 14  Epoch: 538  Training loss = 2.2207  Validation loss = 6.6297  \n",
      "\n",
      "Fold: 14  Epoch: 539  Training loss = 2.2206  Validation loss = 6.6285  \n",
      "\n",
      "Fold: 14  Epoch: 540  Training loss = 2.2203  Validation loss = 6.6273  \n",
      "\n",
      "Fold: 14  Epoch: 541  Training loss = 2.2201  Validation loss = 6.6263  \n",
      "\n",
      "Fold: 14  Epoch: 542  Training loss = 2.2200  Validation loss = 6.6256  \n",
      "\n",
      "Fold: 14  Epoch: 543  Training loss = 2.2201  Validation loss = 6.6247  \n",
      "\n",
      "Fold: 14  Epoch: 544  Training loss = 2.2200  Validation loss = 6.6234  \n",
      "\n",
      "Fold: 14  Epoch: 545  Training loss = 2.2194  Validation loss = 6.6223  \n",
      "\n",
      "Fold: 14  Epoch: 546  Training loss = 2.2193  Validation loss = 6.6218  \n",
      "\n",
      "Fold: 14  Epoch: 547  Training loss = 2.2191  Validation loss = 6.6212  \n",
      "\n",
      "Fold: 14  Epoch: 548  Training loss = 2.2187  Validation loss = 6.6207  \n",
      "\n",
      "Fold: 14  Epoch: 549  Training loss = 2.2185  Validation loss = 6.6200  \n",
      "\n",
      "Fold: 14  Epoch: 550  Training loss = 2.2181  Validation loss = 6.6190  \n",
      "\n",
      "Fold: 14  Epoch: 551  Training loss = 2.2178  Validation loss = 6.6184  \n",
      "\n",
      "Fold: 14  Epoch: 552  Training loss = 2.2177  Validation loss = 6.6175  \n",
      "\n",
      "Fold: 14  Epoch: 553  Training loss = 2.2174  Validation loss = 6.6160  \n",
      "\n",
      "Fold: 14  Epoch: 554  Training loss = 2.2173  Validation loss = 6.6147  \n",
      "\n",
      "Fold: 14  Epoch: 555  Training loss = 2.2172  Validation loss = 6.6149  \n",
      "\n",
      "Fold: 14  Epoch: 556  Training loss = 2.2172  Validation loss = 6.6145  \n",
      "\n",
      "Fold: 14  Epoch: 557  Training loss = 2.2169  Validation loss = 6.6129  \n",
      "\n",
      "Fold: 14  Epoch: 558  Training loss = 2.2165  Validation loss = 6.6118  \n",
      "\n",
      "Fold: 14  Epoch: 559  Training loss = 2.2164  Validation loss = 6.6111  \n",
      "\n",
      "Fold: 14  Epoch: 560  Training loss = 2.2162  Validation loss = 6.6094  \n",
      "\n",
      "Fold: 14  Epoch: 561  Training loss = 2.2157  Validation loss = 6.6089  \n",
      "\n",
      "Fold: 14  Epoch: 562  Training loss = 2.2152  Validation loss = 6.6081  \n",
      "\n",
      "Fold: 14  Epoch: 563  Training loss = 2.2151  Validation loss = 6.6082  \n",
      "\n",
      "Fold: 14  Epoch: 564  Training loss = 2.2148  Validation loss = 6.6072  \n",
      "\n",
      "Fold: 14  Epoch: 565  Training loss = 2.2147  Validation loss = 6.6064  \n",
      "\n",
      "Fold: 14  Epoch: 566  Training loss = 2.2144  Validation loss = 6.6050  \n",
      "\n",
      "Fold: 14  Epoch: 567  Training loss = 2.2145  Validation loss = 6.6038  \n",
      "\n",
      "Fold: 14  Epoch: 568  Training loss = 2.2146  Validation loss = 6.6026  \n",
      "\n",
      "Fold: 14  Epoch: 569  Training loss = 2.2145  Validation loss = 6.6019  \n",
      "\n",
      "Fold: 14  Epoch: 570  Training loss = 2.2144  Validation loss = 6.6019  \n",
      "\n",
      "Fold: 14  Epoch: 571  Training loss = 2.2141  Validation loss = 6.6005  \n",
      "\n",
      "Fold: 14  Epoch: 572  Training loss = 2.2137  Validation loss = 6.5997  \n",
      "\n",
      "Fold: 14  Epoch: 573  Training loss = 2.2134  Validation loss = 6.5996  \n",
      "\n",
      "Fold: 14  Epoch: 574  Training loss = 2.2130  Validation loss = 6.5982  \n",
      "\n",
      "Fold: 14  Epoch: 575  Training loss = 2.2128  Validation loss = 6.5970  \n",
      "\n",
      "Fold: 14  Epoch: 576  Training loss = 2.2126  Validation loss = 6.5958  \n",
      "\n",
      "Fold: 14  Epoch: 577  Training loss = 2.2124  Validation loss = 6.5958  \n",
      "\n",
      "Fold: 14  Epoch: 578  Training loss = 2.2123  Validation loss = 6.5949  \n",
      "\n",
      "Fold: 14  Epoch: 579  Training loss = 2.2122  Validation loss = 6.5942  \n",
      "\n",
      "Fold: 14  Epoch: 580  Training loss = 2.2118  Validation loss = 6.5920  \n",
      "\n",
      "Fold: 14  Epoch: 581  Training loss = 2.2116  Validation loss = 6.5907  \n",
      "\n",
      "Fold: 14  Epoch: 582  Training loss = 2.2113  Validation loss = 6.5892  \n",
      "\n",
      "Fold: 14  Epoch: 583  Training loss = 2.2111  Validation loss = 6.5882  \n",
      "\n",
      "Fold: 14  Epoch: 584  Training loss = 2.2109  Validation loss = 6.5877  \n",
      "\n",
      "Fold: 14  Epoch: 585  Training loss = 2.2109  Validation loss = 6.5860  \n",
      "\n",
      "Fold: 14  Epoch: 586  Training loss = 2.2104  Validation loss = 6.5858  \n",
      "\n",
      "Fold: 14  Epoch: 587  Training loss = 2.2101  Validation loss = 6.5853  \n",
      "\n",
      "Fold: 14  Epoch: 588  Training loss = 2.2097  Validation loss = 6.5840  \n",
      "\n",
      "Fold: 14  Epoch: 589  Training loss = 2.2096  Validation loss = 6.5825  \n",
      "\n",
      "Fold: 14  Epoch: 590  Training loss = 2.2091  Validation loss = 6.5815  \n",
      "\n",
      "Fold: 14  Epoch: 591  Training loss = 2.2089  Validation loss = 6.5804  \n",
      "\n",
      "Fold: 14  Epoch: 592  Training loss = 2.2085  Validation loss = 6.5790  \n",
      "\n",
      "Fold: 14  Epoch: 593  Training loss = 2.2081  Validation loss = 6.5772  \n",
      "\n",
      "Fold: 14  Epoch: 594  Training loss = 2.2080  Validation loss = 6.5775  \n",
      "\n",
      "Fold: 14  Epoch: 595  Training loss = 2.2078  Validation loss = 6.5765  \n",
      "\n",
      "Fold: 14  Epoch: 596  Training loss = 2.2077  Validation loss = 6.5766  \n",
      "\n",
      "Fold: 14  Epoch: 597  Training loss = 2.2075  Validation loss = 6.5761  \n",
      "\n",
      "Fold: 14  Epoch: 598  Training loss = 2.2073  Validation loss = 6.5755  \n",
      "\n",
      "Fold: 14  Epoch: 599  Training loss = 2.2074  Validation loss = 6.5748  \n",
      "\n",
      "Fold: 14  Epoch: 600  Training loss = 2.2070  Validation loss = 6.5743  \n",
      "\n",
      "Fold: 14  Epoch: 601  Training loss = 2.2069  Validation loss = 6.5738  \n",
      "\n",
      "Fold: 14  Epoch: 602  Training loss = 2.2066  Validation loss = 6.5730  \n",
      "\n",
      "Fold: 14  Epoch: 603  Training loss = 2.2064  Validation loss = 6.5724  \n",
      "\n",
      "Fold: 14  Epoch: 604  Training loss = 2.2062  Validation loss = 6.5725  \n",
      "\n",
      "Fold: 14  Epoch: 605  Training loss = 2.2060  Validation loss = 6.5713  \n",
      "\n",
      "Fold: 14  Epoch: 606  Training loss = 2.2056  Validation loss = 6.5706  \n",
      "\n",
      "Fold: 14  Epoch: 607  Training loss = 2.2056  Validation loss = 6.5697  \n",
      "\n",
      "Fold: 14  Epoch: 608  Training loss = 2.2055  Validation loss = 6.5684  \n",
      "\n",
      "Fold: 14  Epoch: 609  Training loss = 2.2053  Validation loss = 6.5678  \n",
      "\n",
      "Fold: 14  Epoch: 610  Training loss = 2.2050  Validation loss = 6.5669  \n",
      "\n",
      "Fold: 14  Epoch: 611  Training loss = 2.2046  Validation loss = 6.5655  \n",
      "\n",
      "Fold: 14  Epoch: 612  Training loss = 2.2041  Validation loss = 6.5634  \n",
      "\n",
      "Fold: 14  Epoch: 613  Training loss = 2.2038  Validation loss = 6.5624  \n",
      "\n",
      "Fold: 14  Epoch: 614  Training loss = 2.2034  Validation loss = 6.5614  \n",
      "\n",
      "Fold: 14  Epoch: 615  Training loss = 2.2033  Validation loss = 6.5608  \n",
      "\n",
      "Fold: 14  Epoch: 616  Training loss = 2.2030  Validation loss = 6.5606  \n",
      "\n",
      "Fold: 14  Epoch: 617  Training loss = 2.2027  Validation loss = 6.5593  \n",
      "\n",
      "Fold: 14  Epoch: 618  Training loss = 2.2025  Validation loss = 6.5585  \n",
      "\n",
      "Fold: 14  Epoch: 619  Training loss = 2.2024  Validation loss = 6.5575  \n",
      "\n",
      "Fold: 14  Epoch: 620  Training loss = 2.2021  Validation loss = 6.5561  \n",
      "\n",
      "Fold: 14  Epoch: 621  Training loss = 2.2017  Validation loss = 6.5554  \n",
      "\n",
      "Fold: 14  Epoch: 622  Training loss = 2.2016  Validation loss = 6.5544  \n",
      "\n",
      "Fold: 14  Epoch: 623  Training loss = 2.2013  Validation loss = 6.5536  \n",
      "\n",
      "Fold: 14  Epoch: 624  Training loss = 2.2009  Validation loss = 6.5517  \n",
      "\n",
      "Fold: 14  Epoch: 625  Training loss = 2.2010  Validation loss = 6.5511  \n",
      "\n",
      "Fold: 14  Epoch: 626  Training loss = 2.2006  Validation loss = 6.5509  \n",
      "\n",
      "Fold: 14  Epoch: 627  Training loss = 2.2005  Validation loss = 6.5501  \n",
      "\n",
      "Fold: 14  Epoch: 628  Training loss = 2.2004  Validation loss = 6.5491  \n",
      "\n",
      "Fold: 14  Epoch: 629  Training loss = 2.2002  Validation loss = 6.5485  \n",
      "\n",
      "Fold: 14  Epoch: 630  Training loss = 2.1997  Validation loss = 6.5478  \n",
      "\n",
      "Fold: 14  Epoch: 631  Training loss = 2.1995  Validation loss = 6.5476  \n",
      "\n",
      "Fold: 14  Epoch: 632  Training loss = 2.1991  Validation loss = 6.5467  \n",
      "\n",
      "Fold: 14  Epoch: 633  Training loss = 2.1989  Validation loss = 6.5455  \n",
      "\n",
      "Fold: 14  Epoch: 634  Training loss = 2.1985  Validation loss = 6.5447  \n",
      "\n",
      "Fold: 14  Epoch: 635  Training loss = 2.1982  Validation loss = 6.5439  \n",
      "\n",
      "Fold: 14  Epoch: 636  Training loss = 2.1980  Validation loss = 6.5434  \n",
      "\n",
      "Fold: 14  Epoch: 637  Training loss = 2.1977  Validation loss = 6.5421  \n",
      "\n",
      "Fold: 14  Epoch: 638  Training loss = 2.1978  Validation loss = 6.5415  \n",
      "\n",
      "Fold: 14  Epoch: 639  Training loss = 2.1973  Validation loss = 6.5402  \n",
      "\n",
      "Fold: 14  Epoch: 640  Training loss = 2.1969  Validation loss = 6.5387  \n",
      "\n",
      "Fold: 14  Epoch: 641  Training loss = 2.1968  Validation loss = 6.5380  \n",
      "\n",
      "Fold: 14  Epoch: 642  Training loss = 2.1964  Validation loss = 6.5368  \n",
      "\n",
      "Fold: 14  Epoch: 643  Training loss = 2.1963  Validation loss = 6.5364  \n",
      "\n",
      "Fold: 14  Epoch: 644  Training loss = 2.1961  Validation loss = 6.5346  \n",
      "\n",
      "Fold: 14  Epoch: 645  Training loss = 2.1959  Validation loss = 6.5338  \n",
      "\n",
      "Fold: 14  Epoch: 646  Training loss = 2.1956  Validation loss = 6.5338  \n",
      "\n",
      "Fold: 14  Epoch: 647  Training loss = 2.1953  Validation loss = 6.5334  \n",
      "\n",
      "Fold: 14  Epoch: 648  Training loss = 2.1951  Validation loss = 6.5328  \n",
      "\n",
      "Fold: 14  Epoch: 649  Training loss = 2.1951  Validation loss = 6.5334  \n",
      "\n",
      "Fold: 14  Epoch: 650  Training loss = 2.1950  Validation loss = 6.5327  \n",
      "\n",
      "Fold: 14  Epoch: 651  Training loss = 2.1946  Validation loss = 6.5319  \n",
      "\n",
      "Fold: 14  Epoch: 652  Training loss = 2.1941  Validation loss = 6.5308  \n",
      "\n",
      "Fold: 14  Epoch: 653  Training loss = 2.1938  Validation loss = 6.5299  \n",
      "\n",
      "Fold: 14  Epoch: 654  Training loss = 2.1936  Validation loss = 6.5294  \n",
      "\n",
      "Fold: 14  Epoch: 655  Training loss = 2.1933  Validation loss = 6.5278  \n",
      "\n",
      "Fold: 14  Epoch: 656  Training loss = 2.1930  Validation loss = 6.5256  \n",
      "\n",
      "Fold: 14  Epoch: 657  Training loss = 2.1926  Validation loss = 6.5238  \n",
      "\n",
      "Fold: 14  Epoch: 658  Training loss = 2.1927  Validation loss = 6.5233  \n",
      "\n",
      "Fold: 14  Epoch: 659  Training loss = 2.1928  Validation loss = 6.5224  \n",
      "\n",
      "Fold: 14  Epoch: 660  Training loss = 2.1926  Validation loss = 6.5216  \n",
      "\n",
      "Fold: 14  Epoch: 661  Training loss = 2.1927  Validation loss = 6.5205  \n",
      "\n",
      "Fold: 14  Epoch: 662  Training loss = 2.1923  Validation loss = 6.5191  \n",
      "\n",
      "Fold: 14  Epoch: 663  Training loss = 2.1917  Validation loss = 6.5186  \n",
      "\n",
      "Fold: 14  Epoch: 664  Training loss = 2.1915  Validation loss = 6.5180  \n",
      "\n",
      "Fold: 14  Epoch: 665  Training loss = 2.1913  Validation loss = 6.5172  \n",
      "\n",
      "Fold: 14  Epoch: 666  Training loss = 2.1909  Validation loss = 6.5166  \n",
      "\n",
      "Fold: 14  Epoch: 667  Training loss = 2.1906  Validation loss = 6.5162  \n",
      "\n",
      "Fold: 14  Epoch: 668  Training loss = 2.1903  Validation loss = 6.5154  \n",
      "\n",
      "Fold: 14  Epoch: 669  Training loss = 2.1899  Validation loss = 6.5144  \n",
      "\n",
      "Fold: 14  Epoch: 670  Training loss = 2.1898  Validation loss = 6.5141  \n",
      "\n",
      "Fold: 14  Epoch: 671  Training loss = 2.1898  Validation loss = 6.5138  \n",
      "\n",
      "Fold: 14  Epoch: 672  Training loss = 2.1895  Validation loss = 6.5140  \n",
      "\n",
      "Fold: 14  Epoch: 673  Training loss = 2.1894  Validation loss = 6.5134  \n",
      "\n",
      "Fold: 14  Epoch: 674  Training loss = 2.1891  Validation loss = 6.5123  \n",
      "\n",
      "Fold: 14  Epoch: 675  Training loss = 2.1889  Validation loss = 6.5114  \n",
      "\n",
      "Fold: 14  Epoch: 676  Training loss = 2.1889  Validation loss = 6.5101  \n",
      "\n",
      "Fold: 14  Epoch: 677  Training loss = 2.1892  Validation loss = 6.5099  \n",
      "\n",
      "Fold: 14  Epoch: 678  Training loss = 2.1886  Validation loss = 6.5088  \n",
      "\n",
      "Fold: 14  Epoch: 679  Training loss = 2.1882  Validation loss = 6.5076  \n",
      "\n",
      "Fold: 14  Epoch: 680  Training loss = 2.1879  Validation loss = 6.5071  \n",
      "\n",
      "Fold: 14  Epoch: 681  Training loss = 2.1879  Validation loss = 6.5066  \n",
      "\n",
      "Fold: 14  Epoch: 682  Training loss = 2.1875  Validation loss = 6.5064  \n",
      "\n",
      "Fold: 14  Epoch: 683  Training loss = 2.1872  Validation loss = 6.5059  \n",
      "\n",
      "Fold: 14  Epoch: 684  Training loss = 2.1870  Validation loss = 6.5054  \n",
      "\n",
      "Fold: 14  Epoch: 685  Training loss = 2.1867  Validation loss = 6.5041  \n",
      "\n",
      "Fold: 14  Epoch: 686  Training loss = 2.1867  Validation loss = 6.5027  \n",
      "\n",
      "Fold: 14  Epoch: 687  Training loss = 2.1865  Validation loss = 6.5023  \n",
      "\n",
      "Fold: 14  Epoch: 688  Training loss = 2.1862  Validation loss = 6.5011  \n",
      "\n",
      "Fold: 14  Epoch: 689  Training loss = 2.1860  Validation loss = 6.4998  \n",
      "\n",
      "Fold: 14  Epoch: 690  Training loss = 2.1855  Validation loss = 6.4990  \n",
      "\n",
      "Fold: 14  Epoch: 691  Training loss = 2.1855  Validation loss = 6.4991  \n",
      "\n",
      "Fold: 14  Epoch: 692  Training loss = 2.1848  Validation loss = 6.4975  \n",
      "\n",
      "Fold: 14  Epoch: 693  Training loss = 2.1845  Validation loss = 6.4976  \n",
      "\n",
      "Fold: 14  Epoch: 694  Training loss = 2.1844  Validation loss = 6.4976  \n",
      "\n",
      "Fold: 14  Epoch: 695  Training loss = 2.1840  Validation loss = 6.4966  \n",
      "\n",
      "Fold: 14  Epoch: 696  Training loss = 2.1838  Validation loss = 6.4954  \n",
      "\n",
      "Fold: 14  Epoch: 697  Training loss = 2.1834  Validation loss = 6.4942  \n",
      "\n",
      "Fold: 14  Epoch: 698  Training loss = 2.1831  Validation loss = 6.4930  \n",
      "\n",
      "Fold: 14  Epoch: 699  Training loss = 2.1829  Validation loss = 6.4923  \n",
      "\n",
      "Fold: 14  Epoch: 700  Training loss = 2.1826  Validation loss = 6.4912  \n",
      "\n",
      "Fold: 14  Epoch: 701  Training loss = 2.1824  Validation loss = 6.4907  \n",
      "\n",
      "Fold: 14  Epoch: 702  Training loss = 2.1821  Validation loss = 6.4893  \n",
      "\n",
      "Fold: 14  Epoch: 703  Training loss = 2.1820  Validation loss = 6.4878  \n",
      "\n",
      "Fold: 14  Epoch: 704  Training loss = 2.1818  Validation loss = 6.4882  \n",
      "\n",
      "Fold: 14  Epoch: 705  Training loss = 2.1813  Validation loss = 6.4867  \n",
      "\n",
      "Fold: 14  Epoch: 706  Training loss = 2.1812  Validation loss = 6.4851  \n",
      "\n",
      "Fold: 14  Epoch: 707  Training loss = 2.1809  Validation loss = 6.4843  \n",
      "\n",
      "Fold: 14  Epoch: 708  Training loss = 2.1809  Validation loss = 6.4842  \n",
      "\n",
      "Fold: 14  Epoch: 709  Training loss = 2.1805  Validation loss = 6.4837  \n",
      "\n",
      "Fold: 14  Epoch: 710  Training loss = 2.1804  Validation loss = 6.4830  \n",
      "\n",
      "Fold: 14  Epoch: 711  Training loss = 2.1802  Validation loss = 6.4832  \n",
      "\n",
      "Fold: 14  Epoch: 712  Training loss = 2.1799  Validation loss = 6.4821  \n",
      "\n",
      "Fold: 14  Epoch: 713  Training loss = 2.1799  Validation loss = 6.4812  \n",
      "\n",
      "Fold: 14  Epoch: 714  Training loss = 2.1802  Validation loss = 6.4808  \n",
      "\n",
      "Fold: 14  Epoch: 715  Training loss = 2.1804  Validation loss = 6.4804  \n",
      "\n",
      "Fold: 14  Epoch: 716  Training loss = 2.1799  Validation loss = 6.4797  \n",
      "\n",
      "Fold: 14  Epoch: 717  Training loss = 2.1799  Validation loss = 6.4788  \n",
      "\n",
      "Fold: 14  Epoch: 718  Training loss = 2.1803  Validation loss = 6.4785  \n",
      "\n",
      "Fold: 14  Epoch: 719  Training loss = 2.1788  Validation loss = 6.4771  \n",
      "\n",
      "Fold: 14  Epoch: 720  Training loss = 2.1784  Validation loss = 6.4758  \n",
      "\n",
      "Fold: 14  Epoch: 721  Training loss = 2.1774  Validation loss = 6.4751  \n",
      "\n",
      "Fold: 14  Epoch: 722  Training loss = 2.1774  Validation loss = 6.4748  \n",
      "\n",
      "Fold: 14  Epoch: 723  Training loss = 2.1771  Validation loss = 6.4742  \n",
      "\n",
      "Fold: 14  Epoch: 724  Training loss = 2.1768  Validation loss = 6.4737  \n",
      "\n",
      "Fold: 14  Epoch: 725  Training loss = 2.1765  Validation loss = 6.4730  \n",
      "\n",
      "Fold: 14  Epoch: 726  Training loss = 2.1763  Validation loss = 6.4717  \n",
      "\n",
      "Fold: 14  Epoch: 727  Training loss = 2.1760  Validation loss = 6.4707  \n",
      "\n",
      "Fold: 14  Epoch: 728  Training loss = 2.1756  Validation loss = 6.4689  \n",
      "\n",
      "Fold: 14  Epoch: 729  Training loss = 2.1754  Validation loss = 6.4684  \n",
      "\n",
      "Fold: 14  Epoch: 730  Training loss = 2.1754  Validation loss = 6.4669  \n",
      "\n",
      "Fold: 14  Epoch: 731  Training loss = 2.1751  Validation loss = 6.4663  \n",
      "\n",
      "Fold: 14  Epoch: 732  Training loss = 2.1747  Validation loss = 6.4658  \n",
      "\n",
      "Fold: 14  Epoch: 733  Training loss = 2.1746  Validation loss = 6.4654  \n",
      "\n",
      "Fold: 14  Epoch: 734  Training loss = 2.1745  Validation loss = 6.4651  \n",
      "\n",
      "Fold: 14  Epoch: 735  Training loss = 2.1742  Validation loss = 6.4647  \n",
      "\n",
      "Fold: 14  Epoch: 736  Training loss = 2.1740  Validation loss = 6.4640  \n",
      "\n",
      "Fold: 14  Epoch: 737  Training loss = 2.1737  Validation loss = 6.4631  \n",
      "\n",
      "Fold: 14  Epoch: 738  Training loss = 2.1736  Validation loss = 6.4623  \n",
      "\n",
      "Fold: 14  Epoch: 739  Training loss = 2.1734  Validation loss = 6.4617  \n",
      "\n",
      "Fold: 14  Epoch: 740  Training loss = 2.1731  Validation loss = 6.4603  \n",
      "\n",
      "Fold: 14  Epoch: 741  Training loss = 2.1728  Validation loss = 6.4605  \n",
      "\n",
      "Fold: 14  Epoch: 742  Training loss = 2.1726  Validation loss = 6.4595  \n",
      "\n",
      "Fold: 14  Epoch: 743  Training loss = 2.1728  Validation loss = 6.4595  \n",
      "\n",
      "Fold: 14  Epoch: 744  Training loss = 2.1722  Validation loss = 6.4588  \n",
      "\n",
      "Fold: 14  Epoch: 745  Training loss = 2.1717  Validation loss = 6.4566  \n",
      "\n",
      "Fold: 14  Epoch: 746  Training loss = 2.1715  Validation loss = 6.4560  \n",
      "\n",
      "Fold: 14  Epoch: 747  Training loss = 2.1713  Validation loss = 6.4557  \n",
      "\n",
      "Fold: 14  Epoch: 748  Training loss = 2.1712  Validation loss = 6.4553  \n",
      "\n",
      "Fold: 14  Epoch: 749  Training loss = 2.1708  Validation loss = 6.4540  \n",
      "\n",
      "Fold: 14  Epoch: 750  Training loss = 2.1708  Validation loss = 6.4538  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 750  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.6773  Validation loss = 7.2800  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.6764  Validation loss = 7.2780  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.6755  Validation loss = 7.2765  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.6749  Validation loss = 7.2750  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.6744  Validation loss = 7.2742  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.6740  Validation loss = 7.2732  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.6731  Validation loss = 7.2714  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.6725  Validation loss = 7.2701  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.6719  Validation loss = 7.2690  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.6712  Validation loss = 7.2677  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.6707  Validation loss = 7.2664  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.6699  Validation loss = 7.2644  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.6690  Validation loss = 7.2625  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.6685  Validation loss = 7.2608  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.6680  Validation loss = 7.2588  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.6668  Validation loss = 7.2566  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.6666  Validation loss = 7.2559  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.6661  Validation loss = 7.2547  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.6656  Validation loss = 7.2538  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.6651  Validation loss = 7.2526  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.6646  Validation loss = 7.2512  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.6641  Validation loss = 7.2493  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.6636  Validation loss = 7.2488  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.6628  Validation loss = 7.2474  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.6623  Validation loss = 7.2459  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 2.6616  Validation loss = 7.2442  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.6608  Validation loss = 7.2432  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 2.6604  Validation loss = 7.2424  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 2.6597  Validation loss = 7.2412  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 2.6590  Validation loss = 7.2394  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 2.6585  Validation loss = 7.2376  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.6579  Validation loss = 7.2367  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 2.6573  Validation loss = 7.2356  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 2.6567  Validation loss = 7.2344  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 2.6561  Validation loss = 7.2326  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 2.6556  Validation loss = 7.2316  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 2.6549  Validation loss = 7.2299  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 2.6544  Validation loss = 7.2286  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 2.6534  Validation loss = 7.2259  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 2.6529  Validation loss = 7.2240  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 2.6521  Validation loss = 7.2221  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 2.6513  Validation loss = 7.2207  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 2.6503  Validation loss = 7.2182  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 2.6496  Validation loss = 7.2162  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 2.6487  Validation loss = 7.2141  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 2.6481  Validation loss = 7.2129  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 2.6474  Validation loss = 7.2114  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 2.6469  Validation loss = 7.2100  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 2.6463  Validation loss = 7.2086  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 2.6461  Validation loss = 7.2082  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 2.6453  Validation loss = 7.2057  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 2.6449  Validation loss = 7.2047  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 2.6441  Validation loss = 7.2031  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 2.6436  Validation loss = 7.2028  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 2.6431  Validation loss = 7.2014  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 2.6425  Validation loss = 7.2003  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 2.6421  Validation loss = 7.1996  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 2.6415  Validation loss = 7.1982  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 2.6410  Validation loss = 7.1972  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 2.6403  Validation loss = 7.1955  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 2.6399  Validation loss = 7.1946  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 2.6397  Validation loss = 7.1940  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 2.6390  Validation loss = 7.1924  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 2.6384  Validation loss = 7.1913  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 2.6377  Validation loss = 7.1897  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 2.6369  Validation loss = 7.1880  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 2.6364  Validation loss = 7.1865  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 2.6358  Validation loss = 7.1857  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 2.6354  Validation loss = 7.1846  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 2.6352  Validation loss = 7.1840  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 2.6348  Validation loss = 7.1835  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 2.6344  Validation loss = 7.1821  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 2.6342  Validation loss = 7.1813  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 2.6338  Validation loss = 7.1805  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 2.6333  Validation loss = 7.1794  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 2.6327  Validation loss = 7.1781  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 2.6324  Validation loss = 7.1772  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 2.6316  Validation loss = 7.1761  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 2.6307  Validation loss = 7.1744  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 2.6303  Validation loss = 7.1733  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 2.6297  Validation loss = 7.1723  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 2.6289  Validation loss = 7.1706  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 2.6285  Validation loss = 7.1694  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 2.6279  Validation loss = 7.1683  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 2.6276  Validation loss = 7.1676  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 2.6270  Validation loss = 7.1662  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 2.6265  Validation loss = 7.1649  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 2.6263  Validation loss = 7.1645  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 2.6257  Validation loss = 7.1633  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 2.6251  Validation loss = 7.1618  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 2.6248  Validation loss = 7.1613  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 2.6240  Validation loss = 7.1592  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 2.6239  Validation loss = 7.1584  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 2.6235  Validation loss = 7.1572  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 2.6229  Validation loss = 7.1557  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 2.6226  Validation loss = 7.1547  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 2.6221  Validation loss = 7.1538  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 2.6217  Validation loss = 7.1524  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 2.6214  Validation loss = 7.1515  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 2.6208  Validation loss = 7.1507  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 2.6205  Validation loss = 7.1498  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 2.6201  Validation loss = 7.1493  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 2.6194  Validation loss = 7.1482  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 2.6186  Validation loss = 7.1466  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 2.6183  Validation loss = 7.1459  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 2.6180  Validation loss = 7.1452  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 2.6178  Validation loss = 7.1448  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 2.6172  Validation loss = 7.1436  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 2.6167  Validation loss = 7.1414  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 2.6162  Validation loss = 7.1401  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 2.6155  Validation loss = 7.1381  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 2.6151  Validation loss = 7.1370  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 2.6148  Validation loss = 7.1352  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 2.6144  Validation loss = 7.1342  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 2.6138  Validation loss = 7.1331  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 2.6137  Validation loss = 7.1319  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 2.6129  Validation loss = 7.1306  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 2.6121  Validation loss = 7.1288  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 2.6116  Validation loss = 7.1272  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 2.6112  Validation loss = 7.1252  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 2.6107  Validation loss = 7.1252  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 2.6100  Validation loss = 7.1240  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 2.6097  Validation loss = 7.1234  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 2.6093  Validation loss = 7.1220  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 2.6088  Validation loss = 7.1211  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 2.6079  Validation loss = 7.1199  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 2.6074  Validation loss = 7.1195  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 2.6068  Validation loss = 7.1173  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 2.6062  Validation loss = 7.1155  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 2.6058  Validation loss = 7.1139  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 2.6050  Validation loss = 7.1131  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 2.6045  Validation loss = 7.1125  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 2.6042  Validation loss = 7.1126  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 2.6037  Validation loss = 7.1111  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 2.6029  Validation loss = 7.1088  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 2.6027  Validation loss = 7.1088  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 2.6022  Validation loss = 7.1076  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 2.6020  Validation loss = 7.1073  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 2.6015  Validation loss = 7.1061  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 2.6008  Validation loss = 7.1045  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 2.6006  Validation loss = 7.1043  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 2.6000  Validation loss = 7.1030  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 2.5995  Validation loss = 7.1020  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 2.5989  Validation loss = 7.1002  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 2.5981  Validation loss = 7.0983  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 2.5981  Validation loss = 7.0978  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 2.5981  Validation loss = 7.0973  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 2.5973  Validation loss = 7.0963  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 2.5964  Validation loss = 7.0940  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 2.5958  Validation loss = 7.0925  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 2.5953  Validation loss = 7.0907  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 2.5948  Validation loss = 7.0895  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 2.5944  Validation loss = 7.0890  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 2.5939  Validation loss = 7.0881  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 2.5934  Validation loss = 7.0871  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 2.5930  Validation loss = 7.0861  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 2.5926  Validation loss = 7.0846  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 2.5922  Validation loss = 7.0837  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 2.5919  Validation loss = 7.0836  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 2.5917  Validation loss = 7.0833  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 2.5913  Validation loss = 7.0824  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 2.5908  Validation loss = 7.0804  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 2.5899  Validation loss = 7.0773  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 2.5896  Validation loss = 7.0765  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 2.5891  Validation loss = 7.0759  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 2.5884  Validation loss = 7.0750  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 2.5878  Validation loss = 7.0734  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 2.5874  Validation loss = 7.0725  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 2.5869  Validation loss = 7.0714  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 2.5865  Validation loss = 7.0705  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 2.5855  Validation loss = 7.0677  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 2.5851  Validation loss = 7.0666  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 2.5847  Validation loss = 7.0662  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 2.5841  Validation loss = 7.0641  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 2.5836  Validation loss = 7.0634  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 2.5831  Validation loss = 7.0624  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 2.5827  Validation loss = 7.0618  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 2.5821  Validation loss = 7.0602  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 2.5815  Validation loss = 7.0586  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 2.5811  Validation loss = 7.0582  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 2.5807  Validation loss = 7.0577  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 2.5803  Validation loss = 7.0561  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 2.5799  Validation loss = 7.0551  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 2.5793  Validation loss = 7.0535  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 2.5788  Validation loss = 7.0525  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 2.5784  Validation loss = 7.0526  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 2.5779  Validation loss = 7.0503  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 2.5772  Validation loss = 7.0486  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 2.5767  Validation loss = 7.0472  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 2.5762  Validation loss = 7.0465  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 2.5758  Validation loss = 7.0455  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 2.5756  Validation loss = 7.0447  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 2.5751  Validation loss = 7.0444  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 2.5746  Validation loss = 7.0437  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 2.5739  Validation loss = 7.0417  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 2.5735  Validation loss = 7.0411  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 2.5730  Validation loss = 7.0394  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 2.5725  Validation loss = 7.0383  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 2.5720  Validation loss = 7.0365  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 2.5714  Validation loss = 7.0348  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 2.5708  Validation loss = 7.0334  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 2.5704  Validation loss = 7.0324  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 2.5696  Validation loss = 7.0308  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 2.5692  Validation loss = 7.0297  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 2.5686  Validation loss = 7.0281  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 2.5686  Validation loss = 7.0272  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 2.5679  Validation loss = 7.0254  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 2.5673  Validation loss = 7.0248  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 2.5671  Validation loss = 7.0242  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 2.5666  Validation loss = 7.0232  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 2.5662  Validation loss = 7.0224  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 2.5656  Validation loss = 7.0211  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 2.5652  Validation loss = 7.0199  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 2.5651  Validation loss = 7.0205  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 2.5647  Validation loss = 7.0192  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 2.5644  Validation loss = 7.0189  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 2.5638  Validation loss = 7.0173  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 2.5637  Validation loss = 7.0178  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 2.5629  Validation loss = 7.0152  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 2.5626  Validation loss = 7.0142  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 2.5622  Validation loss = 7.0130  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 2.5618  Validation loss = 7.0117  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 2.5615  Validation loss = 7.0096  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 2.5609  Validation loss = 7.0080  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 2.5606  Validation loss = 7.0070  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 2.5599  Validation loss = 7.0057  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 2.5594  Validation loss = 7.0047  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 2.5590  Validation loss = 7.0026  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 2.5584  Validation loss = 7.0028  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 2.5580  Validation loss = 7.0022  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 2.5577  Validation loss = 7.0012  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 2.5574  Validation loss = 6.9998  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 2.5571  Validation loss = 6.9999  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 2.5565  Validation loss = 6.9982  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 2.5561  Validation loss = 6.9967  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 2.5556  Validation loss = 6.9963  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 2.5555  Validation loss = 6.9958  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 2.5550  Validation loss = 6.9947  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 2.5544  Validation loss = 6.9938  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 2.5539  Validation loss = 6.9929  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 2.5539  Validation loss = 6.9917  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 2.5533  Validation loss = 6.9907  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 2.5531  Validation loss = 6.9891  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 2.5525  Validation loss = 6.9891  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 2.5516  Validation loss = 6.9891  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 2.5510  Validation loss = 6.9866  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 2.5506  Validation loss = 6.9858  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 2.5499  Validation loss = 6.9845  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 2.5491  Validation loss = 6.9831  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 2.5490  Validation loss = 6.9835  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 2.5488  Validation loss = 6.9833  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 2.5484  Validation loss = 6.9815  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 2.5482  Validation loss = 6.9803  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 2.5477  Validation loss = 6.9784  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 2.5474  Validation loss = 6.9776  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 2.5469  Validation loss = 6.9774  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 2.5461  Validation loss = 6.9769  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 2.5457  Validation loss = 6.9761  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 2.5453  Validation loss = 6.9743  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 2.5448  Validation loss = 6.9730  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 2.5443  Validation loss = 6.9724  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 2.5436  Validation loss = 6.9699  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 2.5434  Validation loss = 6.9691  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 2.5430  Validation loss = 6.9674  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 2.5425  Validation loss = 6.9676  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 2.5418  Validation loss = 6.9658  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 2.5413  Validation loss = 6.9657  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 2.5409  Validation loss = 6.9654  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 2.5406  Validation loss = 6.9658  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 2.5402  Validation loss = 6.9651  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 2.5398  Validation loss = 6.9641  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 2.5393  Validation loss = 6.9624  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 2.5387  Validation loss = 6.9604  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 2.5382  Validation loss = 6.9591  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 2.5381  Validation loss = 6.9601  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 2.5373  Validation loss = 6.9570  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 2.5370  Validation loss = 6.9563  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 2.5365  Validation loss = 6.9548  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 2.5361  Validation loss = 6.9557  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 2.5354  Validation loss = 6.9545  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 2.5351  Validation loss = 6.9542  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 2.5345  Validation loss = 6.9524  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 2.5341  Validation loss = 6.9533  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 2.5335  Validation loss = 6.9511  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 2.5330  Validation loss = 6.9492  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 2.5324  Validation loss = 6.9479  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 2.5320  Validation loss = 6.9470  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 2.5316  Validation loss = 6.9452  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 2.5311  Validation loss = 6.9436  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 2.5306  Validation loss = 6.9427  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 2.5301  Validation loss = 6.9422  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 2.5294  Validation loss = 6.9414  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 2.5291  Validation loss = 6.9417  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 2.5283  Validation loss = 6.9390  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 2.5279  Validation loss = 6.9380  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 2.5274  Validation loss = 6.9365  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 2.5271  Validation loss = 6.9359  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 2.5266  Validation loss = 6.9335  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 2.5263  Validation loss = 6.9341  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 2.5258  Validation loss = 6.9330  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 2.5256  Validation loss = 6.9333  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 2.5253  Validation loss = 6.9321  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 2.5249  Validation loss = 6.9314  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 2.5248  Validation loss = 6.9305  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 2.5245  Validation loss = 6.9302  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 2.5246  Validation loss = 6.9279  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 2.5240  Validation loss = 6.9277  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 2.5235  Validation loss = 6.9280  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 2.5229  Validation loss = 6.9279  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 2.5229  Validation loss = 6.9262  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 2.5226  Validation loss = 6.9264  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 2.5219  Validation loss = 6.9287  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 2.5218  Validation loss = 6.9261  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 2.5209  Validation loss = 6.9269  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 2.5206  Validation loss = 6.9259  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 2.5200  Validation loss = 6.9263  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 2.5197  Validation loss = 6.9261  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 2.5195  Validation loss = 6.9254  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 2.5194  Validation loss = 6.9268  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 2.5190  Validation loss = 6.9257  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 2.5184  Validation loss = 6.9235  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 2.5179  Validation loss = 6.9242  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 2.5176  Validation loss = 6.9222  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 2.5172  Validation loss = 6.9213  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 2.5168  Validation loss = 6.9227  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 2.5166  Validation loss = 6.9197  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 2.5161  Validation loss = 6.9211  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 2.5157  Validation loss = 6.9223  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 2.5153  Validation loss = 6.9223  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 2.5148  Validation loss = 6.9224  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 2.5145  Validation loss = 6.9225  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 2.5139  Validation loss = 6.9203  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 2.5136  Validation loss = 6.9188  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 2.5130  Validation loss = 6.9155  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 2.5125  Validation loss = 6.9152  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 2.5120  Validation loss = 6.9170  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 2.5119  Validation loss = 6.9166  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 2.5115  Validation loss = 6.9157  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 2.5113  Validation loss = 6.9141  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 2.5110  Validation loss = 6.9149  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 2.5106  Validation loss = 6.9145  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 2.5103  Validation loss = 6.9144  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 2.5099  Validation loss = 6.9144  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 2.5095  Validation loss = 6.9145  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 2.5092  Validation loss = 6.9124  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 2.5088  Validation loss = 6.9104  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 2.5081  Validation loss = 6.9097  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 2.5077  Validation loss = 6.9094  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 2.5075  Validation loss = 6.9097  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 2.5072  Validation loss = 6.9106  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 2.5067  Validation loss = 6.9092  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 2.5063  Validation loss = 6.9084  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 2.5059  Validation loss = 6.9085  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 2.5053  Validation loss = 6.9070  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 2.5048  Validation loss = 6.9065  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 2.5046  Validation loss = 6.9053  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 2.5042  Validation loss = 6.9033  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 2.5038  Validation loss = 6.9045  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 2.5035  Validation loss = 6.9049  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 2.5031  Validation loss = 6.9050  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 2.5026  Validation loss = 6.9043  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 2.5023  Validation loss = 6.9034  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 2.5020  Validation loss = 6.9039  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 2.5018  Validation loss = 6.9043  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 2.5011  Validation loss = 6.9018  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 2.5006  Validation loss = 6.8991  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 2.5000  Validation loss = 6.8984  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 2.4995  Validation loss = 6.8971  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 2.4990  Validation loss = 6.8953  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 2.4987  Validation loss = 6.8952  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 2.4983  Validation loss = 6.8935  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 2.4981  Validation loss = 6.8937  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 2.4974  Validation loss = 6.8928  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 2.4973  Validation loss = 6.8927  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 2.4968  Validation loss = 6.8918  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 2.4965  Validation loss = 6.8899  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 2.4959  Validation loss = 6.8890  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 2.4953  Validation loss = 6.8874  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 2.4949  Validation loss = 6.8879  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 2.4943  Validation loss = 6.8859  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 2.4939  Validation loss = 6.8843  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 2.4937  Validation loss = 6.8834  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 2.4932  Validation loss = 6.8842  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 2.4927  Validation loss = 6.8842  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 2.4922  Validation loss = 6.8816  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 2.4917  Validation loss = 6.8800  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 2.4911  Validation loss = 6.8782  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 2.4906  Validation loss = 6.8782  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 2.4900  Validation loss = 6.8767  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 2.4895  Validation loss = 6.8756  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 2.4892  Validation loss = 6.8751  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 2.4885  Validation loss = 6.8719  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 2.4882  Validation loss = 6.8709  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 2.4878  Validation loss = 6.8710  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 2.4873  Validation loss = 6.8709  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 2.4871  Validation loss = 6.8700  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 2.4868  Validation loss = 6.8699  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 2.4863  Validation loss = 6.8690  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 2.4859  Validation loss = 6.8678  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 2.4857  Validation loss = 6.8685  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 2.4852  Validation loss = 6.8671  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 2.4846  Validation loss = 6.8659  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 2.4840  Validation loss = 6.8644  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 2.4837  Validation loss = 6.8645  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 2.4832  Validation loss = 6.8624  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 2.4827  Validation loss = 6.8619  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 2.4823  Validation loss = 6.8616  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 2.4819  Validation loss = 6.8613  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 2.4814  Validation loss = 6.8610  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 2.4811  Validation loss = 6.8599  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 2.4805  Validation loss = 6.8581  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 2.4806  Validation loss = 6.8586  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 2.4797  Validation loss = 6.8563  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 2.4796  Validation loss = 6.8560  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 2.4795  Validation loss = 6.8553  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 2.4796  Validation loss = 6.8552  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 2.4794  Validation loss = 6.8548  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 2.4781  Validation loss = 6.8534  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 2.4774  Validation loss = 6.8519  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 2.4767  Validation loss = 6.8502  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 2.4760  Validation loss = 6.8479  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 2.4758  Validation loss = 6.8475  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 2.4753  Validation loss = 6.8471  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 2.4750  Validation loss = 6.8462  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 2.4746  Validation loss = 6.8455  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 2.4737  Validation loss = 6.8430  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 2.4732  Validation loss = 6.8421  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 2.4728  Validation loss = 6.8411  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 2.4726  Validation loss = 6.8400  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 2.4722  Validation loss = 6.8385  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 2.4718  Validation loss = 6.8380  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 2.4714  Validation loss = 6.8372  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 2.4707  Validation loss = 6.8365  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 2.4703  Validation loss = 6.8353  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 2.4700  Validation loss = 6.8360  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 2.4697  Validation loss = 6.8351  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 2.4691  Validation loss = 6.8337  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 2.4691  Validation loss = 6.8348  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 2.4689  Validation loss = 6.8343  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 2.4684  Validation loss = 6.8328  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 2.4681  Validation loss = 6.8326  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 2.4677  Validation loss = 6.8318  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 2.4671  Validation loss = 6.8299  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 2.4668  Validation loss = 6.8288  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 2.4663  Validation loss = 6.8283  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 2.4658  Validation loss = 6.8262  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 2.4653  Validation loss = 6.8248  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 2.4647  Validation loss = 6.8238  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 2.4642  Validation loss = 6.8224  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 2.4638  Validation loss = 6.8222  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 2.4633  Validation loss = 6.8215  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 2.4629  Validation loss = 6.8191  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 2.4624  Validation loss = 6.8178  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 2.4622  Validation loss = 6.8175  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 2.4620  Validation loss = 6.8163  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 2.4612  Validation loss = 6.8139  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 2.4603  Validation loss = 6.8121  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 2.4601  Validation loss = 6.8125  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 2.4598  Validation loss = 6.8125  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 2.4596  Validation loss = 6.8129  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 2.4589  Validation loss = 6.8111  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 2.4584  Validation loss = 6.8095  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 2.4578  Validation loss = 6.8078  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 2.4574  Validation loss = 6.8066  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 2.4572  Validation loss = 6.8054  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 2.4568  Validation loss = 6.8042  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 2.4563  Validation loss = 6.8046  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 2.4559  Validation loss = 6.8051  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 2.4555  Validation loss = 6.8045  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 2.4552  Validation loss = 6.8044  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 2.4546  Validation loss = 6.8032  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 2.4542  Validation loss = 6.8016  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 2.4537  Validation loss = 6.8010  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 2.4531  Validation loss = 6.7992  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 2.4526  Validation loss = 6.7987  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 2.4521  Validation loss = 6.7973  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 2.4516  Validation loss = 6.7962  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 2.4509  Validation loss = 6.7944  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 2.4506  Validation loss = 6.7938  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 2.4498  Validation loss = 6.7914  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 2.4493  Validation loss = 6.7901  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 2.4490  Validation loss = 6.7898  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 2.4485  Validation loss = 6.7889  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 2.4479  Validation loss = 6.7870  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 2.4476  Validation loss = 6.7869  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 2.4474  Validation loss = 6.7872  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 2.4473  Validation loss = 6.7865  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 2.4464  Validation loss = 6.7848  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 2.4460  Validation loss = 6.7838  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 2.4456  Validation loss = 6.7834  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 2.4452  Validation loss = 6.7829  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 2.4450  Validation loss = 6.7829  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 2.4446  Validation loss = 6.7822  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 2.4443  Validation loss = 6.7825  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 2.4440  Validation loss = 6.7819  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 2.4435  Validation loss = 6.7815  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 2.4427  Validation loss = 6.7793  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 2.4423  Validation loss = 6.7780  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 2.4419  Validation loss = 6.7768  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 2.4416  Validation loss = 6.7759  \n",
      "\n",
      "Fold: 15  Epoch: 501  Training loss = 2.4414  Validation loss = 6.7747  \n",
      "\n",
      "Fold: 15  Epoch: 502  Training loss = 2.4410  Validation loss = 6.7726  \n",
      "\n",
      "Fold: 15  Epoch: 503  Training loss = 2.4406  Validation loss = 6.7719  \n",
      "\n",
      "Fold: 15  Epoch: 504  Training loss = 2.4402  Validation loss = 6.7710  \n",
      "\n",
      "Fold: 15  Epoch: 505  Training loss = 2.4396  Validation loss = 6.7695  \n",
      "\n",
      "Fold: 15  Epoch: 506  Training loss = 2.4388  Validation loss = 6.7682  \n",
      "\n",
      "Fold: 15  Epoch: 507  Training loss = 2.4385  Validation loss = 6.7669  \n",
      "\n",
      "Fold: 15  Epoch: 508  Training loss = 2.4380  Validation loss = 6.7662  \n",
      "\n",
      "Fold: 15  Epoch: 509  Training loss = 2.4374  Validation loss = 6.7653  \n",
      "\n",
      "Fold: 15  Epoch: 510  Training loss = 2.4367  Validation loss = 6.7636  \n",
      "\n",
      "Fold: 15  Epoch: 511  Training loss = 2.4358  Validation loss = 6.7624  \n",
      "\n",
      "Fold: 15  Epoch: 512  Training loss = 2.4353  Validation loss = 6.7616  \n",
      "\n",
      "Fold: 15  Epoch: 513  Training loss = 2.4349  Validation loss = 6.7606  \n",
      "\n",
      "Fold: 15  Epoch: 514  Training loss = 2.4344  Validation loss = 6.7595  \n",
      "\n",
      "Fold: 15  Epoch: 515  Training loss = 2.4340  Validation loss = 6.7581  \n",
      "\n",
      "Fold: 15  Epoch: 516  Training loss = 2.4335  Validation loss = 6.7578  \n",
      "\n",
      "Fold: 15  Epoch: 517  Training loss = 2.4331  Validation loss = 6.7569  \n",
      "\n",
      "Fold: 15  Epoch: 518  Training loss = 2.4330  Validation loss = 6.7565  \n",
      "\n",
      "Fold: 15  Epoch: 519  Training loss = 2.4323  Validation loss = 6.7559  \n",
      "\n",
      "Fold: 15  Epoch: 520  Training loss = 2.4320  Validation loss = 6.7555  \n",
      "\n",
      "Fold: 15  Epoch: 521  Training loss = 2.4314  Validation loss = 6.7542  \n",
      "\n",
      "Fold: 15  Epoch: 522  Training loss = 2.4307  Validation loss = 6.7525  \n",
      "\n",
      "Fold: 15  Epoch: 523  Training loss = 2.4303  Validation loss = 6.7519  \n",
      "\n",
      "Fold: 15  Epoch: 524  Training loss = 2.4303  Validation loss = 6.7515  \n",
      "\n",
      "Fold: 15  Epoch: 525  Training loss = 2.4301  Validation loss = 6.7506  \n",
      "\n",
      "Fold: 15  Epoch: 526  Training loss = 2.4294  Validation loss = 6.7490  \n",
      "\n",
      "Fold: 15  Epoch: 527  Training loss = 2.4292  Validation loss = 6.7488  \n",
      "\n",
      "Fold: 15  Epoch: 528  Training loss = 2.4286  Validation loss = 6.7475  \n",
      "\n",
      "Fold: 15  Epoch: 529  Training loss = 2.4281  Validation loss = 6.7457  \n",
      "\n",
      "Fold: 15  Epoch: 530  Training loss = 2.4280  Validation loss = 6.7451  \n",
      "\n",
      "Fold: 15  Epoch: 531  Training loss = 2.4276  Validation loss = 6.7439  \n",
      "\n",
      "Fold: 15  Epoch: 532  Training loss = 2.4279  Validation loss = 6.7425  \n",
      "\n",
      "Fold: 15  Epoch: 533  Training loss = 2.4262  Validation loss = 6.7402  \n",
      "\n",
      "Fold: 15  Epoch: 534  Training loss = 2.4260  Validation loss = 6.7403  \n",
      "\n",
      "Fold: 15  Epoch: 535  Training loss = 2.4250  Validation loss = 6.7382  \n",
      "\n",
      "Fold: 15  Epoch: 536  Training loss = 2.4245  Validation loss = 6.7377  \n",
      "\n",
      "Fold: 15  Epoch: 537  Training loss = 2.4243  Validation loss = 6.7369  \n",
      "\n",
      "Fold: 15  Epoch: 538  Training loss = 2.4238  Validation loss = 6.7357  \n",
      "\n",
      "Fold: 15  Epoch: 539  Training loss = 2.4233  Validation loss = 6.7335  \n",
      "\n",
      "Fold: 15  Epoch: 540  Training loss = 2.4228  Validation loss = 6.7324  \n",
      "\n",
      "Fold: 15  Epoch: 541  Training loss = 2.4232  Validation loss = 6.7321  \n",
      "\n",
      "Fold: 15  Epoch: 542  Training loss = 2.4225  Validation loss = 6.7315  \n",
      "\n",
      "Fold: 15  Epoch: 543  Training loss = 2.4225  Validation loss = 6.7302  \n",
      "\n",
      "Fold: 15  Epoch: 544  Training loss = 2.4213  Validation loss = 6.7287  \n",
      "\n",
      "Fold: 15  Epoch: 545  Training loss = 2.4206  Validation loss = 6.7274  \n",
      "\n",
      "Fold: 15  Epoch: 546  Training loss = 2.4200  Validation loss = 6.7267  \n",
      "\n",
      "Fold: 15  Epoch: 547  Training loss = 2.4196  Validation loss = 6.7257  \n",
      "\n",
      "Fold: 15  Epoch: 548  Training loss = 2.4191  Validation loss = 6.7245  \n",
      "\n",
      "Fold: 15  Epoch: 549  Training loss = 2.4187  Validation loss = 6.7231  \n",
      "\n",
      "Fold: 15  Epoch: 550  Training loss = 2.4185  Validation loss = 6.7225  \n",
      "\n",
      "Fold: 15  Epoch: 551  Training loss = 2.4174  Validation loss = 6.7199  \n",
      "\n",
      "Fold: 15  Epoch: 552  Training loss = 2.4168  Validation loss = 6.7177  \n",
      "\n",
      "Fold: 15  Epoch: 553  Training loss = 2.4164  Validation loss = 6.7164  \n",
      "\n",
      "Fold: 15  Epoch: 554  Training loss = 2.4159  Validation loss = 6.7153  \n",
      "\n",
      "Fold: 15  Epoch: 555  Training loss = 2.4153  Validation loss = 6.7138  \n",
      "\n",
      "Fold: 15  Epoch: 556  Training loss = 2.4151  Validation loss = 6.7131  \n",
      "\n",
      "Fold: 15  Epoch: 557  Training loss = 2.4148  Validation loss = 6.7122  \n",
      "\n",
      "Fold: 15  Epoch: 558  Training loss = 2.4142  Validation loss = 6.7119  \n",
      "\n",
      "Fold: 15  Epoch: 559  Training loss = 2.4139  Validation loss = 6.7107  \n",
      "\n",
      "Fold: 15  Epoch: 560  Training loss = 2.4137  Validation loss = 6.7096  \n",
      "\n",
      "Fold: 15  Epoch: 561  Training loss = 2.4138  Validation loss = 6.7088  \n",
      "\n",
      "Fold: 15  Epoch: 562  Training loss = 2.4134  Validation loss = 6.7078  \n",
      "\n",
      "Fold: 15  Epoch: 563  Training loss = 2.4122  Validation loss = 6.7073  \n",
      "\n",
      "Fold: 15  Epoch: 564  Training loss = 2.4120  Validation loss = 6.7071  \n",
      "\n",
      "Fold: 15  Epoch: 565  Training loss = 2.4115  Validation loss = 6.7059  \n",
      "\n",
      "Fold: 15  Epoch: 566  Training loss = 2.4112  Validation loss = 6.7053  \n",
      "\n",
      "Fold: 15  Epoch: 567  Training loss = 2.4112  Validation loss = 6.7046  \n",
      "\n",
      "Fold: 15  Epoch: 568  Training loss = 2.4103  Validation loss = 6.7042  \n",
      "\n",
      "Fold: 15  Epoch: 569  Training loss = 2.4103  Validation loss = 6.7033  \n",
      "\n",
      "Fold: 15  Epoch: 570  Training loss = 2.4095  Validation loss = 6.7015  \n",
      "\n",
      "Fold: 15  Epoch: 571  Training loss = 2.4092  Validation loss = 6.7007  \n",
      "\n",
      "Fold: 15  Epoch: 572  Training loss = 2.4086  Validation loss = 6.6996  \n",
      "\n",
      "Fold: 15  Epoch: 573  Training loss = 2.4083  Validation loss = 6.6985  \n",
      "\n",
      "Fold: 15  Epoch: 574  Training loss = 2.4074  Validation loss = 6.6978  \n",
      "\n",
      "Fold: 15  Epoch: 575  Training loss = 2.4068  Validation loss = 6.6971  \n",
      "\n",
      "Fold: 15  Epoch: 576  Training loss = 2.4063  Validation loss = 6.6966  \n",
      "\n",
      "Fold: 15  Epoch: 577  Training loss = 2.4059  Validation loss = 6.6959  \n",
      "\n",
      "Fold: 15  Epoch: 578  Training loss = 2.4057  Validation loss = 6.6936  \n",
      "\n",
      "Fold: 15  Epoch: 579  Training loss = 2.4056  Validation loss = 6.6925  \n",
      "\n",
      "Fold: 15  Epoch: 580  Training loss = 2.4055  Validation loss = 6.6916  \n",
      "\n",
      "Fold: 15  Epoch: 581  Training loss = 2.4045  Validation loss = 6.6902  \n",
      "\n",
      "Fold: 15  Epoch: 582  Training loss = 2.4044  Validation loss = 6.6896  \n",
      "\n",
      "Fold: 15  Epoch: 583  Training loss = 2.4039  Validation loss = 6.6896  \n",
      "\n",
      "Fold: 15  Epoch: 584  Training loss = 2.4033  Validation loss = 6.6882  \n",
      "\n",
      "Fold: 15  Epoch: 585  Training loss = 2.4026  Validation loss = 6.6871  \n",
      "\n",
      "Fold: 15  Epoch: 586  Training loss = 2.4023  Validation loss = 6.6865  \n",
      "\n",
      "Fold: 15  Epoch: 587  Training loss = 2.4017  Validation loss = 6.6858  \n",
      "\n",
      "Fold: 15  Epoch: 588  Training loss = 2.4013  Validation loss = 6.6850  \n",
      "\n",
      "Fold: 15  Epoch: 589  Training loss = 2.4007  Validation loss = 6.6838  \n",
      "\n",
      "Fold: 15  Epoch: 590  Training loss = 2.4002  Validation loss = 6.6827  \n",
      "\n",
      "Fold: 15  Epoch: 591  Training loss = 2.4000  Validation loss = 6.6826  \n",
      "\n",
      "Fold: 15  Epoch: 592  Training loss = 2.3997  Validation loss = 6.6822  \n",
      "\n",
      "Fold: 15  Epoch: 593  Training loss = 2.3992  Validation loss = 6.6811  \n",
      "\n",
      "Fold: 15  Epoch: 594  Training loss = 2.3988  Validation loss = 6.6803  \n",
      "\n",
      "Fold: 15  Epoch: 595  Training loss = 2.3982  Validation loss = 6.6783  \n",
      "\n",
      "Fold: 15  Epoch: 596  Training loss = 2.3977  Validation loss = 6.6772  \n",
      "\n",
      "Fold: 15  Epoch: 597  Training loss = 2.3972  Validation loss = 6.6758  \n",
      "\n",
      "Fold: 15  Epoch: 598  Training loss = 2.3970  Validation loss = 6.6755  \n",
      "\n",
      "Fold: 15  Epoch: 599  Training loss = 2.3966  Validation loss = 6.6747  \n",
      "\n",
      "Fold: 15  Epoch: 600  Training loss = 2.3960  Validation loss = 6.6738  \n",
      "\n",
      "Fold: 15  Epoch: 601  Training loss = 2.3956  Validation loss = 6.6732  \n",
      "\n",
      "Fold: 15  Epoch: 602  Training loss = 2.3952  Validation loss = 6.6718  \n",
      "\n",
      "Fold: 15  Epoch: 603  Training loss = 2.3947  Validation loss = 6.6704  \n",
      "\n",
      "Fold: 15  Epoch: 604  Training loss = 2.3940  Validation loss = 6.6685  \n",
      "\n",
      "Fold: 15  Epoch: 605  Training loss = 2.3936  Validation loss = 6.6667  \n",
      "\n",
      "Fold: 15  Epoch: 606  Training loss = 2.3933  Validation loss = 6.6663  \n",
      "\n",
      "Fold: 15  Epoch: 607  Training loss = 2.3932  Validation loss = 6.6662  \n",
      "\n",
      "Fold: 15  Epoch: 608  Training loss = 2.3930  Validation loss = 6.6659  \n",
      "\n",
      "Fold: 15  Epoch: 609  Training loss = 2.3928  Validation loss = 6.6650  \n",
      "\n",
      "Fold: 15  Epoch: 610  Training loss = 2.3922  Validation loss = 6.6649  \n",
      "\n",
      "Fold: 15  Epoch: 611  Training loss = 2.3921  Validation loss = 6.6633  \n",
      "\n",
      "Fold: 15  Epoch: 612  Training loss = 2.3913  Validation loss = 6.6624  \n",
      "\n",
      "Fold: 15  Epoch: 613  Training loss = 2.3908  Validation loss = 6.6620  \n",
      "\n",
      "Fold: 15  Epoch: 614  Training loss = 2.3906  Validation loss = 6.6619  \n",
      "\n",
      "Fold: 15  Epoch: 615  Training loss = 2.3904  Validation loss = 6.6618  \n",
      "\n",
      "Fold: 15  Epoch: 616  Training loss = 2.3900  Validation loss = 6.6613  \n",
      "\n",
      "Fold: 15  Epoch: 617  Training loss = 2.3893  Validation loss = 6.6598  \n",
      "\n",
      "Fold: 15  Epoch: 618  Training loss = 2.3890  Validation loss = 6.6599  \n",
      "\n",
      "Fold: 15  Epoch: 619  Training loss = 2.3885  Validation loss = 6.6588  \n",
      "\n",
      "Fold: 15  Epoch: 620  Training loss = 2.3878  Validation loss = 6.6569  \n",
      "\n",
      "Fold: 15  Epoch: 621  Training loss = 2.3873  Validation loss = 6.6559  \n",
      "\n",
      "Fold: 15  Epoch: 622  Training loss = 2.3871  Validation loss = 6.6551  \n",
      "\n",
      "Fold: 15  Epoch: 623  Training loss = 2.3867  Validation loss = 6.6550  \n",
      "\n",
      "Fold: 15  Epoch: 624  Training loss = 2.3863  Validation loss = 6.6544  \n",
      "\n",
      "Fold: 15  Epoch: 625  Training loss = 2.3858  Validation loss = 6.6528  \n",
      "\n",
      "Fold: 15  Epoch: 626  Training loss = 2.3857  Validation loss = 6.6529  \n",
      "\n",
      "Fold: 15  Epoch: 627  Training loss = 2.3855  Validation loss = 6.6524  \n",
      "\n",
      "Fold: 15  Epoch: 628  Training loss = 2.3854  Validation loss = 6.6513  \n",
      "\n",
      "Fold: 15  Epoch: 629  Training loss = 2.3848  Validation loss = 6.6504  \n",
      "\n",
      "Fold: 15  Epoch: 630  Training loss = 2.3848  Validation loss = 6.6499  \n",
      "\n",
      "Fold: 15  Epoch: 631  Training loss = 2.3851  Validation loss = 6.6498  \n",
      "\n",
      "Fold: 15  Epoch: 632  Training loss = 2.3841  Validation loss = 6.6491  \n",
      "\n",
      "Fold: 15  Epoch: 633  Training loss = 2.3840  Validation loss = 6.6485  \n",
      "\n",
      "Fold: 15  Epoch: 634  Training loss = 2.3827  Validation loss = 6.6476  \n",
      "\n",
      "Fold: 15  Epoch: 635  Training loss = 2.3823  Validation loss = 6.6471  \n",
      "\n",
      "Fold: 15  Epoch: 636  Training loss = 2.3823  Validation loss = 6.6467  \n",
      "\n",
      "Fold: 15  Epoch: 637  Training loss = 2.3817  Validation loss = 6.6454  \n",
      "\n",
      "Fold: 15  Epoch: 638  Training loss = 2.3808  Validation loss = 6.6436  \n",
      "\n",
      "Fold: 15  Epoch: 639  Training loss = 2.3804  Validation loss = 6.6423  \n",
      "\n",
      "Fold: 15  Epoch: 640  Training loss = 2.3801  Validation loss = 6.6413  \n",
      "\n",
      "Fold: 15  Epoch: 641  Training loss = 2.3798  Validation loss = 6.6400  \n",
      "\n",
      "Fold: 15  Epoch: 642  Training loss = 2.3795  Validation loss = 6.6393  \n",
      "\n",
      "Fold: 15  Epoch: 643  Training loss = 2.3791  Validation loss = 6.6385  \n",
      "\n",
      "Fold: 15  Epoch: 644  Training loss = 2.3785  Validation loss = 6.6368  \n",
      "\n",
      "Fold: 15  Epoch: 645  Training loss = 2.3783  Validation loss = 6.6366  \n",
      "\n",
      "Fold: 15  Epoch: 646  Training loss = 2.3780  Validation loss = 6.6360  \n",
      "\n",
      "Fold: 15  Epoch: 647  Training loss = 2.3776  Validation loss = 6.6351  \n",
      "\n",
      "Fold: 15  Epoch: 648  Training loss = 2.3771  Validation loss = 6.6339  \n",
      "\n",
      "Fold: 15  Epoch: 649  Training loss = 2.3768  Validation loss = 6.6318  \n",
      "\n",
      "Fold: 15  Epoch: 650  Training loss = 2.3766  Validation loss = 6.6315  \n",
      "\n",
      "Fold: 15  Epoch: 651  Training loss = 2.3762  Validation loss = 6.6307  \n",
      "\n",
      "Fold: 15  Epoch: 652  Training loss = 2.3758  Validation loss = 6.6299  \n",
      "\n",
      "Fold: 15  Epoch: 653  Training loss = 2.3759  Validation loss = 6.6288  \n",
      "\n",
      "Fold: 15  Epoch: 654  Training loss = 2.3749  Validation loss = 6.6288  \n",
      "\n",
      "Fold: 15  Epoch: 655  Training loss = 2.3747  Validation loss = 6.6284  \n",
      "\n",
      "Fold: 15  Epoch: 656  Training loss = 2.3743  Validation loss = 6.6269  \n",
      "\n",
      "Fold: 15  Epoch: 657  Training loss = 2.3740  Validation loss = 6.6260  \n",
      "\n",
      "Fold: 15  Epoch: 658  Training loss = 2.3735  Validation loss = 6.6252  \n",
      "\n",
      "Fold: 15  Epoch: 659  Training loss = 2.3737  Validation loss = 6.6243  \n",
      "\n",
      "Fold: 15  Epoch: 660  Training loss = 2.3734  Validation loss = 6.6226  \n",
      "\n",
      "Fold: 15  Epoch: 661  Training loss = 2.3727  Validation loss = 6.6219  \n",
      "\n",
      "Fold: 15  Epoch: 662  Training loss = 2.3725  Validation loss = 6.6207  \n",
      "\n",
      "Fold: 15  Epoch: 663  Training loss = 2.3723  Validation loss = 6.6202  \n",
      "\n",
      "Fold: 15  Epoch: 664  Training loss = 2.3716  Validation loss = 6.6202  \n",
      "\n",
      "Fold: 15  Epoch: 665  Training loss = 2.3711  Validation loss = 6.6196  \n",
      "\n",
      "Fold: 15  Epoch: 666  Training loss = 2.3708  Validation loss = 6.6183  \n",
      "\n",
      "Fold: 15  Epoch: 667  Training loss = 2.3702  Validation loss = 6.6165  \n",
      "\n",
      "Fold: 15  Epoch: 668  Training loss = 2.3699  Validation loss = 6.6156  \n",
      "\n",
      "Fold: 15  Epoch: 669  Training loss = 2.3696  Validation loss = 6.6160  \n",
      "\n",
      "Fold: 15  Epoch: 670  Training loss = 2.3695  Validation loss = 6.6154  \n",
      "\n",
      "Fold: 15  Epoch: 671  Training loss = 2.3689  Validation loss = 6.6137  \n",
      "\n",
      "Fold: 15  Epoch: 672  Training loss = 2.3686  Validation loss = 6.6130  \n",
      "\n",
      "Fold: 15  Epoch: 673  Training loss = 2.3687  Validation loss = 6.6125  \n",
      "\n",
      "Fold: 15  Epoch: 674  Training loss = 2.3680  Validation loss = 6.6108  \n",
      "\n",
      "Fold: 15  Epoch: 675  Training loss = 2.3677  Validation loss = 6.6106  \n",
      "\n",
      "Fold: 15  Epoch: 676  Training loss = 2.3667  Validation loss = 6.6084  \n",
      "\n",
      "Fold: 15  Epoch: 677  Training loss = 2.3663  Validation loss = 6.6068  \n",
      "\n",
      "Fold: 15  Epoch: 678  Training loss = 2.3660  Validation loss = 6.6064  \n",
      "\n",
      "Fold: 15  Epoch: 679  Training loss = 2.3659  Validation loss = 6.6070  \n",
      "\n",
      "Fold: 15  Epoch: 680  Training loss = 2.3655  Validation loss = 6.6065  \n",
      "\n",
      "Fold: 15  Epoch: 681  Training loss = 2.3655  Validation loss = 6.6068  \n",
      "\n",
      "Fold: 15  Epoch: 682  Training loss = 2.3650  Validation loss = 6.6054  \n",
      "\n",
      "Fold: 15  Epoch: 683  Training loss = 2.3646  Validation loss = 6.6046  \n",
      "\n",
      "Fold: 15  Epoch: 684  Training loss = 2.3643  Validation loss = 6.6031  \n",
      "\n",
      "Fold: 15  Epoch: 685  Training loss = 2.3639  Validation loss = 6.6024  \n",
      "\n",
      "Fold: 15  Epoch: 686  Training loss = 2.3636  Validation loss = 6.6020  \n",
      "\n",
      "Fold: 15  Epoch: 687  Training loss = 2.3631  Validation loss = 6.6007  \n",
      "\n",
      "Fold: 15  Epoch: 688  Training loss = 2.3627  Validation loss = 6.5991  \n",
      "\n",
      "Fold: 15  Epoch: 689  Training loss = 2.3629  Validation loss = 6.5971  \n",
      "\n",
      "Fold: 15  Epoch: 690  Training loss = 2.3621  Validation loss = 6.5970  \n",
      "\n",
      "Fold: 15  Epoch: 691  Training loss = 2.3615  Validation loss = 6.5969  \n",
      "\n",
      "Fold: 15  Epoch: 692  Training loss = 2.3613  Validation loss = 6.5965  \n",
      "\n",
      "Fold: 15  Epoch: 693  Training loss = 2.3608  Validation loss = 6.5955  \n",
      "\n",
      "Fold: 15  Epoch: 694  Training loss = 2.3605  Validation loss = 6.5943  \n",
      "\n",
      "Fold: 15  Epoch: 695  Training loss = 2.3602  Validation loss = 6.5938  \n",
      "\n",
      "Fold: 15  Epoch: 696  Training loss = 2.3598  Validation loss = 6.5934  \n",
      "\n",
      "Fold: 15  Epoch: 697  Training loss = 2.3594  Validation loss = 6.5933  \n",
      "\n",
      "Fold: 15  Epoch: 698  Training loss = 2.3590  Validation loss = 6.5917  \n",
      "\n",
      "Fold: 15  Epoch: 699  Training loss = 2.3586  Validation loss = 6.5902  \n",
      "\n",
      "Fold: 15  Epoch: 700  Training loss = 2.3582  Validation loss = 6.5884  \n",
      "\n",
      "Fold: 15  Epoch: 701  Training loss = 2.3580  Validation loss = 6.5883  \n",
      "\n",
      "Fold: 15  Epoch: 702  Training loss = 2.3578  Validation loss = 6.5885  \n",
      "\n",
      "Fold: 15  Epoch: 703  Training loss = 2.3577  Validation loss = 6.5889  \n",
      "\n",
      "Fold: 15  Epoch: 704  Training loss = 2.3573  Validation loss = 6.5869  \n",
      "\n",
      "Fold: 15  Epoch: 705  Training loss = 2.3569  Validation loss = 6.5857  \n",
      "\n",
      "Fold: 15  Epoch: 706  Training loss = 2.3566  Validation loss = 6.5852  \n",
      "\n",
      "Fold: 15  Epoch: 707  Training loss = 2.3562  Validation loss = 6.5841  \n",
      "\n",
      "Fold: 15  Epoch: 708  Training loss = 2.3557  Validation loss = 6.5832  \n",
      "\n",
      "Fold: 15  Epoch: 709  Training loss = 2.3554  Validation loss = 6.5821  \n",
      "\n",
      "Fold: 15  Epoch: 710  Training loss = 2.3551  Validation loss = 6.5807  \n",
      "\n",
      "Fold: 15  Epoch: 711  Training loss = 2.3547  Validation loss = 6.5799  \n",
      "\n",
      "Fold: 15  Epoch: 712  Training loss = 2.3545  Validation loss = 6.5791  \n",
      "\n",
      "Fold: 15  Epoch: 713  Training loss = 2.3543  Validation loss = 6.5793  \n",
      "\n",
      "Fold: 15  Epoch: 714  Training loss = 2.3541  Validation loss = 6.5785  \n",
      "\n",
      "Fold: 15  Epoch: 715  Training loss = 2.3538  Validation loss = 6.5762  \n",
      "\n",
      "Fold: 15  Epoch: 716  Training loss = 2.3532  Validation loss = 6.5755  \n",
      "\n",
      "Fold: 15  Epoch: 717  Training loss = 2.3530  Validation loss = 6.5737  \n",
      "\n",
      "Fold: 15  Epoch: 718  Training loss = 2.3527  Validation loss = 6.5719  \n",
      "\n",
      "Fold: 15  Epoch: 719  Training loss = 2.3523  Validation loss = 6.5713  \n",
      "\n",
      "Fold: 15  Epoch: 720  Training loss = 2.3517  Validation loss = 6.5711  \n",
      "\n",
      "Fold: 15  Epoch: 721  Training loss = 2.3513  Validation loss = 6.5701  \n",
      "\n",
      "Fold: 15  Epoch: 722  Training loss = 2.3512  Validation loss = 6.5690  \n",
      "\n",
      "Fold: 15  Epoch: 723  Training loss = 2.3511  Validation loss = 6.5687  \n",
      "\n",
      "Fold: 15  Epoch: 724  Training loss = 2.3509  Validation loss = 6.5685  \n",
      "\n",
      "Fold: 15  Epoch: 725  Training loss = 2.3511  Validation loss = 6.5677  \n",
      "\n",
      "Fold: 15  Epoch: 726  Training loss = 2.3515  Validation loss = 6.5660  \n",
      "\n",
      "Fold: 15  Epoch: 727  Training loss = 2.3504  Validation loss = 6.5659  \n",
      "\n",
      "Fold: 15  Epoch: 728  Training loss = 2.3504  Validation loss = 6.5647  \n",
      "\n",
      "Fold: 15  Epoch: 729  Training loss = 2.3502  Validation loss = 6.5648  \n",
      "\n",
      "Fold: 15  Epoch: 730  Training loss = 2.3506  Validation loss = 6.5631  \n",
      "\n",
      "Fold: 15  Epoch: 731  Training loss = 2.3495  Validation loss = 6.5631  \n",
      "\n",
      "Fold: 15  Epoch: 732  Training loss = 2.3493  Validation loss = 6.5626  \n",
      "\n",
      "Fold: 15  Epoch: 733  Training loss = 2.3491  Validation loss = 6.5617  \n",
      "\n",
      "Fold: 15  Epoch: 734  Training loss = 2.3486  Validation loss = 6.5620  \n",
      "\n",
      "Fold: 15  Epoch: 735  Training loss = 2.3487  Validation loss = 6.5610  \n",
      "\n",
      "Fold: 15  Epoch: 736  Training loss = 2.3483  Validation loss = 6.5605  \n",
      "\n",
      "Fold: 15  Epoch: 737  Training loss = 2.3482  Validation loss = 6.5599  \n",
      "\n",
      "Fold: 15  Epoch: 738  Training loss = 2.3474  Validation loss = 6.5582  \n",
      "\n",
      "Fold: 15  Epoch: 739  Training loss = 2.3468  Validation loss = 6.5567  \n",
      "\n",
      "Fold: 15  Epoch: 740  Training loss = 2.3461  Validation loss = 6.5560  \n",
      "\n",
      "Fold: 15  Epoch: 741  Training loss = 2.3457  Validation loss = 6.5552  \n",
      "\n",
      "Fold: 15  Epoch: 742  Training loss = 2.3456  Validation loss = 6.5550  \n",
      "\n",
      "Fold: 15  Epoch: 743  Training loss = 2.3451  Validation loss = 6.5542  \n",
      "\n",
      "Fold: 15  Epoch: 744  Training loss = 2.3451  Validation loss = 6.5539  \n",
      "\n",
      "Fold: 15  Epoch: 745  Training loss = 2.3449  Validation loss = 6.5539  \n",
      "\n",
      "Fold: 15  Epoch: 746  Training loss = 2.3452  Validation loss = 6.5524  \n",
      "\n",
      "Fold: 15  Epoch: 747  Training loss = 2.3449  Validation loss = 6.5510  \n",
      "\n",
      "Fold: 15  Epoch: 748  Training loss = 2.3446  Validation loss = 6.5503  \n",
      "\n",
      "Fold: 15  Epoch: 749  Training loss = 2.3440  Validation loss = 6.5487  \n",
      "\n",
      "Fold: 15  Epoch: 750  Training loss = 2.3433  Validation loss = 6.5487  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 749  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.8355  Validation loss = 4.4979  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.8343  Validation loss = 4.4973  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.8337  Validation loss = 4.4935  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.8329  Validation loss = 4.4961  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.8318  Validation loss = 4.4986  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.8306  Validation loss = 4.5039  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.8300  Validation loss = 4.5013  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.8290  Validation loss = 4.4899  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.8278  Validation loss = 4.4914  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.8259  Validation loss = 4.4939  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.8242  Validation loss = 4.4947  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.8232  Validation loss = 4.4931  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.8227  Validation loss = 4.4896  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.8217  Validation loss = 4.4912  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.8215  Validation loss = 4.4933  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.8206  Validation loss = 4.4977  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.8199  Validation loss = 4.5006  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 2.8187  Validation loss = 4.4987  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.8175  Validation loss = 4.4959  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.8172  Validation loss = 4.4960  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 2.8163  Validation loss = 4.5015  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 13  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 3.0264  Validation loss = 3.1795  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 3.0224  Validation loss = 3.1801  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 3.0219  Validation loss = 3.1816  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 3.0192  Validation loss = 3.1840  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 3.0160  Validation loss = 3.1848  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 3.0149  Validation loss = 3.1850  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 3.0128  Validation loss = 3.1858  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 3.0097  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 3.0057  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 3.0030  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.9981  Validation loss = 3.1775  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.9916  Validation loss = 3.1684  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.9890  Validation loss = 3.1658  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.9873  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.9833  Validation loss = 3.1556  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 2.9806  Validation loss = 3.1544  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 2.9804  Validation loss = 3.1585  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 2.9760  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 2.9733  Validation loss = 3.1403  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 2.9708  Validation loss = 3.1359  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 2.9683  Validation loss = 3.1340  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 2.9665  Validation loss = 3.1308  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 2.9652  Validation loss = 3.1285  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 2.9628  Validation loss = 3.1312  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 2.9619  Validation loss = 3.1341  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 2.9601  Validation loss = 3.1312  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 2.9580  Validation loss = 3.1340  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 2.9554  Validation loss = 3.1280  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 2.9544  Validation loss = 3.1245  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 2.9527  Validation loss = 3.1193  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 2.9516  Validation loss = 3.1227  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 2.9502  Validation loss = 3.1231  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 2.9480  Validation loss = 3.1246  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 2.9452  Validation loss = 3.1270  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 2.9443  Validation loss = 3.1273  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 2.9435  Validation loss = 3.1238  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 2.9432  Validation loss = 3.1223  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 2.9406  Validation loss = 3.1286  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 2.9393  Validation loss = 3.1252  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 2.9380  Validation loss = 3.1245  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 2.9380  Validation loss = 3.1272  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 2.9367  Validation loss = 3.1301  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 30  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.0329  Validation loss = 1.3719  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.0311  Validation loss = 1.3709  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.0288  Validation loss = 1.3705  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.0265  Validation loss = 1.3699  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.0246  Validation loss = 1.3695  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.0232  Validation loss = 1.3695  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 3.0230  Validation loss = 1.3695  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 3.0201  Validation loss = 1.3679  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 3.0184  Validation loss = 1.3670  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 3.0165  Validation loss = 1.3669  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.0154  Validation loss = 1.3659  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 3.0147  Validation loss = 1.3667  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 3.0135  Validation loss = 1.3649  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 3.0126  Validation loss = 1.3634  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 3.0112  Validation loss = 1.3627  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 3.0111  Validation loss = 1.3618  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 3.0103  Validation loss = 1.3625  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 3.0087  Validation loss = 1.3630  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 3.0077  Validation loss = 1.3617  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 3.0061  Validation loss = 1.3615  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 3.0058  Validation loss = 1.3603  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 3.0047  Validation loss = 1.3598  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 3.0044  Validation loss = 1.3601  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 3.0037  Validation loss = 1.3603  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 3.0031  Validation loss = 1.3601  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 3.0013  Validation loss = 1.3588  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 2.9996  Validation loss = 1.3582  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 2.9997  Validation loss = 1.3579  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 2.9965  Validation loss = 1.3572  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 2.9956  Validation loss = 1.3574  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 2.9946  Validation loss = 1.3571  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 2.9941  Validation loss = 1.3560  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 2.9937  Validation loss = 1.3564  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 2.9925  Validation loss = 1.3564  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 2.9929  Validation loss = 1.3561  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 2.9926  Validation loss = 1.3564  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 2.9915  Validation loss = 1.3570  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 2.9903  Validation loss = 1.3569  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 2.9884  Validation loss = 1.3559  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 2.9880  Validation loss = 1.3542  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 2.9869  Validation loss = 1.3545  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 2.9869  Validation loss = 1.3535  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 2.9851  Validation loss = 1.3544  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 2.9837  Validation loss = 1.3540  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 2.9827  Validation loss = 1.3538  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 2.9818  Validation loss = 1.3545  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 2.9815  Validation loss = 1.3551  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 2.9801  Validation loss = 1.3548  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 2.9788  Validation loss = 1.3544  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 2.9780  Validation loss = 1.3537  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 2.9772  Validation loss = 1.3529  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 2.9758  Validation loss = 1.3526  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 2.9754  Validation loss = 1.3527  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 2.9744  Validation loss = 1.3522  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 2.9736  Validation loss = 1.3517  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 2.9721  Validation loss = 1.3508  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 2.9714  Validation loss = 1.3510  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 2.9709  Validation loss = 1.3506  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 2.9704  Validation loss = 1.3492  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 2.9701  Validation loss = 1.3508  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 2.9694  Validation loss = 1.3499  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 2.9685  Validation loss = 1.3488  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 2.9682  Validation loss = 1.3484  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 2.9679  Validation loss = 1.3487  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 2.9674  Validation loss = 1.3489  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 2.9668  Validation loss = 1.3490  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 2.9650  Validation loss = 1.3483  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 2.9644  Validation loss = 1.3477  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 2.9640  Validation loss = 1.3484  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 2.9634  Validation loss = 1.3486  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 2.9627  Validation loss = 1.3494  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 2.9619  Validation loss = 1.3480  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 2.9612  Validation loss = 1.3477  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 2.9603  Validation loss = 1.3474  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 2.9588  Validation loss = 1.3473  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 2.9578  Validation loss = 1.3468  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 2.9568  Validation loss = 1.3465  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 2.9549  Validation loss = 1.3453  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 2.9537  Validation loss = 1.3440  \n",
      "\n",
      "Fold: 18  Epoch: 80  Training loss = 2.9535  Validation loss = 1.3436  \n",
      "\n",
      "Fold: 18  Epoch: 81  Training loss = 2.9529  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 18  Epoch: 82  Training loss = 2.9520  Validation loss = 1.3425  \n",
      "\n",
      "Fold: 18  Epoch: 83  Training loss = 2.9516  Validation loss = 1.3428  \n",
      "\n",
      "Fold: 18  Epoch: 84  Training loss = 2.9496  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 18  Epoch: 85  Training loss = 2.9487  Validation loss = 1.3433  \n",
      "\n",
      "Fold: 18  Epoch: 86  Training loss = 2.9479  Validation loss = 1.3438  \n",
      "\n",
      "Fold: 18  Epoch: 87  Training loss = 2.9477  Validation loss = 1.3441  \n",
      "\n",
      "Fold: 18  Epoch: 88  Training loss = 2.9474  Validation loss = 1.3441  \n",
      "\n",
      "Fold: 18  Epoch: 89  Training loss = 2.9469  Validation loss = 1.3461  \n",
      "\n",
      "Fold: 18  Epoch: 90  Training loss = 2.9462  Validation loss = 1.3460  \n",
      "\n",
      "Fold: 18  Epoch: 91  Training loss = 2.9453  Validation loss = 1.3455  \n",
      "\n",
      "Fold: 18  Epoch: 92  Training loss = 2.9446  Validation loss = 1.3445  \n",
      "\n",
      "Fold: 18  Epoch: 93  Training loss = 2.9437  Validation loss = 1.3444  \n",
      "\n",
      "Fold: 18  Epoch: 94  Training loss = 2.9423  Validation loss = 1.3439  \n",
      "\n",
      "Fold: 18  Epoch: 95  Training loss = 2.9420  Validation loss = 1.3441  \n",
      "\n",
      "Fold: 18  Epoch: 96  Training loss = 2.9407  Validation loss = 1.3438  \n",
      "\n",
      "Fold: 18  Epoch: 97  Training loss = 2.9408  Validation loss = 1.3423  \n",
      "\n",
      "Fold: 18  Epoch: 98  Training loss = 2.9390  Validation loss = 1.3421  \n",
      "\n",
      "Fold: 18  Epoch: 99  Training loss = 2.9381  Validation loss = 1.3425  \n",
      "\n",
      "Fold: 18  Epoch: 100  Training loss = 2.9374  Validation loss = 1.3429  \n",
      "\n",
      "Fold: 18  Epoch: 101  Training loss = 2.9363  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 18  Epoch: 102  Training loss = 2.9354  Validation loss = 1.3431  \n",
      "\n",
      "Fold: 18  Epoch: 103  Training loss = 2.9349  Validation loss = 1.3434  \n",
      "\n",
      "Fold: 18  Epoch: 104  Training loss = 2.9344  Validation loss = 1.3434  \n",
      "\n",
      "Fold: 18  Epoch: 105  Training loss = 2.9335  Validation loss = 1.3424  \n",
      "\n",
      "Fold: 18  Epoch: 106  Training loss = 2.9322  Validation loss = 1.3423  \n",
      "\n",
      "Fold: 18  Epoch: 107  Training loss = 2.9315  Validation loss = 1.3420  \n",
      "\n",
      "Fold: 18  Epoch: 108  Training loss = 2.9310  Validation loss = 1.3408  \n",
      "\n",
      "Fold: 18  Epoch: 109  Training loss = 2.9301  Validation loss = 1.3413  \n",
      "\n",
      "Fold: 18  Epoch: 110  Training loss = 2.9289  Validation loss = 1.3420  \n",
      "\n",
      "Fold: 18  Epoch: 111  Training loss = 2.9287  Validation loss = 1.3426  \n",
      "\n",
      "Fold: 18  Epoch: 112  Training loss = 2.9274  Validation loss = 1.3418  \n",
      "\n",
      "Fold: 18  Epoch: 113  Training loss = 2.9267  Validation loss = 1.3419  \n",
      "\n",
      "Fold: 18  Epoch: 114  Training loss = 2.9256  Validation loss = 1.3423  \n",
      "\n",
      "Fold: 18  Epoch: 115  Training loss = 2.9252  Validation loss = 1.3433  \n",
      "\n",
      "Fold: 18  Epoch: 116  Training loss = 2.9247  Validation loss = 1.3432  \n",
      "\n",
      "Fold: 18  Epoch: 117  Training loss = 2.9237  Validation loss = 1.3428  \n",
      "\n",
      "Fold: 18  Epoch: 118  Training loss = 2.9235  Validation loss = 1.3432  \n",
      "\n",
      "Fold: 18  Epoch: 119  Training loss = 2.9231  Validation loss = 1.3439  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 108  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.8908  Validation loss = 2.8269  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.8893  Validation loss = 2.8246  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.8881  Validation loss = 2.8247  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.8874  Validation loss = 2.8262  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.8856  Validation loss = 2.8254  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.8856  Validation loss = 2.8254  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.8845  Validation loss = 2.8222  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.8838  Validation loss = 2.8212  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.8830  Validation loss = 2.8185  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.8816  Validation loss = 2.8179  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.8808  Validation loss = 2.8178  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.8796  Validation loss = 2.8165  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.8786  Validation loss = 2.8173  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.8773  Validation loss = 2.8166  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.8772  Validation loss = 2.8150  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.8772  Validation loss = 2.8141  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 2.8765  Validation loss = 2.8148  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 2.8746  Validation loss = 2.8138  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 2.8725  Validation loss = 2.8134  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 2.8714  Validation loss = 2.8126  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 2.8708  Validation loss = 2.8120  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 2.8700  Validation loss = 2.8106  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 2.8706  Validation loss = 2.8103  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 2.8699  Validation loss = 2.8084  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 2.8693  Validation loss = 2.8071  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 2.8682  Validation loss = 2.8061  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 2.8673  Validation loss = 2.8049  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 2.8669  Validation loss = 2.8050  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 2.8661  Validation loss = 2.8041  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 2.8647  Validation loss = 2.8042  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 2.8640  Validation loss = 2.8043  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 2.8638  Validation loss = 2.8039  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 2.8628  Validation loss = 2.8040  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 2.8623  Validation loss = 2.8032  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 2.8626  Validation loss = 2.8023  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 2.8601  Validation loss = 2.8018  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 2.8595  Validation loss = 2.8014  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 2.8589  Validation loss = 2.8017  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 2.8573  Validation loss = 2.8014  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 2.8542  Validation loss = 2.8029  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 2.8530  Validation loss = 2.8036  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 2.8519  Validation loss = 2.8024  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 2.8512  Validation loss = 2.8026  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 2.8507  Validation loss = 2.8008  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 2.8497  Validation loss = 2.8009  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 2.8493  Validation loss = 2.8014  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 2.8488  Validation loss = 2.8016  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 2.8477  Validation loss = 2.8013  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 2.8471  Validation loss = 2.8017  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 2.8463  Validation loss = 2.8014  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 2.8459  Validation loss = 2.8008  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 2.8448  Validation loss = 2.7990  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 2.8441  Validation loss = 2.7982  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 2.8436  Validation loss = 2.7983  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 2.8426  Validation loss = 2.7975  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 2.8419  Validation loss = 2.7973  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 2.8410  Validation loss = 2.7962  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 2.8400  Validation loss = 2.7969  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 2.8398  Validation loss = 2.7972  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 2.8394  Validation loss = 2.7980  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 2.8388  Validation loss = 2.7978  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 2.8382  Validation loss = 2.7960  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 2.8376  Validation loss = 2.7965  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 2.8375  Validation loss = 2.7965  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 2.8364  Validation loss = 2.7943  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 2.8357  Validation loss = 2.7952  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 2.8355  Validation loss = 2.7966  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 2.8352  Validation loss = 2.7964  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 2.8335  Validation loss = 2.7948  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 2.8333  Validation loss = 2.7938  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 2.8324  Validation loss = 2.7937  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 2.8322  Validation loss = 2.7940  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 2.8313  Validation loss = 2.7934  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 2.8305  Validation loss = 2.7923  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 2.8303  Validation loss = 2.7926  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 2.8298  Validation loss = 2.7921  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 2.8292  Validation loss = 2.7907  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 2.8281  Validation loss = 2.7888  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 2.8278  Validation loss = 2.7879  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 2.8279  Validation loss = 2.7887  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 2.8270  Validation loss = 2.7887  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 2.8266  Validation loss = 2.7895  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 2.8265  Validation loss = 2.7891  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 2.8249  Validation loss = 2.7886  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 2.8243  Validation loss = 2.7877  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 2.8224  Validation loss = 2.7871  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 2.8224  Validation loss = 2.7867  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 2.8219  Validation loss = 2.7867  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 2.8213  Validation loss = 2.7863  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 2.8209  Validation loss = 2.7856  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 2.8200  Validation loss = 2.7859  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 2.8189  Validation loss = 2.7856  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 2.8184  Validation loss = 2.7842  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 2.8176  Validation loss = 2.7844  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 2.8168  Validation loss = 2.7836  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 2.8212  Validation loss = 2.7824  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 2.8158  Validation loss = 2.7830  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 2.8150  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 2.8148  Validation loss = 2.7824  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 2.8141  Validation loss = 2.7836  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 2.8136  Validation loss = 2.7840  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 2.8133  Validation loss = 2.7837  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 2.8125  Validation loss = 2.7838  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 2.8115  Validation loss = 2.7835  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 2.8109  Validation loss = 2.7833  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 2.8106  Validation loss = 2.7829  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 2.8101  Validation loss = 2.7822  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 2.8096  Validation loss = 2.7825  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 2.8087  Validation loss = 2.7814  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 2.8082  Validation loss = 2.7809  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 2.8078  Validation loss = 2.7821  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 2.8076  Validation loss = 2.7814  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 2.8077  Validation loss = 2.7817  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 2.8069  Validation loss = 2.7815  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 2.8066  Validation loss = 2.7810  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 2.8062  Validation loss = 2.7810  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 2.8057  Validation loss = 2.7803  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 2.8054  Validation loss = 2.7799  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 2.8050  Validation loss = 2.7802  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 2.8042  Validation loss = 2.7792  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 2.8037  Validation loss = 2.7788  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 2.8035  Validation loss = 2.7779  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 2.8033  Validation loss = 2.7778  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 2.8026  Validation loss = 2.7767  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 2.8021  Validation loss = 2.7766  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 2.8019  Validation loss = 2.7767  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 2.8017  Validation loss = 2.7767  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 2.8016  Validation loss = 2.7763  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 2.8011  Validation loss = 2.7772  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 2.8015  Validation loss = 2.7776  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 2.8008  Validation loss = 2.7776  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 2.7996  Validation loss = 2.7776  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 2.7990  Validation loss = 2.7773  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 2.7986  Validation loss = 2.7773  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 2.7980  Validation loss = 2.7767  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 2.7976  Validation loss = 2.7764  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 2.7968  Validation loss = 2.7752  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 2.7962  Validation loss = 2.7745  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 2.7951  Validation loss = 2.7742  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 2.7947  Validation loss = 2.7740  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 2.7943  Validation loss = 2.7737  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 2.7938  Validation loss = 2.7729  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 2.7930  Validation loss = 2.7732  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 2.7926  Validation loss = 2.7737  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 2.7921  Validation loss = 2.7731  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 2.7918  Validation loss = 2.7731  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 2.7911  Validation loss = 2.7738  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 2.7903  Validation loss = 2.7710  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 2.7898  Validation loss = 2.7711  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 2.7897  Validation loss = 2.7697  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 2.7887  Validation loss = 2.7693  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 2.7889  Validation loss = 2.7682  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 2.7881  Validation loss = 2.7672  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 2.7875  Validation loss = 2.7663  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 2.7870  Validation loss = 2.7676  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 2.7864  Validation loss = 2.7670  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 2.7866  Validation loss = 2.7668  \n",
      "\n",
      "Fold: 19  Epoch: 158  Training loss = 2.7858  Validation loss = 2.7669  \n",
      "\n",
      "Fold: 19  Epoch: 159  Training loss = 2.7854  Validation loss = 2.7672  \n",
      "\n",
      "Fold: 19  Epoch: 160  Training loss = 2.7850  Validation loss = 2.7668  \n",
      "\n",
      "Fold: 19  Epoch: 161  Training loss = 2.7841  Validation loss = 2.7666  \n",
      "\n",
      "Fold: 19  Epoch: 162  Training loss = 2.7836  Validation loss = 2.7672  \n",
      "\n",
      "Fold: 19  Epoch: 163  Training loss = 2.7839  Validation loss = 2.7670  \n",
      "\n",
      "Fold: 19  Epoch: 164  Training loss = 2.7832  Validation loss = 2.7672  \n",
      "\n",
      "Fold: 19  Epoch: 165  Training loss = 2.7828  Validation loss = 2.7670  \n",
      "\n",
      "Fold: 19  Epoch: 166  Training loss = 2.7826  Validation loss = 2.7664  \n",
      "\n",
      "Fold: 19  Epoch: 167  Training loss = 2.7827  Validation loss = 2.7647  \n",
      "\n",
      "Fold: 19  Epoch: 168  Training loss = 2.7823  Validation loss = 2.7650  \n",
      "\n",
      "Fold: 19  Epoch: 169  Training loss = 2.7811  Validation loss = 2.7651  \n",
      "\n",
      "Fold: 19  Epoch: 170  Training loss = 2.7806  Validation loss = 2.7654  \n",
      "\n",
      "Fold: 19  Epoch: 171  Training loss = 2.7800  Validation loss = 2.7649  \n",
      "\n",
      "Fold: 19  Epoch: 172  Training loss = 2.7801  Validation loss = 2.7654  \n",
      "\n",
      "Fold: 19  Epoch: 173  Training loss = 2.7797  Validation loss = 2.7657  \n",
      "\n",
      "Fold: 19  Epoch: 174  Training loss = 2.7797  Validation loss = 2.7660  \n",
      "\n",
      "Fold: 19  Epoch: 175  Training loss = 2.7792  Validation loss = 2.7648  \n",
      "\n",
      "Fold: 19  Epoch: 176  Training loss = 2.7785  Validation loss = 2.7641  \n",
      "\n",
      "Fold: 19  Epoch: 177  Training loss = 2.7778  Validation loss = 2.7636  \n",
      "\n",
      "Fold: 19  Epoch: 178  Training loss = 2.7772  Validation loss = 2.7630  \n",
      "\n",
      "Fold: 19  Epoch: 179  Training loss = 2.7765  Validation loss = 2.7629  \n",
      "\n",
      "Fold: 19  Epoch: 180  Training loss = 2.7761  Validation loss = 2.7619  \n",
      "\n",
      "Fold: 19  Epoch: 181  Training loss = 2.7756  Validation loss = 2.7617  \n",
      "\n",
      "Fold: 19  Epoch: 182  Training loss = 2.7750  Validation loss = 2.7613  \n",
      "\n",
      "Fold: 19  Epoch: 183  Training loss = 2.7744  Validation loss = 2.7610  \n",
      "\n",
      "Fold: 19  Epoch: 184  Training loss = 2.7736  Validation loss = 2.7586  \n",
      "\n",
      "Fold: 19  Epoch: 185  Training loss = 2.7731  Validation loss = 2.7577  \n",
      "\n",
      "Fold: 19  Epoch: 186  Training loss = 2.7735  Validation loss = 2.7589  \n",
      "\n",
      "Fold: 19  Epoch: 187  Training loss = 2.7728  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 19  Epoch: 188  Training loss = 2.7721  Validation loss = 2.7565  \n",
      "\n",
      "Fold: 19  Epoch: 189  Training loss = 2.7719  Validation loss = 2.7567  \n",
      "\n",
      "Fold: 19  Epoch: 190  Training loss = 2.7716  Validation loss = 2.7569  \n",
      "\n",
      "Fold: 19  Epoch: 191  Training loss = 2.7714  Validation loss = 2.7558  \n",
      "\n",
      "Fold: 19  Epoch: 192  Training loss = 2.7712  Validation loss = 2.7562  \n",
      "\n",
      "Fold: 19  Epoch: 193  Training loss = 2.7706  Validation loss = 2.7557  \n",
      "\n",
      "Fold: 19  Epoch: 194  Training loss = 2.7704  Validation loss = 2.7557  \n",
      "\n",
      "Fold: 19  Epoch: 195  Training loss = 2.7702  Validation loss = 2.7551  \n",
      "\n",
      "Fold: 19  Epoch: 196  Training loss = 2.7697  Validation loss = 2.7558  \n",
      "\n",
      "Fold: 19  Epoch: 197  Training loss = 2.7690  Validation loss = 2.7558  \n",
      "\n",
      "Fold: 19  Epoch: 198  Training loss = 2.7687  Validation loss = 2.7553  \n",
      "\n",
      "Fold: 19  Epoch: 199  Training loss = 2.7684  Validation loss = 2.7560  \n",
      "\n",
      "Fold: 19  Epoch: 200  Training loss = 2.7680  Validation loss = 2.7551  \n",
      "\n",
      "Fold: 19  Epoch: 201  Training loss = 2.7677  Validation loss = 2.7554  \n",
      "\n",
      "Fold: 19  Epoch: 202  Training loss = 2.7672  Validation loss = 2.7552  \n",
      "\n",
      "Fold: 19  Epoch: 203  Training loss = 2.7671  Validation loss = 2.7554  \n",
      "\n",
      "Fold: 19  Epoch: 204  Training loss = 2.7669  Validation loss = 2.7550  \n",
      "\n",
      "Fold: 19  Epoch: 205  Training loss = 2.7665  Validation loss = 2.7552  \n",
      "\n",
      "Fold: 19  Epoch: 206  Training loss = 2.7660  Validation loss = 2.7550  \n",
      "\n",
      "Fold: 19  Epoch: 207  Training loss = 2.7649  Validation loss = 2.7544  \n",
      "\n",
      "Fold: 19  Epoch: 208  Training loss = 2.7646  Validation loss = 2.7538  \n",
      "\n",
      "Fold: 19  Epoch: 209  Training loss = 2.7658  Validation loss = 2.7529  \n",
      "\n",
      "Fold: 19  Epoch: 210  Training loss = 2.7642  Validation loss = 2.7532  \n",
      "\n",
      "Fold: 19  Epoch: 211  Training loss = 2.7636  Validation loss = 2.7522  \n",
      "\n",
      "Fold: 19  Epoch: 212  Training loss = 2.7629  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 19  Epoch: 213  Training loss = 2.7626  Validation loss = 2.7509  \n",
      "\n",
      "Fold: 19  Epoch: 214  Training loss = 2.7625  Validation loss = 2.7510  \n",
      "\n",
      "Fold: 19  Epoch: 215  Training loss = 2.7621  Validation loss = 2.7510  \n",
      "\n",
      "Fold: 19  Epoch: 216  Training loss = 2.7617  Validation loss = 2.7510  \n",
      "\n",
      "Fold: 19  Epoch: 217  Training loss = 2.7613  Validation loss = 2.7498  \n",
      "\n",
      "Fold: 19  Epoch: 218  Training loss = 2.7608  Validation loss = 2.7496  \n",
      "\n",
      "Fold: 19  Epoch: 219  Training loss = 2.7618  Validation loss = 2.7488  \n",
      "\n",
      "Fold: 19  Epoch: 220  Training loss = 2.7600  Validation loss = 2.7503  \n",
      "\n",
      "Fold: 19  Epoch: 221  Training loss = 2.7598  Validation loss = 2.7502  \n",
      "\n",
      "Fold: 19  Epoch: 222  Training loss = 2.7592  Validation loss = 2.7501  \n",
      "\n",
      "Fold: 19  Epoch: 223  Training loss = 2.7589  Validation loss = 2.7501  \n",
      "\n",
      "Fold: 19  Epoch: 224  Training loss = 2.7583  Validation loss = 2.7515  \n",
      "\n",
      "Fold: 19  Epoch: 225  Training loss = 2.7580  Validation loss = 2.7512  \n",
      "\n",
      "Fold: 19  Epoch: 226  Training loss = 2.7575  Validation loss = 2.7508  \n",
      "\n",
      "Fold: 19  Epoch: 227  Training loss = 2.7570  Validation loss = 2.7503  \n",
      "\n",
      "Fold: 19  Epoch: 228  Training loss = 2.7565  Validation loss = 2.7496  \n",
      "\n",
      "Fold: 19  Epoch: 229  Training loss = 2.7562  Validation loss = 2.7498  \n",
      "\n",
      "Fold: 19  Epoch: 230  Training loss = 2.7560  Validation loss = 2.7486  \n",
      "\n",
      "Fold: 19  Epoch: 231  Training loss = 2.7556  Validation loss = 2.7477  \n",
      "\n",
      "Fold: 19  Epoch: 232  Training loss = 2.7548  Validation loss = 2.7481  \n",
      "\n",
      "Fold: 19  Epoch: 233  Training loss = 2.7546  Validation loss = 2.7478  \n",
      "\n",
      "Fold: 19  Epoch: 234  Training loss = 2.7543  Validation loss = 2.7477  \n",
      "\n",
      "Fold: 19  Epoch: 235  Training loss = 2.7538  Validation loss = 2.7475  \n",
      "\n",
      "Fold: 19  Epoch: 236  Training loss = 2.7538  Validation loss = 2.7472  \n",
      "\n",
      "Fold: 19  Epoch: 237  Training loss = 2.7534  Validation loss = 2.7478  \n",
      "\n",
      "Fold: 19  Epoch: 238  Training loss = 2.7528  Validation loss = 2.7472  \n",
      "\n",
      "Fold: 19  Epoch: 239  Training loss = 2.7524  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 19  Epoch: 240  Training loss = 2.7519  Validation loss = 2.7464  \n",
      "\n",
      "Fold: 19  Epoch: 241  Training loss = 2.7515  Validation loss = 2.7460  \n",
      "\n",
      "Fold: 19  Epoch: 242  Training loss = 2.7517  Validation loss = 2.7462  \n",
      "\n",
      "Fold: 19  Epoch: 243  Training loss = 2.7514  Validation loss = 2.7471  \n",
      "\n",
      "Fold: 19  Epoch: 244  Training loss = 2.7513  Validation loss = 2.7478  \n",
      "\n",
      "Fold: 19  Epoch: 245  Training loss = 2.7517  Validation loss = 2.7485  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 241  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.8271  Validation loss = 1.5310  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.8258  Validation loss = 1.5287  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.8245  Validation loss = 1.5266  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.8232  Validation loss = 1.5250  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.8228  Validation loss = 1.5237  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.8225  Validation loss = 1.5202  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.8208  Validation loss = 1.5175  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.8203  Validation loss = 1.5154  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.8206  Validation loss = 1.5137  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.8200  Validation loss = 1.5121  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.8187  Validation loss = 1.5107  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.8186  Validation loss = 1.5114  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 2.8181  Validation loss = 1.5099  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.8175  Validation loss = 1.5090  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.8171  Validation loss = 1.5074  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.8157  Validation loss = 1.5042  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.8147  Validation loss = 1.5013  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.8137  Validation loss = 1.4991  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 2.8134  Validation loss = 1.4985  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 2.8127  Validation loss = 1.4957  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 2.8119  Validation loss = 1.4944  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 2.8114  Validation loss = 1.4941  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 2.8115  Validation loss = 1.4934  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 2.8122  Validation loss = 1.4952  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 2.8110  Validation loss = 1.4929  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 2.8100  Validation loss = 1.4877  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 2.8095  Validation loss = 1.4853  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 2.8089  Validation loss = 1.4842  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 2.8078  Validation loss = 1.4821  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 2.8076  Validation loss = 1.4822  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 2.8070  Validation loss = 1.4801  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 2.8068  Validation loss = 1.4797  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 2.8064  Validation loss = 1.4778  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 2.8064  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 2.8060  Validation loss = 1.4773  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 2.8055  Validation loss = 1.4764  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 2.8045  Validation loss = 1.4732  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 2.8042  Validation loss = 1.4715  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 2.8037  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 2.8034  Validation loss = 1.4689  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 2.8031  Validation loss = 1.4666  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 2.8020  Validation loss = 1.4645  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 2.8015  Validation loss = 1.4621  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 2.8009  Validation loss = 1.4599  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 2.8006  Validation loss = 1.4583  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 2.8007  Validation loss = 1.4569  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 2.8002  Validation loss = 1.4547  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 2.7994  Validation loss = 1.4527  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 2.7988  Validation loss = 1.4523  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 2.7980  Validation loss = 1.4520  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 2.7979  Validation loss = 1.4519  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 2.7977  Validation loss = 1.4507  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 2.7973  Validation loss = 1.4493  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 2.7976  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 2.7987  Validation loss = 1.4462  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 2.7987  Validation loss = 1.4443  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 2.7965  Validation loss = 1.4428  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 2.7954  Validation loss = 1.4409  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 2.7939  Validation loss = 1.4368  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 2.7938  Validation loss = 1.4350  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 2.7930  Validation loss = 1.4337  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 2.7926  Validation loss = 1.4313  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 2.7918  Validation loss = 1.4309  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 2.7916  Validation loss = 1.4307  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 2.7909  Validation loss = 1.4309  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 2.7906  Validation loss = 1.4306  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 2.7900  Validation loss = 1.4282  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 2.7898  Validation loss = 1.4281  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 2.7903  Validation loss = 1.4258  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 2.7882  Validation loss = 1.4255  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 2.7883  Validation loss = 1.4249  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 2.7881  Validation loss = 1.4258  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 2.7879  Validation loss = 1.4246  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 2.7884  Validation loss = 1.4219  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 2.7868  Validation loss = 1.4219  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 2.7860  Validation loss = 1.4195  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 2.7856  Validation loss = 1.4181  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 2.7853  Validation loss = 1.4175  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 2.7850  Validation loss = 1.4169  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 2.7848  Validation loss = 1.4153  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 2.7845  Validation loss = 1.4128  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 2.7836  Validation loss = 1.4115  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 2.7831  Validation loss = 1.4101  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 2.7824  Validation loss = 1.4094  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 2.7821  Validation loss = 1.4105  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 2.7818  Validation loss = 1.4093  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 2.7819  Validation loss = 1.4073  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 2.7814  Validation loss = 1.4049  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 2.7802  Validation loss = 1.4026  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 2.7798  Validation loss = 1.3997  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 2.7793  Validation loss = 1.3981  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 2.7786  Validation loss = 1.3971  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 2.7781  Validation loss = 1.3972  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 2.7775  Validation loss = 1.3974  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 2.7774  Validation loss = 1.3970  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 2.7767  Validation loss = 1.3938  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 2.7760  Validation loss = 1.3898  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 2.7755  Validation loss = 1.3886  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 2.7750  Validation loss = 1.3852  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 2.7748  Validation loss = 1.3847  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 2.7743  Validation loss = 1.3862  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 2.7737  Validation loss = 1.3860  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 2.7735  Validation loss = 1.3852  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 2.7731  Validation loss = 1.3838  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 2.7725  Validation loss = 1.3828  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 2.7721  Validation loss = 1.3797  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 2.7713  Validation loss = 1.3792  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 2.7706  Validation loss = 1.3772  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 2.7698  Validation loss = 1.3748  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 2.7693  Validation loss = 1.3739  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 2.7690  Validation loss = 1.3731  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 2.7685  Validation loss = 1.3714  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 2.7680  Validation loss = 1.3690  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 2.7683  Validation loss = 1.3677  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 2.7672  Validation loss = 1.3668  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 2.7667  Validation loss = 1.3651  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 2.7666  Validation loss = 1.3654  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 2.7661  Validation loss = 1.3648  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 2.7655  Validation loss = 1.3623  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 2.7654  Validation loss = 1.3604  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 2.7647  Validation loss = 1.3592  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 2.7660  Validation loss = 1.3581  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 2.7655  Validation loss = 1.3570  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 2.7644  Validation loss = 1.3561  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 2.7665  Validation loss = 1.3553  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 2.7662  Validation loss = 1.3556  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 2.7663  Validation loss = 1.3531  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 2.7643  Validation loss = 1.3531  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 2.7642  Validation loss = 1.3525  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 2.7623  Validation loss = 1.3527  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 2.7652  Validation loss = 1.3530  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 2.7619  Validation loss = 1.3503  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 2.7620  Validation loss = 1.3480  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 2.7615  Validation loss = 1.3480  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 2.7663  Validation loss = 1.3516  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 2.7637  Validation loss = 1.3510  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 2.7622  Validation loss = 1.3505  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 2.7616  Validation loss = 1.3472  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 2.7611  Validation loss = 1.3455  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 2.7604  Validation loss = 1.3441  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 2.7600  Validation loss = 1.3438  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 2.7598  Validation loss = 1.3440  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 2.7592  Validation loss = 1.3393  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 2.7584  Validation loss = 1.3385  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 2.7569  Validation loss = 1.3361  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 2.7564  Validation loss = 1.3336  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 2.7554  Validation loss = 1.3320  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 2.7547  Validation loss = 1.3314  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 2.7539  Validation loss = 1.3291  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 2.7536  Validation loss = 1.3291  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 2.7522  Validation loss = 1.3281  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 2.7513  Validation loss = 1.3248  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 2.7505  Validation loss = 1.3226  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 2.7499  Validation loss = 1.3201  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 2.7493  Validation loss = 1.3196  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 2.7487  Validation loss = 1.3184  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 2.7478  Validation loss = 1.3146  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 2.7475  Validation loss = 1.3148  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 2.7471  Validation loss = 1.3140  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 2.7480  Validation loss = 1.3151  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 2.7474  Validation loss = 1.3154  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 2.7463  Validation loss = 1.3136  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 2.7454  Validation loss = 1.3113  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 2.7448  Validation loss = 1.3084  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 2.7452  Validation loss = 1.3096  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 2.7443  Validation loss = 1.3070  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 2.7434  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 2.7431  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 2.7423  Validation loss = 1.3018  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 2.7418  Validation loss = 1.2998  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 2.7413  Validation loss = 1.2981  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 2.7407  Validation loss = 1.2977  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 2.7401  Validation loss = 1.2956  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 2.7400  Validation loss = 1.2938  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 2.7410  Validation loss = 1.2896  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 2.7396  Validation loss = 1.2897  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 2.7409  Validation loss = 1.2889  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 2.7405  Validation loss = 1.2877  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 2.7394  Validation loss = 1.2883  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 2.7388  Validation loss = 1.2873  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 2.7400  Validation loss = 1.2835  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 2.7373  Validation loss = 1.2824  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 2.7351  Validation loss = 1.2840  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 2.7345  Validation loss = 1.2826  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 2.7342  Validation loss = 1.2819  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 2.7336  Validation loss = 1.2785  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 2.7339  Validation loss = 1.2758  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 2.7331  Validation loss = 1.2755  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 2.7327  Validation loss = 1.2738  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 2.7320  Validation loss = 1.2721  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 2.7314  Validation loss = 1.2690  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 2.7311  Validation loss = 1.2690  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 2.7304  Validation loss = 1.2677  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 2.7297  Validation loss = 1.2659  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 2.7289  Validation loss = 1.2640  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 2.7286  Validation loss = 1.2637  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 2.7283  Validation loss = 1.2636  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 2.7279  Validation loss = 1.2604  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 2.7278  Validation loss = 1.2579  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 2.7274  Validation loss = 1.2560  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 2.7265  Validation loss = 1.2565  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 2.7262  Validation loss = 1.2556  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 2.7251  Validation loss = 1.2534  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 2.7240  Validation loss = 1.2520  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 2.7237  Validation loss = 1.2516  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 2.7230  Validation loss = 1.2519  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 2.7223  Validation loss = 1.2481  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 2.7221  Validation loss = 1.2491  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 2.7218  Validation loss = 1.2486  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 2.7213  Validation loss = 1.2469  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 2.7209  Validation loss = 1.2428  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 2.7201  Validation loss = 1.2432  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 2.7195  Validation loss = 1.2412  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 2.7190  Validation loss = 1.2390  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 2.7185  Validation loss = 1.2380  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 2.7187  Validation loss = 1.2363  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 2.7177  Validation loss = 1.2354  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 2.7173  Validation loss = 1.2357  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 2.7163  Validation loss = 1.2309  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 2.7158  Validation loss = 1.2313  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 2.7153  Validation loss = 1.2321  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 2.7167  Validation loss = 1.2305  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 2.7193  Validation loss = 1.2280  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 2.7147  Validation loss = 1.2275  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 2.7193  Validation loss = 1.2282  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 2.7179  Validation loss = 1.2271  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 2.7169  Validation loss = 1.2270  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 2.7162  Validation loss = 1.2242  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 2.7158  Validation loss = 1.2193  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 2.7138  Validation loss = 1.2199  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 2.7137  Validation loss = 1.2188  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 2.7132  Validation loss = 1.2191  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 2.7120  Validation loss = 1.2179  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 2.7115  Validation loss = 1.2158  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 2.7105  Validation loss = 1.2147  \n",
      "\n",
      "Fold: 20  Epoch: 236  Training loss = 2.7097  Validation loss = 1.2147  \n",
      "\n",
      "Fold: 20  Epoch: 237  Training loss = 2.7091  Validation loss = 1.2122  \n",
      "\n",
      "Fold: 20  Epoch: 238  Training loss = 2.7087  Validation loss = 1.2105  \n",
      "\n",
      "Fold: 20  Epoch: 239  Training loss = 2.7079  Validation loss = 1.2092  \n",
      "\n",
      "Fold: 20  Epoch: 240  Training loss = 2.7072  Validation loss = 1.2077  \n",
      "\n",
      "Fold: 20  Epoch: 241  Training loss = 2.7064  Validation loss = 1.2046  \n",
      "\n",
      "Fold: 20  Epoch: 242  Training loss = 2.7060  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 20  Epoch: 243  Training loss = 2.7056  Validation loss = 1.2005  \n",
      "\n",
      "Fold: 20  Epoch: 244  Training loss = 2.7053  Validation loss = 1.2011  \n",
      "\n",
      "Fold: 20  Epoch: 245  Training loss = 2.7047  Validation loss = 1.1995  \n",
      "\n",
      "Fold: 20  Epoch: 246  Training loss = 2.7043  Validation loss = 1.1968  \n",
      "\n",
      "Fold: 20  Epoch: 247  Training loss = 2.7031  Validation loss = 1.1945  \n",
      "\n",
      "Fold: 20  Epoch: 248  Training loss = 2.7031  Validation loss = 1.1947  \n",
      "\n",
      "Fold: 20  Epoch: 249  Training loss = 2.7044  Validation loss = 1.1910  \n",
      "\n",
      "Fold: 20  Epoch: 250  Training loss = 2.7025  Validation loss = 1.1904  \n",
      "\n",
      "Fold: 20  Epoch: 251  Training loss = 2.7017  Validation loss = 1.1881  \n",
      "\n",
      "Fold: 20  Epoch: 252  Training loss = 2.7029  Validation loss = 1.1857  \n",
      "\n",
      "Fold: 20  Epoch: 253  Training loss = 2.7019  Validation loss = 1.1865  \n",
      "\n",
      "Fold: 20  Epoch: 254  Training loss = 2.7010  Validation loss = 1.1858  \n",
      "\n",
      "Fold: 20  Epoch: 255  Training loss = 2.7001  Validation loss = 1.1864  \n",
      "\n",
      "Fold: 20  Epoch: 256  Training loss = 2.6999  Validation loss = 1.1846  \n",
      "\n",
      "Fold: 20  Epoch: 257  Training loss = 2.6994  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 20  Epoch: 258  Training loss = 2.6985  Validation loss = 1.1816  \n",
      "\n",
      "Fold: 20  Epoch: 259  Training loss = 2.6986  Validation loss = 1.1826  \n",
      "\n",
      "Fold: 20  Epoch: 260  Training loss = 2.6992  Validation loss = 1.1836  \n",
      "\n",
      "Fold: 20  Epoch: 261  Training loss = 2.6994  Validation loss = 1.1818  \n",
      "\n",
      "Fold: 20  Epoch: 262  Training loss = 2.7019  Validation loss = 1.1816  \n",
      "\n",
      "Fold: 20  Epoch: 263  Training loss = 2.6992  Validation loss = 1.1800  \n",
      "\n",
      "Fold: 20  Epoch: 264  Training loss = 2.6974  Validation loss = 1.1778  \n",
      "\n",
      "Fold: 20  Epoch: 265  Training loss = 2.6972  Validation loss = 1.1771  \n",
      "\n",
      "Fold: 20  Epoch: 266  Training loss = 2.6966  Validation loss = 1.1765  \n",
      "\n",
      "Fold: 20  Epoch: 267  Training loss = 2.6965  Validation loss = 1.1754  \n",
      "\n",
      "Fold: 20  Epoch: 268  Training loss = 2.6951  Validation loss = 1.1731  \n",
      "\n",
      "Fold: 20  Epoch: 269  Training loss = 2.6937  Validation loss = 1.1731  \n",
      "\n",
      "Fold: 20  Epoch: 270  Training loss = 2.6941  Validation loss = 1.1713  \n",
      "\n",
      "Fold: 20  Epoch: 271  Training loss = 2.6951  Validation loss = 1.1722  \n",
      "\n",
      "Fold: 20  Epoch: 272  Training loss = 2.6924  Validation loss = 1.1694  \n",
      "\n",
      "Fold: 20  Epoch: 273  Training loss = 2.6937  Validation loss = 1.1670  \n",
      "\n",
      "Fold: 20  Epoch: 274  Training loss = 2.6919  Validation loss = 1.1651  \n",
      "\n",
      "Fold: 20  Epoch: 275  Training loss = 2.6918  Validation loss = 1.1635  \n",
      "\n",
      "Fold: 20  Epoch: 276  Training loss = 2.6921  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 20  Epoch: 277  Training loss = 2.6911  Validation loss = 1.1617  \n",
      "\n",
      "Fold: 20  Epoch: 278  Training loss = 2.6906  Validation loss = 1.1598  \n",
      "\n",
      "Fold: 20  Epoch: 279  Training loss = 2.6891  Validation loss = 1.1590  \n",
      "\n",
      "Fold: 20  Epoch: 280  Training loss = 2.6905  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 20  Epoch: 281  Training loss = 2.6885  Validation loss = 1.1543  \n",
      "\n",
      "Fold: 20  Epoch: 282  Training loss = 2.6880  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 20  Epoch: 283  Training loss = 2.6886  Validation loss = 1.1495  \n",
      "\n",
      "Fold: 20  Epoch: 284  Training loss = 2.6880  Validation loss = 1.1484  \n",
      "\n",
      "Fold: 20  Epoch: 285  Training loss = 2.6877  Validation loss = 1.1478  \n",
      "\n",
      "Fold: 20  Epoch: 286  Training loss = 2.6861  Validation loss = 1.1472  \n",
      "\n",
      "Fold: 20  Epoch: 287  Training loss = 2.6858  Validation loss = 1.1461  \n",
      "\n",
      "Fold: 20  Epoch: 288  Training loss = 2.6855  Validation loss = 1.1456  \n",
      "\n",
      "Fold: 20  Epoch: 289  Training loss = 2.6851  Validation loss = 1.1437  \n",
      "\n",
      "Fold: 20  Epoch: 290  Training loss = 2.6851  Validation loss = 1.1426  \n",
      "\n",
      "Fold: 20  Epoch: 291  Training loss = 2.6849  Validation loss = 1.1423  \n",
      "\n",
      "Fold: 20  Epoch: 292  Training loss = 2.6844  Validation loss = 1.1405  \n",
      "\n",
      "Fold: 20  Epoch: 293  Training loss = 2.6845  Validation loss = 1.1373  \n",
      "\n",
      "Fold: 20  Epoch: 294  Training loss = 2.6846  Validation loss = 1.1374  \n",
      "\n",
      "Fold: 20  Epoch: 295  Training loss = 2.6840  Validation loss = 1.1363  \n",
      "\n",
      "Fold: 20  Epoch: 296  Training loss = 2.6831  Validation loss = 1.1355  \n",
      "\n",
      "Fold: 20  Epoch: 297  Training loss = 2.6826  Validation loss = 1.1347  \n",
      "\n",
      "Fold: 20  Epoch: 298  Training loss = 2.6820  Validation loss = 1.1340  \n",
      "\n",
      "Fold: 20  Epoch: 299  Training loss = 2.6823  Validation loss = 1.1348  \n",
      "\n",
      "Fold: 20  Epoch: 300  Training loss = 2.6816  Validation loss = 1.1310  \n",
      "\n",
      "Fold: 20  Epoch: 301  Training loss = 2.6811  Validation loss = 1.1308  \n",
      "\n",
      "Fold: 20  Epoch: 302  Training loss = 2.6813  Validation loss = 1.1285  \n",
      "\n",
      "Fold: 20  Epoch: 303  Training loss = 2.6802  Validation loss = 1.1260  \n",
      "\n",
      "Fold: 20  Epoch: 304  Training loss = 2.6798  Validation loss = 1.1257  \n",
      "\n",
      "Fold: 20  Epoch: 305  Training loss = 2.6794  Validation loss = 1.1246  \n",
      "\n",
      "Fold: 20  Epoch: 306  Training loss = 2.6793  Validation loss = 1.1247  \n",
      "\n",
      "Fold: 20  Epoch: 307  Training loss = 2.6789  Validation loss = 1.1239  \n",
      "\n",
      "Fold: 20  Epoch: 308  Training loss = 2.6787  Validation loss = 1.1229  \n",
      "\n",
      "Fold: 20  Epoch: 309  Training loss = 2.6778  Validation loss = 1.1198  \n",
      "\n",
      "Fold: 20  Epoch: 310  Training loss = 2.6774  Validation loss = 1.1189  \n",
      "\n",
      "Fold: 20  Epoch: 311  Training loss = 2.6773  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 20  Epoch: 312  Training loss = 2.6778  Validation loss = 1.1167  \n",
      "\n",
      "Fold: 20  Epoch: 313  Training loss = 2.6784  Validation loss = 1.1158  \n",
      "\n",
      "Fold: 20  Epoch: 314  Training loss = 2.6777  Validation loss = 1.1143  \n",
      "\n",
      "Fold: 20  Epoch: 315  Training loss = 2.6780  Validation loss = 1.1129  \n",
      "\n",
      "Fold: 20  Epoch: 316  Training loss = 2.6794  Validation loss = 1.1132  \n",
      "\n",
      "Fold: 20  Epoch: 317  Training loss = 2.6764  Validation loss = 1.1116  \n",
      "\n",
      "Fold: 20  Epoch: 318  Training loss = 2.6759  Validation loss = 1.1111  \n",
      "\n",
      "Fold: 20  Epoch: 319  Training loss = 2.6750  Validation loss = 1.1103  \n",
      "\n",
      "Fold: 20  Epoch: 320  Training loss = 2.6737  Validation loss = 1.1095  \n",
      "\n",
      "Fold: 20  Epoch: 321  Training loss = 2.6731  Validation loss = 1.1085  \n",
      "\n",
      "Fold: 20  Epoch: 322  Training loss = 2.6728  Validation loss = 1.1080  \n",
      "\n",
      "Fold: 20  Epoch: 323  Training loss = 2.6725  Validation loss = 1.1063  \n",
      "\n",
      "Fold: 20  Epoch: 324  Training loss = 2.6722  Validation loss = 1.1055  \n",
      "\n",
      "Fold: 20  Epoch: 325  Training loss = 2.6723  Validation loss = 1.1063  \n",
      "\n",
      "Fold: 20  Epoch: 326  Training loss = 2.6719  Validation loss = 1.1052  \n",
      "\n",
      "Fold: 20  Epoch: 327  Training loss = 2.6717  Validation loss = 1.1052  \n",
      "\n",
      "Fold: 20  Epoch: 328  Training loss = 2.6713  Validation loss = 1.1033  \n",
      "\n",
      "Fold: 20  Epoch: 329  Training loss = 2.6707  Validation loss = 1.1040  \n",
      "\n",
      "Fold: 20  Epoch: 330  Training loss = 2.6704  Validation loss = 1.1018  \n",
      "\n",
      "Fold: 20  Epoch: 331  Training loss = 2.6700  Validation loss = 1.0998  \n",
      "\n",
      "Fold: 20  Epoch: 332  Training loss = 2.6704  Validation loss = 1.0989  \n",
      "\n",
      "Fold: 20  Epoch: 333  Training loss = 2.6691  Validation loss = 1.0983  \n",
      "\n",
      "Fold: 20  Epoch: 334  Training loss = 2.6687  Validation loss = 1.0951  \n",
      "\n",
      "Fold: 20  Epoch: 335  Training loss = 2.6681  Validation loss = 1.0952  \n",
      "\n",
      "Fold: 20  Epoch: 336  Training loss = 2.6677  Validation loss = 1.0947  \n",
      "\n",
      "Fold: 20  Epoch: 337  Training loss = 2.6673  Validation loss = 1.0956  \n",
      "\n",
      "Fold: 20  Epoch: 338  Training loss = 2.6669  Validation loss = 1.0958  \n",
      "\n",
      "Fold: 20  Epoch: 339  Training loss = 2.6670  Validation loss = 1.0920  \n",
      "\n",
      "Fold: 20  Epoch: 340  Training loss = 2.6669  Validation loss = 1.0906  \n",
      "\n",
      "Fold: 20  Epoch: 341  Training loss = 2.6659  Validation loss = 1.0910  \n",
      "\n",
      "Fold: 20  Epoch: 342  Training loss = 2.6659  Validation loss = 1.0912  \n",
      "\n",
      "Fold: 20  Epoch: 343  Training loss = 2.6651  Validation loss = 1.0924  \n",
      "\n",
      "Fold: 20  Epoch: 344  Training loss = 2.6643  Validation loss = 1.0907  \n",
      "\n",
      "Fold: 20  Epoch: 345  Training loss = 2.6646  Validation loss = 1.0894  \n",
      "\n",
      "Fold: 20  Epoch: 346  Training loss = 2.6659  Validation loss = 1.0884  \n",
      "\n",
      "Fold: 20  Epoch: 347  Training loss = 2.6643  Validation loss = 1.0877  \n",
      "\n",
      "Fold: 20  Epoch: 348  Training loss = 2.6628  Validation loss = 1.0869  \n",
      "\n",
      "Fold: 20  Epoch: 349  Training loss = 2.6626  Validation loss = 1.0859  \n",
      "\n",
      "Fold: 20  Epoch: 350  Training loss = 2.6625  Validation loss = 1.0839  \n",
      "\n",
      "Fold: 20  Epoch: 351  Training loss = 2.6620  Validation loss = 1.0826  \n",
      "\n",
      "Fold: 20  Epoch: 352  Training loss = 2.6617  Validation loss = 1.0842  \n",
      "\n",
      "Fold: 20  Epoch: 353  Training loss = 2.6616  Validation loss = 1.0819  \n",
      "\n",
      "Fold: 20  Epoch: 354  Training loss = 2.6617  Validation loss = 1.0803  \n",
      "\n",
      "Fold: 20  Epoch: 355  Training loss = 2.6606  Validation loss = 1.0805  \n",
      "\n",
      "Fold: 20  Epoch: 356  Training loss = 2.6599  Validation loss = 1.0802  \n",
      "\n",
      "Fold: 20  Epoch: 357  Training loss = 2.6605  Validation loss = 1.0788  \n",
      "\n",
      "Fold: 20  Epoch: 358  Training loss = 2.6607  Validation loss = 1.0778  \n",
      "\n",
      "Fold: 20  Epoch: 359  Training loss = 2.6597  Validation loss = 1.0784  \n",
      "\n",
      "Fold: 20  Epoch: 360  Training loss = 2.6598  Validation loss = 1.0765  \n",
      "\n",
      "Fold: 20  Epoch: 361  Training loss = 2.6591  Validation loss = 1.0756  \n",
      "\n",
      "Fold: 20  Epoch: 362  Training loss = 2.6589  Validation loss = 1.0742  \n",
      "\n",
      "Fold: 20  Epoch: 363  Training loss = 2.6576  Validation loss = 1.0728  \n",
      "\n",
      "Fold: 20  Epoch: 364  Training loss = 2.6570  Validation loss = 1.0731  \n",
      "\n",
      "Fold: 20  Epoch: 365  Training loss = 2.6563  Validation loss = 1.0727  \n",
      "\n",
      "Fold: 20  Epoch: 366  Training loss = 2.6567  Validation loss = 1.0748  \n",
      "\n",
      "Fold: 20  Epoch: 367  Training loss = 2.6560  Validation loss = 1.0736  \n",
      "\n",
      "Fold: 20  Epoch: 368  Training loss = 2.6560  Validation loss = 1.0735  \n",
      "\n",
      "Fold: 20  Epoch: 369  Training loss = 2.6555  Validation loss = 1.0741  \n",
      "\n",
      "Fold: 20  Epoch: 370  Training loss = 2.6547  Validation loss = 1.0728  \n",
      "\n",
      "Fold: 20  Epoch: 371  Training loss = 2.6552  Validation loss = 1.0712  \n",
      "\n",
      "Fold: 20  Epoch: 372  Training loss = 2.6540  Validation loss = 1.0718  \n",
      "\n",
      "Fold: 20  Epoch: 373  Training loss = 2.6535  Validation loss = 1.0716  \n",
      "\n",
      "Fold: 20  Epoch: 374  Training loss = 2.6543  Validation loss = 1.0691  \n",
      "\n",
      "Fold: 20  Epoch: 375  Training loss = 2.6537  Validation loss = 1.0682  \n",
      "\n",
      "Fold: 20  Epoch: 376  Training loss = 2.6530  Validation loss = 1.0653  \n",
      "\n",
      "Fold: 20  Epoch: 377  Training loss = 2.6525  Validation loss = 1.0638  \n",
      "\n",
      "Fold: 20  Epoch: 378  Training loss = 2.6530  Validation loss = 1.0632  \n",
      "\n",
      "Fold: 20  Epoch: 379  Training loss = 2.6521  Validation loss = 1.0626  \n",
      "\n",
      "Fold: 20  Epoch: 380  Training loss = 2.6525  Validation loss = 1.0630  \n",
      "\n",
      "Fold: 20  Epoch: 381  Training loss = 2.6524  Validation loss = 1.0631  \n",
      "\n",
      "Fold: 20  Epoch: 382  Training loss = 2.6504  Validation loss = 1.0615  \n",
      "\n",
      "Fold: 20  Epoch: 383  Training loss = 2.6500  Validation loss = 1.0601  \n",
      "\n",
      "Fold: 20  Epoch: 384  Training loss = 2.6497  Validation loss = 1.0592  \n",
      "\n",
      "Fold: 20  Epoch: 385  Training loss = 2.6493  Validation loss = 1.0582  \n",
      "\n",
      "Fold: 20  Epoch: 386  Training loss = 2.6488  Validation loss = 1.0578  \n",
      "\n",
      "Fold: 20  Epoch: 387  Training loss = 2.6485  Validation loss = 1.0573  \n",
      "\n",
      "Fold: 20  Epoch: 388  Training loss = 2.6480  Validation loss = 1.0566  \n",
      "\n",
      "Fold: 20  Epoch: 389  Training loss = 2.6475  Validation loss = 1.0556  \n",
      "\n",
      "Fold: 20  Epoch: 390  Training loss = 2.6473  Validation loss = 1.0542  \n",
      "\n",
      "Fold: 20  Epoch: 391  Training loss = 2.6468  Validation loss = 1.0543  \n",
      "\n",
      "Fold: 20  Epoch: 392  Training loss = 2.6467  Validation loss = 1.0519  \n",
      "\n",
      "Fold: 20  Epoch: 393  Training loss = 2.6460  Validation loss = 1.0520  \n",
      "\n",
      "Fold: 20  Epoch: 394  Training loss = 2.6459  Validation loss = 1.0526  \n",
      "\n",
      "Fold: 20  Epoch: 395  Training loss = 2.6456  Validation loss = 1.0505  \n",
      "\n",
      "Fold: 20  Epoch: 396  Training loss = 2.6452  Validation loss = 1.0511  \n",
      "\n",
      "Fold: 20  Epoch: 397  Training loss = 2.6450  Validation loss = 1.0495  \n",
      "\n",
      "Fold: 20  Epoch: 398  Training loss = 2.6445  Validation loss = 1.0483  \n",
      "\n",
      "Fold: 20  Epoch: 399  Training loss = 2.6442  Validation loss = 1.0487  \n",
      "\n",
      "Fold: 20  Epoch: 400  Training loss = 2.6442  Validation loss = 1.0471  \n",
      "\n",
      "Fold: 20  Epoch: 401  Training loss = 2.6446  Validation loss = 1.0466  \n",
      "\n",
      "Fold: 20  Epoch: 402  Training loss = 2.6431  Validation loss = 1.0443  \n",
      "\n",
      "Fold: 20  Epoch: 403  Training loss = 2.6426  Validation loss = 1.0425  \n",
      "\n",
      "Fold: 20  Epoch: 404  Training loss = 2.6425  Validation loss = 1.0419  \n",
      "\n",
      "Fold: 20  Epoch: 405  Training loss = 2.6420  Validation loss = 1.0410  \n",
      "\n",
      "Fold: 20  Epoch: 406  Training loss = 2.6422  Validation loss = 1.0407  \n",
      "\n",
      "Fold: 20  Epoch: 407  Training loss = 2.6411  Validation loss = 1.0398  \n",
      "\n",
      "Fold: 20  Epoch: 408  Training loss = 2.6432  Validation loss = 1.0403  \n",
      "\n",
      "Fold: 20  Epoch: 409  Training loss = 2.6410  Validation loss = 1.0396  \n",
      "\n",
      "Fold: 20  Epoch: 410  Training loss = 2.6407  Validation loss = 1.0379  \n",
      "\n",
      "Fold: 20  Epoch: 411  Training loss = 2.6409  Validation loss = 1.0381  \n",
      "\n",
      "Fold: 20  Epoch: 412  Training loss = 2.6397  Validation loss = 1.0396  \n",
      "\n",
      "Fold: 20  Epoch: 413  Training loss = 2.6400  Validation loss = 1.0393  \n",
      "\n",
      "Fold: 20  Epoch: 414  Training loss = 2.6393  Validation loss = 1.0395  \n",
      "\n",
      "Fold: 20  Epoch: 415  Training loss = 2.6386  Validation loss = 1.0396  \n",
      "\n",
      "Fold: 20  Epoch: 416  Training loss = 2.6384  Validation loss = 1.0377  \n",
      "\n",
      "Fold: 20  Epoch: 417  Training loss = 2.6379  Validation loss = 1.0376  \n",
      "\n",
      "Fold: 20  Epoch: 418  Training loss = 2.6374  Validation loss = 1.0384  \n",
      "\n",
      "Fold: 20  Epoch: 419  Training loss = 2.6372  Validation loss = 1.0392  \n",
      "\n",
      "Fold: 20  Epoch: 420  Training loss = 2.6366  Validation loss = 1.0375  \n",
      "\n",
      "Fold: 20  Epoch: 421  Training loss = 2.6365  Validation loss = 1.0369  \n",
      "\n",
      "Fold: 20  Epoch: 422  Training loss = 2.6356  Validation loss = 1.0374  \n",
      "\n",
      "Fold: 20  Epoch: 423  Training loss = 2.6352  Validation loss = 1.0337  \n",
      "\n",
      "Fold: 20  Epoch: 424  Training loss = 2.6352  Validation loss = 1.0328  \n",
      "\n",
      "Fold: 20  Epoch: 425  Training loss = 2.6348  Validation loss = 1.0328  \n",
      "\n",
      "Fold: 20  Epoch: 426  Training loss = 2.6343  Validation loss = 1.0321  \n",
      "\n",
      "Fold: 20  Epoch: 427  Training loss = 2.6341  Validation loss = 1.0310  \n",
      "\n",
      "Fold: 20  Epoch: 428  Training loss = 2.6340  Validation loss = 1.0323  \n",
      "\n",
      "Fold: 20  Epoch: 429  Training loss = 2.6337  Validation loss = 1.0318  \n",
      "\n",
      "Fold: 20  Epoch: 430  Training loss = 2.6331  Validation loss = 1.0293  \n",
      "\n",
      "Fold: 20  Epoch: 431  Training loss = 2.6336  Validation loss = 1.0287  \n",
      "\n",
      "Fold: 20  Epoch: 432  Training loss = 2.6322  Validation loss = 1.0296  \n",
      "\n",
      "Fold: 20  Epoch: 433  Training loss = 2.6320  Validation loss = 1.0302  \n",
      "\n",
      "Fold: 20  Epoch: 434  Training loss = 2.6325  Validation loss = 1.0280  \n",
      "\n",
      "Fold: 20  Epoch: 435  Training loss = 2.6325  Validation loss = 1.0285  \n",
      "\n",
      "Fold: 20  Epoch: 436  Training loss = 2.6321  Validation loss = 1.0287  \n",
      "\n",
      "Fold: 20  Epoch: 437  Training loss = 2.6309  Validation loss = 1.0284  \n",
      "\n",
      "Fold: 20  Epoch: 438  Training loss = 2.6301  Validation loss = 1.0277  \n",
      "\n",
      "Fold: 20  Epoch: 439  Training loss = 2.6303  Validation loss = 1.0273  \n",
      "\n",
      "Fold: 20  Epoch: 440  Training loss = 2.6296  Validation loss = 1.0270  \n",
      "\n",
      "Fold: 20  Epoch: 441  Training loss = 2.6291  Validation loss = 1.0277  \n",
      "\n",
      "Fold: 20  Epoch: 442  Training loss = 2.6290  Validation loss = 1.0281  \n",
      "\n",
      "Fold: 20  Epoch: 443  Training loss = 2.6287  Validation loss = 1.0274  \n",
      "\n",
      "Fold: 20  Epoch: 444  Training loss = 2.6284  Validation loss = 1.0278  \n",
      "\n",
      "Fold: 20  Epoch: 445  Training loss = 2.6280  Validation loss = 1.0279  \n",
      "\n",
      "Fold: 20  Epoch: 446  Training loss = 2.6279  Validation loss = 1.0273  \n",
      "\n",
      "Fold: 20  Epoch: 447  Training loss = 2.6284  Validation loss = 1.0267  \n",
      "\n",
      "Fold: 20  Epoch: 448  Training loss = 2.6275  Validation loss = 1.0263  \n",
      "\n",
      "Fold: 20  Epoch: 449  Training loss = 2.6265  Validation loss = 1.0248  \n",
      "\n",
      "Fold: 20  Epoch: 450  Training loss = 2.6260  Validation loss = 1.0234  \n",
      "\n",
      "Fold: 20  Epoch: 451  Training loss = 2.6256  Validation loss = 1.0235  \n",
      "\n",
      "Fold: 20  Epoch: 452  Training loss = 2.6261  Validation loss = 1.0211  \n",
      "\n",
      "Fold: 20  Epoch: 453  Training loss = 2.6248  Validation loss = 1.0203  \n",
      "\n",
      "Fold: 20  Epoch: 454  Training loss = 2.6251  Validation loss = 1.0203  \n",
      "\n",
      "Fold: 20  Epoch: 455  Training loss = 2.6241  Validation loss = 1.0192  \n",
      "\n",
      "Fold: 20  Epoch: 456  Training loss = 2.6253  Validation loss = 1.0180  \n",
      "\n",
      "Fold: 20  Epoch: 457  Training loss = 2.6241  Validation loss = 1.0173  \n",
      "\n",
      "Fold: 20  Epoch: 458  Training loss = 2.6241  Validation loss = 1.0162  \n",
      "\n",
      "Fold: 20  Epoch: 459  Training loss = 2.6237  Validation loss = 1.0153  \n",
      "\n",
      "Fold: 20  Epoch: 460  Training loss = 2.6219  Validation loss = 1.0148  \n",
      "\n",
      "Fold: 20  Epoch: 461  Training loss = 2.6213  Validation loss = 1.0161  \n",
      "\n",
      "Fold: 20  Epoch: 462  Training loss = 2.6212  Validation loss = 1.0157  \n",
      "\n",
      "Fold: 20  Epoch: 463  Training loss = 2.6206  Validation loss = 1.0172  \n",
      "\n",
      "Fold: 20  Epoch: 464  Training loss = 2.6201  Validation loss = 1.0164  \n",
      "\n",
      "Fold: 20  Epoch: 465  Training loss = 2.6201  Validation loss = 1.0165  \n",
      "\n",
      "Fold: 20  Epoch: 466  Training loss = 2.6217  Validation loss = 1.0166  \n",
      "\n",
      "Fold: 20  Epoch: 467  Training loss = 2.6199  Validation loss = 1.0157  \n",
      "\n",
      "Fold: 20  Epoch: 468  Training loss = 2.6198  Validation loss = 1.0153  \n",
      "\n",
      "Fold: 20  Epoch: 469  Training loss = 2.6187  Validation loss = 1.0128  \n",
      "\n",
      "Fold: 20  Epoch: 470  Training loss = 2.6181  Validation loss = 1.0122  \n",
      "\n",
      "Fold: 20  Epoch: 471  Training loss = 2.6180  Validation loss = 1.0117  \n",
      "\n",
      "Fold: 20  Epoch: 472  Training loss = 2.6176  Validation loss = 1.0119  \n",
      "\n",
      "Fold: 20  Epoch: 473  Training loss = 2.6170  Validation loss = 1.0119  \n",
      "\n",
      "Fold: 20  Epoch: 474  Training loss = 2.6206  Validation loss = 1.0115  \n",
      "\n",
      "Fold: 20  Epoch: 475  Training loss = 2.6183  Validation loss = 1.0137  \n",
      "\n",
      "Fold: 20  Epoch: 476  Training loss = 2.6177  Validation loss = 1.0149  \n",
      "\n",
      "Fold: 20  Epoch: 477  Training loss = 2.6175  Validation loss = 1.0148  \n",
      "\n",
      "Fold: 20  Epoch: 478  Training loss = 2.6165  Validation loss = 1.0117  \n",
      "\n",
      "Fold: 20  Epoch: 479  Training loss = 2.6161  Validation loss = 1.0113  \n",
      "\n",
      "Fold: 20  Epoch: 480  Training loss = 2.6161  Validation loss = 1.0082  \n",
      "\n",
      "Fold: 20  Epoch: 481  Training loss = 2.6159  Validation loss = 1.0081  \n",
      "\n",
      "Fold: 20  Epoch: 482  Training loss = 2.6150  Validation loss = 1.0070  \n",
      "\n",
      "Fold: 20  Epoch: 483  Training loss = 2.6138  Validation loss = 1.0043  \n",
      "\n",
      "Fold: 20  Epoch: 484  Training loss = 2.6130  Validation loss = 1.0036  \n",
      "\n",
      "Fold: 20  Epoch: 485  Training loss = 2.6123  Validation loss = 1.0025  \n",
      "\n",
      "Fold: 20  Epoch: 486  Training loss = 2.6117  Validation loss = 1.0019  \n",
      "\n",
      "Fold: 20  Epoch: 487  Training loss = 2.6112  Validation loss = 1.0024  \n",
      "\n",
      "Fold: 20  Epoch: 488  Training loss = 2.6113  Validation loss = 1.0013  \n",
      "\n",
      "Fold: 20  Epoch: 489  Training loss = 2.6113  Validation loss = 1.0005  \n",
      "\n",
      "Fold: 20  Epoch: 490  Training loss = 2.6103  Validation loss = 1.0005  \n",
      "\n",
      "Fold: 20  Epoch: 491  Training loss = 2.6091  Validation loss = 1.0002  \n",
      "\n",
      "Fold: 20  Epoch: 492  Training loss = 2.6093  Validation loss = 1.0001  \n",
      "\n",
      "Fold: 20  Epoch: 493  Training loss = 2.6085  Validation loss = 1.0002  \n",
      "\n",
      "Fold: 20  Epoch: 494  Training loss = 2.6083  Validation loss = 1.0003  \n",
      "\n",
      "Fold: 20  Epoch: 495  Training loss = 2.6088  Validation loss = 0.9995  \n",
      "\n",
      "Fold: 20  Epoch: 496  Training loss = 2.6075  Validation loss = 0.9991  \n",
      "\n",
      "Fold: 20  Epoch: 497  Training loss = 2.6072  Validation loss = 0.9965  \n",
      "\n",
      "Fold: 20  Epoch: 498  Training loss = 2.6090  Validation loss = 0.9940  \n",
      "\n",
      "Fold: 20  Epoch: 499  Training loss = 2.6093  Validation loss = 0.9958  \n",
      "\n",
      "Fold: 20  Epoch: 500  Training loss = 2.6062  Validation loss = 0.9970  \n",
      "\n",
      "Fold: 20  Epoch: 501  Training loss = 2.6065  Validation loss = 0.9962  \n",
      "\n",
      "Fold: 20  Epoch: 502  Training loss = 2.6054  Validation loss = 0.9974  \n",
      "\n",
      "Fold: 20  Epoch: 503  Training loss = 2.6047  Validation loss = 0.9970  \n",
      "\n",
      "Fold: 20  Epoch: 504  Training loss = 2.6049  Validation loss = 0.9963  \n",
      "\n",
      "Fold: 20  Epoch: 505  Training loss = 2.6041  Validation loss = 0.9976  \n",
      "\n",
      "Fold: 20  Epoch: 506  Training loss = 2.6037  Validation loss = 0.9957  \n",
      "\n",
      "Fold: 20  Epoch: 507  Training loss = 2.6036  Validation loss = 0.9965  \n",
      "\n",
      "Fold: 20  Epoch: 508  Training loss = 2.6041  Validation loss = 0.9976  \n",
      "\n",
      "Fold: 20  Epoch: 509  Training loss = 2.6043  Validation loss = 0.9962  \n",
      "\n",
      "Fold: 20  Epoch: 510  Training loss = 2.6060  Validation loss = 0.9954  \n",
      "\n",
      "Fold: 20  Epoch: 511  Training loss = 2.6082  Validation loss = 0.9951  \n",
      "\n",
      "Fold: 20  Epoch: 512  Training loss = 2.6061  Validation loss = 0.9934  \n",
      "\n",
      "Fold: 20  Epoch: 513  Training loss = 2.6066  Validation loss = 0.9912  \n",
      "\n",
      "Fold: 20  Epoch: 514  Training loss = 2.6016  Validation loss = 0.9897  \n",
      "\n",
      "Fold: 20  Epoch: 515  Training loss = 2.6010  Validation loss = 0.9890  \n",
      "\n",
      "Fold: 20  Epoch: 516  Training loss = 2.6009  Validation loss = 0.9884  \n",
      "\n",
      "Fold: 20  Epoch: 517  Training loss = 2.6021  Validation loss = 0.9877  \n",
      "\n",
      "Fold: 20  Epoch: 518  Training loss = 2.6005  Validation loss = 0.9885  \n",
      "\n",
      "Fold: 20  Epoch: 519  Training loss = 2.6001  Validation loss = 0.9883  \n",
      "\n",
      "Fold: 20  Epoch: 520  Training loss = 2.6007  Validation loss = 0.9895  \n",
      "\n",
      "Fold: 20  Epoch: 521  Training loss = 2.6012  Validation loss = 0.9879  \n",
      "\n",
      "Fold: 20  Epoch: 522  Training loss = 2.5998  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 20  Epoch: 523  Training loss = 2.5998  Validation loss = 0.9855  \n",
      "\n",
      "Fold: 20  Epoch: 524  Training loss = 2.5997  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 20  Epoch: 525  Training loss = 2.6007  Validation loss = 0.9857  \n",
      "\n",
      "Fold: 20  Epoch: 526  Training loss = 2.5993  Validation loss = 0.9872  \n",
      "\n",
      "Fold: 20  Epoch: 527  Training loss = 2.5998  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 20  Epoch: 528  Training loss = 2.5967  Validation loss = 0.9856  \n",
      "\n",
      "Fold: 20  Epoch: 529  Training loss = 2.5962  Validation loss = 0.9851  \n",
      "\n",
      "Fold: 20  Epoch: 530  Training loss = 2.5967  Validation loss = 0.9841  \n",
      "\n",
      "Fold: 20  Epoch: 531  Training loss = 2.5952  Validation loss = 0.9828  \n",
      "\n",
      "Fold: 20  Epoch: 532  Training loss = 2.5955  Validation loss = 0.9827  \n",
      "\n",
      "Fold: 20  Epoch: 533  Training loss = 2.5944  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 20  Epoch: 534  Training loss = 2.5947  Validation loss = 0.9831  \n",
      "\n",
      "Fold: 20  Epoch: 535  Training loss = 2.5940  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 20  Epoch: 536  Training loss = 2.5985  Validation loss = 0.9807  \n",
      "\n",
      "Fold: 20  Epoch: 537  Training loss = 2.5949  Validation loss = 0.9837  \n",
      "\n",
      "Fold: 20  Epoch: 538  Training loss = 2.5938  Validation loss = 0.9847  \n",
      "\n",
      "Fold: 20  Epoch: 539  Training loss = 2.5931  Validation loss = 0.9848  \n",
      "\n",
      "Fold: 20  Epoch: 540  Training loss = 2.5925  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 20  Epoch: 541  Training loss = 2.5916  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 20  Epoch: 542  Training loss = 2.5930  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 20  Epoch: 543  Training loss = 2.5906  Validation loss = 0.9824  \n",
      "\n",
      "Fold: 20  Epoch: 544  Training loss = 2.5906  Validation loss = 0.9820  \n",
      "\n",
      "Fold: 20  Epoch: 545  Training loss = 2.5900  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 546  Training loss = 2.5909  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 547  Training loss = 2.5899  Validation loss = 0.9810  \n",
      "\n",
      "Fold: 20  Epoch: 548  Training loss = 2.5893  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 20  Epoch: 549  Training loss = 2.5913  Validation loss = 0.9779  \n",
      "\n",
      "Fold: 20  Epoch: 550  Training loss = 2.5896  Validation loss = 0.9764  \n",
      "\n",
      "Fold: 20  Epoch: 551  Training loss = 2.5882  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 20  Epoch: 552  Training loss = 2.5875  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 20  Epoch: 553  Training loss = 2.5869  Validation loss = 0.9785  \n",
      "\n",
      "Fold: 20  Epoch: 554  Training loss = 2.5870  Validation loss = 0.9788  \n",
      "\n",
      "Fold: 20  Epoch: 555  Training loss = 2.5872  Validation loss = 0.9777  \n",
      "\n",
      "Fold: 20  Epoch: 556  Training loss = 2.5875  Validation loss = 0.9769  \n",
      "\n",
      "Fold: 20  Epoch: 557  Training loss = 2.5879  Validation loss = 0.9777  \n",
      "\n",
      "Fold: 20  Epoch: 558  Training loss = 2.5885  Validation loss = 0.9773  \n",
      "\n",
      "Fold: 20  Epoch: 559  Training loss = 2.5881  Validation loss = 0.9753  \n",
      "\n",
      "Fold: 20  Epoch: 560  Training loss = 2.5879  Validation loss = 0.9746  \n",
      "\n",
      "Fold: 20  Epoch: 561  Training loss = 2.5857  Validation loss = 0.9747  \n",
      "\n",
      "Fold: 20  Epoch: 562  Training loss = 2.5865  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 20  Epoch: 563  Training loss = 2.5856  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 20  Epoch: 564  Training loss = 2.5838  Validation loss = 0.9719  \n",
      "\n",
      "Fold: 20  Epoch: 565  Training loss = 2.5834  Validation loss = 0.9731  \n",
      "\n",
      "Fold: 20  Epoch: 566  Training loss = 2.5830  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 20  Epoch: 567  Training loss = 2.5837  Validation loss = 0.9736  \n",
      "\n",
      "Fold: 20  Epoch: 568  Training loss = 2.5824  Validation loss = 0.9726  \n",
      "\n",
      "Fold: 20  Epoch: 569  Training loss = 2.5821  Validation loss = 0.9701  \n",
      "\n",
      "Fold: 20  Epoch: 570  Training loss = 2.5811  Validation loss = 0.9690  \n",
      "\n",
      "Fold: 20  Epoch: 571  Training loss = 2.5808  Validation loss = 0.9692  \n",
      "\n",
      "Fold: 20  Epoch: 572  Training loss = 2.5804  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 20  Epoch: 573  Training loss = 2.5801  Validation loss = 0.9676  \n",
      "\n",
      "Fold: 20  Epoch: 574  Training loss = 2.5802  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 20  Epoch: 575  Training loss = 2.5818  Validation loss = 0.9694  \n",
      "\n",
      "Fold: 20  Epoch: 576  Training loss = 2.5798  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 20  Epoch: 577  Training loss = 2.5804  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 578  Training loss = 2.5799  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 579  Training loss = 2.5784  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 20  Epoch: 580  Training loss = 2.5772  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 581  Training loss = 2.5786  Validation loss = 0.9637  \n",
      "\n",
      "Fold: 20  Epoch: 582  Training loss = 2.5783  Validation loss = 0.9625  \n",
      "\n",
      "Fold: 20  Epoch: 583  Training loss = 2.5787  Validation loss = 0.9614  \n",
      "\n",
      "Fold: 20  Epoch: 584  Training loss = 2.5761  Validation loss = 0.9616  \n",
      "\n",
      "Fold: 20  Epoch: 585  Training loss = 2.5762  Validation loss = 0.9633  \n",
      "\n",
      "Fold: 20  Epoch: 586  Training loss = 2.5792  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 587  Training loss = 2.5756  Validation loss = 0.9619  \n",
      "\n",
      "Fold: 20  Epoch: 588  Training loss = 2.5746  Validation loss = 0.9612  \n",
      "\n",
      "Fold: 20  Epoch: 589  Training loss = 2.5747  Validation loss = 0.9626  \n",
      "\n",
      "Fold: 20  Epoch: 590  Training loss = 2.5743  Validation loss = 0.9612  \n",
      "\n",
      "Fold: 20  Epoch: 591  Training loss = 2.5745  Validation loss = 0.9613  \n",
      "\n",
      "Fold: 20  Epoch: 592  Training loss = 2.5741  Validation loss = 0.9587  \n",
      "\n",
      "Fold: 20  Epoch: 593  Training loss = 2.5734  Validation loss = 0.9599  \n",
      "\n",
      "Fold: 20  Epoch: 594  Training loss = 2.5728  Validation loss = 0.9581  \n",
      "\n",
      "Fold: 20  Epoch: 595  Training loss = 2.5727  Validation loss = 0.9567  \n",
      "\n",
      "Fold: 20  Epoch: 596  Training loss = 2.5738  Validation loss = 0.9557  \n",
      "\n",
      "Fold: 20  Epoch: 597  Training loss = 2.5727  Validation loss = 0.9563  \n",
      "\n",
      "Fold: 20  Epoch: 598  Training loss = 2.5729  Validation loss = 0.9583  \n",
      "\n",
      "Fold: 20  Epoch: 599  Training loss = 2.5729  Validation loss = 0.9590  \n",
      "\n",
      "Fold: 20  Epoch: 600  Training loss = 2.5748  Validation loss = 0.9550  \n",
      "\n",
      "Fold: 20  Epoch: 601  Training loss = 2.5743  Validation loss = 0.9550  \n",
      "\n",
      "Fold: 20  Epoch: 602  Training loss = 2.5730  Validation loss = 0.9567  \n",
      "\n",
      "Fold: 20  Epoch: 603  Training loss = 2.5731  Validation loss = 0.9568  \n",
      "\n",
      "Fold: 20  Epoch: 604  Training loss = 2.5723  Validation loss = 0.9576  \n",
      "\n",
      "Fold: 20  Epoch: 605  Training loss = 2.5724  Validation loss = 0.9576  \n",
      "\n",
      "Fold: 20  Epoch: 606  Training loss = 2.5738  Validation loss = 0.9588  \n",
      "\n",
      "Fold: 20  Epoch: 607  Training loss = 2.5758  Validation loss = 0.9574  \n",
      "\n",
      "Fold: 20  Epoch: 608  Training loss = 2.5760  Validation loss = 0.9575  \n",
      "\n",
      "Fold: 20  Epoch: 609  Training loss = 2.5737  Validation loss = 0.9559  \n",
      "\n",
      "Fold: 20  Epoch: 610  Training loss = 2.5724  Validation loss = 0.9548  \n",
      "\n",
      "Fold: 20  Epoch: 611  Training loss = 2.5700  Validation loss = 0.9558  \n",
      "\n",
      "Fold: 20  Epoch: 612  Training loss = 2.5701  Validation loss = 0.9555  \n",
      "\n",
      "Fold: 20  Epoch: 613  Training loss = 2.5712  Validation loss = 0.9553  \n",
      "\n",
      "Fold: 20  Epoch: 614  Training loss = 2.5716  Validation loss = 0.9560  \n",
      "\n",
      "Fold: 20  Epoch: 615  Training loss = 2.5693  Validation loss = 0.9565  \n",
      "\n",
      "Fold: 20  Epoch: 616  Training loss = 2.5682  Validation loss = 0.9575  \n",
      "\n",
      "Fold: 20  Epoch: 617  Training loss = 2.5667  Validation loss = 0.9578  \n",
      "\n",
      "Fold: 20  Epoch: 618  Training loss = 2.5656  Validation loss = 0.9564  \n",
      "\n",
      "Fold: 20  Epoch: 619  Training loss = 2.5647  Validation loss = 0.9567  \n",
      "\n",
      "Fold: 20  Epoch: 620  Training loss = 2.5650  Validation loss = 0.9565  \n",
      "\n",
      "Fold: 20  Epoch: 621  Training loss = 2.5635  Validation loss = 0.9562  \n",
      "\n",
      "Fold: 20  Epoch: 622  Training loss = 2.5633  Validation loss = 0.9573  \n",
      "\n",
      "Fold: 20  Epoch: 623  Training loss = 2.5635  Validation loss = 0.9577  \n",
      "\n",
      "Fold: 20  Epoch: 624  Training loss = 2.5635  Validation loss = 0.9571  \n",
      "\n",
      "Fold: 20  Epoch: 625  Training loss = 2.5622  Validation loss = 0.9581  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 610  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.5420  Validation loss = 3.8957  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.5416  Validation loss = 3.8923  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.5415  Validation loss = 3.9229  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.5422  Validation loss = 3.9398  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.5405  Validation loss = 3.9166  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.5397  Validation loss = 3.9008  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.5404  Validation loss = 3.9018  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.5406  Validation loss = 3.9293  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.5398  Validation loss = 3.8600  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.5393  Validation loss = 3.8631  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.5381  Validation loss = 3.8738  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.5379  Validation loss = 3.8574  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 2.5376  Validation loss = 3.8609  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 2.5369  Validation loss = 3.8612  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 2.5362  Validation loss = 3.8580  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 2.5373  Validation loss = 3.8267  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 2.5352  Validation loss = 3.8638  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 2.5348  Validation loss = 3.8698  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 2.5374  Validation loss = 3.8315  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 2.5342  Validation loss = 3.8559  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 2.5340  Validation loss = 3.8463  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 2.5333  Validation loss = 3.8654  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 2.5329  Validation loss = 3.8482  \n",
      "\n",
      "Fold: 21  Epoch: 24  Training loss = 2.5326  Validation loss = 3.8910  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 16  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.6192  Validation loss = 2.9930  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.6160  Validation loss = 2.9020  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.6159  Validation loss = 2.8955  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.6142  Validation loss = 2.8990  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.6127  Validation loss = 2.8260  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.6125  Validation loss = 2.8182  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 2.6126  Validation loss = 2.8537  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.6112  Validation loss = 2.7838  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.6153  Validation loss = 2.7192  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.6311  Validation loss = 2.8733  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.6248  Validation loss = 2.8274  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.6226  Validation loss = 2.8032  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.6203  Validation loss = 2.6951  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 2.6174  Validation loss = 2.6800  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 2.6159  Validation loss = 2.6336  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 2.6149  Validation loss = 2.7452  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 2.6122  Validation loss = 2.7323  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 2.6096  Validation loss = 2.8236  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 2.6079  Validation loss = 2.8707  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 2.6060  Validation loss = 2.6284  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 2.6058  Validation loss = 2.7037  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 2.6057  Validation loss = 2.6456  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 2.6052  Validation loss = 2.6354  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 2.6031  Validation loss = 2.5846  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 2.6031  Validation loss = 2.6900  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 2.6038  Validation loss = 2.8027  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 2.6034  Validation loss = 2.7274  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 2.6006  Validation loss = 2.8229  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 2.6017  Validation loss = 2.9606  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 24  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.6420  Validation loss = 2.1776  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.6382  Validation loss = 2.1763  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.6472  Validation loss = 2.4208  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.6327  Validation loss = 2.1388  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.6358  Validation loss = 2.2711  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.6048  Validation loss = 1.6384  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.6064  Validation loss = 1.6713  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.6006  Validation loss = 1.7419  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.6016  Validation loss = 1.4621  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.6010  Validation loss = 1.4972  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.5949  Validation loss = 1.5944  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.5898  Validation loss = 1.5780  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.5861  Validation loss = 1.5641  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 2.6033  Validation loss = 1.5744  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 2.5907  Validation loss = 1.8347  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 2.5896  Validation loss = 1.7007  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 2.5893  Validation loss = 1.6696  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 2.5864  Validation loss = 1.6649  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 2.5858  Validation loss = 1.7722  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 2.5844  Validation loss = 1.7569  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 2.5825  Validation loss = 1.8171  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 2.5783  Validation loss = 1.7657  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 2.5755  Validation loss = 1.7315  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 2.5734  Validation loss = 1.6159  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 2.5733  Validation loss = 1.5230  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 2.5757  Validation loss = 1.7441  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 2.5734  Validation loss = 1.6387  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 2.5718  Validation loss = 1.7161  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 2.5705  Validation loss = 1.4704  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 2.5680  Validation loss = 1.5694  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 2.5662  Validation loss = 1.6266  \n",
      "\n",
      "Fold: 23  Epoch: 32  Training loss = 2.5642  Validation loss = 1.5926  \n",
      "\n",
      "Fold: 23  Epoch: 33  Training loss = 2.5816  Validation loss = 1.9475  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 9  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.5933  Validation loss = 1.0740  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.5896  Validation loss = 1.0578  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.5882  Validation loss = 1.0576  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.5841  Validation loss = 1.0581  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.5800  Validation loss = 1.0333  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.5761  Validation loss = 1.0077  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.5695  Validation loss = 1.0315  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.5610  Validation loss = 1.0344  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.5635  Validation loss = 1.0462  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.5599  Validation loss = 1.0254  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.5584  Validation loss = 1.0566  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.5696  Validation loss = 1.0540  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.5579  Validation loss = 1.0488  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.5547  Validation loss = 1.0298  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.5561  Validation loss = 0.9927  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.5557  Validation loss = 0.9905  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.5499  Validation loss = 1.0042  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.5465  Validation loss = 1.0742  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 16  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.4840  Validation loss = 2.5273  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.4831  Validation loss = 2.5265  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.4839  Validation loss = 2.5391  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.4976  Validation loss = 2.5330  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.4814  Validation loss = 2.5351  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.4903  Validation loss = 2.5412  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.4834  Validation loss = 2.5561  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.4784  Validation loss = 2.5338  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.4770  Validation loss = 2.5233  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.4877  Validation loss = 2.6261  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.4861  Validation loss = 2.6181  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.4768  Validation loss = 2.5445  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.4747  Validation loss = 2.5317  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.4737  Validation loss = 2.5322  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.4779  Validation loss = 2.5685  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.4715  Validation loss = 2.5273  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 2.4719  Validation loss = 2.5367  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 2.4866  Validation loss = 2.6155  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 2.4819  Validation loss = 2.5962  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 2.4760  Validation loss = 2.5725  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 2.4710  Validation loss = 2.5440  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 2.4727  Validation loss = 2.5640  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 2.4686  Validation loss = 2.5387  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 2.4691  Validation loss = 2.5343  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 2.4774  Validation loss = 2.5302  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 2.4773  Validation loss = 2.5513  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 2.4761  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 2.4756  Validation loss = 2.5590  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 2.4690  Validation loss = 2.5173  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 2.4696  Validation loss = 2.5316  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 2.4687  Validation loss = 2.5425  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 2.4672  Validation loss = 2.5151  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 2.4662  Validation loss = 2.5156  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 2.4652  Validation loss = 2.5108  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 2.4647  Validation loss = 2.5279  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 2.4632  Validation loss = 2.5293  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 2.4641  Validation loss = 2.5641  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 34  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.4515  Validation loss = 3.1147  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.4531  Validation loss = 3.1300  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.4464  Validation loss = 3.2413  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.4443  Validation loss = 3.2080  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.4453  Validation loss = 3.1640  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.4424  Validation loss = 3.2684  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.4410  Validation loss = 3.2560  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.4529  Validation loss = 3.1380  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.4403  Validation loss = 3.1236  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.4390  Validation loss = 3.1359  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.4384  Validation loss = 3.0993  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.4453  Validation loss = 3.2930  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.4419  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.4387  Validation loss = 3.2482  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.4475  Validation loss = 3.3567  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 2.4490  Validation loss = 3.0405  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 2.4406  Validation loss = 3.2952  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 2.4373  Validation loss = 3.2337  \n",
      "\n",
      "Fold: 26  Epoch: 19  Training loss = 2.4390  Validation loss = 3.3047  \n",
      "\n",
      "Fold: 26  Epoch: 20  Training loss = 2.4354  Validation loss = 3.2309  \n",
      "\n",
      "Fold: 26  Epoch: 21  Training loss = 2.4360  Validation loss = 3.2431  \n",
      "\n",
      "Fold: 26  Epoch: 22  Training loss = 2.4453  Validation loss = 3.3727  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 16  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.4673  Validation loss = 0.5561  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.4592  Validation loss = 0.4970  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.4566  Validation loss = 0.5159  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.4541  Validation loss = 0.5105  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.4519  Validation loss = 0.5166  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.4474  Validation loss = 0.5073  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.4303  Validation loss = 0.5135  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.4471  Validation loss = 0.5384  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.4297  Validation loss = 0.5325  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.4273  Validation loss = 0.5465  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.4270  Validation loss = 0.5414  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.4403  Validation loss = 0.4954  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.4437  Validation loss = 0.5247  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.4663  Validation loss = 0.5623  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.4466  Validation loss = 0.5349  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.4533  Validation loss = 0.5332  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.4228  Validation loss = 0.5208  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.4240  Validation loss = 0.5113  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.4218  Validation loss = 0.5405  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.4594  Validation loss = 0.5158  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 2.4208  Validation loss = 0.5162  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 2.4268  Validation loss = 0.5452  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 2.4327  Validation loss = 0.5347  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 2.4251  Validation loss = 0.5333  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 2.4265  Validation loss = 0.5405  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 2.4267  Validation loss = 0.5285  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 2.4510  Validation loss = 0.5485  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 2.4197  Validation loss = 0.4825  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 2.4337  Validation loss = 0.4733  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 2.4325  Validation loss = 0.5212  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 2.4178  Validation loss = 0.5098  \n",
      "\n",
      "Fold: 27  Epoch: 32  Training loss = 2.4226  Validation loss = 0.5307  \n",
      "\n",
      "Fold: 27  Epoch: 33  Training loss = 2.4327  Validation loss = 0.5297  \n",
      "\n",
      "Fold: 27  Epoch: 34  Training loss = 2.4383  Validation loss = 0.5273  \n",
      "\n",
      "Fold: 27  Epoch: 35  Training loss = 2.4152  Validation loss = 0.5190  \n",
      "\n",
      "Fold: 27  Epoch: 36  Training loss = 2.4205  Validation loss = 0.5273  \n",
      "\n",
      "Fold: 27  Epoch: 37  Training loss = 2.4156  Validation loss = 0.4919  \n",
      "\n",
      "Fold: 27  Epoch: 38  Training loss = 2.4205  Validation loss = 0.5052  \n",
      "\n",
      "Fold: 27  Epoch: 39  Training loss = 2.4203  Validation loss = 0.4904  \n",
      "\n",
      "Fold: 27  Epoch: 40  Training loss = 2.4299  Validation loss = 0.4820  \n",
      "\n",
      "Fold: 27  Epoch: 41  Training loss = 2.4120  Validation loss = 0.5044  \n",
      "\n",
      "Fold: 27  Epoch: 42  Training loss = 2.4827  Validation loss = 0.4622  \n",
      "\n",
      "Fold: 27  Epoch: 43  Training loss = 2.4142  Validation loss = 0.5055  \n",
      "\n",
      "Fold: 27  Epoch: 44  Training loss = 2.4338  Validation loss = 0.5528  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 42  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.3958  Validation loss = 1.2146  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.3934  Validation loss = 1.2161  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.3924  Validation loss = 1.2157  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.4077  Validation loss = 1.2131  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.4290  Validation loss = 1.2154  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.3896  Validation loss = 1.2233  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.4410  Validation loss = 1.2123  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.4011  Validation loss = 1.2142  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.3984  Validation loss = 1.2255  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.4076  Validation loss = 1.2285  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.4153  Validation loss = 1.2247  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.3967  Validation loss = 1.2164  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.3925  Validation loss = 1.2188  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.3876  Validation loss = 1.2168  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.3888  Validation loss = 1.2191  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.4025  Validation loss = 1.2230  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 2.3915  Validation loss = 1.2138  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 2.4038  Validation loss = 1.2210  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 2.3825  Validation loss = 1.2120  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 2.3873  Validation loss = 1.2200  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 2.3900  Validation loss = 1.2119  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 2.3990  Validation loss = 1.2073  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 2.3748  Validation loss = 1.2164  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 2.3863  Validation loss = 1.2215  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 2.3774  Validation loss = 1.2167  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 2.3794  Validation loss = 1.2190  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 2.3723  Validation loss = 1.2211  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 2.3698  Validation loss = 1.2176  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 2.3797  Validation loss = 1.2192  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 2.3826  Validation loss = 1.2159  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 2.3739  Validation loss = 1.2160  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 2.3868  Validation loss = 1.2127  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 2.3826  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 2.3686  Validation loss = 1.2084  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 2.3651  Validation loss = 1.2087  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 2.3652  Validation loss = 1.2092  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 2.3683  Validation loss = 1.2085  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 2.3693  Validation loss = 1.2068  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 2.3753  Validation loss = 1.2061  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 2.3773  Validation loss = 1.2106  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 2.3861  Validation loss = 1.2043  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 2.3682  Validation loss = 1.2061  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 2.3692  Validation loss = 1.2065  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 2.3634  Validation loss = 1.2044  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 2.3636  Validation loss = 1.2060  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 2.3669  Validation loss = 1.2029  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 2.3670  Validation loss = 1.2054  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 2.4057  Validation loss = 1.2113  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 46  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.3456  Validation loss = 1.2152  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.3482  Validation loss = 1.2156  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.3455  Validation loss = 1.2148  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.3418  Validation loss = 1.2167  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.3494  Validation loss = 1.2179  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.3394  Validation loss = 1.2171  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.3414  Validation loss = 1.2165  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.3350  Validation loss = 1.2167  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.3349  Validation loss = 1.2127  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.3290  Validation loss = 1.2113  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.3442  Validation loss = 1.2104  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.3322  Validation loss = 1.2071  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.3279  Validation loss = 1.2073  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.3259  Validation loss = 1.2056  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.3256  Validation loss = 1.2045  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.3250  Validation loss = 1.2014  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 2.3332  Validation loss = 1.1992  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 2.3306  Validation loss = 1.1974  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 2.3436  Validation loss = 1.1991  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.3437  Validation loss = 1.1988  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 2.3258  Validation loss = 1.1991  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 2.3251  Validation loss = 1.1978  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 2.3237  Validation loss = 1.1971  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 2.3231  Validation loss = 1.1955  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 2.3215  Validation loss = 1.1956  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 2.3200  Validation loss = 1.1914  \n",
      "\n",
      "Fold: 29  Epoch: 27  Training loss = 2.3177  Validation loss = 1.1890  \n",
      "\n",
      "Fold: 29  Epoch: 28  Training loss = 2.3200  Validation loss = 1.1874  \n",
      "\n",
      "Fold: 29  Epoch: 29  Training loss = 2.3360  Validation loss = 1.1867  \n",
      "\n",
      "Fold: 29  Epoch: 30  Training loss = 2.3355  Validation loss = 1.1840  \n",
      "\n",
      "Fold: 29  Epoch: 31  Training loss = 2.3152  Validation loss = 1.1849  \n",
      "\n",
      "Fold: 29  Epoch: 32  Training loss = 2.3141  Validation loss = 1.1859  \n",
      "\n",
      "Fold: 29  Epoch: 33  Training loss = 2.3351  Validation loss = 1.1848  \n",
      "\n",
      "Fold: 29  Epoch: 34  Training loss = 2.3158  Validation loss = 1.1836  \n",
      "\n",
      "Fold: 29  Epoch: 35  Training loss = 2.3117  Validation loss = 1.1801  \n",
      "\n",
      "Fold: 29  Epoch: 36  Training loss = 2.3362  Validation loss = 1.1817  \n",
      "\n",
      "Fold: 29  Epoch: 37  Training loss = 2.3168  Validation loss = 1.1773  \n",
      "\n",
      "Fold: 29  Epoch: 38  Training loss = 2.3185  Validation loss = 1.1756  \n",
      "\n",
      "Fold: 29  Epoch: 39  Training loss = 2.3353  Validation loss = 1.1737  \n",
      "\n",
      "Fold: 29  Epoch: 40  Training loss = 2.3125  Validation loss = 1.1711  \n",
      "\n",
      "Fold: 29  Epoch: 41  Training loss = 2.3094  Validation loss = 1.1682  \n",
      "\n",
      "Fold: 29  Epoch: 42  Training loss = 2.3222  Validation loss = 1.1675  \n",
      "\n",
      "Fold: 29  Epoch: 43  Training loss = 2.3242  Validation loss = 1.1669  \n",
      "\n",
      "Fold: 29  Epoch: 44  Training loss = 2.3086  Validation loss = 1.1678  \n",
      "\n",
      "Fold: 29  Epoch: 45  Training loss = 2.3201  Validation loss = 1.1675  \n",
      "\n",
      "Fold: 29  Epoch: 46  Training loss = 2.3315  Validation loss = 1.1674  \n",
      "\n",
      "Fold: 29  Epoch: 47  Training loss = 2.3122  Validation loss = 1.1652  \n",
      "\n",
      "Fold: 29  Epoch: 48  Training loss = 2.3054  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 29  Epoch: 49  Training loss = 2.3041  Validation loss = 1.1623  \n",
      "\n",
      "Fold: 29  Epoch: 50  Training loss = 2.3030  Validation loss = 1.1637  \n",
      "\n",
      "Fold: 29  Epoch: 51  Training loss = 2.3018  Validation loss = 1.1632  \n",
      "\n",
      "Fold: 29  Epoch: 52  Training loss = 2.3236  Validation loss = 1.1642  \n",
      "\n",
      "Fold: 29  Epoch: 53  Training loss = 2.3135  Validation loss = 1.1645  \n",
      "\n",
      "Fold: 29  Epoch: 54  Training loss = 2.3107  Validation loss = 1.1624  \n",
      "\n",
      "Fold: 29  Epoch: 55  Training loss = 2.3020  Validation loss = 1.1637  \n",
      "\n",
      "Fold: 29  Epoch: 56  Training loss = 2.3009  Validation loss = 1.1643  \n",
      "\n",
      "Fold: 29  Epoch: 57  Training loss = 2.3121  Validation loss = 1.1639  \n",
      "\n",
      "Fold: 29  Epoch: 58  Training loss = 2.3012  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 29  Epoch: 59  Training loss = 2.3015  Validation loss = 1.1597  \n",
      "\n",
      "Fold: 29  Epoch: 60  Training loss = 2.3159  Validation loss = 1.1588  \n",
      "\n",
      "Fold: 29  Epoch: 61  Training loss = 2.2964  Validation loss = 1.1565  \n",
      "\n",
      "Fold: 29  Epoch: 62  Training loss = 2.2967  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 29  Epoch: 63  Training loss = 2.3032  Validation loss = 1.1572  \n",
      "\n",
      "Fold: 29  Epoch: 64  Training loss = 2.2961  Validation loss = 1.1556  \n",
      "\n",
      "Fold: 29  Epoch: 65  Training loss = 2.3070  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 29  Epoch: 66  Training loss = 2.2962  Validation loss = 1.1559  \n",
      "\n",
      "Fold: 29  Epoch: 67  Training loss = 2.2954  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 29  Epoch: 68  Training loss = 2.2945  Validation loss = 1.1571  \n",
      "\n",
      "Fold: 29  Epoch: 69  Training loss = 2.3044  Validation loss = 1.1579  \n",
      "\n",
      "Fold: 29  Epoch: 70  Training loss = 2.3143  Validation loss = 1.1583  \n",
      "\n",
      "Fold: 29  Epoch: 71  Training loss = 2.3106  Validation loss = 1.1543  \n",
      "\n",
      "Fold: 29  Epoch: 72  Training loss = 2.2984  Validation loss = 1.1512  \n",
      "\n",
      "Fold: 29  Epoch: 73  Training loss = 2.2935  Validation loss = 1.1513  \n",
      "\n",
      "Fold: 29  Epoch: 74  Training loss = 2.3024  Validation loss = 1.1499  \n",
      "\n",
      "Fold: 29  Epoch: 75  Training loss = 2.2918  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 29  Epoch: 76  Training loss = 2.2933  Validation loss = 1.1555  \n",
      "\n",
      "Fold: 29  Epoch: 77  Training loss = 2.2951  Validation loss = 1.1529  \n",
      "\n",
      "Fold: 29  Epoch: 78  Training loss = 2.2905  Validation loss = 1.1514  \n",
      "\n",
      "Fold: 29  Epoch: 79  Training loss = 2.3086  Validation loss = 1.1479  \n",
      "\n",
      "Fold: 29  Epoch: 80  Training loss = 2.3150  Validation loss = 1.1473  \n",
      "\n",
      "Fold: 29  Epoch: 81  Training loss = 2.3016  Validation loss = 1.1443  \n",
      "\n",
      "Fold: 29  Epoch: 82  Training loss = 2.2881  Validation loss = 1.1434  \n",
      "\n",
      "Fold: 29  Epoch: 83  Training loss = 2.2958  Validation loss = 1.1419  \n",
      "\n",
      "Fold: 29  Epoch: 84  Training loss = 2.2966  Validation loss = 1.1399  \n",
      "\n",
      "Fold: 29  Epoch: 85  Training loss = 2.3050  Validation loss = 1.1387  \n",
      "\n",
      "Fold: 29  Epoch: 86  Training loss = 2.3303  Validation loss = 1.1338  \n",
      "\n",
      "Fold: 29  Epoch: 87  Training loss = 2.2824  Validation loss = 1.1339  \n",
      "\n",
      "Fold: 29  Epoch: 88  Training loss = 2.2823  Validation loss = 1.1310  \n",
      "\n",
      "Fold: 29  Epoch: 89  Training loss = 2.2965  Validation loss = 1.1356  \n",
      "\n",
      "Fold: 29  Epoch: 90  Training loss = 2.2963  Validation loss = 1.1357  \n",
      "\n",
      "Fold: 29  Epoch: 91  Training loss = 2.3020  Validation loss = 1.1363  \n",
      "\n",
      "Fold: 29  Epoch: 92  Training loss = 2.3123  Validation loss = 1.1338  \n",
      "\n",
      "Fold: 29  Epoch: 93  Training loss = 2.2881  Validation loss = 1.1307  \n",
      "\n",
      "Fold: 29  Epoch: 94  Training loss = 2.2823  Validation loss = 1.1308  \n",
      "\n",
      "Fold: 29  Epoch: 95  Training loss = 2.2798  Validation loss = 1.1313  \n",
      "\n",
      "Fold: 29  Epoch: 96  Training loss = 2.2881  Validation loss = 1.1329  \n",
      "\n",
      "Fold: 29  Epoch: 97  Training loss = 2.2857  Validation loss = 1.1294  \n",
      "\n",
      "Fold: 29  Epoch: 98  Training loss = 2.2769  Validation loss = 1.1278  \n",
      "\n",
      "Fold: 29  Epoch: 99  Training loss = 2.2866  Validation loss = 1.1262  \n",
      "\n",
      "Fold: 29  Epoch: 100  Training loss = 2.2760  Validation loss = 1.1240  \n",
      "\n",
      "Fold: 29  Epoch: 101  Training loss = 2.2760  Validation loss = 1.1248  \n",
      "\n",
      "Fold: 29  Epoch: 102  Training loss = 2.3042  Validation loss = 1.1231  \n",
      "\n",
      "Fold: 29  Epoch: 103  Training loss = 2.2750  Validation loss = 1.1206  \n",
      "\n",
      "Fold: 29  Epoch: 104  Training loss = 2.2858  Validation loss = 1.1192  \n",
      "\n",
      "Fold: 29  Epoch: 105  Training loss = 2.2950  Validation loss = 1.1197  \n",
      "\n",
      "Fold: 29  Epoch: 106  Training loss = 2.2733  Validation loss = 1.1211  \n",
      "\n",
      "Fold: 29  Epoch: 107  Training loss = 2.3325  Validation loss = 1.1184  \n",
      "\n",
      "Fold: 29  Epoch: 108  Training loss = 2.2726  Validation loss = 1.1132  \n",
      "\n",
      "Fold: 29  Epoch: 109  Training loss = 2.2841  Validation loss = 1.1150  \n",
      "\n",
      "Fold: 29  Epoch: 110  Training loss = 2.2778  Validation loss = 1.1150  \n",
      "\n",
      "Fold: 29  Epoch: 111  Training loss = 2.2731  Validation loss = 1.1129  \n",
      "\n",
      "Fold: 29  Epoch: 112  Training loss = 2.2737  Validation loss = 1.1087  \n",
      "\n",
      "Fold: 29  Epoch: 113  Training loss = 2.2677  Validation loss = 1.1093  \n",
      "\n",
      "Fold: 29  Epoch: 114  Training loss = 2.2768  Validation loss = 1.1108  \n",
      "\n",
      "Fold: 29  Epoch: 115  Training loss = 2.2779  Validation loss = 1.1054  \n",
      "\n",
      "Fold: 29  Epoch: 116  Training loss = 2.2895  Validation loss = 1.1037  \n",
      "\n",
      "Fold: 29  Epoch: 117  Training loss = 2.2812  Validation loss = 1.1035  \n",
      "\n",
      "Fold: 29  Epoch: 118  Training loss = 2.2875  Validation loss = 1.1013  \n",
      "\n",
      "Fold: 29  Epoch: 119  Training loss = 2.2668  Validation loss = 1.1008  \n",
      "\n",
      "Fold: 29  Epoch: 120  Training loss = 2.2748  Validation loss = 1.1031  \n",
      "\n",
      "Fold: 29  Epoch: 121  Training loss = 2.2630  Validation loss = 1.1026  \n",
      "\n",
      "Fold: 29  Epoch: 122  Training loss = 2.2736  Validation loss = 1.1011  \n",
      "\n",
      "Fold: 29  Epoch: 123  Training loss = 2.2731  Validation loss = 1.1008  \n",
      "\n",
      "Fold: 29  Epoch: 124  Training loss = 2.2719  Validation loss = 1.0985  \n",
      "\n",
      "Fold: 29  Epoch: 125  Training loss = 2.2667  Validation loss = 1.0987  \n",
      "\n",
      "Fold: 29  Epoch: 126  Training loss = 2.2634  Validation loss = 1.1003  \n",
      "\n",
      "Fold: 29  Epoch: 127  Training loss = 2.2991  Validation loss = 1.0985  \n",
      "\n",
      "Fold: 29  Epoch: 128  Training loss = 2.2756  Validation loss = 1.1000  \n",
      "\n",
      "Fold: 29  Epoch: 129  Training loss = 2.2618  Validation loss = 1.1001  \n",
      "\n",
      "Fold: 29  Epoch: 130  Training loss = 2.2593  Validation loss = 1.0975  \n",
      "\n",
      "Fold: 29  Epoch: 131  Training loss = 2.2613  Validation loss = 1.0988  \n",
      "\n",
      "Fold: 29  Epoch: 132  Training loss = 2.2584  Validation loss = 1.0992  \n",
      "\n",
      "Fold: 29  Epoch: 133  Training loss = 2.2760  Validation loss = 1.0969  \n",
      "\n",
      "Fold: 29  Epoch: 134  Training loss = 2.2569  Validation loss = 1.0947  \n",
      "\n",
      "Fold: 29  Epoch: 135  Training loss = 2.2537  Validation loss = 1.0922  \n",
      "\n",
      "Fold: 29  Epoch: 136  Training loss = 2.2532  Validation loss = 1.0898  \n",
      "\n",
      "Fold: 29  Epoch: 137  Training loss = 2.2560  Validation loss = 1.0905  \n",
      "\n",
      "Fold: 29  Epoch: 138  Training loss = 2.2646  Validation loss = 1.0855  \n",
      "\n",
      "Fold: 29  Epoch: 139  Training loss = 2.2587  Validation loss = 1.0837  \n",
      "\n",
      "Fold: 29  Epoch: 140  Training loss = 2.2524  Validation loss = 1.0881  \n",
      "\n",
      "Fold: 29  Epoch: 141  Training loss = 2.2607  Validation loss = 1.0870  \n",
      "\n",
      "Fold: 29  Epoch: 142  Training loss = 2.2533  Validation loss = 1.0876  \n",
      "\n",
      "Fold: 29  Epoch: 143  Training loss = 2.2487  Validation loss = 1.0893  \n",
      "\n",
      "Fold: 29  Epoch: 144  Training loss = 2.2587  Validation loss = 1.0890  \n",
      "\n",
      "Fold: 29  Epoch: 145  Training loss = 2.2541  Validation loss = 1.0854  \n",
      "\n",
      "Fold: 29  Epoch: 146  Training loss = 2.2461  Validation loss = 1.0828  \n",
      "\n",
      "Fold: 29  Epoch: 147  Training loss = 2.2459  Validation loss = 1.0852  \n",
      "\n",
      "Fold: 29  Epoch: 148  Training loss = 2.2503  Validation loss = 1.0829  \n",
      "\n",
      "Fold: 29  Epoch: 149  Training loss = 2.2521  Validation loss = 1.0805  \n",
      "\n",
      "Fold: 29  Epoch: 150  Training loss = 2.2496  Validation loss = 1.0795  \n",
      "\n",
      "Fold: 29  Epoch: 151  Training loss = 2.2475  Validation loss = 1.0816  \n",
      "\n",
      "Fold: 29  Epoch: 152  Training loss = 2.2436  Validation loss = 1.0810  \n",
      "\n",
      "Fold: 29  Epoch: 153  Training loss = 2.2396  Validation loss = 1.0790  \n",
      "\n",
      "Fold: 29  Epoch: 154  Training loss = 2.2524  Validation loss = 1.0798  \n",
      "\n",
      "Fold: 29  Epoch: 155  Training loss = 2.2386  Validation loss = 1.0769  \n",
      "\n",
      "Fold: 29  Epoch: 156  Training loss = 2.2409  Validation loss = 1.0753  \n",
      "\n",
      "Fold: 29  Epoch: 157  Training loss = 2.2384  Validation loss = 1.0751  \n",
      "\n",
      "Fold: 29  Epoch: 158  Training loss = 2.2475  Validation loss = 1.0727  \n",
      "\n",
      "Fold: 29  Epoch: 159  Training loss = 2.2494  Validation loss = 1.0725  \n",
      "\n",
      "Fold: 29  Epoch: 160  Training loss = 2.2485  Validation loss = 1.0731  \n",
      "\n",
      "Fold: 29  Epoch: 161  Training loss = 2.2338  Validation loss = 1.0699  \n",
      "\n",
      "Fold: 29  Epoch: 162  Training loss = 2.2340  Validation loss = 1.0662  \n",
      "\n",
      "Fold: 29  Epoch: 163  Training loss = 2.2303  Validation loss = 1.0644  \n",
      "\n",
      "Fold: 29  Epoch: 164  Training loss = 2.2337  Validation loss = 1.0643  \n",
      "\n",
      "Fold: 29  Epoch: 165  Training loss = 2.2327  Validation loss = 1.0643  \n",
      "\n",
      "Fold: 29  Epoch: 166  Training loss = 2.2273  Validation loss = 1.0620  \n",
      "\n",
      "Fold: 29  Epoch: 167  Training loss = 2.2399  Validation loss = 1.0610  \n",
      "\n",
      "Fold: 29  Epoch: 168  Training loss = 2.2262  Validation loss = 1.0599  \n",
      "\n",
      "Fold: 29  Epoch: 169  Training loss = 2.2331  Validation loss = 1.0603  \n",
      "\n",
      "Fold: 29  Epoch: 170  Training loss = 2.2242  Validation loss = 1.0599  \n",
      "\n",
      "Fold: 29  Epoch: 171  Training loss = 2.2268  Validation loss = 1.0570  \n",
      "\n",
      "Fold: 29  Epoch: 172  Training loss = 2.2229  Validation loss = 1.0549  \n",
      "\n",
      "Fold: 29  Epoch: 173  Training loss = 2.2248  Validation loss = 1.0546  \n",
      "\n",
      "Fold: 29  Epoch: 174  Training loss = 2.2250  Validation loss = 1.0561  \n",
      "\n",
      "Fold: 29  Epoch: 175  Training loss = 2.2272  Validation loss = 1.0553  \n",
      "\n",
      "Fold: 29  Epoch: 176  Training loss = 2.2192  Validation loss = 1.0539  \n",
      "\n",
      "Fold: 29  Epoch: 177  Training loss = 2.2221  Validation loss = 1.0512  \n",
      "\n",
      "Fold: 29  Epoch: 178  Training loss = 2.2230  Validation loss = 1.0500  \n",
      "\n",
      "Fold: 29  Epoch: 179  Training loss = 2.2170  Validation loss = 1.0475  \n",
      "\n",
      "Fold: 29  Epoch: 180  Training loss = 2.2165  Validation loss = 1.0478  \n",
      "\n",
      "Fold: 29  Epoch: 181  Training loss = 2.2180  Validation loss = 1.0484  \n",
      "\n",
      "Fold: 29  Epoch: 182  Training loss = 2.2293  Validation loss = 1.0460  \n",
      "\n",
      "Fold: 29  Epoch: 183  Training loss = 2.2283  Validation loss = 1.0423  \n",
      "\n",
      "Fold: 29  Epoch: 184  Training loss = 2.2158  Validation loss = 1.0426  \n",
      "\n",
      "Fold: 29  Epoch: 185  Training loss = 2.2149  Validation loss = 1.0425  \n",
      "\n",
      "Fold: 29  Epoch: 186  Training loss = 2.2123  Validation loss = 1.0429  \n",
      "\n",
      "Fold: 29  Epoch: 187  Training loss = 2.2125  Validation loss = 1.0417  \n",
      "\n",
      "Fold: 29  Epoch: 188  Training loss = 2.2111  Validation loss = 1.0423  \n",
      "\n",
      "Fold: 29  Epoch: 189  Training loss = 2.2208  Validation loss = 1.0399  \n",
      "\n",
      "Fold: 29  Epoch: 190  Training loss = 2.2087  Validation loss = 1.0383  \n",
      "\n",
      "Fold: 29  Epoch: 191  Training loss = 2.2123  Validation loss = 1.0377  \n",
      "\n",
      "Fold: 29  Epoch: 192  Training loss = 2.2072  Validation loss = 1.0366  \n",
      "\n",
      "Fold: 29  Epoch: 193  Training loss = 2.2189  Validation loss = 1.0335  \n",
      "\n",
      "Fold: 29  Epoch: 194  Training loss = 2.2094  Validation loss = 1.0327  \n",
      "\n",
      "Fold: 29  Epoch: 195  Training loss = 2.2206  Validation loss = 1.0306  \n",
      "\n",
      "Fold: 29  Epoch: 196  Training loss = 2.2048  Validation loss = 1.0300  \n",
      "\n",
      "Fold: 29  Epoch: 197  Training loss = 2.2040  Validation loss = 1.0289  \n",
      "\n",
      "Fold: 29  Epoch: 198  Training loss = 2.2053  Validation loss = 1.0282  \n",
      "\n",
      "Fold: 29  Epoch: 199  Training loss = 2.2212  Validation loss = 1.0281  \n",
      "\n",
      "Fold: 29  Epoch: 200  Training loss = 2.2021  Validation loss = 1.0283  \n",
      "\n",
      "Fold: 29  Epoch: 201  Training loss = 2.2015  Validation loss = 1.0287  \n",
      "\n",
      "Fold: 29  Epoch: 202  Training loss = 2.2036  Validation loss = 1.0260  \n",
      "\n",
      "Fold: 29  Epoch: 203  Training loss = 2.2112  Validation loss = 1.0261  \n",
      "\n",
      "Fold: 29  Epoch: 204  Training loss = 2.1998  Validation loss = 1.0271  \n",
      "\n",
      "Fold: 29  Epoch: 205  Training loss = 2.2025  Validation loss = 1.0273  \n",
      "\n",
      "Fold: 29  Epoch: 206  Training loss = 2.1985  Validation loss = 1.0259  \n",
      "\n",
      "Fold: 29  Epoch: 207  Training loss = 2.1980  Validation loss = 1.0233  \n",
      "\n",
      "Fold: 29  Epoch: 208  Training loss = 2.1987  Validation loss = 1.0200  \n",
      "\n",
      "Fold: 29  Epoch: 209  Training loss = 2.2159  Validation loss = 1.0216  \n",
      "\n",
      "Fold: 29  Epoch: 210  Training loss = 2.2076  Validation loss = 1.0252  \n",
      "\n",
      "Fold: 29  Epoch: 211  Training loss = 2.1974  Validation loss = 1.0213  \n",
      "\n",
      "Fold: 29  Epoch: 212  Training loss = 2.2126  Validation loss = 1.0223  \n",
      "\n",
      "Fold: 29  Epoch: 213  Training loss = 2.1944  Validation loss = 1.0190  \n",
      "\n",
      "Fold: 29  Epoch: 214  Training loss = 2.1924  Validation loss = 1.0204  \n",
      "\n",
      "Fold: 29  Epoch: 215  Training loss = 2.1913  Validation loss = 1.0194  \n",
      "\n",
      "Fold: 29  Epoch: 216  Training loss = 2.2020  Validation loss = 1.0180  \n",
      "\n",
      "Fold: 29  Epoch: 217  Training loss = 2.1926  Validation loss = 1.0225  \n",
      "\n",
      "Fold: 29  Epoch: 218  Training loss = 2.1899  Validation loss = 1.0205  \n",
      "\n",
      "Fold: 29  Epoch: 219  Training loss = 2.1926  Validation loss = 1.0178  \n",
      "\n",
      "Fold: 29  Epoch: 220  Training loss = 2.1962  Validation loss = 1.0177  \n",
      "\n",
      "Fold: 29  Epoch: 221  Training loss = 2.1922  Validation loss = 1.0181  \n",
      "\n",
      "Fold: 29  Epoch: 222  Training loss = 2.1879  Validation loss = 1.0180  \n",
      "\n",
      "Fold: 29  Epoch: 223  Training loss = 2.1940  Validation loss = 1.0164  \n",
      "\n",
      "Fold: 29  Epoch: 224  Training loss = 2.1899  Validation loss = 1.0145  \n",
      "\n",
      "Fold: 29  Epoch: 225  Training loss = 2.1868  Validation loss = 1.0147  \n",
      "\n",
      "Fold: 29  Epoch: 226  Training loss = 2.1883  Validation loss = 1.0150  \n",
      "\n",
      "Fold: 29  Epoch: 227  Training loss = 2.1884  Validation loss = 1.0164  \n",
      "\n",
      "Fold: 29  Epoch: 228  Training loss = 2.1865  Validation loss = 1.0108  \n",
      "\n",
      "Fold: 29  Epoch: 229  Training loss = 2.1860  Validation loss = 1.0105  \n",
      "\n",
      "Fold: 29  Epoch: 230  Training loss = 2.1845  Validation loss = 1.0104  \n",
      "\n",
      "Fold: 29  Epoch: 231  Training loss = 2.1905  Validation loss = 1.0075  \n",
      "\n",
      "Fold: 29  Epoch: 232  Training loss = 2.1885  Validation loss = 1.0074  \n",
      "\n",
      "Fold: 29  Epoch: 233  Training loss = 2.1856  Validation loss = 1.0048  \n",
      "\n",
      "Fold: 29  Epoch: 234  Training loss = 2.1906  Validation loss = 1.0055  \n",
      "\n",
      "Fold: 29  Epoch: 235  Training loss = 2.1824  Validation loss = 1.0036  \n",
      "\n",
      "Fold: 29  Epoch: 236  Training loss = 2.1865  Validation loss = 1.0006  \n",
      "\n",
      "Fold: 29  Epoch: 237  Training loss = 2.1819  Validation loss = 1.0008  \n",
      "\n",
      "Fold: 29  Epoch: 238  Training loss = 2.1824  Validation loss = 1.0009  \n",
      "\n",
      "Fold: 29  Epoch: 239  Training loss = 2.1821  Validation loss = 1.0011  \n",
      "\n",
      "Fold: 29  Epoch: 240  Training loss = 2.1799  Validation loss = 0.9986  \n",
      "\n",
      "Fold: 29  Epoch: 241  Training loss = 2.1816  Validation loss = 0.9996  \n",
      "\n",
      "Fold: 29  Epoch: 242  Training loss = 2.1792  Validation loss = 1.0002  \n",
      "\n",
      "Fold: 29  Epoch: 243  Training loss = 2.1788  Validation loss = 0.9985  \n",
      "\n",
      "Fold: 29  Epoch: 244  Training loss = 2.1791  Validation loss = 0.9999  \n",
      "\n",
      "Fold: 29  Epoch: 245  Training loss = 2.1816  Validation loss = 0.9968  \n",
      "\n",
      "Fold: 29  Epoch: 246  Training loss = 2.1764  Validation loss = 0.9969  \n",
      "\n",
      "Fold: 29  Epoch: 247  Training loss = 2.1774  Validation loss = 0.9982  \n",
      "\n",
      "Fold: 29  Epoch: 248  Training loss = 2.1769  Validation loss = 0.9981  \n",
      "\n",
      "Fold: 29  Epoch: 249  Training loss = 2.1815  Validation loss = 0.9987  \n",
      "\n",
      "Fold: 29  Epoch: 250  Training loss = 2.1811  Validation loss = 1.0002  \n",
      "\n",
      "Fold: 29  Epoch: 251  Training loss = 2.1807  Validation loss = 0.9972  \n",
      "\n",
      "Fold: 29  Epoch: 252  Training loss = 2.1774  Validation loss = 0.9954  \n",
      "\n",
      "Fold: 29  Epoch: 253  Training loss = 2.1741  Validation loss = 0.9947  \n",
      "\n",
      "Fold: 29  Epoch: 254  Training loss = 2.1740  Validation loss = 0.9935  \n",
      "\n",
      "Fold: 29  Epoch: 255  Training loss = 2.1742  Validation loss = 0.9960  \n",
      "\n",
      "Fold: 29  Epoch: 256  Training loss = 2.1740  Validation loss = 0.9956  \n",
      "\n",
      "Fold: 29  Epoch: 257  Training loss = 2.1789  Validation loss = 0.9931  \n",
      "\n",
      "Fold: 29  Epoch: 258  Training loss = 2.1797  Validation loss = 0.9969  \n",
      "\n",
      "Fold: 29  Epoch: 259  Training loss = 2.1729  Validation loss = 0.9955  \n",
      "\n",
      "Fold: 29  Epoch: 260  Training loss = 2.1728  Validation loss = 0.9936  \n",
      "\n",
      "Fold: 29  Epoch: 261  Training loss = 2.1712  Validation loss = 0.9925  \n",
      "\n",
      "Fold: 29  Epoch: 262  Training loss = 2.1732  Validation loss = 0.9904  \n",
      "\n",
      "Fold: 29  Epoch: 263  Training loss = 2.1723  Validation loss = 0.9928  \n",
      "\n",
      "Fold: 29  Epoch: 264  Training loss = 2.1711  Validation loss = 0.9919  \n",
      "\n",
      "Fold: 29  Epoch: 265  Training loss = 2.1776  Validation loss = 0.9923  \n",
      "\n",
      "Fold: 29  Epoch: 266  Training loss = 2.1683  Validation loss = 0.9901  \n",
      "\n",
      "Fold: 29  Epoch: 267  Training loss = 2.1725  Validation loss = 0.9899  \n",
      "\n",
      "Fold: 29  Epoch: 268  Training loss = 2.1691  Validation loss = 0.9917  \n",
      "\n",
      "Fold: 29  Epoch: 269  Training loss = 2.1678  Validation loss = 0.9906  \n",
      "\n",
      "Fold: 29  Epoch: 270  Training loss = 2.1674  Validation loss = 0.9900  \n",
      "\n",
      "Fold: 29  Epoch: 271  Training loss = 2.1660  Validation loss = 0.9898  \n",
      "\n",
      "Fold: 29  Epoch: 272  Training loss = 2.1664  Validation loss = 0.9886  \n",
      "\n",
      "Fold: 29  Epoch: 273  Training loss = 2.1645  Validation loss = 0.9851  \n",
      "\n",
      "Fold: 29  Epoch: 274  Training loss = 2.1736  Validation loss = 0.9854  \n",
      "\n",
      "Fold: 29  Epoch: 275  Training loss = 2.1639  Validation loss = 0.9829  \n",
      "\n",
      "Fold: 29  Epoch: 276  Training loss = 2.1694  Validation loss = 0.9815  \n",
      "\n",
      "Fold: 29  Epoch: 277  Training loss = 2.1734  Validation loss = 0.9816  \n",
      "\n",
      "Fold: 29  Epoch: 278  Training loss = 2.1700  Validation loss = 0.9827  \n",
      "\n",
      "Fold: 29  Epoch: 279  Training loss = 2.1643  Validation loss = 0.9857  \n",
      "\n",
      "Fold: 29  Epoch: 280  Training loss = 2.1634  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 29  Epoch: 281  Training loss = 2.1631  Validation loss = 0.9862  \n",
      "\n",
      "Fold: 29  Epoch: 282  Training loss = 2.1621  Validation loss = 0.9872  \n",
      "\n",
      "Fold: 29  Epoch: 283  Training loss = 2.1621  Validation loss = 0.9854  \n",
      "\n",
      "Fold: 29  Epoch: 284  Training loss = 2.1613  Validation loss = 0.9854  \n",
      "\n",
      "Fold: 29  Epoch: 285  Training loss = 2.1609  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 29  Epoch: 286  Training loss = 2.1637  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 29  Epoch: 287  Training loss = 2.1620  Validation loss = 0.9829  \n",
      "\n",
      "Fold: 29  Epoch: 288  Training loss = 2.1604  Validation loss = 0.9833  \n",
      "\n",
      "Fold: 29  Epoch: 289  Training loss = 2.1658  Validation loss = 0.9812  \n",
      "\n",
      "Fold: 29  Epoch: 290  Training loss = 2.1601  Validation loss = 0.9826  \n",
      "\n",
      "Fold: 29  Epoch: 291  Training loss = 2.1603  Validation loss = 0.9836  \n",
      "\n",
      "Fold: 29  Epoch: 292  Training loss = 2.1640  Validation loss = 0.9824  \n",
      "\n",
      "Fold: 29  Epoch: 293  Training loss = 2.1635  Validation loss = 0.9845  \n",
      "\n",
      "Fold: 29  Epoch: 294  Training loss = 2.1573  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 29  Epoch: 295  Training loss = 2.1582  Validation loss = 0.9862  \n",
      "\n",
      "Fold: 29  Epoch: 296  Training loss = 2.1589  Validation loss = 0.9841  \n",
      "\n",
      "Fold: 29  Epoch: 297  Training loss = 2.1573  Validation loss = 0.9853  \n",
      "\n",
      "Fold: 29  Epoch: 298  Training loss = 2.1573  Validation loss = 0.9831  \n",
      "\n",
      "Fold: 29  Epoch: 299  Training loss = 2.1553  Validation loss = 0.9815  \n",
      "\n",
      "Fold: 29  Epoch: 300  Training loss = 2.1554  Validation loss = 0.9807  \n",
      "\n",
      "Fold: 29  Epoch: 301  Training loss = 2.1542  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 29  Epoch: 302  Training loss = 2.1547  Validation loss = 0.9829  \n",
      "\n",
      "Fold: 29  Epoch: 303  Training loss = 2.1534  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 29  Epoch: 304  Training loss = 2.1549  Validation loss = 0.9864  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 300  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.1549  Validation loss = 1.1743  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.1539  Validation loss = 1.1750  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.1573  Validation loss = 1.1650  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.1558  Validation loss = 1.1450  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.1528  Validation loss = 1.1566  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.1533  Validation loss = 1.1647  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.1599  Validation loss = 1.1701  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.1524  Validation loss = 1.1991  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.1540  Validation loss = 1.2032  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.1504  Validation loss = 1.2019  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.1493  Validation loss = 1.2052  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.1493  Validation loss = 1.1989  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 2.1494  Validation loss = 1.2036  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.1533  Validation loss = 1.2167  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 2.1475  Validation loss = 1.1894  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 2.1487  Validation loss = 1.1857  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 2.1499  Validation loss = 1.1996  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 2.1476  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 2.1461  Validation loss = 1.2064  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 2.1450  Validation loss = 1.2104  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 2.1446  Validation loss = 1.1909  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 2.1569  Validation loss = 1.1813  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 2.1458  Validation loss = 1.1969  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 2.1433  Validation loss = 1.1838  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 2.1426  Validation loss = 1.1986  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 2.1448  Validation loss = 1.2097  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 2.1457  Validation loss = 1.1893  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 2.1439  Validation loss = 1.1781  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 2.1429  Validation loss = 1.1953  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 2.1422  Validation loss = 1.2107  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 4  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.0402  Validation loss = 0.6002  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.0403  Validation loss = 0.6058  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.0401  Validation loss = 0.5884  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.0417  Validation loss = 0.5808  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.0381  Validation loss = 0.5964  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.0383  Validation loss = 0.6036  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.0381  Validation loss = 0.5982  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.0369  Validation loss = 0.5987  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.0372  Validation loss = 0.6007  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.0383  Validation loss = 0.6134  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.0357  Validation loss = 0.5784  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.0360  Validation loss = 0.5922  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.0407  Validation loss = 0.6202  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.0344  Validation loss = 0.6011  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.0333  Validation loss = 0.5876  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.0332  Validation loss = 0.5978  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 2.0322  Validation loss = 0.5921  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 2.0331  Validation loss = 0.6159  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 2.0325  Validation loss = 0.6158  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 2.0310  Validation loss = 0.5915  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 2.0397  Validation loss = 0.5904  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 2.0287  Validation loss = 0.6001  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 2.0284  Validation loss = 0.6212  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 11  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.6830  Validation loss = 1.8432  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.6789  Validation loss = 1.7788  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.6744  Validation loss = 1.5747  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.6747  Validation loss = 1.5307  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.6730  Validation loss = 1.5690  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.6811  Validation loss = 1.4242  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.6731  Validation loss = 1.5407  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.6726  Validation loss = 1.5476  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.6722  Validation loss = 1.6714  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.6734  Validation loss = 1.8018  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.6707  Validation loss = 1.5208  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.6689  Validation loss = 1.5951  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.6692  Validation loss = 1.7364  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.6715  Validation loss = 1.7932  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.6757  Validation loss = 1.8956  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.6659  Validation loss = 1.6735  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.6648  Validation loss = 1.6073  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.6648  Validation loss = 1.6860  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.6654  Validation loss = 1.7178  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.6635  Validation loss = 1.6638  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.6629  Validation loss = 1.6578  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 1.6714  Validation loss = 1.8777  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 1.6621  Validation loss = 1.6996  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 1.6605  Validation loss = 1.5616  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 1.6607  Validation loss = 1.5152  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 1.6586  Validation loss = 1.5608  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 1.6637  Validation loss = 1.4471  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 1.6579  Validation loss = 1.5660  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 1.6660  Validation loss = 1.4095  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 1.6569  Validation loss = 1.6359  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 1.6565  Validation loss = 1.5624  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 1.6557  Validation loss = 1.5924  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 1.6579  Validation loss = 1.7335  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 1.6550  Validation loss = 1.5916  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 1.6551  Validation loss = 1.7007  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 1.6547  Validation loss = 1.6295  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 1.6540  Validation loss = 1.6466  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 1.6533  Validation loss = 1.6506  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 1.6523  Validation loss = 1.5680  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 1.6528  Validation loss = 1.5137  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 1.6529  Validation loss = 1.7092  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 1.6505  Validation loss = 1.6474  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 1.6511  Validation loss = 1.5327  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 1.6493  Validation loss = 1.5604  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 1.6505  Validation loss = 1.5179  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 1.6509  Validation loss = 1.5075  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 1.6480  Validation loss = 1.5842  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 1.6534  Validation loss = 1.4420  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 1.6495  Validation loss = 1.7450  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 29  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 353\n",
      "Average validation error: 2.78373\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.5921  Test loss = 2.6884  \n",
      "\n",
      "Epoch: 2  Training loss = 1.5897  Test loss = 2.6805  \n",
      "\n",
      "Epoch: 3  Training loss = 1.5878  Test loss = 2.6733  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5861  Test loss = 2.6665  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5847  Test loss = 2.6603  \n",
      "\n",
      "Epoch: 6  Training loss = 1.5835  Test loss = 2.6546  \n",
      "\n",
      "Epoch: 7  Training loss = 1.5825  Test loss = 2.6493  \n",
      "\n",
      "Epoch: 8  Training loss = 1.5816  Test loss = 2.6445  \n",
      "\n",
      "Epoch: 9  Training loss = 1.5809  Test loss = 2.6400  \n",
      "\n",
      "Epoch: 10  Training loss = 1.5802  Test loss = 2.6358  \n",
      "\n",
      "Epoch: 11  Training loss = 1.5796  Test loss = 2.6319  \n",
      "\n",
      "Epoch: 12  Training loss = 1.5791  Test loss = 2.6284  \n",
      "\n",
      "Epoch: 13  Training loss = 1.5786  Test loss = 2.6251  \n",
      "\n",
      "Epoch: 14  Training loss = 1.5783  Test loss = 2.6220  \n",
      "\n",
      "Epoch: 15  Training loss = 1.5779  Test loss = 2.6192  \n",
      "\n",
      "Epoch: 16  Training loss = 1.5776  Test loss = 2.6166  \n",
      "\n",
      "Epoch: 17  Training loss = 1.5773  Test loss = 2.6141  \n",
      "\n",
      "Epoch: 18  Training loss = 1.5770  Test loss = 2.6119  \n",
      "\n",
      "Epoch: 19  Training loss = 1.5768  Test loss = 2.6098  \n",
      "\n",
      "Epoch: 20  Training loss = 1.5766  Test loss = 2.6079  \n",
      "\n",
      "Epoch: 21  Training loss = 1.5764  Test loss = 2.6061  \n",
      "\n",
      "Epoch: 22  Training loss = 1.5762  Test loss = 2.6045  \n",
      "\n",
      "Epoch: 23  Training loss = 1.5760  Test loss = 2.6029  \n",
      "\n",
      "Epoch: 24  Training loss = 1.5759  Test loss = 2.6015  \n",
      "\n",
      "Epoch: 25  Training loss = 1.5757  Test loss = 2.6002  \n",
      "\n",
      "Epoch: 26  Training loss = 1.5756  Test loss = 2.5990  \n",
      "\n",
      "Epoch: 27  Training loss = 1.5754  Test loss = 2.5978  \n",
      "\n",
      "Epoch: 28  Training loss = 1.5753  Test loss = 2.5968  \n",
      "\n",
      "Epoch: 29  Training loss = 1.5752  Test loss = 2.5958  \n",
      "\n",
      "Epoch: 30  Training loss = 1.5751  Test loss = 2.5949  \n",
      "\n",
      "Epoch: 31  Training loss = 1.5749  Test loss = 2.5941  \n",
      "\n",
      "Epoch: 32  Training loss = 1.5748  Test loss = 2.5933  \n",
      "\n",
      "Epoch: 33  Training loss = 1.5747  Test loss = 2.5926  \n",
      "\n",
      "Epoch: 34  Training loss = 1.5746  Test loss = 2.5920  \n",
      "\n",
      "Epoch: 35  Training loss = 1.5745  Test loss = 2.5914  \n",
      "\n",
      "Epoch: 36  Training loss = 1.5744  Test loss = 2.5908  \n",
      "\n",
      "Epoch: 37  Training loss = 1.5743  Test loss = 2.5903  \n",
      "\n",
      "Epoch: 38  Training loss = 1.5742  Test loss = 2.5899  \n",
      "\n",
      "Epoch: 39  Training loss = 1.5741  Test loss = 2.5894  \n",
      "\n",
      "Epoch: 40  Training loss = 1.5740  Test loss = 2.5890  \n",
      "\n",
      "Epoch: 41  Training loss = 1.5739  Test loss = 2.5887  \n",
      "\n",
      "Epoch: 42  Training loss = 1.5738  Test loss = 2.5883  \n",
      "\n",
      "Epoch: 43  Training loss = 1.5737  Test loss = 2.5880  \n",
      "\n",
      "Epoch: 44  Training loss = 1.5736  Test loss = 2.5878  \n",
      "\n",
      "Epoch: 45  Training loss = 1.5735  Test loss = 2.5875  \n",
      "\n",
      "Epoch: 46  Training loss = 1.5734  Test loss = 2.5873  \n",
      "\n",
      "Epoch: 47  Training loss = 1.5733  Test loss = 2.5871  \n",
      "\n",
      "Epoch: 48  Training loss = 1.5733  Test loss = 2.5869  \n",
      "\n",
      "Epoch: 49  Training loss = 1.5732  Test loss = 2.5867  \n",
      "\n",
      "Epoch: 50  Training loss = 1.5731  Test loss = 2.5866  \n",
      "\n",
      "Epoch: 51  Training loss = 1.5730  Test loss = 2.5864  \n",
      "\n",
      "Epoch: 52  Training loss = 1.5729  Test loss = 2.5863  \n",
      "\n",
      "Epoch: 53  Training loss = 1.5728  Test loss = 2.5862  \n",
      "\n",
      "Epoch: 54  Training loss = 1.5727  Test loss = 2.5861  \n",
      "\n",
      "Epoch: 55  Training loss = 1.5726  Test loss = 2.5860  \n",
      "\n",
      "Epoch: 56  Training loss = 1.5725  Test loss = 2.5859  \n",
      "\n",
      "Epoch: 57  Training loss = 1.5725  Test loss = 2.5859  \n",
      "\n",
      "Epoch: 58  Training loss = 1.5724  Test loss = 2.5858  \n",
      "\n",
      "Epoch: 59  Training loss = 1.5723  Test loss = 2.5858  \n",
      "\n",
      "Epoch: 60  Training loss = 1.5722  Test loss = 2.5858  \n",
      "\n",
      "Epoch: 61  Training loss = 1.5721  Test loss = 2.5857  \n",
      "\n",
      "Epoch: 62  Training loss = 1.5720  Test loss = 2.5857  \n",
      "\n",
      "Epoch: 63  Training loss = 1.5719  Test loss = 2.5857  \n",
      "\n",
      "Epoch: 64  Training loss = 1.5718  Test loss = 2.5857  \n",
      "\n",
      "Epoch: 65  Training loss = 1.5718  Test loss = 2.5857  \n",
      "\n",
      "Epoch: 66  Training loss = 1.5717  Test loss = 2.5857  \n",
      "\n",
      "Epoch: 67  Training loss = 1.5716  Test loss = 2.5857  \n",
      "\n",
      "Epoch: 68  Training loss = 1.5715  Test loss = 2.5857  \n",
      "\n",
      "Epoch: 69  Training loss = 1.5714  Test loss = 2.5858  \n",
      "\n",
      "Epoch: 70  Training loss = 1.5713  Test loss = 2.5858  \n",
      "\n",
      "Epoch: 71  Training loss = 1.5713  Test loss = 2.5858  \n",
      "\n",
      "Epoch: 72  Training loss = 1.5712  Test loss = 2.5858  \n",
      "\n",
      "Epoch: 73  Training loss = 1.5711  Test loss = 2.5859  \n",
      "\n",
      "Epoch: 74  Training loss = 1.5710  Test loss = 2.5859  \n",
      "\n",
      "Epoch: 75  Training loss = 1.5709  Test loss = 2.5860  \n",
      "\n",
      "Epoch: 76  Training loss = 1.5708  Test loss = 2.5860  \n",
      "\n",
      "Epoch: 77  Training loss = 1.5708  Test loss = 2.5860  \n",
      "\n",
      "Epoch: 78  Training loss = 1.5707  Test loss = 2.5861  \n",
      "\n",
      "Epoch: 79  Training loss = 1.5706  Test loss = 2.5861  \n",
      "\n",
      "Epoch: 80  Training loss = 1.5705  Test loss = 2.5862  \n",
      "\n",
      "Epoch: 81  Training loss = 1.5704  Test loss = 2.5863  \n",
      "\n",
      "Epoch: 82  Training loss = 1.5704  Test loss = 2.5863  \n",
      "\n",
      "Epoch: 83  Training loss = 1.5703  Test loss = 2.5864  \n",
      "\n",
      "Epoch: 84  Training loss = 1.5702  Test loss = 2.5864  \n",
      "\n",
      "Epoch: 85  Training loss = 1.5701  Test loss = 2.5865  \n",
      "\n",
      "Epoch: 86  Training loss = 1.5700  Test loss = 2.5866  \n",
      "\n",
      "Epoch: 87  Training loss = 1.5700  Test loss = 2.5866  \n",
      "\n",
      "Epoch: 88  Training loss = 1.5699  Test loss = 2.5867  \n",
      "\n",
      "Epoch: 89  Training loss = 1.5698  Test loss = 2.5868  \n",
      "\n",
      "Epoch: 90  Training loss = 1.5697  Test loss = 2.5868  \n",
      "\n",
      "Epoch: 91  Training loss = 1.5696  Test loss = 2.5869  \n",
      "\n",
      "Epoch: 92  Training loss = 1.5696  Test loss = 2.5870  \n",
      "\n",
      "Epoch: 93  Training loss = 1.5695  Test loss = 2.5870  \n",
      "\n",
      "Epoch: 94  Training loss = 1.5694  Test loss = 2.5871  \n",
      "\n",
      "Epoch: 95  Training loss = 1.5693  Test loss = 2.5872  \n",
      "\n",
      "Epoch: 96  Training loss = 1.5692  Test loss = 2.5872  \n",
      "\n",
      "Epoch: 97  Training loss = 1.5692  Test loss = 2.5873  \n",
      "\n",
      "Epoch: 98  Training loss = 1.5691  Test loss = 2.5874  \n",
      "\n",
      "Epoch: 99  Training loss = 1.5690  Test loss = 2.5875  \n",
      "\n",
      "Epoch: 100  Training loss = 1.5689  Test loss = 2.5875  \n",
      "\n",
      "Epoch: 101  Training loss = 1.5689  Test loss = 2.5876  \n",
      "\n",
      "Epoch: 102  Training loss = 1.5688  Test loss = 2.5877  \n",
      "\n",
      "Epoch: 103  Training loss = 1.5687  Test loss = 2.5878  \n",
      "\n",
      "Epoch: 104  Training loss = 1.5686  Test loss = 2.5878  \n",
      "\n",
      "Epoch: 105  Training loss = 1.5685  Test loss = 2.5879  \n",
      "\n",
      "Epoch: 106  Training loss = 1.5685  Test loss = 2.5880  \n",
      "\n",
      "Epoch: 107  Training loss = 1.5684  Test loss = 2.5881  \n",
      "\n",
      "Epoch: 108  Training loss = 1.5683  Test loss = 2.5881  \n",
      "\n",
      "Epoch: 109  Training loss = 1.5682  Test loss = 2.5882  \n",
      "\n",
      "Epoch: 110  Training loss = 1.5682  Test loss = 2.5883  \n",
      "\n",
      "Epoch: 111  Training loss = 1.5681  Test loss = 2.5884  \n",
      "\n",
      "Epoch: 112  Training loss = 1.5680  Test loss = 2.5884  \n",
      "\n",
      "Epoch: 113  Training loss = 1.5679  Test loss = 2.5885  \n",
      "\n",
      "Epoch: 114  Training loss = 1.5679  Test loss = 2.5886  \n",
      "\n",
      "Epoch: 115  Training loss = 1.5678  Test loss = 2.5887  \n",
      "\n",
      "Epoch: 116  Training loss = 1.5677  Test loss = 2.5887  \n",
      "\n",
      "Epoch: 117  Training loss = 1.5676  Test loss = 2.5888  \n",
      "\n",
      "Epoch: 118  Training loss = 1.5676  Test loss = 2.5889  \n",
      "\n",
      "Epoch: 119  Training loss = 1.5675  Test loss = 2.5890  \n",
      "\n",
      "Epoch: 120  Training loss = 1.5674  Test loss = 2.5890  \n",
      "\n",
      "Epoch: 121  Training loss = 1.5673  Test loss = 2.5891  \n",
      "\n",
      "Epoch: 122  Training loss = 1.5673  Test loss = 2.5892  \n",
      "\n",
      "Epoch: 123  Training loss = 1.5672  Test loss = 2.5893  \n",
      "\n",
      "Epoch: 124  Training loss = 1.5671  Test loss = 2.5893  \n",
      "\n",
      "Epoch: 125  Training loss = 1.5670  Test loss = 2.5894  \n",
      "\n",
      "Epoch: 126  Training loss = 1.5670  Test loss = 2.5895  \n",
      "\n",
      "Epoch: 127  Training loss = 1.5669  Test loss = 2.5896  \n",
      "\n",
      "Epoch: 128  Training loss = 1.5668  Test loss = 2.5897  \n",
      "\n",
      "Epoch: 129  Training loss = 1.5667  Test loss = 2.5897  \n",
      "\n",
      "Epoch: 130  Training loss = 1.5667  Test loss = 2.5898  \n",
      "\n",
      "Epoch: 131  Training loss = 1.5666  Test loss = 2.5899  \n",
      "\n",
      "Epoch: 132  Training loss = 1.5665  Test loss = 2.5900  \n",
      "\n",
      "Epoch: 133  Training loss = 1.5664  Test loss = 2.5900  \n",
      "\n",
      "Epoch: 134  Training loss = 1.5664  Test loss = 2.5901  \n",
      "\n",
      "Epoch: 135  Training loss = 1.5663  Test loss = 2.5902  \n",
      "\n",
      "Epoch: 136  Training loss = 1.5662  Test loss = 2.5903  \n",
      "\n",
      "Epoch: 137  Training loss = 1.5662  Test loss = 2.5903  \n",
      "\n",
      "Epoch: 138  Training loss = 1.5661  Test loss = 2.5904  \n",
      "\n",
      "Epoch: 139  Training loss = 1.5660  Test loss = 2.5905  \n",
      "\n",
      "Epoch: 140  Training loss = 1.5659  Test loss = 2.5906  \n",
      "\n",
      "Epoch: 141  Training loss = 1.5659  Test loss = 2.5906  \n",
      "\n",
      "Epoch: 142  Training loss = 1.5658  Test loss = 2.5907  \n",
      "\n",
      "Epoch: 143  Training loss = 1.5657  Test loss = 2.5908  \n",
      "\n",
      "Epoch: 144  Training loss = 1.5657  Test loss = 2.5908  \n",
      "\n",
      "Epoch: 145  Training loss = 1.5656  Test loss = 2.5909  \n",
      "\n",
      "Epoch: 146  Training loss = 1.5655  Test loss = 2.5910  \n",
      "\n",
      "Epoch: 147  Training loss = 1.5654  Test loss = 2.5911  \n",
      "\n",
      "Epoch: 148  Training loss = 1.5654  Test loss = 2.5911  \n",
      "\n",
      "Epoch: 149  Training loss = 1.5653  Test loss = 2.5912  \n",
      "\n",
      "Epoch: 150  Training loss = 1.5652  Test loss = 2.5913  \n",
      "\n",
      "Epoch: 151  Training loss = 1.5652  Test loss = 2.5914  \n",
      "\n",
      "Epoch: 152  Training loss = 1.5651  Test loss = 2.5914  \n",
      "\n",
      "Epoch: 153  Training loss = 1.5650  Test loss = 2.5915  \n",
      "\n",
      "Epoch: 154  Training loss = 1.5649  Test loss = 2.5916  \n",
      "\n",
      "Epoch: 155  Training loss = 1.5649  Test loss = 2.5916  \n",
      "\n",
      "Epoch: 156  Training loss = 1.5648  Test loss = 2.5917  \n",
      "\n",
      "Epoch: 157  Training loss = 1.5647  Test loss = 2.5918  \n",
      "\n",
      "Epoch: 158  Training loss = 1.5647  Test loss = 2.5919  \n",
      "\n",
      "Epoch: 159  Training loss = 1.5646  Test loss = 2.5919  \n",
      "\n",
      "Epoch: 160  Training loss = 1.5645  Test loss = 2.5920  \n",
      "\n",
      "Epoch: 161  Training loss = 1.5645  Test loss = 2.5921  \n",
      "\n",
      "Epoch: 162  Training loss = 1.5644  Test loss = 2.5921  \n",
      "\n",
      "Epoch: 163  Training loss = 1.5643  Test loss = 2.5922  \n",
      "\n",
      "Epoch: 164  Training loss = 1.5642  Test loss = 2.5923  \n",
      "\n",
      "Epoch: 165  Training loss = 1.5642  Test loss = 2.5924  \n",
      "\n",
      "Epoch: 166  Training loss = 1.5641  Test loss = 2.5924  \n",
      "\n",
      "Epoch: 167  Training loss = 1.5640  Test loss = 2.5925  \n",
      "\n",
      "Epoch: 168  Training loss = 1.5640  Test loss = 2.5926  \n",
      "\n",
      "Epoch: 169  Training loss = 1.5639  Test loss = 2.5926  \n",
      "\n",
      "Epoch: 170  Training loss = 1.5638  Test loss = 2.5927  \n",
      "\n",
      "Epoch: 171  Training loss = 1.5638  Test loss = 2.5928  \n",
      "\n",
      "Epoch: 172  Training loss = 1.5637  Test loss = 2.5928  \n",
      "\n",
      "Epoch: 173  Training loss = 1.5636  Test loss = 2.5929  \n",
      "\n",
      "Epoch: 174  Training loss = 1.5636  Test loss = 2.5930  \n",
      "\n",
      "Epoch: 175  Training loss = 1.5635  Test loss = 2.5931  \n",
      "\n",
      "Epoch: 176  Training loss = 1.5634  Test loss = 2.5931  \n",
      "\n",
      "Epoch: 177  Training loss = 1.5634  Test loss = 2.5932  \n",
      "\n",
      "Epoch: 178  Training loss = 1.5633  Test loss = 2.5933  \n",
      "\n",
      "Epoch: 179  Training loss = 1.5632  Test loss = 2.5933  \n",
      "\n",
      "Epoch: 180  Training loss = 1.5631  Test loss = 2.5934  \n",
      "\n",
      "Epoch: 181  Training loss = 1.5631  Test loss = 2.5935  \n",
      "\n",
      "Epoch: 182  Training loss = 1.5630  Test loss = 2.5935  \n",
      "\n",
      "Epoch: 183  Training loss = 1.5629  Test loss = 2.5936  \n",
      "\n",
      "Epoch: 184  Training loss = 1.5629  Test loss = 2.5937  \n",
      "\n",
      "Epoch: 185  Training loss = 1.5628  Test loss = 2.5937  \n",
      "\n",
      "Epoch: 186  Training loss = 1.5627  Test loss = 2.5938  \n",
      "\n",
      "Epoch: 187  Training loss = 1.5627  Test loss = 2.5939  \n",
      "\n",
      "Epoch: 188  Training loss = 1.5626  Test loss = 2.5939  \n",
      "\n",
      "Epoch: 189  Training loss = 1.5625  Test loss = 2.5940  \n",
      "\n",
      "Epoch: 190  Training loss = 1.5625  Test loss = 2.5941  \n",
      "\n",
      "Epoch: 191  Training loss = 1.5624  Test loss = 2.5941  \n",
      "\n",
      "Epoch: 192  Training loss = 1.5623  Test loss = 2.5942  \n",
      "\n",
      "Epoch: 193  Training loss = 1.5623  Test loss = 2.5943  \n",
      "\n",
      "Epoch: 194  Training loss = 1.5622  Test loss = 2.5943  \n",
      "\n",
      "Epoch: 195  Training loss = 1.5621  Test loss = 2.5944  \n",
      "\n",
      "Epoch: 196  Training loss = 1.5621  Test loss = 2.5944  \n",
      "\n",
      "Epoch: 197  Training loss = 1.5620  Test loss = 2.5945  \n",
      "\n",
      "Epoch: 198  Training loss = 1.5619  Test loss = 2.5946  \n",
      "\n",
      "Epoch: 199  Training loss = 1.5619  Test loss = 2.5946  \n",
      "\n",
      "Epoch: 200  Training loss = 1.5618  Test loss = 2.5947  \n",
      "\n",
      "Epoch: 201  Training loss = 1.5617  Test loss = 2.5948  \n",
      "\n",
      "Epoch: 202  Training loss = 1.5617  Test loss = 2.5948  \n",
      "\n",
      "Epoch: 203  Training loss = 1.5616  Test loss = 2.5949  \n",
      "\n",
      "Epoch: 204  Training loss = 1.5615  Test loss = 2.5950  \n",
      "\n",
      "Epoch: 205  Training loss = 1.5615  Test loss = 2.5950  \n",
      "\n",
      "Epoch: 206  Training loss = 1.5614  Test loss = 2.5951  \n",
      "\n",
      "Epoch: 207  Training loss = 1.5613  Test loss = 2.5951  \n",
      "\n",
      "Epoch: 208  Training loss = 1.5613  Test loss = 2.5952  \n",
      "\n",
      "Epoch: 209  Training loss = 1.5612  Test loss = 2.5953  \n",
      "\n",
      "Epoch: 210  Training loss = 1.5611  Test loss = 2.5953  \n",
      "\n",
      "Epoch: 211  Training loss = 1.5611  Test loss = 2.5954  \n",
      "\n",
      "Epoch: 212  Training loss = 1.5610  Test loss = 2.5955  \n",
      "\n",
      "Epoch: 213  Training loss = 1.5609  Test loss = 2.5955  \n",
      "\n",
      "Epoch: 214  Training loss = 1.5609  Test loss = 2.5956  \n",
      "\n",
      "Epoch: 215  Training loss = 1.5608  Test loss = 2.5956  \n",
      "\n",
      "Epoch: 216  Training loss = 1.5607  Test loss = 2.5957  \n",
      "\n",
      "Epoch: 217  Training loss = 1.5607  Test loss = 2.5958  \n",
      "\n",
      "Epoch: 218  Training loss = 1.5606  Test loss = 2.5958  \n",
      "\n",
      "Epoch: 219  Training loss = 1.5606  Test loss = 2.5959  \n",
      "\n",
      "Epoch: 220  Training loss = 1.5605  Test loss = 2.5959  \n",
      "\n",
      "Epoch: 221  Training loss = 1.5604  Test loss = 2.5960  \n",
      "\n",
      "Epoch: 222  Training loss = 1.5604  Test loss = 2.5961  \n",
      "\n",
      "Epoch: 223  Training loss = 1.5603  Test loss = 2.5961  \n",
      "\n",
      "Epoch: 224  Training loss = 1.5602  Test loss = 2.5962  \n",
      "\n",
      "Epoch: 225  Training loss = 1.5602  Test loss = 2.5962  \n",
      "\n",
      "Epoch: 226  Training loss = 1.5601  Test loss = 2.5963  \n",
      "\n",
      "Epoch: 227  Training loss = 1.5600  Test loss = 2.5963  \n",
      "\n",
      "Epoch: 228  Training loss = 1.5600  Test loss = 2.5964  \n",
      "\n",
      "Epoch: 229  Training loss = 1.5599  Test loss = 2.5965  \n",
      "\n",
      "Epoch: 230  Training loss = 1.5598  Test loss = 2.5965  \n",
      "\n",
      "Epoch: 231  Training loss = 1.5598  Test loss = 2.5966  \n",
      "\n",
      "Epoch: 232  Training loss = 1.5597  Test loss = 2.5966  \n",
      "\n",
      "Epoch: 233  Training loss = 1.5596  Test loss = 2.5967  \n",
      "\n",
      "Epoch: 234  Training loss = 1.5596  Test loss = 2.5968  \n",
      "\n",
      "Epoch: 235  Training loss = 1.5595  Test loss = 2.5968  \n",
      "\n",
      "Epoch: 236  Training loss = 1.5595  Test loss = 2.5969  \n",
      "\n",
      "Epoch: 237  Training loss = 1.5594  Test loss = 2.5969  \n",
      "\n",
      "Epoch: 238  Training loss = 1.5593  Test loss = 2.5970  \n",
      "\n",
      "Epoch: 239  Training loss = 1.5593  Test loss = 2.5970  \n",
      "\n",
      "Epoch: 240  Training loss = 1.5592  Test loss = 2.5971  \n",
      "\n",
      "Epoch: 241  Training loss = 1.5591  Test loss = 2.5971  \n",
      "\n",
      "Epoch: 242  Training loss = 1.5591  Test loss = 2.5972  \n",
      "\n",
      "Epoch: 243  Training loss = 1.5590  Test loss = 2.5973  \n",
      "\n",
      "Epoch: 244  Training loss = 1.5589  Test loss = 2.5973  \n",
      "\n",
      "Epoch: 245  Training loss = 1.5589  Test loss = 2.5974  \n",
      "\n",
      "Epoch: 246  Training loss = 1.5588  Test loss = 2.5974  \n",
      "\n",
      "Epoch: 247  Training loss = 1.5588  Test loss = 2.5975  \n",
      "\n",
      "Epoch: 248  Training loss = 1.5587  Test loss = 2.5975  \n",
      "\n",
      "Epoch: 249  Training loss = 1.5586  Test loss = 2.5976  \n",
      "\n",
      "Epoch: 250  Training loss = 1.5586  Test loss = 2.5976  \n",
      "\n",
      "Epoch: 251  Training loss = 1.5585  Test loss = 2.5977  \n",
      "\n",
      "Epoch: 252  Training loss = 1.5584  Test loss = 2.5977  \n",
      "\n",
      "Epoch: 253  Training loss = 1.5584  Test loss = 2.5978  \n",
      "\n",
      "Epoch: 254  Training loss = 1.5583  Test loss = 2.5979  \n",
      "\n",
      "Epoch: 255  Training loss = 1.5582  Test loss = 2.5979  \n",
      "\n",
      "Epoch: 256  Training loss = 1.5582  Test loss = 2.5980  \n",
      "\n",
      "Epoch: 257  Training loss = 1.5581  Test loss = 2.5980  \n",
      "\n",
      "Epoch: 258  Training loss = 1.5581  Test loss = 2.5981  \n",
      "\n",
      "Epoch: 259  Training loss = 1.5580  Test loss = 2.5981  \n",
      "\n",
      "Epoch: 260  Training loss = 1.5579  Test loss = 2.5982  \n",
      "\n",
      "Epoch: 261  Training loss = 1.5579  Test loss = 2.5982  \n",
      "\n",
      "Epoch: 262  Training loss = 1.5578  Test loss = 2.5983  \n",
      "\n",
      "Epoch: 263  Training loss = 1.5577  Test loss = 2.5983  \n",
      "\n",
      "Epoch: 264  Training loss = 1.5577  Test loss = 2.5984  \n",
      "\n",
      "Epoch: 265  Training loss = 1.5576  Test loss = 2.5984  \n",
      "\n",
      "Epoch: 266  Training loss = 1.5576  Test loss = 2.5985  \n",
      "\n",
      "Epoch: 267  Training loss = 1.5575  Test loss = 2.5985  \n",
      "\n",
      "Epoch: 268  Training loss = 1.5574  Test loss = 2.5986  \n",
      "\n",
      "Epoch: 269  Training loss = 1.5574  Test loss = 2.5986  \n",
      "\n",
      "Epoch: 270  Training loss = 1.5573  Test loss = 2.5987  \n",
      "\n",
      "Epoch: 271  Training loss = 1.5572  Test loss = 2.5987  \n",
      "\n",
      "Epoch: 272  Training loss = 1.5572  Test loss = 2.5988  \n",
      "\n",
      "Epoch: 273  Training loss = 1.5571  Test loss = 2.5988  \n",
      "\n",
      "Epoch: 274  Training loss = 1.5571  Test loss = 2.5989  \n",
      "\n",
      "Epoch: 275  Training loss = 1.5570  Test loss = 2.5989  \n",
      "\n",
      "Epoch: 276  Training loss = 1.5569  Test loss = 2.5990  \n",
      "\n",
      "Epoch: 277  Training loss = 1.5569  Test loss = 2.5990  \n",
      "\n",
      "Epoch: 278  Training loss = 1.5568  Test loss = 2.5991  \n",
      "\n",
      "Epoch: 279  Training loss = 1.5567  Test loss = 2.5991  \n",
      "\n",
      "Epoch: 280  Training loss = 1.5567  Test loss = 2.5992  \n",
      "\n",
      "Epoch: 281  Training loss = 1.5566  Test loss = 2.5992  \n",
      "\n",
      "Epoch: 282  Training loss = 1.5566  Test loss = 2.5993  \n",
      "\n",
      "Epoch: 283  Training loss = 1.5565  Test loss = 2.5993  \n",
      "\n",
      "Epoch: 284  Training loss = 1.5564  Test loss = 2.5994  \n",
      "\n",
      "Epoch: 285  Training loss = 1.5564  Test loss = 2.5994  \n",
      "\n",
      "Epoch: 286  Training loss = 1.5563  Test loss = 2.5994  \n",
      "\n",
      "Epoch: 287  Training loss = 1.5562  Test loss = 2.5995  \n",
      "\n",
      "Epoch: 288  Training loss = 1.5562  Test loss = 2.5995  \n",
      "\n",
      "Epoch: 289  Training loss = 1.5561  Test loss = 2.5996  \n",
      "\n",
      "Epoch: 290  Training loss = 1.5561  Test loss = 2.5996  \n",
      "\n",
      "Epoch: 291  Training loss = 1.5560  Test loss = 2.5997  \n",
      "\n",
      "Epoch: 292  Training loss = 1.5559  Test loss = 2.5997  \n",
      "\n",
      "Epoch: 293  Training loss = 1.5559  Test loss = 2.5998  \n",
      "\n",
      "Epoch: 294  Training loss = 1.5558  Test loss = 2.5998  \n",
      "\n",
      "Epoch: 295  Training loss = 1.5558  Test loss = 2.5999  \n",
      "\n",
      "Epoch: 296  Training loss = 1.5557  Test loss = 2.5999  \n",
      "\n",
      "Epoch: 297  Training loss = 1.5556  Test loss = 2.6000  \n",
      "\n",
      "Epoch: 298  Training loss = 1.5556  Test loss = 2.6000  \n",
      "\n",
      "Epoch: 299  Training loss = 1.5555  Test loss = 2.6000  \n",
      "\n",
      "Epoch: 300  Training loss = 1.5554  Test loss = 2.6001  \n",
      "\n",
      "Epoch: 301  Training loss = 1.5554  Test loss = 2.6001  \n",
      "\n",
      "Epoch: 302  Training loss = 1.5553  Test loss = 2.6002  \n",
      "\n",
      "Epoch: 303  Training loss = 1.5553  Test loss = 2.6002  \n",
      "\n",
      "Epoch: 304  Training loss = 1.5552  Test loss = 2.6003  \n",
      "\n",
      "Epoch: 305  Training loss = 1.5551  Test loss = 2.6003  \n",
      "\n",
      "Epoch: 306  Training loss = 1.5551  Test loss = 2.6004  \n",
      "\n",
      "Epoch: 307  Training loss = 1.5550  Test loss = 2.6004  \n",
      "\n",
      "Epoch: 308  Training loss = 1.5550  Test loss = 2.6004  \n",
      "\n",
      "Epoch: 309  Training loss = 1.5549  Test loss = 2.6005  \n",
      "\n",
      "Epoch: 310  Training loss = 1.5548  Test loss = 2.6005  \n",
      "\n",
      "Epoch: 311  Training loss = 1.5548  Test loss = 2.6006  \n",
      "\n",
      "Epoch: 312  Training loss = 1.5547  Test loss = 2.6006  \n",
      "\n",
      "Epoch: 313  Training loss = 1.5547  Test loss = 2.6007  \n",
      "\n",
      "Epoch: 314  Training loss = 1.5546  Test loss = 2.6007  \n",
      "\n",
      "Epoch: 315  Training loss = 1.5545  Test loss = 2.6007  \n",
      "\n",
      "Epoch: 316  Training loss = 1.5545  Test loss = 2.6008  \n",
      "\n",
      "Epoch: 317  Training loss = 1.5544  Test loss = 2.6008  \n",
      "\n",
      "Epoch: 318  Training loss = 1.5544  Test loss = 2.6009  \n",
      "\n",
      "Epoch: 319  Training loss = 1.5543  Test loss = 2.6009  \n",
      "\n",
      "Epoch: 320  Training loss = 1.5542  Test loss = 2.6009  \n",
      "\n",
      "Epoch: 321  Training loss = 1.5542  Test loss = 2.6010  \n",
      "\n",
      "Epoch: 322  Training loss = 1.5541  Test loss = 2.6010  \n",
      "\n",
      "Epoch: 323  Training loss = 1.5541  Test loss = 2.6011  \n",
      "\n",
      "Epoch: 324  Training loss = 1.5540  Test loss = 2.6011  \n",
      "\n",
      "Epoch: 325  Training loss = 1.5539  Test loss = 2.6011  \n",
      "\n",
      "Epoch: 326  Training loss = 1.5539  Test loss = 2.6012  \n",
      "\n",
      "Epoch: 327  Training loss = 1.5538  Test loss = 2.6012  \n",
      "\n",
      "Epoch: 328  Training loss = 1.5538  Test loss = 2.6013  \n",
      "\n",
      "Epoch: 329  Training loss = 1.5537  Test loss = 2.6013  \n",
      "\n",
      "Epoch: 330  Training loss = 1.5536  Test loss = 2.6013  \n",
      "\n",
      "Epoch: 331  Training loss = 1.5536  Test loss = 2.6014  \n",
      "\n",
      "Epoch: 332  Training loss = 1.5535  Test loss = 2.6014  \n",
      "\n",
      "Epoch: 333  Training loss = 1.5535  Test loss = 2.6015  \n",
      "\n",
      "Epoch: 334  Training loss = 1.5534  Test loss = 2.6015  \n",
      "\n",
      "Epoch: 335  Training loss = 1.5533  Test loss = 2.6015  \n",
      "\n",
      "Epoch: 336  Training loss = 1.5533  Test loss = 2.6016  \n",
      "\n",
      "Epoch: 337  Training loss = 1.5532  Test loss = 2.6016  \n",
      "\n",
      "Epoch: 338  Training loss = 1.5532  Test loss = 2.6017  \n",
      "\n",
      "Epoch: 339  Training loss = 1.5531  Test loss = 2.6017  \n",
      "\n",
      "Epoch: 340  Training loss = 1.5530  Test loss = 2.6017  \n",
      "\n",
      "Epoch: 341  Training loss = 1.5530  Test loss = 2.6018  \n",
      "\n",
      "Epoch: 342  Training loss = 1.5529  Test loss = 2.6018  \n",
      "\n",
      "Epoch: 343  Training loss = 1.5529  Test loss = 2.6018  \n",
      "\n",
      "Epoch: 344  Training loss = 1.5528  Test loss = 2.6019  \n",
      "\n",
      "Epoch: 345  Training loss = 1.5527  Test loss = 2.6019  \n",
      "\n",
      "Epoch: 346  Training loss = 1.5527  Test loss = 2.6020  \n",
      "\n",
      "Epoch: 347  Training loss = 1.5526  Test loss = 2.6020  \n",
      "\n",
      "Epoch: 348  Training loss = 1.5526  Test loss = 2.6020  \n",
      "\n",
      "Epoch: 349  Training loss = 1.5525  Test loss = 2.6021  \n",
      "\n",
      "Epoch: 350  Training loss = 1.5524  Test loss = 2.6021  \n",
      "\n",
      "Epoch: 351  Training loss = 1.5524  Test loss = 2.6021  \n",
      "\n",
      "Epoch: 352  Training loss = 1.5523  Test loss = 2.6022  \n",
      "\n",
      "Epoch: 353  Training loss = 1.5523  Test loss = 2.6022  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2CWpMT/03upUDBaOngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x78de5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGdHYgyAIasZviFO3K/6BdEEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x76e56a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.60221017322 \n",
      "Fixed scheme MAE:  1.59858331189\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.5523  Test loss = 1.9412  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.5588  Test loss = 1.4709  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.4247  Test loss = 0.9327  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.4288  Test loss = 1.2369  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.3394  Test loss = 0.6314  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.2925  Test loss = 0.3698  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.2515  Test loss = 0.2292  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.2209  Test loss = 0.0850  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.1664  Test loss = 0.4649  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.1585  Test loss = 1.1824  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.1189  Test loss = 1.0697  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.1189  Test loss = 1.4505  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.0939  Test loss = 0.6505  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.0968  Test loss = 2.8859  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.1537  Test loss = 3.9070  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.2509  Test loss = 5.1520  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.3460  Test loss = 1.0034  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.3436  Test loss = 0.8526  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.3474  Test loss = 0.4702  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.2424  Test loss = 0.6310  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.1710  Test loss = 2.0991  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.1996  Test loss = 2.5611  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.2216  Test loss = 1.1581  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.2154  Test loss = 1.3370  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.1577  Test loss = 1.1744  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.1668  Test loss = 0.3178  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.1656  Test loss = 0.3326  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1617  Test loss = 1.8563  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.1297  Test loss = 0.5047  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.1284  Test loss = 0.0897  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.1275  Test loss = 3.6873  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.2026  Test loss = 1.3978  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.1386  Test loss = 1.0536  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.1461  Test loss = 0.2885  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.1113  Test loss = 0.6157  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.0973  Test loss = 5.8682  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.2653  Test loss = 1.2736  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2448  Test loss = 1.7637  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2542  Test loss = 1.2186  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2627  Test loss = 1.6535  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.1663  Test loss = 1.2716  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.1742  Test loss = 1.6563  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.1901  Test loss = 2.2178  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.2181  Test loss = 12.5657  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9848  Test loss = 6.2058  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1249  Test loss = 1.1307  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1291  Test loss = 1.2602  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1335  Test loss = 0.9104  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.8991  Test loss = 1.7395  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.9031  Test loss = 2.0978  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.9207  Test loss = 0.2782  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.9198  Test loss = 1.8336  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.8871  Test loss = 2.1874  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.9063  Test loss = 2.3720  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.9280  Test loss = 0.0285  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.9249  Test loss = 0.1930  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.8381  Test loss = 0.2759  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.8384  Test loss = 1.8174  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.8505  Test loss = 0.5060  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.8503  Test loss = 0.6556  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.8142  Test loss = 0.2529  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.8129  Test loss = 2.6960  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.8368  Test loss = 0.4180  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.8345  Test loss = 0.9044  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.7969  Test loss = 0.9074  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.7993  Test loss = 0.0779  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.7979  Test loss = 0.9644  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.8017  Test loss = 2.2857  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.7964  Test loss = 4.4158  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.8778  Test loss = 0.3373  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.8779  Test loss = 0.8548  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.8729  Test loss = 2.4713  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.8476  Test loss = 2.5872  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.8731  Test loss = 0.7243  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.8749  Test loss = 0.9508  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.8783  Test loss = 0.4793  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.8518  Test loss = 0.7240  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nahG+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7828630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.3686424084 \n",
      "Updating scheme MAE:  1.56004899138\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"../../../models/lstm/1Q/3_cells/1q_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(\"../../../models/lstm/1Q/3_cells/1q_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
