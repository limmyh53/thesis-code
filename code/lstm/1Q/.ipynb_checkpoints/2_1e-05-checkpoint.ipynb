{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/2_cells/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 750\n",
    "learning_rate = 1e-5\n",
    "batch_size = 5\n",
    "early_stop_iters = 15\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 12 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell]*2, state_is_tuple = True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(stacked_cells, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 12 \n",
      "Learning rate = 1e-05 \n",
      "Epochs = 750 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 15 \n",
      "Learning rate = 1e-05\n",
      "Fold: 1  Epoch: 1  Training loss = 3.1078  Validation loss = 3.1244  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.1072  Validation loss = 3.1232  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.1067  Validation loss = 3.1222  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.1057  Validation loss = 3.1201  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.1052  Validation loss = 3.1190  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.1047  Validation loss = 3.1179  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.1040  Validation loss = 3.1165  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.1035  Validation loss = 3.1155  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.1027  Validation loss = 3.1137  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.1020  Validation loss = 3.1123  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.1014  Validation loss = 3.1109  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.1006  Validation loss = 3.1094  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.0999  Validation loss = 3.1079  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.0993  Validation loss = 3.1066  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.0988  Validation loss = 3.1055  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.0979  Validation loss = 3.1037  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.0975  Validation loss = 3.1028  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.0970  Validation loss = 3.1017  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.0964  Validation loss = 3.1004  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.0958  Validation loss = 3.0992  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.0951  Validation loss = 3.0977  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.0941  Validation loss = 3.0957  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.0937  Validation loss = 3.0947  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.0932  Validation loss = 3.0937  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.0928  Validation loss = 3.0927  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.0923  Validation loss = 3.0918  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.0919  Validation loss = 3.0908  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.0912  Validation loss = 3.0894  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.0906  Validation loss = 3.0881  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.0902  Validation loss = 3.0871  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.0897  Validation loss = 3.0860  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.0891  Validation loss = 3.0849  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.0884  Validation loss = 3.0833  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.0879  Validation loss = 3.0823  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.0874  Validation loss = 3.0812  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.0868  Validation loss = 3.0799  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.0861  Validation loss = 3.0785  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.0856  Validation loss = 3.0773  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.0850  Validation loss = 3.0761  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.0844  Validation loss = 3.0749  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.0839  Validation loss = 3.0737  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.0833  Validation loss = 3.0724  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.0828  Validation loss = 3.0713  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.0819  Validation loss = 3.0695  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.0813  Validation loss = 3.0683  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.0808  Validation loss = 3.0671  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.0804  Validation loss = 3.0662  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.0800  Validation loss = 3.0652  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.0793  Validation loss = 3.0639  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.0787  Validation loss = 3.0626  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.0781  Validation loss = 3.0613  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.0776  Validation loss = 3.0602  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.0771  Validation loss = 3.0590  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.0765  Validation loss = 3.0578  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.0759  Validation loss = 3.0565  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.0754  Validation loss = 3.0554  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.0749  Validation loss = 3.0543  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.0744  Validation loss = 3.0531  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.0739  Validation loss = 3.0521  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.0735  Validation loss = 3.0511  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.0726  Validation loss = 3.0493  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.0721  Validation loss = 3.0483  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.0715  Validation loss = 3.0469  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.0709  Validation loss = 3.0455  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.0704  Validation loss = 3.0445  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.0700  Validation loss = 3.0436  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.0694  Validation loss = 3.0422  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.0687  Validation loss = 3.0407  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.0678  Validation loss = 3.0389  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.0672  Validation loss = 3.0375  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.0666  Validation loss = 3.0363  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.0663  Validation loss = 3.0354  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.0656  Validation loss = 3.0340  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.0649  Validation loss = 3.0325  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.0645  Validation loss = 3.0315  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.0639  Validation loss = 3.0302  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.0633  Validation loss = 3.0289  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.0623  Validation loss = 3.0268  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.0616  Validation loss = 3.0252  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.0611  Validation loss = 3.0241  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.0606  Validation loss = 3.0229  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.0600  Validation loss = 3.0216  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.0594  Validation loss = 3.0204  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.0588  Validation loss = 3.0190  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.0584  Validation loss = 3.0182  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.0579  Validation loss = 3.0171  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.0576  Validation loss = 3.0163  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.0572  Validation loss = 3.0154  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.0567  Validation loss = 3.0145  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.0563  Validation loss = 3.0134  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.0557  Validation loss = 3.0122  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.0554  Validation loss = 3.0114  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.0548  Validation loss = 3.0102  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.0542  Validation loss = 3.0089  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.0536  Validation loss = 3.0075  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.0532  Validation loss = 3.0067  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.0527  Validation loss = 3.0055  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.0523  Validation loss = 3.0046  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.0516  Validation loss = 3.0030  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.0511  Validation loss = 3.0020  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.0508  Validation loss = 3.0012  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.0502  Validation loss = 3.0000  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.0495  Validation loss = 2.9985  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.0489  Validation loss = 2.9970  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.0485  Validation loss = 2.9960  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.0478  Validation loss = 2.9945  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.0473  Validation loss = 2.9935  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.0467  Validation loss = 2.9920  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.0461  Validation loss = 2.9908  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.0456  Validation loss = 2.9897  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.0450  Validation loss = 2.9884  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.0446  Validation loss = 2.9874  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.0439  Validation loss = 2.9860  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.0435  Validation loss = 2.9849  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.0429  Validation loss = 2.9838  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.0425  Validation loss = 2.9828  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.0420  Validation loss = 2.9816  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.0414  Validation loss = 2.9803  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.0411  Validation loss = 2.9796  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.0406  Validation loss = 2.9786  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.0401  Validation loss = 2.9774  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.0397  Validation loss = 2.9764  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.0391  Validation loss = 2.9751  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.0385  Validation loss = 2.9739  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.0380  Validation loss = 2.9728  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.0373  Validation loss = 2.9712  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.0367  Validation loss = 2.9699  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.0363  Validation loss = 2.9688  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.0359  Validation loss = 2.9680  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.0354  Validation loss = 2.9668  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.0347  Validation loss = 2.9653  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.0344  Validation loss = 2.9646  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.0340  Validation loss = 2.9636  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.0334  Validation loss = 2.9623  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.0328  Validation loss = 2.9609  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.0323  Validation loss = 2.9597  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.0318  Validation loss = 2.9586  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.0314  Validation loss = 2.9578  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.0311  Validation loss = 2.9570  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.0305  Validation loss = 2.9556  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.0300  Validation loss = 2.9544  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.0294  Validation loss = 2.9531  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.0290  Validation loss = 2.9522  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.0286  Validation loss = 2.9514  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.0279  Validation loss = 2.9496  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.0273  Validation loss = 2.9484  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.0268  Validation loss = 2.9473  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.0266  Validation loss = 2.9466  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.0261  Validation loss = 2.9454  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.0256  Validation loss = 2.9443  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.0250  Validation loss = 2.9430  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.0243  Validation loss = 2.9413  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.0239  Validation loss = 2.9405  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.0235  Validation loss = 2.9394  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.0227  Validation loss = 2.9377  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.0222  Validation loss = 2.9366  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.0217  Validation loss = 2.9354  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.0213  Validation loss = 2.9345  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.0209  Validation loss = 2.9336  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.0202  Validation loss = 2.9320  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.0199  Validation loss = 2.9312  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.0195  Validation loss = 2.9304  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.0190  Validation loss = 2.9291  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.0186  Validation loss = 2.9281  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.0182  Validation loss = 2.9272  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.0176  Validation loss = 2.9259  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.0169  Validation loss = 2.9243  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.0164  Validation loss = 2.9232  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.0159  Validation loss = 2.9219  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.0152  Validation loss = 2.9204  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.0149  Validation loss = 2.9197  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.0146  Validation loss = 2.9190  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.0142  Validation loss = 2.9179  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.0137  Validation loss = 2.9168  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.0132  Validation loss = 2.9157  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.0125  Validation loss = 2.9141  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.0121  Validation loss = 2.9130  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.0115  Validation loss = 2.9117  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.0111  Validation loss = 2.9108  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.0107  Validation loss = 2.9098  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.0103  Validation loss = 2.9089  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.0097  Validation loss = 2.9075  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.0094  Validation loss = 2.9068  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.0090  Validation loss = 2.9057  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.0084  Validation loss = 2.9043  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.0080  Validation loss = 2.9034  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.0075  Validation loss = 2.9023  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.0070  Validation loss = 2.9012  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.0067  Validation loss = 2.9004  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.0063  Validation loss = 2.8994  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.0059  Validation loss = 2.8983  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.0056  Validation loss = 2.8977  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.0049  Validation loss = 2.8961  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.0044  Validation loss = 2.8948  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.0041  Validation loss = 2.8942  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.0037  Validation loss = 2.8931  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.0033  Validation loss = 2.8922  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.0028  Validation loss = 2.8911  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.0024  Validation loss = 2.8902  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.0018  Validation loss = 2.8889  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.0015  Validation loss = 2.8880  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.0011  Validation loss = 2.8871  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.0009  Validation loss = 2.8866  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.0004  Validation loss = 2.8854  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.0002  Validation loss = 2.8850  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 2.9998  Validation loss = 2.8840  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 2.9991  Validation loss = 2.8825  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 2.9988  Validation loss = 2.8817  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 2.9984  Validation loss = 2.8808  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 2.9981  Validation loss = 2.8800  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 2.9976  Validation loss = 2.8788  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 2.9972  Validation loss = 2.8778  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 2.9968  Validation loss = 2.8769  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 2.9964  Validation loss = 2.8760  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 2.9961  Validation loss = 2.8752  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 2.9956  Validation loss = 2.8740  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 2.9951  Validation loss = 2.8727  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 2.9948  Validation loss = 2.8720  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 2.9943  Validation loss = 2.8708  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 2.9937  Validation loss = 2.8694  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 2.9932  Validation loss = 2.8682  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 2.9925  Validation loss = 2.8665  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 2.9922  Validation loss = 2.8658  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 2.9917  Validation loss = 2.8647  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 2.9910  Validation loss = 2.8630  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 2.9907  Validation loss = 2.8621  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 2.9902  Validation loss = 2.8611  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 2.9898  Validation loss = 2.8601  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 2.9893  Validation loss = 2.8588  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 2.9889  Validation loss = 2.8578  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 2.9885  Validation loss = 2.8569  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 2.9882  Validation loss = 2.8561  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 2.9878  Validation loss = 2.8551  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 2.9873  Validation loss = 2.8540  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 2.9871  Validation loss = 2.8535  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 2.9867  Validation loss = 2.8524  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 2.9863  Validation loss = 2.8515  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 2.9857  Validation loss = 2.8500  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 2.9853  Validation loss = 2.8489  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 2.9847  Validation loss = 2.8477  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 2.9844  Validation loss = 2.8468  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 2.9841  Validation loss = 2.8461  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 2.9837  Validation loss = 2.8452  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 2.9832  Validation loss = 2.8440  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 2.9826  Validation loss = 2.8425  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 2.9822  Validation loss = 2.8416  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 2.9820  Validation loss = 2.8410  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 2.9817  Validation loss = 2.8403  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 2.9814  Validation loss = 2.8397  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 2.9812  Validation loss = 2.8390  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 2.9808  Validation loss = 2.8382  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 2.9804  Validation loss = 2.8372  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 2.9801  Validation loss = 2.8363  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 2.9797  Validation loss = 2.8354  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 2.9792  Validation loss = 2.8341  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 2.9789  Validation loss = 2.8334  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 2.9785  Validation loss = 2.8323  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 2.9782  Validation loss = 2.8317  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 2.9778  Validation loss = 2.8308  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 2.9775  Validation loss = 2.8300  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 2.9771  Validation loss = 2.8290  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 2.9766  Validation loss = 2.8277  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 2.9762  Validation loss = 2.8268  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 2.9757  Validation loss = 2.8256  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 2.9753  Validation loss = 2.8245  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 2.9749  Validation loss = 2.8235  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 2.9745  Validation loss = 2.8226  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 2.9742  Validation loss = 2.8217  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 2.9739  Validation loss = 2.8210  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 2.9735  Validation loss = 2.8200  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 2.9732  Validation loss = 2.8193  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 2.9727  Validation loss = 2.8181  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 2.9724  Validation loss = 2.8173  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 2.9719  Validation loss = 2.8162  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 2.9716  Validation loss = 2.8152  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 2.9713  Validation loss = 2.8145  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 2.9710  Validation loss = 2.8137  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 2.9706  Validation loss = 2.8127  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 2.9702  Validation loss = 2.8119  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 2.9700  Validation loss = 2.8113  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 2.9697  Validation loss = 2.8104  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 2.9691  Validation loss = 2.8090  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 2.9689  Validation loss = 2.8085  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 2.9684  Validation loss = 2.8072  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 2.9678  Validation loss = 2.8058  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 2.9675  Validation loss = 2.8050  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 2.9669  Validation loss = 2.8035  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 2.9665  Validation loss = 2.8025  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 2.9661  Validation loss = 2.8015  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 2.9657  Validation loss = 2.8005  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 2.9652  Validation loss = 2.7994  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 2.9648  Validation loss = 2.7984  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 2.9644  Validation loss = 2.7973  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 2.9640  Validation loss = 2.7963  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 2.9638  Validation loss = 2.7957  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 2.9633  Validation loss = 2.7946  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 2.9630  Validation loss = 2.7938  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 2.9626  Validation loss = 2.7927  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 2.9621  Validation loss = 2.7915  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 2.9617  Validation loss = 2.7905  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 2.9613  Validation loss = 2.7895  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 2.9608  Validation loss = 2.7881  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 2.9603  Validation loss = 2.7869  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 2.9598  Validation loss = 2.7857  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 2.9594  Validation loss = 2.7848  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 2.9592  Validation loss = 2.7841  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 2.9589  Validation loss = 2.7835  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 2.9587  Validation loss = 2.7829  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 2.9585  Validation loss = 2.7824  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 2.9581  Validation loss = 2.7814  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 2.9577  Validation loss = 2.7804  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 2.9573  Validation loss = 2.7795  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 2.9570  Validation loss = 2.7785  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 2.9568  Validation loss = 2.7780  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 2.9563  Validation loss = 2.7768  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 2.9560  Validation loss = 2.7760  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 2.9556  Validation loss = 2.7751  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 2.9552  Validation loss = 2.7740  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 2.9549  Validation loss = 2.7732  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 2.9546  Validation loss = 2.7725  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 2.9544  Validation loss = 2.7718  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 2.9541  Validation loss = 2.7712  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 2.9535  Validation loss = 2.7697  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 2.9532  Validation loss = 2.7689  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 2.9529  Validation loss = 2.7682  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 2.9526  Validation loss = 2.7672  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 2.9523  Validation loss = 2.7665  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 2.9520  Validation loss = 2.7658  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 2.9517  Validation loss = 2.7650  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 2.9514  Validation loss = 2.7643  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 2.9510  Validation loss = 2.7631  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 2.9505  Validation loss = 2.7619  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 2.9502  Validation loss = 2.7610  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 2.9498  Validation loss = 2.7602  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 2.9494  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 2.9490  Validation loss = 2.7581  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 2.9488  Validation loss = 2.7574  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 2.9483  Validation loss = 2.7561  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 2.9479  Validation loss = 2.7552  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 2.9477  Validation loss = 2.7546  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 2.9473  Validation loss = 2.7535  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 2.9469  Validation loss = 2.7526  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 2.9465  Validation loss = 2.7516  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 2.9460  Validation loss = 2.7503  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 2.9456  Validation loss = 2.7493  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 2.9454  Validation loss = 2.7487  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 2.9450  Validation loss = 2.7477  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 2.9446  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 2.9443  Validation loss = 2.7459  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 2.9439  Validation loss = 2.7447  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 2.9435  Validation loss = 2.7436  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 2.9432  Validation loss = 2.7429  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 2.9427  Validation loss = 2.7416  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 2.9424  Validation loss = 2.7409  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 2.9420  Validation loss = 2.7398  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 2.9417  Validation loss = 2.7391  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 2.9414  Validation loss = 2.7381  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 2.9410  Validation loss = 2.7371  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 2.9406  Validation loss = 2.7361  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 2.9403  Validation loss = 2.7353  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 2.9400  Validation loss = 2.7344  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 2.9395  Validation loss = 2.7332  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 2.9392  Validation loss = 2.7325  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 2.9390  Validation loss = 2.7320  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 2.9386  Validation loss = 2.7309  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 2.9382  Validation loss = 2.7298  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 2.9377  Validation loss = 2.7286  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 2.9373  Validation loss = 2.7274  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 2.9369  Validation loss = 2.7265  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 2.9366  Validation loss = 2.7257  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 2.9363  Validation loss = 2.7248  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 2.9358  Validation loss = 2.7235  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 2.9356  Validation loss = 2.7230  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 2.9354  Validation loss = 2.7223  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 2.9351  Validation loss = 2.7216  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 2.9345  Validation loss = 2.7202  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 2.9342  Validation loss = 2.7193  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 2.9340  Validation loss = 2.7186  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 2.9336  Validation loss = 2.7176  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 2.9332  Validation loss = 2.7166  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 2.9329  Validation loss = 2.7157  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 2.9325  Validation loss = 2.7146  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 2.9321  Validation loss = 2.7137  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 2.9318  Validation loss = 2.7128  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 2.9315  Validation loss = 2.7121  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 2.9311  Validation loss = 2.7110  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 2.9307  Validation loss = 2.7100  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 2.9305  Validation loss = 2.7095  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 2.9303  Validation loss = 2.7089  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 2.9300  Validation loss = 2.7081  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 2.9298  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 2.9295  Validation loss = 2.7066  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 2.9290  Validation loss = 2.7053  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 2.9286  Validation loss = 2.7042  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 2.9283  Validation loss = 2.7035  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 2.9279  Validation loss = 2.7024  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 2.9275  Validation loss = 2.7014  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 2.9272  Validation loss = 2.7005  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 2.9270  Validation loss = 2.6999  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 2.9265  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 2.9261  Validation loss = 2.6975  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 2.9256  Validation loss = 2.6962  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 2.9253  Validation loss = 2.6955  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 2.9250  Validation loss = 2.6945  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 2.9246  Validation loss = 2.6935  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 2.9243  Validation loss = 2.6926  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 2.9237  Validation loss = 2.6912  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 2.9235  Validation loss = 2.6905  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 2.9232  Validation loss = 2.6898  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 2.9229  Validation loss = 2.6890  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 2.9225  Validation loss = 2.6880  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 2.9223  Validation loss = 2.6873  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 2.9219  Validation loss = 2.6862  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 2.9217  Validation loss = 2.6856  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 2.9214  Validation loss = 2.6847  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 2.9210  Validation loss = 2.6839  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 2.9207  Validation loss = 2.6830  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 2.9205  Validation loss = 2.6824  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 2.9202  Validation loss = 2.6815  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 2.9199  Validation loss = 2.6807  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 2.9197  Validation loss = 2.6801  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 2.9195  Validation loss = 2.6798  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 2.9191  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 2.9189  Validation loss = 2.6780  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 2.9185  Validation loss = 2.6771  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 2.9182  Validation loss = 2.6760  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 2.9179  Validation loss = 2.6753  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 2.9177  Validation loss = 2.6748  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 2.9173  Validation loss = 2.6736  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 2.9170  Validation loss = 2.6727  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 2.9166  Validation loss = 2.6718  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 2.9164  Validation loss = 2.6711  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 2.9159  Validation loss = 2.6699  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 2.9157  Validation loss = 2.6694  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 2.9152  Validation loss = 2.6680  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 2.9149  Validation loss = 2.6670  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 2.9145  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 2.9141  Validation loss = 2.6650  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 2.9138  Validation loss = 2.6641  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 2.9132  Validation loss = 2.6627  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 2.9128  Validation loss = 2.6615  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 2.9125  Validation loss = 2.6606  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 2.9122  Validation loss = 2.6597  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 2.9119  Validation loss = 2.6590  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 2.9118  Validation loss = 2.6586  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 2.9115  Validation loss = 2.6579  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 2.9112  Validation loss = 2.6569  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 2.9110  Validation loss = 2.6563  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 2.9107  Validation loss = 2.6557  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 2.9102  Validation loss = 2.6541  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 2.9098  Validation loss = 2.6533  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 2.9096  Validation loss = 2.6524  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 2.9092  Validation loss = 2.6515  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 2.9089  Validation loss = 2.6507  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 2.9086  Validation loss = 2.6498  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 2.9084  Validation loss = 2.6491  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 2.9080  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 2.9076  Validation loss = 2.6470  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 2.9075  Validation loss = 2.6466  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 2.9073  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 2.9070  Validation loss = 2.6452  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 2.9066  Validation loss = 2.6443  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 2.9062  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 2.9058  Validation loss = 2.6419  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 2.9054  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 2.9052  Validation loss = 2.6403  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 2.9049  Validation loss = 2.6393  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 2.9047  Validation loss = 2.6387  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 2.9043  Validation loss = 2.6376  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 2.9040  Validation loss = 2.6369  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 2.9037  Validation loss = 2.6360  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 2.9033  Validation loss = 2.6350  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 2.9030  Validation loss = 2.6341  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 2.9027  Validation loss = 2.6332  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 2.9023  Validation loss = 2.6322  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 2.9021  Validation loss = 2.6317  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 2.9020  Validation loss = 2.6312  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 2.9016  Validation loss = 2.6301  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 2.9013  Validation loss = 2.6293  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 2.9009  Validation loss = 2.6280  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 2.9005  Validation loss = 2.6270  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 2.9003  Validation loss = 2.6266  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 2.9002  Validation loss = 2.6261  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 2.8999  Validation loss = 2.6253  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 2.8996  Validation loss = 2.6244  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 2.8993  Validation loss = 2.6236  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 2.8989  Validation loss = 2.6226  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 2.8986  Validation loss = 2.6217  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 2.8985  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 2.8983  Validation loss = 2.6209  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 2.8982  Validation loss = 2.6205  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 2.8981  Validation loss = 2.6202  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 2.8978  Validation loss = 2.6194  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 2.8974  Validation loss = 2.6184  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 2.8972  Validation loss = 2.6176  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 2.8970  Validation loss = 2.6171  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 2.8967  Validation loss = 2.6164  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 2.8964  Validation loss = 2.6154  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 2.8960  Validation loss = 2.6144  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 2.8959  Validation loss = 2.6139  \n",
      "\n",
      "Fold: 1  Epoch: 501  Training loss = 2.8957  Validation loss = 2.6133  \n",
      "\n",
      "Fold: 1  Epoch: 502  Training loss = 2.8952  Validation loss = 2.6121  \n",
      "\n",
      "Fold: 1  Epoch: 503  Training loss = 2.8949  Validation loss = 2.6110  \n",
      "\n",
      "Fold: 1  Epoch: 504  Training loss = 2.8946  Validation loss = 2.6101  \n",
      "\n",
      "Fold: 1  Epoch: 505  Training loss = 2.8943  Validation loss = 2.6095  \n",
      "\n",
      "Fold: 1  Epoch: 506  Training loss = 2.8942  Validation loss = 2.6090  \n",
      "\n",
      "Fold: 1  Epoch: 507  Training loss = 2.8940  Validation loss = 2.6086  \n",
      "\n",
      "Fold: 1  Epoch: 508  Training loss = 2.8938  Validation loss = 2.6079  \n",
      "\n",
      "Fold: 1  Epoch: 509  Training loss = 2.8935  Validation loss = 2.6069  \n",
      "\n",
      "Fold: 1  Epoch: 510  Training loss = 2.8932  Validation loss = 2.6060  \n",
      "\n",
      "Fold: 1  Epoch: 511  Training loss = 2.8929  Validation loss = 2.6053  \n",
      "\n",
      "Fold: 1  Epoch: 512  Training loss = 2.8925  Validation loss = 2.6041  \n",
      "\n",
      "Fold: 1  Epoch: 513  Training loss = 2.8923  Validation loss = 2.6035  \n",
      "\n",
      "Fold: 1  Epoch: 514  Training loss = 2.8921  Validation loss = 2.6028  \n",
      "\n",
      "Fold: 1  Epoch: 515  Training loss = 2.8918  Validation loss = 2.6021  \n",
      "\n",
      "Fold: 1  Epoch: 516  Training loss = 2.8916  Validation loss = 2.6014  \n",
      "\n",
      "Fold: 1  Epoch: 517  Training loss = 2.8912  Validation loss = 2.6004  \n",
      "\n",
      "Fold: 1  Epoch: 518  Training loss = 2.8908  Validation loss = 2.5992  \n",
      "\n",
      "Fold: 1  Epoch: 519  Training loss = 2.8905  Validation loss = 2.5984  \n",
      "\n",
      "Fold: 1  Epoch: 520  Training loss = 2.8903  Validation loss = 2.5976  \n",
      "\n",
      "Fold: 1  Epoch: 521  Training loss = 2.8898  Validation loss = 2.5962  \n",
      "\n",
      "Fold: 1  Epoch: 522  Training loss = 2.8896  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 1  Epoch: 523  Training loss = 2.8894  Validation loss = 2.5950  \n",
      "\n",
      "Fold: 1  Epoch: 524  Training loss = 2.8890  Validation loss = 2.5939  \n",
      "\n",
      "Fold: 1  Epoch: 525  Training loss = 2.8886  Validation loss = 2.5928  \n",
      "\n",
      "Fold: 1  Epoch: 526  Training loss = 2.8883  Validation loss = 2.5919  \n",
      "\n",
      "Fold: 1  Epoch: 527  Training loss = 2.8882  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 1  Epoch: 528  Training loss = 2.8879  Validation loss = 2.5909  \n",
      "\n",
      "Fold: 1  Epoch: 529  Training loss = 2.8877  Validation loss = 2.5903  \n",
      "\n",
      "Fold: 1  Epoch: 530  Training loss = 2.8873  Validation loss = 2.5891  \n",
      "\n",
      "Fold: 1  Epoch: 531  Training loss = 2.8871  Validation loss = 2.5886  \n",
      "\n",
      "Fold: 1  Epoch: 532  Training loss = 2.8868  Validation loss = 2.5875  \n",
      "\n",
      "Fold: 1  Epoch: 533  Training loss = 2.8864  Validation loss = 2.5866  \n",
      "\n",
      "Fold: 1  Epoch: 534  Training loss = 2.8861  Validation loss = 2.5857  \n",
      "\n",
      "Fold: 1  Epoch: 535  Training loss = 2.8859  Validation loss = 2.5850  \n",
      "\n",
      "Fold: 1  Epoch: 536  Training loss = 2.8856  Validation loss = 2.5840  \n",
      "\n",
      "Fold: 1  Epoch: 537  Training loss = 2.8852  Validation loss = 2.5830  \n",
      "\n",
      "Fold: 1  Epoch: 538  Training loss = 2.8850  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 1  Epoch: 539  Training loss = 2.8848  Validation loss = 2.5819  \n",
      "\n",
      "Fold: 1  Epoch: 540  Training loss = 2.8845  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 1  Epoch: 541  Training loss = 2.8840  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 1  Epoch: 542  Training loss = 2.8837  Validation loss = 2.5785  \n",
      "\n",
      "Fold: 1  Epoch: 543  Training loss = 2.8834  Validation loss = 2.5777  \n",
      "\n",
      "Fold: 1  Epoch: 544  Training loss = 2.8832  Validation loss = 2.5772  \n",
      "\n",
      "Fold: 1  Epoch: 545  Training loss = 2.8829  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 1  Epoch: 546  Training loss = 2.8826  Validation loss = 2.5756  \n",
      "\n",
      "Fold: 1  Epoch: 547  Training loss = 2.8823  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 1  Epoch: 548  Training loss = 2.8821  Validation loss = 2.5741  \n",
      "\n",
      "Fold: 1  Epoch: 549  Training loss = 2.8819  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 1  Epoch: 550  Training loss = 2.8816  Validation loss = 2.5725  \n",
      "\n",
      "Fold: 1  Epoch: 551  Training loss = 2.8814  Validation loss = 2.5718  \n",
      "\n",
      "Fold: 1  Epoch: 552  Training loss = 2.8811  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 1  Epoch: 553  Training loss = 2.8809  Validation loss = 2.5704  \n",
      "\n",
      "Fold: 1  Epoch: 554  Training loss = 2.8807  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 1  Epoch: 555  Training loss = 2.8805  Validation loss = 2.5693  \n",
      "\n",
      "Fold: 1  Epoch: 556  Training loss = 2.8802  Validation loss = 2.5683  \n",
      "\n",
      "Fold: 1  Epoch: 557  Training loss = 2.8798  Validation loss = 2.5673  \n",
      "\n",
      "Fold: 1  Epoch: 558  Training loss = 2.8795  Validation loss = 2.5663  \n",
      "\n",
      "Fold: 1  Epoch: 559  Training loss = 2.8793  Validation loss = 2.5659  \n",
      "\n",
      "Fold: 1  Epoch: 560  Training loss = 2.8790  Validation loss = 2.5650  \n",
      "\n",
      "Fold: 1  Epoch: 561  Training loss = 2.8787  Validation loss = 2.5640  \n",
      "\n",
      "Fold: 1  Epoch: 562  Training loss = 2.8784  Validation loss = 2.5632  \n",
      "\n",
      "Fold: 1  Epoch: 563  Training loss = 2.8783  Validation loss = 2.5627  \n",
      "\n",
      "Fold: 1  Epoch: 564  Training loss = 2.8779  Validation loss = 2.5617  \n",
      "\n",
      "Fold: 1  Epoch: 565  Training loss = 2.8777  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 1  Epoch: 566  Training loss = 2.8774  Validation loss = 2.5603  \n",
      "\n",
      "Fold: 1  Epoch: 567  Training loss = 2.8772  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 1  Epoch: 568  Training loss = 2.8768  Validation loss = 2.5586  \n",
      "\n",
      "Fold: 1  Epoch: 569  Training loss = 2.8764  Validation loss = 2.5572  \n",
      "\n",
      "Fold: 1  Epoch: 570  Training loss = 2.8761  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 1  Epoch: 571  Training loss = 2.8759  Validation loss = 2.5558  \n",
      "\n",
      "Fold: 1  Epoch: 572  Training loss = 2.8756  Validation loss = 2.5548  \n",
      "\n",
      "Fold: 1  Epoch: 573  Training loss = 2.8752  Validation loss = 2.5536  \n",
      "\n",
      "Fold: 1  Epoch: 574  Training loss = 2.8750  Validation loss = 2.5530  \n",
      "\n",
      "Fold: 1  Epoch: 575  Training loss = 2.8747  Validation loss = 2.5522  \n",
      "\n",
      "Fold: 1  Epoch: 576  Training loss = 2.8744  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 1  Epoch: 577  Training loss = 2.8742  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 1  Epoch: 578  Training loss = 2.8739  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 1  Epoch: 579  Training loss = 2.8737  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 1  Epoch: 580  Training loss = 2.8736  Validation loss = 2.5487  \n",
      "\n",
      "Fold: 1  Epoch: 581  Training loss = 2.8733  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 1  Epoch: 582  Training loss = 2.8730  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 1  Epoch: 583  Training loss = 2.8727  Validation loss = 2.5461  \n",
      "\n",
      "Fold: 1  Epoch: 584  Training loss = 2.8724  Validation loss = 2.5453  \n",
      "\n",
      "Fold: 1  Epoch: 585  Training loss = 2.8723  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 1  Epoch: 586  Training loss = 2.8720  Validation loss = 2.5442  \n",
      "\n",
      "Fold: 1  Epoch: 587  Training loss = 2.8717  Validation loss = 2.5432  \n",
      "\n",
      "Fold: 1  Epoch: 588  Training loss = 2.8715  Validation loss = 2.5427  \n",
      "\n",
      "Fold: 1  Epoch: 589  Training loss = 2.8712  Validation loss = 2.5417  \n",
      "\n",
      "Fold: 1  Epoch: 590  Training loss = 2.8710  Validation loss = 2.5410  \n",
      "\n",
      "Fold: 1  Epoch: 591  Training loss = 2.8707  Validation loss = 2.5400  \n",
      "\n",
      "Fold: 1  Epoch: 592  Training loss = 2.8703  Validation loss = 2.5390  \n",
      "\n",
      "Fold: 1  Epoch: 593  Training loss = 2.8702  Validation loss = 2.5386  \n",
      "\n",
      "Fold: 1  Epoch: 594  Training loss = 2.8699  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 1  Epoch: 595  Training loss = 2.8697  Validation loss = 2.5373  \n",
      "\n",
      "Fold: 1  Epoch: 596  Training loss = 2.8695  Validation loss = 2.5367  \n",
      "\n",
      "Fold: 1  Epoch: 597  Training loss = 2.8692  Validation loss = 2.5356  \n",
      "\n",
      "Fold: 1  Epoch: 598  Training loss = 2.8690  Validation loss = 2.5352  \n",
      "\n",
      "Fold: 1  Epoch: 599  Training loss = 2.8687  Validation loss = 2.5341  \n",
      "\n",
      "Fold: 1  Epoch: 600  Training loss = 2.8685  Validation loss = 2.5334  \n",
      "\n",
      "Fold: 1  Epoch: 601  Training loss = 2.8682  Validation loss = 2.5325  \n",
      "\n",
      "Fold: 1  Epoch: 602  Training loss = 2.8678  Validation loss = 2.5313  \n",
      "\n",
      "Fold: 1  Epoch: 603  Training loss = 2.8675  Validation loss = 2.5305  \n",
      "\n",
      "Fold: 1  Epoch: 604  Training loss = 2.8674  Validation loss = 2.5301  \n",
      "\n",
      "Fold: 1  Epoch: 605  Training loss = 2.8671  Validation loss = 2.5293  \n",
      "\n",
      "Fold: 1  Epoch: 606  Training loss = 2.8669  Validation loss = 2.5286  \n",
      "\n",
      "Fold: 1  Epoch: 607  Training loss = 2.8666  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 1  Epoch: 608  Training loss = 2.8664  Validation loss = 2.5270  \n",
      "\n",
      "Fold: 1  Epoch: 609  Training loss = 2.8661  Validation loss = 2.5262  \n",
      "\n",
      "Fold: 1  Epoch: 610  Training loss = 2.8659  Validation loss = 2.5256  \n",
      "\n",
      "Fold: 1  Epoch: 611  Training loss = 2.8655  Validation loss = 2.5244  \n",
      "\n",
      "Fold: 1  Epoch: 612  Training loss = 2.8651  Validation loss = 2.5232  \n",
      "\n",
      "Fold: 1  Epoch: 613  Training loss = 2.8649  Validation loss = 2.5227  \n",
      "\n",
      "Fold: 1  Epoch: 614  Training loss = 2.8646  Validation loss = 2.5216  \n",
      "\n",
      "Fold: 1  Epoch: 615  Training loss = 2.8645  Validation loss = 2.5212  \n",
      "\n",
      "Fold: 1  Epoch: 616  Training loss = 2.8642  Validation loss = 2.5205  \n",
      "\n",
      "Fold: 1  Epoch: 617  Training loss = 2.8640  Validation loss = 2.5197  \n",
      "\n",
      "Fold: 1  Epoch: 618  Training loss = 2.8636  Validation loss = 2.5184  \n",
      "\n",
      "Fold: 1  Epoch: 619  Training loss = 2.8633  Validation loss = 2.5175  \n",
      "\n",
      "Fold: 1  Epoch: 620  Training loss = 2.8630  Validation loss = 2.5168  \n",
      "\n",
      "Fold: 1  Epoch: 621  Training loss = 2.8628  Validation loss = 2.5159  \n",
      "\n",
      "Fold: 1  Epoch: 622  Training loss = 2.8626  Validation loss = 2.5154  \n",
      "\n",
      "Fold: 1  Epoch: 623  Training loss = 2.8624  Validation loss = 2.5148  \n",
      "\n",
      "Fold: 1  Epoch: 624  Training loss = 2.8621  Validation loss = 2.5140  \n",
      "\n",
      "Fold: 1  Epoch: 625  Training loss = 2.8619  Validation loss = 2.5132  \n",
      "\n",
      "Fold: 1  Epoch: 626  Training loss = 2.8617  Validation loss = 2.5128  \n",
      "\n",
      "Fold: 1  Epoch: 627  Training loss = 2.8614  Validation loss = 2.5118  \n",
      "\n",
      "Fold: 1  Epoch: 628  Training loss = 2.8612  Validation loss = 2.5111  \n",
      "\n",
      "Fold: 1  Epoch: 629  Training loss = 2.8609  Validation loss = 2.5104  \n",
      "\n",
      "Fold: 1  Epoch: 630  Training loss = 2.8607  Validation loss = 2.5096  \n",
      "\n",
      "Fold: 1  Epoch: 631  Training loss = 2.8605  Validation loss = 2.5090  \n",
      "\n",
      "Fold: 1  Epoch: 632  Training loss = 2.8602  Validation loss = 2.5079  \n",
      "\n",
      "Fold: 1  Epoch: 633  Training loss = 2.8599  Validation loss = 2.5072  \n",
      "\n",
      "Fold: 1  Epoch: 634  Training loss = 2.8596  Validation loss = 2.5063  \n",
      "\n",
      "Fold: 1  Epoch: 635  Training loss = 2.8593  Validation loss = 2.5054  \n",
      "\n",
      "Fold: 1  Epoch: 636  Training loss = 2.8591  Validation loss = 2.5047  \n",
      "\n",
      "Fold: 1  Epoch: 637  Training loss = 2.8589  Validation loss = 2.5040  \n",
      "\n",
      "Fold: 1  Epoch: 638  Training loss = 2.8587  Validation loss = 2.5034  \n",
      "\n",
      "Fold: 1  Epoch: 639  Training loss = 2.8586  Validation loss = 2.5031  \n",
      "\n",
      "Fold: 1  Epoch: 640  Training loss = 2.8582  Validation loss = 2.5020  \n",
      "\n",
      "Fold: 1  Epoch: 641  Training loss = 2.8580  Validation loss = 2.5013  \n",
      "\n",
      "Fold: 1  Epoch: 642  Training loss = 2.8578  Validation loss = 2.5006  \n",
      "\n",
      "Fold: 1  Epoch: 643  Training loss = 2.8573  Validation loss = 2.4992  \n",
      "\n",
      "Fold: 1  Epoch: 644  Training loss = 2.8570  Validation loss = 2.4983  \n",
      "\n",
      "Fold: 1  Epoch: 645  Training loss = 2.8569  Validation loss = 2.4979  \n",
      "\n",
      "Fold: 1  Epoch: 646  Training loss = 2.8566  Validation loss = 2.4971  \n",
      "\n",
      "Fold: 1  Epoch: 647  Training loss = 2.8565  Validation loss = 2.4966  \n",
      "\n",
      "Fold: 1  Epoch: 648  Training loss = 2.8562  Validation loss = 2.4956  \n",
      "\n",
      "Fold: 1  Epoch: 649  Training loss = 2.8560  Validation loss = 2.4951  \n",
      "\n",
      "Fold: 1  Epoch: 650  Training loss = 2.8556  Validation loss = 2.4937  \n",
      "\n",
      "Fold: 1  Epoch: 651  Training loss = 2.8553  Validation loss = 2.4930  \n",
      "\n",
      "Fold: 1  Epoch: 652  Training loss = 2.8550  Validation loss = 2.4919  \n",
      "\n",
      "Fold: 1  Epoch: 653  Training loss = 2.8548  Validation loss = 2.4913  \n",
      "\n",
      "Fold: 1  Epoch: 654  Training loss = 2.8544  Validation loss = 2.4899  \n",
      "\n",
      "Fold: 1  Epoch: 655  Training loss = 2.8541  Validation loss = 2.4889  \n",
      "\n",
      "Fold: 1  Epoch: 656  Training loss = 2.8537  Validation loss = 2.4877  \n",
      "\n",
      "Fold: 1  Epoch: 657  Training loss = 2.8534  Validation loss = 2.4869  \n",
      "\n",
      "Fold: 1  Epoch: 658  Training loss = 2.8532  Validation loss = 2.4863  \n",
      "\n",
      "Fold: 1  Epoch: 659  Training loss = 2.8530  Validation loss = 2.4856  \n",
      "\n",
      "Fold: 1  Epoch: 660  Training loss = 2.8527  Validation loss = 2.4847  \n",
      "\n",
      "Fold: 1  Epoch: 661  Training loss = 2.8525  Validation loss = 2.4841  \n",
      "\n",
      "Fold: 1  Epoch: 662  Training loss = 2.8523  Validation loss = 2.4833  \n",
      "\n",
      "Fold: 1  Epoch: 663  Training loss = 2.8521  Validation loss = 2.4826  \n",
      "\n",
      "Fold: 1  Epoch: 664  Training loss = 2.8518  Validation loss = 2.4819  \n",
      "\n",
      "Fold: 1  Epoch: 665  Training loss = 2.8517  Validation loss = 2.4814  \n",
      "\n",
      "Fold: 1  Epoch: 666  Training loss = 2.8516  Validation loss = 2.4809  \n",
      "\n",
      "Fold: 1  Epoch: 667  Training loss = 2.8513  Validation loss = 2.4802  \n",
      "\n",
      "Fold: 1  Epoch: 668  Training loss = 2.8512  Validation loss = 2.4796  \n",
      "\n",
      "Fold: 1  Epoch: 669  Training loss = 2.8508  Validation loss = 2.4787  \n",
      "\n",
      "Fold: 1  Epoch: 670  Training loss = 2.8506  Validation loss = 2.4778  \n",
      "\n",
      "Fold: 1  Epoch: 671  Training loss = 2.8502  Validation loss = 2.4766  \n",
      "\n",
      "Fold: 1  Epoch: 672  Training loss = 2.8500  Validation loss = 2.4760  \n",
      "\n",
      "Fold: 1  Epoch: 673  Training loss = 2.8496  Validation loss = 2.4747  \n",
      "\n",
      "Fold: 1  Epoch: 674  Training loss = 2.8494  Validation loss = 2.4741  \n",
      "\n",
      "Fold: 1  Epoch: 675  Training loss = 2.8492  Validation loss = 2.4734  \n",
      "\n",
      "Fold: 1  Epoch: 676  Training loss = 2.8489  Validation loss = 2.4724  \n",
      "\n",
      "Fold: 1  Epoch: 677  Training loss = 2.8487  Validation loss = 2.4717  \n",
      "\n",
      "Fold: 1  Epoch: 678  Training loss = 2.8484  Validation loss = 2.4708  \n",
      "\n",
      "Fold: 1  Epoch: 679  Training loss = 2.8483  Validation loss = 2.4704  \n",
      "\n",
      "Fold: 1  Epoch: 680  Training loss = 2.8479  Validation loss = 2.4694  \n",
      "\n",
      "Fold: 1  Epoch: 681  Training loss = 2.8477  Validation loss = 2.4685  \n",
      "\n",
      "Fold: 1  Epoch: 682  Training loss = 2.8473  Validation loss = 2.4675  \n",
      "\n",
      "Fold: 1  Epoch: 683  Training loss = 2.8470  Validation loss = 2.4663  \n",
      "\n",
      "Fold: 1  Epoch: 684  Training loss = 2.8467  Validation loss = 2.4656  \n",
      "\n",
      "Fold: 1  Epoch: 685  Training loss = 2.8464  Validation loss = 2.4647  \n",
      "\n",
      "Fold: 1  Epoch: 686  Training loss = 2.8462  Validation loss = 2.4639  \n",
      "\n",
      "Fold: 1  Epoch: 687  Training loss = 2.8461  Validation loss = 2.4635  \n",
      "\n",
      "Fold: 1  Epoch: 688  Training loss = 2.8459  Validation loss = 2.4630  \n",
      "\n",
      "Fold: 1  Epoch: 689  Training loss = 2.8456  Validation loss = 2.4620  \n",
      "\n",
      "Fold: 1  Epoch: 690  Training loss = 2.8454  Validation loss = 2.4612  \n",
      "\n",
      "Fold: 1  Epoch: 691  Training loss = 2.8451  Validation loss = 2.4603  \n",
      "\n",
      "Fold: 1  Epoch: 692  Training loss = 2.8449  Validation loss = 2.4597  \n",
      "\n",
      "Fold: 1  Epoch: 693  Training loss = 2.8447  Validation loss = 2.4589  \n",
      "\n",
      "Fold: 1  Epoch: 694  Training loss = 2.8445  Validation loss = 2.4583  \n",
      "\n",
      "Fold: 1  Epoch: 695  Training loss = 2.8441  Validation loss = 2.4572  \n",
      "\n",
      "Fold: 1  Epoch: 696  Training loss = 2.8439  Validation loss = 2.4564  \n",
      "\n",
      "Fold: 1  Epoch: 697  Training loss = 2.8437  Validation loss = 2.4558  \n",
      "\n",
      "Fold: 1  Epoch: 698  Training loss = 2.8434  Validation loss = 2.4547  \n",
      "\n",
      "Fold: 1  Epoch: 699  Training loss = 2.8432  Validation loss = 2.4542  \n",
      "\n",
      "Fold: 1  Epoch: 700  Training loss = 2.8429  Validation loss = 2.4534  \n",
      "\n",
      "Fold: 1  Epoch: 701  Training loss = 2.8428  Validation loss = 2.4529  \n",
      "\n",
      "Fold: 1  Epoch: 702  Training loss = 2.8425  Validation loss = 2.4520  \n",
      "\n",
      "Fold: 1  Epoch: 703  Training loss = 2.8424  Validation loss = 2.4516  \n",
      "\n",
      "Fold: 1  Epoch: 704  Training loss = 2.8421  Validation loss = 2.4507  \n",
      "\n",
      "Fold: 1  Epoch: 705  Training loss = 2.8419  Validation loss = 2.4500  \n",
      "\n",
      "Fold: 1  Epoch: 706  Training loss = 2.8416  Validation loss = 2.4490  \n",
      "\n",
      "Fold: 1  Epoch: 707  Training loss = 2.8412  Validation loss = 2.4480  \n",
      "\n",
      "Fold: 1  Epoch: 708  Training loss = 2.8410  Validation loss = 2.4470  \n",
      "\n",
      "Fold: 1  Epoch: 709  Training loss = 2.8405  Validation loss = 2.4456  \n",
      "\n",
      "Fold: 1  Epoch: 710  Training loss = 2.8404  Validation loss = 2.4452  \n",
      "\n",
      "Fold: 1  Epoch: 711  Training loss = 2.8403  Validation loss = 2.4448  \n",
      "\n",
      "Fold: 1  Epoch: 712  Training loss = 2.8401  Validation loss = 2.4443  \n",
      "\n",
      "Fold: 1  Epoch: 713  Training loss = 2.8398  Validation loss = 2.4434  \n",
      "\n",
      "Fold: 1  Epoch: 714  Training loss = 2.8397  Validation loss = 2.4428  \n",
      "\n",
      "Fold: 1  Epoch: 715  Training loss = 2.8396  Validation loss = 2.4425  \n",
      "\n",
      "Fold: 1  Epoch: 716  Training loss = 2.8394  Validation loss = 2.4418  \n",
      "\n",
      "Fold: 1  Epoch: 717  Training loss = 2.8392  Validation loss = 2.4412  \n",
      "\n",
      "Fold: 1  Epoch: 718  Training loss = 2.8391  Validation loss = 2.4410  \n",
      "\n",
      "Fold: 1  Epoch: 719  Training loss = 2.8390  Validation loss = 2.4405  \n",
      "\n",
      "Fold: 1  Epoch: 720  Training loss = 2.8387  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 1  Epoch: 721  Training loss = 2.8383  Validation loss = 2.4382  \n",
      "\n",
      "Fold: 1  Epoch: 722  Training loss = 2.8380  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 1  Epoch: 723  Training loss = 2.8377  Validation loss = 2.4364  \n",
      "\n",
      "Fold: 1  Epoch: 724  Training loss = 2.8375  Validation loss = 2.4355  \n",
      "\n",
      "Fold: 1  Epoch: 725  Training loss = 2.8371  Validation loss = 2.4344  \n",
      "\n",
      "Fold: 1  Epoch: 726  Training loss = 2.8368  Validation loss = 2.4334  \n",
      "\n",
      "Fold: 1  Epoch: 727  Training loss = 2.8366  Validation loss = 2.4326  \n",
      "\n",
      "Fold: 1  Epoch: 728  Training loss = 2.8364  Validation loss = 2.4322  \n",
      "\n",
      "Fold: 1  Epoch: 729  Training loss = 2.8362  Validation loss = 2.4314  \n",
      "\n",
      "Fold: 1  Epoch: 730  Training loss = 2.8360  Validation loss = 2.4307  \n",
      "\n",
      "Fold: 1  Epoch: 731  Training loss = 2.8357  Validation loss = 2.4296  \n",
      "\n",
      "Fold: 1  Epoch: 732  Training loss = 2.8354  Validation loss = 2.4286  \n",
      "\n",
      "Fold: 1  Epoch: 733  Training loss = 2.8352  Validation loss = 2.4279  \n",
      "\n",
      "Fold: 1  Epoch: 734  Training loss = 2.8349  Validation loss = 2.4270  \n",
      "\n",
      "Fold: 1  Epoch: 735  Training loss = 2.8347  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 1  Epoch: 736  Training loss = 2.8345  Validation loss = 2.4257  \n",
      "\n",
      "Fold: 1  Epoch: 737  Training loss = 2.8342  Validation loss = 2.4248  \n",
      "\n",
      "Fold: 1  Epoch: 738  Training loss = 2.8339  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 1  Epoch: 739  Training loss = 2.8338  Validation loss = 2.4233  \n",
      "\n",
      "Fold: 1  Epoch: 740  Training loss = 2.8334  Validation loss = 2.4221  \n",
      "\n",
      "Fold: 1  Epoch: 741  Training loss = 2.8332  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 1  Epoch: 742  Training loss = 2.8330  Validation loss = 2.4208  \n",
      "\n",
      "Fold: 1  Epoch: 743  Training loss = 2.8329  Validation loss = 2.4203  \n",
      "\n",
      "Fold: 1  Epoch: 744  Training loss = 2.8325  Validation loss = 2.4191  \n",
      "\n",
      "Fold: 1  Epoch: 745  Training loss = 2.8324  Validation loss = 2.4186  \n",
      "\n",
      "Fold: 1  Epoch: 746  Training loss = 2.8322  Validation loss = 2.4178  \n",
      "\n",
      "Fold: 1  Epoch: 747  Training loss = 2.8320  Validation loss = 2.4173  \n",
      "\n",
      "Fold: 1  Epoch: 748  Training loss = 2.8317  Validation loss = 2.4164  \n",
      "\n",
      "Fold: 1  Epoch: 749  Training loss = 2.8315  Validation loss = 2.4156  \n",
      "\n",
      "Fold: 1  Epoch: 750  Training loss = 2.8314  Validation loss = 2.4152  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 750  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.7472  Validation loss = 2.7276  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.7469  Validation loss = 2.7269  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.7466  Validation loss = 2.7261  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.7464  Validation loss = 2.7258  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.7463  Validation loss = 2.7254  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.7460  Validation loss = 2.7246  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.7459  Validation loss = 2.7242  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.7456  Validation loss = 2.7236  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.7454  Validation loss = 2.7230  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.7451  Validation loss = 2.7223  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.7448  Validation loss = 2.7218  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.7446  Validation loss = 2.7213  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.7443  Validation loss = 2.7205  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.7441  Validation loss = 2.7200  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.7440  Validation loss = 2.7196  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.7438  Validation loss = 2.7189  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.7436  Validation loss = 2.7184  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.7432  Validation loss = 2.7175  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.7431  Validation loss = 2.7170  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.7428  Validation loss = 2.7163  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.7425  Validation loss = 2.7156  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.7422  Validation loss = 2.7151  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.7420  Validation loss = 2.7144  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.7418  Validation loss = 2.7139  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.7415  Validation loss = 2.7133  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.7413  Validation loss = 2.7127  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.7411  Validation loss = 2.7122  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.7406  Validation loss = 2.7111  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.7402  Validation loss = 2.7102  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.7400  Validation loss = 2.7098  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.7398  Validation loss = 2.7092  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.7397  Validation loss = 2.7088  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.7395  Validation loss = 2.7083  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.7391  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.7389  Validation loss = 2.7069  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.7386  Validation loss = 2.7061  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.7385  Validation loss = 2.7057  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.7382  Validation loss = 2.7051  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.7379  Validation loss = 2.7044  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.7378  Validation loss = 2.7043  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.7377  Validation loss = 2.7039  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.7375  Validation loss = 2.7035  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.7371  Validation loss = 2.7027  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.7370  Validation loss = 2.7024  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.7368  Validation loss = 2.7019  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.7363  Validation loss = 2.7008  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.7361  Validation loss = 2.7002  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.7358  Validation loss = 2.6994  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.7356  Validation loss = 2.6988  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.7352  Validation loss = 2.6978  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.7349  Validation loss = 2.6971  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.7346  Validation loss = 2.6963  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.7343  Validation loss = 2.6957  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.7341  Validation loss = 2.6952  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.7340  Validation loss = 2.6948  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.7338  Validation loss = 2.6943  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.7336  Validation loss = 2.6935  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.7335  Validation loss = 2.6933  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.7333  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.7330  Validation loss = 2.6922  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.7327  Validation loss = 2.6914  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.7324  Validation loss = 2.6907  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.7323  Validation loss = 2.6903  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.7321  Validation loss = 2.6897  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.7319  Validation loss = 2.6894  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.7315  Validation loss = 2.6885  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.7313  Validation loss = 2.6880  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.7311  Validation loss = 2.6875  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.7309  Validation loss = 2.6868  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.7306  Validation loss = 2.6861  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.7301  Validation loss = 2.6849  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.7298  Validation loss = 2.6839  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.7295  Validation loss = 2.6834  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.7293  Validation loss = 2.6828  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.7290  Validation loss = 2.6822  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.7288  Validation loss = 2.6817  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.7285  Validation loss = 2.6809  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.7284  Validation loss = 2.6805  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.7280  Validation loss = 2.6796  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.7277  Validation loss = 2.6789  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.7275  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.7273  Validation loss = 2.6776  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.7271  Validation loss = 2.6768  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.7268  Validation loss = 2.6760  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.7267  Validation loss = 2.6756  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.7265  Validation loss = 2.6750  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.7262  Validation loss = 2.6743  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.7258  Validation loss = 2.6735  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.7257  Validation loss = 2.6729  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.7254  Validation loss = 2.6724  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.7252  Validation loss = 2.6718  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.7249  Validation loss = 2.6709  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.7246  Validation loss = 2.6702  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.7243  Validation loss = 2.6695  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.7241  Validation loss = 2.6690  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.7238  Validation loss = 2.6682  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.7236  Validation loss = 2.6677  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.7234  Validation loss = 2.6672  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.7233  Validation loss = 2.6669  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.7232  Validation loss = 2.6666  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.7230  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.7228  Validation loss = 2.6656  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.7225  Validation loss = 2.6648  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.7223  Validation loss = 2.6643  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.7222  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.7218  Validation loss = 2.6630  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.7215  Validation loss = 2.6622  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.7214  Validation loss = 2.6619  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.7212  Validation loss = 2.6613  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.7210  Validation loss = 2.6606  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.7209  Validation loss = 2.6603  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.7206  Validation loss = 2.6597  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.7204  Validation loss = 2.6592  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.7203  Validation loss = 2.6586  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.7200  Validation loss = 2.6578  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.7199  Validation loss = 2.6574  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.7196  Validation loss = 2.6568  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.7196  Validation loss = 2.6567  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.7193  Validation loss = 2.6559  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.7192  Validation loss = 2.6554  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.7189  Validation loss = 2.6547  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.7187  Validation loss = 2.6543  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.7185  Validation loss = 2.6537  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.7184  Validation loss = 2.6536  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.7181  Validation loss = 2.6528  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.7179  Validation loss = 2.6524  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.7176  Validation loss = 2.6517  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.7174  Validation loss = 2.6512  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.7170  Validation loss = 2.6502  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.7168  Validation loss = 2.6496  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.7167  Validation loss = 2.6492  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.7164  Validation loss = 2.6483  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.7162  Validation loss = 2.6478  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.7161  Validation loss = 2.6474  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.7156  Validation loss = 2.6465  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.7155  Validation loss = 2.6461  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.7154  Validation loss = 2.6458  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.7151  Validation loss = 2.6452  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.7149  Validation loss = 2.6447  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.7147  Validation loss = 2.6440  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.7145  Validation loss = 2.6436  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.7143  Validation loss = 2.6430  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.7140  Validation loss = 2.6423  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.7138  Validation loss = 2.6419  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.7138  Validation loss = 2.6416  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.7136  Validation loss = 2.6411  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.7132  Validation loss = 2.6402  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.7129  Validation loss = 2.6393  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.7127  Validation loss = 2.6388  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.7124  Validation loss = 2.6381  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.7122  Validation loss = 2.6375  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.7120  Validation loss = 2.6367  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.7115  Validation loss = 2.6356  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.7112  Validation loss = 2.6347  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.7109  Validation loss = 2.6340  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.7107  Validation loss = 2.6335  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.7106  Validation loss = 2.6330  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.7105  Validation loss = 2.6328  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.7101  Validation loss = 2.6317  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.7098  Validation loss = 2.6311  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.7095  Validation loss = 2.6303  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.7093  Validation loss = 2.6297  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.7092  Validation loss = 2.6293  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.7090  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.7089  Validation loss = 2.6284  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.7087  Validation loss = 2.6278  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.7084  Validation loss = 2.6273  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.7082  Validation loss = 2.6266  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.7079  Validation loss = 2.6257  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.7078  Validation loss = 2.6253  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.7076  Validation loss = 2.6247  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.7074  Validation loss = 2.6242  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.7072  Validation loss = 2.6239  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.7070  Validation loss = 2.6234  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.7066  Validation loss = 2.6224  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.7064  Validation loss = 2.6217  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.7061  Validation loss = 2.6209  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.7057  Validation loss = 2.6200  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.7055  Validation loss = 2.6194  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.7053  Validation loss = 2.6188  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.7052  Validation loss = 2.6185  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.7050  Validation loss = 2.6180  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.7049  Validation loss = 2.6175  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.7048  Validation loss = 2.6172  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.7046  Validation loss = 2.6168  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.7045  Validation loss = 2.6163  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.7043  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.7041  Validation loss = 2.6151  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.7039  Validation loss = 2.6146  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.7036  Validation loss = 2.6138  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.7034  Validation loss = 2.6133  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.7031  Validation loss = 2.6127  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.7030  Validation loss = 2.6122  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.7027  Validation loss = 2.6116  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.7025  Validation loss = 2.6110  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.7024  Validation loss = 2.6106  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.7022  Validation loss = 2.6100  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.7020  Validation loss = 2.6095  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.7017  Validation loss = 2.6089  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.7015  Validation loss = 2.6084  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.7014  Validation loss = 2.6079  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.7012  Validation loss = 2.6075  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.7009  Validation loss = 2.6066  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.7008  Validation loss = 2.6061  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.7006  Validation loss = 2.6056  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.7003  Validation loss = 2.6048  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.7000  Validation loss = 2.6041  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.6997  Validation loss = 2.6032  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.6994  Validation loss = 2.6024  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.6992  Validation loss = 2.6018  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.6990  Validation loss = 2.6011  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.6987  Validation loss = 2.6006  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.6986  Validation loss = 2.6001  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.6985  Validation loss = 2.5998  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.6983  Validation loss = 2.5993  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.6980  Validation loss = 2.5985  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.6979  Validation loss = 2.5981  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.6978  Validation loss = 2.5978  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.6976  Validation loss = 2.5973  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.6975  Validation loss = 2.5968  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.6973  Validation loss = 2.5964  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.6971  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.6970  Validation loss = 2.5952  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.6969  Validation loss = 2.5949  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.6967  Validation loss = 2.5942  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.6965  Validation loss = 2.5936  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.6963  Validation loss = 2.5930  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.6961  Validation loss = 2.5925  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.6960  Validation loss = 2.5922  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.6959  Validation loss = 2.5917  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.6956  Validation loss = 2.5911  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.6955  Validation loss = 2.5908  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.6953  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.6950  Validation loss = 2.5895  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.6948  Validation loss = 2.5889  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.6946  Validation loss = 2.5881  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.6944  Validation loss = 2.5877  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.6942  Validation loss = 2.5870  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.6940  Validation loss = 2.5864  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.6939  Validation loss = 2.5861  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.6937  Validation loss = 2.5857  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.6935  Validation loss = 2.5850  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.6931  Validation loss = 2.5842  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.6929  Validation loss = 2.5835  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.6928  Validation loss = 2.5829  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.6924  Validation loss = 2.5820  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.6923  Validation loss = 2.5816  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.6921  Validation loss = 2.5812  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.6920  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.6918  Validation loss = 2.5802  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.6916  Validation loss = 2.5796  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.6914  Validation loss = 2.5790  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.6911  Validation loss = 2.5782  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.6909  Validation loss = 2.5776  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.6907  Validation loss = 2.5771  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.6905  Validation loss = 2.5767  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.6905  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.6903  Validation loss = 2.5759  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.6901  Validation loss = 2.5752  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.6900  Validation loss = 2.5749  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.6898  Validation loss = 2.5743  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.6894  Validation loss = 2.5731  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.6891  Validation loss = 2.5724  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.6889  Validation loss = 2.5716  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.6887  Validation loss = 2.5711  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.6886  Validation loss = 2.5707  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.6884  Validation loss = 2.5700  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.6882  Validation loss = 2.5695  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.6880  Validation loss = 2.5689  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.6878  Validation loss = 2.5686  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.6876  Validation loss = 2.5681  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.6875  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.6874  Validation loss = 2.5673  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.6874  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.6872  Validation loss = 2.5666  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.6868  Validation loss = 2.5658  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.6867  Validation loss = 2.5651  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.6866  Validation loss = 2.5649  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.6865  Validation loss = 2.5646  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.6863  Validation loss = 2.5642  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.6860  Validation loss = 2.5634  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.6859  Validation loss = 2.5629  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.6856  Validation loss = 2.5623  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.6854  Validation loss = 2.5617  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.6852  Validation loss = 2.5612  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.6849  Validation loss = 2.5603  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.6848  Validation loss = 2.5599  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.6848  Validation loss = 2.5597  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.6846  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.6845  Validation loss = 2.5588  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.6843  Validation loss = 2.5583  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.6842  Validation loss = 2.5579  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.6840  Validation loss = 2.5574  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.6840  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.6839  Validation loss = 2.5570  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.6836  Validation loss = 2.5561  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.6836  Validation loss = 2.5561  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.6833  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.6832  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.6830  Validation loss = 2.5543  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.6828  Validation loss = 2.5538  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.6827  Validation loss = 2.5534  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.6824  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.6823  Validation loss = 2.5520  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.6821  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.6818  Validation loss = 2.5507  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.6815  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.6813  Validation loss = 2.5491  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.6811  Validation loss = 2.5485  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.6809  Validation loss = 2.5479  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.6807  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.6806  Validation loss = 2.5466  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.6805  Validation loss = 2.5464  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.6802  Validation loss = 2.5455  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.6802  Validation loss = 2.5455  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.6799  Validation loss = 2.5446  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.6797  Validation loss = 2.5441  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.6796  Validation loss = 2.5438  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.6795  Validation loss = 2.5432  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.6794  Validation loss = 2.5428  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.6792  Validation loss = 2.5423  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.6790  Validation loss = 2.5417  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.6789  Validation loss = 2.5413  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.6788  Validation loss = 2.5409  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.6787  Validation loss = 2.5405  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.6785  Validation loss = 2.5400  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.6783  Validation loss = 2.5394  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.6782  Validation loss = 2.5389  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.6780  Validation loss = 2.5384  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.6779  Validation loss = 2.5382  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.6778  Validation loss = 2.5377  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.6776  Validation loss = 2.5371  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.6775  Validation loss = 2.5369  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.6774  Validation loss = 2.5364  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.6773  Validation loss = 2.5359  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.6771  Validation loss = 2.5355  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.6769  Validation loss = 2.5348  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.6767  Validation loss = 2.5341  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.6766  Validation loss = 2.5338  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.6765  Validation loss = 2.5335  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.6764  Validation loss = 2.5331  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.6763  Validation loss = 2.5326  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.6762  Validation loss = 2.5322  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.6759  Validation loss = 2.5315  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.6757  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.6755  Validation loss = 2.5301  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.6754  Validation loss = 2.5296  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.6752  Validation loss = 2.5291  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.6750  Validation loss = 2.5286  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.6748  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.6746  Validation loss = 2.5272  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.6743  Validation loss = 2.5263  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.6741  Validation loss = 2.5260  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.6740  Validation loss = 2.5255  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.6738  Validation loss = 2.5249  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.6735  Validation loss = 2.5243  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.6733  Validation loss = 2.5236  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.6731  Validation loss = 2.5230  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.6731  Validation loss = 2.5228  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.6730  Validation loss = 2.5225  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.6729  Validation loss = 2.5221  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.6728  Validation loss = 2.5218  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.6727  Validation loss = 2.5214  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.6725  Validation loss = 2.5209  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.6725  Validation loss = 2.5206  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.6723  Validation loss = 2.5200  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.6721  Validation loss = 2.5194  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.6720  Validation loss = 2.5190  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.6719  Validation loss = 2.5188  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.6718  Validation loss = 2.5182  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.6716  Validation loss = 2.5177  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.6715  Validation loss = 2.5174  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.6713  Validation loss = 2.5168  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.6710  Validation loss = 2.5158  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.6709  Validation loss = 2.5154  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.6708  Validation loss = 2.5148  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.6706  Validation loss = 2.5142  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.6704  Validation loss = 2.5137  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.6703  Validation loss = 2.5131  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.6702  Validation loss = 2.5129  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.6701  Validation loss = 2.5126  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.6700  Validation loss = 2.5123  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.6699  Validation loss = 2.5118  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.6698  Validation loss = 2.5113  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.6696  Validation loss = 2.5109  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.6695  Validation loss = 2.5105  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.6693  Validation loss = 2.5100  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.6692  Validation loss = 2.5097  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.6691  Validation loss = 2.5092  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.6689  Validation loss = 2.5085  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.6688  Validation loss = 2.5082  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.6686  Validation loss = 2.5077  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.6685  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.6684  Validation loss = 2.5071  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.6683  Validation loss = 2.5067  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.6681  Validation loss = 2.5059  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.6679  Validation loss = 2.5057  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.6678  Validation loss = 2.5051  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.6675  Validation loss = 2.5044  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.6674  Validation loss = 2.5041  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.6672  Validation loss = 2.5036  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.6671  Validation loss = 2.5032  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.6669  Validation loss = 2.5025  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.6667  Validation loss = 2.5022  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.6666  Validation loss = 2.5017  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.6665  Validation loss = 2.5016  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.6664  Validation loss = 2.5013  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.6662  Validation loss = 2.5006  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.6660  Validation loss = 2.5001  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.6659  Validation loss = 2.4996  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.6657  Validation loss = 2.4991  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.6656  Validation loss = 2.4988  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.6654  Validation loss = 2.4982  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.6652  Validation loss = 2.4976  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.6650  Validation loss = 2.4970  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.6648  Validation loss = 2.4963  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.6645  Validation loss = 2.4955  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.6644  Validation loss = 2.4950  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.6642  Validation loss = 2.4946  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.6642  Validation loss = 2.4943  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.6641  Validation loss = 2.4940  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.6639  Validation loss = 2.4933  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.6637  Validation loss = 2.4928  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.6636  Validation loss = 2.4922  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.6634  Validation loss = 2.4917  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.6633  Validation loss = 2.4914  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.6632  Validation loss = 2.4910  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.6631  Validation loss = 2.4905  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.6630  Validation loss = 2.4902  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.6629  Validation loss = 2.4898  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.6627  Validation loss = 2.4892  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.6627  Validation loss = 2.4890  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.6625  Validation loss = 2.4887  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.6624  Validation loss = 2.4882  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.6622  Validation loss = 2.4875  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.6620  Validation loss = 2.4871  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.6619  Validation loss = 2.4866  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.6618  Validation loss = 2.4861  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.6617  Validation loss = 2.4858  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.6617  Validation loss = 2.4855  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.6616  Validation loss = 2.4852  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.6615  Validation loss = 2.4848  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.6614  Validation loss = 2.4845  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.6613  Validation loss = 2.4840  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.6611  Validation loss = 2.4834  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.6609  Validation loss = 2.4828  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.6608  Validation loss = 2.4822  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.6607  Validation loss = 2.4818  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.6605  Validation loss = 2.4815  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.6604  Validation loss = 2.4810  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.6604  Validation loss = 2.4807  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.6602  Validation loss = 2.4803  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.6601  Validation loss = 2.4798  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.6599  Validation loss = 2.4793  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.6598  Validation loss = 2.4791  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.6597  Validation loss = 2.4789  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.6596  Validation loss = 2.4785  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.6595  Validation loss = 2.4782  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.6595  Validation loss = 2.4780  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.6593  Validation loss = 2.4775  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.6593  Validation loss = 2.4773  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.6592  Validation loss = 2.4768  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.6590  Validation loss = 2.4764  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.6587  Validation loss = 2.4755  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.6587  Validation loss = 2.4753  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.6585  Validation loss = 2.4748  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.6583  Validation loss = 2.4743  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.6582  Validation loss = 2.4737  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.6581  Validation loss = 2.4733  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.6579  Validation loss = 2.4728  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.6578  Validation loss = 2.4724  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.6577  Validation loss = 2.4720  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.6576  Validation loss = 2.4716  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.6574  Validation loss = 2.4710  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.6573  Validation loss = 2.4706  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.6571  Validation loss = 2.4701  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.6569  Validation loss = 2.4694  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.6568  Validation loss = 2.4688  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.6567  Validation loss = 2.4685  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.6566  Validation loss = 2.4683  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.6565  Validation loss = 2.4678  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.6563  Validation loss = 2.4672  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.6561  Validation loss = 2.4667  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.6560  Validation loss = 2.4663  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.6557  Validation loss = 2.4656  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.6556  Validation loss = 2.4651  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.6555  Validation loss = 2.4647  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.6554  Validation loss = 2.4642  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.6553  Validation loss = 2.4638  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.6552  Validation loss = 2.4636  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.6551  Validation loss = 2.4633  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.6550  Validation loss = 2.4631  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.6548  Validation loss = 2.4622  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.6547  Validation loss = 2.4619  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.6544  Validation loss = 2.4611  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.6543  Validation loss = 2.4610  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.6544  Validation loss = 2.4611  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.6542  Validation loss = 2.4605  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.6540  Validation loss = 2.4595  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.6539  Validation loss = 2.4591  \n",
      "\n",
      "Fold: 2  Epoch: 501  Training loss = 2.6537  Validation loss = 2.4585  \n",
      "\n",
      "Fold: 2  Epoch: 502  Training loss = 2.6536  Validation loss = 2.4581  \n",
      "\n",
      "Fold: 2  Epoch: 503  Training loss = 2.6534  Validation loss = 2.4574  \n",
      "\n",
      "Fold: 2  Epoch: 504  Training loss = 2.6533  Validation loss = 2.4571  \n",
      "\n",
      "Fold: 2  Epoch: 505  Training loss = 2.6533  Validation loss = 2.4571  \n",
      "\n",
      "Fold: 2  Epoch: 506  Training loss = 2.6531  Validation loss = 2.4563  \n",
      "\n",
      "Fold: 2  Epoch: 507  Training loss = 2.6530  Validation loss = 2.4559  \n",
      "\n",
      "Fold: 2  Epoch: 508  Training loss = 2.6528  Validation loss = 2.4551  \n",
      "\n",
      "Fold: 2  Epoch: 509  Training loss = 2.6527  Validation loss = 2.4548  \n",
      "\n",
      "Fold: 2  Epoch: 510  Training loss = 2.6525  Validation loss = 2.4542  \n",
      "\n",
      "Fold: 2  Epoch: 511  Training loss = 2.6524  Validation loss = 2.4537  \n",
      "\n",
      "Fold: 2  Epoch: 512  Training loss = 2.6523  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 2  Epoch: 513  Training loss = 2.6522  Validation loss = 2.4531  \n",
      "\n",
      "Fold: 2  Epoch: 514  Training loss = 2.6521  Validation loss = 2.4527  \n",
      "\n",
      "Fold: 2  Epoch: 515  Training loss = 2.6519  Validation loss = 2.4523  \n",
      "\n",
      "Fold: 2  Epoch: 516  Training loss = 2.6519  Validation loss = 2.4519  \n",
      "\n",
      "Fold: 2  Epoch: 517  Training loss = 2.6517  Validation loss = 2.4514  \n",
      "\n",
      "Fold: 2  Epoch: 518  Training loss = 2.6515  Validation loss = 2.4509  \n",
      "\n",
      "Fold: 2  Epoch: 519  Training loss = 2.6515  Validation loss = 2.4506  \n",
      "\n",
      "Fold: 2  Epoch: 520  Training loss = 2.6514  Validation loss = 2.4502  \n",
      "\n",
      "Fold: 2  Epoch: 521  Training loss = 2.6512  Validation loss = 2.4495  \n",
      "\n",
      "Fold: 2  Epoch: 522  Training loss = 2.6509  Validation loss = 2.4485  \n",
      "\n",
      "Fold: 2  Epoch: 523  Training loss = 2.6507  Validation loss = 2.4478  \n",
      "\n",
      "Fold: 2  Epoch: 524  Training loss = 2.6506  Validation loss = 2.4473  \n",
      "\n",
      "Fold: 2  Epoch: 525  Training loss = 2.6504  Validation loss = 2.4468  \n",
      "\n",
      "Fold: 2  Epoch: 526  Training loss = 2.6503  Validation loss = 2.4464  \n",
      "\n",
      "Fold: 2  Epoch: 527  Training loss = 2.6501  Validation loss = 2.4455  \n",
      "\n",
      "Fold: 2  Epoch: 528  Training loss = 2.6499  Validation loss = 2.4449  \n",
      "\n",
      "Fold: 2  Epoch: 529  Training loss = 2.6498  Validation loss = 2.4446  \n",
      "\n",
      "Fold: 2  Epoch: 530  Training loss = 2.6496  Validation loss = 2.4438  \n",
      "\n",
      "Fold: 2  Epoch: 531  Training loss = 2.6495  Validation loss = 2.4435  \n",
      "\n",
      "Fold: 2  Epoch: 532  Training loss = 2.6494  Validation loss = 2.4431  \n",
      "\n",
      "Fold: 2  Epoch: 533  Training loss = 2.6491  Validation loss = 2.4424  \n",
      "\n",
      "Fold: 2  Epoch: 534  Training loss = 2.6490  Validation loss = 2.4418  \n",
      "\n",
      "Fold: 2  Epoch: 535  Training loss = 2.6488  Validation loss = 2.4413  \n",
      "\n",
      "Fold: 2  Epoch: 536  Training loss = 2.6488  Validation loss = 2.4410  \n",
      "\n",
      "Fold: 2  Epoch: 537  Training loss = 2.6487  Validation loss = 2.4407  \n",
      "\n",
      "Fold: 2  Epoch: 538  Training loss = 2.6485  Validation loss = 2.4401  \n",
      "\n",
      "Fold: 2  Epoch: 539  Training loss = 2.6483  Validation loss = 2.4395  \n",
      "\n",
      "Fold: 2  Epoch: 540  Training loss = 2.6481  Validation loss = 2.4386  \n",
      "\n",
      "Fold: 2  Epoch: 541  Training loss = 2.6479  Validation loss = 2.4380  \n",
      "\n",
      "Fold: 2  Epoch: 542  Training loss = 2.6478  Validation loss = 2.4375  \n",
      "\n",
      "Fold: 2  Epoch: 543  Training loss = 2.6476  Validation loss = 2.4371  \n",
      "\n",
      "Fold: 2  Epoch: 544  Training loss = 2.6476  Validation loss = 2.4367  \n",
      "\n",
      "Fold: 2  Epoch: 545  Training loss = 2.6476  Validation loss = 2.4368  \n",
      "\n",
      "Fold: 2  Epoch: 546  Training loss = 2.6474  Validation loss = 2.4363  \n",
      "\n",
      "Fold: 2  Epoch: 547  Training loss = 2.6472  Validation loss = 2.4357  \n",
      "\n",
      "Fold: 2  Epoch: 548  Training loss = 2.6472  Validation loss = 2.4355  \n",
      "\n",
      "Fold: 2  Epoch: 549  Training loss = 2.6470  Validation loss = 2.4350  \n",
      "\n",
      "Fold: 2  Epoch: 550  Training loss = 2.6469  Validation loss = 2.4345  \n",
      "\n",
      "Fold: 2  Epoch: 551  Training loss = 2.6468  Validation loss = 2.4340  \n",
      "\n",
      "Fold: 2  Epoch: 552  Training loss = 2.6466  Validation loss = 2.4333  \n",
      "\n",
      "Fold: 2  Epoch: 553  Training loss = 2.6463  Validation loss = 2.4323  \n",
      "\n",
      "Fold: 2  Epoch: 554  Training loss = 2.6462  Validation loss = 2.4316  \n",
      "\n",
      "Fold: 2  Epoch: 555  Training loss = 2.6461  Validation loss = 2.4312  \n",
      "\n",
      "Fold: 2  Epoch: 556  Training loss = 2.6459  Validation loss = 2.4306  \n",
      "\n",
      "Fold: 2  Epoch: 557  Training loss = 2.6459  Validation loss = 2.4305  \n",
      "\n",
      "Fold: 2  Epoch: 558  Training loss = 2.6458  Validation loss = 2.4299  \n",
      "\n",
      "Fold: 2  Epoch: 559  Training loss = 2.6456  Validation loss = 2.4294  \n",
      "\n",
      "Fold: 2  Epoch: 560  Training loss = 2.6455  Validation loss = 2.4289  \n",
      "\n",
      "Fold: 2  Epoch: 561  Training loss = 2.6454  Validation loss = 2.4284  \n",
      "\n",
      "Fold: 2  Epoch: 562  Training loss = 2.6453  Validation loss = 2.4280  \n",
      "\n",
      "Fold: 2  Epoch: 563  Training loss = 2.6452  Validation loss = 2.4274  \n",
      "\n",
      "Fold: 2  Epoch: 564  Training loss = 2.6450  Validation loss = 2.4268  \n",
      "\n",
      "Fold: 2  Epoch: 565  Training loss = 2.6448  Validation loss = 2.4263  \n",
      "\n",
      "Fold: 2  Epoch: 566  Training loss = 2.6446  Validation loss = 2.4255  \n",
      "\n",
      "Fold: 2  Epoch: 567  Training loss = 2.6445  Validation loss = 2.4253  \n",
      "\n",
      "Fold: 2  Epoch: 568  Training loss = 2.6444  Validation loss = 2.4248  \n",
      "\n",
      "Fold: 2  Epoch: 569  Training loss = 2.6443  Validation loss = 2.4243  \n",
      "\n",
      "Fold: 2  Epoch: 570  Training loss = 2.6441  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 2  Epoch: 571  Training loss = 2.6439  Validation loss = 2.4230  \n",
      "\n",
      "Fold: 2  Epoch: 572  Training loss = 2.6438  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 2  Epoch: 573  Training loss = 2.6438  Validation loss = 2.4223  \n",
      "\n",
      "Fold: 2  Epoch: 574  Training loss = 2.6437  Validation loss = 2.4222  \n",
      "\n",
      "Fold: 2  Epoch: 575  Training loss = 2.6436  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 2  Epoch: 576  Training loss = 2.6436  Validation loss = 2.4215  \n",
      "\n",
      "Fold: 2  Epoch: 577  Training loss = 2.6435  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 2  Epoch: 578  Training loss = 2.6435  Validation loss = 2.4210  \n",
      "\n",
      "Fold: 2  Epoch: 579  Training loss = 2.6434  Validation loss = 2.4206  \n",
      "\n",
      "Fold: 2  Epoch: 580  Training loss = 2.6432  Validation loss = 2.4202  \n",
      "\n",
      "Fold: 2  Epoch: 581  Training loss = 2.6431  Validation loss = 2.4196  \n",
      "\n",
      "Fold: 2  Epoch: 582  Training loss = 2.6430  Validation loss = 2.4194  \n",
      "\n",
      "Fold: 2  Epoch: 583  Training loss = 2.6429  Validation loss = 2.4190  \n",
      "\n",
      "Fold: 2  Epoch: 584  Training loss = 2.6427  Validation loss = 2.4182  \n",
      "\n",
      "Fold: 2  Epoch: 585  Training loss = 2.6427  Validation loss = 2.4178  \n",
      "\n",
      "Fold: 2  Epoch: 586  Training loss = 2.6425  Validation loss = 2.4172  \n",
      "\n",
      "Fold: 2  Epoch: 587  Training loss = 2.6424  Validation loss = 2.4166  \n",
      "\n",
      "Fold: 2  Epoch: 588  Training loss = 2.6422  Validation loss = 2.4160  \n",
      "\n",
      "Fold: 2  Epoch: 589  Training loss = 2.6422  Validation loss = 2.4159  \n",
      "\n",
      "Fold: 2  Epoch: 590  Training loss = 2.6420  Validation loss = 2.4153  \n",
      "\n",
      "Fold: 2  Epoch: 591  Training loss = 2.6418  Validation loss = 2.4150  \n",
      "\n",
      "Fold: 2  Epoch: 592  Training loss = 2.6417  Validation loss = 2.4144  \n",
      "\n",
      "Fold: 2  Epoch: 593  Training loss = 2.6416  Validation loss = 2.4140  \n",
      "\n",
      "Fold: 2  Epoch: 594  Training loss = 2.6414  Validation loss = 2.4133  \n",
      "\n",
      "Fold: 2  Epoch: 595  Training loss = 2.6413  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 2  Epoch: 596  Training loss = 2.6412  Validation loss = 2.4125  \n",
      "\n",
      "Fold: 2  Epoch: 597  Training loss = 2.6410  Validation loss = 2.4120  \n",
      "\n",
      "Fold: 2  Epoch: 598  Training loss = 2.6410  Validation loss = 2.4119  \n",
      "\n",
      "Fold: 2  Epoch: 599  Training loss = 2.6410  Validation loss = 2.4116  \n",
      "\n",
      "Fold: 2  Epoch: 600  Training loss = 2.6409  Validation loss = 2.4110  \n",
      "\n",
      "Fold: 2  Epoch: 601  Training loss = 2.6408  Validation loss = 2.4107  \n",
      "\n",
      "Fold: 2  Epoch: 602  Training loss = 2.6407  Validation loss = 2.4102  \n",
      "\n",
      "Fold: 2  Epoch: 603  Training loss = 2.6406  Validation loss = 2.4098  \n",
      "\n",
      "Fold: 2  Epoch: 604  Training loss = 2.6404  Validation loss = 2.4092  \n",
      "\n",
      "Fold: 2  Epoch: 605  Training loss = 2.6403  Validation loss = 2.4087  \n",
      "\n",
      "Fold: 2  Epoch: 606  Training loss = 2.6401  Validation loss = 2.4082  \n",
      "\n",
      "Fold: 2  Epoch: 607  Training loss = 2.6401  Validation loss = 2.4080  \n",
      "\n",
      "Fold: 2  Epoch: 608  Training loss = 2.6400  Validation loss = 2.4078  \n",
      "\n",
      "Fold: 2  Epoch: 609  Training loss = 2.6400  Validation loss = 2.4075  \n",
      "\n",
      "Fold: 2  Epoch: 610  Training loss = 2.6399  Validation loss = 2.4070  \n",
      "\n",
      "Fold: 2  Epoch: 611  Training loss = 2.6399  Validation loss = 2.4069  \n",
      "\n",
      "Fold: 2  Epoch: 612  Training loss = 2.6397  Validation loss = 2.4063  \n",
      "\n",
      "Fold: 2  Epoch: 613  Training loss = 2.6395  Validation loss = 2.4056  \n",
      "\n",
      "Fold: 2  Epoch: 614  Training loss = 2.6395  Validation loss = 2.4054  \n",
      "\n",
      "Fold: 2  Epoch: 615  Training loss = 2.6395  Validation loss = 2.4053  \n",
      "\n",
      "Fold: 2  Epoch: 616  Training loss = 2.6395  Validation loss = 2.4052  \n",
      "\n",
      "Fold: 2  Epoch: 617  Training loss = 2.6394  Validation loss = 2.4049  \n",
      "\n",
      "Fold: 2  Epoch: 618  Training loss = 2.6393  Validation loss = 2.4044  \n",
      "\n",
      "Fold: 2  Epoch: 619  Training loss = 2.6392  Validation loss = 2.4037  \n",
      "\n",
      "Fold: 2  Epoch: 620  Training loss = 2.6391  Validation loss = 2.4034  \n",
      "\n",
      "Fold: 2  Epoch: 621  Training loss = 2.6390  Validation loss = 2.4034  \n",
      "\n",
      "Fold: 2  Epoch: 622  Training loss = 2.6388  Validation loss = 2.4026  \n",
      "\n",
      "Fold: 2  Epoch: 623  Training loss = 2.6387  Validation loss = 2.4020  \n",
      "\n",
      "Fold: 2  Epoch: 624  Training loss = 2.6385  Validation loss = 2.4013  \n",
      "\n",
      "Fold: 2  Epoch: 625  Training loss = 2.6384  Validation loss = 2.4009  \n",
      "\n",
      "Fold: 2  Epoch: 626  Training loss = 2.6384  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 2  Epoch: 627  Training loss = 2.6383  Validation loss = 2.4003  \n",
      "\n",
      "Fold: 2  Epoch: 628  Training loss = 2.6382  Validation loss = 2.4001  \n",
      "\n",
      "Fold: 2  Epoch: 629  Training loss = 2.6381  Validation loss = 2.3996  \n",
      "\n",
      "Fold: 2  Epoch: 630  Training loss = 2.6379  Validation loss = 2.3991  \n",
      "\n",
      "Fold: 2  Epoch: 631  Training loss = 2.6379  Validation loss = 2.3988  \n",
      "\n",
      "Fold: 2  Epoch: 632  Training loss = 2.6379  Validation loss = 2.3988  \n",
      "\n",
      "Fold: 2  Epoch: 633  Training loss = 2.6377  Validation loss = 2.3982  \n",
      "\n",
      "Fold: 2  Epoch: 634  Training loss = 2.6377  Validation loss = 2.3978  \n",
      "\n",
      "Fold: 2  Epoch: 635  Training loss = 2.6376  Validation loss = 2.3976  \n",
      "\n",
      "Fold: 2  Epoch: 636  Training loss = 2.6375  Validation loss = 2.3972  \n",
      "\n",
      "Fold: 2  Epoch: 637  Training loss = 2.6374  Validation loss = 2.3967  \n",
      "\n",
      "Fold: 2  Epoch: 638  Training loss = 2.6373  Validation loss = 2.3962  \n",
      "\n",
      "Fold: 2  Epoch: 639  Training loss = 2.6372  Validation loss = 2.3959  \n",
      "\n",
      "Fold: 2  Epoch: 640  Training loss = 2.6370  Validation loss = 2.3952  \n",
      "\n",
      "Fold: 2  Epoch: 641  Training loss = 2.6369  Validation loss = 2.3949  \n",
      "\n",
      "Fold: 2  Epoch: 642  Training loss = 2.6367  Validation loss = 2.3940  \n",
      "\n",
      "Fold: 2  Epoch: 643  Training loss = 2.6366  Validation loss = 2.3938  \n",
      "\n",
      "Fold: 2  Epoch: 644  Training loss = 2.6365  Validation loss = 2.3932  \n",
      "\n",
      "Fold: 2  Epoch: 645  Training loss = 2.6364  Validation loss = 2.3929  \n",
      "\n",
      "Fold: 2  Epoch: 646  Training loss = 2.6364  Validation loss = 2.3928  \n",
      "\n",
      "Fold: 2  Epoch: 647  Training loss = 2.6362  Validation loss = 2.3923  \n",
      "\n",
      "Fold: 2  Epoch: 648  Training loss = 2.6361  Validation loss = 2.3916  \n",
      "\n",
      "Fold: 2  Epoch: 649  Training loss = 2.6359  Validation loss = 2.3910  \n",
      "\n",
      "Fold: 2  Epoch: 650  Training loss = 2.6358  Validation loss = 2.3906  \n",
      "\n",
      "Fold: 2  Epoch: 651  Training loss = 2.6357  Validation loss = 2.3902  \n",
      "\n",
      "Fold: 2  Epoch: 652  Training loss = 2.6357  Validation loss = 2.3899  \n",
      "\n",
      "Fold: 2  Epoch: 653  Training loss = 2.6354  Validation loss = 2.3891  \n",
      "\n",
      "Fold: 2  Epoch: 654  Training loss = 2.6353  Validation loss = 2.3885  \n",
      "\n",
      "Fold: 2  Epoch: 655  Training loss = 2.6351  Validation loss = 2.3880  \n",
      "\n",
      "Fold: 2  Epoch: 656  Training loss = 2.6349  Validation loss = 2.3872  \n",
      "\n",
      "Fold: 2  Epoch: 657  Training loss = 2.6348  Validation loss = 2.3868  \n",
      "\n",
      "Fold: 2  Epoch: 658  Training loss = 2.6348  Validation loss = 2.3866  \n",
      "\n",
      "Fold: 2  Epoch: 659  Training loss = 2.6346  Validation loss = 2.3858  \n",
      "\n",
      "Fold: 2  Epoch: 660  Training loss = 2.6345  Validation loss = 2.3857  \n",
      "\n",
      "Fold: 2  Epoch: 661  Training loss = 2.6344  Validation loss = 2.3854  \n",
      "\n",
      "Fold: 2  Epoch: 662  Training loss = 2.6342  Validation loss = 2.3846  \n",
      "\n",
      "Fold: 2  Epoch: 663  Training loss = 2.6342  Validation loss = 2.3843  \n",
      "\n",
      "Fold: 2  Epoch: 664  Training loss = 2.6342  Validation loss = 2.3842  \n",
      "\n",
      "Fold: 2  Epoch: 665  Training loss = 2.6341  Validation loss = 2.3841  \n",
      "\n",
      "Fold: 2  Epoch: 666  Training loss = 2.6341  Validation loss = 2.3838  \n",
      "\n",
      "Fold: 2  Epoch: 667  Training loss = 2.6340  Validation loss = 2.3836  \n",
      "\n",
      "Fold: 2  Epoch: 668  Training loss = 2.6338  Validation loss = 2.3828  \n",
      "\n",
      "Fold: 2  Epoch: 669  Training loss = 2.6338  Validation loss = 2.3828  \n",
      "\n",
      "Fold: 2  Epoch: 670  Training loss = 2.6337  Validation loss = 2.3825  \n",
      "\n",
      "Fold: 2  Epoch: 671  Training loss = 2.6336  Validation loss = 2.3823  \n",
      "\n",
      "Fold: 2  Epoch: 672  Training loss = 2.6335  Validation loss = 2.3817  \n",
      "\n",
      "Fold: 2  Epoch: 673  Training loss = 2.6334  Validation loss = 2.3813  \n",
      "\n",
      "Fold: 2  Epoch: 674  Training loss = 2.6333  Validation loss = 2.3810  \n",
      "\n",
      "Fold: 2  Epoch: 675  Training loss = 2.6332  Validation loss = 2.3803  \n",
      "\n",
      "Fold: 2  Epoch: 676  Training loss = 2.6331  Validation loss = 2.3800  \n",
      "\n",
      "Fold: 2  Epoch: 677  Training loss = 2.6330  Validation loss = 2.3796  \n",
      "\n",
      "Fold: 2  Epoch: 678  Training loss = 2.6329  Validation loss = 2.3792  \n",
      "\n",
      "Fold: 2  Epoch: 679  Training loss = 2.6329  Validation loss = 2.3789  \n",
      "\n",
      "Fold: 2  Epoch: 680  Training loss = 2.6328  Validation loss = 2.3785  \n",
      "\n",
      "Fold: 2  Epoch: 681  Training loss = 2.6327  Validation loss = 2.3778  \n",
      "\n",
      "Fold: 2  Epoch: 682  Training loss = 2.6326  Validation loss = 2.3773  \n",
      "\n",
      "Fold: 2  Epoch: 683  Training loss = 2.6325  Validation loss = 2.3771  \n",
      "\n",
      "Fold: 2  Epoch: 684  Training loss = 2.6325  Validation loss = 2.3769  \n",
      "\n",
      "Fold: 2  Epoch: 685  Training loss = 2.6324  Validation loss = 2.3766  \n",
      "\n",
      "Fold: 2  Epoch: 686  Training loss = 2.6323  Validation loss = 2.3763  \n",
      "\n",
      "Fold: 2  Epoch: 687  Training loss = 2.6322  Validation loss = 2.3758  \n",
      "\n",
      "Fold: 2  Epoch: 688  Training loss = 2.6322  Validation loss = 2.3758  \n",
      "\n",
      "Fold: 2  Epoch: 689  Training loss = 2.6322  Validation loss = 2.3755  \n",
      "\n",
      "Fold: 2  Epoch: 690  Training loss = 2.6321  Validation loss = 2.3752  \n",
      "\n",
      "Fold: 2  Epoch: 691  Training loss = 2.6320  Validation loss = 2.3746  \n",
      "\n",
      "Fold: 2  Epoch: 692  Training loss = 2.6319  Validation loss = 2.3744  \n",
      "\n",
      "Fold: 2  Epoch: 693  Training loss = 2.6317  Validation loss = 2.3734  \n",
      "\n",
      "Fold: 2  Epoch: 694  Training loss = 2.6316  Validation loss = 2.3733  \n",
      "\n",
      "Fold: 2  Epoch: 695  Training loss = 2.6315  Validation loss = 2.3727  \n",
      "\n",
      "Fold: 2  Epoch: 696  Training loss = 2.6314  Validation loss = 2.3726  \n",
      "\n",
      "Fold: 2  Epoch: 697  Training loss = 2.6313  Validation loss = 2.3721  \n",
      "\n",
      "Fold: 2  Epoch: 698  Training loss = 2.6311  Validation loss = 2.3713  \n",
      "\n",
      "Fold: 2  Epoch: 699  Training loss = 2.6310  Validation loss = 2.3709  \n",
      "\n",
      "Fold: 2  Epoch: 700  Training loss = 2.6309  Validation loss = 2.3705  \n",
      "\n",
      "Fold: 2  Epoch: 701  Training loss = 2.6308  Validation loss = 2.3699  \n",
      "\n",
      "Fold: 2  Epoch: 702  Training loss = 2.6308  Validation loss = 2.3699  \n",
      "\n",
      "Fold: 2  Epoch: 703  Training loss = 2.6307  Validation loss = 2.3695  \n",
      "\n",
      "Fold: 2  Epoch: 704  Training loss = 2.6307  Validation loss = 2.3693  \n",
      "\n",
      "Fold: 2  Epoch: 705  Training loss = 2.6307  Validation loss = 2.3692  \n",
      "\n",
      "Fold: 2  Epoch: 706  Training loss = 2.6307  Validation loss = 2.3691  \n",
      "\n",
      "Fold: 2  Epoch: 707  Training loss = 2.6304  Validation loss = 2.3681  \n",
      "\n",
      "Fold: 2  Epoch: 708  Training loss = 2.6302  Validation loss = 2.3675  \n",
      "\n",
      "Fold: 2  Epoch: 709  Training loss = 2.6302  Validation loss = 2.3672  \n",
      "\n",
      "Fold: 2  Epoch: 710  Training loss = 2.6301  Validation loss = 2.3667  \n",
      "\n",
      "Fold: 2  Epoch: 711  Training loss = 2.6299  Validation loss = 2.3660  \n",
      "\n",
      "Fold: 2  Epoch: 712  Training loss = 2.6297  Validation loss = 2.3653  \n",
      "\n",
      "Fold: 2  Epoch: 713  Training loss = 2.6296  Validation loss = 2.3650  \n",
      "\n",
      "Fold: 2  Epoch: 714  Training loss = 2.6296  Validation loss = 2.3649  \n",
      "\n",
      "Fold: 2  Epoch: 715  Training loss = 2.6295  Validation loss = 2.3645  \n",
      "\n",
      "Fold: 2  Epoch: 716  Training loss = 2.6294  Validation loss = 2.3641  \n",
      "\n",
      "Fold: 2  Epoch: 717  Training loss = 2.6293  Validation loss = 2.3637  \n",
      "\n",
      "Fold: 2  Epoch: 718  Training loss = 2.6292  Validation loss = 2.3632  \n",
      "\n",
      "Fold: 2  Epoch: 719  Training loss = 2.6292  Validation loss = 2.3630  \n",
      "\n",
      "Fold: 2  Epoch: 720  Training loss = 2.6291  Validation loss = 2.3628  \n",
      "\n",
      "Fold: 2  Epoch: 721  Training loss = 2.6289  Validation loss = 2.3621  \n",
      "\n",
      "Fold: 2  Epoch: 722  Training loss = 2.6288  Validation loss = 2.3618  \n",
      "\n",
      "Fold: 2  Epoch: 723  Training loss = 2.6287  Validation loss = 2.3613  \n",
      "\n",
      "Fold: 2  Epoch: 724  Training loss = 2.6286  Validation loss = 2.3610  \n",
      "\n",
      "Fold: 2  Epoch: 725  Training loss = 2.6285  Validation loss = 2.3605  \n",
      "\n",
      "Fold: 2  Epoch: 726  Training loss = 2.6284  Validation loss = 2.3601  \n",
      "\n",
      "Fold: 2  Epoch: 727  Training loss = 2.6283  Validation loss = 2.3596  \n",
      "\n",
      "Fold: 2  Epoch: 728  Training loss = 2.6282  Validation loss = 2.3591  \n",
      "\n",
      "Fold: 2  Epoch: 729  Training loss = 2.6281  Validation loss = 2.3589  \n",
      "\n",
      "Fold: 2  Epoch: 730  Training loss = 2.6279  Validation loss = 2.3580  \n",
      "\n",
      "Fold: 2  Epoch: 731  Training loss = 2.6277  Validation loss = 2.3576  \n",
      "\n",
      "Fold: 2  Epoch: 732  Training loss = 2.6277  Validation loss = 2.3573  \n",
      "\n",
      "Fold: 2  Epoch: 733  Training loss = 2.6275  Validation loss = 2.3565  \n",
      "\n",
      "Fold: 2  Epoch: 734  Training loss = 2.6273  Validation loss = 2.3559  \n",
      "\n",
      "Fold: 2  Epoch: 735  Training loss = 2.6273  Validation loss = 2.3556  \n",
      "\n",
      "Fold: 2  Epoch: 736  Training loss = 2.6272  Validation loss = 2.3553  \n",
      "\n",
      "Fold: 2  Epoch: 737  Training loss = 2.6271  Validation loss = 2.3550  \n",
      "\n",
      "Fold: 2  Epoch: 738  Training loss = 2.6269  Validation loss = 2.3542  \n",
      "\n",
      "Fold: 2  Epoch: 739  Training loss = 2.6269  Validation loss = 2.3542  \n",
      "\n",
      "Fold: 2  Epoch: 740  Training loss = 2.6269  Validation loss = 2.3542  \n",
      "\n",
      "Fold: 2  Epoch: 741  Training loss = 2.6268  Validation loss = 2.3535  \n",
      "\n",
      "Fold: 2  Epoch: 742  Training loss = 2.6267  Validation loss = 2.3532  \n",
      "\n",
      "Fold: 2  Epoch: 743  Training loss = 2.6267  Validation loss = 2.3530  \n",
      "\n",
      "Fold: 2  Epoch: 744  Training loss = 2.6265  Validation loss = 2.3523  \n",
      "\n",
      "Fold: 2  Epoch: 745  Training loss = 2.6264  Validation loss = 2.3518  \n",
      "\n",
      "Fold: 2  Epoch: 746  Training loss = 2.6263  Validation loss = 2.3514  \n",
      "\n",
      "Fold: 2  Epoch: 747  Training loss = 2.6261  Validation loss = 2.3506  \n",
      "\n",
      "Fold: 2  Epoch: 748  Training loss = 2.6260  Validation loss = 2.3502  \n",
      "\n",
      "Fold: 2  Epoch: 749  Training loss = 2.6259  Validation loss = 2.3497  \n",
      "\n",
      "Fold: 2  Epoch: 750  Training loss = 2.6258  Validation loss = 2.3492  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 750  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.5922  Validation loss = 3.2774  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.5921  Validation loss = 3.2766  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.5920  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.5920  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.5919  Validation loss = 3.2755  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.5918  Validation loss = 3.2747  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.5917  Validation loss = 3.2744  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.5917  Validation loss = 3.2743  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.5916  Validation loss = 3.2739  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.5915  Validation loss = 3.2736  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.5914  Validation loss = 3.2725  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.5912  Validation loss = 3.2718  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.5912  Validation loss = 3.2717  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.5911  Validation loss = 3.2710  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.5910  Validation loss = 3.2705  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.5909  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.5909  Validation loss = 3.2699  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.5908  Validation loss = 3.2690  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.5907  Validation loss = 3.2687  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.5906  Validation loss = 3.2679  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.5905  Validation loss = 3.2672  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.5904  Validation loss = 3.2668  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.5903  Validation loss = 3.2664  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.5902  Validation loss = 3.2660  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.5901  Validation loss = 3.2652  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.5900  Validation loss = 3.2645  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.5898  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.5897  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.5896  Validation loss = 3.2620  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.5895  Validation loss = 3.2617  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.5895  Validation loss = 3.2616  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.5894  Validation loss = 3.2615  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.5893  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.5893  Validation loss = 3.2605  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.5891  Validation loss = 3.2592  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.5890  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.5888  Validation loss = 3.2578  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.5888  Validation loss = 3.2576  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.5887  Validation loss = 3.2572  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.5886  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.5885  Validation loss = 3.2563  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.5885  Validation loss = 3.2555  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.5883  Validation loss = 3.2546  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.5882  Validation loss = 3.2542  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.5880  Validation loss = 3.2529  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.5879  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.5879  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.5878  Validation loss = 3.2519  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.5877  Validation loss = 3.2516  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.5876  Validation loss = 3.2509  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.5875  Validation loss = 3.2500  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.5874  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.5873  Validation loss = 3.2490  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.5872  Validation loss = 3.2482  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.5870  Validation loss = 3.2472  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.5869  Validation loss = 3.2469  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.5868  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.5868  Validation loss = 3.2460  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.5867  Validation loss = 3.2456  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.5866  Validation loss = 3.2451  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.5865  Validation loss = 3.2443  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.5864  Validation loss = 3.2438  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.5863  Validation loss = 3.2431  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.5861  Validation loss = 3.2422  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.5861  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.5861  Validation loss = 3.2418  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.5860  Validation loss = 3.2413  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.5859  Validation loss = 3.2406  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.5858  Validation loss = 3.2401  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.5857  Validation loss = 3.2398  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.5857  Validation loss = 3.2396  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.5856  Validation loss = 3.2390  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.5855  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.5855  Validation loss = 3.2382  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.5853  Validation loss = 3.2376  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.5853  Validation loss = 3.2374  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.5853  Validation loss = 3.2372  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.5852  Validation loss = 3.2367  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.5851  Validation loss = 3.2361  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.5849  Validation loss = 3.2351  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.5848  Validation loss = 3.2343  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.5847  Validation loss = 3.2338  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.5846  Validation loss = 3.2329  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.5845  Validation loss = 3.2326  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.5844  Validation loss = 3.2318  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.5843  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.5842  Validation loss = 3.2309  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.5842  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.5842  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.5840  Validation loss = 3.2298  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.5840  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.5839  Validation loss = 3.2290  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.5838  Validation loss = 3.2287  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.5837  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.5837  Validation loss = 3.2279  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.5836  Validation loss = 3.2273  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.5835  Validation loss = 3.2272  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.5835  Validation loss = 3.2273  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.5834  Validation loss = 3.2264  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.5833  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.5832  Validation loss = 3.2251  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.5831  Validation loss = 3.2248  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.5831  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.5830  Validation loss = 3.2243  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.5830  Validation loss = 3.2243  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.5829  Validation loss = 3.2239  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.5829  Validation loss = 3.2238  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.5828  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.5827  Validation loss = 3.2226  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.5827  Validation loss = 3.2226  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.5826  Validation loss = 3.2222  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.5826  Validation loss = 3.2219  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.5825  Validation loss = 3.2217  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.5824  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.5824  Validation loss = 3.2210  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.5823  Validation loss = 3.2206  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.5823  Validation loss = 3.2205  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.5821  Validation loss = 3.2196  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.5820  Validation loss = 3.2188  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.5820  Validation loss = 3.2184  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.5819  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.5818  Validation loss = 3.2177  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.5818  Validation loss = 3.2176  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.5817  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.5817  Validation loss = 3.2171  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.5817  Validation loss = 3.2169  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.5815  Validation loss = 3.2161  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.5814  Validation loss = 3.2154  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.5814  Validation loss = 3.2153  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.5813  Validation loss = 3.2148  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.5812  Validation loss = 3.2142  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.5811  Validation loss = 3.2139  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.5811  Validation loss = 3.2135  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.5809  Validation loss = 3.2129  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.5808  Validation loss = 3.2122  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.5808  Validation loss = 3.2117  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.5807  Validation loss = 3.2112  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.5806  Validation loss = 3.2111  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.5806  Validation loss = 3.2106  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.5804  Validation loss = 3.2097  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.5803  Validation loss = 3.2092  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.5803  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.5802  Validation loss = 3.2085  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.5801  Validation loss = 3.2078  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.5800  Validation loss = 3.2073  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.5799  Validation loss = 3.2066  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.5798  Validation loss = 3.2060  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.5798  Validation loss = 3.2059  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.5797  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.5796  Validation loss = 3.2046  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.5795  Validation loss = 3.2041  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.5794  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.5793  Validation loss = 3.2027  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.5792  Validation loss = 3.2024  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.5792  Validation loss = 3.2021  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.5791  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.5790  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.5790  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.5790  Validation loss = 3.2011  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.5789  Validation loss = 3.2004  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.5789  Validation loss = 3.2003  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.5788  Validation loss = 3.2002  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.5787  Validation loss = 3.1997  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.5786  Validation loss = 3.1990  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.5786  Validation loss = 3.1989  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.5785  Validation loss = 3.1983  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.5785  Validation loss = 3.1982  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.5784  Validation loss = 3.1979  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.5783  Validation loss = 3.1974  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.5783  Validation loss = 3.1972  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.5782  Validation loss = 3.1967  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.5781  Validation loss = 3.1962  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.5781  Validation loss = 3.1959  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.5781  Validation loss = 3.1957  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.5780  Validation loss = 3.1951  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.5780  Validation loss = 3.1952  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.5778  Validation loss = 3.1944  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.5778  Validation loss = 3.1940  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.5777  Validation loss = 3.1938  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.5776  Validation loss = 3.1933  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.5775  Validation loss = 3.1924  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.5774  Validation loss = 3.1919  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.5773  Validation loss = 3.1913  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.5773  Validation loss = 3.1908  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.5772  Validation loss = 3.1906  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.5772  Validation loss = 3.1904  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.5771  Validation loss = 3.1904  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.5771  Validation loss = 3.1904  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.5771  Validation loss = 3.1903  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.5770  Validation loss = 3.1899  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.5770  Validation loss = 3.1897  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.5769  Validation loss = 3.1896  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.5769  Validation loss = 3.1892  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.5768  Validation loss = 3.1886  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.5768  Validation loss = 3.1886  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.5767  Validation loss = 3.1883  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.5767  Validation loss = 3.1881  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.5766  Validation loss = 3.1876  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.5765  Validation loss = 3.1873  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.5764  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.5763  Validation loss = 3.1860  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.5762  Validation loss = 3.1854  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.5762  Validation loss = 3.1850  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.5761  Validation loss = 3.1843  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.5760  Validation loss = 3.1841  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.5760  Validation loss = 3.1839  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.5759  Validation loss = 3.1835  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.5758  Validation loss = 3.1829  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.5758  Validation loss = 3.1829  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.5758  Validation loss = 3.1828  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.5757  Validation loss = 3.1823  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.5756  Validation loss = 3.1819  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.5756  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.5755  Validation loss = 3.1816  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.5755  Validation loss = 3.1814  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.5754  Validation loss = 3.1811  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.5753  Validation loss = 3.1805  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.5753  Validation loss = 3.1801  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.5752  Validation loss = 3.1797  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.5751  Validation loss = 3.1791  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.5750  Validation loss = 3.1786  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.5750  Validation loss = 3.1782  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.5749  Validation loss = 3.1778  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.5749  Validation loss = 3.1776  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.5748  Validation loss = 3.1770  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.5747  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.5747  Validation loss = 3.1765  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.5746  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.5745  Validation loss = 3.1758  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.5745  Validation loss = 3.1754  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.5745  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.5744  Validation loss = 3.1752  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.5743  Validation loss = 3.1745  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.5742  Validation loss = 3.1740  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.5742  Validation loss = 3.1738  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.5742  Validation loss = 3.1739  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.5741  Validation loss = 3.1734  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.5740  Validation loss = 3.1723  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.5739  Validation loss = 3.1720  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.5739  Validation loss = 3.1720  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.5738  Validation loss = 3.1714  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.5738  Validation loss = 3.1712  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.5737  Validation loss = 3.1708  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.5736  Validation loss = 3.1703  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.5736  Validation loss = 3.1700  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.5735  Validation loss = 3.1694  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.5734  Validation loss = 3.1690  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.5733  Validation loss = 3.1684  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.5733  Validation loss = 3.1681  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.5732  Validation loss = 3.1676  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.5731  Validation loss = 3.1672  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.5730  Validation loss = 3.1664  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.5730  Validation loss = 3.1663  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.5729  Validation loss = 3.1659  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.5729  Validation loss = 3.1656  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.5728  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.5727  Validation loss = 3.1644  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.5727  Validation loss = 3.1641  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.5726  Validation loss = 3.1640  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.5726  Validation loss = 3.1635  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.5725  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.5723  Validation loss = 3.1619  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.5722  Validation loss = 3.1614  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.5721  Validation loss = 3.1604  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.5720  Validation loss = 3.1600  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.5720  Validation loss = 3.1596  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.5719  Validation loss = 3.1592  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.5719  Validation loss = 3.1593  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.5718  Validation loss = 3.1587  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.5717  Validation loss = 3.1583  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.5717  Validation loss = 3.1580  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.5716  Validation loss = 3.1574  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.5715  Validation loss = 3.1568  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.5714  Validation loss = 3.1563  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.5714  Validation loss = 3.1562  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.5713  Validation loss = 3.1558  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.5713  Validation loss = 3.1556  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.5712  Validation loss = 3.1553  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.5712  Validation loss = 3.1550  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.5711  Validation loss = 3.1545  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.5710  Validation loss = 3.1542  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.5710  Validation loss = 3.1538  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.5709  Validation loss = 3.1534  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.5709  Validation loss = 3.1534  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.5708  Validation loss = 3.1531  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.5708  Validation loss = 3.1528  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.5707  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.5706  Validation loss = 3.1517  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.5706  Validation loss = 3.1514  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.5705  Validation loss = 3.1510  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.5705  Validation loss = 3.1508  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.5704  Validation loss = 3.1503  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.5704  Validation loss = 3.1500  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.5703  Validation loss = 3.1496  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.5702  Validation loss = 3.1489  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.5702  Validation loss = 3.1487  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.5701  Validation loss = 3.1483  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.5700  Validation loss = 3.1479  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.5700  Validation loss = 3.1477  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.5699  Validation loss = 3.1474  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.5699  Validation loss = 3.1470  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.5698  Validation loss = 3.1468  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.5698  Validation loss = 3.1466  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.5698  Validation loss = 3.1463  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.5697  Validation loss = 3.1459  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.5696  Validation loss = 3.1456  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.5696  Validation loss = 3.1453  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.5695  Validation loss = 3.1450  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.5695  Validation loss = 3.1446  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.5694  Validation loss = 3.1440  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.5694  Validation loss = 3.1440  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.5693  Validation loss = 3.1440  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.5693  Validation loss = 3.1440  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.5693  Validation loss = 3.1442  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.5693  Validation loss = 3.1440  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.5692  Validation loss = 3.1438  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.5691  Validation loss = 3.1433  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.5691  Validation loss = 3.1427  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.5690  Validation loss = 3.1421  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.5690  Validation loss = 3.1420  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.5689  Validation loss = 3.1421  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.5689  Validation loss = 3.1418  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.5688  Validation loss = 3.1415  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.5688  Validation loss = 3.1415  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.5687  Validation loss = 3.1410  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.5687  Validation loss = 3.1406  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.5686  Validation loss = 3.1399  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.5686  Validation loss = 3.1397  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.5685  Validation loss = 3.1392  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.5684  Validation loss = 3.1389  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.5684  Validation loss = 3.1384  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.5683  Validation loss = 3.1378  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.5682  Validation loss = 3.1376  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.5681  Validation loss = 3.1371  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.5681  Validation loss = 3.1368  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.5680  Validation loss = 3.1364  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.5680  Validation loss = 3.1363  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.5679  Validation loss = 3.1358  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.5679  Validation loss = 3.1355  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.5678  Validation loss = 3.1350  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.5677  Validation loss = 3.1347  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.5677  Validation loss = 3.1345  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.5676  Validation loss = 3.1340  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.5675  Validation loss = 3.1336  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.5675  Validation loss = 3.1334  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.5674  Validation loss = 3.1333  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.5674  Validation loss = 3.1327  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.5673  Validation loss = 3.1326  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.5673  Validation loss = 3.1323  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.5672  Validation loss = 3.1319  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.5671  Validation loss = 3.1314  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.5670  Validation loss = 3.1308  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.5670  Validation loss = 3.1308  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.5669  Validation loss = 3.1304  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.5669  Validation loss = 3.1302  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.5668  Validation loss = 3.1302  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.5668  Validation loss = 3.1298  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.5668  Validation loss = 3.1298  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.5667  Validation loss = 3.1295  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.5667  Validation loss = 3.1291  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.5666  Validation loss = 3.1287  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.5666  Validation loss = 3.1288  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.5665  Validation loss = 3.1284  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.5665  Validation loss = 3.1282  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.5664  Validation loss = 3.1278  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.5664  Validation loss = 3.1273  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.5663  Validation loss = 3.1269  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.5663  Validation loss = 3.1264  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.5662  Validation loss = 3.1262  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.5662  Validation loss = 3.1256  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.5661  Validation loss = 3.1253  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.5660  Validation loss = 3.1250  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.5660  Validation loss = 3.1245  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.5659  Validation loss = 3.1240  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.5658  Validation loss = 3.1236  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.5658  Validation loss = 3.1233  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.5658  Validation loss = 3.1231  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.5657  Validation loss = 3.1227  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.5657  Validation loss = 3.1224  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.5656  Validation loss = 3.1222  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.5656  Validation loss = 3.1219  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.5656  Validation loss = 3.1221  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.5655  Validation loss = 3.1217  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.5655  Validation loss = 3.1213  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.5654  Validation loss = 3.1209  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.5654  Validation loss = 3.1209  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.5654  Validation loss = 3.1207  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.5653  Validation loss = 3.1204  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.5653  Validation loss = 3.1203  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.5652  Validation loss = 3.1200  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.5652  Validation loss = 3.1198  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.5651  Validation loss = 3.1197  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.5651  Validation loss = 3.1195  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.5651  Validation loss = 3.1195  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.5650  Validation loss = 3.1189  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.5650  Validation loss = 3.1190  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.5649  Validation loss = 3.1190  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.5649  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.5648  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.5648  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.5648  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.5647  Validation loss = 3.1179  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.5647  Validation loss = 3.1176  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.5646  Validation loss = 3.1168  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.5645  Validation loss = 3.1163  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.5644  Validation loss = 3.1158  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.5644  Validation loss = 3.1158  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.5644  Validation loss = 3.1158  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.5643  Validation loss = 3.1154  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.5642  Validation loss = 3.1150  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.5642  Validation loss = 3.1147  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.5642  Validation loss = 3.1147  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.5640  Validation loss = 3.1138  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.5640  Validation loss = 3.1136  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.5639  Validation loss = 3.1131  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.5639  Validation loss = 3.1126  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.5638  Validation loss = 3.1127  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.5638  Validation loss = 3.1123  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.5637  Validation loss = 3.1120  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.5637  Validation loss = 3.1120  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.5637  Validation loss = 3.1118  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.5636  Validation loss = 3.1116  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.5636  Validation loss = 3.1114  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.5635  Validation loss = 3.1112  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.5635  Validation loss = 3.1105  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.5634  Validation loss = 3.1106  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.5634  Validation loss = 3.1102  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.5633  Validation loss = 3.1096  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.5632  Validation loss = 3.1094  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.5632  Validation loss = 3.1090  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.5631  Validation loss = 3.1088  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.5631  Validation loss = 3.1084  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.5631  Validation loss = 3.1085  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.5630  Validation loss = 3.1083  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.5630  Validation loss = 3.1079  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.5629  Validation loss = 3.1076  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.5628  Validation loss = 3.1072  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.5628  Validation loss = 3.1070  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.5628  Validation loss = 3.1070  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.5627  Validation loss = 3.1067  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.5627  Validation loss = 3.1063  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.5626  Validation loss = 3.1060  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.5626  Validation loss = 3.1057  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.5625  Validation loss = 3.1053  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.5624  Validation loss = 3.1046  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.5624  Validation loss = 3.1041  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.5623  Validation loss = 3.1039  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.5623  Validation loss = 3.1038  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.5622  Validation loss = 3.1037  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.5622  Validation loss = 3.1036  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.5622  Validation loss = 3.1034  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.5621  Validation loss = 3.1031  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.5621  Validation loss = 3.1026  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.5620  Validation loss = 3.1023  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.5619  Validation loss = 3.1018  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.5619  Validation loss = 3.1013  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.5618  Validation loss = 3.1016  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.5618  Validation loss = 3.1016  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.5617  Validation loss = 3.1011  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.5617  Validation loss = 3.1011  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.5617  Validation loss = 3.1011  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.5616  Validation loss = 3.1004  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.5616  Validation loss = 3.1003  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.5615  Validation loss = 3.0999  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.5615  Validation loss = 3.0998  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.5614  Validation loss = 3.0995  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.5614  Validation loss = 3.0991  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.5613  Validation loss = 3.0989  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.5613  Validation loss = 3.0984  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.5612  Validation loss = 3.0980  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.5612  Validation loss = 3.0979  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.5611  Validation loss = 3.0975  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.5611  Validation loss = 3.0975  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.5610  Validation loss = 3.0971  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.5610  Validation loss = 3.0967  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.5609  Validation loss = 3.0963  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.5609  Validation loss = 3.0961  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.5608  Validation loss = 3.0959  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.5608  Validation loss = 3.0957  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.5607  Validation loss = 3.0955  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.5607  Validation loss = 3.0953  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.5606  Validation loss = 3.0950  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.5606  Validation loss = 3.0947  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.5605  Validation loss = 3.0946  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.5605  Validation loss = 3.0945  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.5604  Validation loss = 3.0940  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.5604  Validation loss = 3.0938  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.5603  Validation loss = 3.0934  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.5602  Validation loss = 3.0930  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.5602  Validation loss = 3.0928  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.5601  Validation loss = 3.0922  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.5601  Validation loss = 3.0918  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.5600  Validation loss = 3.0914  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.5600  Validation loss = 3.0913  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.5599  Validation loss = 3.0908  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.5599  Validation loss = 3.0906  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.5598  Validation loss = 3.0902  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.5598  Validation loss = 3.0901  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.5597  Validation loss = 3.0897  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.5596  Validation loss = 3.0895  \n",
      "\n",
      "Fold: 3  Epoch: 501  Training loss = 1.5596  Validation loss = 3.0893  \n",
      "\n",
      "Fold: 3  Epoch: 502  Training loss = 1.5596  Validation loss = 3.0893  \n",
      "\n",
      "Fold: 3  Epoch: 503  Training loss = 1.5595  Validation loss = 3.0892  \n",
      "\n",
      "Fold: 3  Epoch: 504  Training loss = 1.5595  Validation loss = 3.0887  \n",
      "\n",
      "Fold: 3  Epoch: 505  Training loss = 1.5594  Validation loss = 3.0882  \n",
      "\n",
      "Fold: 3  Epoch: 506  Training loss = 1.5593  Validation loss = 3.0878  \n",
      "\n",
      "Fold: 3  Epoch: 507  Training loss = 1.5593  Validation loss = 3.0877  \n",
      "\n",
      "Fold: 3  Epoch: 508  Training loss = 1.5592  Validation loss = 3.0876  \n",
      "\n",
      "Fold: 3  Epoch: 509  Training loss = 1.5591  Validation loss = 3.0868  \n",
      "\n",
      "Fold: 3  Epoch: 510  Training loss = 1.5591  Validation loss = 3.0864  \n",
      "\n",
      "Fold: 3  Epoch: 511  Training loss = 1.5590  Validation loss = 3.0863  \n",
      "\n",
      "Fold: 3  Epoch: 512  Training loss = 1.5590  Validation loss = 3.0859  \n",
      "\n",
      "Fold: 3  Epoch: 513  Training loss = 1.5589  Validation loss = 3.0858  \n",
      "\n",
      "Fold: 3  Epoch: 514  Training loss = 1.5589  Validation loss = 3.0854  \n",
      "\n",
      "Fold: 3  Epoch: 515  Training loss = 1.5588  Validation loss = 3.0852  \n",
      "\n",
      "Fold: 3  Epoch: 516  Training loss = 1.5588  Validation loss = 3.0850  \n",
      "\n",
      "Fold: 3  Epoch: 517  Training loss = 1.5587  Validation loss = 3.0849  \n",
      "\n",
      "Fold: 3  Epoch: 518  Training loss = 1.5587  Validation loss = 3.0846  \n",
      "\n",
      "Fold: 3  Epoch: 519  Training loss = 1.5587  Validation loss = 3.0844  \n",
      "\n",
      "Fold: 3  Epoch: 520  Training loss = 1.5586  Validation loss = 3.0841  \n",
      "\n",
      "Fold: 3  Epoch: 521  Training loss = 1.5586  Validation loss = 3.0840  \n",
      "\n",
      "Fold: 3  Epoch: 522  Training loss = 1.5586  Validation loss = 3.0839  \n",
      "\n",
      "Fold: 3  Epoch: 523  Training loss = 1.5586  Validation loss = 3.0843  \n",
      "\n",
      "Fold: 3  Epoch: 524  Training loss = 1.5585  Validation loss = 3.0838  \n",
      "\n",
      "Fold: 3  Epoch: 525  Training loss = 1.5584  Validation loss = 3.0835  \n",
      "\n",
      "Fold: 3  Epoch: 526  Training loss = 1.5584  Validation loss = 3.0831  \n",
      "\n",
      "Fold: 3  Epoch: 527  Training loss = 1.5583  Validation loss = 3.0827  \n",
      "\n",
      "Fold: 3  Epoch: 528  Training loss = 1.5582  Validation loss = 3.0823  \n",
      "\n",
      "Fold: 3  Epoch: 529  Training loss = 1.5582  Validation loss = 3.0820  \n",
      "\n",
      "Fold: 3  Epoch: 530  Training loss = 1.5581  Validation loss = 3.0818  \n",
      "\n",
      "Fold: 3  Epoch: 531  Training loss = 1.5581  Validation loss = 3.0814  \n",
      "\n",
      "Fold: 3  Epoch: 532  Training loss = 1.5580  Validation loss = 3.0809  \n",
      "\n",
      "Fold: 3  Epoch: 533  Training loss = 1.5580  Validation loss = 3.0807  \n",
      "\n",
      "Fold: 3  Epoch: 534  Training loss = 1.5579  Validation loss = 3.0807  \n",
      "\n",
      "Fold: 3  Epoch: 535  Training loss = 1.5579  Validation loss = 3.0803  \n",
      "\n",
      "Fold: 3  Epoch: 536  Training loss = 1.5578  Validation loss = 3.0798  \n",
      "\n",
      "Fold: 3  Epoch: 537  Training loss = 1.5578  Validation loss = 3.0795  \n",
      "\n",
      "Fold: 3  Epoch: 538  Training loss = 1.5577  Validation loss = 3.0792  \n",
      "\n",
      "Fold: 3  Epoch: 539  Training loss = 1.5576  Validation loss = 3.0787  \n",
      "\n",
      "Fold: 3  Epoch: 540  Training loss = 1.5576  Validation loss = 3.0786  \n",
      "\n",
      "Fold: 3  Epoch: 541  Training loss = 1.5575  Validation loss = 3.0782  \n",
      "\n",
      "Fold: 3  Epoch: 542  Training loss = 1.5575  Validation loss = 3.0781  \n",
      "\n",
      "Fold: 3  Epoch: 543  Training loss = 1.5574  Validation loss = 3.0777  \n",
      "\n",
      "Fold: 3  Epoch: 544  Training loss = 1.5574  Validation loss = 3.0772  \n",
      "\n",
      "Fold: 3  Epoch: 545  Training loss = 1.5573  Validation loss = 3.0770  \n",
      "\n",
      "Fold: 3  Epoch: 546  Training loss = 1.5573  Validation loss = 3.0772  \n",
      "\n",
      "Fold: 3  Epoch: 547  Training loss = 1.5573  Validation loss = 3.0772  \n",
      "\n",
      "Fold: 3  Epoch: 548  Training loss = 1.5572  Validation loss = 3.0770  \n",
      "\n",
      "Fold: 3  Epoch: 549  Training loss = 1.5572  Validation loss = 3.0768  \n",
      "\n",
      "Fold: 3  Epoch: 550  Training loss = 1.5571  Validation loss = 3.0767  \n",
      "\n",
      "Fold: 3  Epoch: 551  Training loss = 1.5570  Validation loss = 3.0764  \n",
      "\n",
      "Fold: 3  Epoch: 552  Training loss = 1.5570  Validation loss = 3.0764  \n",
      "\n",
      "Fold: 3  Epoch: 553  Training loss = 1.5570  Validation loss = 3.0761  \n",
      "\n",
      "Fold: 3  Epoch: 554  Training loss = 1.5569  Validation loss = 3.0758  \n",
      "\n",
      "Fold: 3  Epoch: 555  Training loss = 1.5569  Validation loss = 3.0757  \n",
      "\n",
      "Fold: 3  Epoch: 556  Training loss = 1.5568  Validation loss = 3.0755  \n",
      "\n",
      "Fold: 3  Epoch: 557  Training loss = 1.5568  Validation loss = 3.0752  \n",
      "\n",
      "Fold: 3  Epoch: 558  Training loss = 1.5568  Validation loss = 3.0754  \n",
      "\n",
      "Fold: 3  Epoch: 559  Training loss = 1.5567  Validation loss = 3.0750  \n",
      "\n",
      "Fold: 3  Epoch: 560  Training loss = 1.5567  Validation loss = 3.0749  \n",
      "\n",
      "Fold: 3  Epoch: 561  Training loss = 1.5566  Validation loss = 3.0746  \n",
      "\n",
      "Fold: 3  Epoch: 562  Training loss = 1.5566  Validation loss = 3.0740  \n",
      "\n",
      "Fold: 3  Epoch: 563  Training loss = 1.5565  Validation loss = 3.0737  \n",
      "\n",
      "Fold: 3  Epoch: 564  Training loss = 1.5565  Validation loss = 3.0732  \n",
      "\n",
      "Fold: 3  Epoch: 565  Training loss = 1.5564  Validation loss = 3.0728  \n",
      "\n",
      "Fold: 3  Epoch: 566  Training loss = 1.5564  Validation loss = 3.0725  \n",
      "\n",
      "Fold: 3  Epoch: 567  Training loss = 1.5563  Validation loss = 3.0721  \n",
      "\n",
      "Fold: 3  Epoch: 568  Training loss = 1.5563  Validation loss = 3.0721  \n",
      "\n",
      "Fold: 3  Epoch: 569  Training loss = 1.5563  Validation loss = 3.0719  \n",
      "\n",
      "Fold: 3  Epoch: 570  Training loss = 1.5562  Validation loss = 3.0717  \n",
      "\n",
      "Fold: 3  Epoch: 571  Training loss = 1.5562  Validation loss = 3.0717  \n",
      "\n",
      "Fold: 3  Epoch: 572  Training loss = 1.5562  Validation loss = 3.0717  \n",
      "\n",
      "Fold: 3  Epoch: 573  Training loss = 1.5561  Validation loss = 3.0713  \n",
      "\n",
      "Fold: 3  Epoch: 574  Training loss = 1.5561  Validation loss = 3.0713  \n",
      "\n",
      "Fold: 3  Epoch: 575  Training loss = 1.5560  Validation loss = 3.0713  \n",
      "\n",
      "Fold: 3  Epoch: 576  Training loss = 1.5560  Validation loss = 3.0706  \n",
      "\n",
      "Fold: 3  Epoch: 577  Training loss = 1.5560  Validation loss = 3.0707  \n",
      "\n",
      "Fold: 3  Epoch: 578  Training loss = 1.5559  Validation loss = 3.0704  \n",
      "\n",
      "Fold: 3  Epoch: 579  Training loss = 1.5559  Validation loss = 3.0706  \n",
      "\n",
      "Fold: 3  Epoch: 580  Training loss = 1.5558  Validation loss = 3.0704  \n",
      "\n",
      "Fold: 3  Epoch: 581  Training loss = 1.5558  Validation loss = 3.0705  \n",
      "\n",
      "Fold: 3  Epoch: 582  Training loss = 1.5558  Validation loss = 3.0707  \n",
      "\n",
      "Fold: 3  Epoch: 583  Training loss = 1.5558  Validation loss = 3.0706  \n",
      "\n",
      "Fold: 3  Epoch: 584  Training loss = 1.5557  Validation loss = 3.0700  \n",
      "\n",
      "Fold: 3  Epoch: 585  Training loss = 1.5556  Validation loss = 3.0697  \n",
      "\n",
      "Fold: 3  Epoch: 586  Training loss = 1.5556  Validation loss = 3.0696  \n",
      "\n",
      "Fold: 3  Epoch: 587  Training loss = 1.5555  Validation loss = 3.0692  \n",
      "\n",
      "Fold: 3  Epoch: 588  Training loss = 1.5555  Validation loss = 3.0691  \n",
      "\n",
      "Fold: 3  Epoch: 589  Training loss = 1.5555  Validation loss = 3.0689  \n",
      "\n",
      "Fold: 3  Epoch: 590  Training loss = 1.5555  Validation loss = 3.0690  \n",
      "\n",
      "Fold: 3  Epoch: 591  Training loss = 1.5554  Validation loss = 3.0687  \n",
      "\n",
      "Fold: 3  Epoch: 592  Training loss = 1.5554  Validation loss = 3.0687  \n",
      "\n",
      "Fold: 3  Epoch: 593  Training loss = 1.5554  Validation loss = 3.0688  \n",
      "\n",
      "Fold: 3  Epoch: 594  Training loss = 1.5553  Validation loss = 3.0687  \n",
      "\n",
      "Fold: 3  Epoch: 595  Training loss = 1.5553  Validation loss = 3.0684  \n",
      "\n",
      "Fold: 3  Epoch: 596  Training loss = 1.5552  Validation loss = 3.0682  \n",
      "\n",
      "Fold: 3  Epoch: 597  Training loss = 1.5552  Validation loss = 3.0681  \n",
      "\n",
      "Fold: 3  Epoch: 598  Training loss = 1.5551  Validation loss = 3.0675  \n",
      "\n",
      "Fold: 3  Epoch: 599  Training loss = 1.5550  Validation loss = 3.0673  \n",
      "\n",
      "Fold: 3  Epoch: 600  Training loss = 1.5550  Validation loss = 3.0667  \n",
      "\n",
      "Fold: 3  Epoch: 601  Training loss = 1.5549  Validation loss = 3.0661  \n",
      "\n",
      "Fold: 3  Epoch: 602  Training loss = 1.5548  Validation loss = 3.0655  \n",
      "\n",
      "Fold: 3  Epoch: 603  Training loss = 1.5548  Validation loss = 3.0652  \n",
      "\n",
      "Fold: 3  Epoch: 604  Training loss = 1.5547  Validation loss = 3.0651  \n",
      "\n",
      "Fold: 3  Epoch: 605  Training loss = 1.5547  Validation loss = 3.0652  \n",
      "\n",
      "Fold: 3  Epoch: 606  Training loss = 1.5547  Validation loss = 3.0650  \n",
      "\n",
      "Fold: 3  Epoch: 607  Training loss = 1.5546  Validation loss = 3.0646  \n",
      "\n",
      "Fold: 3  Epoch: 608  Training loss = 1.5546  Validation loss = 3.0644  \n",
      "\n",
      "Fold: 3  Epoch: 609  Training loss = 1.5545  Validation loss = 3.0642  \n",
      "\n",
      "Fold: 3  Epoch: 610  Training loss = 1.5545  Validation loss = 3.0641  \n",
      "\n",
      "Fold: 3  Epoch: 611  Training loss = 1.5545  Validation loss = 3.0641  \n",
      "\n",
      "Fold: 3  Epoch: 612  Training loss = 1.5544  Validation loss = 3.0641  \n",
      "\n",
      "Fold: 3  Epoch: 613  Training loss = 1.5544  Validation loss = 3.0636  \n",
      "\n",
      "Fold: 3  Epoch: 614  Training loss = 1.5543  Validation loss = 3.0635  \n",
      "\n",
      "Fold: 3  Epoch: 615  Training loss = 1.5543  Validation loss = 3.0632  \n",
      "\n",
      "Fold: 3  Epoch: 616  Training loss = 1.5542  Validation loss = 3.0627  \n",
      "\n",
      "Fold: 3  Epoch: 617  Training loss = 1.5542  Validation loss = 3.0627  \n",
      "\n",
      "Fold: 3  Epoch: 618  Training loss = 1.5541  Validation loss = 3.0625  \n",
      "\n",
      "Fold: 3  Epoch: 619  Training loss = 1.5541  Validation loss = 3.0624  \n",
      "\n",
      "Fold: 3  Epoch: 620  Training loss = 1.5540  Validation loss = 3.0616  \n",
      "\n",
      "Fold: 3  Epoch: 621  Training loss = 1.5540  Validation loss = 3.0614  \n",
      "\n",
      "Fold: 3  Epoch: 622  Training loss = 1.5539  Validation loss = 3.0614  \n",
      "\n",
      "Fold: 3  Epoch: 623  Training loss = 1.5539  Validation loss = 3.0610  \n",
      "\n",
      "Fold: 3  Epoch: 624  Training loss = 1.5538  Validation loss = 3.0608  \n",
      "\n",
      "Fold: 3  Epoch: 625  Training loss = 1.5538  Validation loss = 3.0610  \n",
      "\n",
      "Fold: 3  Epoch: 626  Training loss = 1.5537  Validation loss = 3.0608  \n",
      "\n",
      "Fold: 3  Epoch: 627  Training loss = 1.5537  Validation loss = 3.0606  \n",
      "\n",
      "Fold: 3  Epoch: 628  Training loss = 1.5536  Validation loss = 3.0603  \n",
      "\n",
      "Fold: 3  Epoch: 629  Training loss = 1.5536  Validation loss = 3.0599  \n",
      "\n",
      "Fold: 3  Epoch: 630  Training loss = 1.5535  Validation loss = 3.0595  \n",
      "\n",
      "Fold: 3  Epoch: 631  Training loss = 1.5535  Validation loss = 3.0593  \n",
      "\n",
      "Fold: 3  Epoch: 632  Training loss = 1.5534  Validation loss = 3.0589  \n",
      "\n",
      "Fold: 3  Epoch: 633  Training loss = 1.5534  Validation loss = 3.0591  \n",
      "\n",
      "Fold: 3  Epoch: 634  Training loss = 1.5533  Validation loss = 3.0586  \n",
      "\n",
      "Fold: 3  Epoch: 635  Training loss = 1.5533  Validation loss = 3.0585  \n",
      "\n",
      "Fold: 3  Epoch: 636  Training loss = 1.5532  Validation loss = 3.0584  \n",
      "\n",
      "Fold: 3  Epoch: 637  Training loss = 1.5532  Validation loss = 3.0580  \n",
      "\n",
      "Fold: 3  Epoch: 638  Training loss = 1.5531  Validation loss = 3.0576  \n",
      "\n",
      "Fold: 3  Epoch: 639  Training loss = 1.5531  Validation loss = 3.0574  \n",
      "\n",
      "Fold: 3  Epoch: 640  Training loss = 1.5530  Validation loss = 3.0568  \n",
      "\n",
      "Fold: 3  Epoch: 641  Training loss = 1.5530  Validation loss = 3.0566  \n",
      "\n",
      "Fold: 3  Epoch: 642  Training loss = 1.5529  Validation loss = 3.0562  \n",
      "\n",
      "Fold: 3  Epoch: 643  Training loss = 1.5529  Validation loss = 3.0563  \n",
      "\n",
      "Fold: 3  Epoch: 644  Training loss = 1.5529  Validation loss = 3.0561  \n",
      "\n",
      "Fold: 3  Epoch: 645  Training loss = 1.5528  Validation loss = 3.0558  \n",
      "\n",
      "Fold: 3  Epoch: 646  Training loss = 1.5527  Validation loss = 3.0554  \n",
      "\n",
      "Fold: 3  Epoch: 647  Training loss = 1.5527  Validation loss = 3.0555  \n",
      "\n",
      "Fold: 3  Epoch: 648  Training loss = 1.5527  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 3  Epoch: 649  Training loss = 1.5526  Validation loss = 3.0552  \n",
      "\n",
      "Fold: 3  Epoch: 650  Training loss = 1.5526  Validation loss = 3.0551  \n",
      "\n",
      "Fold: 3  Epoch: 651  Training loss = 1.5525  Validation loss = 3.0546  \n",
      "\n",
      "Fold: 3  Epoch: 652  Training loss = 1.5525  Validation loss = 3.0546  \n",
      "\n",
      "Fold: 3  Epoch: 653  Training loss = 1.5525  Validation loss = 3.0543  \n",
      "\n",
      "Fold: 3  Epoch: 654  Training loss = 1.5524  Validation loss = 3.0540  \n",
      "\n",
      "Fold: 3  Epoch: 655  Training loss = 1.5524  Validation loss = 3.0538  \n",
      "\n",
      "Fold: 3  Epoch: 656  Training loss = 1.5523  Validation loss = 3.0537  \n",
      "\n",
      "Fold: 3  Epoch: 657  Training loss = 1.5523  Validation loss = 3.0536  \n",
      "\n",
      "Fold: 3  Epoch: 658  Training loss = 1.5522  Validation loss = 3.0533  \n",
      "\n",
      "Fold: 3  Epoch: 659  Training loss = 1.5522  Validation loss = 3.0527  \n",
      "\n",
      "Fold: 3  Epoch: 660  Training loss = 1.5521  Validation loss = 3.0526  \n",
      "\n",
      "Fold: 3  Epoch: 661  Training loss = 1.5520  Validation loss = 3.0521  \n",
      "\n",
      "Fold: 3  Epoch: 662  Training loss = 1.5520  Validation loss = 3.0514  \n",
      "\n",
      "Fold: 3  Epoch: 663  Training loss = 1.5519  Validation loss = 3.0509  \n",
      "\n",
      "Fold: 3  Epoch: 664  Training loss = 1.5518  Validation loss = 3.0509  \n",
      "\n",
      "Fold: 3  Epoch: 665  Training loss = 1.5518  Validation loss = 3.0504  \n",
      "\n",
      "Fold: 3  Epoch: 666  Training loss = 1.5518  Validation loss = 3.0503  \n",
      "\n",
      "Fold: 3  Epoch: 667  Training loss = 1.5517  Validation loss = 3.0500  \n",
      "\n",
      "Fold: 3  Epoch: 668  Training loss = 1.5517  Validation loss = 3.0498  \n",
      "\n",
      "Fold: 3  Epoch: 669  Training loss = 1.5516  Validation loss = 3.0498  \n",
      "\n",
      "Fold: 3  Epoch: 670  Training loss = 1.5516  Validation loss = 3.0495  \n",
      "\n",
      "Fold: 3  Epoch: 671  Training loss = 1.5515  Validation loss = 3.0494  \n",
      "\n",
      "Fold: 3  Epoch: 672  Training loss = 1.5515  Validation loss = 3.0492  \n",
      "\n",
      "Fold: 3  Epoch: 673  Training loss = 1.5514  Validation loss = 3.0487  \n",
      "\n",
      "Fold: 3  Epoch: 674  Training loss = 1.5514  Validation loss = 3.0485  \n",
      "\n",
      "Fold: 3  Epoch: 675  Training loss = 1.5513  Validation loss = 3.0480  \n",
      "\n",
      "Fold: 3  Epoch: 676  Training loss = 1.5513  Validation loss = 3.0477  \n",
      "\n",
      "Fold: 3  Epoch: 677  Training loss = 1.5512  Validation loss = 3.0476  \n",
      "\n",
      "Fold: 3  Epoch: 678  Training loss = 1.5512  Validation loss = 3.0470  \n",
      "\n",
      "Fold: 3  Epoch: 679  Training loss = 1.5511  Validation loss = 3.0467  \n",
      "\n",
      "Fold: 3  Epoch: 680  Training loss = 1.5511  Validation loss = 3.0467  \n",
      "\n",
      "Fold: 3  Epoch: 681  Training loss = 1.5511  Validation loss = 3.0465  \n",
      "\n",
      "Fold: 3  Epoch: 682  Training loss = 1.5510  Validation loss = 3.0463  \n",
      "\n",
      "Fold: 3  Epoch: 683  Training loss = 1.5510  Validation loss = 3.0458  \n",
      "\n",
      "Fold: 3  Epoch: 684  Training loss = 1.5509  Validation loss = 3.0454  \n",
      "\n",
      "Fold: 3  Epoch: 685  Training loss = 1.5509  Validation loss = 3.0452  \n",
      "\n",
      "Fold: 3  Epoch: 686  Training loss = 1.5508  Validation loss = 3.0453  \n",
      "\n",
      "Fold: 3  Epoch: 687  Training loss = 1.5508  Validation loss = 3.0452  \n",
      "\n",
      "Fold: 3  Epoch: 688  Training loss = 1.5507  Validation loss = 3.0451  \n",
      "\n",
      "Fold: 3  Epoch: 689  Training loss = 1.5507  Validation loss = 3.0446  \n",
      "\n",
      "Fold: 3  Epoch: 690  Training loss = 1.5507  Validation loss = 3.0444  \n",
      "\n",
      "Fold: 3  Epoch: 691  Training loss = 1.5506  Validation loss = 3.0440  \n",
      "\n",
      "Fold: 3  Epoch: 692  Training loss = 1.5505  Validation loss = 3.0438  \n",
      "\n",
      "Fold: 3  Epoch: 693  Training loss = 1.5505  Validation loss = 3.0433  \n",
      "\n",
      "Fold: 3  Epoch: 694  Training loss = 1.5504  Validation loss = 3.0429  \n",
      "\n",
      "Fold: 3  Epoch: 695  Training loss = 1.5504  Validation loss = 3.0426  \n",
      "\n",
      "Fold: 3  Epoch: 696  Training loss = 1.5504  Validation loss = 3.0426  \n",
      "\n",
      "Fold: 3  Epoch: 697  Training loss = 1.5503  Validation loss = 3.0424  \n",
      "\n",
      "Fold: 3  Epoch: 698  Training loss = 1.5503  Validation loss = 3.0422  \n",
      "\n",
      "Fold: 3  Epoch: 699  Training loss = 1.5502  Validation loss = 3.0420  \n",
      "\n",
      "Fold: 3  Epoch: 700  Training loss = 1.5502  Validation loss = 3.0418  \n",
      "\n",
      "Fold: 3  Epoch: 701  Training loss = 1.5501  Validation loss = 3.0417  \n",
      "\n",
      "Fold: 3  Epoch: 702  Training loss = 1.5501  Validation loss = 3.0415  \n",
      "\n",
      "Fold: 3  Epoch: 703  Training loss = 1.5500  Validation loss = 3.0409  \n",
      "\n",
      "Fold: 3  Epoch: 704  Training loss = 1.5500  Validation loss = 3.0407  \n",
      "\n",
      "Fold: 3  Epoch: 705  Training loss = 1.5499  Validation loss = 3.0407  \n",
      "\n",
      "Fold: 3  Epoch: 706  Training loss = 1.5499  Validation loss = 3.0407  \n",
      "\n",
      "Fold: 3  Epoch: 707  Training loss = 1.5498  Validation loss = 3.0402  \n",
      "\n",
      "Fold: 3  Epoch: 708  Training loss = 1.5498  Validation loss = 3.0404  \n",
      "\n",
      "Fold: 3  Epoch: 709  Training loss = 1.5498  Validation loss = 3.0405  \n",
      "\n",
      "Fold: 3  Epoch: 710  Training loss = 1.5498  Validation loss = 3.0406  \n",
      "\n",
      "Fold: 3  Epoch: 711  Training loss = 1.5497  Validation loss = 3.0403  \n",
      "\n",
      "Fold: 3  Epoch: 712  Training loss = 1.5496  Validation loss = 3.0400  \n",
      "\n",
      "Fold: 3  Epoch: 713  Training loss = 1.5496  Validation loss = 3.0396  \n",
      "\n",
      "Fold: 3  Epoch: 714  Training loss = 1.5496  Validation loss = 3.0395  \n",
      "\n",
      "Fold: 3  Epoch: 715  Training loss = 1.5495  Validation loss = 3.0395  \n",
      "\n",
      "Fold: 3  Epoch: 716  Training loss = 1.5495  Validation loss = 3.0395  \n",
      "\n",
      "Fold: 3  Epoch: 717  Training loss = 1.5495  Validation loss = 3.0394  \n",
      "\n",
      "Fold: 3  Epoch: 718  Training loss = 1.5494  Validation loss = 3.0393  \n",
      "\n",
      "Fold: 3  Epoch: 719  Training loss = 1.5493  Validation loss = 3.0387  \n",
      "\n",
      "Fold: 3  Epoch: 720  Training loss = 1.5493  Validation loss = 3.0383  \n",
      "\n",
      "Fold: 3  Epoch: 721  Training loss = 1.5492  Validation loss = 3.0381  \n",
      "\n",
      "Fold: 3  Epoch: 722  Training loss = 1.5492  Validation loss = 3.0378  \n",
      "\n",
      "Fold: 3  Epoch: 723  Training loss = 1.5491  Validation loss = 3.0378  \n",
      "\n",
      "Fold: 3  Epoch: 724  Training loss = 1.5491  Validation loss = 3.0375  \n",
      "\n",
      "Fold: 3  Epoch: 725  Training loss = 1.5491  Validation loss = 3.0377  \n",
      "\n",
      "Fold: 3  Epoch: 726  Training loss = 1.5491  Validation loss = 3.0376  \n",
      "\n",
      "Fold: 3  Epoch: 727  Training loss = 1.5490  Validation loss = 3.0374  \n",
      "\n",
      "Fold: 3  Epoch: 728  Training loss = 1.5490  Validation loss = 3.0371  \n",
      "\n",
      "Fold: 3  Epoch: 729  Training loss = 1.5489  Validation loss = 3.0367  \n",
      "\n",
      "Fold: 3  Epoch: 730  Training loss = 1.5489  Validation loss = 3.0364  \n",
      "\n",
      "Fold: 3  Epoch: 731  Training loss = 1.5489  Validation loss = 3.0367  \n",
      "\n",
      "Fold: 3  Epoch: 732  Training loss = 1.5488  Validation loss = 3.0366  \n",
      "\n",
      "Fold: 3  Epoch: 733  Training loss = 1.5488  Validation loss = 3.0363  \n",
      "\n",
      "Fold: 3  Epoch: 734  Training loss = 1.5487  Validation loss = 3.0355  \n",
      "\n",
      "Fold: 3  Epoch: 735  Training loss = 1.5487  Validation loss = 3.0352  \n",
      "\n",
      "Fold: 3  Epoch: 736  Training loss = 1.5487  Validation loss = 3.0354  \n",
      "\n",
      "Fold: 3  Epoch: 737  Training loss = 1.5486  Validation loss = 3.0349  \n",
      "\n",
      "Fold: 3  Epoch: 738  Training loss = 1.5485  Validation loss = 3.0347  \n",
      "\n",
      "Fold: 3  Epoch: 739  Training loss = 1.5485  Validation loss = 3.0343  \n",
      "\n",
      "Fold: 3  Epoch: 740  Training loss = 1.5485  Validation loss = 3.0343  \n",
      "\n",
      "Fold: 3  Epoch: 741  Training loss = 1.5484  Validation loss = 3.0342  \n",
      "\n",
      "Fold: 3  Epoch: 742  Training loss = 1.5484  Validation loss = 3.0342  \n",
      "\n",
      "Fold: 3  Epoch: 743  Training loss = 1.5483  Validation loss = 3.0339  \n",
      "\n",
      "Fold: 3  Epoch: 744  Training loss = 1.5483  Validation loss = 3.0338  \n",
      "\n",
      "Fold: 3  Epoch: 745  Training loss = 1.5483  Validation loss = 3.0337  \n",
      "\n",
      "Fold: 3  Epoch: 746  Training loss = 1.5482  Validation loss = 3.0334  \n",
      "\n",
      "Fold: 3  Epoch: 747  Training loss = 1.5482  Validation loss = 3.0334  \n",
      "\n",
      "Fold: 3  Epoch: 748  Training loss = 1.5481  Validation loss = 3.0326  \n",
      "\n",
      "Fold: 3  Epoch: 749  Training loss = 1.5480  Validation loss = 3.0321  \n",
      "\n",
      "Fold: 3  Epoch: 750  Training loss = 1.5479  Validation loss = 3.0317  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 750  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.6219  Validation loss = 4.3299  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.6218  Validation loss = 4.3298  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.6218  Validation loss = 4.3296  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.6217  Validation loss = 4.3294  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.6217  Validation loss = 4.3290  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.6216  Validation loss = 4.3286  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.6215  Validation loss = 4.3283  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.6214  Validation loss = 4.3277  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.6213  Validation loss = 4.3271  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.6213  Validation loss = 4.3269  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.6212  Validation loss = 4.3266  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.6211  Validation loss = 4.3259  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.6210  Validation loss = 4.3255  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.6209  Validation loss = 4.3251  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.6209  Validation loss = 4.3249  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.6208  Validation loss = 4.3248  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.6207  Validation loss = 4.3241  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.6207  Validation loss = 4.3241  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.6206  Validation loss = 4.3237  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.6205  Validation loss = 4.3233  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.6204  Validation loss = 4.3227  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.6203  Validation loss = 4.3222  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.6202  Validation loss = 4.3216  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.6201  Validation loss = 4.3212  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.6201  Validation loss = 4.3211  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.6200  Validation loss = 4.3209  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.6200  Validation loss = 4.3205  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.6199  Validation loss = 4.3200  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.6198  Validation loss = 4.3197  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.6197  Validation loss = 4.3193  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.6196  Validation loss = 4.3187  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.6196  Validation loss = 4.3186  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.6195  Validation loss = 4.3183  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.6194  Validation loss = 4.3177  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.6193  Validation loss = 4.3174  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.6192  Validation loss = 4.3165  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.6191  Validation loss = 4.3160  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.6190  Validation loss = 4.3153  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.6188  Validation loss = 4.3147  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.6187  Validation loss = 4.3143  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.6187  Validation loss = 4.3139  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.6186  Validation loss = 4.3137  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.6185  Validation loss = 4.3131  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.6184  Validation loss = 4.3126  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.6183  Validation loss = 4.3122  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.6183  Validation loss = 4.3119  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.6182  Validation loss = 4.3116  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.6181  Validation loss = 4.3110  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.6180  Validation loss = 4.3106  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.6179  Validation loss = 4.3099  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.6178  Validation loss = 4.3093  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.6177  Validation loss = 4.3088  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.6176  Validation loss = 4.3085  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.6175  Validation loss = 4.3079  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.6174  Validation loss = 4.3074  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.6173  Validation loss = 4.3070  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.6172  Validation loss = 4.3065  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.6171  Validation loss = 4.3060  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.6171  Validation loss = 4.3058  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.6171  Validation loss = 4.3057  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.6170  Validation loss = 4.3052  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.6169  Validation loss = 4.3050  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.6168  Validation loss = 4.3042  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.6167  Validation loss = 4.3039  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.6166  Validation loss = 4.3035  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.6165  Validation loss = 4.3029  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.6165  Validation loss = 4.3026  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.6163  Validation loss = 4.3019  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.6162  Validation loss = 4.3013  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.6162  Validation loss = 4.3011  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.6161  Validation loss = 4.3009  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.6160  Validation loss = 4.3002  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.6158  Validation loss = 4.2994  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.6158  Validation loss = 4.2991  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.6157  Validation loss = 4.2985  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.6156  Validation loss = 4.2980  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.6155  Validation loss = 4.2976  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.6155  Validation loss = 4.2972  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.6153  Validation loss = 4.2965  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.6153  Validation loss = 4.2961  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.6152  Validation loss = 4.2959  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.6150  Validation loss = 4.2949  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.6150  Validation loss = 4.2946  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.6149  Validation loss = 4.2938  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.6148  Validation loss = 4.2936  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.6147  Validation loss = 4.2932  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.6147  Validation loss = 4.2927  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.6146  Validation loss = 4.2922  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.6145  Validation loss = 4.2918  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.6144  Validation loss = 4.2916  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.6144  Validation loss = 4.2914  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.6143  Validation loss = 4.2910  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.6142  Validation loss = 4.2906  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.6142  Validation loss = 4.2902  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.6141  Validation loss = 4.2898  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.6141  Validation loss = 4.2898  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.6140  Validation loss = 4.2894  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.6139  Validation loss = 4.2889  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.6138  Validation loss = 4.2884  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.6138  Validation loss = 4.2880  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.6137  Validation loss = 4.2876  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.6136  Validation loss = 4.2870  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.6135  Validation loss = 4.2864  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.6134  Validation loss = 4.2862  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.6133  Validation loss = 4.2856  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.6132  Validation loss = 4.2851  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.6131  Validation loss = 4.2845  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.6131  Validation loss = 4.2844  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.6129  Validation loss = 4.2836  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.6128  Validation loss = 4.2831  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.6127  Validation loss = 4.2825  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.6127  Validation loss = 4.2820  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.6125  Validation loss = 4.2815  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.6125  Validation loss = 4.2812  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.6124  Validation loss = 4.2809  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.6124  Validation loss = 4.2806  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.6122  Validation loss = 4.2800  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.6122  Validation loss = 4.2797  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.6121  Validation loss = 4.2793  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.6120  Validation loss = 4.2791  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.6120  Validation loss = 4.2792  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.6119  Validation loss = 4.2788  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.6118  Validation loss = 4.2781  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.6118  Validation loss = 4.2778  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.6117  Validation loss = 4.2778  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.6117  Validation loss = 4.2775  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.6116  Validation loss = 4.2772  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.6115  Validation loss = 4.2767  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.6115  Validation loss = 4.2767  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.6114  Validation loss = 4.2762  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.6113  Validation loss = 4.2758  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.6112  Validation loss = 4.2753  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.6111  Validation loss = 4.2746  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.6110  Validation loss = 4.2740  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.6110  Validation loss = 4.2739  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.6110  Validation loss = 4.2739  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.6109  Validation loss = 4.2736  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.6108  Validation loss = 4.2733  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.6108  Validation loss = 4.2729  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.6107  Validation loss = 4.2724  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.6107  Validation loss = 4.2724  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.6106  Validation loss = 4.2720  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.6105  Validation loss = 4.2714  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.6104  Validation loss = 4.2710  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.6103  Validation loss = 4.2704  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.6103  Validation loss = 4.2702  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.6102  Validation loss = 4.2697  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.6101  Validation loss = 4.2694  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.6100  Validation loss = 4.2690  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.6100  Validation loss = 4.2692  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.6099  Validation loss = 4.2687  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.6099  Validation loss = 4.2685  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.6098  Validation loss = 4.2679  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.6097  Validation loss = 4.2674  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.6096  Validation loss = 4.2669  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.6095  Validation loss = 4.2666  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.6095  Validation loss = 4.2665  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.6094  Validation loss = 4.2662  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.6093  Validation loss = 4.2655  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.6092  Validation loss = 4.2653  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.6092  Validation loss = 4.2650  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.6091  Validation loss = 4.2648  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.6091  Validation loss = 4.2644  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.6090  Validation loss = 4.2642  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.6088  Validation loss = 4.2634  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.6088  Validation loss = 4.2631  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.6087  Validation loss = 4.2629  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.6086  Validation loss = 4.2623  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.6086  Validation loss = 4.2619  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.6084  Validation loss = 4.2612  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.6083  Validation loss = 4.2606  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.6082  Validation loss = 4.2601  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.6081  Validation loss = 4.2593  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.6080  Validation loss = 4.2590  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.6080  Validation loss = 4.2587  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.6079  Validation loss = 4.2583  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.6078  Validation loss = 4.2581  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.6078  Validation loss = 4.2577  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.6076  Validation loss = 4.2570  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.6075  Validation loss = 4.2562  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.6075  Validation loss = 4.2560  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.6073  Validation loss = 4.2555  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.6073  Validation loss = 4.2551  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.6072  Validation loss = 4.2547  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.6071  Validation loss = 4.2544  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.6070  Validation loss = 4.2538  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.6070  Validation loss = 4.2536  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.6069  Validation loss = 4.2533  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.6068  Validation loss = 4.2530  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.6068  Validation loss = 4.2526  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.6066  Validation loss = 4.2520  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.6065  Validation loss = 4.2515  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.6064  Validation loss = 4.2507  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.6063  Validation loss = 4.2502  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.6062  Validation loss = 4.2498  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.6062  Validation loss = 4.2494  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.6061  Validation loss = 4.2490  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.6060  Validation loss = 4.2487  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.6059  Validation loss = 4.2480  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.6058  Validation loss = 4.2474  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.6057  Validation loss = 4.2469  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.6056  Validation loss = 4.2462  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.6056  Validation loss = 4.2460  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.6055  Validation loss = 4.2456  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.6053  Validation loss = 4.2449  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.6053  Validation loss = 4.2445  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.6052  Validation loss = 4.2443  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.6051  Validation loss = 4.2439  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.6051  Validation loss = 4.2437  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.6050  Validation loss = 4.2436  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.6049  Validation loss = 4.2431  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.6047  Validation loss = 4.2421  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.6047  Validation loss = 4.2419  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.6046  Validation loss = 4.2416  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.6045  Validation loss = 4.2413  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.6044  Validation loss = 4.2405  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.6043  Validation loss = 4.2401  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.6042  Validation loss = 4.2396  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.6041  Validation loss = 4.2389  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.6040  Validation loss = 4.2384  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.6039  Validation loss = 4.2380  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.6039  Validation loss = 4.2383  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.6038  Validation loss = 4.2377  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.6037  Validation loss = 4.2371  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.6037  Validation loss = 4.2373  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.6037  Validation loss = 4.2374  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.6036  Validation loss = 4.2371  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.6034  Validation loss = 4.2362  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.6033  Validation loss = 4.2357  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.6033  Validation loss = 4.2353  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.6032  Validation loss = 4.2349  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.6031  Validation loss = 4.2343  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.6031  Validation loss = 4.2342  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.6030  Validation loss = 4.2340  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.6030  Validation loss = 4.2339  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.6029  Validation loss = 4.2335  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.6028  Validation loss = 4.2329  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.6027  Validation loss = 4.2326  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.6027  Validation loss = 4.2326  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.6026  Validation loss = 4.2317  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.6024  Validation loss = 4.2308  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.6023  Validation loss = 4.2301  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.6022  Validation loss = 4.2298  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.6021  Validation loss = 4.2292  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.6020  Validation loss = 4.2288  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.6019  Validation loss = 4.2280  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.6018  Validation loss = 4.2276  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.6017  Validation loss = 4.2274  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.6017  Validation loss = 4.2271  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.6016  Validation loss = 4.2266  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.6015  Validation loss = 4.2265  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.6014  Validation loss = 4.2259  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.6014  Validation loss = 4.2259  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.6013  Validation loss = 4.2252  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.6011  Validation loss = 4.2246  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.6010  Validation loss = 4.2240  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.6009  Validation loss = 4.2235  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.6008  Validation loss = 4.2227  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.6007  Validation loss = 4.2225  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.6006  Validation loss = 4.2220  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.6005  Validation loss = 4.2214  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.6005  Validation loss = 4.2212  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.6004  Validation loss = 4.2209  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.6004  Validation loss = 4.2205  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.6003  Validation loss = 4.2201  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.6002  Validation loss = 4.2195  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.6002  Validation loss = 4.2198  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.6001  Validation loss = 4.2193  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.6000  Validation loss = 4.2190  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.5999  Validation loss = 4.2188  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.5999  Validation loss = 4.2184  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.5998  Validation loss = 4.2183  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.5997  Validation loss = 4.2178  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.5996  Validation loss = 4.2174  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.5996  Validation loss = 4.2171  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.5995  Validation loss = 4.2168  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.5994  Validation loss = 4.2166  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.5994  Validation loss = 4.2162  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.5993  Validation loss = 4.2161  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.5992  Validation loss = 4.2157  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.5992  Validation loss = 4.2154  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.5991  Validation loss = 4.2149  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.5990  Validation loss = 4.2147  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.5990  Validation loss = 4.2148  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.5989  Validation loss = 4.2142  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.5988  Validation loss = 4.2139  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.5988  Validation loss = 4.2136  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.5987  Validation loss = 4.2131  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.5985  Validation loss = 4.2123  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.5984  Validation loss = 4.2118  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.5984  Validation loss = 4.2115  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.5984  Validation loss = 4.2116  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.5983  Validation loss = 4.2113  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.5982  Validation loss = 4.2109  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.5981  Validation loss = 4.2107  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.5980  Validation loss = 4.2097  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.5979  Validation loss = 4.2093  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.5979  Validation loss = 4.2094  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.5978  Validation loss = 4.2089  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.5977  Validation loss = 4.2087  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.5975  Validation loss = 4.2078  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.5974  Validation loss = 4.2073  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.5973  Validation loss = 4.2068  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.5973  Validation loss = 4.2067  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.5972  Validation loss = 4.2060  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.5971  Validation loss = 4.2059  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.5970  Validation loss = 4.2055  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.5969  Validation loss = 4.2049  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.5968  Validation loss = 4.2045  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.5968  Validation loss = 4.2042  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.5967  Validation loss = 4.2042  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.5967  Validation loss = 4.2042  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.5966  Validation loss = 4.2038  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.5965  Validation loss = 4.2033  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.5965  Validation loss = 4.2031  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.5964  Validation loss = 4.2026  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.5964  Validation loss = 4.2026  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.5962  Validation loss = 4.2020  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.5962  Validation loss = 4.2017  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.5961  Validation loss = 4.2013  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.5960  Validation loss = 4.2010  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.5960  Validation loss = 4.2006  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.5959  Validation loss = 4.2003  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.5957  Validation loss = 4.1995  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.5956  Validation loss = 4.1988  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.5956  Validation loss = 4.1985  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.5955  Validation loss = 4.1983  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.5954  Validation loss = 4.1977  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.5953  Validation loss = 4.1976  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.5953  Validation loss = 4.1973  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.5952  Validation loss = 4.1972  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.5951  Validation loss = 4.1965  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.5949  Validation loss = 4.1957  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.5948  Validation loss = 4.1954  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.5947  Validation loss = 4.1950  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.5947  Validation loss = 4.1946  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.5946  Validation loss = 4.1945  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.5946  Validation loss = 4.1941  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.5945  Validation loss = 4.1942  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.5944  Validation loss = 4.1936  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.5943  Validation loss = 4.1931  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.5942  Validation loss = 4.1922  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.5940  Validation loss = 4.1916  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.5940  Validation loss = 4.1916  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.5939  Validation loss = 4.1913  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.5939  Validation loss = 4.1910  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.5938  Validation loss = 4.1908  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.5937  Validation loss = 4.1902  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.5936  Validation loss = 4.1898  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.5935  Validation loss = 4.1893  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.5935  Validation loss = 4.1892  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.5933  Validation loss = 4.1886  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.5932  Validation loss = 4.1882  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.5931  Validation loss = 4.1878  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.5931  Validation loss = 4.1874  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.5930  Validation loss = 4.1872  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.5929  Validation loss = 4.1869  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.5928  Validation loss = 4.1864  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.5928  Validation loss = 4.1863  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.5927  Validation loss = 4.1859  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.5926  Validation loss = 4.1855  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.5925  Validation loss = 4.1849  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.5925  Validation loss = 4.1848  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.5924  Validation loss = 4.1844  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.5923  Validation loss = 4.1842  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.5922  Validation loss = 4.1833  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.5922  Validation loss = 4.1833  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.5921  Validation loss = 4.1832  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.5921  Validation loss = 4.1832  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.5920  Validation loss = 4.1827  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.5919  Validation loss = 4.1820  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.5918  Validation loss = 4.1816  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.5917  Validation loss = 4.1814  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.5917  Validation loss = 4.1813  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.5916  Validation loss = 4.1813  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.5916  Validation loss = 4.1813  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.5915  Validation loss = 4.1808  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.5914  Validation loss = 4.1804  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.5914  Validation loss = 4.1803  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.5912  Validation loss = 4.1795  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.5912  Validation loss = 4.1792  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.5910  Validation loss = 4.1784  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.5909  Validation loss = 4.1779  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.5908  Validation loss = 4.1776  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.5907  Validation loss = 4.1769  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.5907  Validation loss = 4.1768  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.5906  Validation loss = 4.1766  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.5905  Validation loss = 4.1762  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.5904  Validation loss = 4.1755  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.5902  Validation loss = 4.1748  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.5901  Validation loss = 4.1743  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.5901  Validation loss = 4.1741  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.5900  Validation loss = 4.1741  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.5900  Validation loss = 4.1744  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.5900  Validation loss = 4.1742  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.5900  Validation loss = 4.1743  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.5898  Validation loss = 4.1737  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.5898  Validation loss = 4.1737  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.5897  Validation loss = 4.1736  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.5897  Validation loss = 4.1735  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.5896  Validation loss = 4.1730  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.5895  Validation loss = 4.1725  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.5894  Validation loss = 4.1717  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.5894  Validation loss = 4.1716  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.5893  Validation loss = 4.1714  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.5892  Validation loss = 4.1711  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.5891  Validation loss = 4.1708  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.5890  Validation loss = 4.1703  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.5890  Validation loss = 4.1701  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.5888  Validation loss = 4.1695  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.5888  Validation loss = 4.1696  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.5887  Validation loss = 4.1691  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.5887  Validation loss = 4.1689  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.5886  Validation loss = 4.1687  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.5886  Validation loss = 4.1690  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.5885  Validation loss = 4.1683  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.5884  Validation loss = 4.1681  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.5884  Validation loss = 4.1679  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.5882  Validation loss = 4.1673  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.5882  Validation loss = 4.1673  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.5882  Validation loss = 4.1672  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.5881  Validation loss = 4.1667  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.5880  Validation loss = 4.1663  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.5879  Validation loss = 4.1663  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.5878  Validation loss = 4.1659  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.5877  Validation loss = 4.1656  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.5876  Validation loss = 4.1649  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.5875  Validation loss = 4.1644  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.5874  Validation loss = 4.1639  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.5873  Validation loss = 4.1637  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.5873  Validation loss = 4.1633  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.5872  Validation loss = 4.1634  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.5872  Validation loss = 4.1632  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.5871  Validation loss = 4.1627  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.5870  Validation loss = 4.1624  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.5870  Validation loss = 4.1624  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.5868  Validation loss = 4.1614  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.5867  Validation loss = 4.1608  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.5866  Validation loss = 4.1604  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.5866  Validation loss = 4.1602  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.5865  Validation loss = 4.1597  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.5863  Validation loss = 4.1589  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.5862  Validation loss = 4.1589  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.5862  Validation loss = 4.1587  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.5861  Validation loss = 4.1583  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.5861  Validation loss = 4.1581  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.5859  Validation loss = 4.1574  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.5859  Validation loss = 4.1574  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.5857  Validation loss = 4.1568  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.5856  Validation loss = 4.1562  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.5855  Validation loss = 4.1560  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.5854  Validation loss = 4.1556  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.5853  Validation loss = 4.1550  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.5852  Validation loss = 4.1547  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.5851  Validation loss = 4.1542  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.5850  Validation loss = 4.1538  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.5849  Validation loss = 4.1532  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.5848  Validation loss = 4.1527  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.5847  Validation loss = 4.1522  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.5845  Validation loss = 4.1515  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.5845  Validation loss = 4.1514  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.5844  Validation loss = 4.1511  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.5843  Validation loss = 4.1505  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.5843  Validation loss = 4.1505  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.5842  Validation loss = 4.1505  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.5842  Validation loss = 4.1505  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.5841  Validation loss = 4.1502  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.5840  Validation loss = 4.1499  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.5839  Validation loss = 4.1495  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.5839  Validation loss = 4.1494  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.5838  Validation loss = 4.1487  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.5837  Validation loss = 4.1484  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.5836  Validation loss = 4.1479  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.5835  Validation loss = 4.1473  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.5834  Validation loss = 4.1468  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.5833  Validation loss = 4.1465  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.5833  Validation loss = 4.1465  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.5830  Validation loss = 4.1455  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.5830  Validation loss = 4.1453  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.5829  Validation loss = 4.1449  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.5828  Validation loss = 4.1444  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.5827  Validation loss = 4.1443  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.5827  Validation loss = 4.1442  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.5826  Validation loss = 4.1440  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.5825  Validation loss = 4.1435  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.5825  Validation loss = 4.1432  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.5824  Validation loss = 4.1431  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.5823  Validation loss = 4.1429  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.5822  Validation loss = 4.1424  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.5821  Validation loss = 4.1418  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.5820  Validation loss = 4.1412  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.5819  Validation loss = 4.1406  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.5818  Validation loss = 4.1403  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.5817  Validation loss = 4.1399  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.5816  Validation loss = 4.1395  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.5814  Validation loss = 4.1389  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.5813  Validation loss = 4.1384  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.5813  Validation loss = 4.1384  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.5813  Validation loss = 4.1384  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.5812  Validation loss = 4.1380  \n",
      "\n",
      "Fold: 4  Epoch: 501  Training loss = 1.5811  Validation loss = 4.1375  \n",
      "\n",
      "Fold: 4  Epoch: 502  Training loss = 1.5810  Validation loss = 4.1371  \n",
      "\n",
      "Fold: 4  Epoch: 503  Training loss = 1.5808  Validation loss = 4.1363  \n",
      "\n",
      "Fold: 4  Epoch: 504  Training loss = 1.5808  Validation loss = 4.1362  \n",
      "\n",
      "Fold: 4  Epoch: 505  Training loss = 1.5805  Validation loss = 4.1352  \n",
      "\n",
      "Fold: 4  Epoch: 506  Training loss = 1.5805  Validation loss = 4.1347  \n",
      "\n",
      "Fold: 4  Epoch: 507  Training loss = 1.5804  Validation loss = 4.1345  \n",
      "\n",
      "Fold: 4  Epoch: 508  Training loss = 1.5803  Validation loss = 4.1343  \n",
      "\n",
      "Fold: 4  Epoch: 509  Training loss = 1.5803  Validation loss = 4.1339  \n",
      "\n",
      "Fold: 4  Epoch: 510  Training loss = 1.5802  Validation loss = 4.1337  \n",
      "\n",
      "Fold: 4  Epoch: 511  Training loss = 1.5801  Validation loss = 4.1334  \n",
      "\n",
      "Fold: 4  Epoch: 512  Training loss = 1.5800  Validation loss = 4.1331  \n",
      "\n",
      "Fold: 4  Epoch: 513  Training loss = 1.5800  Validation loss = 4.1330  \n",
      "\n",
      "Fold: 4  Epoch: 514  Training loss = 1.5799  Validation loss = 4.1327  \n",
      "\n",
      "Fold: 4  Epoch: 515  Training loss = 1.5798  Validation loss = 4.1321  \n",
      "\n",
      "Fold: 4  Epoch: 516  Training loss = 1.5797  Validation loss = 4.1320  \n",
      "\n",
      "Fold: 4  Epoch: 517  Training loss = 1.5796  Validation loss = 4.1318  \n",
      "\n",
      "Fold: 4  Epoch: 518  Training loss = 1.5796  Validation loss = 4.1316  \n",
      "\n",
      "Fold: 4  Epoch: 519  Training loss = 1.5795  Validation loss = 4.1312  \n",
      "\n",
      "Fold: 4  Epoch: 520  Training loss = 1.5794  Validation loss = 4.1311  \n",
      "\n",
      "Fold: 4  Epoch: 521  Training loss = 1.5794  Validation loss = 4.1312  \n",
      "\n",
      "Fold: 4  Epoch: 522  Training loss = 1.5794  Validation loss = 4.1311  \n",
      "\n",
      "Fold: 4  Epoch: 523  Training loss = 1.5793  Validation loss = 4.1308  \n",
      "\n",
      "Fold: 4  Epoch: 524  Training loss = 1.5792  Validation loss = 4.1305  \n",
      "\n",
      "Fold: 4  Epoch: 525  Training loss = 1.5791  Validation loss = 4.1303  \n",
      "\n",
      "Fold: 4  Epoch: 526  Training loss = 1.5790  Validation loss = 4.1299  \n",
      "\n",
      "Fold: 4  Epoch: 527  Training loss = 1.5789  Validation loss = 4.1297  \n",
      "\n",
      "Fold: 4  Epoch: 528  Training loss = 1.5789  Validation loss = 4.1295  \n",
      "\n",
      "Fold: 4  Epoch: 529  Training loss = 1.5788  Validation loss = 4.1290  \n",
      "\n",
      "Fold: 4  Epoch: 530  Training loss = 1.5788  Validation loss = 4.1290  \n",
      "\n",
      "Fold: 4  Epoch: 531  Training loss = 1.5786  Validation loss = 4.1283  \n",
      "\n",
      "Fold: 4  Epoch: 532  Training loss = 1.5785  Validation loss = 4.1277  \n",
      "\n",
      "Fold: 4  Epoch: 533  Training loss = 1.5785  Validation loss = 4.1277  \n",
      "\n",
      "Fold: 4  Epoch: 534  Training loss = 1.5784  Validation loss = 4.1274  \n",
      "\n",
      "Fold: 4  Epoch: 535  Training loss = 1.5784  Validation loss = 4.1277  \n",
      "\n",
      "Fold: 4  Epoch: 536  Training loss = 1.5782  Validation loss = 4.1270  \n",
      "\n",
      "Fold: 4  Epoch: 537  Training loss = 1.5781  Validation loss = 4.1262  \n",
      "\n",
      "Fold: 4  Epoch: 538  Training loss = 1.5781  Validation loss = 4.1264  \n",
      "\n",
      "Fold: 4  Epoch: 539  Training loss = 1.5780  Validation loss = 4.1263  \n",
      "\n",
      "Fold: 4  Epoch: 540  Training loss = 1.5779  Validation loss = 4.1259  \n",
      "\n",
      "Fold: 4  Epoch: 541  Training loss = 1.5779  Validation loss = 4.1261  \n",
      "\n",
      "Fold: 4  Epoch: 542  Training loss = 1.5779  Validation loss = 4.1261  \n",
      "\n",
      "Fold: 4  Epoch: 543  Training loss = 1.5778  Validation loss = 4.1258  \n",
      "\n",
      "Fold: 4  Epoch: 544  Training loss = 1.5777  Validation loss = 4.1257  \n",
      "\n",
      "Fold: 4  Epoch: 545  Training loss = 1.5776  Validation loss = 4.1252  \n",
      "\n",
      "Fold: 4  Epoch: 546  Training loss = 1.5776  Validation loss = 4.1250  \n",
      "\n",
      "Fold: 4  Epoch: 547  Training loss = 1.5774  Validation loss = 4.1243  \n",
      "\n",
      "Fold: 4  Epoch: 548  Training loss = 1.5773  Validation loss = 4.1238  \n",
      "\n",
      "Fold: 4  Epoch: 549  Training loss = 1.5773  Validation loss = 4.1237  \n",
      "\n",
      "Fold: 4  Epoch: 550  Training loss = 1.5772  Validation loss = 4.1235  \n",
      "\n",
      "Fold: 4  Epoch: 551  Training loss = 1.5772  Validation loss = 4.1232  \n",
      "\n",
      "Fold: 4  Epoch: 552  Training loss = 1.5771  Validation loss = 4.1228  \n",
      "\n",
      "Fold: 4  Epoch: 553  Training loss = 1.5770  Validation loss = 4.1225  \n",
      "\n",
      "Fold: 4  Epoch: 554  Training loss = 1.5769  Validation loss = 4.1222  \n",
      "\n",
      "Fold: 4  Epoch: 555  Training loss = 1.5769  Validation loss = 4.1220  \n",
      "\n",
      "Fold: 4  Epoch: 556  Training loss = 1.5768  Validation loss = 4.1217  \n",
      "\n",
      "Fold: 4  Epoch: 557  Training loss = 1.5768  Validation loss = 4.1216  \n",
      "\n",
      "Fold: 4  Epoch: 558  Training loss = 1.5767  Validation loss = 4.1215  \n",
      "\n",
      "Fold: 4  Epoch: 559  Training loss = 1.5766  Validation loss = 4.1211  \n",
      "\n",
      "Fold: 4  Epoch: 560  Training loss = 1.5766  Validation loss = 4.1208  \n",
      "\n",
      "Fold: 4  Epoch: 561  Training loss = 1.5765  Validation loss = 4.1206  \n",
      "\n",
      "Fold: 4  Epoch: 562  Training loss = 1.5764  Validation loss = 4.1202  \n",
      "\n",
      "Fold: 4  Epoch: 563  Training loss = 1.5763  Validation loss = 4.1202  \n",
      "\n",
      "Fold: 4  Epoch: 564  Training loss = 1.5763  Validation loss = 4.1197  \n",
      "\n",
      "Fold: 4  Epoch: 565  Training loss = 1.5762  Validation loss = 4.1194  \n",
      "\n",
      "Fold: 4  Epoch: 566  Training loss = 1.5761  Validation loss = 4.1190  \n",
      "\n",
      "Fold: 4  Epoch: 567  Training loss = 1.5760  Validation loss = 4.1191  \n",
      "\n",
      "Fold: 4  Epoch: 568  Training loss = 1.5759  Validation loss = 4.1185  \n",
      "\n",
      "Fold: 4  Epoch: 569  Training loss = 1.5758  Validation loss = 4.1181  \n",
      "\n",
      "Fold: 4  Epoch: 570  Training loss = 1.5758  Validation loss = 4.1182  \n",
      "\n",
      "Fold: 4  Epoch: 571  Training loss = 1.5757  Validation loss = 4.1178  \n",
      "\n",
      "Fold: 4  Epoch: 572  Training loss = 1.5757  Validation loss = 4.1180  \n",
      "\n",
      "Fold: 4  Epoch: 573  Training loss = 1.5756  Validation loss = 4.1173  \n",
      "\n",
      "Fold: 4  Epoch: 574  Training loss = 1.5755  Validation loss = 4.1169  \n",
      "\n",
      "Fold: 4  Epoch: 575  Training loss = 1.5755  Validation loss = 4.1168  \n",
      "\n",
      "Fold: 4  Epoch: 576  Training loss = 1.5755  Validation loss = 4.1167  \n",
      "\n",
      "Fold: 4  Epoch: 577  Training loss = 1.5755  Validation loss = 4.1169  \n",
      "\n",
      "Fold: 4  Epoch: 578  Training loss = 1.5754  Validation loss = 4.1167  \n",
      "\n",
      "Fold: 4  Epoch: 579  Training loss = 1.5753  Validation loss = 4.1161  \n",
      "\n",
      "Fold: 4  Epoch: 580  Training loss = 1.5752  Validation loss = 4.1158  \n",
      "\n",
      "Fold: 4  Epoch: 581  Training loss = 1.5752  Validation loss = 4.1154  \n",
      "\n",
      "Fold: 4  Epoch: 582  Training loss = 1.5751  Validation loss = 4.1150  \n",
      "\n",
      "Fold: 4  Epoch: 583  Training loss = 1.5751  Validation loss = 4.1151  \n",
      "\n",
      "Fold: 4  Epoch: 584  Training loss = 1.5750  Validation loss = 4.1149  \n",
      "\n",
      "Fold: 4  Epoch: 585  Training loss = 1.5749  Validation loss = 4.1140  \n",
      "\n",
      "Fold: 4  Epoch: 586  Training loss = 1.5748  Validation loss = 4.1135  \n",
      "\n",
      "Fold: 4  Epoch: 587  Training loss = 1.5747  Validation loss = 4.1133  \n",
      "\n",
      "Fold: 4  Epoch: 588  Training loss = 1.5747  Validation loss = 4.1130  \n",
      "\n",
      "Fold: 4  Epoch: 589  Training loss = 1.5746  Validation loss = 4.1127  \n",
      "\n",
      "Fold: 4  Epoch: 590  Training loss = 1.5745  Validation loss = 4.1127  \n",
      "\n",
      "Fold: 4  Epoch: 591  Training loss = 1.5745  Validation loss = 4.1128  \n",
      "\n",
      "Fold: 4  Epoch: 592  Training loss = 1.5745  Validation loss = 4.1127  \n",
      "\n",
      "Fold: 4  Epoch: 593  Training loss = 1.5744  Validation loss = 4.1126  \n",
      "\n",
      "Fold: 4  Epoch: 594  Training loss = 1.5744  Validation loss = 4.1124  \n",
      "\n",
      "Fold: 4  Epoch: 595  Training loss = 1.5743  Validation loss = 4.1120  \n",
      "\n",
      "Fold: 4  Epoch: 596  Training loss = 1.5742  Validation loss = 4.1118  \n",
      "\n",
      "Fold: 4  Epoch: 597  Training loss = 1.5741  Validation loss = 4.1112  \n",
      "\n",
      "Fold: 4  Epoch: 598  Training loss = 1.5740  Validation loss = 4.1106  \n",
      "\n",
      "Fold: 4  Epoch: 599  Training loss = 1.5739  Validation loss = 4.1101  \n",
      "\n",
      "Fold: 4  Epoch: 600  Training loss = 1.5739  Validation loss = 4.1097  \n",
      "\n",
      "Fold: 4  Epoch: 601  Training loss = 1.5738  Validation loss = 4.1093  \n",
      "\n",
      "Fold: 4  Epoch: 602  Training loss = 1.5737  Validation loss = 4.1090  \n",
      "\n",
      "Fold: 4  Epoch: 603  Training loss = 1.5736  Validation loss = 4.1087  \n",
      "\n",
      "Fold: 4  Epoch: 604  Training loss = 1.5736  Validation loss = 4.1087  \n",
      "\n",
      "Fold: 4  Epoch: 605  Training loss = 1.5736  Validation loss = 4.1086  \n",
      "\n",
      "Fold: 4  Epoch: 606  Training loss = 1.5734  Validation loss = 4.1081  \n",
      "\n",
      "Fold: 4  Epoch: 607  Training loss = 1.5734  Validation loss = 4.1075  \n",
      "\n",
      "Fold: 4  Epoch: 608  Training loss = 1.5733  Validation loss = 4.1071  \n",
      "\n",
      "Fold: 4  Epoch: 609  Training loss = 1.5733  Validation loss = 4.1071  \n",
      "\n",
      "Fold: 4  Epoch: 610  Training loss = 1.5731  Validation loss = 4.1064  \n",
      "\n",
      "Fold: 4  Epoch: 611  Training loss = 1.5730  Validation loss = 4.1061  \n",
      "\n",
      "Fold: 4  Epoch: 612  Training loss = 1.5729  Validation loss = 4.1059  \n",
      "\n",
      "Fold: 4  Epoch: 613  Training loss = 1.5729  Validation loss = 4.1055  \n",
      "\n",
      "Fold: 4  Epoch: 614  Training loss = 1.5728  Validation loss = 4.1052  \n",
      "\n",
      "Fold: 4  Epoch: 615  Training loss = 1.5727  Validation loss = 4.1050  \n",
      "\n",
      "Fold: 4  Epoch: 616  Training loss = 1.5726  Validation loss = 4.1044  \n",
      "\n",
      "Fold: 4  Epoch: 617  Training loss = 1.5725  Validation loss = 4.1037  \n",
      "\n",
      "Fold: 4  Epoch: 618  Training loss = 1.5724  Validation loss = 4.1032  \n",
      "\n",
      "Fold: 4  Epoch: 619  Training loss = 1.5724  Validation loss = 4.1029  \n",
      "\n",
      "Fold: 4  Epoch: 620  Training loss = 1.5722  Validation loss = 4.1020  \n",
      "\n",
      "Fold: 4  Epoch: 621  Training loss = 1.5722  Validation loss = 4.1022  \n",
      "\n",
      "Fold: 4  Epoch: 622  Training loss = 1.5722  Validation loss = 4.1022  \n",
      "\n",
      "Fold: 4  Epoch: 623  Training loss = 1.5721  Validation loss = 4.1021  \n",
      "\n",
      "Fold: 4  Epoch: 624  Training loss = 1.5720  Validation loss = 4.1018  \n",
      "\n",
      "Fold: 4  Epoch: 625  Training loss = 1.5720  Validation loss = 4.1021  \n",
      "\n",
      "Fold: 4  Epoch: 626  Training loss = 1.5720  Validation loss = 4.1020  \n",
      "\n",
      "Fold: 4  Epoch: 627  Training loss = 1.5719  Validation loss = 4.1017  \n",
      "\n",
      "Fold: 4  Epoch: 628  Training loss = 1.5719  Validation loss = 4.1016  \n",
      "\n",
      "Fold: 4  Epoch: 629  Training loss = 1.5718  Validation loss = 4.1013  \n",
      "\n",
      "Fold: 4  Epoch: 630  Training loss = 1.5718  Validation loss = 4.1013  \n",
      "\n",
      "Fold: 4  Epoch: 631  Training loss = 1.5718  Validation loss = 4.1011  \n",
      "\n",
      "Fold: 4  Epoch: 632  Training loss = 1.5717  Validation loss = 4.1009  \n",
      "\n",
      "Fold: 4  Epoch: 633  Training loss = 1.5716  Validation loss = 4.1004  \n",
      "\n",
      "Fold: 4  Epoch: 634  Training loss = 1.5715  Validation loss = 4.0999  \n",
      "\n",
      "Fold: 4  Epoch: 635  Training loss = 1.5713  Validation loss = 4.0992  \n",
      "\n",
      "Fold: 4  Epoch: 636  Training loss = 1.5713  Validation loss = 4.0991  \n",
      "\n",
      "Fold: 4  Epoch: 637  Training loss = 1.5711  Validation loss = 4.0982  \n",
      "\n",
      "Fold: 4  Epoch: 638  Training loss = 1.5710  Validation loss = 4.0978  \n",
      "\n",
      "Fold: 4  Epoch: 639  Training loss = 1.5709  Validation loss = 4.0973  \n",
      "\n",
      "Fold: 4  Epoch: 640  Training loss = 1.5709  Validation loss = 4.0972  \n",
      "\n",
      "Fold: 4  Epoch: 641  Training loss = 1.5708  Validation loss = 4.0971  \n",
      "\n",
      "Fold: 4  Epoch: 642  Training loss = 1.5708  Validation loss = 4.0968  \n",
      "\n",
      "Fold: 4  Epoch: 643  Training loss = 1.5708  Validation loss = 4.0969  \n",
      "\n",
      "Fold: 4  Epoch: 644  Training loss = 1.5707  Validation loss = 4.0966  \n",
      "\n",
      "Fold: 4  Epoch: 645  Training loss = 1.5706  Validation loss = 4.0963  \n",
      "\n",
      "Fold: 4  Epoch: 646  Training loss = 1.5705  Validation loss = 4.0962  \n",
      "\n",
      "Fold: 4  Epoch: 647  Training loss = 1.5705  Validation loss = 4.0964  \n",
      "\n",
      "Fold: 4  Epoch: 648  Training loss = 1.5704  Validation loss = 4.0957  \n",
      "\n",
      "Fold: 4  Epoch: 649  Training loss = 1.5703  Validation loss = 4.0953  \n",
      "\n",
      "Fold: 4  Epoch: 650  Training loss = 1.5702  Validation loss = 4.0950  \n",
      "\n",
      "Fold: 4  Epoch: 651  Training loss = 1.5702  Validation loss = 4.0949  \n",
      "\n",
      "Fold: 4  Epoch: 652  Training loss = 1.5702  Validation loss = 4.0947  \n",
      "\n",
      "Fold: 4  Epoch: 653  Training loss = 1.5701  Validation loss = 4.0947  \n",
      "\n",
      "Fold: 4  Epoch: 654  Training loss = 1.5701  Validation loss = 4.0946  \n",
      "\n",
      "Fold: 4  Epoch: 655  Training loss = 1.5700  Validation loss = 4.0939  \n",
      "\n",
      "Fold: 4  Epoch: 656  Training loss = 1.5700  Validation loss = 4.0941  \n",
      "\n",
      "Fold: 4  Epoch: 657  Training loss = 1.5699  Validation loss = 4.0939  \n",
      "\n",
      "Fold: 4  Epoch: 658  Training loss = 1.5699  Validation loss = 4.0939  \n",
      "\n",
      "Fold: 4  Epoch: 659  Training loss = 1.5698  Validation loss = 4.0937  \n",
      "\n",
      "Fold: 4  Epoch: 660  Training loss = 1.5698  Validation loss = 4.0933  \n",
      "\n",
      "Fold: 4  Epoch: 661  Training loss = 1.5696  Validation loss = 4.0927  \n",
      "\n",
      "Fold: 4  Epoch: 662  Training loss = 1.5696  Validation loss = 4.0924  \n",
      "\n",
      "Fold: 4  Epoch: 663  Training loss = 1.5695  Validation loss = 4.0920  \n",
      "\n",
      "Fold: 4  Epoch: 664  Training loss = 1.5694  Validation loss = 4.0915  \n",
      "\n",
      "Fold: 4  Epoch: 665  Training loss = 1.5694  Validation loss = 4.0915  \n",
      "\n",
      "Fold: 4  Epoch: 666  Training loss = 1.5692  Validation loss = 4.0911  \n",
      "\n",
      "Fold: 4  Epoch: 667  Training loss = 1.5692  Validation loss = 4.0911  \n",
      "\n",
      "Fold: 4  Epoch: 668  Training loss = 1.5691  Validation loss = 4.0906  \n",
      "\n",
      "Fold: 4  Epoch: 669  Training loss = 1.5690  Validation loss = 4.0901  \n",
      "\n",
      "Fold: 4  Epoch: 670  Training loss = 1.5690  Validation loss = 4.0900  \n",
      "\n",
      "Fold: 4  Epoch: 671  Training loss = 1.5689  Validation loss = 4.0895  \n",
      "\n",
      "Fold: 4  Epoch: 672  Training loss = 1.5689  Validation loss = 4.0895  \n",
      "\n",
      "Fold: 4  Epoch: 673  Training loss = 1.5688  Validation loss = 4.0893  \n",
      "\n",
      "Fold: 4  Epoch: 674  Training loss = 1.5687  Validation loss = 4.0890  \n",
      "\n",
      "Fold: 4  Epoch: 675  Training loss = 1.5687  Validation loss = 4.0890  \n",
      "\n",
      "Fold: 4  Epoch: 676  Training loss = 1.5686  Validation loss = 4.0889  \n",
      "\n",
      "Fold: 4  Epoch: 677  Training loss = 1.5686  Validation loss = 4.0888  \n",
      "\n",
      "Fold: 4  Epoch: 678  Training loss = 1.5686  Validation loss = 4.0885  \n",
      "\n",
      "Fold: 4  Epoch: 679  Training loss = 1.5685  Validation loss = 4.0883  \n",
      "\n",
      "Fold: 4  Epoch: 680  Training loss = 1.5685  Validation loss = 4.0882  \n",
      "\n",
      "Fold: 4  Epoch: 681  Training loss = 1.5684  Validation loss = 4.0876  \n",
      "\n",
      "Fold: 4  Epoch: 682  Training loss = 1.5684  Validation loss = 4.0878  \n",
      "\n",
      "Fold: 4  Epoch: 683  Training loss = 1.5684  Validation loss = 4.0879  \n",
      "\n",
      "Fold: 4  Epoch: 684  Training loss = 1.5683  Validation loss = 4.0874  \n",
      "\n",
      "Fold: 4  Epoch: 685  Training loss = 1.5682  Validation loss = 4.0875  \n",
      "\n",
      "Fold: 4  Epoch: 686  Training loss = 1.5682  Validation loss = 4.0871  \n",
      "\n",
      "Fold: 4  Epoch: 687  Training loss = 1.5681  Validation loss = 4.0871  \n",
      "\n",
      "Fold: 4  Epoch: 688  Training loss = 1.5681  Validation loss = 4.0868  \n",
      "\n",
      "Fold: 4  Epoch: 689  Training loss = 1.5680  Validation loss = 4.0867  \n",
      "\n",
      "Fold: 4  Epoch: 690  Training loss = 1.5680  Validation loss = 4.0865  \n",
      "\n",
      "Fold: 4  Epoch: 691  Training loss = 1.5679  Validation loss = 4.0864  \n",
      "\n",
      "Fold: 4  Epoch: 692  Training loss = 1.5679  Validation loss = 4.0863  \n",
      "\n",
      "Fold: 4  Epoch: 693  Training loss = 1.5678  Validation loss = 4.0861  \n",
      "\n",
      "Fold: 4  Epoch: 694  Training loss = 1.5678  Validation loss = 4.0859  \n",
      "\n",
      "Fold: 4  Epoch: 695  Training loss = 1.5676  Validation loss = 4.0852  \n",
      "\n",
      "Fold: 4  Epoch: 696  Training loss = 1.5676  Validation loss = 4.0850  \n",
      "\n",
      "Fold: 4  Epoch: 697  Training loss = 1.5676  Validation loss = 4.0853  \n",
      "\n",
      "Fold: 4  Epoch: 698  Training loss = 1.5676  Validation loss = 4.0852  \n",
      "\n",
      "Fold: 4  Epoch: 699  Training loss = 1.5675  Validation loss = 4.0848  \n",
      "\n",
      "Fold: 4  Epoch: 700  Training loss = 1.5674  Validation loss = 4.0842  \n",
      "\n",
      "Fold: 4  Epoch: 701  Training loss = 1.5673  Validation loss = 4.0841  \n",
      "\n",
      "Fold: 4  Epoch: 702  Training loss = 1.5673  Validation loss = 4.0839  \n",
      "\n",
      "Fold: 4  Epoch: 703  Training loss = 1.5672  Validation loss = 4.0837  \n",
      "\n",
      "Fold: 4  Epoch: 704  Training loss = 1.5671  Validation loss = 4.0827  \n",
      "\n",
      "Fold: 4  Epoch: 705  Training loss = 1.5670  Validation loss = 4.0824  \n",
      "\n",
      "Fold: 4  Epoch: 706  Training loss = 1.5669  Validation loss = 4.0820  \n",
      "\n",
      "Fold: 4  Epoch: 707  Training loss = 1.5669  Validation loss = 4.0817  \n",
      "\n",
      "Fold: 4  Epoch: 708  Training loss = 1.5668  Validation loss = 4.0816  \n",
      "\n",
      "Fold: 4  Epoch: 709  Training loss = 1.5668  Validation loss = 4.0817  \n",
      "\n",
      "Fold: 4  Epoch: 710  Training loss = 1.5667  Validation loss = 4.0809  \n",
      "\n",
      "Fold: 4  Epoch: 711  Training loss = 1.5666  Validation loss = 4.0807  \n",
      "\n",
      "Fold: 4  Epoch: 712  Training loss = 1.5666  Validation loss = 4.0807  \n",
      "\n",
      "Fold: 4  Epoch: 713  Training loss = 1.5665  Validation loss = 4.0804  \n",
      "\n",
      "Fold: 4  Epoch: 714  Training loss = 1.5665  Validation loss = 4.0805  \n",
      "\n",
      "Fold: 4  Epoch: 715  Training loss = 1.5664  Validation loss = 4.0805  \n",
      "\n",
      "Fold: 4  Epoch: 716  Training loss = 1.5664  Validation loss = 4.0802  \n",
      "\n",
      "Fold: 4  Epoch: 717  Training loss = 1.5663  Validation loss = 4.0799  \n",
      "\n",
      "Fold: 4  Epoch: 718  Training loss = 1.5663  Validation loss = 4.0797  \n",
      "\n",
      "Fold: 4  Epoch: 719  Training loss = 1.5662  Validation loss = 4.0796  \n",
      "\n",
      "Fold: 4  Epoch: 720  Training loss = 1.5661  Validation loss = 4.0792  \n",
      "\n",
      "Fold: 4  Epoch: 721  Training loss = 1.5661  Validation loss = 4.0791  \n",
      "\n",
      "Fold: 4  Epoch: 722  Training loss = 1.5661  Validation loss = 4.0790  \n",
      "\n",
      "Fold: 4  Epoch: 723  Training loss = 1.5660  Validation loss = 4.0787  \n",
      "\n",
      "Fold: 4  Epoch: 724  Training loss = 1.5659  Validation loss = 4.0785  \n",
      "\n",
      "Fold: 4  Epoch: 725  Training loss = 1.5658  Validation loss = 4.0780  \n",
      "\n",
      "Fold: 4  Epoch: 726  Training loss = 1.5658  Validation loss = 4.0778  \n",
      "\n",
      "Fold: 4  Epoch: 727  Training loss = 1.5658  Validation loss = 4.0780  \n",
      "\n",
      "Fold: 4  Epoch: 728  Training loss = 1.5657  Validation loss = 4.0779  \n",
      "\n",
      "Fold: 4  Epoch: 729  Training loss = 1.5657  Validation loss = 4.0779  \n",
      "\n",
      "Fold: 4  Epoch: 730  Training loss = 1.5657  Validation loss = 4.0778  \n",
      "\n",
      "Fold: 4  Epoch: 731  Training loss = 1.5656  Validation loss = 4.0776  \n",
      "\n",
      "Fold: 4  Epoch: 732  Training loss = 1.5655  Validation loss = 4.0771  \n",
      "\n",
      "Fold: 4  Epoch: 733  Training loss = 1.5655  Validation loss = 4.0771  \n",
      "\n",
      "Fold: 4  Epoch: 734  Training loss = 1.5654  Validation loss = 4.0767  \n",
      "\n",
      "Fold: 4  Epoch: 735  Training loss = 1.5654  Validation loss = 4.0768  \n",
      "\n",
      "Fold: 4  Epoch: 736  Training loss = 1.5654  Validation loss = 4.0769  \n",
      "\n",
      "Fold: 4  Epoch: 737  Training loss = 1.5653  Validation loss = 4.0769  \n",
      "\n",
      "Fold: 4  Epoch: 738  Training loss = 1.5653  Validation loss = 4.0765  \n",
      "\n",
      "Fold: 4  Epoch: 739  Training loss = 1.5651  Validation loss = 4.0759  \n",
      "\n",
      "Fold: 4  Epoch: 740  Training loss = 1.5651  Validation loss = 4.0755  \n",
      "\n",
      "Fold: 4  Epoch: 741  Training loss = 1.5650  Validation loss = 4.0751  \n",
      "\n",
      "Fold: 4  Epoch: 742  Training loss = 1.5650  Validation loss = 4.0752  \n",
      "\n",
      "Fold: 4  Epoch: 743  Training loss = 1.5649  Validation loss = 4.0748  \n",
      "\n",
      "Fold: 4  Epoch: 744  Training loss = 1.5648  Validation loss = 4.0746  \n",
      "\n",
      "Fold: 4  Epoch: 745  Training loss = 1.5648  Validation loss = 4.0747  \n",
      "\n",
      "Fold: 4  Epoch: 746  Training loss = 1.5648  Validation loss = 4.0745  \n",
      "\n",
      "Fold: 4  Epoch: 747  Training loss = 1.5647  Validation loss = 4.0740  \n",
      "\n",
      "Fold: 4  Epoch: 748  Training loss = 1.5647  Validation loss = 4.0740  \n",
      "\n",
      "Fold: 4  Epoch: 749  Training loss = 1.5646  Validation loss = 4.0740  \n",
      "\n",
      "Fold: 4  Epoch: 750  Training loss = 1.5646  Validation loss = 4.0739  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 750  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.8109  Validation loss = 3.8481  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.8107  Validation loss = 3.8473  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.8106  Validation loss = 3.8466  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.8105  Validation loss = 3.8466  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.8103  Validation loss = 3.8457  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.8103  Validation loss = 3.8458  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.8101  Validation loss = 3.8452  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.8100  Validation loss = 3.8452  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.8097  Validation loss = 3.8441  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.8095  Validation loss = 3.8430  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.8093  Validation loss = 3.8420  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.8091  Validation loss = 3.8414  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.8090  Validation loss = 3.8411  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.8088  Validation loss = 3.8401  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.8087  Validation loss = 3.8392  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.8085  Validation loss = 3.8388  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.8085  Validation loss = 3.8385  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.8082  Validation loss = 3.8374  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.8080  Validation loss = 3.8362  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.8079  Validation loss = 3.8355  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.8077  Validation loss = 3.8345  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.8075  Validation loss = 3.8336  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.8073  Validation loss = 3.8325  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.8071  Validation loss = 3.8323  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.8070  Validation loss = 3.8317  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.8068  Validation loss = 3.8312  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.8066  Validation loss = 3.8305  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.8064  Validation loss = 3.8300  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.8064  Validation loss = 3.8300  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.8063  Validation loss = 3.8298  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.8061  Validation loss = 3.8291  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.8060  Validation loss = 3.8285  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.8058  Validation loss = 3.8278  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.8057  Validation loss = 3.8277  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.8055  Validation loss = 3.8266  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.8054  Validation loss = 3.8266  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.8053  Validation loss = 3.8262  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.8052  Validation loss = 3.8260  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.8051  Validation loss = 3.8259  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.8049  Validation loss = 3.8251  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.8047  Validation loss = 3.8239  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.8045  Validation loss = 3.8236  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.8045  Validation loss = 3.8235  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.8044  Validation loss = 3.8232  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.8044  Validation loss = 3.8230  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.8042  Validation loss = 3.8221  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.8041  Validation loss = 3.8217  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.8040  Validation loss = 3.8215  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.8038  Validation loss = 3.8205  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.8037  Validation loss = 3.8194  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.8035  Validation loss = 3.8188  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.8034  Validation loss = 3.8187  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.8033  Validation loss = 3.8186  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.8032  Validation loss = 3.8181  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.8028  Validation loss = 3.8163  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.8026  Validation loss = 3.8147  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.8024  Validation loss = 3.8140  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.8023  Validation loss = 3.8137  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.8021  Validation loss = 3.8128  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.8019  Validation loss = 3.8124  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.8017  Validation loss = 3.8115  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.8016  Validation loss = 3.8110  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.8015  Validation loss = 3.8113  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.8014  Validation loss = 3.8107  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.8012  Validation loss = 3.8101  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.8011  Validation loss = 3.8094  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.8009  Validation loss = 3.8091  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.8008  Validation loss = 3.8086  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.8006  Validation loss = 3.8078  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.8004  Validation loss = 3.8072  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.8004  Validation loss = 3.8072  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.8003  Validation loss = 3.8067  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.8001  Validation loss = 3.8062  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.8000  Validation loss = 3.8056  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.7997  Validation loss = 3.8039  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.7996  Validation loss = 3.8035  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.7996  Validation loss = 3.8038  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 1.7993  Validation loss = 3.8026  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 1.7992  Validation loss = 3.8025  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 1.7991  Validation loss = 3.8021  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 1.7989  Validation loss = 3.8010  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 1.7987  Validation loss = 3.8005  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 1.7984  Validation loss = 3.7997  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 1.7983  Validation loss = 3.7988  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 1.7982  Validation loss = 3.7985  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 1.7980  Validation loss = 3.7982  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 1.7980  Validation loss = 3.7982  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 1.7979  Validation loss = 3.7981  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 1.7978  Validation loss = 3.7975  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 1.7976  Validation loss = 3.7964  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 1.7975  Validation loss = 3.7966  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 1.7974  Validation loss = 3.7968  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 1.7972  Validation loss = 3.7953  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 1.7971  Validation loss = 3.7952  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 1.7969  Validation loss = 3.7942  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 1.7967  Validation loss = 3.7936  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 1.7966  Validation loss = 3.7930  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 1.7965  Validation loss = 3.7931  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 1.7963  Validation loss = 3.7924  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 1.7962  Validation loss = 3.7922  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 1.7960  Validation loss = 3.7913  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 1.7958  Validation loss = 3.7906  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 1.7957  Validation loss = 3.7908  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 1.7956  Validation loss = 3.7900  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 1.7954  Validation loss = 3.7895  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 1.7953  Validation loss = 3.7895  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 1.7952  Validation loss = 3.7885  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 1.7950  Validation loss = 3.7877  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 1.7948  Validation loss = 3.7867  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 1.7947  Validation loss = 3.7868  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 1.7945  Validation loss = 3.7859  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 1.7944  Validation loss = 3.7852  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 1.7943  Validation loss = 3.7849  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 1.7941  Validation loss = 3.7844  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 1.7940  Validation loss = 3.7836  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 1.7938  Validation loss = 3.7830  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 1.7937  Validation loss = 3.7826  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 1.7935  Validation loss = 3.7814  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 1.7933  Validation loss = 3.7803  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 1.7933  Validation loss = 3.7804  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 1.7932  Validation loss = 3.7799  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 1.7929  Validation loss = 3.7786  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 1.7928  Validation loss = 3.7780  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 1.7927  Validation loss = 3.7782  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 1.7926  Validation loss = 3.7776  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 1.7926  Validation loss = 3.7785  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 1.7925  Validation loss = 3.7784  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 1.7923  Validation loss = 3.7778  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 1.7923  Validation loss = 3.7778  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 1.7922  Validation loss = 3.7778  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 1.7920  Validation loss = 3.7767  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 1.7919  Validation loss = 3.7762  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 1.7918  Validation loss = 3.7761  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 1.7917  Validation loss = 3.7759  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 1.7916  Validation loss = 3.7753  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 1.7916  Validation loss = 3.7757  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 1.7913  Validation loss = 3.7743  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 1.7913  Validation loss = 3.7747  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 1.7911  Validation loss = 3.7741  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 1.7910  Validation loss = 3.7733  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 1.7909  Validation loss = 3.7734  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 1.7909  Validation loss = 3.7734  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 1.7907  Validation loss = 3.7724  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 1.7906  Validation loss = 3.7713  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 1.7904  Validation loss = 3.7706  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 1.7903  Validation loss = 3.7703  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 1.7901  Validation loss = 3.7690  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 1.7901  Validation loss = 3.7687  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 1.7899  Validation loss = 3.7675  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 1.7897  Validation loss = 3.7665  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 1.7895  Validation loss = 3.7661  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 1.7895  Validation loss = 3.7656  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 1.7894  Validation loss = 3.7657  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 1.7893  Validation loss = 3.7656  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 1.7891  Validation loss = 3.7650  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 1.7890  Validation loss = 3.7642  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 1.7888  Validation loss = 3.7636  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 1.7887  Validation loss = 3.7631  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 1.7887  Validation loss = 3.7633  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 1.7886  Validation loss = 3.7630  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 1.7885  Validation loss = 3.7624  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 1.7884  Validation loss = 3.7624  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 1.7882  Validation loss = 3.7616  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 1.7881  Validation loss = 3.7612  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 1.7880  Validation loss = 3.7606  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 1.7879  Validation loss = 3.7608  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 1.7877  Validation loss = 3.7598  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 1.7877  Validation loss = 3.7597  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 1.7876  Validation loss = 3.7596  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 1.7874  Validation loss = 3.7583  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 1.7873  Validation loss = 3.7580  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 1.7872  Validation loss = 3.7573  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 1.7871  Validation loss = 3.7568  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 1.7870  Validation loss = 3.7567  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 1.7869  Validation loss = 3.7564  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 1.7868  Validation loss = 3.7560  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 1.7866  Validation loss = 3.7554  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 1.7865  Validation loss = 3.7548  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 1.7864  Validation loss = 3.7541  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 1.7863  Validation loss = 3.7538  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 1.7860  Validation loss = 3.7523  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 1.7859  Validation loss = 3.7521  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 1.7858  Validation loss = 3.7516  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 1.7858  Validation loss = 3.7517  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 1.7857  Validation loss = 3.7513  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 1.7855  Validation loss = 3.7505  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 1.7854  Validation loss = 3.7501  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 1.7853  Validation loss = 3.7493  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 1.7852  Validation loss = 3.7486  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 1.7851  Validation loss = 3.7484  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 1.7850  Validation loss = 3.7479  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 1.7850  Validation loss = 3.7481  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 1.7849  Validation loss = 3.7475  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 1.7847  Validation loss = 3.7464  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 1.7846  Validation loss = 3.7462  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 1.7844  Validation loss = 3.7459  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 1.7843  Validation loss = 3.7456  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 1.7843  Validation loss = 3.7456  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 1.7842  Validation loss = 3.7449  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 1.7842  Validation loss = 3.7450  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 1.7841  Validation loss = 3.7447  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 1.7840  Validation loss = 3.7442  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 1.7839  Validation loss = 3.7435  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 1.7839  Validation loss = 3.7444  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 1.7838  Validation loss = 3.7438  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 1.7837  Validation loss = 3.7439  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 1.7836  Validation loss = 3.7440  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 1.7835  Validation loss = 3.7432  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 1.7833  Validation loss = 3.7424  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 1.7831  Validation loss = 3.7412  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 1.7830  Validation loss = 3.7405  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 1.7829  Validation loss = 3.7403  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 1.7827  Validation loss = 3.7399  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 1.7826  Validation loss = 3.7390  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 1.7825  Validation loss = 3.7387  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 1.7824  Validation loss = 3.7379  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 1.7824  Validation loss = 3.7386  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 1.7823  Validation loss = 3.7382  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 1.7822  Validation loss = 3.7383  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 1.7821  Validation loss = 3.7380  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 1.7821  Validation loss = 3.7381  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 1.7819  Validation loss = 3.7375  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 1.7818  Validation loss = 3.7372  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 1.7818  Validation loss = 3.7371  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 1.7816  Validation loss = 3.7359  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 1.7815  Validation loss = 3.7357  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 1.7815  Validation loss = 3.7362  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 1.7813  Validation loss = 3.7354  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 1.7812  Validation loss = 3.7345  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 1.7811  Validation loss = 3.7345  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 1.7810  Validation loss = 3.7341  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 1.7809  Validation loss = 3.7332  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 1.7808  Validation loss = 3.7324  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 1.7806  Validation loss = 3.7318  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 1.7805  Validation loss = 3.7317  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 1.7804  Validation loss = 3.7318  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 1.7803  Validation loss = 3.7308  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 1.7802  Validation loss = 3.7307  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 1.7801  Validation loss = 3.7298  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 1.7800  Validation loss = 3.7299  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 1.7799  Validation loss = 3.7299  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 1.7798  Validation loss = 3.7293  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 1.7797  Validation loss = 3.7288  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 1.7796  Validation loss = 3.7285  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 1.7794  Validation loss = 3.7273  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 1.7794  Validation loss = 3.7273  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 1.7793  Validation loss = 3.7266  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 1.7792  Validation loss = 3.7263  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 1.7791  Validation loss = 3.7260  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 1.7790  Validation loss = 3.7257  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 1.7789  Validation loss = 3.7252  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 1.7787  Validation loss = 3.7241  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 1.7786  Validation loss = 3.7232  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 1.7786  Validation loss = 3.7229  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 1.7784  Validation loss = 3.7225  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 1.7783  Validation loss = 3.7217  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 1.7782  Validation loss = 3.7210  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 1.7781  Validation loss = 3.7208  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 1.7780  Validation loss = 3.7208  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 1.7779  Validation loss = 3.7203  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 1.7779  Validation loss = 3.7203  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 1.7778  Validation loss = 3.7198  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 1.7777  Validation loss = 3.7192  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 1.7775  Validation loss = 3.7182  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 1.7774  Validation loss = 3.7174  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 1.7772  Validation loss = 3.7162  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 1.7771  Validation loss = 3.7162  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 1.7770  Validation loss = 3.7155  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 1.7769  Validation loss = 3.7157  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 1.7768  Validation loss = 3.7153  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 1.7767  Validation loss = 3.7153  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 1.7766  Validation loss = 3.7151  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 1.7765  Validation loss = 3.7138  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 1.7764  Validation loss = 3.7141  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 1.7762  Validation loss = 3.7129  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 1.7761  Validation loss = 3.7121  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 1.7760  Validation loss = 3.7120  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 1.7760  Validation loss = 3.7117  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 1.7759  Validation loss = 3.7119  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 1.7758  Validation loss = 3.7116  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 1.7757  Validation loss = 3.7107  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 1.7756  Validation loss = 3.7105  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 1.7755  Validation loss = 3.7104  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 1.7753  Validation loss = 3.7098  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 1.7752  Validation loss = 3.7096  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 1.7751  Validation loss = 3.7089  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 1.7749  Validation loss = 3.7075  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 1.7749  Validation loss = 3.7074  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 1.7748  Validation loss = 3.7074  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 1.7747  Validation loss = 3.7076  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 1.7746  Validation loss = 3.7065  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 1.7744  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 1.7743  Validation loss = 3.7056  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 1.7742  Validation loss = 3.7053  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 1.7741  Validation loss = 3.7049  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 1.7740  Validation loss = 3.7040  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 1.7739  Validation loss = 3.7030  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 1.7738  Validation loss = 3.7026  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 1.7736  Validation loss = 3.7012  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 1.7735  Validation loss = 3.7010  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 1.7735  Validation loss = 3.7011  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 1.7734  Validation loss = 3.7012  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 1.7734  Validation loss = 3.7009  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 1.7733  Validation loss = 3.7011  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 1.7733  Validation loss = 3.7016  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 1.7731  Validation loss = 3.7004  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 1.7729  Validation loss = 3.6994  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 1.7727  Validation loss = 3.6978  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 1.7726  Validation loss = 3.6974  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 1.7725  Validation loss = 3.6964  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 1.7724  Validation loss = 3.6961  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 1.7723  Validation loss = 3.6960  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 1.7722  Validation loss = 3.6949  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 1.7720  Validation loss = 3.6937  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 1.7719  Validation loss = 3.6933  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 1.7719  Validation loss = 3.6927  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 1.7718  Validation loss = 3.6928  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 1.7717  Validation loss = 3.6926  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 1.7716  Validation loss = 3.6923  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 1.7715  Validation loss = 3.6916  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 1.7714  Validation loss = 3.6921  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 1.7713  Validation loss = 3.6914  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 1.7713  Validation loss = 3.6917  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 1.7711  Validation loss = 3.6913  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 1.7711  Validation loss = 3.6916  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 1.7710  Validation loss = 3.6906  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 1.7709  Validation loss = 3.6903  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 1.7708  Validation loss = 3.6901  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 1.7707  Validation loss = 3.6896  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 1.7706  Validation loss = 3.6891  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 1.7704  Validation loss = 3.6883  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 1.7704  Validation loss = 3.6882  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 1.7703  Validation loss = 3.6878  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 1.7701  Validation loss = 3.6865  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 1.7700  Validation loss = 3.6854  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 1.7699  Validation loss = 3.6847  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 1.7698  Validation loss = 3.6842  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 1.7697  Validation loss = 3.6839  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 1.7696  Validation loss = 3.6834  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 1.7695  Validation loss = 3.6830  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 1.7695  Validation loss = 3.6829  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 1.7693  Validation loss = 3.6818  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 1.7692  Validation loss = 3.6812  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 1.7691  Validation loss = 3.6814  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 1.7690  Validation loss = 3.6810  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 1.7690  Validation loss = 3.6811  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 1.7689  Validation loss = 3.6811  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 1.7689  Validation loss = 3.6811  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 1.7687  Validation loss = 3.6803  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 1.7686  Validation loss = 3.6794  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 1.7685  Validation loss = 3.6791  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 1.7683  Validation loss = 3.6777  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 1.7683  Validation loss = 3.6778  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 1.7682  Validation loss = 3.6782  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 1.7680  Validation loss = 3.6777  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 1.7680  Validation loss = 3.6772  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 1.7678  Validation loss = 3.6760  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 1.7677  Validation loss = 3.6751  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 1.7676  Validation loss = 3.6747  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 1.7675  Validation loss = 3.6738  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 1.7675  Validation loss = 3.6738  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 1.7674  Validation loss = 3.6732  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 1.7673  Validation loss = 3.6725  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 1.7672  Validation loss = 3.6722  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 1.7671  Validation loss = 3.6719  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 1.7670  Validation loss = 3.6717  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 1.7669  Validation loss = 3.6716  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 1.7668  Validation loss = 3.6710  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 1.7667  Validation loss = 3.6706  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 1.7665  Validation loss = 3.6695  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 1.7664  Validation loss = 3.6684  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 1.7663  Validation loss = 3.6678  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 1.7661  Validation loss = 3.6667  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 1.7661  Validation loss = 3.6663  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 1.7660  Validation loss = 3.6661  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 1.7659  Validation loss = 3.6659  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 1.7658  Validation loss = 3.6649  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 1.7657  Validation loss = 3.6643  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 1.7656  Validation loss = 3.6637  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 1.7655  Validation loss = 3.6630  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 1.7653  Validation loss = 3.6616  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 1.7653  Validation loss = 3.6618  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 1.7651  Validation loss = 3.6610  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 1.7650  Validation loss = 3.6606  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 1.7649  Validation loss = 3.6604  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 1.7648  Validation loss = 3.6602  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 1.7648  Validation loss = 3.6600  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 1.7646  Validation loss = 3.6593  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 1.7646  Validation loss = 3.6592  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 1.7645  Validation loss = 3.6594  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 1.7645  Validation loss = 3.6593  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 1.7644  Validation loss = 3.6588  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 1.7642  Validation loss = 3.6580  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 1.7641  Validation loss = 3.6574  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 1.7640  Validation loss = 3.6574  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 1.7640  Validation loss = 3.6573  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 1.7639  Validation loss = 3.6575  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 1.7638  Validation loss = 3.6568  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 1.7637  Validation loss = 3.6559  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 1.7637  Validation loss = 3.6557  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 1.7636  Validation loss = 3.6550  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 1.7635  Validation loss = 3.6541  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 1.7634  Validation loss = 3.6537  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 1.7633  Validation loss = 3.6532  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 1.7632  Validation loss = 3.6523  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 1.7631  Validation loss = 3.6525  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 1.7630  Validation loss = 3.6517  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 1.7629  Validation loss = 3.6513  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 1.7629  Validation loss = 3.6521  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 1.7629  Validation loss = 3.6527  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 1.7628  Validation loss = 3.6514  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 1.7628  Validation loss = 3.6514  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 1.7626  Validation loss = 3.6503  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 1.7626  Validation loss = 3.6508  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 1.7625  Validation loss = 3.6499  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 1.7624  Validation loss = 3.6492  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 1.7623  Validation loss = 3.6483  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 1.7622  Validation loss = 3.6476  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 1.7621  Validation loss = 3.6478  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 1.7620  Validation loss = 3.6475  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 1.7620  Validation loss = 3.6470  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 1.7618  Validation loss = 3.6460  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 1.7617  Validation loss = 3.6457  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 1.7616  Validation loss = 3.6449  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 1.7615  Validation loss = 3.6450  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 1.7614  Validation loss = 3.6441  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 1.7614  Validation loss = 3.6444  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 1.7612  Validation loss = 3.6432  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 1.7611  Validation loss = 3.6432  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 1.7610  Validation loss = 3.6426  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 1.7610  Validation loss = 3.6425  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 1.7609  Validation loss = 3.6422  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 1.7608  Validation loss = 3.6413  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 1.7606  Validation loss = 3.6406  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 1.7605  Validation loss = 3.6402  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 1.7604  Validation loss = 3.6391  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 1.7603  Validation loss = 3.6384  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 1.7603  Validation loss = 3.6387  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 1.7602  Validation loss = 3.6388  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 1.7600  Validation loss = 3.6376  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 1.7600  Validation loss = 3.6381  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 1.7599  Validation loss = 3.6380  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 1.7599  Validation loss = 3.6377  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 1.7598  Validation loss = 3.6374  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 1.7597  Validation loss = 3.6367  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 1.7597  Validation loss = 3.6369  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 1.7596  Validation loss = 3.6364  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 1.7595  Validation loss = 3.6356  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 1.7594  Validation loss = 3.6350  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 1.7594  Validation loss = 3.6347  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 1.7593  Validation loss = 3.6342  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 1.7591  Validation loss = 3.6331  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 1.7590  Validation loss = 3.6326  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 1.7589  Validation loss = 3.6319  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 1.7588  Validation loss = 3.6322  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 1.7588  Validation loss = 3.6322  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 1.7586  Validation loss = 3.6310  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 1.7586  Validation loss = 3.6304  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 1.7585  Validation loss = 3.6298  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 1.7584  Validation loss = 3.6296  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 1.7584  Validation loss = 3.6299  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 1.7582  Validation loss = 3.6297  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 1.7581  Validation loss = 3.6290  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 1.7581  Validation loss = 3.6293  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 1.7580  Validation loss = 3.6291  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 1.7579  Validation loss = 3.6289  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 1.7579  Validation loss = 3.6293  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 1.7578  Validation loss = 3.6284  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 1.7577  Validation loss = 3.6281  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 1.7576  Validation loss = 3.6280  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 1.7575  Validation loss = 3.6273  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 1.7575  Validation loss = 3.6276  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 1.7574  Validation loss = 3.6274  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 1.7573  Validation loss = 3.6262  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 1.7572  Validation loss = 3.6258  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 1.7571  Validation loss = 3.6255  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 1.7571  Validation loss = 3.6259  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 1.7570  Validation loss = 3.6248  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 1.7569  Validation loss = 3.6246  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 1.7568  Validation loss = 3.6238  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 1.7567  Validation loss = 3.6229  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 1.7567  Validation loss = 3.6225  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 1.7566  Validation loss = 3.6233  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 1.7566  Validation loss = 3.6235  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 1.7565  Validation loss = 3.6224  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 1.7564  Validation loss = 3.6219  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 1.7562  Validation loss = 3.6206  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 1.7562  Validation loss = 3.6205  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 1.7560  Validation loss = 3.6194  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 1.7560  Validation loss = 3.6191  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 1.7559  Validation loss = 3.6189  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 1.7559  Validation loss = 3.6186  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 1.7558  Validation loss = 3.6184  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 1.7557  Validation loss = 3.6173  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 1.7556  Validation loss = 3.6174  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 1.7556  Validation loss = 3.6167  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 1.7555  Validation loss = 3.6171  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 1.7555  Validation loss = 3.6165  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 1.7554  Validation loss = 3.6161  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 1.7552  Validation loss = 3.6150  \n",
      "\n",
      "Fold: 5  Epoch: 501  Training loss = 1.7551  Validation loss = 3.6147  \n",
      "\n",
      "Fold: 5  Epoch: 502  Training loss = 1.7551  Validation loss = 3.6148  \n",
      "\n",
      "Fold: 5  Epoch: 503  Training loss = 1.7550  Validation loss = 3.6145  \n",
      "\n",
      "Fold: 5  Epoch: 504  Training loss = 1.7549  Validation loss = 3.6136  \n",
      "\n",
      "Fold: 5  Epoch: 505  Training loss = 1.7549  Validation loss = 3.6141  \n",
      "\n",
      "Fold: 5  Epoch: 506  Training loss = 1.7548  Validation loss = 3.6135  \n",
      "\n",
      "Fold: 5  Epoch: 507  Training loss = 1.7547  Validation loss = 3.6133  \n",
      "\n",
      "Fold: 5  Epoch: 508  Training loss = 1.7546  Validation loss = 3.6122  \n",
      "\n",
      "Fold: 5  Epoch: 509  Training loss = 1.7545  Validation loss = 3.6119  \n",
      "\n",
      "Fold: 5  Epoch: 510  Training loss = 1.7544  Validation loss = 3.6117  \n",
      "\n",
      "Fold: 5  Epoch: 511  Training loss = 1.7543  Validation loss = 3.6110  \n",
      "\n",
      "Fold: 5  Epoch: 512  Training loss = 1.7543  Validation loss = 3.6114  \n",
      "\n",
      "Fold: 5  Epoch: 513  Training loss = 1.7542  Validation loss = 3.6107  \n",
      "\n",
      "Fold: 5  Epoch: 514  Training loss = 1.7541  Validation loss = 3.6099  \n",
      "\n",
      "Fold: 5  Epoch: 515  Training loss = 1.7540  Validation loss = 3.6089  \n",
      "\n",
      "Fold: 5  Epoch: 516  Training loss = 1.7540  Validation loss = 3.6091  \n",
      "\n",
      "Fold: 5  Epoch: 517  Training loss = 1.7539  Validation loss = 3.6088  \n",
      "\n",
      "Fold: 5  Epoch: 518  Training loss = 1.7538  Validation loss = 3.6085  \n",
      "\n",
      "Fold: 5  Epoch: 519  Training loss = 1.7537  Validation loss = 3.6078  \n",
      "\n",
      "Fold: 5  Epoch: 520  Training loss = 1.7536  Validation loss = 3.6070  \n",
      "\n",
      "Fold: 5  Epoch: 521  Training loss = 1.7535  Validation loss = 3.6061  \n",
      "\n",
      "Fold: 5  Epoch: 522  Training loss = 1.7534  Validation loss = 3.6060  \n",
      "\n",
      "Fold: 5  Epoch: 523  Training loss = 1.7533  Validation loss = 3.6057  \n",
      "\n",
      "Fold: 5  Epoch: 524  Training loss = 1.7533  Validation loss = 3.6055  \n",
      "\n",
      "Fold: 5  Epoch: 525  Training loss = 1.7532  Validation loss = 3.6048  \n",
      "\n",
      "Fold: 5  Epoch: 526  Training loss = 1.7531  Validation loss = 3.6045  \n",
      "\n",
      "Fold: 5  Epoch: 527  Training loss = 1.7531  Validation loss = 3.6047  \n",
      "\n",
      "Fold: 5  Epoch: 528  Training loss = 1.7530  Validation loss = 3.6041  \n",
      "\n",
      "Fold: 5  Epoch: 529  Training loss = 1.7529  Validation loss = 3.6032  \n",
      "\n",
      "Fold: 5  Epoch: 530  Training loss = 1.7528  Validation loss = 3.6032  \n",
      "\n",
      "Fold: 5  Epoch: 531  Training loss = 1.7528  Validation loss = 3.6032  \n",
      "\n",
      "Fold: 5  Epoch: 532  Training loss = 1.7528  Validation loss = 3.6036  \n",
      "\n",
      "Fold: 5  Epoch: 533  Training loss = 1.7527  Validation loss = 3.6033  \n",
      "\n",
      "Fold: 5  Epoch: 534  Training loss = 1.7526  Validation loss = 3.6021  \n",
      "\n",
      "Fold: 5  Epoch: 535  Training loss = 1.7525  Validation loss = 3.6014  \n",
      "\n",
      "Fold: 5  Epoch: 536  Training loss = 1.7524  Validation loss = 3.6014  \n",
      "\n",
      "Fold: 5  Epoch: 537  Training loss = 1.7524  Validation loss = 3.6014  \n",
      "\n",
      "Fold: 5  Epoch: 538  Training loss = 1.7523  Validation loss = 3.6001  \n",
      "\n",
      "Fold: 5  Epoch: 539  Training loss = 1.7522  Validation loss = 3.5992  \n",
      "\n",
      "Fold: 5  Epoch: 540  Training loss = 1.7521  Validation loss = 3.5991  \n",
      "\n",
      "Fold: 5  Epoch: 541  Training loss = 1.7520  Validation loss = 3.5985  \n",
      "\n",
      "Fold: 5  Epoch: 542  Training loss = 1.7520  Validation loss = 3.5985  \n",
      "\n",
      "Fold: 5  Epoch: 543  Training loss = 1.7519  Validation loss = 3.5983  \n",
      "\n",
      "Fold: 5  Epoch: 544  Training loss = 1.7519  Validation loss = 3.5981  \n",
      "\n",
      "Fold: 5  Epoch: 545  Training loss = 1.7518  Validation loss = 3.5974  \n",
      "\n",
      "Fold: 5  Epoch: 546  Training loss = 1.7517  Validation loss = 3.5968  \n",
      "\n",
      "Fold: 5  Epoch: 547  Training loss = 1.7516  Validation loss = 3.5974  \n",
      "\n",
      "Fold: 5  Epoch: 548  Training loss = 1.7515  Validation loss = 3.5971  \n",
      "\n",
      "Fold: 5  Epoch: 549  Training loss = 1.7515  Validation loss = 3.5969  \n",
      "\n",
      "Fold: 5  Epoch: 550  Training loss = 1.7514  Validation loss = 3.5970  \n",
      "\n",
      "Fold: 5  Epoch: 551  Training loss = 1.7513  Validation loss = 3.5963  \n",
      "\n",
      "Fold: 5  Epoch: 552  Training loss = 1.7513  Validation loss = 3.5965  \n",
      "\n",
      "Fold: 5  Epoch: 553  Training loss = 1.7512  Validation loss = 3.5968  \n",
      "\n",
      "Fold: 5  Epoch: 554  Training loss = 1.7511  Validation loss = 3.5958  \n",
      "\n",
      "Fold: 5  Epoch: 555  Training loss = 1.7510  Validation loss = 3.5953  \n",
      "\n",
      "Fold: 5  Epoch: 556  Training loss = 1.7509  Validation loss = 3.5951  \n",
      "\n",
      "Fold: 5  Epoch: 557  Training loss = 1.7509  Validation loss = 3.5944  \n",
      "\n",
      "Fold: 5  Epoch: 558  Training loss = 1.7507  Validation loss = 3.5926  \n",
      "\n",
      "Fold: 5  Epoch: 559  Training loss = 1.7506  Validation loss = 3.5920  \n",
      "\n",
      "Fold: 5  Epoch: 560  Training loss = 1.7505  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 5  Epoch: 561  Training loss = 1.7505  Validation loss = 3.5925  \n",
      "\n",
      "Fold: 5  Epoch: 562  Training loss = 1.7503  Validation loss = 3.5912  \n",
      "\n",
      "Fold: 5  Epoch: 563  Training loss = 1.7502  Validation loss = 3.5902  \n",
      "\n",
      "Fold: 5  Epoch: 564  Training loss = 1.7501  Validation loss = 3.5894  \n",
      "\n",
      "Fold: 5  Epoch: 565  Training loss = 1.7500  Validation loss = 3.5885  \n",
      "\n",
      "Fold: 5  Epoch: 566  Training loss = 1.7500  Validation loss = 3.5881  \n",
      "\n",
      "Fold: 5  Epoch: 567  Training loss = 1.7499  Validation loss = 3.5876  \n",
      "\n",
      "Fold: 5  Epoch: 568  Training loss = 1.7498  Validation loss = 3.5870  \n",
      "\n",
      "Fold: 5  Epoch: 569  Training loss = 1.7497  Validation loss = 3.5865  \n",
      "\n",
      "Fold: 5  Epoch: 570  Training loss = 1.7496  Validation loss = 3.5863  \n",
      "\n",
      "Fold: 5  Epoch: 571  Training loss = 1.7495  Validation loss = 3.5858  \n",
      "\n",
      "Fold: 5  Epoch: 572  Training loss = 1.7495  Validation loss = 3.5852  \n",
      "\n",
      "Fold: 5  Epoch: 573  Training loss = 1.7495  Validation loss = 3.5855  \n",
      "\n",
      "Fold: 5  Epoch: 574  Training loss = 1.7494  Validation loss = 3.5845  \n",
      "\n",
      "Fold: 5  Epoch: 575  Training loss = 1.7493  Validation loss = 3.5843  \n",
      "\n",
      "Fold: 5  Epoch: 576  Training loss = 1.7492  Validation loss = 3.5836  \n",
      "\n",
      "Fold: 5  Epoch: 577  Training loss = 1.7491  Validation loss = 3.5827  \n",
      "\n",
      "Fold: 5  Epoch: 578  Training loss = 1.7490  Validation loss = 3.5823  \n",
      "\n",
      "Fold: 5  Epoch: 579  Training loss = 1.7490  Validation loss = 3.5816  \n",
      "\n",
      "Fold: 5  Epoch: 580  Training loss = 1.7489  Validation loss = 3.5804  \n",
      "\n",
      "Fold: 5  Epoch: 581  Training loss = 1.7488  Validation loss = 3.5800  \n",
      "\n",
      "Fold: 5  Epoch: 582  Training loss = 1.7487  Validation loss = 3.5793  \n",
      "\n",
      "Fold: 5  Epoch: 583  Training loss = 1.7486  Validation loss = 3.5786  \n",
      "\n",
      "Fold: 5  Epoch: 584  Training loss = 1.7486  Validation loss = 3.5784  \n",
      "\n",
      "Fold: 5  Epoch: 585  Training loss = 1.7484  Validation loss = 3.5777  \n",
      "\n",
      "Fold: 5  Epoch: 586  Training loss = 1.7484  Validation loss = 3.5774  \n",
      "\n",
      "Fold: 5  Epoch: 587  Training loss = 1.7483  Validation loss = 3.5765  \n",
      "\n",
      "Fold: 5  Epoch: 588  Training loss = 1.7482  Validation loss = 3.5764  \n",
      "\n",
      "Fold: 5  Epoch: 589  Training loss = 1.7481  Validation loss = 3.5758  \n",
      "\n",
      "Fold: 5  Epoch: 590  Training loss = 1.7481  Validation loss = 3.5750  \n",
      "\n",
      "Fold: 5  Epoch: 591  Training loss = 1.7480  Validation loss = 3.5742  \n",
      "\n",
      "Fold: 5  Epoch: 592  Training loss = 1.7479  Validation loss = 3.5739  \n",
      "\n",
      "Fold: 5  Epoch: 593  Training loss = 1.7477  Validation loss = 3.5735  \n",
      "\n",
      "Fold: 5  Epoch: 594  Training loss = 1.7477  Validation loss = 3.5731  \n",
      "\n",
      "Fold: 5  Epoch: 595  Training loss = 1.7476  Validation loss = 3.5724  \n",
      "\n",
      "Fold: 5  Epoch: 596  Training loss = 1.7475  Validation loss = 3.5722  \n",
      "\n",
      "Fold: 5  Epoch: 597  Training loss = 1.7475  Validation loss = 3.5721  \n",
      "\n",
      "Fold: 5  Epoch: 598  Training loss = 1.7474  Validation loss = 3.5717  \n",
      "\n",
      "Fold: 5  Epoch: 599  Training loss = 1.7474  Validation loss = 3.5714  \n",
      "\n",
      "Fold: 5  Epoch: 600  Training loss = 1.7472  Validation loss = 3.5699  \n",
      "\n",
      "Fold: 5  Epoch: 601  Training loss = 1.7471  Validation loss = 3.5691  \n",
      "\n",
      "Fold: 5  Epoch: 602  Training loss = 1.7471  Validation loss = 3.5688  \n",
      "\n",
      "Fold: 5  Epoch: 603  Training loss = 1.7470  Validation loss = 3.5683  \n",
      "\n",
      "Fold: 5  Epoch: 604  Training loss = 1.7469  Validation loss = 3.5672  \n",
      "\n",
      "Fold: 5  Epoch: 605  Training loss = 1.7468  Validation loss = 3.5668  \n",
      "\n",
      "Fold: 5  Epoch: 606  Training loss = 1.7468  Validation loss = 3.5672  \n",
      "\n",
      "Fold: 5  Epoch: 607  Training loss = 1.7467  Validation loss = 3.5669  \n",
      "\n",
      "Fold: 5  Epoch: 608  Training loss = 1.7466  Validation loss = 3.5667  \n",
      "\n",
      "Fold: 5  Epoch: 609  Training loss = 1.7466  Validation loss = 3.5661  \n",
      "\n",
      "Fold: 5  Epoch: 610  Training loss = 1.7465  Validation loss = 3.5651  \n",
      "\n",
      "Fold: 5  Epoch: 611  Training loss = 1.7464  Validation loss = 3.5650  \n",
      "\n",
      "Fold: 5  Epoch: 612  Training loss = 1.7463  Validation loss = 3.5648  \n",
      "\n",
      "Fold: 5  Epoch: 613  Training loss = 1.7463  Validation loss = 3.5649  \n",
      "\n",
      "Fold: 5  Epoch: 614  Training loss = 1.7463  Validation loss = 3.5654  \n",
      "\n",
      "Fold: 5  Epoch: 615  Training loss = 1.7462  Validation loss = 3.5655  \n",
      "\n",
      "Fold: 5  Epoch: 616  Training loss = 1.7461  Validation loss = 3.5643  \n",
      "\n",
      "Fold: 5  Epoch: 617  Training loss = 1.7460  Validation loss = 3.5639  \n",
      "\n",
      "Fold: 5  Epoch: 618  Training loss = 1.7459  Validation loss = 3.5630  \n",
      "\n",
      "Fold: 5  Epoch: 619  Training loss = 1.7459  Validation loss = 3.5632  \n",
      "\n",
      "Fold: 5  Epoch: 620  Training loss = 1.7458  Validation loss = 3.5630  \n",
      "\n",
      "Fold: 5  Epoch: 621  Training loss = 1.7458  Validation loss = 3.5627  \n",
      "\n",
      "Fold: 5  Epoch: 622  Training loss = 1.7456  Validation loss = 3.5615  \n",
      "\n",
      "Fold: 5  Epoch: 623  Training loss = 1.7456  Validation loss = 3.5614  \n",
      "\n",
      "Fold: 5  Epoch: 624  Training loss = 1.7455  Validation loss = 3.5621  \n",
      "\n",
      "Fold: 5  Epoch: 625  Training loss = 1.7455  Validation loss = 3.5621  \n",
      "\n",
      "Fold: 5  Epoch: 626  Training loss = 1.7454  Validation loss = 3.5622  \n",
      "\n",
      "Fold: 5  Epoch: 627  Training loss = 1.7454  Validation loss = 3.5621  \n",
      "\n",
      "Fold: 5  Epoch: 628  Training loss = 1.7453  Validation loss = 3.5623  \n",
      "\n",
      "Fold: 5  Epoch: 629  Training loss = 1.7452  Validation loss = 3.5619  \n",
      "\n",
      "Fold: 5  Epoch: 630  Training loss = 1.7452  Validation loss = 3.5623  \n",
      "\n",
      "Fold: 5  Epoch: 631  Training loss = 1.7451  Validation loss = 3.5620  \n",
      "\n",
      "Fold: 5  Epoch: 632  Training loss = 1.7450  Validation loss = 3.5615  \n",
      "\n",
      "Fold: 5  Epoch: 633  Training loss = 1.7450  Validation loss = 3.5617  \n",
      "\n",
      "Fold: 5  Epoch: 634  Training loss = 1.7449  Validation loss = 3.5620  \n",
      "\n",
      "Fold: 5  Epoch: 635  Training loss = 1.7449  Validation loss = 3.5621  \n",
      "\n",
      "Fold: 5  Epoch: 636  Training loss = 1.7449  Validation loss = 3.5626  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 623  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.9294  Validation loss = 1.4332  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.9290  Validation loss = 1.4326  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.9288  Validation loss = 1.4325  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.9284  Validation loss = 1.4319  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.9280  Validation loss = 1.4313  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.9277  Validation loss = 1.4307  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.9271  Validation loss = 1.4298  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.9268  Validation loss = 1.4290  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.9265  Validation loss = 1.4285  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.9262  Validation loss = 1.4280  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.9259  Validation loss = 1.4274  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.9256  Validation loss = 1.4269  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.9252  Validation loss = 1.4265  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.9244  Validation loss = 1.4252  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 1.9241  Validation loss = 1.4247  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 1.9238  Validation loss = 1.4242  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 1.9233  Validation loss = 1.4235  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 1.9231  Validation loss = 1.4233  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 1.9226  Validation loss = 1.4224  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 1.9220  Validation loss = 1.4212  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 1.9218  Validation loss = 1.4207  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 1.9215  Validation loss = 1.4203  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 1.9212  Validation loss = 1.4196  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 1.9208  Validation loss = 1.4189  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 1.9206  Validation loss = 1.4187  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 1.9204  Validation loss = 1.4180  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 1.9202  Validation loss = 1.4177  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 1.9198  Validation loss = 1.4171  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 1.9196  Validation loss = 1.4167  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 1.9191  Validation loss = 1.4156  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 1.9189  Validation loss = 1.4151  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 1.9186  Validation loss = 1.4147  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 1.9183  Validation loss = 1.4140  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 1.9181  Validation loss = 1.4138  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 1.9177  Validation loss = 1.4129  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 1.9175  Validation loss = 1.4125  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 1.9173  Validation loss = 1.4122  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 1.9168  Validation loss = 1.4110  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 1.9165  Validation loss = 1.4103  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 1.9162  Validation loss = 1.4096  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 1.9158  Validation loss = 1.4090  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 1.9154  Validation loss = 1.4080  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 1.9150  Validation loss = 1.4073  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 1.9145  Validation loss = 1.4062  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 1.9141  Validation loss = 1.4052  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 1.9138  Validation loss = 1.4049  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 1.9135  Validation loss = 1.4043  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 1.9132  Validation loss = 1.4038  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 1.9129  Validation loss = 1.4029  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 1.9126  Validation loss = 1.4024  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 1.9121  Validation loss = 1.4016  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 1.9119  Validation loss = 1.4010  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 1.9117  Validation loss = 1.4005  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 1.9112  Validation loss = 1.3996  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 1.9110  Validation loss = 1.3992  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 1.9107  Validation loss = 1.3987  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 1.9104  Validation loss = 1.3984  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 1.9100  Validation loss = 1.3976  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 1.9097  Validation loss = 1.3969  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 1.9095  Validation loss = 1.3964  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 1.9091  Validation loss = 1.3957  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 1.9089  Validation loss = 1.3949  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 1.9086  Validation loss = 1.3945  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 1.9083  Validation loss = 1.3936  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 1.9080  Validation loss = 1.3930  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 1.9075  Validation loss = 1.3917  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 1.9073  Validation loss = 1.3913  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 1.9071  Validation loss = 1.3909  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 1.9067  Validation loss = 1.3900  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 1.9063  Validation loss = 1.3892  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 1.9060  Validation loss = 1.3885  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 1.9058  Validation loss = 1.3882  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 1.9054  Validation loss = 1.3873  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 1.9052  Validation loss = 1.3870  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 1.9049  Validation loss = 1.3864  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 1.9047  Validation loss = 1.3858  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 1.9044  Validation loss = 1.3855  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 1.9041  Validation loss = 1.3845  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 1.9039  Validation loss = 1.3839  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 1.9037  Validation loss = 1.3835  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 1.9034  Validation loss = 1.3832  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 1.9031  Validation loss = 1.3825  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 1.9029  Validation loss = 1.3821  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 1.9025  Validation loss = 1.3813  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 1.9023  Validation loss = 1.3809  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 1.9019  Validation loss = 1.3803  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 1.9016  Validation loss = 1.3797  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 1.9012  Validation loss = 1.3787  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 1.9010  Validation loss = 1.3785  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 1.9007  Validation loss = 1.3779  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 1.9005  Validation loss = 1.3773  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 1.9003  Validation loss = 1.3768  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 1.8999  Validation loss = 1.3763  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 1.8998  Validation loss = 1.3761  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 1.8998  Validation loss = 1.3762  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 1.8995  Validation loss = 1.3757  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 1.8993  Validation loss = 1.3752  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 1.8989  Validation loss = 1.3744  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 1.8986  Validation loss = 1.3738  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 1.8985  Validation loss = 1.3736  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 1.8981  Validation loss = 1.3727  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 1.8979  Validation loss = 1.3722  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 1.8978  Validation loss = 1.3721  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 1.8974  Validation loss = 1.3714  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 1.8972  Validation loss = 1.3709  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 1.8969  Validation loss = 1.3703  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 1.8965  Validation loss = 1.3696  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 1.8962  Validation loss = 1.3690  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 1.8961  Validation loss = 1.3692  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 1.8958  Validation loss = 1.3684  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 1.8956  Validation loss = 1.3680  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 1.8952  Validation loss = 1.3670  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 1.8950  Validation loss = 1.3667  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 1.8948  Validation loss = 1.3662  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 1.8944  Validation loss = 1.3652  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 1.8943  Validation loss = 1.3647  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 1.8940  Validation loss = 1.3641  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 1.8937  Validation loss = 1.3633  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 1.8935  Validation loss = 1.3632  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 1.8932  Validation loss = 1.3625  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 1.8931  Validation loss = 1.3622  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 1.8928  Validation loss = 1.3616  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 1.8927  Validation loss = 1.3612  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 1.8924  Validation loss = 1.3605  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 1.8923  Validation loss = 1.3603  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 1.8921  Validation loss = 1.3602  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 1.8918  Validation loss = 1.3595  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 1.8917  Validation loss = 1.3595  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 1.8913  Validation loss = 1.3586  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 1.8911  Validation loss = 1.3582  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 1.8909  Validation loss = 1.3577  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 1.8906  Validation loss = 1.3569  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 1.8904  Validation loss = 1.3562  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 1.8902  Validation loss = 1.3560  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 1.8901  Validation loss = 1.3557  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 1.8900  Validation loss = 1.3557  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 1.8897  Validation loss = 1.3549  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 1.8896  Validation loss = 1.3548  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 1.8894  Validation loss = 1.3546  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 1.8892  Validation loss = 1.3542  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 1.8891  Validation loss = 1.3539  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 1.8888  Validation loss = 1.3531  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 1.8884  Validation loss = 1.3522  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 1.8882  Validation loss = 1.3518  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 1.8880  Validation loss = 1.3515  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 1.8878  Validation loss = 1.3511  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 1.8876  Validation loss = 1.3505  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 1.8873  Validation loss = 1.3498  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 1.8871  Validation loss = 1.3496  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 1.8869  Validation loss = 1.3490  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 1.8866  Validation loss = 1.3483  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 1.8863  Validation loss = 1.3478  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 1.8860  Validation loss = 1.3470  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 1.8858  Validation loss = 1.3465  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 1.8855  Validation loss = 1.3456  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 1.8853  Validation loss = 1.3453  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 1.8851  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 1.8849  Validation loss = 1.3444  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 1.8847  Validation loss = 1.3439  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 1.8845  Validation loss = 1.3433  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 1.8844  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 1.8841  Validation loss = 1.3427  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 1.8838  Validation loss = 1.3419  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 1.8836  Validation loss = 1.3415  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 1.8833  Validation loss = 1.3407  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 1.8832  Validation loss = 1.3408  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 1.8829  Validation loss = 1.3399  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 1.8826  Validation loss = 1.3392  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 1.8823  Validation loss = 1.3386  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 1.8821  Validation loss = 1.3379  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 1.8818  Validation loss = 1.3370  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 1.8815  Validation loss = 1.3364  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 1.8813  Validation loss = 1.3358  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 1.8811  Validation loss = 1.3351  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 1.8810  Validation loss = 1.3353  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 1.8808  Validation loss = 1.3345  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 1.8806  Validation loss = 1.3342  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 1.8804  Validation loss = 1.3337  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 1.8801  Validation loss = 1.3331  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 1.8799  Validation loss = 1.3325  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 1.8797  Validation loss = 1.3320  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 1.8796  Validation loss = 1.3319  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 1.8794  Validation loss = 1.3313  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 1.8792  Validation loss = 1.3312  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 1.8789  Validation loss = 1.3306  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 1.8787  Validation loss = 1.3302  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 1.8785  Validation loss = 1.3292  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 1.8783  Validation loss = 1.3290  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 1.8782  Validation loss = 1.3285  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 1.8780  Validation loss = 1.3281  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 1.8777  Validation loss = 1.3273  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 1.8776  Validation loss = 1.3271  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 1.8773  Validation loss = 1.3266  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 1.8772  Validation loss = 1.3262  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 1.8770  Validation loss = 1.3258  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 1.8768  Validation loss = 1.3252  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 1.8765  Validation loss = 1.3244  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 1.8764  Validation loss = 1.3242  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 1.8762  Validation loss = 1.3238  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 1.8759  Validation loss = 1.3232  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 1.8758  Validation loss = 1.3229  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 1.8756  Validation loss = 1.3222  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 1.8755  Validation loss = 1.3223  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 1.8753  Validation loss = 1.3219  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 1.8752  Validation loss = 1.3219  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 1.8750  Validation loss = 1.3214  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 1.8749  Validation loss = 1.3210  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 1.8746  Validation loss = 1.3202  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 1.8744  Validation loss = 1.3198  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 1.8741  Validation loss = 1.3190  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 1.8739  Validation loss = 1.3187  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 1.8738  Validation loss = 1.3185  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 1.8736  Validation loss = 1.3180  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 1.8735  Validation loss = 1.3176  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 1.8733  Validation loss = 1.3171  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 1.8730  Validation loss = 1.3163  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 1.8727  Validation loss = 1.3154  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 1.8726  Validation loss = 1.3152  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 1.8724  Validation loss = 1.3147  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 1.8721  Validation loss = 1.3140  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 1.8720  Validation loss = 1.3139  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 1.8717  Validation loss = 1.3130  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 1.8714  Validation loss = 1.3124  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 1.8713  Validation loss = 1.3120  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 1.8711  Validation loss = 1.3114  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 1.8708  Validation loss = 1.3109  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 1.8706  Validation loss = 1.3103  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 1.8705  Validation loss = 1.3099  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 1.8702  Validation loss = 1.3092  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 1.8701  Validation loss = 1.3089  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 1.8699  Validation loss = 1.3086  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 1.8698  Validation loss = 1.3083  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 1.8696  Validation loss = 1.3078  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 1.8694  Validation loss = 1.3073  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 1.8692  Validation loss = 1.3068  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 1.8690  Validation loss = 1.3064  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 1.8688  Validation loss = 1.3061  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 1.8687  Validation loss = 1.3058  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 1.8685  Validation loss = 1.3053  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 1.8683  Validation loss = 1.3051  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 1.8683  Validation loss = 1.3050  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 1.8680  Validation loss = 1.3044  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 1.8679  Validation loss = 1.3039  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 1.8676  Validation loss = 1.3030  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 1.8674  Validation loss = 1.3026  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 1.8672  Validation loss = 1.3022  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 1.8670  Validation loss = 1.3017  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 1.8668  Validation loss = 1.3011  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 1.8666  Validation loss = 1.3007  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 1.8663  Validation loss = 1.3000  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 1.8663  Validation loss = 1.2999  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 1.8662  Validation loss = 1.2997  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 1.8660  Validation loss = 1.2994  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 1.8659  Validation loss = 1.2993  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 1.8657  Validation loss = 1.2989  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 1.8656  Validation loss = 1.2988  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 1.8654  Validation loss = 1.2984  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 1.8652  Validation loss = 1.2979  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 1.8649  Validation loss = 1.2970  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 1.8647  Validation loss = 1.2966  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 1.8646  Validation loss = 1.2963  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 1.8645  Validation loss = 1.2961  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 1.8643  Validation loss = 1.2956  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 1.8641  Validation loss = 1.2953  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 1.8639  Validation loss = 1.2949  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 1.8638  Validation loss = 1.2946  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 1.8636  Validation loss = 1.2939  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 1.8634  Validation loss = 1.2935  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 1.8633  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 1.8631  Validation loss = 1.2926  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 1.8629  Validation loss = 1.2924  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 1.8627  Validation loss = 1.2917  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 1.8625  Validation loss = 1.2912  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 1.8623  Validation loss = 1.2907  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 1.8621  Validation loss = 1.2901  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 1.8619  Validation loss = 1.2897  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 1.8618  Validation loss = 1.2896  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 1.8616  Validation loss = 1.2891  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 1.8615  Validation loss = 1.2886  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 1.8613  Validation loss = 1.2880  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 1.8611  Validation loss = 1.2878  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 1.8611  Validation loss = 1.2877  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 1.8609  Validation loss = 1.2873  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 1.8606  Validation loss = 1.2867  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 1.8606  Validation loss = 1.2867  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 1.8603  Validation loss = 1.2861  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 1.8599  Validation loss = 1.2851  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 1.8598  Validation loss = 1.2848  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 1.8596  Validation loss = 1.2844  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 1.8595  Validation loss = 1.2842  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 1.8594  Validation loss = 1.2840  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 1.8592  Validation loss = 1.2835  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 1.8591  Validation loss = 1.2833  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 1.8590  Validation loss = 1.2831  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 1.8588  Validation loss = 1.2825  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 1.8586  Validation loss = 1.2823  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 1.8584  Validation loss = 1.2816  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 1.8583  Validation loss = 1.2812  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 1.8581  Validation loss = 1.2808  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 1.8578  Validation loss = 1.2800  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 1.8576  Validation loss = 1.2796  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 1.8575  Validation loss = 1.2795  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 1.8573  Validation loss = 1.2791  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 1.8571  Validation loss = 1.2784  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 1.8570  Validation loss = 1.2780  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 1.8568  Validation loss = 1.2776  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 1.8565  Validation loss = 1.2767  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 1.8563  Validation loss = 1.2759  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 1.8561  Validation loss = 1.2753  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 1.8559  Validation loss = 1.2750  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 1.8557  Validation loss = 1.2744  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 1.8554  Validation loss = 1.2734  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 1.8553  Validation loss = 1.2730  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 1.8553  Validation loss = 1.2731  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 1.8551  Validation loss = 1.2726  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 1.8549  Validation loss = 1.2721  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 1.8547  Validation loss = 1.2715  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 1.8545  Validation loss = 1.2710  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 1.8544  Validation loss = 1.2707  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 1.8543  Validation loss = 1.2706  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 1.8541  Validation loss = 1.2701  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 1.8540  Validation loss = 1.2698  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 1.8539  Validation loss = 1.2697  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 1.8538  Validation loss = 1.2696  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 1.8537  Validation loss = 1.2693  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 1.8534  Validation loss = 1.2686  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 1.8533  Validation loss = 1.2680  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 1.8531  Validation loss = 1.2675  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 1.8529  Validation loss = 1.2669  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 1.8527  Validation loss = 1.2665  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 1.8526  Validation loss = 1.2660  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 1.8524  Validation loss = 1.2656  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 1.8522  Validation loss = 1.2648  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 1.8520  Validation loss = 1.2644  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 1.8518  Validation loss = 1.2638  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 1.8517  Validation loss = 1.2634  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 1.8515  Validation loss = 1.2630  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 1.8514  Validation loss = 1.2629  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 1.8513  Validation loss = 1.2626  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 1.8510  Validation loss = 1.2619  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 1.8508  Validation loss = 1.2615  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 1.8507  Validation loss = 1.2611  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 1.8506  Validation loss = 1.2609  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 1.8504  Validation loss = 1.2603  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 1.8503  Validation loss = 1.2602  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 1.8501  Validation loss = 1.2595  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 1.8499  Validation loss = 1.2591  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 1.8497  Validation loss = 1.2586  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 1.8495  Validation loss = 1.2583  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 1.8494  Validation loss = 1.2580  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 1.8492  Validation loss = 1.2575  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 1.8491  Validation loss = 1.2572  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 1.8489  Validation loss = 1.2566  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 1.8488  Validation loss = 1.2563  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 1.8487  Validation loss = 1.2562  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 1.8487  Validation loss = 1.2562  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 1.8486  Validation loss = 1.2562  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 1.8482  Validation loss = 1.2550  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 1.8481  Validation loss = 1.2547  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 1.8480  Validation loss = 1.2545  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 1.8477  Validation loss = 1.2536  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 1.8475  Validation loss = 1.2530  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 1.8473  Validation loss = 1.2524  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 1.8472  Validation loss = 1.2522  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 1.8471  Validation loss = 1.2518  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 1.8470  Validation loss = 1.2518  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 1.8468  Validation loss = 1.2512  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 1.8467  Validation loss = 1.2512  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 1.8466  Validation loss = 1.2507  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 1.8465  Validation loss = 1.2506  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 1.8463  Validation loss = 1.2502  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 1.8463  Validation loss = 1.2504  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 1.8461  Validation loss = 1.2499  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 1.8460  Validation loss = 1.2498  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 1.8459  Validation loss = 1.2495  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 1.8457  Validation loss = 1.2491  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 1.8456  Validation loss = 1.2485  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 1.8454  Validation loss = 1.2482  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 1.8453  Validation loss = 1.2478  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 1.8451  Validation loss = 1.2477  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 1.8450  Validation loss = 1.2474  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 1.8449  Validation loss = 1.2473  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 1.8448  Validation loss = 1.2470  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 1.8446  Validation loss = 1.2465  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 1.8444  Validation loss = 1.2459  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 1.8442  Validation loss = 1.2455  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 1.8441  Validation loss = 1.2453  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 1.8440  Validation loss = 1.2450  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 1.8439  Validation loss = 1.2449  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 1.8439  Validation loss = 1.2453  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 1.8438  Validation loss = 1.2450  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 1.8436  Validation loss = 1.2449  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 1.8436  Validation loss = 1.2450  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 1.8434  Validation loss = 1.2446  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 1.8432  Validation loss = 1.2441  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 1.8431  Validation loss = 1.2437  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 1.8430  Validation loss = 1.2434  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 1.8429  Validation loss = 1.2433  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 1.8427  Validation loss = 1.2427  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 1.8426  Validation loss = 1.2427  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 1.8425  Validation loss = 1.2425  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 1.8423  Validation loss = 1.2419  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 1.8422  Validation loss = 1.2415  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 1.8421  Validation loss = 1.2416  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 1.8420  Validation loss = 1.2414  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 1.8418  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 1.8417  Validation loss = 1.2405  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 1.8415  Validation loss = 1.2400  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 1.8413  Validation loss = 1.2394  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 1.8411  Validation loss = 1.2388  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 1.8409  Validation loss = 1.2381  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 1.8407  Validation loss = 1.2374  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 1.8405  Validation loss = 1.2370  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 1.8404  Validation loss = 1.2365  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 1.8402  Validation loss = 1.2359  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 1.8400  Validation loss = 1.2354  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 1.8398  Validation loss = 1.2348  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 1.8397  Validation loss = 1.2347  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 1.8395  Validation loss = 1.2344  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 1.8394  Validation loss = 1.2341  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 1.8393  Validation loss = 1.2338  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 1.8391  Validation loss = 1.2334  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 1.8390  Validation loss = 1.2330  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 1.8388  Validation loss = 1.2326  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 1.8387  Validation loss = 1.2324  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 1.8385  Validation loss = 1.2316  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 1.8383  Validation loss = 1.2311  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 1.8381  Validation loss = 1.2306  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 1.8380  Validation loss = 1.2305  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 1.8379  Validation loss = 1.2299  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 1.8377  Validation loss = 1.2295  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 1.8376  Validation loss = 1.2291  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 1.8375  Validation loss = 1.2293  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 1.8374  Validation loss = 1.2290  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 1.8372  Validation loss = 1.2287  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 1.8371  Validation loss = 1.2282  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 1.8368  Validation loss = 1.2275  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 1.8367  Validation loss = 1.2270  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 1.8366  Validation loss = 1.2269  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 1.8364  Validation loss = 1.2266  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 1.8363  Validation loss = 1.2261  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 1.8362  Validation loss = 1.2260  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 1.8361  Validation loss = 1.2257  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 1.8359  Validation loss = 1.2252  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 1.8357  Validation loss = 1.2250  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 1.8355  Validation loss = 1.2242  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 1.8354  Validation loss = 1.2240  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 1.8353  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 1.8352  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 1.8350  Validation loss = 1.2233  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 1.8349  Validation loss = 1.2231  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 1.8348  Validation loss = 1.2229  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 1.8346  Validation loss = 1.2225  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 1.8345  Validation loss = 1.2222  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 1.8342  Validation loss = 1.2214  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 1.8341  Validation loss = 1.2208  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 1.8340  Validation loss = 1.2209  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 1.8338  Validation loss = 1.2201  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 1.8337  Validation loss = 1.2201  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 1.8336  Validation loss = 1.2196  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 1.8335  Validation loss = 1.2195  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 1.8334  Validation loss = 1.2196  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 1.8333  Validation loss = 1.2194  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 1.8331  Validation loss = 1.2188  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 1.8329  Validation loss = 1.2180  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 1.8327  Validation loss = 1.2176  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 1.8326  Validation loss = 1.2175  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 1.8325  Validation loss = 1.2172  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 1.8322  Validation loss = 1.2163  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 1.8321  Validation loss = 1.2159  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 1.8320  Validation loss = 1.2156  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 1.8318  Validation loss = 1.2152  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 1.8317  Validation loss = 1.2146  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 1.8315  Validation loss = 1.2142  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 1.8314  Validation loss = 1.2140  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 1.8313  Validation loss = 1.2137  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 1.8312  Validation loss = 1.2136  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 1.8311  Validation loss = 1.2133  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 1.8309  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 1.8307  Validation loss = 1.2123  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 1.8306  Validation loss = 1.2121  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 1.8304  Validation loss = 1.2119  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 1.8302  Validation loss = 1.2111  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 1.8301  Validation loss = 1.2104  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 1.8299  Validation loss = 1.2101  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 1.8298  Validation loss = 1.2095  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 1.8296  Validation loss = 1.2091  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 1.8295  Validation loss = 1.2089  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 1.8293  Validation loss = 1.2085  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 1.8292  Validation loss = 1.2081  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 1.8290  Validation loss = 1.2075  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 1.8289  Validation loss = 1.2072  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 1.8288  Validation loss = 1.2070  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 1.8287  Validation loss = 1.2068  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 1.8286  Validation loss = 1.2066  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 1.8285  Validation loss = 1.2063  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 1.8282  Validation loss = 1.2056  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 1.8281  Validation loss = 1.2054  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 1.8280  Validation loss = 1.2049  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 1.8278  Validation loss = 1.2042  \n",
      "\n",
      "Fold: 6  Epoch: 501  Training loss = 1.8276  Validation loss = 1.2038  \n",
      "\n",
      "Fold: 6  Epoch: 502  Training loss = 1.8275  Validation loss = 1.2034  \n",
      "\n",
      "Fold: 6  Epoch: 503  Training loss = 1.8273  Validation loss = 1.2031  \n",
      "\n",
      "Fold: 6  Epoch: 504  Training loss = 1.8270  Validation loss = 1.2023  \n",
      "\n",
      "Fold: 6  Epoch: 505  Training loss = 1.8269  Validation loss = 1.2022  \n",
      "\n",
      "Fold: 6  Epoch: 506  Training loss = 1.8268  Validation loss = 1.2018  \n",
      "\n",
      "Fold: 6  Epoch: 507  Training loss = 1.8267  Validation loss = 1.2018  \n",
      "\n",
      "Fold: 6  Epoch: 508  Training loss = 1.8265  Validation loss = 1.2012  \n",
      "\n",
      "Fold: 6  Epoch: 509  Training loss = 1.8264  Validation loss = 1.2011  \n",
      "\n",
      "Fold: 6  Epoch: 510  Training loss = 1.8262  Validation loss = 1.2004  \n",
      "\n",
      "Fold: 6  Epoch: 511  Training loss = 1.8261  Validation loss = 1.2001  \n",
      "\n",
      "Fold: 6  Epoch: 512  Training loss = 1.8259  Validation loss = 1.1996  \n",
      "\n",
      "Fold: 6  Epoch: 513  Training loss = 1.8257  Validation loss = 1.1989  \n",
      "\n",
      "Fold: 6  Epoch: 514  Training loss = 1.8255  Validation loss = 1.1984  \n",
      "\n",
      "Fold: 6  Epoch: 515  Training loss = 1.8254  Validation loss = 1.1980  \n",
      "\n",
      "Fold: 6  Epoch: 516  Training loss = 1.8252  Validation loss = 1.1976  \n",
      "\n",
      "Fold: 6  Epoch: 517  Training loss = 1.8251  Validation loss = 1.1975  \n",
      "\n",
      "Fold: 6  Epoch: 518  Training loss = 1.8250  Validation loss = 1.1970  \n",
      "\n",
      "Fold: 6  Epoch: 519  Training loss = 1.8248  Validation loss = 1.1967  \n",
      "\n",
      "Fold: 6  Epoch: 520  Training loss = 1.8247  Validation loss = 1.1966  \n",
      "\n",
      "Fold: 6  Epoch: 521  Training loss = 1.8247  Validation loss = 1.1967  \n",
      "\n",
      "Fold: 6  Epoch: 522  Training loss = 1.8246  Validation loss = 1.1965  \n",
      "\n",
      "Fold: 6  Epoch: 523  Training loss = 1.8245  Validation loss = 1.1961  \n",
      "\n",
      "Fold: 6  Epoch: 524  Training loss = 1.8244  Validation loss = 1.1958  \n",
      "\n",
      "Fold: 6  Epoch: 525  Training loss = 1.8242  Validation loss = 1.1956  \n",
      "\n",
      "Fold: 6  Epoch: 526  Training loss = 1.8240  Validation loss = 1.1948  \n",
      "\n",
      "Fold: 6  Epoch: 527  Training loss = 1.8238  Validation loss = 1.1942  \n",
      "\n",
      "Fold: 6  Epoch: 528  Training loss = 1.8236  Validation loss = 1.1938  \n",
      "\n",
      "Fold: 6  Epoch: 529  Training loss = 1.8236  Validation loss = 1.1939  \n",
      "\n",
      "Fold: 6  Epoch: 530  Training loss = 1.8234  Validation loss = 1.1935  \n",
      "\n",
      "Fold: 6  Epoch: 531  Training loss = 1.8233  Validation loss = 1.1930  \n",
      "\n",
      "Fold: 6  Epoch: 532  Training loss = 1.8231  Validation loss = 1.1925  \n",
      "\n",
      "Fold: 6  Epoch: 533  Training loss = 1.8229  Validation loss = 1.1918  \n",
      "\n",
      "Fold: 6  Epoch: 534  Training loss = 1.8228  Validation loss = 1.1915  \n",
      "\n",
      "Fold: 6  Epoch: 535  Training loss = 1.8228  Validation loss = 1.1917  \n",
      "\n",
      "Fold: 6  Epoch: 536  Training loss = 1.8226  Validation loss = 1.1912  \n",
      "\n",
      "Fold: 6  Epoch: 537  Training loss = 1.8225  Validation loss = 1.1908  \n",
      "\n",
      "Fold: 6  Epoch: 538  Training loss = 1.8223  Validation loss = 1.1903  \n",
      "\n",
      "Fold: 6  Epoch: 539  Training loss = 1.8222  Validation loss = 1.1901  \n",
      "\n",
      "Fold: 6  Epoch: 540  Training loss = 1.8220  Validation loss = 1.1896  \n",
      "\n",
      "Fold: 6  Epoch: 541  Training loss = 1.8219  Validation loss = 1.1895  \n",
      "\n",
      "Fold: 6  Epoch: 542  Training loss = 1.8217  Validation loss = 1.1887  \n",
      "\n",
      "Fold: 6  Epoch: 543  Training loss = 1.8216  Validation loss = 1.1884  \n",
      "\n",
      "Fold: 6  Epoch: 544  Training loss = 1.8215  Validation loss = 1.1883  \n",
      "\n",
      "Fold: 6  Epoch: 545  Training loss = 1.8214  Validation loss = 1.1883  \n",
      "\n",
      "Fold: 6  Epoch: 546  Training loss = 1.8213  Validation loss = 1.1880  \n",
      "\n",
      "Fold: 6  Epoch: 547  Training loss = 1.8212  Validation loss = 1.1877  \n",
      "\n",
      "Fold: 6  Epoch: 548  Training loss = 1.8210  Validation loss = 1.1875  \n",
      "\n",
      "Fold: 6  Epoch: 549  Training loss = 1.8209  Validation loss = 1.1875  \n",
      "\n",
      "Fold: 6  Epoch: 550  Training loss = 1.8208  Validation loss = 1.1873  \n",
      "\n",
      "Fold: 6  Epoch: 551  Training loss = 1.8207  Validation loss = 1.1870  \n",
      "\n",
      "Fold: 6  Epoch: 552  Training loss = 1.8205  Validation loss = 1.1863  \n",
      "\n",
      "Fold: 6  Epoch: 553  Training loss = 1.8203  Validation loss = 1.1857  \n",
      "\n",
      "Fold: 6  Epoch: 554  Training loss = 1.8202  Validation loss = 1.1853  \n",
      "\n",
      "Fold: 6  Epoch: 555  Training loss = 1.8199  Validation loss = 1.1846  \n",
      "\n",
      "Fold: 6  Epoch: 556  Training loss = 1.8198  Validation loss = 1.1843  \n",
      "\n",
      "Fold: 6  Epoch: 557  Training loss = 1.8198  Validation loss = 1.1846  \n",
      "\n",
      "Fold: 6  Epoch: 558  Training loss = 1.8196  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 6  Epoch: 559  Training loss = 1.8195  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 6  Epoch: 560  Training loss = 1.8194  Validation loss = 1.1835  \n",
      "\n",
      "Fold: 6  Epoch: 561  Training loss = 1.8192  Validation loss = 1.1830  \n",
      "\n",
      "Fold: 6  Epoch: 562  Training loss = 1.8191  Validation loss = 1.1828  \n",
      "\n",
      "Fold: 6  Epoch: 563  Training loss = 1.8189  Validation loss = 1.1823  \n",
      "\n",
      "Fold: 6  Epoch: 564  Training loss = 1.8189  Validation loss = 1.1823  \n",
      "\n",
      "Fold: 6  Epoch: 565  Training loss = 1.8187  Validation loss = 1.1822  \n",
      "\n",
      "Fold: 6  Epoch: 566  Training loss = 1.8186  Validation loss = 1.1816  \n",
      "\n",
      "Fold: 6  Epoch: 567  Training loss = 1.8184  Validation loss = 1.1811  \n",
      "\n",
      "Fold: 6  Epoch: 568  Training loss = 1.8183  Validation loss = 1.1810  \n",
      "\n",
      "Fold: 6  Epoch: 569  Training loss = 1.8182  Validation loss = 1.1807  \n",
      "\n",
      "Fold: 6  Epoch: 570  Training loss = 1.8181  Validation loss = 1.1808  \n",
      "\n",
      "Fold: 6  Epoch: 571  Training loss = 1.8180  Validation loss = 1.1806  \n",
      "\n",
      "Fold: 6  Epoch: 572  Training loss = 1.8179  Validation loss = 1.1805  \n",
      "\n",
      "Fold: 6  Epoch: 573  Training loss = 1.8178  Validation loss = 1.1802  \n",
      "\n",
      "Fold: 6  Epoch: 574  Training loss = 1.8176  Validation loss = 1.1800  \n",
      "\n",
      "Fold: 6  Epoch: 575  Training loss = 1.8175  Validation loss = 1.1797  \n",
      "\n",
      "Fold: 6  Epoch: 576  Training loss = 1.8175  Validation loss = 1.1797  \n",
      "\n",
      "Fold: 6  Epoch: 577  Training loss = 1.8174  Validation loss = 1.1795  \n",
      "\n",
      "Fold: 6  Epoch: 578  Training loss = 1.8173  Validation loss = 1.1793  \n",
      "\n",
      "Fold: 6  Epoch: 579  Training loss = 1.8171  Validation loss = 1.1789  \n",
      "\n",
      "Fold: 6  Epoch: 580  Training loss = 1.8170  Validation loss = 1.1785  \n",
      "\n",
      "Fold: 6  Epoch: 581  Training loss = 1.8168  Validation loss = 1.1781  \n",
      "\n",
      "Fold: 6  Epoch: 582  Training loss = 1.8167  Validation loss = 1.1781  \n",
      "\n",
      "Fold: 6  Epoch: 583  Training loss = 1.8166  Validation loss = 1.1777  \n",
      "\n",
      "Fold: 6  Epoch: 584  Training loss = 1.8163  Validation loss = 1.1768  \n",
      "\n",
      "Fold: 6  Epoch: 585  Training loss = 1.8162  Validation loss = 1.1767  \n",
      "\n",
      "Fold: 6  Epoch: 586  Training loss = 1.8161  Validation loss = 1.1763  \n",
      "\n",
      "Fold: 6  Epoch: 587  Training loss = 1.8160  Validation loss = 1.1757  \n",
      "\n",
      "Fold: 6  Epoch: 588  Training loss = 1.8159  Validation loss = 1.1758  \n",
      "\n",
      "Fold: 6  Epoch: 589  Training loss = 1.8158  Validation loss = 1.1756  \n",
      "\n",
      "Fold: 6  Epoch: 590  Training loss = 1.8157  Validation loss = 1.1756  \n",
      "\n",
      "Fold: 6  Epoch: 591  Training loss = 1.8155  Validation loss = 1.1749  \n",
      "\n",
      "Fold: 6  Epoch: 592  Training loss = 1.8153  Validation loss = 1.1745  \n",
      "\n",
      "Fold: 6  Epoch: 593  Training loss = 1.8152  Validation loss = 1.1742  \n",
      "\n",
      "Fold: 6  Epoch: 594  Training loss = 1.8151  Validation loss = 1.1740  \n",
      "\n",
      "Fold: 6  Epoch: 595  Training loss = 1.8149  Validation loss = 1.1732  \n",
      "\n",
      "Fold: 6  Epoch: 596  Training loss = 1.8148  Validation loss = 1.1731  \n",
      "\n",
      "Fold: 6  Epoch: 597  Training loss = 1.8147  Validation loss = 1.1730  \n",
      "\n",
      "Fold: 6  Epoch: 598  Training loss = 1.8145  Validation loss = 1.1724  \n",
      "\n",
      "Fold: 6  Epoch: 599  Training loss = 1.8144  Validation loss = 1.1724  \n",
      "\n",
      "Fold: 6  Epoch: 600  Training loss = 1.8143  Validation loss = 1.1721  \n",
      "\n",
      "Fold: 6  Epoch: 601  Training loss = 1.8142  Validation loss = 1.1718  \n",
      "\n",
      "Fold: 6  Epoch: 602  Training loss = 1.8140  Validation loss = 1.1712  \n",
      "\n",
      "Fold: 6  Epoch: 603  Training loss = 1.8139  Validation loss = 1.1712  \n",
      "\n",
      "Fold: 6  Epoch: 604  Training loss = 1.8137  Validation loss = 1.1706  \n",
      "\n",
      "Fold: 6  Epoch: 605  Training loss = 1.8135  Validation loss = 1.1699  \n",
      "\n",
      "Fold: 6  Epoch: 606  Training loss = 1.8134  Validation loss = 1.1696  \n",
      "\n",
      "Fold: 6  Epoch: 607  Training loss = 1.8132  Validation loss = 1.1688  \n",
      "\n",
      "Fold: 6  Epoch: 608  Training loss = 1.8131  Validation loss = 1.1690  \n",
      "\n",
      "Fold: 6  Epoch: 609  Training loss = 1.8130  Validation loss = 1.1690  \n",
      "\n",
      "Fold: 6  Epoch: 610  Training loss = 1.8129  Validation loss = 1.1688  \n",
      "\n",
      "Fold: 6  Epoch: 611  Training loss = 1.8127  Validation loss = 1.1681  \n",
      "\n",
      "Fold: 6  Epoch: 612  Training loss = 1.8125  Validation loss = 1.1676  \n",
      "\n",
      "Fold: 6  Epoch: 613  Training loss = 1.8125  Validation loss = 1.1675  \n",
      "\n",
      "Fold: 6  Epoch: 614  Training loss = 1.8123  Validation loss = 1.1672  \n",
      "\n",
      "Fold: 6  Epoch: 615  Training loss = 1.8121  Validation loss = 1.1664  \n",
      "\n",
      "Fold: 6  Epoch: 616  Training loss = 1.8119  Validation loss = 1.1656  \n",
      "\n",
      "Fold: 6  Epoch: 617  Training loss = 1.8117  Validation loss = 1.1650  \n",
      "\n",
      "Fold: 6  Epoch: 618  Training loss = 1.8115  Validation loss = 1.1643  \n",
      "\n",
      "Fold: 6  Epoch: 619  Training loss = 1.8114  Validation loss = 1.1641  \n",
      "\n",
      "Fold: 6  Epoch: 620  Training loss = 1.8114  Validation loss = 1.1639  \n",
      "\n",
      "Fold: 6  Epoch: 621  Training loss = 1.8113  Validation loss = 1.1640  \n",
      "\n",
      "Fold: 6  Epoch: 622  Training loss = 1.8111  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 6  Epoch: 623  Training loss = 1.8110  Validation loss = 1.1632  \n",
      "\n",
      "Fold: 6  Epoch: 624  Training loss = 1.8108  Validation loss = 1.1625  \n",
      "\n",
      "Fold: 6  Epoch: 625  Training loss = 1.8107  Validation loss = 1.1622  \n",
      "\n",
      "Fold: 6  Epoch: 626  Training loss = 1.8105  Validation loss = 1.1615  \n",
      "\n",
      "Fold: 6  Epoch: 627  Training loss = 1.8104  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 6  Epoch: 628  Training loss = 1.8102  Validation loss = 1.1607  \n",
      "\n",
      "Fold: 6  Epoch: 629  Training loss = 1.8101  Validation loss = 1.1605  \n",
      "\n",
      "Fold: 6  Epoch: 630  Training loss = 1.8100  Validation loss = 1.1601  \n",
      "\n",
      "Fold: 6  Epoch: 631  Training loss = 1.8098  Validation loss = 1.1596  \n",
      "\n",
      "Fold: 6  Epoch: 632  Training loss = 1.8097  Validation loss = 1.1594  \n",
      "\n",
      "Fold: 6  Epoch: 633  Training loss = 1.8096  Validation loss = 1.1590  \n",
      "\n",
      "Fold: 6  Epoch: 634  Training loss = 1.8095  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 6  Epoch: 635  Training loss = 1.8094  Validation loss = 1.1588  \n",
      "\n",
      "Fold: 6  Epoch: 636  Training loss = 1.8093  Validation loss = 1.1587  \n",
      "\n",
      "Fold: 6  Epoch: 637  Training loss = 1.8092  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 6  Epoch: 638  Training loss = 1.8090  Validation loss = 1.1579  \n",
      "\n",
      "Fold: 6  Epoch: 639  Training loss = 1.8088  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 6  Epoch: 640  Training loss = 1.8087  Validation loss = 1.1572  \n",
      "\n",
      "Fold: 6  Epoch: 641  Training loss = 1.8085  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 6  Epoch: 642  Training loss = 1.8084  Validation loss = 1.1563  \n",
      "\n",
      "Fold: 6  Epoch: 643  Training loss = 1.8083  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 6  Epoch: 644  Training loss = 1.8082  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 6  Epoch: 645  Training loss = 1.8081  Validation loss = 1.1558  \n",
      "\n",
      "Fold: 6  Epoch: 646  Training loss = 1.8080  Validation loss = 1.1555  \n",
      "\n",
      "Fold: 6  Epoch: 647  Training loss = 1.8079  Validation loss = 1.1555  \n",
      "\n",
      "Fold: 6  Epoch: 648  Training loss = 1.8077  Validation loss = 1.1549  \n",
      "\n",
      "Fold: 6  Epoch: 649  Training loss = 1.8076  Validation loss = 1.1548  \n",
      "\n",
      "Fold: 6  Epoch: 650  Training loss = 1.8074  Validation loss = 1.1542  \n",
      "\n",
      "Fold: 6  Epoch: 651  Training loss = 1.8073  Validation loss = 1.1538  \n",
      "\n",
      "Fold: 6  Epoch: 652  Training loss = 1.8072  Validation loss = 1.1537  \n",
      "\n",
      "Fold: 6  Epoch: 653  Training loss = 1.8071  Validation loss = 1.1534  \n",
      "\n",
      "Fold: 6  Epoch: 654  Training loss = 1.8069  Validation loss = 1.1532  \n",
      "\n",
      "Fold: 6  Epoch: 655  Training loss = 1.8068  Validation loss = 1.1529  \n",
      "\n",
      "Fold: 6  Epoch: 656  Training loss = 1.8067  Validation loss = 1.1527  \n",
      "\n",
      "Fold: 6  Epoch: 657  Training loss = 1.8065  Validation loss = 1.1525  \n",
      "\n",
      "Fold: 6  Epoch: 658  Training loss = 1.8064  Validation loss = 1.1521  \n",
      "\n",
      "Fold: 6  Epoch: 659  Training loss = 1.8063  Validation loss = 1.1524  \n",
      "\n",
      "Fold: 6  Epoch: 660  Training loss = 1.8062  Validation loss = 1.1521  \n",
      "\n",
      "Fold: 6  Epoch: 661  Training loss = 1.8060  Validation loss = 1.1519  \n",
      "\n",
      "Fold: 6  Epoch: 662  Training loss = 1.8058  Validation loss = 1.1512  \n",
      "\n",
      "Fold: 6  Epoch: 663  Training loss = 1.8057  Validation loss = 1.1513  \n",
      "\n",
      "Fold: 6  Epoch: 664  Training loss = 1.8056  Validation loss = 1.1510  \n",
      "\n",
      "Fold: 6  Epoch: 665  Training loss = 1.8055  Validation loss = 1.1509  \n",
      "\n",
      "Fold: 6  Epoch: 666  Training loss = 1.8053  Validation loss = 1.1506  \n",
      "\n",
      "Fold: 6  Epoch: 667  Training loss = 1.8052  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 6  Epoch: 668  Training loss = 1.8051  Validation loss = 1.1499  \n",
      "\n",
      "Fold: 6  Epoch: 669  Training loss = 1.8049  Validation loss = 1.1493  \n",
      "\n",
      "Fold: 6  Epoch: 670  Training loss = 1.8048  Validation loss = 1.1490  \n",
      "\n",
      "Fold: 6  Epoch: 671  Training loss = 1.8047  Validation loss = 1.1491  \n",
      "\n",
      "Fold: 6  Epoch: 672  Training loss = 1.8046  Validation loss = 1.1488  \n",
      "\n",
      "Fold: 6  Epoch: 673  Training loss = 1.8045  Validation loss = 1.1489  \n",
      "\n",
      "Fold: 6  Epoch: 674  Training loss = 1.8043  Validation loss = 1.1484  \n",
      "\n",
      "Fold: 6  Epoch: 675  Training loss = 1.8043  Validation loss = 1.1484  \n",
      "\n",
      "Fold: 6  Epoch: 676  Training loss = 1.8041  Validation loss = 1.1480  \n",
      "\n",
      "Fold: 6  Epoch: 677  Training loss = 1.8040  Validation loss = 1.1478  \n",
      "\n",
      "Fold: 6  Epoch: 678  Training loss = 1.8038  Validation loss = 1.1477  \n",
      "\n",
      "Fold: 6  Epoch: 679  Training loss = 1.8037  Validation loss = 1.1474  \n",
      "\n",
      "Fold: 6  Epoch: 680  Training loss = 1.8036  Validation loss = 1.1473  \n",
      "\n",
      "Fold: 6  Epoch: 681  Training loss = 1.8035  Validation loss = 1.1471  \n",
      "\n",
      "Fold: 6  Epoch: 682  Training loss = 1.8033  Validation loss = 1.1467  \n",
      "\n",
      "Fold: 6  Epoch: 683  Training loss = 1.8031  Validation loss = 1.1459  \n",
      "\n",
      "Fold: 6  Epoch: 684  Training loss = 1.8030  Validation loss = 1.1454  \n",
      "\n",
      "Fold: 6  Epoch: 685  Training loss = 1.8029  Validation loss = 1.1453  \n",
      "\n",
      "Fold: 6  Epoch: 686  Training loss = 1.8027  Validation loss = 1.1449  \n",
      "\n",
      "Fold: 6  Epoch: 687  Training loss = 1.8026  Validation loss = 1.1446  \n",
      "\n",
      "Fold: 6  Epoch: 688  Training loss = 1.8025  Validation loss = 1.1445  \n",
      "\n",
      "Fold: 6  Epoch: 689  Training loss = 1.8024  Validation loss = 1.1442  \n",
      "\n",
      "Fold: 6  Epoch: 690  Training loss = 1.8022  Validation loss = 1.1438  \n",
      "\n",
      "Fold: 6  Epoch: 691  Training loss = 1.8021  Validation loss = 1.1437  \n",
      "\n",
      "Fold: 6  Epoch: 692  Training loss = 1.8020  Validation loss = 1.1434  \n",
      "\n",
      "Fold: 6  Epoch: 693  Training loss = 1.8018  Validation loss = 1.1429  \n",
      "\n",
      "Fold: 6  Epoch: 694  Training loss = 1.8017  Validation loss = 1.1425  \n",
      "\n",
      "Fold: 6  Epoch: 695  Training loss = 1.8016  Validation loss = 1.1420  \n",
      "\n",
      "Fold: 6  Epoch: 696  Training loss = 1.8015  Validation loss = 1.1419  \n",
      "\n",
      "Fold: 6  Epoch: 697  Training loss = 1.8013  Validation loss = 1.1416  \n",
      "\n",
      "Fold: 6  Epoch: 698  Training loss = 1.8012  Validation loss = 1.1411  \n",
      "\n",
      "Fold: 6  Epoch: 699  Training loss = 1.8011  Validation loss = 1.1409  \n",
      "\n",
      "Fold: 6  Epoch: 700  Training loss = 1.8009  Validation loss = 1.1406  \n",
      "\n",
      "Fold: 6  Epoch: 701  Training loss = 1.8008  Validation loss = 1.1405  \n",
      "\n",
      "Fold: 6  Epoch: 702  Training loss = 1.8007  Validation loss = 1.1403  \n",
      "\n",
      "Fold: 6  Epoch: 703  Training loss = 1.8006  Validation loss = 1.1401  \n",
      "\n",
      "Fold: 6  Epoch: 704  Training loss = 1.8005  Validation loss = 1.1399  \n",
      "\n",
      "Fold: 6  Epoch: 705  Training loss = 1.8003  Validation loss = 1.1394  \n",
      "\n",
      "Fold: 6  Epoch: 706  Training loss = 1.8002  Validation loss = 1.1396  \n",
      "\n",
      "Fold: 6  Epoch: 707  Training loss = 1.8000  Validation loss = 1.1390  \n",
      "\n",
      "Fold: 6  Epoch: 708  Training loss = 1.7999  Validation loss = 1.1386  \n",
      "\n",
      "Fold: 6  Epoch: 709  Training loss = 1.7998  Validation loss = 1.1382  \n",
      "\n",
      "Fold: 6  Epoch: 710  Training loss = 1.7996  Validation loss = 1.1376  \n",
      "\n",
      "Fold: 6  Epoch: 711  Training loss = 1.7994  Validation loss = 1.1369  \n",
      "\n",
      "Fold: 6  Epoch: 712  Training loss = 1.7992  Validation loss = 1.1366  \n",
      "\n",
      "Fold: 6  Epoch: 713  Training loss = 1.7991  Validation loss = 1.1363  \n",
      "\n",
      "Fold: 6  Epoch: 714  Training loss = 1.7989  Validation loss = 1.1356  \n",
      "\n",
      "Fold: 6  Epoch: 715  Training loss = 1.7987  Validation loss = 1.1350  \n",
      "\n",
      "Fold: 6  Epoch: 716  Training loss = 1.7986  Validation loss = 1.1351  \n",
      "\n",
      "Fold: 6  Epoch: 717  Training loss = 1.7986  Validation loss = 1.1351  \n",
      "\n",
      "Fold: 6  Epoch: 718  Training loss = 1.7984  Validation loss = 1.1347  \n",
      "\n",
      "Fold: 6  Epoch: 719  Training loss = 1.7983  Validation loss = 1.1345  \n",
      "\n",
      "Fold: 6  Epoch: 720  Training loss = 1.7982  Validation loss = 1.1344  \n",
      "\n",
      "Fold: 6  Epoch: 721  Training loss = 1.7980  Validation loss = 1.1339  \n",
      "\n",
      "Fold: 6  Epoch: 722  Training loss = 1.7979  Validation loss = 1.1336  \n",
      "\n",
      "Fold: 6  Epoch: 723  Training loss = 1.7977  Validation loss = 1.1332  \n",
      "\n",
      "Fold: 6  Epoch: 724  Training loss = 1.7976  Validation loss = 1.1329  \n",
      "\n",
      "Fold: 6  Epoch: 725  Training loss = 1.7976  Validation loss = 1.1330  \n",
      "\n",
      "Fold: 6  Epoch: 726  Training loss = 1.7974  Validation loss = 1.1324  \n",
      "\n",
      "Fold: 6  Epoch: 727  Training loss = 1.7972  Validation loss = 1.1319  \n",
      "\n",
      "Fold: 6  Epoch: 728  Training loss = 1.7972  Validation loss = 1.1321  \n",
      "\n",
      "Fold: 6  Epoch: 729  Training loss = 1.7971  Validation loss = 1.1318  \n",
      "\n",
      "Fold: 6  Epoch: 730  Training loss = 1.7970  Validation loss = 1.1316  \n",
      "\n",
      "Fold: 6  Epoch: 731  Training loss = 1.7969  Validation loss = 1.1316  \n",
      "\n",
      "Fold: 6  Epoch: 732  Training loss = 1.7967  Validation loss = 1.1310  \n",
      "\n",
      "Fold: 6  Epoch: 733  Training loss = 1.7966  Validation loss = 1.1309  \n",
      "\n",
      "Fold: 6  Epoch: 734  Training loss = 1.7964  Validation loss = 1.1303  \n",
      "\n",
      "Fold: 6  Epoch: 735  Training loss = 1.7963  Validation loss = 1.1299  \n",
      "\n",
      "Fold: 6  Epoch: 736  Training loss = 1.7961  Validation loss = 1.1297  \n",
      "\n",
      "Fold: 6  Epoch: 737  Training loss = 1.7960  Validation loss = 1.1294  \n",
      "\n",
      "Fold: 6  Epoch: 738  Training loss = 1.7959  Validation loss = 1.1294  \n",
      "\n",
      "Fold: 6  Epoch: 739  Training loss = 1.7958  Validation loss = 1.1293  \n",
      "\n",
      "Fold: 6  Epoch: 740  Training loss = 1.7957  Validation loss = 1.1291  \n",
      "\n",
      "Fold: 6  Epoch: 741  Training loss = 1.7955  Validation loss = 1.1284  \n",
      "\n",
      "Fold: 6  Epoch: 742  Training loss = 1.7954  Validation loss = 1.1286  \n",
      "\n",
      "Fold: 6  Epoch: 743  Training loss = 1.7953  Validation loss = 1.1283  \n",
      "\n",
      "Fold: 6  Epoch: 744  Training loss = 1.7950  Validation loss = 1.1274  \n",
      "\n",
      "Fold: 6  Epoch: 745  Training loss = 1.7949  Validation loss = 1.1269  \n",
      "\n",
      "Fold: 6  Epoch: 746  Training loss = 1.7948  Validation loss = 1.1268  \n",
      "\n",
      "Fold: 6  Epoch: 747  Training loss = 1.7946  Validation loss = 1.1264  \n",
      "\n",
      "Fold: 6  Epoch: 748  Training loss = 1.7946  Validation loss = 1.1265  \n",
      "\n",
      "Fold: 6  Epoch: 749  Training loss = 1.7944  Validation loss = 1.1262  \n",
      "\n",
      "Fold: 6  Epoch: 750  Training loss = 1.7943  Validation loss = 1.1261  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 750  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.7223  Validation loss = 1.0258  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.7220  Validation loss = 1.0250  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.7218  Validation loss = 1.0247  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.7216  Validation loss = 1.0241  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.7214  Validation loss = 1.0240  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.7212  Validation loss = 1.0236  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.7210  Validation loss = 1.0230  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.7208  Validation loss = 1.0227  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.7206  Validation loss = 1.0224  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.7205  Validation loss = 1.0223  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.7202  Validation loss = 1.0218  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.7200  Validation loss = 1.0212  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.7198  Validation loss = 1.0209  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.7195  Validation loss = 1.0203  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.7193  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.7192  Validation loss = 1.0197  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.7189  Validation loss = 1.0190  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.7187  Validation loss = 1.0183  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.7185  Validation loss = 1.0178  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.7182  Validation loss = 1.0171  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.7179  Validation loss = 1.0164  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.7177  Validation loss = 1.0158  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 1.7175  Validation loss = 1.0155  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 1.7172  Validation loss = 1.0146  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 1.7171  Validation loss = 1.0143  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 1.7169  Validation loss = 1.0141  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 1.7167  Validation loss = 1.0139  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 1.7165  Validation loss = 1.0131  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 1.7164  Validation loss = 1.0133  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 1.7162  Validation loss = 1.0130  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 1.7160  Validation loss = 1.0126  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 1.7159  Validation loss = 1.0123  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 1.7157  Validation loss = 1.0119  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 1.7155  Validation loss = 1.0114  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 1.7153  Validation loss = 1.0112  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 1.7151  Validation loss = 1.0109  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 1.7149  Validation loss = 1.0102  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 1.7147  Validation loss = 1.0098  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 1.7145  Validation loss = 1.0095  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 1.7144  Validation loss = 1.0094  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 1.7142  Validation loss = 1.0092  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 1.7139  Validation loss = 1.0084  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 1.7137  Validation loss = 1.0080  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 1.7135  Validation loss = 1.0074  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 1.7133  Validation loss = 1.0069  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 1.7131  Validation loss = 1.0063  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 1.7128  Validation loss = 1.0059  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 1.7127  Validation loss = 1.0056  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 1.7125  Validation loss = 1.0053  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 1.7123  Validation loss = 1.0048  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 1.7121  Validation loss = 1.0042  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 1.7119  Validation loss = 1.0039  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 1.7116  Validation loss = 1.0031  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 1.7116  Validation loss = 1.0030  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 1.7114  Validation loss = 1.0026  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 1.7112  Validation loss = 1.0024  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 1.7111  Validation loss = 1.0022  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 1.7109  Validation loss = 1.0018  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 1.7105  Validation loss = 1.0006  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 1.7103  Validation loss = 1.0001  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 1.7101  Validation loss = 0.9996  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 1.7099  Validation loss = 0.9995  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 1.7097  Validation loss = 0.9988  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 1.7094  Validation loss = 0.9982  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 1.7093  Validation loss = 0.9979  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 1.7090  Validation loss = 0.9975  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 1.7088  Validation loss = 0.9968  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 1.7085  Validation loss = 0.9963  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 1.7083  Validation loss = 0.9958  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 1.7082  Validation loss = 0.9955  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 1.7079  Validation loss = 0.9949  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 1.7076  Validation loss = 0.9942  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 1.7075  Validation loss = 0.9940  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 1.7075  Validation loss = 0.9942  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 1.7074  Validation loss = 0.9940  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 1.7072  Validation loss = 0.9936  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 1.7070  Validation loss = 0.9932  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 1.7067  Validation loss = 0.9927  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 1.7065  Validation loss = 0.9922  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 1.7063  Validation loss = 0.9918  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 1.7061  Validation loss = 0.9914  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 1.7060  Validation loss = 0.9912  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 1.7059  Validation loss = 0.9908  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 1.7057  Validation loss = 0.9903  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 1.7055  Validation loss = 0.9900  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 1.7052  Validation loss = 0.9893  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 1.7051  Validation loss = 0.9891  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 1.7049  Validation loss = 0.9885  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 1.7047  Validation loss = 0.9879  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 1.7044  Validation loss = 0.9872  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 1.7044  Validation loss = 0.9874  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 1.7042  Validation loss = 0.9870  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 1.7040  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 1.7038  Validation loss = 0.9864  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 1.7036  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 1.7034  Validation loss = 0.9857  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 1.7033  Validation loss = 0.9855  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 1.7031  Validation loss = 0.9849  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 1.7029  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 1.7026  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 1.7023  Validation loss = 0.9831  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 1.7021  Validation loss = 0.9826  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 1.7020  Validation loss = 0.9823  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 1.7018  Validation loss = 0.9823  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 1.7016  Validation loss = 0.9817  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 1.7014  Validation loss = 0.9814  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 1.7013  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 1.7011  Validation loss = 0.9806  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 1.7009  Validation loss = 0.9803  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 1.7006  Validation loss = 0.9795  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 1.7004  Validation loss = 0.9790  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 1.7002  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 1.7000  Validation loss = 0.9782  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 1.6998  Validation loss = 0.9776  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 1.6996  Validation loss = 0.9771  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 1.6995  Validation loss = 0.9771  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 1.6992  Validation loss = 0.9763  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 1.6988  Validation loss = 0.9753  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 1.6987  Validation loss = 0.9752  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 1.6985  Validation loss = 0.9749  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 1.6983  Validation loss = 0.9745  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 1.6981  Validation loss = 0.9742  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 1.6979  Validation loss = 0.9736  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 1.6977  Validation loss = 0.9730  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 1.6974  Validation loss = 0.9725  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 1.6973  Validation loss = 0.9722  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 1.6972  Validation loss = 0.9724  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 1.6971  Validation loss = 0.9724  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 1.6969  Validation loss = 0.9721  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 1.6968  Validation loss = 0.9724  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 1.6967  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 1.6965  Validation loss = 0.9715  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 1.6963  Validation loss = 0.9711  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 1.6961  Validation loss = 0.9708  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 1.6958  Validation loss = 0.9701  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 1.6955  Validation loss = 0.9696  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 1.6955  Validation loss = 0.9696  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 1.6952  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 1.6950  Validation loss = 0.9688  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 1.6949  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 1.6948  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 1.6946  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 1.6944  Validation loss = 0.9678  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 1.6943  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 1.6941  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 1.6939  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 1.6937  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 1.6936  Validation loss = 0.9658  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 1.6934  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 1.6931  Validation loss = 0.9650  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 1.6929  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 1.6927  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 1.6927  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 1.6924  Validation loss = 0.9635  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 1.6923  Validation loss = 0.9632  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 1.6921  Validation loss = 0.9627  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 1.6920  Validation loss = 0.9627  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 1.6918  Validation loss = 0.9625  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 1.6916  Validation loss = 0.9619  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 1.6914  Validation loss = 0.9614  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 1.6912  Validation loss = 0.9614  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 1.6910  Validation loss = 0.9611  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 1.6908  Validation loss = 0.9603  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 1.6905  Validation loss = 0.9597  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 1.6904  Validation loss = 0.9593  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 1.6901  Validation loss = 0.9588  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 1.6899  Validation loss = 0.9582  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 1.6896  Validation loss = 0.9572  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 1.6894  Validation loss = 0.9568  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 1.6891  Validation loss = 0.9562  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 1.6889  Validation loss = 0.9558  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 1.6887  Validation loss = 0.9554  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 1.6886  Validation loss = 0.9552  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 1.6885  Validation loss = 0.9551  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 1.6883  Validation loss = 0.9545  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 1.6880  Validation loss = 0.9538  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 1.6878  Validation loss = 0.9533  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 1.6876  Validation loss = 0.9530  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 1.6874  Validation loss = 0.9522  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 1.6872  Validation loss = 0.9517  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 1.6870  Validation loss = 0.9512  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 1.6869  Validation loss = 0.9512  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 1.6868  Validation loss = 0.9510  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 1.6866  Validation loss = 0.9507  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 1.6864  Validation loss = 0.9502  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 1.6863  Validation loss = 0.9505  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 1.6861  Validation loss = 0.9500  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 1.6860  Validation loss = 0.9499  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 1.6859  Validation loss = 0.9499  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 1.6857  Validation loss = 0.9496  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 1.6856  Validation loss = 0.9497  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 1.6853  Validation loss = 0.9490  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 1.6852  Validation loss = 0.9489  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 1.6850  Validation loss = 0.9484  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 1.6849  Validation loss = 0.9485  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 1.6847  Validation loss = 0.9482  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 1.6845  Validation loss = 0.9477  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 1.6844  Validation loss = 0.9476  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 1.6843  Validation loss = 0.9476  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 1.6841  Validation loss = 0.9474  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 1.6840  Validation loss = 0.9471  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 1.6838  Validation loss = 0.9470  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 1.6836  Validation loss = 0.9467  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 1.6834  Validation loss = 0.9460  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 1.6833  Validation loss = 0.9462  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 1.6831  Validation loss = 0.9457  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 1.6829  Validation loss = 0.9451  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 1.6827  Validation loss = 0.9450  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 1.6825  Validation loss = 0.9444  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 1.6824  Validation loss = 0.9443  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 1.6823  Validation loss = 0.9440  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 1.6821  Validation loss = 0.9438  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 1.6820  Validation loss = 0.9438  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 1.6819  Validation loss = 0.9435  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 1.6817  Validation loss = 0.9431  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 1.6815  Validation loss = 0.9429  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 1.6814  Validation loss = 0.9427  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 1.6812  Validation loss = 0.9424  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 1.6810  Validation loss = 0.9420  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 1.6809  Validation loss = 0.9418  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 1.6808  Validation loss = 0.9415  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 1.6805  Validation loss = 0.9410  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 1.6803  Validation loss = 0.9404  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 1.6801  Validation loss = 0.9397  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 1.6800  Validation loss = 0.9396  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 1.6798  Validation loss = 0.9393  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 1.6797  Validation loss = 0.9392  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 1.6796  Validation loss = 0.9393  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 1.6794  Validation loss = 0.9389  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 1.6793  Validation loss = 0.9388  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 1.6791  Validation loss = 0.9384  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 1.6789  Validation loss = 0.9379  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 1.6787  Validation loss = 0.9374  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 1.6785  Validation loss = 0.9370  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 1.6782  Validation loss = 0.9361  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 1.6780  Validation loss = 0.9360  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 1.6779  Validation loss = 0.9359  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 1.6778  Validation loss = 0.9357  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 1.6776  Validation loss = 0.9354  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 1.6775  Validation loss = 0.9351  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 1.6773  Validation loss = 0.9349  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 1.6771  Validation loss = 0.9344  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 1.6770  Validation loss = 0.9341  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 1.6768  Validation loss = 0.9337  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 1.6766  Validation loss = 0.9332  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 1.6764  Validation loss = 0.9331  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 1.6762  Validation loss = 0.9328  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 1.6760  Validation loss = 0.9321  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 1.6757  Validation loss = 0.9314  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 1.6756  Validation loss = 0.9312  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 1.6754  Validation loss = 0.9309  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 1.6753  Validation loss = 0.9309  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 1.6751  Validation loss = 0.9304  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 1.6749  Validation loss = 0.9299  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 1.6747  Validation loss = 0.9295  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 1.6745  Validation loss = 0.9290  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 1.6743  Validation loss = 0.9285  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 1.6742  Validation loss = 0.9285  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 1.6740  Validation loss = 0.9284  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 1.6739  Validation loss = 0.9280  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 1.6738  Validation loss = 0.9279  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 1.6737  Validation loss = 0.9278  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 1.6734  Validation loss = 0.9272  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 1.6733  Validation loss = 0.9272  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 1.6731  Validation loss = 0.9269  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 1.6730  Validation loss = 0.9266  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 1.6729  Validation loss = 0.9264  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 1.6728  Validation loss = 0.9264  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 1.6726  Validation loss = 0.9262  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 1.6725  Validation loss = 0.9258  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 1.6723  Validation loss = 0.9253  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 1.6721  Validation loss = 0.9248  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 1.6719  Validation loss = 0.9247  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 1.6718  Validation loss = 0.9243  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 1.6716  Validation loss = 0.9239  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 1.6714  Validation loss = 0.9237  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 1.6713  Validation loss = 0.9234  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 1.6711  Validation loss = 0.9229  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 1.6709  Validation loss = 0.9227  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 1.6708  Validation loss = 0.9225  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 1.6707  Validation loss = 0.9223  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 1.6705  Validation loss = 0.9217  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 1.6703  Validation loss = 0.9215  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 1.6702  Validation loss = 0.9212  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 1.6701  Validation loss = 0.9212  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 1.6699  Validation loss = 0.9208  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 1.6698  Validation loss = 0.9206  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 1.6695  Validation loss = 0.9203  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 1.6694  Validation loss = 0.9202  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 1.6692  Validation loss = 0.9199  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 1.6691  Validation loss = 0.9198  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 1.6689  Validation loss = 0.9195  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 1.6687  Validation loss = 0.9189  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 1.6685  Validation loss = 0.9187  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 1.6684  Validation loss = 0.9185  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 1.6682  Validation loss = 0.9182  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 1.6681  Validation loss = 0.9178  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 1.6680  Validation loss = 0.9177  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 1.6678  Validation loss = 0.9170  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 1.6676  Validation loss = 0.9167  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 1.6674  Validation loss = 0.9162  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 1.6673  Validation loss = 0.9162  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 1.6671  Validation loss = 0.9157  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 1.6670  Validation loss = 0.9157  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 1.6669  Validation loss = 0.9156  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 1.6668  Validation loss = 0.9156  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 1.6666  Validation loss = 0.9153  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 1.6664  Validation loss = 0.9151  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 1.6663  Validation loss = 0.9147  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 1.6662  Validation loss = 0.9148  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 1.6661  Validation loss = 0.9150  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 1.6659  Validation loss = 0.9146  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 1.6658  Validation loss = 0.9144  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 1.6657  Validation loss = 0.9143  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 1.6655  Validation loss = 0.9140  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 1.6653  Validation loss = 0.9136  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 1.6652  Validation loss = 0.9132  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 1.6650  Validation loss = 0.9129  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 1.6649  Validation loss = 0.9130  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 1.6648  Validation loss = 0.9130  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 1.6646  Validation loss = 0.9126  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 1.6645  Validation loss = 0.9124  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 1.6643  Validation loss = 0.9123  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 1.6642  Validation loss = 0.9122  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 1.6640  Validation loss = 0.9120  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 1.6639  Validation loss = 0.9117  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 1.6637  Validation loss = 0.9114  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 1.6635  Validation loss = 0.9113  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 1.6634  Validation loss = 0.9112  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 1.6633  Validation loss = 0.9113  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 1.6632  Validation loss = 0.9109  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 1.6630  Validation loss = 0.9106  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 1.6629  Validation loss = 0.9102  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 1.6627  Validation loss = 0.9100  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 1.6627  Validation loss = 0.9101  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 1.6625  Validation loss = 0.9097  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 1.6624  Validation loss = 0.9096  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 1.6623  Validation loss = 0.9094  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 1.6622  Validation loss = 0.9096  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 1.6621  Validation loss = 0.9097  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 1.6620  Validation loss = 0.9099  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 1.6618  Validation loss = 0.9097  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 1.6617  Validation loss = 0.9096  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 1.6617  Validation loss = 0.9101  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 1.6615  Validation loss = 0.9097  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 1.6613  Validation loss = 0.9092  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 1.6612  Validation loss = 0.9091  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 1.6610  Validation loss = 0.9085  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 1.6609  Validation loss = 0.9087  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 1.6607  Validation loss = 0.9081  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 1.6605  Validation loss = 0.9081  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 1.6604  Validation loss = 0.9083  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 1.6604  Validation loss = 0.9082  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 1.6602  Validation loss = 0.9078  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 1.6601  Validation loss = 0.9075  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 1.6599  Validation loss = 0.9071  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 1.6598  Validation loss = 0.9071  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 1.6597  Validation loss = 0.9073  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 1.6595  Validation loss = 0.9067  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 1.6594  Validation loss = 0.9065  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 1.6593  Validation loss = 0.9067  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 1.6592  Validation loss = 0.9063  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 1.6590  Validation loss = 0.9058  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 1.6587  Validation loss = 0.9054  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 1.6586  Validation loss = 0.9052  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 1.6584  Validation loss = 0.9049  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 1.6583  Validation loss = 0.9047  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 1.6581  Validation loss = 0.9044  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 1.6580  Validation loss = 0.9046  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 1.6579  Validation loss = 0.9046  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 1.6577  Validation loss = 0.9044  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 1.6575  Validation loss = 0.9043  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 1.6574  Validation loss = 0.9042  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 1.6572  Validation loss = 0.9038  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 1.6570  Validation loss = 0.9034  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 1.6569  Validation loss = 0.9033  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 1.6568  Validation loss = 0.9033  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 1.6566  Validation loss = 0.9028  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 1.6565  Validation loss = 0.9028  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 1.6564  Validation loss = 0.9029  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 1.6562  Validation loss = 0.9026  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 1.6561  Validation loss = 0.9026  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 1.6559  Validation loss = 0.9022  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 1.6558  Validation loss = 0.9020  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 1.6555  Validation loss = 0.9013  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 1.6554  Validation loss = 0.9009  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 1.6553  Validation loss = 0.9009  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 1.6551  Validation loss = 0.9009  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 1.6550  Validation loss = 0.9005  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 1.6548  Validation loss = 0.9000  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 1.6547  Validation loss = 0.9001  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 1.6545  Validation loss = 0.8998  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 1.6544  Validation loss = 0.8997  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 1.6542  Validation loss = 0.8993  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 1.6540  Validation loss = 0.8986  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 1.6539  Validation loss = 0.8985  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 1.6538  Validation loss = 0.8985  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 1.6536  Validation loss = 0.8982  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 1.6535  Validation loss = 0.8979  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 1.6534  Validation loss = 0.8979  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 1.6532  Validation loss = 0.8974  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 1.6531  Validation loss = 0.8977  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 1.6530  Validation loss = 0.8979  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 1.6528  Validation loss = 0.8975  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 1.6527  Validation loss = 0.8976  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 1.6526  Validation loss = 0.8977  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 1.6525  Validation loss = 0.8974  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 1.6523  Validation loss = 0.8973  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 1.6522  Validation loss = 0.8970  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 1.6520  Validation loss = 0.8971  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 1.6518  Validation loss = 0.8964  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 1.6517  Validation loss = 0.8966  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 1.6516  Validation loss = 0.8965  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 1.6515  Validation loss = 0.8965  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 1.6514  Validation loss = 0.8965  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 1.6513  Validation loss = 0.8964  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 1.6511  Validation loss = 0.8961  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 1.6510  Validation loss = 0.8959  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 1.6509  Validation loss = 0.8959  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 1.6507  Validation loss = 0.8958  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 1.6506  Validation loss = 0.8955  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 1.6504  Validation loss = 0.8954  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 1.6504  Validation loss = 0.8957  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 1.6502  Validation loss = 0.8955  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 1.6501  Validation loss = 0.8953  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 1.6499  Validation loss = 0.8952  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 1.6498  Validation loss = 0.8949  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 1.6496  Validation loss = 0.8946  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 1.6493  Validation loss = 0.8938  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 1.6491  Validation loss = 0.8936  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 1.6490  Validation loss = 0.8936  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 1.6489  Validation loss = 0.8939  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 1.6488  Validation loss = 0.8938  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 1.6486  Validation loss = 0.8936  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 1.6484  Validation loss = 0.8931  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 1.6483  Validation loss = 0.8930  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 1.6481  Validation loss = 0.8926  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 1.6480  Validation loss = 0.8923  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 1.6477  Validation loss = 0.8919  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 1.6476  Validation loss = 0.8913  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 1.6475  Validation loss = 0.8913  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 1.6472  Validation loss = 0.8904  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 1.6471  Validation loss = 0.8902  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 1.6469  Validation loss = 0.8898  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 1.6468  Validation loss = 0.8897  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 1.6466  Validation loss = 0.8894  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 1.6464  Validation loss = 0.8893  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 1.6463  Validation loss = 0.8892  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 1.6462  Validation loss = 0.8890  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 1.6460  Validation loss = 0.8886  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 1.6459  Validation loss = 0.8881  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 1.6457  Validation loss = 0.8880  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 1.6456  Validation loss = 0.8876  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 1.6454  Validation loss = 0.8874  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 1.6453  Validation loss = 0.8872  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 1.6451  Validation loss = 0.8870  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 1.6450  Validation loss = 0.8872  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 1.6449  Validation loss = 0.8870  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 1.6447  Validation loss = 0.8867  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 1.6446  Validation loss = 0.8860  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 1.6445  Validation loss = 0.8863  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 1.6444  Validation loss = 0.8862  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 1.6442  Validation loss = 0.8858  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 1.6441  Validation loss = 0.8858  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 1.6440  Validation loss = 0.8857  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 1.6438  Validation loss = 0.8856  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 1.6437  Validation loss = 0.8854  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 1.6437  Validation loss = 0.8858  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 1.6435  Validation loss = 0.8856  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 1.6434  Validation loss = 0.8856  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 1.6433  Validation loss = 0.8852  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 1.6431  Validation loss = 0.8850  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 1.6430  Validation loss = 0.8849  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 1.6429  Validation loss = 0.8846  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 1.6427  Validation loss = 0.8847  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 1.6426  Validation loss = 0.8847  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 1.6425  Validation loss = 0.8844  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 1.6423  Validation loss = 0.8844  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 1.6422  Validation loss = 0.8841  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 1.6421  Validation loss = 0.8839  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 1.6419  Validation loss = 0.8838  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 1.6418  Validation loss = 0.8839  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 1.6416  Validation loss = 0.8831  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 1.6414  Validation loss = 0.8829  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 1.6413  Validation loss = 0.8829  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 1.6412  Validation loss = 0.8829  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 1.6410  Validation loss = 0.8824  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 1.6410  Validation loss = 0.8830  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 1.6409  Validation loss = 0.8830  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 1.6408  Validation loss = 0.8829  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 1.6405  Validation loss = 0.8821  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 1.6404  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 1.6403  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 1.6401  Validation loss = 0.8818  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 1.6400  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 1.6398  Validation loss = 0.8814  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 1.6397  Validation loss = 0.8812  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 1.6396  Validation loss = 0.8811  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 1.6394  Validation loss = 0.8809  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 1.6392  Validation loss = 0.8807  \n",
      "\n",
      "Fold: 7  Epoch: 501  Training loss = 1.6391  Validation loss = 0.8805  \n",
      "\n",
      "Fold: 7  Epoch: 502  Training loss = 1.6390  Validation loss = 0.8803  \n",
      "\n",
      "Fold: 7  Epoch: 503  Training loss = 1.6389  Validation loss = 0.8803  \n",
      "\n",
      "Fold: 7  Epoch: 504  Training loss = 1.6387  Validation loss = 0.8799  \n",
      "\n",
      "Fold: 7  Epoch: 505  Training loss = 1.6385  Validation loss = 0.8794  \n",
      "\n",
      "Fold: 7  Epoch: 506  Training loss = 1.6384  Validation loss = 0.8795  \n",
      "\n",
      "Fold: 7  Epoch: 507  Training loss = 1.6382  Validation loss = 0.8790  \n",
      "\n",
      "Fold: 7  Epoch: 508  Training loss = 1.6379  Validation loss = 0.8785  \n",
      "\n",
      "Fold: 7  Epoch: 509  Training loss = 1.6378  Validation loss = 0.8783  \n",
      "\n",
      "Fold: 7  Epoch: 510  Training loss = 1.6376  Validation loss = 0.8779  \n",
      "\n",
      "Fold: 7  Epoch: 511  Training loss = 1.6375  Validation loss = 0.8779  \n",
      "\n",
      "Fold: 7  Epoch: 512  Training loss = 1.6373  Validation loss = 0.8775  \n",
      "\n",
      "Fold: 7  Epoch: 513  Training loss = 1.6372  Validation loss = 0.8774  \n",
      "\n",
      "Fold: 7  Epoch: 514  Training loss = 1.6371  Validation loss = 0.8775  \n",
      "\n",
      "Fold: 7  Epoch: 515  Training loss = 1.6370  Validation loss = 0.8774  \n",
      "\n",
      "Fold: 7  Epoch: 516  Training loss = 1.6368  Validation loss = 0.8768  \n",
      "\n",
      "Fold: 7  Epoch: 517  Training loss = 1.6366  Validation loss = 0.8764  \n",
      "\n",
      "Fold: 7  Epoch: 518  Training loss = 1.6365  Validation loss = 0.8762  \n",
      "\n",
      "Fold: 7  Epoch: 519  Training loss = 1.6363  Validation loss = 0.8760  \n",
      "\n",
      "Fold: 7  Epoch: 520  Training loss = 1.6362  Validation loss = 0.8756  \n",
      "\n",
      "Fold: 7  Epoch: 521  Training loss = 1.6361  Validation loss = 0.8755  \n",
      "\n",
      "Fold: 7  Epoch: 522  Training loss = 1.6359  Validation loss = 0.8753  \n",
      "\n",
      "Fold: 7  Epoch: 523  Training loss = 1.6359  Validation loss = 0.8755  \n",
      "\n",
      "Fold: 7  Epoch: 524  Training loss = 1.6358  Validation loss = 0.8757  \n",
      "\n",
      "Fold: 7  Epoch: 525  Training loss = 1.6357  Validation loss = 0.8754  \n",
      "\n",
      "Fold: 7  Epoch: 526  Training loss = 1.6355  Validation loss = 0.8753  \n",
      "\n",
      "Fold: 7  Epoch: 527  Training loss = 1.6354  Validation loss = 0.8752  \n",
      "\n",
      "Fold: 7  Epoch: 528  Training loss = 1.6352  Validation loss = 0.8749  \n",
      "\n",
      "Fold: 7  Epoch: 529  Training loss = 1.6351  Validation loss = 0.8750  \n",
      "\n",
      "Fold: 7  Epoch: 530  Training loss = 1.6350  Validation loss = 0.8750  \n",
      "\n",
      "Fold: 7  Epoch: 531  Training loss = 1.6349  Validation loss = 0.8751  \n",
      "\n",
      "Fold: 7  Epoch: 532  Training loss = 1.6347  Validation loss = 0.8747  \n",
      "\n",
      "Fold: 7  Epoch: 533  Training loss = 1.6345  Validation loss = 0.8747  \n",
      "\n",
      "Fold: 7  Epoch: 534  Training loss = 1.6344  Validation loss = 0.8742  \n",
      "\n",
      "Fold: 7  Epoch: 535  Training loss = 1.6343  Validation loss = 0.8745  \n",
      "\n",
      "Fold: 7  Epoch: 536  Training loss = 1.6343  Validation loss = 0.8747  \n",
      "\n",
      "Fold: 7  Epoch: 537  Training loss = 1.6341  Validation loss = 0.8747  \n",
      "\n",
      "Fold: 7  Epoch: 538  Training loss = 1.6340  Validation loss = 0.8746  \n",
      "\n",
      "Fold: 7  Epoch: 539  Training loss = 1.6339  Validation loss = 0.8746  \n",
      "\n",
      "Fold: 7  Epoch: 540  Training loss = 1.6338  Validation loss = 0.8748  \n",
      "\n",
      "Fold: 7  Epoch: 541  Training loss = 1.6336  Validation loss = 0.8747  \n",
      "\n",
      "Fold: 7  Epoch: 542  Training loss = 1.6335  Validation loss = 0.8745  \n",
      "\n",
      "Fold: 7  Epoch: 543  Training loss = 1.6334  Validation loss = 0.8745  \n",
      "\n",
      "Fold: 7  Epoch: 544  Training loss = 1.6332  Validation loss = 0.8745  \n",
      "\n",
      "Fold: 7  Epoch: 545  Training loss = 1.6331  Validation loss = 0.8743  \n",
      "\n",
      "Fold: 7  Epoch: 546  Training loss = 1.6329  Validation loss = 0.8740  \n",
      "\n",
      "Fold: 7  Epoch: 547  Training loss = 1.6328  Validation loss = 0.8735  \n",
      "\n",
      "Fold: 7  Epoch: 548  Training loss = 1.6327  Validation loss = 0.8735  \n",
      "\n",
      "Fold: 7  Epoch: 549  Training loss = 1.6325  Validation loss = 0.8735  \n",
      "\n",
      "Fold: 7  Epoch: 550  Training loss = 1.6324  Validation loss = 0.8734  \n",
      "\n",
      "Fold: 7  Epoch: 551  Training loss = 1.6323  Validation loss = 0.8733  \n",
      "\n",
      "Fold: 7  Epoch: 552  Training loss = 1.6322  Validation loss = 0.8729  \n",
      "\n",
      "Fold: 7  Epoch: 553  Training loss = 1.6320  Validation loss = 0.8728  \n",
      "\n",
      "Fold: 7  Epoch: 554  Training loss = 1.6319  Validation loss = 0.8725  \n",
      "\n",
      "Fold: 7  Epoch: 555  Training loss = 1.6317  Validation loss = 0.8721  \n",
      "\n",
      "Fold: 7  Epoch: 556  Training loss = 1.6316  Validation loss = 0.8720  \n",
      "\n",
      "Fold: 7  Epoch: 557  Training loss = 1.6315  Validation loss = 0.8719  \n",
      "\n",
      "Fold: 7  Epoch: 558  Training loss = 1.6313  Validation loss = 0.8714  \n",
      "\n",
      "Fold: 7  Epoch: 559  Training loss = 1.6311  Validation loss = 0.8714  \n",
      "\n",
      "Fold: 7  Epoch: 560  Training loss = 1.6309  Validation loss = 0.8708  \n",
      "\n",
      "Fold: 7  Epoch: 561  Training loss = 1.6309  Validation loss = 0.8712  \n",
      "\n",
      "Fold: 7  Epoch: 562  Training loss = 1.6308  Validation loss = 0.8712  \n",
      "\n",
      "Fold: 7  Epoch: 563  Training loss = 1.6307  Validation loss = 0.8708  \n",
      "\n",
      "Fold: 7  Epoch: 564  Training loss = 1.6305  Validation loss = 0.8705  \n",
      "\n",
      "Fold: 7  Epoch: 565  Training loss = 1.6304  Validation loss = 0.8706  \n",
      "\n",
      "Fold: 7  Epoch: 566  Training loss = 1.6302  Validation loss = 0.8704  \n",
      "\n",
      "Fold: 7  Epoch: 567  Training loss = 1.6302  Validation loss = 0.8707  \n",
      "\n",
      "Fold: 7  Epoch: 568  Training loss = 1.6301  Validation loss = 0.8705  \n",
      "\n",
      "Fold: 7  Epoch: 569  Training loss = 1.6299  Validation loss = 0.8700  \n",
      "\n",
      "Fold: 7  Epoch: 570  Training loss = 1.6297  Validation loss = 0.8700  \n",
      "\n",
      "Fold: 7  Epoch: 571  Training loss = 1.6296  Validation loss = 0.8699  \n",
      "\n",
      "Fold: 7  Epoch: 572  Training loss = 1.6295  Validation loss = 0.8695  \n",
      "\n",
      "Fold: 7  Epoch: 573  Training loss = 1.6292  Validation loss = 0.8690  \n",
      "\n",
      "Fold: 7  Epoch: 574  Training loss = 1.6291  Validation loss = 0.8688  \n",
      "\n",
      "Fold: 7  Epoch: 575  Training loss = 1.6290  Validation loss = 0.8689  \n",
      "\n",
      "Fold: 7  Epoch: 576  Training loss = 1.6288  Validation loss = 0.8686  \n",
      "\n",
      "Fold: 7  Epoch: 577  Training loss = 1.6287  Validation loss = 0.8688  \n",
      "\n",
      "Fold: 7  Epoch: 578  Training loss = 1.6286  Validation loss = 0.8685  \n",
      "\n",
      "Fold: 7  Epoch: 579  Training loss = 1.6285  Validation loss = 0.8689  \n",
      "\n",
      "Fold: 7  Epoch: 580  Training loss = 1.6284  Validation loss = 0.8690  \n",
      "\n",
      "Fold: 7  Epoch: 581  Training loss = 1.6282  Validation loss = 0.8688  \n",
      "\n",
      "Fold: 7  Epoch: 582  Training loss = 1.6281  Validation loss = 0.8688  \n",
      "\n",
      "Fold: 7  Epoch: 583  Training loss = 1.6279  Validation loss = 0.8686  \n",
      "\n",
      "Fold: 7  Epoch: 584  Training loss = 1.6278  Validation loss = 0.8681  \n",
      "\n",
      "Fold: 7  Epoch: 585  Training loss = 1.6277  Validation loss = 0.8685  \n",
      "\n",
      "Fold: 7  Epoch: 586  Training loss = 1.6275  Validation loss = 0.8683  \n",
      "\n",
      "Fold: 7  Epoch: 587  Training loss = 1.6275  Validation loss = 0.8684  \n",
      "\n",
      "Fold: 7  Epoch: 588  Training loss = 1.6272  Validation loss = 0.8679  \n",
      "\n",
      "Fold: 7  Epoch: 589  Training loss = 1.6272  Validation loss = 0.8679  \n",
      "\n",
      "Fold: 7  Epoch: 590  Training loss = 1.6270  Validation loss = 0.8678  \n",
      "\n",
      "Fold: 7  Epoch: 591  Training loss = 1.6269  Validation loss = 0.8675  \n",
      "\n",
      "Fold: 7  Epoch: 592  Training loss = 1.6268  Validation loss = 0.8676  \n",
      "\n",
      "Fold: 7  Epoch: 593  Training loss = 1.6267  Validation loss = 0.8675  \n",
      "\n",
      "Fold: 7  Epoch: 594  Training loss = 1.6266  Validation loss = 0.8674  \n",
      "\n",
      "Fold: 7  Epoch: 595  Training loss = 1.6264  Validation loss = 0.8677  \n",
      "\n",
      "Fold: 7  Epoch: 596  Training loss = 1.6264  Validation loss = 0.8678  \n",
      "\n",
      "Fold: 7  Epoch: 597  Training loss = 1.6262  Validation loss = 0.8675  \n",
      "\n",
      "Fold: 7  Epoch: 598  Training loss = 1.6261  Validation loss = 0.8672  \n",
      "\n",
      "Fold: 7  Epoch: 599  Training loss = 1.6260  Validation loss = 0.8674  \n",
      "\n",
      "Fold: 7  Epoch: 600  Training loss = 1.6259  Validation loss = 0.8673  \n",
      "\n",
      "Fold: 7  Epoch: 601  Training loss = 1.6258  Validation loss = 0.8673  \n",
      "\n",
      "Fold: 7  Epoch: 602  Training loss = 1.6258  Validation loss = 0.8674  \n",
      "\n",
      "Fold: 7  Epoch: 603  Training loss = 1.6256  Validation loss = 0.8673  \n",
      "\n",
      "Fold: 7  Epoch: 604  Training loss = 1.6255  Validation loss = 0.8673  \n",
      "\n",
      "Fold: 7  Epoch: 605  Training loss = 1.6254  Validation loss = 0.8676  \n",
      "\n",
      "Fold: 7  Epoch: 606  Training loss = 1.6252  Validation loss = 0.8669  \n",
      "\n",
      "Fold: 7  Epoch: 607  Training loss = 1.6251  Validation loss = 0.8668  \n",
      "\n",
      "Fold: 7  Epoch: 608  Training loss = 1.6249  Validation loss = 0.8662  \n",
      "\n",
      "Fold: 7  Epoch: 609  Training loss = 1.6247  Validation loss = 0.8661  \n",
      "\n",
      "Fold: 7  Epoch: 610  Training loss = 1.6247  Validation loss = 0.8661  \n",
      "\n",
      "Fold: 7  Epoch: 611  Training loss = 1.6245  Validation loss = 0.8662  \n",
      "\n",
      "Fold: 7  Epoch: 612  Training loss = 1.6244  Validation loss = 0.8661  \n",
      "\n",
      "Fold: 7  Epoch: 613  Training loss = 1.6243  Validation loss = 0.8658  \n",
      "\n",
      "Fold: 7  Epoch: 614  Training loss = 1.6241  Validation loss = 0.8655  \n",
      "\n",
      "Fold: 7  Epoch: 615  Training loss = 1.6240  Validation loss = 0.8653  \n",
      "\n",
      "Fold: 7  Epoch: 616  Training loss = 1.6239  Validation loss = 0.8656  \n",
      "\n",
      "Fold: 7  Epoch: 617  Training loss = 1.6236  Validation loss = 0.8652  \n",
      "\n",
      "Fold: 7  Epoch: 618  Training loss = 1.6235  Validation loss = 0.8649  \n",
      "\n",
      "Fold: 7  Epoch: 619  Training loss = 1.6234  Validation loss = 0.8649  \n",
      "\n",
      "Fold: 7  Epoch: 620  Training loss = 1.6233  Validation loss = 0.8649  \n",
      "\n",
      "Fold: 7  Epoch: 621  Training loss = 1.6232  Validation loss = 0.8647  \n",
      "\n",
      "Fold: 7  Epoch: 622  Training loss = 1.6230  Validation loss = 0.8646  \n",
      "\n",
      "Fold: 7  Epoch: 623  Training loss = 1.6228  Validation loss = 0.8643  \n",
      "\n",
      "Fold: 7  Epoch: 624  Training loss = 1.6227  Validation loss = 0.8642  \n",
      "\n",
      "Fold: 7  Epoch: 625  Training loss = 1.6226  Validation loss = 0.8641  \n",
      "\n",
      "Fold: 7  Epoch: 626  Training loss = 1.6224  Validation loss = 0.8638  \n",
      "\n",
      "Fold: 7  Epoch: 627  Training loss = 1.6222  Validation loss = 0.8637  \n",
      "\n",
      "Fold: 7  Epoch: 628  Training loss = 1.6222  Validation loss = 0.8639  \n",
      "\n",
      "Fold: 7  Epoch: 629  Training loss = 1.6220  Validation loss = 0.8638  \n",
      "\n",
      "Fold: 7  Epoch: 630  Training loss = 1.6219  Validation loss = 0.8638  \n",
      "\n",
      "Fold: 7  Epoch: 631  Training loss = 1.6218  Validation loss = 0.8640  \n",
      "\n",
      "Fold: 7  Epoch: 632  Training loss = 1.6217  Validation loss = 0.8638  \n",
      "\n",
      "Fold: 7  Epoch: 633  Training loss = 1.6216  Validation loss = 0.8639  \n",
      "\n",
      "Fold: 7  Epoch: 634  Training loss = 1.6214  Validation loss = 0.8639  \n",
      "\n",
      "Fold: 7  Epoch: 635  Training loss = 1.6213  Validation loss = 0.8637  \n",
      "\n",
      "Fold: 7  Epoch: 636  Training loss = 1.6211  Validation loss = 0.8636  \n",
      "\n",
      "Fold: 7  Epoch: 637  Training loss = 1.6210  Validation loss = 0.8634  \n",
      "\n",
      "Fold: 7  Epoch: 638  Training loss = 1.6209  Validation loss = 0.8631  \n",
      "\n",
      "Fold: 7  Epoch: 639  Training loss = 1.6208  Validation loss = 0.8632  \n",
      "\n",
      "Fold: 7  Epoch: 640  Training loss = 1.6207  Validation loss = 0.8634  \n",
      "\n",
      "Fold: 7  Epoch: 641  Training loss = 1.6206  Validation loss = 0.8633  \n",
      "\n",
      "Fold: 7  Epoch: 642  Training loss = 1.6205  Validation loss = 0.8630  \n",
      "\n",
      "Fold: 7  Epoch: 643  Training loss = 1.6204  Validation loss = 0.8628  \n",
      "\n",
      "Fold: 7  Epoch: 644  Training loss = 1.6202  Validation loss = 0.8630  \n",
      "\n",
      "Fold: 7  Epoch: 645  Training loss = 1.6201  Validation loss = 0.8630  \n",
      "\n",
      "Fold: 7  Epoch: 646  Training loss = 1.6200  Validation loss = 0.8627  \n",
      "\n",
      "Fold: 7  Epoch: 647  Training loss = 1.6198  Validation loss = 0.8623  \n",
      "\n",
      "Fold: 7  Epoch: 648  Training loss = 1.6197  Validation loss = 0.8622  \n",
      "\n",
      "Fold: 7  Epoch: 649  Training loss = 1.6196  Validation loss = 0.8622  \n",
      "\n",
      "Fold: 7  Epoch: 650  Training loss = 1.6194  Validation loss = 0.8619  \n",
      "\n",
      "Fold: 7  Epoch: 651  Training loss = 1.6194  Validation loss = 0.8622  \n",
      "\n",
      "Fold: 7  Epoch: 652  Training loss = 1.6192  Validation loss = 0.8619  \n",
      "\n",
      "Fold: 7  Epoch: 653  Training loss = 1.6191  Validation loss = 0.8617  \n",
      "\n",
      "Fold: 7  Epoch: 654  Training loss = 1.6190  Validation loss = 0.8619  \n",
      "\n",
      "Fold: 7  Epoch: 655  Training loss = 1.6189  Validation loss = 0.8619  \n",
      "\n",
      "Fold: 7  Epoch: 656  Training loss = 1.6187  Validation loss = 0.8612  \n",
      "\n",
      "Fold: 7  Epoch: 657  Training loss = 1.6185  Validation loss = 0.8609  \n",
      "\n",
      "Fold: 7  Epoch: 658  Training loss = 1.6184  Validation loss = 0.8609  \n",
      "\n",
      "Fold: 7  Epoch: 659  Training loss = 1.6182  Validation loss = 0.8603  \n",
      "\n",
      "Fold: 7  Epoch: 660  Training loss = 1.6181  Validation loss = 0.8604  \n",
      "\n",
      "Fold: 7  Epoch: 661  Training loss = 1.6180  Validation loss = 0.8601  \n",
      "\n",
      "Fold: 7  Epoch: 662  Training loss = 1.6178  Validation loss = 0.8600  \n",
      "\n",
      "Fold: 7  Epoch: 663  Training loss = 1.6177  Validation loss = 0.8596  \n",
      "\n",
      "Fold: 7  Epoch: 664  Training loss = 1.6176  Validation loss = 0.8595  \n",
      "\n",
      "Fold: 7  Epoch: 665  Training loss = 1.6175  Validation loss = 0.8597  \n",
      "\n",
      "Fold: 7  Epoch: 666  Training loss = 1.6173  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 7  Epoch: 667  Training loss = 1.6172  Validation loss = 0.8595  \n",
      "\n",
      "Fold: 7  Epoch: 668  Training loss = 1.6170  Validation loss = 0.8594  \n",
      "\n",
      "Fold: 7  Epoch: 669  Training loss = 1.6169  Validation loss = 0.8592  \n",
      "\n",
      "Fold: 7  Epoch: 670  Training loss = 1.6167  Validation loss = 0.8592  \n",
      "\n",
      "Fold: 7  Epoch: 671  Training loss = 1.6165  Validation loss = 0.8587  \n",
      "\n",
      "Fold: 7  Epoch: 672  Training loss = 1.6163  Validation loss = 0.8584  \n",
      "\n",
      "Fold: 7  Epoch: 673  Training loss = 1.6162  Validation loss = 0.8584  \n",
      "\n",
      "Fold: 7  Epoch: 674  Training loss = 1.6161  Validation loss = 0.8584  \n",
      "\n",
      "Fold: 7  Epoch: 675  Training loss = 1.6160  Validation loss = 0.8580  \n",
      "\n",
      "Fold: 7  Epoch: 676  Training loss = 1.6158  Validation loss = 0.8576  \n",
      "\n",
      "Fold: 7  Epoch: 677  Training loss = 1.6157  Validation loss = 0.8576  \n",
      "\n",
      "Fold: 7  Epoch: 678  Training loss = 1.6156  Validation loss = 0.8578  \n",
      "\n",
      "Fold: 7  Epoch: 679  Training loss = 1.6154  Validation loss = 0.8577  \n",
      "\n",
      "Fold: 7  Epoch: 680  Training loss = 1.6152  Validation loss = 0.8570  \n",
      "\n",
      "Fold: 7  Epoch: 681  Training loss = 1.6150  Validation loss = 0.8563  \n",
      "\n",
      "Fold: 7  Epoch: 682  Training loss = 1.6149  Validation loss = 0.8560  \n",
      "\n",
      "Fold: 7  Epoch: 683  Training loss = 1.6148  Validation loss = 0.8559  \n",
      "\n",
      "Fold: 7  Epoch: 684  Training loss = 1.6147  Validation loss = 0.8562  \n",
      "\n",
      "Fold: 7  Epoch: 685  Training loss = 1.6146  Validation loss = 0.8559  \n",
      "\n",
      "Fold: 7  Epoch: 686  Training loss = 1.6144  Validation loss = 0.8561  \n",
      "\n",
      "Fold: 7  Epoch: 687  Training loss = 1.6143  Validation loss = 0.8558  \n",
      "\n",
      "Fold: 7  Epoch: 688  Training loss = 1.6141  Validation loss = 0.8553  \n",
      "\n",
      "Fold: 7  Epoch: 689  Training loss = 1.6140  Validation loss = 0.8549  \n",
      "\n",
      "Fold: 7  Epoch: 690  Training loss = 1.6139  Validation loss = 0.8550  \n",
      "\n",
      "Fold: 7  Epoch: 691  Training loss = 1.6138  Validation loss = 0.8546  \n",
      "\n",
      "Fold: 7  Epoch: 692  Training loss = 1.6136  Validation loss = 0.8546  \n",
      "\n",
      "Fold: 7  Epoch: 693  Training loss = 1.6135  Validation loss = 0.8548  \n",
      "\n",
      "Fold: 7  Epoch: 694  Training loss = 1.6134  Validation loss = 0.8545  \n",
      "\n",
      "Fold: 7  Epoch: 695  Training loss = 1.6132  Validation loss = 0.8544  \n",
      "\n",
      "Fold: 7  Epoch: 696  Training loss = 1.6131  Validation loss = 0.8545  \n",
      "\n",
      "Fold: 7  Epoch: 697  Training loss = 1.6129  Validation loss = 0.8544  \n",
      "\n",
      "Fold: 7  Epoch: 698  Training loss = 1.6127  Validation loss = 0.8538  \n",
      "\n",
      "Fold: 7  Epoch: 699  Training loss = 1.6126  Validation loss = 0.8536  \n",
      "\n",
      "Fold: 7  Epoch: 700  Training loss = 1.6125  Validation loss = 0.8535  \n",
      "\n",
      "Fold: 7  Epoch: 701  Training loss = 1.6124  Validation loss = 0.8539  \n",
      "\n",
      "Fold: 7  Epoch: 702  Training loss = 1.6123  Validation loss = 0.8535  \n",
      "\n",
      "Fold: 7  Epoch: 703  Training loss = 1.6122  Validation loss = 0.8540  \n",
      "\n",
      "Fold: 7  Epoch: 704  Training loss = 1.6121  Validation loss = 0.8539  \n",
      "\n",
      "Fold: 7  Epoch: 705  Training loss = 1.6120  Validation loss = 0.8544  \n",
      "\n",
      "Fold: 7  Epoch: 706  Training loss = 1.6119  Validation loss = 0.8544  \n",
      "\n",
      "Fold: 7  Epoch: 707  Training loss = 1.6118  Validation loss = 0.8544  \n",
      "\n",
      "Fold: 7  Epoch: 708  Training loss = 1.6117  Validation loss = 0.8548  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 700  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.5712  Validation loss = 5.8801  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.5711  Validation loss = 5.8796  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.5709  Validation loss = 5.8791  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.5707  Validation loss = 5.8784  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.5707  Validation loss = 5.8782  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.5705  Validation loss = 5.8781  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.5704  Validation loss = 5.8778  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.5702  Validation loss = 5.8773  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.5700  Validation loss = 5.8765  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.5699  Validation loss = 5.8763  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.5697  Validation loss = 5.8760  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.5696  Validation loss = 5.8760  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.5695  Validation loss = 5.8757  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.5694  Validation loss = 5.8755  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.5693  Validation loss = 5.8752  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.5692  Validation loss = 5.8754  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.5691  Validation loss = 5.8755  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.5689  Validation loss = 5.8751  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.5688  Validation loss = 5.8747  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 1.5687  Validation loss = 5.8747  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 1.5685  Validation loss = 5.8739  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 1.5684  Validation loss = 5.8744  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 1.5683  Validation loss = 5.8738  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 1.5681  Validation loss = 5.8737  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 1.5679  Validation loss = 5.8728  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 1.5678  Validation loss = 5.8725  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 1.5677  Validation loss = 5.8724  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 1.5676  Validation loss = 5.8721  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 1.5674  Validation loss = 5.8716  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 1.5673  Validation loss = 5.8712  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 1.5671  Validation loss = 5.8710  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 1.5670  Validation loss = 5.8706  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 1.5668  Validation loss = 5.8699  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 1.5666  Validation loss = 5.8698  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 1.5664  Validation loss = 5.8692  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 1.5664  Validation loss = 5.8694  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 1.5662  Validation loss = 5.8690  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 1.5661  Validation loss = 5.8688  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 1.5660  Validation loss = 5.8686  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 1.5659  Validation loss = 5.8686  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 1.5658  Validation loss = 5.8681  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 1.5656  Validation loss = 5.8678  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 1.5655  Validation loss = 5.8675  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 1.5654  Validation loss = 5.8673  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 1.5652  Validation loss = 5.8669  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 1.5651  Validation loss = 5.8663  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 1.5649  Validation loss = 5.8659  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 1.5648  Validation loss = 5.8657  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 1.5648  Validation loss = 5.8657  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 1.5647  Validation loss = 5.8656  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 1.5645  Validation loss = 5.8654  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 1.5645  Validation loss = 5.8654  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 1.5643  Validation loss = 5.8649  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 1.5641  Validation loss = 5.8641  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 1.5639  Validation loss = 5.8636  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 1.5638  Validation loss = 5.8633  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 1.5637  Validation loss = 5.8631  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 1.5635  Validation loss = 5.8621  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 1.5633  Validation loss = 5.8618  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 1.5631  Validation loss = 5.8611  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 1.5629  Validation loss = 5.8606  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 1.5629  Validation loss = 5.8610  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 1.5627  Validation loss = 5.8607  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 1.5625  Validation loss = 5.8602  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 1.5624  Validation loss = 5.8601  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 1.5623  Validation loss = 5.8599  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 1.5622  Validation loss = 5.8594  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 1.5621  Validation loss = 5.8593  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 1.5620  Validation loss = 5.8593  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 1.5619  Validation loss = 5.8592  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 1.5618  Validation loss = 5.8594  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 1.5617  Validation loss = 5.8595  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 1.5616  Validation loss = 5.8594  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 1.5614  Validation loss = 5.8589  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 1.5613  Validation loss = 5.8586  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 1.5612  Validation loss = 5.8586  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 1.5610  Validation loss = 5.8581  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 1.5609  Validation loss = 5.8576  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 1.5608  Validation loss = 5.8574  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 1.5606  Validation loss = 5.8571  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 1.5605  Validation loss = 5.8574  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 1.5604  Validation loss = 5.8572  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 1.5602  Validation loss = 5.8570  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 1.5600  Validation loss = 5.8560  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 1.5599  Validation loss = 5.8557  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 1.5598  Validation loss = 5.8556  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 1.5596  Validation loss = 5.8550  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 1.5594  Validation loss = 5.8548  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 1.5593  Validation loss = 5.8542  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 1.5592  Validation loss = 5.8543  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 1.5591  Validation loss = 5.8537  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 1.5589  Validation loss = 5.8537  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 1.5588  Validation loss = 5.8534  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 1.5587  Validation loss = 5.8530  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 1.5586  Validation loss = 5.8528  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 1.5585  Validation loss = 5.8531  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 1.5583  Validation loss = 5.8531  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 1.5582  Validation loss = 5.8525  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 1.5581  Validation loss = 5.8522  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 1.5580  Validation loss = 5.8522  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 1.5578  Validation loss = 5.8515  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 1.5577  Validation loss = 5.8517  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 1.5575  Validation loss = 5.8510  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 1.5573  Validation loss = 5.8507  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 1.5572  Validation loss = 5.8502  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 1.5571  Validation loss = 5.8500  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 1.5569  Validation loss = 5.8490  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 1.5567  Validation loss = 5.8486  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 1.5566  Validation loss = 5.8487  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 1.5565  Validation loss = 5.8483  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 1.5564  Validation loss = 5.8483  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 1.5563  Validation loss = 5.8481  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 1.5561  Validation loss = 5.8475  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 1.5560  Validation loss = 5.8475  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 1.5559  Validation loss = 5.8472  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 1.5557  Validation loss = 5.8466  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 1.5556  Validation loss = 5.8466  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 1.5555  Validation loss = 5.8466  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 1.5554  Validation loss = 5.8463  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 1.5553  Validation loss = 5.8463  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 1.5551  Validation loss = 5.8460  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 1.5551  Validation loss = 5.8465  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 1.5549  Validation loss = 5.8459  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 1.5548  Validation loss = 5.8455  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 1.5546  Validation loss = 5.8449  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 1.5544  Validation loss = 5.8444  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 1.5543  Validation loss = 5.8441  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 1.5542  Validation loss = 5.8441  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 1.5540  Validation loss = 5.8437  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 1.5539  Validation loss = 5.8433  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 1.5537  Validation loss = 5.8429  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 1.5536  Validation loss = 5.8425  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 1.5536  Validation loss = 5.8429  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 1.5534  Validation loss = 5.8424  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 1.5532  Validation loss = 5.8417  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 1.5531  Validation loss = 5.8416  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 1.5530  Validation loss = 5.8415  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 1.5529  Validation loss = 5.8412  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 1.5528  Validation loss = 5.8411  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 1.5527  Validation loss = 5.8406  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 1.5525  Validation loss = 5.8400  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 1.5523  Validation loss = 5.8394  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 1.5522  Validation loss = 5.8393  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 1.5521  Validation loss = 5.8390  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 1.5519  Validation loss = 5.8383  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 1.5517  Validation loss = 5.8381  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 1.5516  Validation loss = 5.8376  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 1.5515  Validation loss = 5.8373  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 1.5513  Validation loss = 5.8370  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 1.5512  Validation loss = 5.8371  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 1.5512  Validation loss = 5.8375  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 1.5510  Validation loss = 5.8371  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 1.5509  Validation loss = 5.8366  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 1.5508  Validation loss = 5.8364  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 1.5506  Validation loss = 5.8363  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 1.5505  Validation loss = 5.8360  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 1.5504  Validation loss = 5.8361  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 1.5503  Validation loss = 5.8359  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 1.5501  Validation loss = 5.8358  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 1.5500  Validation loss = 5.8350  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 1.5498  Validation loss = 5.8347  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 1.5497  Validation loss = 5.8343  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 1.5496  Validation loss = 5.8342  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 1.5494  Validation loss = 5.8336  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 1.5492  Validation loss = 5.8334  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 1.5491  Validation loss = 5.8328  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 1.5490  Validation loss = 5.8331  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 1.5488  Validation loss = 5.8324  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 1.5486  Validation loss = 5.8323  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 1.5485  Validation loss = 5.8318  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 1.5484  Validation loss = 5.8314  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 1.5482  Validation loss = 5.8307  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 1.5481  Validation loss = 5.8308  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 1.5479  Validation loss = 5.8301  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 1.5478  Validation loss = 5.8302  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 1.5477  Validation loss = 5.8307  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 1.5476  Validation loss = 5.8306  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 1.5475  Validation loss = 5.8303  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 1.5474  Validation loss = 5.8301  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 1.5473  Validation loss = 5.8299  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 1.5471  Validation loss = 5.8298  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 1.5470  Validation loss = 5.8294  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 1.5468  Validation loss = 5.8290  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 1.5467  Validation loss = 5.8286  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 1.5466  Validation loss = 5.8287  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 1.5465  Validation loss = 5.8285  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 1.5463  Validation loss = 5.8277  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 1.5462  Validation loss = 5.8274  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 1.5461  Validation loss = 5.8273  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 1.5459  Validation loss = 5.8270  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 1.5458  Validation loss = 5.8266  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 1.5457  Validation loss = 5.8264  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 1.5455  Validation loss = 5.8260  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 1.5454  Validation loss = 5.8259  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 1.5453  Validation loss = 5.8261  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 1.5452  Validation loss = 5.8262  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 1.5450  Validation loss = 5.8251  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 1.5449  Validation loss = 5.8250  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 1.5447  Validation loss = 5.8244  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 1.5446  Validation loss = 5.8238  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 1.5445  Validation loss = 5.8236  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 1.5443  Validation loss = 5.8234  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 1.5442  Validation loss = 5.8230  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 1.5440  Validation loss = 5.8228  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 1.5439  Validation loss = 5.8223  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 1.5438  Validation loss = 5.8224  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 1.5436  Validation loss = 5.8221  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 1.5435  Validation loss = 5.8221  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 1.5434  Validation loss = 5.8217  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 1.5433  Validation loss = 5.8219  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 1.5431  Validation loss = 5.8213  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 1.5431  Validation loss = 5.8213  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 1.5429  Validation loss = 5.8210  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 1.5428  Validation loss = 5.8206  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 1.5427  Validation loss = 5.8204  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 1.5425  Validation loss = 5.8201  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 1.5423  Validation loss = 5.8192  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 1.5422  Validation loss = 5.8191  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 1.5420  Validation loss = 5.8184  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 1.5418  Validation loss = 5.8180  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 1.5417  Validation loss = 5.8176  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 1.5416  Validation loss = 5.8174  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 1.5415  Validation loss = 5.8168  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 1.5414  Validation loss = 5.8168  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 1.5413  Validation loss = 5.8164  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 1.5411  Validation loss = 5.8160  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 1.5410  Validation loss = 5.8157  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 1.5408  Validation loss = 5.8153  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 1.5407  Validation loss = 5.8146  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 1.5405  Validation loss = 5.8147  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 1.5404  Validation loss = 5.8143  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 1.5402  Validation loss = 5.8138  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 1.5402  Validation loss = 5.8140  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 1.5401  Validation loss = 5.8139  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 1.5399  Validation loss = 5.8137  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 1.5398  Validation loss = 5.8135  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 1.5397  Validation loss = 5.8132  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 1.5396  Validation loss = 5.8133  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 1.5395  Validation loss = 5.8132  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 1.5393  Validation loss = 5.8126  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 1.5392  Validation loss = 5.8121  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 1.5390  Validation loss = 5.8117  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 1.5389  Validation loss = 5.8117  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 1.5388  Validation loss = 5.8116  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 1.5386  Validation loss = 5.8113  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 1.5385  Validation loss = 5.8112  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 1.5383  Validation loss = 5.8109  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 1.5382  Validation loss = 5.8109  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 1.5381  Validation loss = 5.8102  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 1.5379  Validation loss = 5.8100  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 1.5378  Validation loss = 5.8095  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 1.5377  Validation loss = 5.8092  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 1.5376  Validation loss = 5.8086  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 1.5375  Validation loss = 5.8083  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 1.5373  Validation loss = 5.8083  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 1.5372  Validation loss = 5.8084  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 1.5371  Validation loss = 5.8078  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 1.5369  Validation loss = 5.8071  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 1.5368  Validation loss = 5.8068  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 1.5366  Validation loss = 5.8069  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 1.5365  Validation loss = 5.8067  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 1.5363  Validation loss = 5.8064  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 1.5361  Validation loss = 5.8058  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 1.5361  Validation loss = 5.8061  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 1.5359  Validation loss = 5.8056  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 1.5358  Validation loss = 5.8056  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 1.5358  Validation loss = 5.8059  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 1.5356  Validation loss = 5.8056  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 1.5355  Validation loss = 5.8050  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 1.5354  Validation loss = 5.8048  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 1.5353  Validation loss = 5.8048  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 1.5351  Validation loss = 5.8043  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 1.5349  Validation loss = 5.8035  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 1.5348  Validation loss = 5.8033  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 1.5347  Validation loss = 5.8031  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 1.5345  Validation loss = 5.8031  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 1.5345  Validation loss = 5.8031  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 1.5343  Validation loss = 5.8027  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 1.5342  Validation loss = 5.8021  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 1.5340  Validation loss = 5.8016  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 1.5339  Validation loss = 5.8010  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 1.5337  Validation loss = 5.8008  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 1.5335  Validation loss = 5.7998  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 1.5334  Validation loss = 5.7996  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 1.5333  Validation loss = 5.7994  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 1.5332  Validation loss = 5.7992  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 1.5330  Validation loss = 5.7990  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 1.5329  Validation loss = 5.7987  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 1.5328  Validation loss = 5.7981  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 1.5326  Validation loss = 5.7975  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 1.5325  Validation loss = 5.7972  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 1.5324  Validation loss = 5.7972  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 1.5323  Validation loss = 5.7965  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 1.5321  Validation loss = 5.7961  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 1.5319  Validation loss = 5.7955  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 1.5319  Validation loss = 5.7959  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 1.5316  Validation loss = 5.7950  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 1.5315  Validation loss = 5.7952  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 1.5315  Validation loss = 5.7957  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 1.5313  Validation loss = 5.7955  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 1.5313  Validation loss = 5.7958  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 1.5311  Validation loss = 5.7959  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 1.5310  Validation loss = 5.7961  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 1.5308  Validation loss = 5.7954  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 1.5307  Validation loss = 5.7958  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 1.5305  Validation loss = 5.7954  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 1.5304  Validation loss = 5.7954  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 1.5303  Validation loss = 5.7950  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 1.5301  Validation loss = 5.7950  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 1.5301  Validation loss = 5.7950  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 1.5299  Validation loss = 5.7947  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 1.5298  Validation loss = 5.7945  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 1.5297  Validation loss = 5.7948  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 1.5295  Validation loss = 5.7942  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 1.5294  Validation loss = 5.7942  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 1.5293  Validation loss = 5.7939  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 1.5292  Validation loss = 5.7935  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 1.5290  Validation loss = 5.7932  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 1.5290  Validation loss = 5.7940  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 1.5289  Validation loss = 5.7941  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 1.5288  Validation loss = 5.7940  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 1.5286  Validation loss = 5.7938  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 1.5285  Validation loss = 5.7941  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 1.5284  Validation loss = 5.7938  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 1.5283  Validation loss = 5.7935  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 1.5282  Validation loss = 5.7936  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 1.5280  Validation loss = 5.7930  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 1.5278  Validation loss = 5.7919  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 1.5276  Validation loss = 5.7915  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 1.5275  Validation loss = 5.7918  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 1.5274  Validation loss = 5.7921  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 1.5272  Validation loss = 5.7918  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 1.5271  Validation loss = 5.7916  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 1.5269  Validation loss = 5.7913  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 1.5268  Validation loss = 5.7909  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 1.5266  Validation loss = 5.7906  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 1.5265  Validation loss = 5.7907  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 1.5264  Validation loss = 5.7905  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 1.5262  Validation loss = 5.7897  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 1.5261  Validation loss = 5.7891  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 1.5259  Validation loss = 5.7888  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 1.5258  Validation loss = 5.7882  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 1.5257  Validation loss = 5.7880  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 1.5256  Validation loss = 5.7878  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 1.5255  Validation loss = 5.7879  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 1.5254  Validation loss = 5.7883  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 1.5253  Validation loss = 5.7880  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 1.5252  Validation loss = 5.7880  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 1.5250  Validation loss = 5.7871  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 1.5249  Validation loss = 5.7866  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 1.5248  Validation loss = 5.7868  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 1.5246  Validation loss = 5.7862  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 1.5246  Validation loss = 5.7863  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 1.5245  Validation loss = 5.7863  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 1.5243  Validation loss = 5.7857  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 1.5242  Validation loss = 5.7855  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 1.5241  Validation loss = 5.7852  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 1.5239  Validation loss = 5.7849  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 1.5238  Validation loss = 5.7847  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 1.5236  Validation loss = 5.7840  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 1.5234  Validation loss = 5.7833  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 1.5233  Validation loss = 5.7827  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 1.5232  Validation loss = 5.7827  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 1.5230  Validation loss = 5.7822  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 1.5228  Validation loss = 5.7816  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 1.5227  Validation loss = 5.7813  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 1.5226  Validation loss = 5.7809  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 1.5224  Validation loss = 5.7803  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 1.5223  Validation loss = 5.7803  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 1.5222  Validation loss = 5.7805  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 1.5221  Validation loss = 5.7801  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 1.5221  Validation loss = 5.7802  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 1.5219  Validation loss = 5.7797  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 1.5218  Validation loss = 5.7791  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 1.5217  Validation loss = 5.7791  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 1.5215  Validation loss = 5.7787  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 1.5213  Validation loss = 5.7779  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 1.5212  Validation loss = 5.7775  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 1.5210  Validation loss = 5.7767  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 1.5209  Validation loss = 5.7768  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 1.5208  Validation loss = 5.7766  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 1.5208  Validation loss = 5.7765  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 1.5206  Validation loss = 5.7766  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 1.5206  Validation loss = 5.7771  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 1.5204  Validation loss = 5.7766  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 1.5202  Validation loss = 5.7767  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 1.5200  Validation loss = 5.7759  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 1.5200  Validation loss = 5.7760  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 1.5198  Validation loss = 5.7757  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 1.5197  Validation loss = 5.7751  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 1.5196  Validation loss = 5.7753  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 1.5195  Validation loss = 5.7745  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 1.5193  Validation loss = 5.7740  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 1.5192  Validation loss = 5.7740  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 1.5191  Validation loss = 5.7740  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 1.5190  Validation loss = 5.7735  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 1.5188  Validation loss = 5.7727  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 1.5187  Validation loss = 5.7724  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 1.5186  Validation loss = 5.7718  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 1.5184  Validation loss = 5.7717  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 1.5183  Validation loss = 5.7714  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 1.5182  Validation loss = 5.7712  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 1.5180  Validation loss = 5.7704  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 1.5178  Validation loss = 5.7701  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 1.5177  Validation loss = 5.7700  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 1.5176  Validation loss = 5.7696  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 1.5175  Validation loss = 5.7695  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 1.5174  Validation loss = 5.7693  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 1.5172  Validation loss = 5.7691  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 1.5172  Validation loss = 5.7692  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 1.5171  Validation loss = 5.7694  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 1.5169  Validation loss = 5.7690  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 1.5168  Validation loss = 5.7680  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 1.5166  Validation loss = 5.7677  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 1.5164  Validation loss = 5.7670  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 1.5164  Validation loss = 5.7669  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 1.5162  Validation loss = 5.7669  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 1.5161  Validation loss = 5.7660  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 1.5159  Validation loss = 5.7657  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 1.5158  Validation loss = 5.7654  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 1.5156  Validation loss = 5.7657  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 1.5155  Validation loss = 5.7652  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 1.5154  Validation loss = 5.7652  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 1.5153  Validation loss = 5.7649  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 1.5152  Validation loss = 5.7647  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 1.5151  Validation loss = 5.7646  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 1.5150  Validation loss = 5.7645  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 1.5149  Validation loss = 5.7649  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 1.5148  Validation loss = 5.7650  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 1.5147  Validation loss = 5.7654  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 1.5146  Validation loss = 5.7653  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 1.5145  Validation loss = 5.7659  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 1.5143  Validation loss = 5.7653  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 1.5142  Validation loss = 5.7647  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 1.5140  Validation loss = 5.7642  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 1.5139  Validation loss = 5.7640  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 1.5138  Validation loss = 5.7640  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 1.5137  Validation loss = 5.7642  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 1.5135  Validation loss = 5.7638  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 1.5134  Validation loss = 5.7635  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 1.5133  Validation loss = 5.7635  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 1.5132  Validation loss = 5.7632  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 1.5130  Validation loss = 5.7632  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 1.5130  Validation loss = 5.7639  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 1.5129  Validation loss = 5.7631  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 1.5127  Validation loss = 5.7625  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 1.5126  Validation loss = 5.7624  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 1.5124  Validation loss = 5.7621  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 1.5123  Validation loss = 5.7616  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 1.5122  Validation loss = 5.7618  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 1.5121  Validation loss = 5.7618  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 1.5120  Validation loss = 5.7614  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 1.5118  Validation loss = 5.7610  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 1.5117  Validation loss = 5.7608  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 1.5115  Validation loss = 5.7603  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 1.5114  Validation loss = 5.7599  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 1.5113  Validation loss = 5.7596  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 1.5111  Validation loss = 5.7593  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 1.5110  Validation loss = 5.7588  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 1.5109  Validation loss = 5.7587  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 1.5107  Validation loss = 5.7576  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 1.5105  Validation loss = 5.7568  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 1.5105  Validation loss = 5.7571  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 1.5104  Validation loss = 5.7571  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 1.5103  Validation loss = 5.7568  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 1.5102  Validation loss = 5.7573  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 1.5101  Validation loss = 5.7572  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 1.5100  Validation loss = 5.7572  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 1.5098  Validation loss = 5.7569  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 1.5097  Validation loss = 5.7566  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 1.5095  Validation loss = 5.7558  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 1.5094  Validation loss = 5.7557  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 1.5093  Validation loss = 5.7559  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 1.5092  Validation loss = 5.7561  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 1.5091  Validation loss = 5.7559  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 1.5090  Validation loss = 5.7553  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 1.5089  Validation loss = 5.7551  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 1.5088  Validation loss = 5.7550  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 1.5087  Validation loss = 5.7551  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 1.5085  Validation loss = 5.7549  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 1.5084  Validation loss = 5.7549  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 1.5083  Validation loss = 5.7550  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 1.5082  Validation loss = 5.7550  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 1.5081  Validation loss = 5.7547  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 1.5080  Validation loss = 5.7547  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 1.5079  Validation loss = 5.7550  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 1.5077  Validation loss = 5.7550  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 1.5076  Validation loss = 5.7546  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 1.5075  Validation loss = 5.7542  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 1.5074  Validation loss = 5.7542  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 1.5072  Validation loss = 5.7544  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 1.5071  Validation loss = 5.7543  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 1.5070  Validation loss = 5.7541  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 1.5069  Validation loss = 5.7538  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 1.5068  Validation loss = 5.7538  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 1.5067  Validation loss = 5.7537  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 1.5066  Validation loss = 5.7538  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 1.5064  Validation loss = 5.7533  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 1.5063  Validation loss = 5.7531  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 1.5062  Validation loss = 5.7528  \n",
      "\n",
      "Fold: 8  Epoch: 501  Training loss = 1.5061  Validation loss = 5.7523  \n",
      "\n",
      "Fold: 8  Epoch: 502  Training loss = 1.5060  Validation loss = 5.7524  \n",
      "\n",
      "Fold: 8  Epoch: 503  Training loss = 1.5058  Validation loss = 5.7518  \n",
      "\n",
      "Fold: 8  Epoch: 504  Training loss = 1.5058  Validation loss = 5.7518  \n",
      "\n",
      "Fold: 8  Epoch: 505  Training loss = 1.5057  Validation loss = 5.7513  \n",
      "\n",
      "Fold: 8  Epoch: 506  Training loss = 1.5055  Validation loss = 5.7508  \n",
      "\n",
      "Fold: 8  Epoch: 507  Training loss = 1.5054  Validation loss = 5.7508  \n",
      "\n",
      "Fold: 8  Epoch: 508  Training loss = 1.5053  Validation loss = 5.7507  \n",
      "\n",
      "Fold: 8  Epoch: 509  Training loss = 1.5052  Validation loss = 5.7504  \n",
      "\n",
      "Fold: 8  Epoch: 510  Training loss = 1.5051  Validation loss = 5.7501  \n",
      "\n",
      "Fold: 8  Epoch: 511  Training loss = 1.5050  Validation loss = 5.7497  \n",
      "\n",
      "Fold: 8  Epoch: 512  Training loss = 1.5048  Validation loss = 5.7498  \n",
      "\n",
      "Fold: 8  Epoch: 513  Training loss = 1.5048  Validation loss = 5.7497  \n",
      "\n",
      "Fold: 8  Epoch: 514  Training loss = 1.5047  Validation loss = 5.7498  \n",
      "\n",
      "Fold: 8  Epoch: 515  Training loss = 1.5045  Validation loss = 5.7499  \n",
      "\n",
      "Fold: 8  Epoch: 516  Training loss = 1.5044  Validation loss = 5.7496  \n",
      "\n",
      "Fold: 8  Epoch: 517  Training loss = 1.5042  Validation loss = 5.7491  \n",
      "\n",
      "Fold: 8  Epoch: 518  Training loss = 1.5041  Validation loss = 5.7486  \n",
      "\n",
      "Fold: 8  Epoch: 519  Training loss = 1.5040  Validation loss = 5.7485  \n",
      "\n",
      "Fold: 8  Epoch: 520  Training loss = 1.5039  Validation loss = 5.7487  \n",
      "\n",
      "Fold: 8  Epoch: 521  Training loss = 1.5037  Validation loss = 5.7482  \n",
      "\n",
      "Fold: 8  Epoch: 522  Training loss = 1.5036  Validation loss = 5.7479  \n",
      "\n",
      "Fold: 8  Epoch: 523  Training loss = 1.5035  Validation loss = 5.7474  \n",
      "\n",
      "Fold: 8  Epoch: 524  Training loss = 1.5034  Validation loss = 5.7477  \n",
      "\n",
      "Fold: 8  Epoch: 525  Training loss = 1.5033  Validation loss = 5.7477  \n",
      "\n",
      "Fold: 8  Epoch: 526  Training loss = 1.5031  Validation loss = 5.7476  \n",
      "\n",
      "Fold: 8  Epoch: 527  Training loss = 1.5029  Validation loss = 5.7469  \n",
      "\n",
      "Fold: 8  Epoch: 528  Training loss = 1.5027  Validation loss = 5.7462  \n",
      "\n",
      "Fold: 8  Epoch: 529  Training loss = 1.5026  Validation loss = 5.7461  \n",
      "\n",
      "Fold: 8  Epoch: 530  Training loss = 1.5025  Validation loss = 5.7456  \n",
      "\n",
      "Fold: 8  Epoch: 531  Training loss = 1.5023  Validation loss = 5.7458  \n",
      "\n",
      "Fold: 8  Epoch: 532  Training loss = 1.5022  Validation loss = 5.7456  \n",
      "\n",
      "Fold: 8  Epoch: 533  Training loss = 1.5021  Validation loss = 5.7448  \n",
      "\n",
      "Fold: 8  Epoch: 534  Training loss = 1.5019  Validation loss = 5.7446  \n",
      "\n",
      "Fold: 8  Epoch: 535  Training loss = 1.5018  Validation loss = 5.7445  \n",
      "\n",
      "Fold: 8  Epoch: 536  Training loss = 1.5016  Validation loss = 5.7439  \n",
      "\n",
      "Fold: 8  Epoch: 537  Training loss = 1.5015  Validation loss = 5.7433  \n",
      "\n",
      "Fold: 8  Epoch: 538  Training loss = 1.5014  Validation loss = 5.7431  \n",
      "\n",
      "Fold: 8  Epoch: 539  Training loss = 1.5013  Validation loss = 5.7428  \n",
      "\n",
      "Fold: 8  Epoch: 540  Training loss = 1.5011  Validation loss = 5.7425  \n",
      "\n",
      "Fold: 8  Epoch: 541  Training loss = 1.5010  Validation loss = 5.7425  \n",
      "\n",
      "Fold: 8  Epoch: 542  Training loss = 1.5009  Validation loss = 5.7424  \n",
      "\n",
      "Fold: 8  Epoch: 543  Training loss = 1.5007  Validation loss = 5.7422  \n",
      "\n",
      "Fold: 8  Epoch: 544  Training loss = 1.5006  Validation loss = 5.7419  \n",
      "\n",
      "Fold: 8  Epoch: 545  Training loss = 1.5005  Validation loss = 5.7419  \n",
      "\n",
      "Fold: 8  Epoch: 546  Training loss = 1.5004  Validation loss = 5.7417  \n",
      "\n",
      "Fold: 8  Epoch: 547  Training loss = 1.5002  Validation loss = 5.7414  \n",
      "\n",
      "Fold: 8  Epoch: 548  Training loss = 1.5001  Validation loss = 5.7407  \n",
      "\n",
      "Fold: 8  Epoch: 549  Training loss = 1.4999  Validation loss = 5.7401  \n",
      "\n",
      "Fold: 8  Epoch: 550  Training loss = 1.4998  Validation loss = 5.7398  \n",
      "\n",
      "Fold: 8  Epoch: 551  Training loss = 1.4997  Validation loss = 5.7396  \n",
      "\n",
      "Fold: 8  Epoch: 552  Training loss = 1.4996  Validation loss = 5.7392  \n",
      "\n",
      "Fold: 8  Epoch: 553  Training loss = 1.4994  Validation loss = 5.7387  \n",
      "\n",
      "Fold: 8  Epoch: 554  Training loss = 1.4993  Validation loss = 5.7384  \n",
      "\n",
      "Fold: 8  Epoch: 555  Training loss = 1.4992  Validation loss = 5.7377  \n",
      "\n",
      "Fold: 8  Epoch: 556  Training loss = 1.4990  Validation loss = 5.7375  \n",
      "\n",
      "Fold: 8  Epoch: 557  Training loss = 1.4989  Validation loss = 5.7376  \n",
      "\n",
      "Fold: 8  Epoch: 558  Training loss = 1.4988  Validation loss = 5.7374  \n",
      "\n",
      "Fold: 8  Epoch: 559  Training loss = 1.4988  Validation loss = 5.7380  \n",
      "\n",
      "Fold: 8  Epoch: 560  Training loss = 1.4986  Validation loss = 5.7376  \n",
      "\n",
      "Fold: 8  Epoch: 561  Training loss = 1.4985  Validation loss = 5.7372  \n",
      "\n",
      "Fold: 8  Epoch: 562  Training loss = 1.4984  Validation loss = 5.7376  \n",
      "\n",
      "Fold: 8  Epoch: 563  Training loss = 1.4982  Validation loss = 5.7372  \n",
      "\n",
      "Fold: 8  Epoch: 564  Training loss = 1.4980  Validation loss = 5.7365  \n",
      "\n",
      "Fold: 8  Epoch: 565  Training loss = 1.4979  Validation loss = 5.7362  \n",
      "\n",
      "Fold: 8  Epoch: 566  Training loss = 1.4977  Validation loss = 5.7357  \n",
      "\n",
      "Fold: 8  Epoch: 567  Training loss = 1.4977  Validation loss = 5.7362  \n",
      "\n",
      "Fold: 8  Epoch: 568  Training loss = 1.4976  Validation loss = 5.7366  \n",
      "\n",
      "Fold: 8  Epoch: 569  Training loss = 1.4975  Validation loss = 5.7366  \n",
      "\n",
      "Fold: 8  Epoch: 570  Training loss = 1.4973  Validation loss = 5.7367  \n",
      "\n",
      "Fold: 8  Epoch: 571  Training loss = 1.4972  Validation loss = 5.7366  \n",
      "\n",
      "Fold: 8  Epoch: 572  Training loss = 1.4971  Validation loss = 5.7360  \n",
      "\n",
      "Fold: 8  Epoch: 573  Training loss = 1.4970  Validation loss = 5.7353  \n",
      "\n",
      "Fold: 8  Epoch: 574  Training loss = 1.4968  Validation loss = 5.7346  \n",
      "\n",
      "Fold: 8  Epoch: 575  Training loss = 1.4967  Validation loss = 5.7341  \n",
      "\n",
      "Fold: 8  Epoch: 576  Training loss = 1.4966  Validation loss = 5.7338  \n",
      "\n",
      "Fold: 8  Epoch: 577  Training loss = 1.4964  Validation loss = 5.7333  \n",
      "\n",
      "Fold: 8  Epoch: 578  Training loss = 1.4963  Validation loss = 5.7323  \n",
      "\n",
      "Fold: 8  Epoch: 579  Training loss = 1.4961  Validation loss = 5.7320  \n",
      "\n",
      "Fold: 8  Epoch: 580  Training loss = 1.4960  Validation loss = 5.7312  \n",
      "\n",
      "Fold: 8  Epoch: 581  Training loss = 1.4959  Validation loss = 5.7317  \n",
      "\n",
      "Fold: 8  Epoch: 582  Training loss = 1.4957  Validation loss = 5.7312  \n",
      "\n",
      "Fold: 8  Epoch: 583  Training loss = 1.4956  Validation loss = 5.7315  \n",
      "\n",
      "Fold: 8  Epoch: 584  Training loss = 1.4955  Validation loss = 5.7318  \n",
      "\n",
      "Fold: 8  Epoch: 585  Training loss = 1.4954  Validation loss = 5.7317  \n",
      "\n",
      "Fold: 8  Epoch: 586  Training loss = 1.4953  Validation loss = 5.7312  \n",
      "\n",
      "Fold: 8  Epoch: 587  Training loss = 1.4952  Validation loss = 5.7307  \n",
      "\n",
      "Fold: 8  Epoch: 588  Training loss = 1.4950  Validation loss = 5.7302  \n",
      "\n",
      "Fold: 8  Epoch: 589  Training loss = 1.4950  Validation loss = 5.7307  \n",
      "\n",
      "Fold: 8  Epoch: 590  Training loss = 1.4948  Validation loss = 5.7304  \n",
      "\n",
      "Fold: 8  Epoch: 591  Training loss = 1.4947  Validation loss = 5.7299  \n",
      "\n",
      "Fold: 8  Epoch: 592  Training loss = 1.4946  Validation loss = 5.7296  \n",
      "\n",
      "Fold: 8  Epoch: 593  Training loss = 1.4945  Validation loss = 5.7299  \n",
      "\n",
      "Fold: 8  Epoch: 594  Training loss = 1.4944  Validation loss = 5.7302  \n",
      "\n",
      "Fold: 8  Epoch: 595  Training loss = 1.4943  Validation loss = 5.7299  \n",
      "\n",
      "Fold: 8  Epoch: 596  Training loss = 1.4942  Validation loss = 5.7298  \n",
      "\n",
      "Fold: 8  Epoch: 597  Training loss = 1.4941  Validation loss = 5.7295  \n",
      "\n",
      "Fold: 8  Epoch: 598  Training loss = 1.4940  Validation loss = 5.7290  \n",
      "\n",
      "Fold: 8  Epoch: 599  Training loss = 1.4939  Validation loss = 5.7290  \n",
      "\n",
      "Fold: 8  Epoch: 600  Training loss = 1.4938  Validation loss = 5.7297  \n",
      "\n",
      "Fold: 8  Epoch: 601  Training loss = 1.4937  Validation loss = 5.7295  \n",
      "\n",
      "Fold: 8  Epoch: 602  Training loss = 1.4935  Validation loss = 5.7287  \n",
      "\n",
      "Fold: 8  Epoch: 603  Training loss = 1.4934  Validation loss = 5.7289  \n",
      "\n",
      "Fold: 8  Epoch: 604  Training loss = 1.4934  Validation loss = 5.7294  \n",
      "\n",
      "Fold: 8  Epoch: 605  Training loss = 1.4933  Validation loss = 5.7293  \n",
      "\n",
      "Fold: 8  Epoch: 606  Training loss = 1.4931  Validation loss = 5.7290  \n",
      "\n",
      "Fold: 8  Epoch: 607  Training loss = 1.4930  Validation loss = 5.7285  \n",
      "\n",
      "Fold: 8  Epoch: 608  Training loss = 1.4929  Validation loss = 5.7286  \n",
      "\n",
      "Fold: 8  Epoch: 609  Training loss = 1.4928  Validation loss = 5.7283  \n",
      "\n",
      "Fold: 8  Epoch: 610  Training loss = 1.4927  Validation loss = 5.7279  \n",
      "\n",
      "Fold: 8  Epoch: 611  Training loss = 1.4925  Validation loss = 5.7272  \n",
      "\n",
      "Fold: 8  Epoch: 612  Training loss = 1.4924  Validation loss = 5.7267  \n",
      "\n",
      "Fold: 8  Epoch: 613  Training loss = 1.4923  Validation loss = 5.7260  \n",
      "\n",
      "Fold: 8  Epoch: 614  Training loss = 1.4921  Validation loss = 5.7251  \n",
      "\n",
      "Fold: 8  Epoch: 615  Training loss = 1.4920  Validation loss = 5.7251  \n",
      "\n",
      "Fold: 8  Epoch: 616  Training loss = 1.4919  Validation loss = 5.7246  \n",
      "\n",
      "Fold: 8  Epoch: 617  Training loss = 1.4917  Validation loss = 5.7243  \n",
      "\n",
      "Fold: 8  Epoch: 618  Training loss = 1.4916  Validation loss = 5.7240  \n",
      "\n",
      "Fold: 8  Epoch: 619  Training loss = 1.4915  Validation loss = 5.7244  \n",
      "\n",
      "Fold: 8  Epoch: 620  Training loss = 1.4913  Validation loss = 5.7239  \n",
      "\n",
      "Fold: 8  Epoch: 621  Training loss = 1.4911  Validation loss = 5.7227  \n",
      "\n",
      "Fold: 8  Epoch: 622  Training loss = 1.4910  Validation loss = 5.7224  \n",
      "\n",
      "Fold: 8  Epoch: 623  Training loss = 1.4909  Validation loss = 5.7223  \n",
      "\n",
      "Fold: 8  Epoch: 624  Training loss = 1.4907  Validation loss = 5.7213  \n",
      "\n",
      "Fold: 8  Epoch: 625  Training loss = 1.4905  Validation loss = 5.7202  \n",
      "\n",
      "Fold: 8  Epoch: 626  Training loss = 1.4903  Validation loss = 5.7193  \n",
      "\n",
      "Fold: 8  Epoch: 627  Training loss = 1.4902  Validation loss = 5.7190  \n",
      "\n",
      "Fold: 8  Epoch: 628  Training loss = 1.4901  Validation loss = 5.7182  \n",
      "\n",
      "Fold: 8  Epoch: 629  Training loss = 1.4899  Validation loss = 5.7180  \n",
      "\n",
      "Fold: 8  Epoch: 630  Training loss = 1.4897  Validation loss = 5.7180  \n",
      "\n",
      "Fold: 8  Epoch: 631  Training loss = 1.4896  Validation loss = 5.7181  \n",
      "\n",
      "Fold: 8  Epoch: 632  Training loss = 1.4895  Validation loss = 5.7181  \n",
      "\n",
      "Fold: 8  Epoch: 633  Training loss = 1.4894  Validation loss = 5.7178  \n",
      "\n",
      "Fold: 8  Epoch: 634  Training loss = 1.4893  Validation loss = 5.7169  \n",
      "\n",
      "Fold: 8  Epoch: 635  Training loss = 1.4892  Validation loss = 5.7170  \n",
      "\n",
      "Fold: 8  Epoch: 636  Training loss = 1.4890  Validation loss = 5.7166  \n",
      "\n",
      "Fold: 8  Epoch: 637  Training loss = 1.4889  Validation loss = 5.7163  \n",
      "\n",
      "Fold: 8  Epoch: 638  Training loss = 1.4888  Validation loss = 5.7163  \n",
      "\n",
      "Fold: 8  Epoch: 639  Training loss = 1.4886  Validation loss = 5.7158  \n",
      "\n",
      "Fold: 8  Epoch: 640  Training loss = 1.4885  Validation loss = 5.7157  \n",
      "\n",
      "Fold: 8  Epoch: 641  Training loss = 1.4883  Validation loss = 5.7147  \n",
      "\n",
      "Fold: 8  Epoch: 642  Training loss = 1.4882  Validation loss = 5.7145  \n",
      "\n",
      "Fold: 8  Epoch: 643  Training loss = 1.4881  Validation loss = 5.7139  \n",
      "\n",
      "Fold: 8  Epoch: 644  Training loss = 1.4879  Validation loss = 5.7135  \n",
      "\n",
      "Fold: 8  Epoch: 645  Training loss = 1.4878  Validation loss = 5.7136  \n",
      "\n",
      "Fold: 8  Epoch: 646  Training loss = 1.4877  Validation loss = 5.7134  \n",
      "\n",
      "Fold: 8  Epoch: 647  Training loss = 1.4876  Validation loss = 5.7132  \n",
      "\n",
      "Fold: 8  Epoch: 648  Training loss = 1.4874  Validation loss = 5.7134  \n",
      "\n",
      "Fold: 8  Epoch: 649  Training loss = 1.4873  Validation loss = 5.7133  \n",
      "\n",
      "Fold: 8  Epoch: 650  Training loss = 1.4872  Validation loss = 5.7133  \n",
      "\n",
      "Fold: 8  Epoch: 651  Training loss = 1.4871  Validation loss = 5.7132  \n",
      "\n",
      "Fold: 8  Epoch: 652  Training loss = 1.4870  Validation loss = 5.7133  \n",
      "\n",
      "Fold: 8  Epoch: 653  Training loss = 1.4870  Validation loss = 5.7131  \n",
      "\n",
      "Fold: 8  Epoch: 654  Training loss = 1.4868  Validation loss = 5.7130  \n",
      "\n",
      "Fold: 8  Epoch: 655  Training loss = 1.4867  Validation loss = 5.7129  \n",
      "\n",
      "Fold: 8  Epoch: 656  Training loss = 1.4865  Validation loss = 5.7121  \n",
      "\n",
      "Fold: 8  Epoch: 657  Training loss = 1.4864  Validation loss = 5.7119  \n",
      "\n",
      "Fold: 8  Epoch: 658  Training loss = 1.4863  Validation loss = 5.7113  \n",
      "\n",
      "Fold: 8  Epoch: 659  Training loss = 1.4862  Validation loss = 5.7110  \n",
      "\n",
      "Fold: 8  Epoch: 660  Training loss = 1.4860  Validation loss = 5.7107  \n",
      "\n",
      "Fold: 8  Epoch: 661  Training loss = 1.4859  Validation loss = 5.7106  \n",
      "\n",
      "Fold: 8  Epoch: 662  Training loss = 1.4857  Validation loss = 5.7096  \n",
      "\n",
      "Fold: 8  Epoch: 663  Training loss = 1.4856  Validation loss = 5.7091  \n",
      "\n",
      "Fold: 8  Epoch: 664  Training loss = 1.4855  Validation loss = 5.7081  \n",
      "\n",
      "Fold: 8  Epoch: 665  Training loss = 1.4854  Validation loss = 5.7080  \n",
      "\n",
      "Fold: 8  Epoch: 666  Training loss = 1.4852  Validation loss = 5.7079  \n",
      "\n",
      "Fold: 8  Epoch: 667  Training loss = 1.4852  Validation loss = 5.7085  \n",
      "\n",
      "Fold: 8  Epoch: 668  Training loss = 1.4851  Validation loss = 5.7086  \n",
      "\n",
      "Fold: 8  Epoch: 669  Training loss = 1.4849  Validation loss = 5.7084  \n",
      "\n",
      "Fold: 8  Epoch: 670  Training loss = 1.4848  Validation loss = 5.7084  \n",
      "\n",
      "Fold: 8  Epoch: 671  Training loss = 1.4847  Validation loss = 5.7080  \n",
      "\n",
      "Fold: 8  Epoch: 672  Training loss = 1.4845  Validation loss = 5.7078  \n",
      "\n",
      "Fold: 8  Epoch: 673  Training loss = 1.4844  Validation loss = 5.7076  \n",
      "\n",
      "Fold: 8  Epoch: 674  Training loss = 1.4843  Validation loss = 5.7076  \n",
      "\n",
      "Fold: 8  Epoch: 675  Training loss = 1.4842  Validation loss = 5.7079  \n",
      "\n",
      "Fold: 8  Epoch: 676  Training loss = 1.4841  Validation loss = 5.7081  \n",
      "\n",
      "Fold: 8  Epoch: 677  Training loss = 1.4839  Validation loss = 5.7076  \n",
      "\n",
      "Fold: 8  Epoch: 678  Training loss = 1.4838  Validation loss = 5.7077  \n",
      "\n",
      "Fold: 8  Epoch: 679  Training loss = 1.4837  Validation loss = 5.7077  \n",
      "\n",
      "Fold: 8  Epoch: 680  Training loss = 1.4836  Validation loss = 5.7075  \n",
      "\n",
      "Fold: 8  Epoch: 681  Training loss = 1.4835  Validation loss = 5.7074  \n",
      "\n",
      "Fold: 8  Epoch: 682  Training loss = 1.4833  Validation loss = 5.7074  \n",
      "\n",
      "Fold: 8  Epoch: 683  Training loss = 1.4832  Validation loss = 5.7072  \n",
      "\n",
      "Fold: 8  Epoch: 684  Training loss = 1.4831  Validation loss = 5.7064  \n",
      "\n",
      "Fold: 8  Epoch: 685  Training loss = 1.4829  Validation loss = 5.7056  \n",
      "\n",
      "Fold: 8  Epoch: 686  Training loss = 1.4829  Validation loss = 5.7056  \n",
      "\n",
      "Fold: 8  Epoch: 687  Training loss = 1.4828  Validation loss = 5.7056  \n",
      "\n",
      "Fold: 8  Epoch: 688  Training loss = 1.4827  Validation loss = 5.7057  \n",
      "\n",
      "Fold: 8  Epoch: 689  Training loss = 1.4826  Validation loss = 5.7061  \n",
      "\n",
      "Fold: 8  Epoch: 690  Training loss = 1.4825  Validation loss = 5.7060  \n",
      "\n",
      "Fold: 8  Epoch: 691  Training loss = 1.4824  Validation loss = 5.7063  \n",
      "\n",
      "Fold: 8  Epoch: 692  Training loss = 1.4824  Validation loss = 5.7070  \n",
      "\n",
      "Fold: 8  Epoch: 693  Training loss = 1.4823  Validation loss = 5.7068  \n",
      "\n",
      "Fold: 8  Epoch: 694  Training loss = 1.4822  Validation loss = 5.7065  \n",
      "\n",
      "Fold: 8  Epoch: 695  Training loss = 1.4821  Validation loss = 5.7067  \n",
      "\n",
      "Fold: 8  Epoch: 696  Training loss = 1.4819  Validation loss = 5.7061  \n",
      "\n",
      "Fold: 8  Epoch: 697  Training loss = 1.4818  Validation loss = 5.7061  \n",
      "\n",
      "Fold: 8  Epoch: 698  Training loss = 1.4816  Validation loss = 5.7051  \n",
      "\n",
      "Fold: 8  Epoch: 699  Training loss = 1.4815  Validation loss = 5.7047  \n",
      "\n",
      "Fold: 8  Epoch: 700  Training loss = 1.4814  Validation loss = 5.7046  \n",
      "\n",
      "Fold: 8  Epoch: 701  Training loss = 1.4813  Validation loss = 5.7042  \n",
      "\n",
      "Fold: 8  Epoch: 702  Training loss = 1.4812  Validation loss = 5.7038  \n",
      "\n",
      "Fold: 8  Epoch: 703  Training loss = 1.4810  Validation loss = 5.7035  \n",
      "\n",
      "Fold: 8  Epoch: 704  Training loss = 1.4809  Validation loss = 5.7033  \n",
      "\n",
      "Fold: 8  Epoch: 705  Training loss = 1.4808  Validation loss = 5.7032  \n",
      "\n",
      "Fold: 8  Epoch: 706  Training loss = 1.4807  Validation loss = 5.7029  \n",
      "\n",
      "Fold: 8  Epoch: 707  Training loss = 1.4806  Validation loss = 5.7027  \n",
      "\n",
      "Fold: 8  Epoch: 708  Training loss = 1.4804  Validation loss = 5.7021  \n",
      "\n",
      "Fold: 8  Epoch: 709  Training loss = 1.4804  Validation loss = 5.7016  \n",
      "\n",
      "Fold: 8  Epoch: 710  Training loss = 1.4802  Validation loss = 5.7014  \n",
      "\n",
      "Fold: 8  Epoch: 711  Training loss = 1.4801  Validation loss = 5.7014  \n",
      "\n",
      "Fold: 8  Epoch: 712  Training loss = 1.4799  Validation loss = 5.7015  \n",
      "\n",
      "Fold: 8  Epoch: 713  Training loss = 1.4798  Validation loss = 5.7020  \n",
      "\n",
      "Fold: 8  Epoch: 714  Training loss = 1.4797  Validation loss = 5.7020  \n",
      "\n",
      "Fold: 8  Epoch: 715  Training loss = 1.4796  Validation loss = 5.7014  \n",
      "\n",
      "Fold: 8  Epoch: 716  Training loss = 1.4794  Validation loss = 5.7010  \n",
      "\n",
      "Fold: 8  Epoch: 717  Training loss = 1.4793  Validation loss = 5.7006  \n",
      "\n",
      "Fold: 8  Epoch: 718  Training loss = 1.4791  Validation loss = 5.7005  \n",
      "\n",
      "Fold: 8  Epoch: 719  Training loss = 1.4790  Validation loss = 5.6998  \n",
      "\n",
      "Fold: 8  Epoch: 720  Training loss = 1.4789  Validation loss = 5.6993  \n",
      "\n",
      "Fold: 8  Epoch: 721  Training loss = 1.4788  Validation loss = 5.6989  \n",
      "\n",
      "Fold: 8  Epoch: 722  Training loss = 1.4786  Validation loss = 5.6984  \n",
      "\n",
      "Fold: 8  Epoch: 723  Training loss = 1.4785  Validation loss = 5.6982  \n",
      "\n",
      "Fold: 8  Epoch: 724  Training loss = 1.4784  Validation loss = 5.6977  \n",
      "\n",
      "Fold: 8  Epoch: 725  Training loss = 1.4782  Validation loss = 5.6972  \n",
      "\n",
      "Fold: 8  Epoch: 726  Training loss = 1.4781  Validation loss = 5.6967  \n",
      "\n",
      "Fold: 8  Epoch: 727  Training loss = 1.4780  Validation loss = 5.6971  \n",
      "\n",
      "Fold: 8  Epoch: 728  Training loss = 1.4779  Validation loss = 5.6970  \n",
      "\n",
      "Fold: 8  Epoch: 729  Training loss = 1.4778  Validation loss = 5.6971  \n",
      "\n",
      "Fold: 8  Epoch: 730  Training loss = 1.4777  Validation loss = 5.6969  \n",
      "\n",
      "Fold: 8  Epoch: 731  Training loss = 1.4775  Validation loss = 5.6966  \n",
      "\n",
      "Fold: 8  Epoch: 732  Training loss = 1.4774  Validation loss = 5.6959  \n",
      "\n",
      "Fold: 8  Epoch: 733  Training loss = 1.4773  Validation loss = 5.6958  \n",
      "\n",
      "Fold: 8  Epoch: 734  Training loss = 1.4772  Validation loss = 5.6955  \n",
      "\n",
      "Fold: 8  Epoch: 735  Training loss = 1.4771  Validation loss = 5.6947  \n",
      "\n",
      "Fold: 8  Epoch: 736  Training loss = 1.4769  Validation loss = 5.6946  \n",
      "\n",
      "Fold: 8  Epoch: 737  Training loss = 1.4768  Validation loss = 5.6946  \n",
      "\n",
      "Fold: 8  Epoch: 738  Training loss = 1.4766  Validation loss = 5.6936  \n",
      "\n",
      "Fold: 8  Epoch: 739  Training loss = 1.4765  Validation loss = 5.6936  \n",
      "\n",
      "Fold: 8  Epoch: 740  Training loss = 1.4764  Validation loss = 5.6937  \n",
      "\n",
      "Fold: 8  Epoch: 741  Training loss = 1.4763  Validation loss = 5.6936  \n",
      "\n",
      "Fold: 8  Epoch: 742  Training loss = 1.4761  Validation loss = 5.6936  \n",
      "\n",
      "Fold: 8  Epoch: 743  Training loss = 1.4760  Validation loss = 5.6940  \n",
      "\n",
      "Fold: 8  Epoch: 744  Training loss = 1.4759  Validation loss = 5.6943  \n",
      "\n",
      "Fold: 8  Epoch: 745  Training loss = 1.4758  Validation loss = 5.6938  \n",
      "\n",
      "Fold: 8  Epoch: 746  Training loss = 1.4756  Validation loss = 5.6934  \n",
      "\n",
      "Fold: 8  Epoch: 747  Training loss = 1.4755  Validation loss = 5.6930  \n",
      "\n",
      "Fold: 8  Epoch: 748  Training loss = 1.4754  Validation loss = 5.6925  \n",
      "\n",
      "Fold: 8  Epoch: 749  Training loss = 1.4753  Validation loss = 5.6926  \n",
      "\n",
      "Fold: 8  Epoch: 750  Training loss = 1.4752  Validation loss = 5.6927  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 748  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.0259  Validation loss = 9.0206  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.0256  Validation loss = 9.0198  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.0254  Validation loss = 9.0192  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.0251  Validation loss = 9.0180  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.0248  Validation loss = 9.0170  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.0244  Validation loss = 9.0157  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.0242  Validation loss = 9.0144  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.0240  Validation loss = 9.0139  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.0237  Validation loss = 9.0117  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.0233  Validation loss = 9.0099  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.0231  Validation loss = 9.0085  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.0228  Validation loss = 9.0066  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.0225  Validation loss = 9.0053  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.0222  Validation loss = 9.0039  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.0218  Validation loss = 9.0025  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.0215  Validation loss = 9.0005  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.0213  Validation loss = 8.9999  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.0210  Validation loss = 8.9984  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.0208  Validation loss = 8.9975  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.0206  Validation loss = 8.9969  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.0202  Validation loss = 8.9956  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.0199  Validation loss = 8.9941  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.0194  Validation loss = 8.9918  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.0194  Validation loss = 8.9917  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.0191  Validation loss = 8.9906  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.0190  Validation loss = 8.9900  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.0188  Validation loss = 8.9891  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.0186  Validation loss = 8.9878  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.0183  Validation loss = 8.9863  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.0182  Validation loss = 8.9861  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.0178  Validation loss = 8.9839  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.0176  Validation loss = 8.9828  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.0172  Validation loss = 8.9815  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.0170  Validation loss = 8.9798  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.0168  Validation loss = 8.9789  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.0166  Validation loss = 8.9781  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.0162  Validation loss = 8.9766  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.0160  Validation loss = 8.9758  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.0159  Validation loss = 8.9750  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.0157  Validation loss = 8.9741  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.0154  Validation loss = 8.9724  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.0154  Validation loss = 8.9722  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.0151  Validation loss = 8.9710  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.0149  Validation loss = 8.9706  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.0148  Validation loss = 8.9698  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.0146  Validation loss = 8.9689  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.0144  Validation loss = 8.9678  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.0141  Validation loss = 8.9659  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.0140  Validation loss = 8.9655  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.0136  Validation loss = 8.9638  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.0134  Validation loss = 8.9627  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.0132  Validation loss = 8.9617  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.0130  Validation loss = 8.9603  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.0127  Validation loss = 8.9588  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.0126  Validation loss = 8.9578  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.0125  Validation loss = 8.9574  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.0122  Validation loss = 8.9566  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.0119  Validation loss = 8.9547  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.0117  Validation loss = 8.9540  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.0113  Validation loss = 8.9522  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.0111  Validation loss = 8.9516  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.0108  Validation loss = 8.9505  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.0107  Validation loss = 8.9500  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.0106  Validation loss = 8.9495  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.0105  Validation loss = 8.9490  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.0101  Validation loss = 8.9474  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.0099  Validation loss = 8.9462  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.0096  Validation loss = 8.9450  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.0094  Validation loss = 8.9436  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.0090  Validation loss = 8.9415  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.0086  Validation loss = 8.9400  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.0083  Validation loss = 8.9383  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.0081  Validation loss = 8.9372  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.0079  Validation loss = 8.9366  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.0076  Validation loss = 8.9349  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.0074  Validation loss = 8.9343  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.0072  Validation loss = 8.9330  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.0069  Validation loss = 8.9321  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.0067  Validation loss = 8.9309  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.0065  Validation loss = 8.9302  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.0064  Validation loss = 8.9300  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.0062  Validation loss = 8.9290  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.0059  Validation loss = 8.9282  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.0058  Validation loss = 8.9272  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.0056  Validation loss = 8.9265  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.0053  Validation loss = 8.9254  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.0051  Validation loss = 8.9247  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.0050  Validation loss = 8.9241  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.0047  Validation loss = 8.9222  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.0045  Validation loss = 8.9215  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.0042  Validation loss = 8.9200  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.0040  Validation loss = 8.9191  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.0038  Validation loss = 8.9184  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.0037  Validation loss = 8.9180  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.0035  Validation loss = 8.9170  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.0031  Validation loss = 8.9149  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.0029  Validation loss = 8.9137  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.0029  Validation loss = 8.9137  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.0027  Validation loss = 8.9127  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.0025  Validation loss = 8.9119  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.0023  Validation loss = 8.9107  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.0022  Validation loss = 8.9101  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.0021  Validation loss = 8.9100  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.0018  Validation loss = 8.9086  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.0015  Validation loss = 8.9066  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.0013  Validation loss = 8.9058  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.0012  Validation loss = 8.9048  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.0011  Validation loss = 8.9043  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.0010  Validation loss = 8.9038  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.0008  Validation loss = 8.9034  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.0006  Validation loss = 8.9023  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.0005  Validation loss = 8.9015  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.0002  Validation loss = 8.9002  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.0001  Validation loss = 8.8992  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 1.9999  Validation loss = 8.8986  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 1.9997  Validation loss = 8.8977  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 1.9996  Validation loss = 8.8968  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 1.9994  Validation loss = 8.8960  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 1.9990  Validation loss = 8.8945  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 1.9988  Validation loss = 8.8938  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 1.9986  Validation loss = 8.8928  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 1.9986  Validation loss = 8.8927  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 1.9984  Validation loss = 8.8921  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 1.9983  Validation loss = 8.8915  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 1.9981  Validation loss = 8.8907  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 1.9978  Validation loss = 8.8893  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 1.9976  Validation loss = 8.8880  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 1.9972  Validation loss = 8.8864  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 1.9970  Validation loss = 8.8853  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 1.9966  Validation loss = 8.8838  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 1.9963  Validation loss = 8.8822  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 1.9961  Validation loss = 8.8811  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 1.9958  Validation loss = 8.8797  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 1.9957  Validation loss = 8.8789  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 1.9954  Validation loss = 8.8778  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 1.9952  Validation loss = 8.8765  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 1.9950  Validation loss = 8.8753  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 1.9948  Validation loss = 8.8745  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 1.9945  Validation loss = 8.8731  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 1.9943  Validation loss = 8.8721  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 1.9940  Validation loss = 8.8706  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 1.9938  Validation loss = 8.8695  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 1.9935  Validation loss = 8.8685  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 1.9933  Validation loss = 8.8673  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 1.9931  Validation loss = 8.8660  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 1.9928  Validation loss = 8.8647  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 1.9927  Validation loss = 8.8641  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 1.9924  Validation loss = 8.8627  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 1.9921  Validation loss = 8.8608  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 1.9920  Validation loss = 8.8603  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 1.9917  Validation loss = 8.8592  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 1.9915  Validation loss = 8.8582  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 1.9913  Validation loss = 8.8574  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 1.9912  Validation loss = 8.8566  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 1.9909  Validation loss = 8.8554  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 1.9906  Validation loss = 8.8539  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 1.9906  Validation loss = 8.8538  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 1.9905  Validation loss = 8.8534  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 1.9903  Validation loss = 8.8527  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 1.9902  Validation loss = 8.8521  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 1.9900  Validation loss = 8.8513  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 1.9898  Validation loss = 8.8503  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 1.9896  Validation loss = 8.8496  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 1.9894  Validation loss = 8.8491  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 1.9894  Validation loss = 8.8490  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 1.9892  Validation loss = 8.8482  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 1.9891  Validation loss = 8.8476  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 1.9888  Validation loss = 8.8464  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 1.9886  Validation loss = 8.8455  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 1.9883  Validation loss = 8.8441  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 1.9881  Validation loss = 8.8426  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 1.9877  Validation loss = 8.8409  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 1.9875  Validation loss = 8.8399  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 1.9874  Validation loss = 8.8392  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 1.9873  Validation loss = 8.8389  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 1.9871  Validation loss = 8.8382  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 1.9869  Validation loss = 8.8375  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 1.9868  Validation loss = 8.8368  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 1.9865  Validation loss = 8.8356  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 1.9863  Validation loss = 8.8345  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 1.9862  Validation loss = 8.8339  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 1.9860  Validation loss = 8.8328  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 1.9859  Validation loss = 8.8325  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 1.9858  Validation loss = 8.8321  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 1.9855  Validation loss = 8.8303  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 1.9853  Validation loss = 8.8294  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 1.9852  Validation loss = 8.8291  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 1.9850  Validation loss = 8.8284  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 1.9849  Validation loss = 8.8281  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 1.9847  Validation loss = 8.8270  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 1.9845  Validation loss = 8.8259  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 1.9843  Validation loss = 8.8254  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 1.9841  Validation loss = 8.8240  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 1.9839  Validation loss = 8.8232  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 1.9837  Validation loss = 8.8220  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 1.9835  Validation loss = 8.8210  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 1.9833  Validation loss = 8.8203  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 1.9830  Validation loss = 8.8187  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 1.9828  Validation loss = 8.8179  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 1.9826  Validation loss = 8.8171  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 1.9824  Validation loss = 8.8161  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 1.9822  Validation loss = 8.8153  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 1.9820  Validation loss = 8.8140  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 1.9819  Validation loss = 8.8137  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 1.9817  Validation loss = 8.8125  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 1.9816  Validation loss = 8.8122  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 1.9815  Validation loss = 8.8118  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 1.9813  Validation loss = 8.8110  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 1.9812  Validation loss = 8.8108  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 1.9810  Validation loss = 8.8098  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 1.9808  Validation loss = 8.8092  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 1.9807  Validation loss = 8.8082  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 1.9805  Validation loss = 8.8077  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 1.9804  Validation loss = 8.8073  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 1.9802  Validation loss = 8.8066  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 1.9800  Validation loss = 8.8052  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 1.9798  Validation loss = 8.8046  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 1.9797  Validation loss = 8.8041  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 1.9796  Validation loss = 8.8039  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 1.9794  Validation loss = 8.8029  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 1.9792  Validation loss = 8.8018  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 1.9789  Validation loss = 8.8003  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 1.9788  Validation loss = 8.8000  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 1.9787  Validation loss = 8.7997  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 1.9785  Validation loss = 8.7987  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 1.9782  Validation loss = 8.7972  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 1.9781  Validation loss = 8.7969  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 1.9780  Validation loss = 8.7965  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 1.9778  Validation loss = 8.7956  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 1.9778  Validation loss = 8.7954  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 1.9777  Validation loss = 8.7955  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 1.9776  Validation loss = 8.7948  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 1.9774  Validation loss = 8.7940  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 1.9772  Validation loss = 8.7931  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 1.9770  Validation loss = 8.7924  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 1.9768  Validation loss = 8.7916  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 1.9767  Validation loss = 8.7909  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 1.9765  Validation loss = 8.7901  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 1.9763  Validation loss = 8.7894  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 1.9763  Validation loss = 8.7894  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 1.9760  Validation loss = 8.7882  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 1.9759  Validation loss = 8.7878  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 1.9757  Validation loss = 8.7870  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 1.9756  Validation loss = 8.7863  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 1.9754  Validation loss = 8.7851  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 1.9752  Validation loss = 8.7840  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 1.9750  Validation loss = 8.7831  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 1.9748  Validation loss = 8.7821  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 1.9747  Validation loss = 8.7817  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 1.9745  Validation loss = 8.7813  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 1.9743  Validation loss = 8.7803  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 1.9742  Validation loss = 8.7798  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 1.9741  Validation loss = 8.7796  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 1.9739  Validation loss = 8.7784  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 1.9736  Validation loss = 8.7774  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 1.9735  Validation loss = 8.7764  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 1.9732  Validation loss = 8.7748  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 1.9731  Validation loss = 8.7746  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 1.9730  Validation loss = 8.7742  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 1.9728  Validation loss = 8.7736  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 1.9726  Validation loss = 8.7723  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 1.9725  Validation loss = 8.7721  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 1.9722  Validation loss = 8.7704  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 1.9721  Validation loss = 8.7702  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 1.9718  Validation loss = 8.7686  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 1.9716  Validation loss = 8.7676  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 1.9715  Validation loss = 8.7672  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 1.9713  Validation loss = 8.7664  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 1.9712  Validation loss = 8.7655  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 1.9711  Validation loss = 8.7654  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 1.9709  Validation loss = 8.7644  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 1.9706  Validation loss = 8.7633  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 1.9706  Validation loss = 8.7632  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 1.9704  Validation loss = 8.7624  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 1.9700  Validation loss = 8.7606  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 1.9698  Validation loss = 8.7596  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 1.9695  Validation loss = 8.7583  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 1.9693  Validation loss = 8.7573  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 1.9692  Validation loss = 8.7567  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 1.9692  Validation loss = 8.7565  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 1.9690  Validation loss = 8.7559  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 1.9689  Validation loss = 8.7554  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 1.9687  Validation loss = 8.7549  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 1.9686  Validation loss = 8.7543  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 1.9685  Validation loss = 8.7539  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 1.9684  Validation loss = 8.7536  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 1.9680  Validation loss = 8.7518  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 1.9679  Validation loss = 8.7516  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 1.9677  Validation loss = 8.7503  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 1.9676  Validation loss = 8.7498  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 1.9674  Validation loss = 8.7490  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 1.9671  Validation loss = 8.7473  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 1.9669  Validation loss = 8.7464  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 1.9667  Validation loss = 8.7455  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 1.9665  Validation loss = 8.7445  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 1.9663  Validation loss = 8.7434  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 1.9661  Validation loss = 8.7430  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 1.9658  Validation loss = 8.7411  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 1.9656  Validation loss = 8.7401  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 1.9654  Validation loss = 8.7393  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 1.9654  Validation loss = 8.7394  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 1.9652  Validation loss = 8.7383  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 1.9650  Validation loss = 8.7380  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 1.9649  Validation loss = 8.7378  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 1.9649  Validation loss = 8.7378  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 1.9647  Validation loss = 8.7374  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 1.9646  Validation loss = 8.7372  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 1.9645  Validation loss = 8.7365  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 1.9643  Validation loss = 8.7362  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 1.9641  Validation loss = 8.7351  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 1.9640  Validation loss = 8.7346  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 1.9640  Validation loss = 8.7347  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 1.9638  Validation loss = 8.7341  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 1.9637  Validation loss = 8.7336  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 1.9634  Validation loss = 8.7323  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 1.9632  Validation loss = 8.7312  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 1.9630  Validation loss = 8.7305  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 1.9628  Validation loss = 8.7296  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 1.9626  Validation loss = 8.7285  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 1.9624  Validation loss = 8.7272  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 1.9622  Validation loss = 8.7266  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 1.9621  Validation loss = 8.7262  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 1.9619  Validation loss = 8.7255  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 1.9617  Validation loss = 8.7242  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 1.9616  Validation loss = 8.7237  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 1.9614  Validation loss = 8.7231  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 1.9612  Validation loss = 8.7218  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 1.9610  Validation loss = 8.7210  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 1.9608  Validation loss = 8.7202  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 1.9608  Validation loss = 8.7201  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 1.9606  Validation loss = 8.7197  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 1.9605  Validation loss = 8.7193  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 1.9603  Validation loss = 8.7181  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 1.9601  Validation loss = 8.7171  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 1.9599  Validation loss = 8.7161  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 1.9598  Validation loss = 8.7156  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 1.9596  Validation loss = 8.7145  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 1.9594  Validation loss = 8.7139  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 1.9592  Validation loss = 8.7126  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 1.9589  Validation loss = 8.7115  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 1.9587  Validation loss = 8.7108  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 1.9585  Validation loss = 8.7096  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 1.9584  Validation loss = 8.7093  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 1.9582  Validation loss = 8.7082  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 1.9579  Validation loss = 8.7068  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 1.9578  Validation loss = 8.7062  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 1.9576  Validation loss = 8.7056  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 1.9574  Validation loss = 8.7045  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 1.9573  Validation loss = 8.7044  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 1.9571  Validation loss = 8.7031  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 1.9569  Validation loss = 8.7024  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 1.9568  Validation loss = 8.7018  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 1.9566  Validation loss = 8.7011  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 1.9565  Validation loss = 8.7006  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 1.9563  Validation loss = 8.6996  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 1.9562  Validation loss = 8.6991  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 1.9560  Validation loss = 8.6981  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 1.9559  Validation loss = 8.6979  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 1.9558  Validation loss = 8.6976  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 1.9556  Validation loss = 8.6973  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 1.9554  Validation loss = 8.6964  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 1.9552  Validation loss = 8.6955  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 1.9552  Validation loss = 8.6952  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 1.9550  Validation loss = 8.6947  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 1.9549  Validation loss = 8.6943  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 1.9547  Validation loss = 8.6937  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 1.9546  Validation loss = 8.6928  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 1.9544  Validation loss = 8.6920  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 1.9542  Validation loss = 8.6912  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 1.9540  Validation loss = 8.6901  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 1.9538  Validation loss = 8.6889  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 1.9537  Validation loss = 8.6885  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 1.9535  Validation loss = 8.6878  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 1.9534  Validation loss = 8.6877  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 1.9532  Validation loss = 8.6868  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 1.9531  Validation loss = 8.6865  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 1.9529  Validation loss = 8.6856  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 1.9528  Validation loss = 8.6851  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 1.9526  Validation loss = 8.6841  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 1.9524  Validation loss = 8.6832  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 1.9522  Validation loss = 8.6824  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 1.9521  Validation loss = 8.6818  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 1.9520  Validation loss = 8.6813  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 1.9518  Validation loss = 8.6804  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 1.9517  Validation loss = 8.6801  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 1.9514  Validation loss = 8.6784  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 1.9513  Validation loss = 8.6779  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 1.9511  Validation loss = 8.6770  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 1.9509  Validation loss = 8.6764  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 1.9507  Validation loss = 8.6754  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 1.9506  Validation loss = 8.6749  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 1.9504  Validation loss = 8.6742  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 1.9503  Validation loss = 8.6739  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 1.9502  Validation loss = 8.6736  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 1.9501  Validation loss = 8.6733  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 1.9499  Validation loss = 8.6725  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 1.9497  Validation loss = 8.6719  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 1.9495  Validation loss = 8.6709  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 1.9494  Validation loss = 8.6701  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 1.9492  Validation loss = 8.6694  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 1.9490  Validation loss = 8.6686  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 1.9489  Validation loss = 8.6683  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 1.9488  Validation loss = 8.6681  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 1.9487  Validation loss = 8.6676  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 1.9485  Validation loss = 8.6669  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 1.9484  Validation loss = 8.6661  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 1.9482  Validation loss = 8.6656  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 1.9480  Validation loss = 8.6643  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 1.9478  Validation loss = 8.6639  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 1.9477  Validation loss = 8.6630  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 1.9475  Validation loss = 8.6623  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 1.9474  Validation loss = 8.6618  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 1.9472  Validation loss = 8.6607  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 1.9469  Validation loss = 8.6596  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 1.9468  Validation loss = 8.6591  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 1.9466  Validation loss = 8.6585  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 1.9465  Validation loss = 8.6578  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 1.9463  Validation loss = 8.6572  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 1.9462  Validation loss = 8.6569  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 1.9461  Validation loss = 8.6565  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 1.9459  Validation loss = 8.6556  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 1.9457  Validation loss = 8.6548  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 1.9456  Validation loss = 8.6540  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 1.9454  Validation loss = 8.6534  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 1.9453  Validation loss = 8.6529  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 1.9452  Validation loss = 8.6525  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 1.9450  Validation loss = 8.6516  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 1.9449  Validation loss = 8.6511  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 1.9447  Validation loss = 8.6508  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 1.9446  Validation loss = 8.6501  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 1.9444  Validation loss = 8.6497  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 1.9443  Validation loss = 8.6491  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 1.9441  Validation loss = 8.6485  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 1.9440  Validation loss = 8.6478  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 1.9438  Validation loss = 8.6473  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 1.9436  Validation loss = 8.6462  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 1.9435  Validation loss = 8.6455  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 1.9433  Validation loss = 8.6446  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 1.9431  Validation loss = 8.6441  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 1.9430  Validation loss = 8.6437  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 1.9429  Validation loss = 8.6431  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 1.9427  Validation loss = 8.6425  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 1.9426  Validation loss = 8.6422  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 1.9424  Validation loss = 8.6414  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 1.9422  Validation loss = 8.6401  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 1.9420  Validation loss = 8.6388  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 1.9418  Validation loss = 8.6381  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 1.9415  Validation loss = 8.6368  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 1.9413  Validation loss = 8.6358  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 1.9411  Validation loss = 8.6350  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 1.9410  Validation loss = 8.6347  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 1.9409  Validation loss = 8.6344  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 1.9408  Validation loss = 8.6340  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 1.9407  Validation loss = 8.6337  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 1.9405  Validation loss = 8.6331  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 1.9403  Validation loss = 8.6321  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 1.9401  Validation loss = 8.6312  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 1.9400  Validation loss = 8.6305  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 1.9398  Validation loss = 8.6295  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 1.9396  Validation loss = 8.6289  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 1.9393  Validation loss = 8.6273  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 1.9393  Validation loss = 8.6274  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 1.9392  Validation loss = 8.6273  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 1.9391  Validation loss = 8.6268  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 1.9389  Validation loss = 8.6262  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 1.9388  Validation loss = 8.6258  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 1.9387  Validation loss = 8.6254  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 1.9385  Validation loss = 8.6243  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 1.9383  Validation loss = 8.6237  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 1.9382  Validation loss = 8.6233  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 1.9380  Validation loss = 8.6224  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 1.9379  Validation loss = 8.6223  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 1.9378  Validation loss = 8.6220  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 1.9376  Validation loss = 8.6208  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 1.9375  Validation loss = 8.6207  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 1.9374  Validation loss = 8.6203  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 1.9372  Validation loss = 8.6198  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 1.9371  Validation loss = 8.6195  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 1.9369  Validation loss = 8.6184  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 1.9367  Validation loss = 8.6170  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 1.9364  Validation loss = 8.6156  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 1.9363  Validation loss = 8.6150  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 1.9361  Validation loss = 8.6138  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 1.9359  Validation loss = 8.6129  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 1.9356  Validation loss = 8.6119  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 1.9354  Validation loss = 8.6105  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 1.9354  Validation loss = 8.6107  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 1.9351  Validation loss = 8.6097  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 1.9350  Validation loss = 8.6088  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 1.9347  Validation loss = 8.6074  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 1.9346  Validation loss = 8.6066  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 1.9344  Validation loss = 8.6060  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 1.9342  Validation loss = 8.6051  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 1.9341  Validation loss = 8.6046  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 1.9339  Validation loss = 8.6038  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 1.9337  Validation loss = 8.6030  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 1.9335  Validation loss = 8.6022  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 1.9333  Validation loss = 8.6015  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 1.9332  Validation loss = 8.6011  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 1.9331  Validation loss = 8.6009  \n",
      "\n",
      "Fold: 9  Epoch: 501  Training loss = 1.9329  Validation loss = 8.6004  \n",
      "\n",
      "Fold: 9  Epoch: 502  Training loss = 1.9328  Validation loss = 8.5999  \n",
      "\n",
      "Fold: 9  Epoch: 503  Training loss = 1.9326  Validation loss = 8.5990  \n",
      "\n",
      "Fold: 9  Epoch: 504  Training loss = 1.9325  Validation loss = 8.5987  \n",
      "\n",
      "Fold: 9  Epoch: 505  Training loss = 1.9324  Validation loss = 8.5986  \n",
      "\n",
      "Fold: 9  Epoch: 506  Training loss = 1.9323  Validation loss = 8.5984  \n",
      "\n",
      "Fold: 9  Epoch: 507  Training loss = 1.9323  Validation loss = 8.5985  \n",
      "\n",
      "Fold: 9  Epoch: 508  Training loss = 1.9322  Validation loss = 8.5984  \n",
      "\n",
      "Fold: 9  Epoch: 509  Training loss = 1.9320  Validation loss = 8.5977  \n",
      "\n",
      "Fold: 9  Epoch: 510  Training loss = 1.9319  Validation loss = 8.5976  \n",
      "\n",
      "Fold: 9  Epoch: 511  Training loss = 1.9319  Validation loss = 8.5976  \n",
      "\n",
      "Fold: 9  Epoch: 512  Training loss = 1.9317  Validation loss = 8.5968  \n",
      "\n",
      "Fold: 9  Epoch: 513  Training loss = 1.9316  Validation loss = 8.5963  \n",
      "\n",
      "Fold: 9  Epoch: 514  Training loss = 1.9314  Validation loss = 8.5956  \n",
      "\n",
      "Fold: 9  Epoch: 515  Training loss = 1.9313  Validation loss = 8.5953  \n",
      "\n",
      "Fold: 9  Epoch: 516  Training loss = 1.9311  Validation loss = 8.5946  \n",
      "\n",
      "Fold: 9  Epoch: 517  Training loss = 1.9310  Validation loss = 8.5936  \n",
      "\n",
      "Fold: 9  Epoch: 518  Training loss = 1.9309  Validation loss = 8.5936  \n",
      "\n",
      "Fold: 9  Epoch: 519  Training loss = 1.9306  Validation loss = 8.5926  \n",
      "\n",
      "Fold: 9  Epoch: 520  Training loss = 1.9305  Validation loss = 8.5921  \n",
      "\n",
      "Fold: 9  Epoch: 521  Training loss = 1.9304  Validation loss = 8.5915  \n",
      "\n",
      "Fold: 9  Epoch: 522  Training loss = 1.9303  Validation loss = 8.5911  \n",
      "\n",
      "Fold: 9  Epoch: 523  Training loss = 1.9301  Validation loss = 8.5906  \n",
      "\n",
      "Fold: 9  Epoch: 524  Training loss = 1.9299  Validation loss = 8.5896  \n",
      "\n",
      "Fold: 9  Epoch: 525  Training loss = 1.9298  Validation loss = 8.5892  \n",
      "\n",
      "Fold: 9  Epoch: 526  Training loss = 1.9297  Validation loss = 8.5887  \n",
      "\n",
      "Fold: 9  Epoch: 527  Training loss = 1.9295  Validation loss = 8.5876  \n",
      "\n",
      "Fold: 9  Epoch: 528  Training loss = 1.9293  Validation loss = 8.5869  \n",
      "\n",
      "Fold: 9  Epoch: 529  Training loss = 1.9291  Validation loss = 8.5858  \n",
      "\n",
      "Fold: 9  Epoch: 530  Training loss = 1.9289  Validation loss = 8.5847  \n",
      "\n",
      "Fold: 9  Epoch: 531  Training loss = 1.9286  Validation loss = 8.5835  \n",
      "\n",
      "Fold: 9  Epoch: 532  Training loss = 1.9285  Validation loss = 8.5832  \n",
      "\n",
      "Fold: 9  Epoch: 533  Training loss = 1.9284  Validation loss = 8.5827  \n",
      "\n",
      "Fold: 9  Epoch: 534  Training loss = 1.9283  Validation loss = 8.5827  \n",
      "\n",
      "Fold: 9  Epoch: 535  Training loss = 1.9281  Validation loss = 8.5818  \n",
      "\n",
      "Fold: 9  Epoch: 536  Training loss = 1.9280  Validation loss = 8.5814  \n",
      "\n",
      "Fold: 9  Epoch: 537  Training loss = 1.9278  Validation loss = 8.5803  \n",
      "\n",
      "Fold: 9  Epoch: 538  Training loss = 1.9276  Validation loss = 8.5798  \n",
      "\n",
      "Fold: 9  Epoch: 539  Training loss = 1.9275  Validation loss = 8.5795  \n",
      "\n",
      "Fold: 9  Epoch: 540  Training loss = 1.9274  Validation loss = 8.5793  \n",
      "\n",
      "Fold: 9  Epoch: 541  Training loss = 1.9273  Validation loss = 8.5788  \n",
      "\n",
      "Fold: 9  Epoch: 542  Training loss = 1.9271  Validation loss = 8.5780  \n",
      "\n",
      "Fold: 9  Epoch: 543  Training loss = 1.9270  Validation loss = 8.5776  \n",
      "\n",
      "Fold: 9  Epoch: 544  Training loss = 1.9268  Validation loss = 8.5764  \n",
      "\n",
      "Fold: 9  Epoch: 545  Training loss = 1.9266  Validation loss = 8.5756  \n",
      "\n",
      "Fold: 9  Epoch: 546  Training loss = 1.9264  Validation loss = 8.5749  \n",
      "\n",
      "Fold: 9  Epoch: 547  Training loss = 1.9262  Validation loss = 8.5742  \n",
      "\n",
      "Fold: 9  Epoch: 548  Training loss = 1.9261  Validation loss = 8.5737  \n",
      "\n",
      "Fold: 9  Epoch: 549  Training loss = 1.9259  Validation loss = 8.5730  \n",
      "\n",
      "Fold: 9  Epoch: 550  Training loss = 1.9258  Validation loss = 8.5726  \n",
      "\n",
      "Fold: 9  Epoch: 551  Training loss = 1.9257  Validation loss = 8.5725  \n",
      "\n",
      "Fold: 9  Epoch: 552  Training loss = 1.9255  Validation loss = 8.5714  \n",
      "\n",
      "Fold: 9  Epoch: 553  Training loss = 1.9253  Validation loss = 8.5702  \n",
      "\n",
      "Fold: 9  Epoch: 554  Training loss = 1.9251  Validation loss = 8.5692  \n",
      "\n",
      "Fold: 9  Epoch: 555  Training loss = 1.9250  Validation loss = 8.5687  \n",
      "\n",
      "Fold: 9  Epoch: 556  Training loss = 1.9248  Validation loss = 8.5678  \n",
      "\n",
      "Fold: 9  Epoch: 557  Training loss = 1.9247  Validation loss = 8.5675  \n",
      "\n",
      "Fold: 9  Epoch: 558  Training loss = 1.9245  Validation loss = 8.5668  \n",
      "\n",
      "Fold: 9  Epoch: 559  Training loss = 1.9245  Validation loss = 8.5664  \n",
      "\n",
      "Fold: 9  Epoch: 560  Training loss = 1.9242  Validation loss = 8.5650  \n",
      "\n",
      "Fold: 9  Epoch: 561  Training loss = 1.9241  Validation loss = 8.5648  \n",
      "\n",
      "Fold: 9  Epoch: 562  Training loss = 1.9240  Validation loss = 8.5642  \n",
      "\n",
      "Fold: 9  Epoch: 563  Training loss = 1.9238  Validation loss = 8.5635  \n",
      "\n",
      "Fold: 9  Epoch: 564  Training loss = 1.9237  Validation loss = 8.5628  \n",
      "\n",
      "Fold: 9  Epoch: 565  Training loss = 1.9235  Validation loss = 8.5621  \n",
      "\n",
      "Fold: 9  Epoch: 566  Training loss = 1.9234  Validation loss = 8.5620  \n",
      "\n",
      "Fold: 9  Epoch: 567  Training loss = 1.9232  Validation loss = 8.5610  \n",
      "\n",
      "Fold: 9  Epoch: 568  Training loss = 1.9231  Validation loss = 8.5606  \n",
      "\n",
      "Fold: 9  Epoch: 569  Training loss = 1.9231  Validation loss = 8.5609  \n",
      "\n",
      "Fold: 9  Epoch: 570  Training loss = 1.9229  Validation loss = 8.5605  \n",
      "\n",
      "Fold: 9  Epoch: 571  Training loss = 1.9227  Validation loss = 8.5595  \n",
      "\n",
      "Fold: 9  Epoch: 572  Training loss = 1.9225  Validation loss = 8.5585  \n",
      "\n",
      "Fold: 9  Epoch: 573  Training loss = 1.9224  Validation loss = 8.5576  \n",
      "\n",
      "Fold: 9  Epoch: 574  Training loss = 1.9223  Validation loss = 8.5576  \n",
      "\n",
      "Fold: 9  Epoch: 575  Training loss = 1.9222  Validation loss = 8.5570  \n",
      "\n",
      "Fold: 9  Epoch: 576  Training loss = 1.9221  Validation loss = 8.5567  \n",
      "\n",
      "Fold: 9  Epoch: 577  Training loss = 1.9219  Validation loss = 8.5559  \n",
      "\n",
      "Fold: 9  Epoch: 578  Training loss = 1.9218  Validation loss = 8.5557  \n",
      "\n",
      "Fold: 9  Epoch: 579  Training loss = 1.9217  Validation loss = 8.5550  \n",
      "\n",
      "Fold: 9  Epoch: 580  Training loss = 1.9215  Validation loss = 8.5544  \n",
      "\n",
      "Fold: 9  Epoch: 581  Training loss = 1.9213  Validation loss = 8.5534  \n",
      "\n",
      "Fold: 9  Epoch: 582  Training loss = 1.9212  Validation loss = 8.5524  \n",
      "\n",
      "Fold: 9  Epoch: 583  Training loss = 1.9211  Validation loss = 8.5525  \n",
      "\n",
      "Fold: 9  Epoch: 584  Training loss = 1.9210  Validation loss = 8.5522  \n",
      "\n",
      "Fold: 9  Epoch: 585  Training loss = 1.9208  Validation loss = 8.5515  \n",
      "\n",
      "Fold: 9  Epoch: 586  Training loss = 1.9207  Validation loss = 8.5509  \n",
      "\n",
      "Fold: 9  Epoch: 587  Training loss = 1.9205  Validation loss = 8.5498  \n",
      "\n",
      "Fold: 9  Epoch: 588  Training loss = 1.9203  Validation loss = 8.5489  \n",
      "\n",
      "Fold: 9  Epoch: 589  Training loss = 1.9201  Validation loss = 8.5475  \n",
      "\n",
      "Fold: 9  Epoch: 590  Training loss = 1.9199  Validation loss = 8.5467  \n",
      "\n",
      "Fold: 9  Epoch: 591  Training loss = 1.9199  Validation loss = 8.5466  \n",
      "\n",
      "Fold: 9  Epoch: 592  Training loss = 1.9197  Validation loss = 8.5460  \n",
      "\n",
      "Fold: 9  Epoch: 593  Training loss = 1.9196  Validation loss = 8.5456  \n",
      "\n",
      "Fold: 9  Epoch: 594  Training loss = 1.9195  Validation loss = 8.5453  \n",
      "\n",
      "Fold: 9  Epoch: 595  Training loss = 1.9194  Validation loss = 8.5451  \n",
      "\n",
      "Fold: 9  Epoch: 596  Training loss = 1.9192  Validation loss = 8.5444  \n",
      "\n",
      "Fold: 9  Epoch: 597  Training loss = 1.9191  Validation loss = 8.5440  \n",
      "\n",
      "Fold: 9  Epoch: 598  Training loss = 1.9189  Validation loss = 8.5433  \n",
      "\n",
      "Fold: 9  Epoch: 599  Training loss = 1.9189  Validation loss = 8.5435  \n",
      "\n",
      "Fold: 9  Epoch: 600  Training loss = 1.9187  Validation loss = 8.5430  \n",
      "\n",
      "Fold: 9  Epoch: 601  Training loss = 1.9186  Validation loss = 8.5425  \n",
      "\n",
      "Fold: 9  Epoch: 602  Training loss = 1.9184  Validation loss = 8.5415  \n",
      "\n",
      "Fold: 9  Epoch: 603  Training loss = 1.9182  Validation loss = 8.5406  \n",
      "\n",
      "Fold: 9  Epoch: 604  Training loss = 1.9181  Validation loss = 8.5403  \n",
      "\n",
      "Fold: 9  Epoch: 605  Training loss = 1.9179  Validation loss = 8.5394  \n",
      "\n",
      "Fold: 9  Epoch: 606  Training loss = 1.9178  Validation loss = 8.5387  \n",
      "\n",
      "Fold: 9  Epoch: 607  Training loss = 1.9177  Validation loss = 8.5384  \n",
      "\n",
      "Fold: 9  Epoch: 608  Training loss = 1.9176  Validation loss = 8.5374  \n",
      "\n",
      "Fold: 9  Epoch: 609  Training loss = 1.9174  Validation loss = 8.5367  \n",
      "\n",
      "Fold: 9  Epoch: 610  Training loss = 1.9173  Validation loss = 8.5366  \n",
      "\n",
      "Fold: 9  Epoch: 611  Training loss = 1.9172  Validation loss = 8.5359  \n",
      "\n",
      "Fold: 9  Epoch: 612  Training loss = 1.9171  Validation loss = 8.5354  \n",
      "\n",
      "Fold: 9  Epoch: 613  Training loss = 1.9169  Validation loss = 8.5347  \n",
      "\n",
      "Fold: 9  Epoch: 614  Training loss = 1.9168  Validation loss = 8.5342  \n",
      "\n",
      "Fold: 9  Epoch: 615  Training loss = 1.9167  Validation loss = 8.5341  \n",
      "\n",
      "Fold: 9  Epoch: 616  Training loss = 1.9166  Validation loss = 8.5340  \n",
      "\n",
      "Fold: 9  Epoch: 617  Training loss = 1.9165  Validation loss = 8.5337  \n",
      "\n",
      "Fold: 9  Epoch: 618  Training loss = 1.9164  Validation loss = 8.5331  \n",
      "\n",
      "Fold: 9  Epoch: 619  Training loss = 1.9163  Validation loss = 8.5325  \n",
      "\n",
      "Fold: 9  Epoch: 620  Training loss = 1.9160  Validation loss = 8.5309  \n",
      "\n",
      "Fold: 9  Epoch: 621  Training loss = 1.9158  Validation loss = 8.5296  \n",
      "\n",
      "Fold: 9  Epoch: 622  Training loss = 1.9156  Validation loss = 8.5291  \n",
      "\n",
      "Fold: 9  Epoch: 623  Training loss = 1.9155  Validation loss = 8.5280  \n",
      "\n",
      "Fold: 9  Epoch: 624  Training loss = 1.9152  Validation loss = 8.5268  \n",
      "\n",
      "Fold: 9  Epoch: 625  Training loss = 1.9151  Validation loss = 8.5263  \n",
      "\n",
      "Fold: 9  Epoch: 626  Training loss = 1.9150  Validation loss = 8.5261  \n",
      "\n",
      "Fold: 9  Epoch: 627  Training loss = 1.9149  Validation loss = 8.5259  \n",
      "\n",
      "Fold: 9  Epoch: 628  Training loss = 1.9147  Validation loss = 8.5253  \n",
      "\n",
      "Fold: 9  Epoch: 629  Training loss = 1.9146  Validation loss = 8.5249  \n",
      "\n",
      "Fold: 9  Epoch: 630  Training loss = 1.9145  Validation loss = 8.5242  \n",
      "\n",
      "Fold: 9  Epoch: 631  Training loss = 1.9143  Validation loss = 8.5237  \n",
      "\n",
      "Fold: 9  Epoch: 632  Training loss = 1.9142  Validation loss = 8.5230  \n",
      "\n",
      "Fold: 9  Epoch: 633  Training loss = 1.9140  Validation loss = 8.5216  \n",
      "\n",
      "Fold: 9  Epoch: 634  Training loss = 1.9139  Validation loss = 8.5217  \n",
      "\n",
      "Fold: 9  Epoch: 635  Training loss = 1.9138  Validation loss = 8.5211  \n",
      "\n",
      "Fold: 9  Epoch: 636  Training loss = 1.9137  Validation loss = 8.5209  \n",
      "\n",
      "Fold: 9  Epoch: 637  Training loss = 1.9136  Validation loss = 8.5202  \n",
      "\n",
      "Fold: 9  Epoch: 638  Training loss = 1.9134  Validation loss = 8.5192  \n",
      "\n",
      "Fold: 9  Epoch: 639  Training loss = 1.9132  Validation loss = 8.5183  \n",
      "\n",
      "Fold: 9  Epoch: 640  Training loss = 1.9131  Validation loss = 8.5175  \n",
      "\n",
      "Fold: 9  Epoch: 641  Training loss = 1.9129  Validation loss = 8.5169  \n",
      "\n",
      "Fold: 9  Epoch: 642  Training loss = 1.9128  Validation loss = 8.5166  \n",
      "\n",
      "Fold: 9  Epoch: 643  Training loss = 1.9127  Validation loss = 8.5157  \n",
      "\n",
      "Fold: 9  Epoch: 644  Training loss = 1.9125  Validation loss = 8.5149  \n",
      "\n",
      "Fold: 9  Epoch: 645  Training loss = 1.9124  Validation loss = 8.5142  \n",
      "\n",
      "Fold: 9  Epoch: 646  Training loss = 1.9122  Validation loss = 8.5133  \n",
      "\n",
      "Fold: 9  Epoch: 647  Training loss = 1.9122  Validation loss = 8.5137  \n",
      "\n",
      "Fold: 9  Epoch: 648  Training loss = 1.9120  Validation loss = 8.5128  \n",
      "\n",
      "Fold: 9  Epoch: 649  Training loss = 1.9118  Validation loss = 8.5109  \n",
      "\n",
      "Fold: 9  Epoch: 650  Training loss = 1.9117  Validation loss = 8.5106  \n",
      "\n",
      "Fold: 9  Epoch: 651  Training loss = 1.9115  Validation loss = 8.5097  \n",
      "\n",
      "Fold: 9  Epoch: 652  Training loss = 1.9114  Validation loss = 8.5091  \n",
      "\n",
      "Fold: 9  Epoch: 653  Training loss = 1.9113  Validation loss = 8.5087  \n",
      "\n",
      "Fold: 9  Epoch: 654  Training loss = 1.9111  Validation loss = 8.5077  \n",
      "\n",
      "Fold: 9  Epoch: 655  Training loss = 1.9110  Validation loss = 8.5074  \n",
      "\n",
      "Fold: 9  Epoch: 656  Training loss = 1.9108  Validation loss = 8.5071  \n",
      "\n",
      "Fold: 9  Epoch: 657  Training loss = 1.9108  Validation loss = 8.5067  \n",
      "\n",
      "Fold: 9  Epoch: 658  Training loss = 1.9106  Validation loss = 8.5052  \n",
      "\n",
      "Fold: 9  Epoch: 659  Training loss = 1.9104  Validation loss = 8.5043  \n",
      "\n",
      "Fold: 9  Epoch: 660  Training loss = 1.9102  Validation loss = 8.5026  \n",
      "\n",
      "Fold: 9  Epoch: 661  Training loss = 1.9100  Validation loss = 8.5019  \n",
      "\n",
      "Fold: 9  Epoch: 662  Training loss = 1.9098  Validation loss = 8.5008  \n",
      "\n",
      "Fold: 9  Epoch: 663  Training loss = 1.9097  Validation loss = 8.5003  \n",
      "\n",
      "Fold: 9  Epoch: 664  Training loss = 1.9095  Validation loss = 8.4986  \n",
      "\n",
      "Fold: 9  Epoch: 665  Training loss = 1.9094  Validation loss = 8.4974  \n",
      "\n",
      "Fold: 9  Epoch: 666  Training loss = 1.9092  Validation loss = 8.4955  \n",
      "\n",
      "Fold: 9  Epoch: 667  Training loss = 1.9089  Validation loss = 8.4938  \n",
      "\n",
      "Fold: 9  Epoch: 668  Training loss = 1.9087  Validation loss = 8.4926  \n",
      "\n",
      "Fold: 9  Epoch: 669  Training loss = 1.9086  Validation loss = 8.4921  \n",
      "\n",
      "Fold: 9  Epoch: 670  Training loss = 1.9084  Validation loss = 8.4902  \n",
      "\n",
      "Fold: 9  Epoch: 671  Training loss = 1.9083  Validation loss = 8.4897  \n",
      "\n",
      "Fold: 9  Epoch: 672  Training loss = 1.9082  Validation loss = 8.4889  \n",
      "\n",
      "Fold: 9  Epoch: 673  Training loss = 1.9080  Validation loss = 8.4880  \n",
      "\n",
      "Fold: 9  Epoch: 674  Training loss = 1.9079  Validation loss = 8.4876  \n",
      "\n",
      "Fold: 9  Epoch: 675  Training loss = 1.9077  Validation loss = 8.4861  \n",
      "\n",
      "Fold: 9  Epoch: 676  Training loss = 1.9075  Validation loss = 8.4844  \n",
      "\n",
      "Fold: 9  Epoch: 677  Training loss = 1.9074  Validation loss = 8.4843  \n",
      "\n",
      "Fold: 9  Epoch: 678  Training loss = 1.9073  Validation loss = 8.4840  \n",
      "\n",
      "Fold: 9  Epoch: 679  Training loss = 1.9072  Validation loss = 8.4838  \n",
      "\n",
      "Fold: 9  Epoch: 680  Training loss = 1.9072  Validation loss = 8.4838  \n",
      "\n",
      "Fold: 9  Epoch: 681  Training loss = 1.9070  Validation loss = 8.4829  \n",
      "\n",
      "Fold: 9  Epoch: 682  Training loss = 1.9069  Validation loss = 8.4820  \n",
      "\n",
      "Fold: 9  Epoch: 683  Training loss = 1.9068  Validation loss = 8.4818  \n",
      "\n",
      "Fold: 9  Epoch: 684  Training loss = 1.9066  Validation loss = 8.4808  \n",
      "\n",
      "Fold: 9  Epoch: 685  Training loss = 1.9065  Validation loss = 8.4802  \n",
      "\n",
      "Fold: 9  Epoch: 686  Training loss = 1.9062  Validation loss = 8.4776  \n",
      "\n",
      "Fold: 9  Epoch: 687  Training loss = 1.9061  Validation loss = 8.4772  \n",
      "\n",
      "Fold: 9  Epoch: 688  Training loss = 1.9060  Validation loss = 8.4765  \n",
      "\n",
      "Fold: 9  Epoch: 689  Training loss = 1.9059  Validation loss = 8.4766  \n",
      "\n",
      "Fold: 9  Epoch: 690  Training loss = 1.9058  Validation loss = 8.4760  \n",
      "\n",
      "Fold: 9  Epoch: 691  Training loss = 1.9057  Validation loss = 8.4751  \n",
      "\n",
      "Fold: 9  Epoch: 692  Training loss = 1.9055  Validation loss = 8.4734  \n",
      "\n",
      "Fold: 9  Epoch: 693  Training loss = 1.9053  Validation loss = 8.4725  \n",
      "\n",
      "Fold: 9  Epoch: 694  Training loss = 1.9051  Validation loss = 8.4712  \n",
      "\n",
      "Fold: 9  Epoch: 695  Training loss = 1.9050  Validation loss = 8.4701  \n",
      "\n",
      "Fold: 9  Epoch: 696  Training loss = 1.9048  Validation loss = 8.4689  \n",
      "\n",
      "Fold: 9  Epoch: 697  Training loss = 1.9047  Validation loss = 8.4674  \n",
      "\n",
      "Fold: 9  Epoch: 698  Training loss = 1.9046  Validation loss = 8.4673  \n",
      "\n",
      "Fold: 9  Epoch: 699  Training loss = 1.9045  Validation loss = 8.4668  \n",
      "\n",
      "Fold: 9  Epoch: 700  Training loss = 1.9043  Validation loss = 8.4654  \n",
      "\n",
      "Fold: 9  Epoch: 701  Training loss = 1.9042  Validation loss = 8.4640  \n",
      "\n",
      "Fold: 9  Epoch: 702  Training loss = 1.9040  Validation loss = 8.4623  \n",
      "\n",
      "Fold: 9  Epoch: 703  Training loss = 1.9039  Validation loss = 8.4607  \n",
      "\n",
      "Fold: 9  Epoch: 704  Training loss = 1.9037  Validation loss = 8.4595  \n",
      "\n",
      "Fold: 9  Epoch: 705  Training loss = 1.9036  Validation loss = 8.4587  \n",
      "\n",
      "Fold: 9  Epoch: 706  Training loss = 1.9035  Validation loss = 8.4578  \n",
      "\n",
      "Fold: 9  Epoch: 707  Training loss = 1.9033  Validation loss = 8.4565  \n",
      "\n",
      "Fold: 9  Epoch: 708  Training loss = 1.9032  Validation loss = 8.4562  \n",
      "\n",
      "Fold: 9  Epoch: 709  Training loss = 1.9031  Validation loss = 8.4550  \n",
      "\n",
      "Fold: 9  Epoch: 710  Training loss = 1.9029  Validation loss = 8.4543  \n",
      "\n",
      "Fold: 9  Epoch: 711  Training loss = 1.9029  Validation loss = 8.4539  \n",
      "\n",
      "Fold: 9  Epoch: 712  Training loss = 1.9027  Validation loss = 8.4518  \n",
      "\n",
      "Fold: 9  Epoch: 713  Training loss = 1.9025  Validation loss = 8.4505  \n",
      "\n",
      "Fold: 9  Epoch: 714  Training loss = 1.9023  Validation loss = 8.4481  \n",
      "\n",
      "Fold: 9  Epoch: 715  Training loss = 1.9022  Validation loss = 8.4476  \n",
      "\n",
      "Fold: 9  Epoch: 716  Training loss = 1.9021  Validation loss = 8.4466  \n",
      "\n",
      "Fold: 9  Epoch: 717  Training loss = 1.9020  Validation loss = 8.4461  \n",
      "\n",
      "Fold: 9  Epoch: 718  Training loss = 1.9019  Validation loss = 8.4452  \n",
      "\n",
      "Fold: 9  Epoch: 719  Training loss = 1.9018  Validation loss = 8.4441  \n",
      "\n",
      "Fold: 9  Epoch: 720  Training loss = 1.9017  Validation loss = 8.4435  \n",
      "\n",
      "Fold: 9  Epoch: 721  Training loss = 1.9016  Validation loss = 8.4425  \n",
      "\n",
      "Fold: 9  Epoch: 722  Training loss = 1.9015  Validation loss = 8.4419  \n",
      "\n",
      "Fold: 9  Epoch: 723  Training loss = 1.9014  Validation loss = 8.4411  \n",
      "\n",
      "Fold: 9  Epoch: 724  Training loss = 1.9012  Validation loss = 8.4394  \n",
      "\n",
      "Fold: 9  Epoch: 725  Training loss = 1.9012  Validation loss = 8.4394  \n",
      "\n",
      "Fold: 9  Epoch: 726  Training loss = 1.9010  Validation loss = 8.4370  \n",
      "\n",
      "Fold: 9  Epoch: 727  Training loss = 1.9008  Validation loss = 8.4361  \n",
      "\n",
      "Fold: 9  Epoch: 728  Training loss = 1.9007  Validation loss = 8.4358  \n",
      "\n",
      "Fold: 9  Epoch: 729  Training loss = 1.9006  Validation loss = 8.4347  \n",
      "\n",
      "Fold: 9  Epoch: 730  Training loss = 1.9005  Validation loss = 8.4330  \n",
      "\n",
      "Fold: 9  Epoch: 731  Training loss = 1.9003  Validation loss = 8.4319  \n",
      "\n",
      "Fold: 9  Epoch: 732  Training loss = 1.9002  Validation loss = 8.4310  \n",
      "\n",
      "Fold: 9  Epoch: 733  Training loss = 1.9001  Validation loss = 8.4298  \n",
      "\n",
      "Fold: 9  Epoch: 734  Training loss = 1.8999  Validation loss = 8.4281  \n",
      "\n",
      "Fold: 9  Epoch: 735  Training loss = 1.8998  Validation loss = 8.4267  \n",
      "\n",
      "Fold: 9  Epoch: 736  Training loss = 1.8996  Validation loss = 8.4245  \n",
      "\n",
      "Fold: 9  Epoch: 737  Training loss = 1.8995  Validation loss = 8.4232  \n",
      "\n",
      "Fold: 9  Epoch: 738  Training loss = 1.8993  Validation loss = 8.4211  \n",
      "\n",
      "Fold: 9  Epoch: 739  Training loss = 1.8993  Validation loss = 8.4206  \n",
      "\n",
      "Fold: 9  Epoch: 740  Training loss = 1.8991  Validation loss = 8.4200  \n",
      "\n",
      "Fold: 9  Epoch: 741  Training loss = 1.8990  Validation loss = 8.4177  \n",
      "\n",
      "Fold: 9  Epoch: 742  Training loss = 1.8989  Validation loss = 8.4174  \n",
      "\n",
      "Fold: 9  Epoch: 743  Training loss = 1.8988  Validation loss = 8.4156  \n",
      "\n",
      "Fold: 9  Epoch: 744  Training loss = 1.8986  Validation loss = 8.4140  \n",
      "\n",
      "Fold: 9  Epoch: 745  Training loss = 1.8985  Validation loss = 8.4134  \n",
      "\n",
      "Fold: 9  Epoch: 746  Training loss = 1.8984  Validation loss = 8.4111  \n",
      "\n",
      "Fold: 9  Epoch: 747  Training loss = 1.8982  Validation loss = 8.4092  \n",
      "\n",
      "Fold: 9  Epoch: 748  Training loss = 1.8981  Validation loss = 8.4079  \n",
      "\n",
      "Fold: 9  Epoch: 749  Training loss = 1.8980  Validation loss = 8.4059  \n",
      "\n",
      "Fold: 9  Epoch: 750  Training loss = 1.8978  Validation loss = 8.4046  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 750  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.7628  Validation loss = 3.8831  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.7622  Validation loss = 3.8824  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.7617  Validation loss = 3.8818  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.7612  Validation loss = 3.8810  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.7604  Validation loss = 3.8799  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.7592  Validation loss = 3.8786  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.7582  Validation loss = 3.8771  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.7574  Validation loss = 3.8753  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.7569  Validation loss = 3.8742  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.7559  Validation loss = 3.8727  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.7555  Validation loss = 3.8719  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.7545  Validation loss = 3.8704  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.7537  Validation loss = 3.8690  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.7531  Validation loss = 3.8678  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 2.7526  Validation loss = 3.8669  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.7521  Validation loss = 3.8660  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 2.7518  Validation loss = 3.8655  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 2.7509  Validation loss = 3.8636  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 2.7506  Validation loss = 3.8631  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.7498  Validation loss = 3.8620  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 2.7490  Validation loss = 3.8601  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 2.7483  Validation loss = 3.8587  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 2.7477  Validation loss = 3.8573  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 2.7472  Validation loss = 3.8563  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 2.7466  Validation loss = 3.8553  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 2.7461  Validation loss = 3.8541  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 2.7454  Validation loss = 3.8526  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 2.7447  Validation loss = 3.8513  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 2.7436  Validation loss = 3.8488  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 2.7430  Validation loss = 3.8474  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 2.7424  Validation loss = 3.8457  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 2.7421  Validation loss = 3.8453  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 2.7419  Validation loss = 3.8451  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 2.7415  Validation loss = 3.8442  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 2.7407  Validation loss = 3.8425  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 2.7401  Validation loss = 3.8410  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 2.7395  Validation loss = 3.8396  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 2.7388  Validation loss = 3.8380  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 2.7378  Validation loss = 3.8358  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 2.7373  Validation loss = 3.8345  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 2.7369  Validation loss = 3.8337  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 2.7362  Validation loss = 3.8321  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 2.7356  Validation loss = 3.8305  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 2.7350  Validation loss = 3.8291  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 2.7346  Validation loss = 3.8284  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 2.7342  Validation loss = 3.8275  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 2.7335  Validation loss = 3.8257  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 2.7331  Validation loss = 3.8250  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 2.7328  Validation loss = 3.8245  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 2.7323  Validation loss = 3.8235  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 2.7319  Validation loss = 3.8227  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 2.7314  Validation loss = 3.8214  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 2.7309  Validation loss = 3.8203  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 2.7302  Validation loss = 3.8186  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 2.7297  Validation loss = 3.8174  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 2.7290  Validation loss = 3.8155  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 2.7284  Validation loss = 3.8143  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 2.7280  Validation loss = 3.8135  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 2.7276  Validation loss = 3.8128  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 2.7274  Validation loss = 3.8125  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 2.7269  Validation loss = 3.8113  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 2.7265  Validation loss = 3.8107  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 2.7254  Validation loss = 3.8077  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 2.7246  Validation loss = 3.8059  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 2.7240  Validation loss = 3.8043  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 2.7233  Validation loss = 3.8025  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 2.7228  Validation loss = 3.8013  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 2.7222  Validation loss = 3.7999  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 2.7216  Validation loss = 3.7983  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 2.7211  Validation loss = 3.7973  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 2.7199  Validation loss = 3.7942  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 2.7195  Validation loss = 3.7932  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 2.7193  Validation loss = 3.7928  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 2.7189  Validation loss = 3.7919  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 2.7182  Validation loss = 3.7902  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 2.7176  Validation loss = 3.7888  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 2.7172  Validation loss = 3.7878  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 2.7168  Validation loss = 3.7868  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 2.7161  Validation loss = 3.7849  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 2.7155  Validation loss = 3.7835  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 2.7147  Validation loss = 3.7813  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 2.7141  Validation loss = 3.7799  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 2.7134  Validation loss = 3.7782  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 2.7128  Validation loss = 3.7768  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 2.7123  Validation loss = 3.7757  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 2.7119  Validation loss = 3.7747  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 2.7114  Validation loss = 3.7737  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 2.7111  Validation loss = 3.7730  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 2.7107  Validation loss = 3.7720  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 2.7102  Validation loss = 3.7707  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 2.7097  Validation loss = 3.7697  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 2.7091  Validation loss = 3.7680  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 2.7085  Validation loss = 3.7667  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 2.7077  Validation loss = 3.7645  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 2.7071  Validation loss = 3.7629  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 2.7065  Validation loss = 3.7616  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 2.7061  Validation loss = 3.7605  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 2.7053  Validation loss = 3.7583  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 2.7051  Validation loss = 3.7581  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 2.7048  Validation loss = 3.7574  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 2.7045  Validation loss = 3.7569  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 2.7040  Validation loss = 3.7555  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 2.7036  Validation loss = 3.7545  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 2.7028  Validation loss = 3.7524  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 2.7022  Validation loss = 3.7508  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 2.7017  Validation loss = 3.7495  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 2.7012  Validation loss = 3.7485  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 2.7008  Validation loss = 3.7473  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 2.7001  Validation loss = 3.7456  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 2.6995  Validation loss = 3.7441  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 2.6990  Validation loss = 3.7429  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 2.6986  Validation loss = 3.7422  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 2.6983  Validation loss = 3.7415  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 2.6981  Validation loss = 3.7412  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 2.6976  Validation loss = 3.7399  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 2.6970  Validation loss = 3.7383  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 2.6964  Validation loss = 3.7370  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 2.6962  Validation loss = 3.7365  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 2.6959  Validation loss = 3.7357  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 2.6954  Validation loss = 3.7344  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 2.6948  Validation loss = 3.7329  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 2.6946  Validation loss = 3.7326  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 2.6937  Validation loss = 3.7305  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 2.6936  Validation loss = 3.7301  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 2.6930  Validation loss = 3.7287  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 2.6925  Validation loss = 3.7273  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 2.6920  Validation loss = 3.7263  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 2.6913  Validation loss = 3.7245  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 2.6909  Validation loss = 3.7233  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 2.6904  Validation loss = 3.7222  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 2.6900  Validation loss = 3.7211  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 2.6895  Validation loss = 3.7200  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 2.6892  Validation loss = 3.7193  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 2.6887  Validation loss = 3.7182  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 2.6885  Validation loss = 3.7175  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 2.6879  Validation loss = 3.7161  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 2.6876  Validation loss = 3.7152  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 2.6872  Validation loss = 3.7143  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 2.6865  Validation loss = 3.7125  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 2.6859  Validation loss = 3.7108  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 2.6856  Validation loss = 3.7102  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 2.6852  Validation loss = 3.7091  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 2.6844  Validation loss = 3.7071  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 2.6840  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 2.6838  Validation loss = 3.7058  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 2.6833  Validation loss = 3.7045  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 2.6828  Validation loss = 3.7035  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 2.6825  Validation loss = 3.7029  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 2.6821  Validation loss = 3.7021  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 2.6815  Validation loss = 3.7002  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 2.6813  Validation loss = 3.7000  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 2.6809  Validation loss = 3.6989  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 2.6802  Validation loss = 3.6969  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 2.6796  Validation loss = 3.6955  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 2.6792  Validation loss = 3.6943  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 2.6787  Validation loss = 3.6930  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 2.6783  Validation loss = 3.6920  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 2.6778  Validation loss = 3.6908  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 2.6772  Validation loss = 3.6893  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 2.6769  Validation loss = 3.6883  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 2.6765  Validation loss = 3.6873  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 2.6758  Validation loss = 3.6852  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 2.6753  Validation loss = 3.6841  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 2.6750  Validation loss = 3.6834  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 2.6744  Validation loss = 3.6819  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 2.6740  Validation loss = 3.6811  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 2.6736  Validation loss = 3.6801  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 2.6734  Validation loss = 3.6795  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 2.6729  Validation loss = 3.6782  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 2.6725  Validation loss = 3.6773  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 2.6720  Validation loss = 3.6761  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 2.6717  Validation loss = 3.6755  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 2.6713  Validation loss = 3.6743  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 2.6707  Validation loss = 3.6728  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 2.6703  Validation loss = 3.6717  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 2.6697  Validation loss = 3.6703  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 2.6694  Validation loss = 3.6696  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 2.6691  Validation loss = 3.6686  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 2.6685  Validation loss = 3.6670  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 2.6681  Validation loss = 3.6660  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 2.6674  Validation loss = 3.6643  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 2.6671  Validation loss = 3.6635  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 2.6666  Validation loss = 3.6621  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 2.6661  Validation loss = 3.6609  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 2.6656  Validation loss = 3.6597  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 2.6652  Validation loss = 3.6589  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 2.6649  Validation loss = 3.6583  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 2.6646  Validation loss = 3.6576  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 2.6640  Validation loss = 3.6557  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 2.6636  Validation loss = 3.6548  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 2.6633  Validation loss = 3.6541  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 2.6628  Validation loss = 3.6530  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 2.6624  Validation loss = 3.6518  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 2.6620  Validation loss = 3.6508  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 2.6613  Validation loss = 3.6484  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 2.6607  Validation loss = 3.6470  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 2.6606  Validation loss = 3.6468  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 2.6603  Validation loss = 3.6460  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 2.6597  Validation loss = 3.6443  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 2.6594  Validation loss = 3.6435  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 2.6591  Validation loss = 3.6425  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 2.6588  Validation loss = 3.6415  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 2.6583  Validation loss = 3.6402  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 2.6579  Validation loss = 3.6394  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 2.6575  Validation loss = 3.6382  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 2.6571  Validation loss = 3.6367  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 2.6569  Validation loss = 3.6363  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 2.6564  Validation loss = 3.6348  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 2.6560  Validation loss = 3.6333  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 2.6555  Validation loss = 3.6313  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 2.6551  Validation loss = 3.6294  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 2.6549  Validation loss = 3.6288  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 2.6545  Validation loss = 3.6281  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 2.6541  Validation loss = 3.6272  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 2.6537  Validation loss = 3.6256  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 2.6531  Validation loss = 3.6235  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 2.6527  Validation loss = 3.6212  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 2.6523  Validation loss = 3.6199  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 2.6519  Validation loss = 3.6181  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 2.6515  Validation loss = 3.6164  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 2.6512  Validation loss = 3.6158  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 2.6509  Validation loss = 3.6139  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 2.6506  Validation loss = 3.6134  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 2.6502  Validation loss = 3.6114  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 2.6499  Validation loss = 3.6118  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 2.6494  Validation loss = 3.6089  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 2.6491  Validation loss = 3.6055  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 2.6488  Validation loss = 3.6061  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 2.6483  Validation loss = 3.6056  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 2.6480  Validation loss = 3.6056  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 2.6475  Validation loss = 3.6058  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 2.6473  Validation loss = 3.6046  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 2.6467  Validation loss = 3.6024  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 2.6463  Validation loss = 3.6015  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 2.6461  Validation loss = 3.6002  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 2.6456  Validation loss = 3.5977  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 2.6453  Validation loss = 3.5961  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 2.6449  Validation loss = 3.5978  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 2.6444  Validation loss = 3.5973  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 2.6441  Validation loss = 3.5965  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 2.6438  Validation loss = 3.5950  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 2.6433  Validation loss = 3.5928  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 2.6430  Validation loss = 3.5908  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 2.6426  Validation loss = 3.5870  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 2.6419  Validation loss = 3.5891  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 2.6414  Validation loss = 3.5877  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 2.6411  Validation loss = 3.5856  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 2.6408  Validation loss = 3.5843  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 2.6406  Validation loss = 3.5855  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 2.6404  Validation loss = 3.5848  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 2.6401  Validation loss = 3.5837  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 2.6398  Validation loss = 3.5828  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 2.6392  Validation loss = 3.5831  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 2.6389  Validation loss = 3.5801  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 2.6386  Validation loss = 3.5804  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 2.6384  Validation loss = 3.5812  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 2.6380  Validation loss = 3.5791  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 2.6377  Validation loss = 3.5756  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 2.6374  Validation loss = 3.5760  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 2.6370  Validation loss = 3.5749  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 2.6364  Validation loss = 3.5765  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 2.6359  Validation loss = 3.5741  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 2.6353  Validation loss = 3.5734  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 2.6350  Validation loss = 3.5700  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 2.6347  Validation loss = 3.5716  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 2.6343  Validation loss = 3.5713  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 2.6339  Validation loss = 3.5679  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 2.6336  Validation loss = 3.5670  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 2.6333  Validation loss = 3.5642  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 2.6331  Validation loss = 3.5630  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 2.6327  Validation loss = 3.5623  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 2.6325  Validation loss = 3.5624  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 2.6320  Validation loss = 3.5624  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 2.6316  Validation loss = 3.5593  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 2.6314  Validation loss = 3.5595  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 2.6309  Validation loss = 3.5616  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 2.6304  Validation loss = 3.5581  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 2.6302  Validation loss = 3.5570  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 2.6297  Validation loss = 3.5535  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 2.6292  Validation loss = 3.5526  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 2.6287  Validation loss = 3.5498  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 2.6283  Validation loss = 3.5514  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 2.6281  Validation loss = 3.5523  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 2.6277  Validation loss = 3.5516  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 2.6272  Validation loss = 3.5487  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 2.6269  Validation loss = 3.5486  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 2.6264  Validation loss = 3.5466  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 2.6261  Validation loss = 3.5439  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 2.6257  Validation loss = 3.5421  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 2.6255  Validation loss = 3.5428  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 2.6250  Validation loss = 3.5419  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 2.6247  Validation loss = 3.5432  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 2.6243  Validation loss = 3.5415  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 2.6238  Validation loss = 3.5398  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 2.6235  Validation loss = 3.5384  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 2.6231  Validation loss = 3.5385  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 2.6224  Validation loss = 3.5365  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 2.6222  Validation loss = 3.5355  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 2.6217  Validation loss = 3.5344  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 2.6213  Validation loss = 3.5319  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 2.6208  Validation loss = 3.5327  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 2.6203  Validation loss = 3.5318  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 2.6198  Validation loss = 3.5285  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 2.6196  Validation loss = 3.5302  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 2.6194  Validation loss = 3.5300  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 2.6191  Validation loss = 3.5278  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 2.6189  Validation loss = 3.5282  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 2.6183  Validation loss = 3.5252  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 2.6178  Validation loss = 3.5231  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 2.6176  Validation loss = 3.5216  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 2.6172  Validation loss = 3.5207  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 2.6169  Validation loss = 3.5209  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 2.6167  Validation loss = 3.5186  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 2.6165  Validation loss = 3.5181  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 2.6163  Validation loss = 3.5174  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 2.6161  Validation loss = 3.5177  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 2.6155  Validation loss = 3.5202  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 2.6153  Validation loss = 3.5203  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 2.6150  Validation loss = 3.5204  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 2.6145  Validation loss = 3.5180  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 2.6142  Validation loss = 3.5179  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 2.6140  Validation loss = 3.5174  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 2.6135  Validation loss = 3.5146  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 2.6132  Validation loss = 3.5138  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 2.6129  Validation loss = 3.5114  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 2.6125  Validation loss = 3.5080  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 2.6123  Validation loss = 3.5074  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 2.6119  Validation loss = 3.5066  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 2.6115  Validation loss = 3.5074  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 2.6110  Validation loss = 3.5082  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 2.6107  Validation loss = 3.5081  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 2.6105  Validation loss = 3.5068  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 2.6102  Validation loss = 3.5070  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 2.6101  Validation loss = 3.5065  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 2.6095  Validation loss = 3.5057  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 2.6092  Validation loss = 3.5044  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 2.6087  Validation loss = 3.5036  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 2.6083  Validation loss = 3.5026  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 2.6079  Validation loss = 3.5024  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 2.6076  Validation loss = 3.5003  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 2.6071  Validation loss = 3.4969  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 2.6069  Validation loss = 3.4966  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 2.6067  Validation loss = 3.4969  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 2.6063  Validation loss = 3.4958  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 2.6058  Validation loss = 3.4941  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 2.6055  Validation loss = 3.4939  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 2.6053  Validation loss = 3.4938  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 2.6049  Validation loss = 3.4924  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 2.6046  Validation loss = 3.4932  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 2.6043  Validation loss = 3.4915  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 2.6041  Validation loss = 3.4901  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 2.6037  Validation loss = 3.4901  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 2.6034  Validation loss = 3.4885  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 2.6030  Validation loss = 3.4862  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 2.6028  Validation loss = 3.4862  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 2.6026  Validation loss = 3.4856  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 2.6025  Validation loss = 3.4852  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 2.6022  Validation loss = 3.4847  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 2.6018  Validation loss = 3.4836  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 2.6014  Validation loss = 3.4842  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 2.6011  Validation loss = 3.4822  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 2.6007  Validation loss = 3.4807  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 2.6004  Validation loss = 3.4794  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 2.5999  Validation loss = 3.4787  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 2.5996  Validation loss = 3.4786  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 2.5992  Validation loss = 3.4774  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 2.5988  Validation loss = 3.4767  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 2.5985  Validation loss = 3.4756  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 2.5983  Validation loss = 3.4768  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 2.5981  Validation loss = 3.4761  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 2.5976  Validation loss = 3.4746  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 2.5973  Validation loss = 3.4751  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 2.5971  Validation loss = 3.4752  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 2.5968  Validation loss = 3.4752  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 2.5966  Validation loss = 3.4733  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 2.5962  Validation loss = 3.4709  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 2.5958  Validation loss = 3.4694  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 2.5953  Validation loss = 3.4671  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 2.5950  Validation loss = 3.4669  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 2.5948  Validation loss = 3.4673  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 2.5946  Validation loss = 3.4670  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 2.5942  Validation loss = 3.4648  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 2.5939  Validation loss = 3.4656  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 2.5935  Validation loss = 3.4648  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 2.5933  Validation loss = 3.4643  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 2.5931  Validation loss = 3.4632  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 2.5925  Validation loss = 3.4607  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 2.5922  Validation loss = 3.4585  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 2.5918  Validation loss = 3.4576  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 2.5918  Validation loss = 3.4588  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 2.5913  Validation loss = 3.4556  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 2.5911  Validation loss = 3.4572  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 2.5909  Validation loss = 3.4567  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 2.5905  Validation loss = 3.4576  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 2.5903  Validation loss = 3.4575  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 2.5898  Validation loss = 3.4559  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 2.5896  Validation loss = 3.4553  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 2.5891  Validation loss = 3.4533  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 2.5885  Validation loss = 3.4501  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 2.5882  Validation loss = 3.4495  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 2.5879  Validation loss = 3.4497  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 2.5876  Validation loss = 3.4502  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 2.5871  Validation loss = 3.4490  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 2.5867  Validation loss = 3.4462  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 2.5864  Validation loss = 3.4449  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 2.5863  Validation loss = 3.4451  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 2.5859  Validation loss = 3.4423  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 2.5856  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 2.5852  Validation loss = 3.4415  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 2.5847  Validation loss = 3.4414  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 2.5844  Validation loss = 3.4404  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 2.5843  Validation loss = 3.4393  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 2.5839  Validation loss = 3.4384  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 2.5836  Validation loss = 3.4375  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 2.5834  Validation loss = 3.4372  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 2.5830  Validation loss = 3.4361  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 2.5827  Validation loss = 3.4351  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 2.5824  Validation loss = 3.4364  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 2.5821  Validation loss = 3.4351  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 2.5819  Validation loss = 3.4351  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 2.5816  Validation loss = 3.4347  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 2.5812  Validation loss = 3.4322  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 2.5810  Validation loss = 3.4322  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 2.5807  Validation loss = 3.4319  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 2.5803  Validation loss = 3.4313  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 2.5799  Validation loss = 3.4306  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 2.5794  Validation loss = 3.4297  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 2.5791  Validation loss = 3.4281  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 2.5787  Validation loss = 3.4261  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 2.5784  Validation loss = 3.4228  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 2.5781  Validation loss = 3.4217  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 2.5780  Validation loss = 3.4228  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 2.5776  Validation loss = 3.4212  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 2.5774  Validation loss = 3.4207  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 2.5769  Validation loss = 3.4195  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 2.5766  Validation loss = 3.4193  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 2.5763  Validation loss = 3.4191  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 2.5761  Validation loss = 3.4181  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 2.5758  Validation loss = 3.4183  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 2.5754  Validation loss = 3.4168  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 2.5751  Validation loss = 3.4159  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 2.5746  Validation loss = 3.4147  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 2.5743  Validation loss = 3.4146  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 2.5740  Validation loss = 3.4126  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 2.5736  Validation loss = 3.4114  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 2.5733  Validation loss = 3.4092  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 2.5728  Validation loss = 3.4080  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 2.5725  Validation loss = 3.4067  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 2.5723  Validation loss = 3.4068  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 2.5720  Validation loss = 3.4061  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 2.5715  Validation loss = 3.4045  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 2.5712  Validation loss = 3.4041  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 2.5710  Validation loss = 3.4054  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 2.5704  Validation loss = 3.4016  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 2.5701  Validation loss = 3.4006  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 2.5699  Validation loss = 3.4004  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 2.5695  Validation loss = 3.4006  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 2.5691  Validation loss = 3.4013  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 2.5687  Validation loss = 3.4001  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 2.5684  Validation loss = 3.3992  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 2.5681  Validation loss = 3.3999  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 2.5679  Validation loss = 3.3993  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 2.5675  Validation loss = 3.3982  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 2.5673  Validation loss = 3.3969  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 2.5671  Validation loss = 3.3964  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 2.5669  Validation loss = 3.3961  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 2.5664  Validation loss = 3.3940  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 2.5662  Validation loss = 3.3942  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 2.5657  Validation loss = 3.3922  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 2.5651  Validation loss = 3.3889  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 2.5648  Validation loss = 3.3877  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 2.5644  Validation loss = 3.3862  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 2.5642  Validation loss = 3.3863  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 2.5638  Validation loss = 3.3853  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 2.5635  Validation loss = 3.3834  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 2.5631  Validation loss = 3.3832  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 2.5628  Validation loss = 3.3834  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 2.5625  Validation loss = 3.3818  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 2.5621  Validation loss = 3.3805  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 2.5619  Validation loss = 3.3810  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 2.5616  Validation loss = 3.3797  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 2.5613  Validation loss = 3.3788  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 2.5611  Validation loss = 3.3775  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 2.5608  Validation loss = 3.3760  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 2.5604  Validation loss = 3.3747  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 2.5601  Validation loss = 3.3730  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 2.5599  Validation loss = 3.3734  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 2.5596  Validation loss = 3.3732  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 2.5592  Validation loss = 3.3732  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 2.5587  Validation loss = 3.3738  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 2.5584  Validation loss = 3.3728  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 2.5580  Validation loss = 3.3730  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 2.5578  Validation loss = 3.3728  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 2.5575  Validation loss = 3.3720  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 2.5572  Validation loss = 3.3711  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 2.5570  Validation loss = 3.3705  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 2.5565  Validation loss = 3.3676  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 2.5563  Validation loss = 3.3671  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 2.5559  Validation loss = 3.3663  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 2.5555  Validation loss = 3.3657  \n",
      "\n",
      "Fold: 10  Epoch: 501  Training loss = 2.5554  Validation loss = 3.3655  \n",
      "\n",
      "Fold: 10  Epoch: 502  Training loss = 2.5552  Validation loss = 3.3655  \n",
      "\n",
      "Fold: 10  Epoch: 503  Training loss = 2.5548  Validation loss = 3.3640  \n",
      "\n",
      "Fold: 10  Epoch: 504  Training loss = 2.5544  Validation loss = 3.3621  \n",
      "\n",
      "Fold: 10  Epoch: 505  Training loss = 2.5540  Validation loss = 3.3604  \n",
      "\n",
      "Fold: 10  Epoch: 506  Training loss = 2.5538  Validation loss = 3.3607  \n",
      "\n",
      "Fold: 10  Epoch: 507  Training loss = 2.5535  Validation loss = 3.3594  \n",
      "\n",
      "Fold: 10  Epoch: 508  Training loss = 2.5532  Validation loss = 3.3582  \n",
      "\n",
      "Fold: 10  Epoch: 509  Training loss = 2.5529  Validation loss = 3.3586  \n",
      "\n",
      "Fold: 10  Epoch: 510  Training loss = 2.5525  Validation loss = 3.3583  \n",
      "\n",
      "Fold: 10  Epoch: 511  Training loss = 2.5524  Validation loss = 3.3590  \n",
      "\n",
      "Fold: 10  Epoch: 512  Training loss = 2.5521  Validation loss = 3.3585  \n",
      "\n",
      "Fold: 10  Epoch: 513  Training loss = 2.5519  Validation loss = 3.3586  \n",
      "\n",
      "Fold: 10  Epoch: 514  Training loss = 2.5514  Validation loss = 3.3575  \n",
      "\n",
      "Fold: 10  Epoch: 515  Training loss = 2.5511  Validation loss = 3.3565  \n",
      "\n",
      "Fold: 10  Epoch: 516  Training loss = 2.5507  Validation loss = 3.3547  \n",
      "\n",
      "Fold: 10  Epoch: 517  Training loss = 2.5504  Validation loss = 3.3542  \n",
      "\n",
      "Fold: 10  Epoch: 518  Training loss = 2.5502  Validation loss = 3.3541  \n",
      "\n",
      "Fold: 10  Epoch: 519  Training loss = 2.5498  Validation loss = 3.3536  \n",
      "\n",
      "Fold: 10  Epoch: 520  Training loss = 2.5494  Validation loss = 3.3517  \n",
      "\n",
      "Fold: 10  Epoch: 521  Training loss = 2.5492  Validation loss = 3.3517  \n",
      "\n",
      "Fold: 10  Epoch: 522  Training loss = 2.5488  Validation loss = 3.3505  \n",
      "\n",
      "Fold: 10  Epoch: 523  Training loss = 2.5484  Validation loss = 3.3492  \n",
      "\n",
      "Fold: 10  Epoch: 524  Training loss = 2.5482  Validation loss = 3.3490  \n",
      "\n",
      "Fold: 10  Epoch: 525  Training loss = 2.5480  Validation loss = 3.3474  \n",
      "\n",
      "Fold: 10  Epoch: 526  Training loss = 2.5477  Validation loss = 3.3473  \n",
      "\n",
      "Fold: 10  Epoch: 527  Training loss = 2.5477  Validation loss = 3.3476  \n",
      "\n",
      "Fold: 10  Epoch: 528  Training loss = 2.5475  Validation loss = 3.3462  \n",
      "\n",
      "Fold: 10  Epoch: 529  Training loss = 2.5470  Validation loss = 3.3435  \n",
      "\n",
      "Fold: 10  Epoch: 530  Training loss = 2.5467  Validation loss = 3.3433  \n",
      "\n",
      "Fold: 10  Epoch: 531  Training loss = 2.5464  Validation loss = 3.3427  \n",
      "\n",
      "Fold: 10  Epoch: 532  Training loss = 2.5461  Validation loss = 3.3421  \n",
      "\n",
      "Fold: 10  Epoch: 533  Training loss = 2.5457  Validation loss = 3.3414  \n",
      "\n",
      "Fold: 10  Epoch: 534  Training loss = 2.5453  Validation loss = 3.3401  \n",
      "\n",
      "Fold: 10  Epoch: 535  Training loss = 2.5449  Validation loss = 3.3402  \n",
      "\n",
      "Fold: 10  Epoch: 536  Training loss = 2.5447  Validation loss = 3.3404  \n",
      "\n",
      "Fold: 10  Epoch: 537  Training loss = 2.5444  Validation loss = 3.3399  \n",
      "\n",
      "Fold: 10  Epoch: 538  Training loss = 2.5441  Validation loss = 3.3386  \n",
      "\n",
      "Fold: 10  Epoch: 539  Training loss = 2.5437  Validation loss = 3.3376  \n",
      "\n",
      "Fold: 10  Epoch: 540  Training loss = 2.5434  Validation loss = 3.3366  \n",
      "\n",
      "Fold: 10  Epoch: 541  Training loss = 2.5431  Validation loss = 3.3362  \n",
      "\n",
      "Fold: 10  Epoch: 542  Training loss = 2.5427  Validation loss = 3.3339  \n",
      "\n",
      "Fold: 10  Epoch: 543  Training loss = 2.5425  Validation loss = 3.3343  \n",
      "\n",
      "Fold: 10  Epoch: 544  Training loss = 2.5423  Validation loss = 3.3336  \n",
      "\n",
      "Fold: 10  Epoch: 545  Training loss = 2.5419  Validation loss = 3.3323  \n",
      "\n",
      "Fold: 10  Epoch: 546  Training loss = 2.5415  Validation loss = 3.3306  \n",
      "\n",
      "Fold: 10  Epoch: 547  Training loss = 2.5413  Validation loss = 3.3301  \n",
      "\n",
      "Fold: 10  Epoch: 548  Training loss = 2.5410  Validation loss = 3.3292  \n",
      "\n",
      "Fold: 10  Epoch: 549  Training loss = 2.5408  Validation loss = 3.3296  \n",
      "\n",
      "Fold: 10  Epoch: 550  Training loss = 2.5406  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 10  Epoch: 551  Training loss = 2.5405  Validation loss = 3.3291  \n",
      "\n",
      "Fold: 10  Epoch: 552  Training loss = 2.5400  Validation loss = 3.3278  \n",
      "\n",
      "Fold: 10  Epoch: 553  Training loss = 2.5397  Validation loss = 3.3279  \n",
      "\n",
      "Fold: 10  Epoch: 554  Training loss = 2.5394  Validation loss = 3.3279  \n",
      "\n",
      "Fold: 10  Epoch: 555  Training loss = 2.5390  Validation loss = 3.3272  \n",
      "\n",
      "Fold: 10  Epoch: 556  Training loss = 2.5388  Validation loss = 3.3265  \n",
      "\n",
      "Fold: 10  Epoch: 557  Training loss = 2.5384  Validation loss = 3.3243  \n",
      "\n",
      "Fold: 10  Epoch: 558  Training loss = 2.5381  Validation loss = 3.3249  \n",
      "\n",
      "Fold: 10  Epoch: 559  Training loss = 2.5378  Validation loss = 3.3236  \n",
      "\n",
      "Fold: 10  Epoch: 560  Training loss = 2.5373  Validation loss = 3.3207  \n",
      "\n",
      "Fold: 10  Epoch: 561  Training loss = 2.5371  Validation loss = 3.3203  \n",
      "\n",
      "Fold: 10  Epoch: 562  Training loss = 2.5367  Validation loss = 3.3197  \n",
      "\n",
      "Fold: 10  Epoch: 563  Training loss = 2.5365  Validation loss = 3.3198  \n",
      "\n",
      "Fold: 10  Epoch: 564  Training loss = 2.5361  Validation loss = 3.3192  \n",
      "\n",
      "Fold: 10  Epoch: 565  Training loss = 2.5356  Validation loss = 3.3167  \n",
      "\n",
      "Fold: 10  Epoch: 566  Training loss = 2.5352  Validation loss = 3.3146  \n",
      "\n",
      "Fold: 10  Epoch: 567  Training loss = 2.5346  Validation loss = 3.3127  \n",
      "\n",
      "Fold: 10  Epoch: 568  Training loss = 2.5340  Validation loss = 3.3113  \n",
      "\n",
      "Fold: 10  Epoch: 569  Training loss = 2.5337  Validation loss = 3.3104  \n",
      "\n",
      "Fold: 10  Epoch: 570  Training loss = 2.5333  Validation loss = 3.3083  \n",
      "\n",
      "Fold: 10  Epoch: 571  Training loss = 2.5327  Validation loss = 3.3065  \n",
      "\n",
      "Fold: 10  Epoch: 572  Training loss = 2.5324  Validation loss = 3.3056  \n",
      "\n",
      "Fold: 10  Epoch: 573  Training loss = 2.5323  Validation loss = 3.3062  \n",
      "\n",
      "Fold: 10  Epoch: 574  Training loss = 2.5319  Validation loss = 3.3051  \n",
      "\n",
      "Fold: 10  Epoch: 575  Training loss = 2.5317  Validation loss = 3.3042  \n",
      "\n",
      "Fold: 10  Epoch: 576  Training loss = 2.5312  Validation loss = 3.3026  \n",
      "\n",
      "Fold: 10  Epoch: 577  Training loss = 2.5310  Validation loss = 3.3027  \n",
      "\n",
      "Fold: 10  Epoch: 578  Training loss = 2.5307  Validation loss = 3.3022  \n",
      "\n",
      "Fold: 10  Epoch: 579  Training loss = 2.5303  Validation loss = 3.3007  \n",
      "\n",
      "Fold: 10  Epoch: 580  Training loss = 2.5298  Validation loss = 3.2998  \n",
      "\n",
      "Fold: 10  Epoch: 581  Training loss = 2.5295  Validation loss = 3.2992  \n",
      "\n",
      "Fold: 10  Epoch: 582  Training loss = 2.5293  Validation loss = 3.2988  \n",
      "\n",
      "Fold: 10  Epoch: 583  Training loss = 2.5288  Validation loss = 3.2974  \n",
      "\n",
      "Fold: 10  Epoch: 584  Training loss = 2.5284  Validation loss = 3.2958  \n",
      "\n",
      "Fold: 10  Epoch: 585  Training loss = 2.5282  Validation loss = 3.2964  \n",
      "\n",
      "Fold: 10  Epoch: 586  Training loss = 2.5278  Validation loss = 3.2958  \n",
      "\n",
      "Fold: 10  Epoch: 587  Training loss = 2.5274  Validation loss = 3.2941  \n",
      "\n",
      "Fold: 10  Epoch: 588  Training loss = 2.5274  Validation loss = 3.2946  \n",
      "\n",
      "Fold: 10  Epoch: 589  Training loss = 2.5270  Validation loss = 3.2932  \n",
      "\n",
      "Fold: 10  Epoch: 590  Training loss = 2.5265  Validation loss = 3.2909  \n",
      "\n",
      "Fold: 10  Epoch: 591  Training loss = 2.5261  Validation loss = 3.2900  \n",
      "\n",
      "Fold: 10  Epoch: 592  Training loss = 2.5256  Validation loss = 3.2888  \n",
      "\n",
      "Fold: 10  Epoch: 593  Training loss = 2.5251  Validation loss = 3.2869  \n",
      "\n",
      "Fold: 10  Epoch: 594  Training loss = 2.5246  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 10  Epoch: 595  Training loss = 2.5243  Validation loss = 3.2846  \n",
      "\n",
      "Fold: 10  Epoch: 596  Training loss = 2.5241  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 10  Epoch: 597  Training loss = 2.5238  Validation loss = 3.2844  \n",
      "\n",
      "Fold: 10  Epoch: 598  Training loss = 2.5235  Validation loss = 3.2826  \n",
      "\n",
      "Fold: 10  Epoch: 599  Training loss = 2.5233  Validation loss = 3.2823  \n",
      "\n",
      "Fold: 10  Epoch: 600  Training loss = 2.5230  Validation loss = 3.2810  \n",
      "\n",
      "Fold: 10  Epoch: 601  Training loss = 2.5228  Validation loss = 3.2822  \n",
      "\n",
      "Fold: 10  Epoch: 602  Training loss = 2.5223  Validation loss = 3.2804  \n",
      "\n",
      "Fold: 10  Epoch: 603  Training loss = 2.5219  Validation loss = 3.2792  \n",
      "\n",
      "Fold: 10  Epoch: 604  Training loss = 2.5217  Validation loss = 3.2785  \n",
      "\n",
      "Fold: 10  Epoch: 605  Training loss = 2.5212  Validation loss = 3.2764  \n",
      "\n",
      "Fold: 10  Epoch: 606  Training loss = 2.5210  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 10  Epoch: 607  Training loss = 2.5207  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 10  Epoch: 608  Training loss = 2.5204  Validation loss = 3.2751  \n",
      "\n",
      "Fold: 10  Epoch: 609  Training loss = 2.5200  Validation loss = 3.2734  \n",
      "\n",
      "Fold: 10  Epoch: 610  Training loss = 2.5197  Validation loss = 3.2720  \n",
      "\n",
      "Fold: 10  Epoch: 611  Training loss = 2.5193  Validation loss = 3.2702  \n",
      "\n",
      "Fold: 10  Epoch: 612  Training loss = 2.5192  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 10  Epoch: 613  Training loss = 2.5188  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 10  Epoch: 614  Training loss = 2.5185  Validation loss = 3.2709  \n",
      "\n",
      "Fold: 10  Epoch: 615  Training loss = 2.5182  Validation loss = 3.2709  \n",
      "\n",
      "Fold: 10  Epoch: 616  Training loss = 2.5178  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 10  Epoch: 617  Training loss = 2.5174  Validation loss = 3.2686  \n",
      "\n",
      "Fold: 10  Epoch: 618  Training loss = 2.5173  Validation loss = 3.2692  \n",
      "\n",
      "Fold: 10  Epoch: 619  Training loss = 2.5170  Validation loss = 3.2684  \n",
      "\n",
      "Fold: 10  Epoch: 620  Training loss = 2.5165  Validation loss = 3.2672  \n",
      "\n",
      "Fold: 10  Epoch: 621  Training loss = 2.5163  Validation loss = 3.2665  \n",
      "\n",
      "Fold: 10  Epoch: 622  Training loss = 2.5159  Validation loss = 3.2650  \n",
      "\n",
      "Fold: 10  Epoch: 623  Training loss = 2.5155  Validation loss = 3.2640  \n",
      "\n",
      "Fold: 10  Epoch: 624  Training loss = 2.5154  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 10  Epoch: 625  Training loss = 2.5150  Validation loss = 3.2628  \n",
      "\n",
      "Fold: 10  Epoch: 626  Training loss = 2.5147  Validation loss = 3.2623  \n",
      "\n",
      "Fold: 10  Epoch: 627  Training loss = 2.5146  Validation loss = 3.2621  \n",
      "\n",
      "Fold: 10  Epoch: 628  Training loss = 2.5142  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 10  Epoch: 629  Training loss = 2.5139  Validation loss = 3.2601  \n",
      "\n",
      "Fold: 10  Epoch: 630  Training loss = 2.5136  Validation loss = 3.2591  \n",
      "\n",
      "Fold: 10  Epoch: 631  Training loss = 2.5131  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 10  Epoch: 632  Training loss = 2.5127  Validation loss = 3.2577  \n",
      "\n",
      "Fold: 10  Epoch: 633  Training loss = 2.5123  Validation loss = 3.2572  \n",
      "\n",
      "Fold: 10  Epoch: 634  Training loss = 2.5121  Validation loss = 3.2569  \n",
      "\n",
      "Fold: 10  Epoch: 635  Training loss = 2.5116  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 10  Epoch: 636  Training loss = 2.5114  Validation loss = 3.2550  \n",
      "\n",
      "Fold: 10  Epoch: 637  Training loss = 2.5112  Validation loss = 3.2544  \n",
      "\n",
      "Fold: 10  Epoch: 638  Training loss = 2.5108  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 10  Epoch: 639  Training loss = 2.5105  Validation loss = 3.2531  \n",
      "\n",
      "Fold: 10  Epoch: 640  Training loss = 2.5102  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 10  Epoch: 641  Training loss = 2.5100  Validation loss = 3.2523  \n",
      "\n",
      "Fold: 10  Epoch: 642  Training loss = 2.5097  Validation loss = 3.2520  \n",
      "\n",
      "Fold: 10  Epoch: 643  Training loss = 2.5091  Validation loss = 3.2502  \n",
      "\n",
      "Fold: 10  Epoch: 644  Training loss = 2.5087  Validation loss = 3.2486  \n",
      "\n",
      "Fold: 10  Epoch: 645  Training loss = 2.5086  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 10  Epoch: 646  Training loss = 2.5080  Validation loss = 3.2461  \n",
      "\n",
      "Fold: 10  Epoch: 647  Training loss = 2.5078  Validation loss = 3.2457  \n",
      "\n",
      "Fold: 10  Epoch: 648  Training loss = 2.5076  Validation loss = 3.2454  \n",
      "\n",
      "Fold: 10  Epoch: 649  Training loss = 2.5074  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 10  Epoch: 650  Training loss = 2.5071  Validation loss = 3.2440  \n",
      "\n",
      "Fold: 10  Epoch: 651  Training loss = 2.5069  Validation loss = 3.2441  \n",
      "\n",
      "Fold: 10  Epoch: 652  Training loss = 2.5067  Validation loss = 3.2443  \n",
      "\n",
      "Fold: 10  Epoch: 653  Training loss = 2.5064  Validation loss = 3.2428  \n",
      "\n",
      "Fold: 10  Epoch: 654  Training loss = 2.5061  Validation loss = 3.2426  \n",
      "\n",
      "Fold: 10  Epoch: 655  Training loss = 2.5059  Validation loss = 3.2429  \n",
      "\n",
      "Fold: 10  Epoch: 656  Training loss = 2.5056  Validation loss = 3.2425  \n",
      "\n",
      "Fold: 10  Epoch: 657  Training loss = 2.5053  Validation loss = 3.2410  \n",
      "\n",
      "Fold: 10  Epoch: 658  Training loss = 2.5050  Validation loss = 3.2405  \n",
      "\n",
      "Fold: 10  Epoch: 659  Training loss = 2.5047  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 10  Epoch: 660  Training loss = 2.5043  Validation loss = 3.2390  \n",
      "\n",
      "Fold: 10  Epoch: 661  Training loss = 2.5040  Validation loss = 3.2386  \n",
      "\n",
      "Fold: 10  Epoch: 662  Training loss = 2.5036  Validation loss = 3.2371  \n",
      "\n",
      "Fold: 10  Epoch: 663  Training loss = 2.5033  Validation loss = 3.2361  \n",
      "\n",
      "Fold: 10  Epoch: 664  Training loss = 2.5031  Validation loss = 3.2357  \n",
      "\n",
      "Fold: 10  Epoch: 665  Training loss = 2.5028  Validation loss = 3.2349  \n",
      "\n",
      "Fold: 10  Epoch: 666  Training loss = 2.5025  Validation loss = 3.2333  \n",
      "\n",
      "Fold: 10  Epoch: 667  Training loss = 2.5022  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 10  Epoch: 668  Training loss = 2.5019  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 10  Epoch: 669  Training loss = 2.5015  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 10  Epoch: 670  Training loss = 2.5014  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 10  Epoch: 671  Training loss = 2.5010  Validation loss = 3.2300  \n",
      "\n",
      "Fold: 10  Epoch: 672  Training loss = 2.5006  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 10  Epoch: 673  Training loss = 2.5001  Validation loss = 3.2271  \n",
      "\n",
      "Fold: 10  Epoch: 674  Training loss = 2.4999  Validation loss = 3.2270  \n",
      "\n",
      "Fold: 10  Epoch: 675  Training loss = 2.4996  Validation loss = 3.2263  \n",
      "\n",
      "Fold: 10  Epoch: 676  Training loss = 2.4994  Validation loss = 3.2248  \n",
      "\n",
      "Fold: 10  Epoch: 677  Training loss = 2.4992  Validation loss = 3.2256  \n",
      "\n",
      "Fold: 10  Epoch: 678  Training loss = 2.4988  Validation loss = 3.2253  \n",
      "\n",
      "Fold: 10  Epoch: 679  Training loss = 2.4985  Validation loss = 3.2249  \n",
      "\n",
      "Fold: 10  Epoch: 680  Training loss = 2.4981  Validation loss = 3.2237  \n",
      "\n",
      "Fold: 10  Epoch: 681  Training loss = 2.4978  Validation loss = 3.2227  \n",
      "\n",
      "Fold: 10  Epoch: 682  Training loss = 2.4973  Validation loss = 3.2193  \n",
      "\n",
      "Fold: 10  Epoch: 683  Training loss = 2.4970  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 10  Epoch: 684  Training loss = 2.4968  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 10  Epoch: 685  Training loss = 2.4966  Validation loss = 3.2149  \n",
      "\n",
      "Fold: 10  Epoch: 686  Training loss = 2.4961  Validation loss = 3.2131  \n",
      "\n",
      "Fold: 10  Epoch: 687  Training loss = 2.4957  Validation loss = 3.2110  \n",
      "\n",
      "Fold: 10  Epoch: 688  Training loss = 2.4955  Validation loss = 3.2106  \n",
      "\n",
      "Fold: 10  Epoch: 689  Training loss = 2.4951  Validation loss = 3.2100  \n",
      "\n",
      "Fold: 10  Epoch: 690  Training loss = 2.4947  Validation loss = 3.2096  \n",
      "\n",
      "Fold: 10  Epoch: 691  Training loss = 2.4943  Validation loss = 3.2081  \n",
      "\n",
      "Fold: 10  Epoch: 692  Training loss = 2.4940  Validation loss = 3.2085  \n",
      "\n",
      "Fold: 10  Epoch: 693  Training loss = 2.4937  Validation loss = 3.2092  \n",
      "\n",
      "Fold: 10  Epoch: 694  Training loss = 2.4934  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 10  Epoch: 695  Training loss = 2.4929  Validation loss = 3.2074  \n",
      "\n",
      "Fold: 10  Epoch: 696  Training loss = 2.4925  Validation loss = 3.2076  \n",
      "\n",
      "Fold: 10  Epoch: 697  Training loss = 2.4922  Validation loss = 3.2064  \n",
      "\n",
      "Fold: 10  Epoch: 698  Training loss = 2.4919  Validation loss = 3.2068  \n",
      "\n",
      "Fold: 10  Epoch: 699  Training loss = 2.4917  Validation loss = 3.2063  \n",
      "\n",
      "Fold: 10  Epoch: 700  Training loss = 2.4916  Validation loss = 3.2070  \n",
      "\n",
      "Fold: 10  Epoch: 701  Training loss = 2.4912  Validation loss = 3.2054  \n",
      "\n",
      "Fold: 10  Epoch: 702  Training loss = 2.4910  Validation loss = 3.2057  \n",
      "\n",
      "Fold: 10  Epoch: 703  Training loss = 2.4908  Validation loss = 3.2053  \n",
      "\n",
      "Fold: 10  Epoch: 704  Training loss = 2.4906  Validation loss = 3.2042  \n",
      "\n",
      "Fold: 10  Epoch: 705  Training loss = 2.4904  Validation loss = 3.2053  \n",
      "\n",
      "Fold: 10  Epoch: 706  Training loss = 2.4900  Validation loss = 3.2039  \n",
      "\n",
      "Fold: 10  Epoch: 707  Training loss = 2.4899  Validation loss = 3.2046  \n",
      "\n",
      "Fold: 10  Epoch: 708  Training loss = 2.4897  Validation loss = 3.2049  \n",
      "\n",
      "Fold: 10  Epoch: 709  Training loss = 2.4894  Validation loss = 3.2038  \n",
      "\n",
      "Fold: 10  Epoch: 710  Training loss = 2.4891  Validation loss = 3.2036  \n",
      "\n",
      "Fold: 10  Epoch: 711  Training loss = 2.4887  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 10  Epoch: 712  Training loss = 2.4885  Validation loss = 3.2038  \n",
      "\n",
      "Fold: 10  Epoch: 713  Training loss = 2.4883  Validation loss = 3.2037  \n",
      "\n",
      "Fold: 10  Epoch: 714  Training loss = 2.4879  Validation loss = 3.2021  \n",
      "\n",
      "Fold: 10  Epoch: 715  Training loss = 2.4876  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 10  Epoch: 716  Training loss = 2.4874  Validation loss = 3.2017  \n",
      "\n",
      "Fold: 10  Epoch: 717  Training loss = 2.4872  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 10  Epoch: 718  Training loss = 2.4869  Validation loss = 3.1986  \n",
      "\n",
      "Fold: 10  Epoch: 719  Training loss = 2.4868  Validation loss = 3.1987  \n",
      "\n",
      "Fold: 10  Epoch: 720  Training loss = 2.4864  Validation loss = 3.1954  \n",
      "\n",
      "Fold: 10  Epoch: 721  Training loss = 2.4861  Validation loss = 3.1952  \n",
      "\n",
      "Fold: 10  Epoch: 722  Training loss = 2.4857  Validation loss = 3.1920  \n",
      "\n",
      "Fold: 10  Epoch: 723  Training loss = 2.4854  Validation loss = 3.1897  \n",
      "\n",
      "Fold: 10  Epoch: 724  Training loss = 2.4852  Validation loss = 3.1882  \n",
      "\n",
      "Fold: 10  Epoch: 725  Training loss = 2.4849  Validation loss = 3.1869  \n",
      "\n",
      "Fold: 10  Epoch: 726  Training loss = 2.4846  Validation loss = 3.1800  \n",
      "\n",
      "Fold: 10  Epoch: 727  Training loss = 2.4842  Validation loss = 3.1837  \n",
      "\n",
      "Fold: 10  Epoch: 728  Training loss = 2.4837  Validation loss = 3.1846  \n",
      "\n",
      "Fold: 10  Epoch: 729  Training loss = 2.4832  Validation loss = 3.1843  \n",
      "\n",
      "Fold: 10  Epoch: 730  Training loss = 2.4827  Validation loss = 3.1829  \n",
      "\n",
      "Fold: 10  Epoch: 731  Training loss = 2.4823  Validation loss = 3.1805  \n",
      "\n",
      "Fold: 10  Epoch: 732  Training loss = 2.4819  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 10  Epoch: 733  Training loss = 2.4815  Validation loss = 3.1816  \n",
      "\n",
      "Fold: 10  Epoch: 734  Training loss = 2.4813  Validation loss = 3.1833  \n",
      "\n",
      "Fold: 10  Epoch: 735  Training loss = 2.4811  Validation loss = 3.1812  \n",
      "\n",
      "Fold: 10  Epoch: 736  Training loss = 2.4808  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 10  Epoch: 737  Training loss = 2.4804  Validation loss = 3.1809  \n",
      "\n",
      "Fold: 10  Epoch: 738  Training loss = 2.4802  Validation loss = 3.1805  \n",
      "\n",
      "Fold: 10  Epoch: 739  Training loss = 2.4797  Validation loss = 3.1791  \n",
      "\n",
      "Fold: 10  Epoch: 740  Training loss = 2.4795  Validation loss = 3.1794  \n",
      "\n",
      "Fold: 10  Epoch: 741  Training loss = 2.4791  Validation loss = 3.1782  \n",
      "\n",
      "Fold: 10  Epoch: 742  Training loss = 2.4787  Validation loss = 3.1780  \n",
      "\n",
      "Fold: 10  Epoch: 743  Training loss = 2.4783  Validation loss = 3.1770  \n",
      "\n",
      "Fold: 10  Epoch: 744  Training loss = 2.4781  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 10  Epoch: 745  Training loss = 2.4777  Validation loss = 3.1754  \n",
      "\n",
      "Fold: 10  Epoch: 746  Training loss = 2.4775  Validation loss = 3.1758  \n",
      "\n",
      "Fold: 10  Epoch: 747  Training loss = 2.4773  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 10  Epoch: 748  Training loss = 2.4771  Validation loss = 3.1747  \n",
      "\n",
      "Fold: 10  Epoch: 749  Training loss = 2.4768  Validation loss = 3.1722  \n",
      "\n",
      "Fold: 10  Epoch: 750  Training loss = 2.4766  Validation loss = 3.1710  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 750  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 2.5578  Validation loss = 1.2131  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 2.5371  Validation loss = 1.2121  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 2.5366  Validation loss = 1.2114  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 2.5362  Validation loss = 1.2109  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 2.5358  Validation loss = 1.2104  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 2.5356  Validation loss = 1.2103  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 2.5353  Validation loss = 1.2100  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 2.5348  Validation loss = 1.2092  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 2.5345  Validation loss = 1.2090  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 2.5340  Validation loss = 1.2082  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 2.5335  Validation loss = 1.2076  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 2.5332  Validation loss = 1.2072  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 2.5328  Validation loss = 1.2065  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 2.5324  Validation loss = 1.2058  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 2.5318  Validation loss = 1.2051  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 2.5312  Validation loss = 1.2040  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 2.5310  Validation loss = 1.2038  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 2.5306  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 2.5303  Validation loss = 1.2031  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 2.5298  Validation loss = 1.2026  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 2.5294  Validation loss = 1.2023  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 2.5291  Validation loss = 1.2018  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 2.5287  Validation loss = 1.2014  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 2.5280  Validation loss = 1.2004  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 2.5276  Validation loss = 1.1999  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 2.5272  Validation loss = 1.1995  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 2.5267  Validation loss = 1.1988  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 2.5262  Validation loss = 1.1982  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 2.5259  Validation loss = 1.1980  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 2.5256  Validation loss = 1.1975  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 2.5253  Validation loss = 1.1973  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 2.5248  Validation loss = 1.1966  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 2.5247  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 2.5235  Validation loss = 1.1957  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 2.5174  Validation loss = 1.1951  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 2.5168  Validation loss = 1.1944  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 2.5166  Validation loss = 1.1944  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 2.5162  Validation loss = 1.1939  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 2.5159  Validation loss = 1.1936  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 2.5154  Validation loss = 1.1930  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 2.5151  Validation loss = 1.1927  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 2.5146  Validation loss = 1.1921  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 2.5142  Validation loss = 1.1912  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 2.5140  Validation loss = 1.1909  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 2.5138  Validation loss = 1.1904  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 2.5134  Validation loss = 1.1898  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 2.5131  Validation loss = 1.1894  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 2.5128  Validation loss = 1.1893  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 2.5125  Validation loss = 1.1887  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 2.5121  Validation loss = 1.1887  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 2.5118  Validation loss = 1.1883  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 2.5114  Validation loss = 1.1877  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 2.5112  Validation loss = 1.1877  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 2.5108  Validation loss = 1.1870  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 2.5103  Validation loss = 1.1864  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 2.5098  Validation loss = 1.1854  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 2.5095  Validation loss = 1.1852  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 2.5090  Validation loss = 1.1846  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 2.5084  Validation loss = 1.1835  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 2.5077  Validation loss = 1.1822  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 2.5073  Validation loss = 1.1819  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 2.5068  Validation loss = 1.1811  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 2.5065  Validation loss = 1.1807  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 2.5059  Validation loss = 1.1800  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 2.5057  Validation loss = 1.1797  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 2.5052  Validation loss = 1.1790  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 2.5048  Validation loss = 1.1784  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 2.5044  Validation loss = 1.1778  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 2.5040  Validation loss = 1.1775  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 2.5036  Validation loss = 1.1770  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 2.5033  Validation loss = 1.1766  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 2.5031  Validation loss = 1.1763  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 2.5026  Validation loss = 1.1760  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 2.5022  Validation loss = 1.1754  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 2.5019  Validation loss = 1.1749  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 2.5016  Validation loss = 1.1749  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 2.5013  Validation loss = 1.1743  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 2.5008  Validation loss = 1.1736  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 2.5004  Validation loss = 1.1730  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 2.4999  Validation loss = 1.1722  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 2.4993  Validation loss = 1.1715  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 2.4990  Validation loss = 1.1710  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 2.4986  Validation loss = 1.1705  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 2.4982  Validation loss = 1.1705  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 2.4976  Validation loss = 1.1696  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 2.4971  Validation loss = 1.1689  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 2.4964  Validation loss = 1.1677  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 2.4957  Validation loss = 1.1667  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 2.4952  Validation loss = 1.1661  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 2.4951  Validation loss = 1.1662  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 2.4947  Validation loss = 1.1658  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 2.4943  Validation loss = 1.1652  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 2.4941  Validation loss = 1.1651  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 2.4936  Validation loss = 1.1646  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 2.4932  Validation loss = 1.1642  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 2.4926  Validation loss = 1.1635  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 2.4920  Validation loss = 1.1629  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 2.4916  Validation loss = 1.1624  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 2.4911  Validation loss = 1.1613  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 2.4909  Validation loss = 1.1610  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 2.4904  Validation loss = 1.1604  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 2.4900  Validation loss = 1.1600  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 2.4896  Validation loss = 1.1601  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 2.4892  Validation loss = 1.1597  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 2.4891  Validation loss = 1.1596  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 2.4887  Validation loss = 1.1593  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 2.4885  Validation loss = 1.1591  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 2.4883  Validation loss = 1.1593  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 2.4878  Validation loss = 1.1588  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 2.4874  Validation loss = 1.1585  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 2.4872  Validation loss = 1.1585  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 2.4869  Validation loss = 1.1581  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 2.4863  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 2.4860  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 2.4855  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 2.4853  Validation loss = 1.1565  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 2.4850  Validation loss = 1.1560  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 2.4846  Validation loss = 1.1557  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 2.4843  Validation loss = 1.1556  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 2.4838  Validation loss = 1.1554  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 2.4836  Validation loss = 1.1559  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 2.4829  Validation loss = 1.1549  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 2.4826  Validation loss = 1.1552  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 2.4822  Validation loss = 1.1552  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 2.4819  Validation loss = 1.1545  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 2.4813  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 2.4810  Validation loss = 1.1547  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 2.4807  Validation loss = 1.1543  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 2.4804  Validation loss = 1.1541  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 2.4800  Validation loss = 1.1543  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 2.4797  Validation loss = 1.1547  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 2.4794  Validation loss = 1.1548  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 2.4790  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 2.4784  Validation loss = 1.1538  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 2.4779  Validation loss = 1.1531  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 2.4777  Validation loss = 1.1526  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 2.4775  Validation loss = 1.1525  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 2.4771  Validation loss = 1.1519  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 2.4767  Validation loss = 1.1514  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 2.4764  Validation loss = 1.1517  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 2.4762  Validation loss = 1.1518  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 2.4757  Validation loss = 1.1512  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 2.4754  Validation loss = 1.1509  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 2.4751  Validation loss = 1.1510  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 2.4745  Validation loss = 1.1508  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 2.4742  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 2.4735  Validation loss = 1.1496  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 2.4732  Validation loss = 1.1493  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 2.4728  Validation loss = 1.1496  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 2.4726  Validation loss = 1.1499  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 2.4722  Validation loss = 1.1498  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 2.4718  Validation loss = 1.1493  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 2.4714  Validation loss = 1.1494  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 2.4710  Validation loss = 1.1499  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 2.4706  Validation loss = 1.1497  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 2.4703  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 2.4699  Validation loss = 1.1496  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 2.4697  Validation loss = 1.1500  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 2.4693  Validation loss = 1.1506  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 2.4688  Validation loss = 1.1498  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 2.4683  Validation loss = 1.1496  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 2.4679  Validation loss = 1.1489  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 2.4676  Validation loss = 1.1492  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 2.4671  Validation loss = 1.1495  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 2.4667  Validation loss = 1.1491  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 2.4664  Validation loss = 1.1495  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 2.4659  Validation loss = 1.1482  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 2.4654  Validation loss = 1.1472  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 2.4651  Validation loss = 1.1463  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 2.4647  Validation loss = 1.1462  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 2.4644  Validation loss = 1.1459  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 2.4640  Validation loss = 1.1455  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 2.4639  Validation loss = 1.1461  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 2.4634  Validation loss = 1.1460  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 2.4630  Validation loss = 1.1455  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 2.4627  Validation loss = 1.1457  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 2.4623  Validation loss = 1.1460  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 2.4619  Validation loss = 1.1461  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 2.4613  Validation loss = 1.1464  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 2.4609  Validation loss = 1.1461  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 2.4605  Validation loss = 1.1464  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 2.4603  Validation loss = 1.1468  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 2.4599  Validation loss = 1.1466  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 2.4596  Validation loss = 1.1465  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 2.4592  Validation loss = 1.1474  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 172  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 2.4459  Validation loss = 2.1435  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.4454  Validation loss = 2.1403  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 2.4450  Validation loss = 2.1419  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.4447  Validation loss = 2.1497  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 2.4445  Validation loss = 2.1575  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.4442  Validation loss = 2.1608  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 2.4440  Validation loss = 2.1622  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 2.4437  Validation loss = 2.1781  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.4432  Validation loss = 2.1760  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 2.4430  Validation loss = 2.1824  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 2.4424  Validation loss = 2.1754  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 2.4422  Validation loss = 2.1795  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 2.4416  Validation loss = 2.1835  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 2.4412  Validation loss = 2.1792  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 2.4408  Validation loss = 2.1761  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 2.4402  Validation loss = 2.1678  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 2.4401  Validation loss = 2.1871  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 2  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.4614  Validation loss = 3.8933  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.4610  Validation loss = 3.8924  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.4583  Validation loss = 3.8902  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.4559  Validation loss = 3.8883  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 2.4513  Validation loss = 3.8860  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 2.4506  Validation loss = 3.8851  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 2.4493  Validation loss = 3.8827  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 2.4483  Validation loss = 3.8809  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 2.4476  Validation loss = 3.8795  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 2.4470  Validation loss = 3.8781  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 2.4468  Validation loss = 3.8776  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 2.4461  Validation loss = 3.8758  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.4454  Validation loss = 3.8738  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.4443  Validation loss = 3.8712  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.4437  Validation loss = 3.8697  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.4428  Validation loss = 3.8679  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 2.4425  Validation loss = 3.8670  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 2.4418  Validation loss = 3.8654  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 2.4410  Validation loss = 3.8628  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 2.4405  Validation loss = 3.8615  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 2.4398  Validation loss = 3.8595  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.4395  Validation loss = 3.8586  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.4389  Validation loss = 3.8572  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 2.4383  Validation loss = 3.8556  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.4375  Validation loss = 3.8534  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 2.4374  Validation loss = 3.8530  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 2.4370  Validation loss = 3.8519  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 2.4366  Validation loss = 3.8506  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 2.4358  Validation loss = 3.8481  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 2.4353  Validation loss = 3.8469  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 2.4347  Validation loss = 3.8452  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 2.4341  Validation loss = 3.8433  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 2.4337  Validation loss = 3.8424  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 2.4334  Validation loss = 3.8414  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 2.4329  Validation loss = 3.8400  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 2.4324  Validation loss = 3.8387  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 2.4320  Validation loss = 3.8374  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 2.4314  Validation loss = 3.8358  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 2.4310  Validation loss = 3.8344  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 2.4303  Validation loss = 3.8324  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 2.4299  Validation loss = 3.8311  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 2.4296  Validation loss = 3.8304  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 2.4294  Validation loss = 3.8298  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 2.4289  Validation loss = 3.8283  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 2.4282  Validation loss = 3.8258  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 2.4278  Validation loss = 3.8247  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 2.4273  Validation loss = 3.8234  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 2.4271  Validation loss = 3.8224  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 2.4266  Validation loss = 3.8209  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 2.4261  Validation loss = 3.8195  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 2.4256  Validation loss = 3.8179  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 2.4252  Validation loss = 3.8166  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 2.4249  Validation loss = 3.8157  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 2.4241  Validation loss = 3.8133  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 2.4238  Validation loss = 3.8120  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 2.4234  Validation loss = 3.8110  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 2.4229  Validation loss = 3.8095  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 2.4226  Validation loss = 3.8088  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 2.4221  Validation loss = 3.8072  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 2.4219  Validation loss = 3.8064  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 2.4215  Validation loss = 3.8052  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 2.4211  Validation loss = 3.8039  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 2.4207  Validation loss = 3.8028  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 2.4204  Validation loss = 3.8018  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 2.4199  Validation loss = 3.8004  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 2.4196  Validation loss = 3.7995  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 2.4193  Validation loss = 3.7990  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 2.4191  Validation loss = 3.7986  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 2.4187  Validation loss = 3.7973  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 2.4183  Validation loss = 3.7959  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 2.4177  Validation loss = 3.7940  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 2.4173  Validation loss = 3.7931  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 2.4168  Validation loss = 3.7913  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 2.4162  Validation loss = 3.7896  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 2.4160  Validation loss = 3.7893  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 2.4156  Validation loss = 3.7882  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 2.4150  Validation loss = 3.7860  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 2.4146  Validation loss = 3.7850  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 2.4142  Validation loss = 3.7840  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 2.4140  Validation loss = 3.7832  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 2.4137  Validation loss = 3.7824  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 2.4133  Validation loss = 3.7813  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 2.4128  Validation loss = 3.7798  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 2.4122  Validation loss = 3.7778  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 2.4114  Validation loss = 3.7750  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 2.4110  Validation loss = 3.7734  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 2.4106  Validation loss = 3.7722  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 2.4103  Validation loss = 3.7712  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 2.4099  Validation loss = 3.7702  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 2.4098  Validation loss = 3.7700  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 2.4097  Validation loss = 3.7699  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 2.4094  Validation loss = 3.7689  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 2.4090  Validation loss = 3.7678  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 2.4084  Validation loss = 3.7658  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 2.4081  Validation loss = 3.7647  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 2.4074  Validation loss = 3.7627  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 2.4072  Validation loss = 3.7620  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 2.4067  Validation loss = 3.7601  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 2.4065  Validation loss = 3.7595  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 2.4061  Validation loss = 3.7583  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 2.4057  Validation loss = 3.7572  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 2.4050  Validation loss = 3.7546  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 2.4046  Validation loss = 3.7530  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 2.4043  Validation loss = 3.7523  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 2.4040  Validation loss = 3.7514  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 2.4035  Validation loss = 3.7497  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 2.4031  Validation loss = 3.7487  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 2.4028  Validation loss = 3.7478  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 2.4022  Validation loss = 3.7457  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 2.4021  Validation loss = 3.7457  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 2.4017  Validation loss = 3.7445  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 2.4013  Validation loss = 3.7432  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 2.4009  Validation loss = 3.7416  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 2.4005  Validation loss = 3.7404  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 2.4000  Validation loss = 3.7390  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 2.3998  Validation loss = 3.7382  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 2.3993  Validation loss = 3.7363  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 2.3992  Validation loss = 3.7364  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 2.3987  Validation loss = 3.7345  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 2.3984  Validation loss = 3.7335  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 2.3978  Validation loss = 3.7312  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 2.3973  Validation loss = 3.7297  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 2.3968  Validation loss = 3.7282  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 2.3966  Validation loss = 3.7280  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 2.3963  Validation loss = 3.7271  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 2.3960  Validation loss = 3.7262  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 2.3957  Validation loss = 3.7252  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 2.3956  Validation loss = 3.7253  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 2.3951  Validation loss = 3.7239  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 2.3946  Validation loss = 3.7219  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 2.3941  Validation loss = 3.7200  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 2.3936  Validation loss = 3.7183  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 2.3934  Validation loss = 3.7176  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 2.3929  Validation loss = 3.7159  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 2.3926  Validation loss = 3.7147  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 2.3922  Validation loss = 3.7134  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 2.3920  Validation loss = 3.7128  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 2.3916  Validation loss = 3.7119  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 2.3911  Validation loss = 3.7099  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 2.3906  Validation loss = 3.7082  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 2.3903  Validation loss = 3.7071  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 2.3899  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 2.3895  Validation loss = 3.7046  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 2.3891  Validation loss = 3.7033  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 2.3888  Validation loss = 3.7022  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 2.3886  Validation loss = 3.7015  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 2.3882  Validation loss = 3.7004  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 2.3880  Validation loss = 3.6996  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 2.3877  Validation loss = 3.6989  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 2.3874  Validation loss = 3.6980  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 2.3869  Validation loss = 3.6962  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 2.3866  Validation loss = 3.6949  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 2.3863  Validation loss = 3.6943  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 2.3860  Validation loss = 3.6932  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 2.3856  Validation loss = 3.6917  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 2.3853  Validation loss = 3.6910  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 2.3851  Validation loss = 3.6903  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 2.3845  Validation loss = 3.6880  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 2.3841  Validation loss = 3.6867  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 2.3838  Validation loss = 3.6857  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 2.3835  Validation loss = 3.6845  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 2.3830  Validation loss = 3.6825  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 2.3826  Validation loss = 3.6815  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 2.3823  Validation loss = 3.6806  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 2.3821  Validation loss = 3.6801  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 2.3818  Validation loss = 3.6791  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 2.3814  Validation loss = 3.6776  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 2.3811  Validation loss = 3.6762  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 2.3806  Validation loss = 3.6747  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 2.3803  Validation loss = 3.6738  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 2.3799  Validation loss = 3.6723  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 2.3796  Validation loss = 3.6713  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 2.3793  Validation loss = 3.6703  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 2.3791  Validation loss = 3.6696  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 2.3786  Validation loss = 3.6674  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 2.3782  Validation loss = 3.6662  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 2.3777  Validation loss = 3.6645  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 2.3773  Validation loss = 3.6634  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 2.3769  Validation loss = 3.6619  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 2.3767  Validation loss = 3.6612  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 2.3763  Validation loss = 3.6600  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 2.3759  Validation loss = 3.6582  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 2.3756  Validation loss = 3.6570  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 2.3752  Validation loss = 3.6558  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 2.3748  Validation loss = 3.6552  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 2.3744  Validation loss = 3.6542  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 2.3739  Validation loss = 3.6522  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 2.3738  Validation loss = 3.6517  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 2.3735  Validation loss = 3.6509  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 2.3733  Validation loss = 3.6505  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 2.3731  Validation loss = 3.6503  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 2.3727  Validation loss = 3.6492  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 2.3725  Validation loss = 3.6486  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 2.3722  Validation loss = 3.6480  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 2.3718  Validation loss = 3.6467  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 2.3716  Validation loss = 3.6460  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 2.3714  Validation loss = 3.6455  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 2.3712  Validation loss = 3.6448  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 2.3710  Validation loss = 3.6445  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 2.3706  Validation loss = 3.6427  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 2.3702  Validation loss = 3.6417  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 2.3699  Validation loss = 3.6406  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 2.3695  Validation loss = 3.6389  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 2.3692  Validation loss = 3.6381  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 2.3687  Validation loss = 3.6368  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 2.3683  Validation loss = 3.6351  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 2.3680  Validation loss = 3.6341  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 2.3676  Validation loss = 3.6331  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 2.3672  Validation loss = 3.6317  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 2.3668  Validation loss = 3.6303  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 2.3663  Validation loss = 3.6287  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 2.3660  Validation loss = 3.6277  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 2.3657  Validation loss = 3.6263  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 2.3655  Validation loss = 3.6256  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 2.3651  Validation loss = 3.6247  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 2.3647  Validation loss = 3.6234  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 2.3646  Validation loss = 3.6231  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 2.3644  Validation loss = 3.6228  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 2.3641  Validation loss = 3.6219  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 2.3637  Validation loss = 3.6207  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 2.3636  Validation loss = 3.6208  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 2.3632  Validation loss = 3.6195  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 2.3629  Validation loss = 3.6184  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 2.3626  Validation loss = 3.6176  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 2.3622  Validation loss = 3.6156  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 2.3619  Validation loss = 3.6147  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 2.3617  Validation loss = 3.6141  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 2.3614  Validation loss = 3.6133  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 2.3607  Validation loss = 3.6108  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 2.3604  Validation loss = 3.6094  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 2.3600  Validation loss = 3.6084  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 2.3599  Validation loss = 3.6084  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 2.3595  Validation loss = 3.6068  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 2.3592  Validation loss = 3.6064  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 2.3587  Validation loss = 3.6043  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 2.3585  Validation loss = 3.6037  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 2.3583  Validation loss = 3.6033  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 2.3583  Validation loss = 3.6033  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 2.3580  Validation loss = 3.6021  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 2.3577  Validation loss = 3.6014  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 2.3574  Validation loss = 3.6005  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 2.3571  Validation loss = 3.5996  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 2.3566  Validation loss = 3.5978  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 2.3564  Validation loss = 3.5974  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 2.3559  Validation loss = 3.5954  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 2.3555  Validation loss = 3.5935  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 2.3551  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 2.3548  Validation loss = 3.5915  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 2.3545  Validation loss = 3.5905  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 2.3543  Validation loss = 3.5895  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 2.3540  Validation loss = 3.5884  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 2.3537  Validation loss = 3.5873  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 2.3533  Validation loss = 3.5862  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 2.3531  Validation loss = 3.5854  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 2.3528  Validation loss = 3.5845  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 2.3525  Validation loss = 3.5834  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 2.3523  Validation loss = 3.5832  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 2.3521  Validation loss = 3.5827  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 2.3518  Validation loss = 3.5815  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 2.3516  Validation loss = 3.5809  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 2.3512  Validation loss = 3.5801  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 2.3509  Validation loss = 3.5790  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 2.3505  Validation loss = 3.5778  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 2.3502  Validation loss = 3.5772  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 2.3499  Validation loss = 3.5761  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 2.3494  Validation loss = 3.5741  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 2.3492  Validation loss = 3.5735  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 2.3488  Validation loss = 3.5719  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 2.3485  Validation loss = 3.5708  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 2.3483  Validation loss = 3.5703  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 2.3479  Validation loss = 3.5692  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 2.3477  Validation loss = 3.5683  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 2.3474  Validation loss = 3.5675  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 2.3470  Validation loss = 3.5662  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 2.3465  Validation loss = 3.5644  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 2.3462  Validation loss = 3.5633  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 2.3460  Validation loss = 3.5630  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 2.3457  Validation loss = 3.5621  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 2.3454  Validation loss = 3.5612  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 2.3451  Validation loss = 3.5600  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 2.3448  Validation loss = 3.5591  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 2.3445  Validation loss = 3.5582  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 2.3442  Validation loss = 3.5567  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 2.3440  Validation loss = 3.5566  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 2.3437  Validation loss = 3.5558  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 2.3433  Validation loss = 3.5543  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 2.3430  Validation loss = 3.5534  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 2.3425  Validation loss = 3.5510  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 2.3422  Validation loss = 3.5499  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 2.3420  Validation loss = 3.5493  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 2.3417  Validation loss = 3.5488  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 2.3414  Validation loss = 3.5478  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 2.3410  Validation loss = 3.5461  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 2.3407  Validation loss = 3.5450  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 2.3403  Validation loss = 3.5429  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 2.3398  Validation loss = 3.5413  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 2.3395  Validation loss = 3.5407  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 2.3393  Validation loss = 3.5400  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 2.3390  Validation loss = 3.5385  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 2.3386  Validation loss = 3.5371  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 2.3384  Validation loss = 3.5368  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 2.3381  Validation loss = 3.5359  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 2.3380  Validation loss = 3.5358  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 2.3378  Validation loss = 3.5349  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 2.3374  Validation loss = 3.5334  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 2.3372  Validation loss = 3.5330  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 2.3370  Validation loss = 3.5324  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 2.3366  Validation loss = 3.5311  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 2.3363  Validation loss = 3.5301  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 2.3364  Validation loss = 3.5305  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 2.3361  Validation loss = 3.5295  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 2.3359  Validation loss = 3.5293  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 2.3357  Validation loss = 3.5281  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 2.3354  Validation loss = 3.5275  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 2.3351  Validation loss = 3.5261  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 2.3347  Validation loss = 3.5238  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 2.3344  Validation loss = 3.5232  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 2.3343  Validation loss = 3.5223  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 2.3341  Validation loss = 3.5221  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 2.3337  Validation loss = 3.5205  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 2.3335  Validation loss = 3.5197  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 2.3330  Validation loss = 3.5178  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 2.3327  Validation loss = 3.5169  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 2.3325  Validation loss = 3.5160  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 2.3323  Validation loss = 3.5156  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 2.3320  Validation loss = 3.5148  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 2.3318  Validation loss = 3.5140  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 2.3315  Validation loss = 3.5132  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 2.3314  Validation loss = 3.5130  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 2.3309  Validation loss = 3.5111  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 2.3307  Validation loss = 3.5109  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 2.3306  Validation loss = 3.5105  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 2.3302  Validation loss = 3.5087  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 2.3299  Validation loss = 3.5076  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 2.3296  Validation loss = 3.5066  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 2.3293  Validation loss = 3.5051  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 2.3289  Validation loss = 3.5033  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 2.3286  Validation loss = 3.5025  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 2.3283  Validation loss = 3.5015  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 2.3281  Validation loss = 3.5010  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 2.3280  Validation loss = 3.5007  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 2.3277  Validation loss = 3.4999  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 2.3275  Validation loss = 3.4997  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 2.3272  Validation loss = 3.4986  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 2.3270  Validation loss = 3.4979  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 2.3267  Validation loss = 3.4971  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 2.3264  Validation loss = 3.4964  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 2.3260  Validation loss = 3.4941  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 2.3257  Validation loss = 3.4934  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 2.3254  Validation loss = 3.4917  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 2.3251  Validation loss = 3.4907  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 2.3249  Validation loss = 3.4899  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 2.3246  Validation loss = 3.4886  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 2.3244  Validation loss = 3.4877  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 2.3242  Validation loss = 3.4867  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 2.3240  Validation loss = 3.4866  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 2.3235  Validation loss = 3.4846  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 2.3231  Validation loss = 3.4830  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 2.3227  Validation loss = 3.4816  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 2.3224  Validation loss = 3.4811  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 2.3222  Validation loss = 3.4802  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 2.3219  Validation loss = 3.4793  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 2.3216  Validation loss = 3.4773  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 2.3214  Validation loss = 3.4772  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 2.3211  Validation loss = 3.4761  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 2.3211  Validation loss = 3.4759  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 2.3207  Validation loss = 3.4746  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 2.3204  Validation loss = 3.4733  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 2.3202  Validation loss = 3.4730  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 2.3200  Validation loss = 3.4725  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 2.3197  Validation loss = 3.4712  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 2.3196  Validation loss = 3.4713  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 2.3192  Validation loss = 3.4698  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 2.3188  Validation loss = 3.4682  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 2.3186  Validation loss = 3.4667  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 2.3182  Validation loss = 3.4651  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 2.3180  Validation loss = 3.4636  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 2.3177  Validation loss = 3.4626  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 2.3174  Validation loss = 3.4612  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 2.3172  Validation loss = 3.4609  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 2.3170  Validation loss = 3.4603  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 2.3167  Validation loss = 3.4601  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 2.3164  Validation loss = 3.4585  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 2.3159  Validation loss = 3.4566  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 2.3158  Validation loss = 3.4562  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 2.3157  Validation loss = 3.4561  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 2.3155  Validation loss = 3.4549  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 2.3153  Validation loss = 3.4544  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 2.3150  Validation loss = 3.4533  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 2.3146  Validation loss = 3.4533  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 2.3143  Validation loss = 3.4520  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 2.3140  Validation loss = 3.4507  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 2.3137  Validation loss = 3.4504  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 2.3133  Validation loss = 3.4490  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 2.3130  Validation loss = 3.4480  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 2.3127  Validation loss = 3.4465  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 2.3123  Validation loss = 3.4447  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 2.3120  Validation loss = 3.4431  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 2.3119  Validation loss = 3.4432  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 2.3117  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 2.3114  Validation loss = 3.4411  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 2.3112  Validation loss = 3.4405  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 2.3109  Validation loss = 3.4398  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 2.3106  Validation loss = 3.4376  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 2.3102  Validation loss = 3.4357  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 2.3101  Validation loss = 3.4348  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 2.3098  Validation loss = 3.4343  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 2.3097  Validation loss = 3.4338  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 2.3095  Validation loss = 3.4336  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 2.3093  Validation loss = 3.4326  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 2.3091  Validation loss = 3.4317  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 2.3088  Validation loss = 3.4302  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 2.3084  Validation loss = 3.4291  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 2.3082  Validation loss = 3.4288  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 2.3080  Validation loss = 3.4291  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 2.3078  Validation loss = 3.4282  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 2.3077  Validation loss = 3.4280  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 2.3073  Validation loss = 3.4263  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 2.3071  Validation loss = 3.4255  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 2.3068  Validation loss = 3.4240  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 2.3066  Validation loss = 3.4236  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 2.3063  Validation loss = 3.4227  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 2.3060  Validation loss = 3.4220  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 2.3058  Validation loss = 3.4212  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 2.3056  Validation loss = 3.4214  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 2.3055  Validation loss = 3.4207  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 2.3053  Validation loss = 3.4204  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 2.3050  Validation loss = 3.4197  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 2.3048  Validation loss = 3.4197  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 2.3046  Validation loss = 3.4190  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 2.3044  Validation loss = 3.4182  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 2.3040  Validation loss = 3.4171  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 2.3038  Validation loss = 3.4162  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 2.3036  Validation loss = 3.4157  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 2.3034  Validation loss = 3.4148  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 2.3031  Validation loss = 3.4138  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 2.3029  Validation loss = 3.4130  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 2.3026  Validation loss = 3.4118  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 2.3026  Validation loss = 3.4121  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 2.3023  Validation loss = 3.4112  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 2.3023  Validation loss = 3.4114  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 2.3022  Validation loss = 3.4115  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 2.3019  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 2.3016  Validation loss = 3.4089  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 2.3012  Validation loss = 3.4074  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 2.3010  Validation loss = 3.4071  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 2.3008  Validation loss = 3.4063  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 2.3007  Validation loss = 3.4062  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 2.3006  Validation loss = 3.4061  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 2.3004  Validation loss = 3.4057  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 2.3000  Validation loss = 3.4039  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 2.2996  Validation loss = 3.4027  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 2.2993  Validation loss = 3.4019  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 2.2988  Validation loss = 3.3999  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 2.2986  Validation loss = 3.3993  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 2.2985  Validation loss = 3.3986  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 2.2983  Validation loss = 3.3982  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 2.2981  Validation loss = 3.3975  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 2.2978  Validation loss = 3.3965  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 2.2976  Validation loss = 3.3961  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 2.2973  Validation loss = 3.3954  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 2.2971  Validation loss = 3.3949  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 2.2969  Validation loss = 3.3944  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 2.2968  Validation loss = 3.3941  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 2.2965  Validation loss = 3.3929  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 2.2964  Validation loss = 3.3924  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 2.2961  Validation loss = 3.3910  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 2.2958  Validation loss = 3.3899  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 2.2956  Validation loss = 3.3893  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 2.2952  Validation loss = 3.3882  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 2.2951  Validation loss = 3.3871  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 2.2949  Validation loss = 3.3866  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 2.2947  Validation loss = 3.3857  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 2.2945  Validation loss = 3.3846  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 2.2943  Validation loss = 3.3846  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 2.2942  Validation loss = 3.3847  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 2.2940  Validation loss = 3.3835  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 2.2938  Validation loss = 3.3826  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 2.2935  Validation loss = 3.3814  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 2.2932  Validation loss = 3.3810  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 2.2931  Validation loss = 3.3807  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 2.2926  Validation loss = 3.3784  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 2.2925  Validation loss = 3.3775  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 2.2921  Validation loss = 3.3759  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 2.2919  Validation loss = 3.3750  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 2.2917  Validation loss = 3.3740  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 2.2913  Validation loss = 3.3729  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 2.2910  Validation loss = 3.3720  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 2.2908  Validation loss = 3.3712  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 2.2905  Validation loss = 3.3698  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 2.2902  Validation loss = 3.3690  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 2.2899  Validation loss = 3.3689  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 2.2897  Validation loss = 3.3678  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 2.2893  Validation loss = 3.3673  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 2.2892  Validation loss = 3.3671  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 2.2890  Validation loss = 3.3671  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 2.2888  Validation loss = 3.3666  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 2.2884  Validation loss = 3.3650  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 2.2881  Validation loss = 3.3635  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 2.2878  Validation loss = 3.3621  \n",
      "\n",
      "Fold: 13  Epoch: 501  Training loss = 2.2875  Validation loss = 3.3614  \n",
      "\n",
      "Fold: 13  Epoch: 502  Training loss = 2.2872  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 13  Epoch: 503  Training loss = 2.2869  Validation loss = 3.3588  \n",
      "\n",
      "Fold: 13  Epoch: 504  Training loss = 2.2867  Validation loss = 3.3582  \n",
      "\n",
      "Fold: 13  Epoch: 505  Training loss = 2.2863  Validation loss = 3.3559  \n",
      "\n",
      "Fold: 13  Epoch: 506  Training loss = 2.2860  Validation loss = 3.3550  \n",
      "\n",
      "Fold: 13  Epoch: 507  Training loss = 2.2858  Validation loss = 3.3552  \n",
      "\n",
      "Fold: 13  Epoch: 508  Training loss = 2.2858  Validation loss = 3.3554  \n",
      "\n",
      "Fold: 13  Epoch: 509  Training loss = 2.2854  Validation loss = 3.3540  \n",
      "\n",
      "Fold: 13  Epoch: 510  Training loss = 2.2850  Validation loss = 3.3523  \n",
      "\n",
      "Fold: 13  Epoch: 511  Training loss = 2.2848  Validation loss = 3.3515  \n",
      "\n",
      "Fold: 13  Epoch: 512  Training loss = 2.2844  Validation loss = 3.3501  \n",
      "\n",
      "Fold: 13  Epoch: 513  Training loss = 2.2842  Validation loss = 3.3490  \n",
      "\n",
      "Fold: 13  Epoch: 514  Training loss = 2.2840  Validation loss = 3.3490  \n",
      "\n",
      "Fold: 13  Epoch: 515  Training loss = 2.2838  Validation loss = 3.3482  \n",
      "\n",
      "Fold: 13  Epoch: 516  Training loss = 2.2836  Validation loss = 3.3475  \n",
      "\n",
      "Fold: 13  Epoch: 517  Training loss = 2.2832  Validation loss = 3.3458  \n",
      "\n",
      "Fold: 13  Epoch: 518  Training loss = 2.2831  Validation loss = 3.3454  \n",
      "\n",
      "Fold: 13  Epoch: 519  Training loss = 2.2830  Validation loss = 3.3456  \n",
      "\n",
      "Fold: 13  Epoch: 520  Training loss = 2.2827  Validation loss = 3.3447  \n",
      "\n",
      "Fold: 13  Epoch: 521  Training loss = 2.2825  Validation loss = 3.3437  \n",
      "\n",
      "Fold: 13  Epoch: 522  Training loss = 2.2824  Validation loss = 3.3433  \n",
      "\n",
      "Fold: 13  Epoch: 523  Training loss = 2.2821  Validation loss = 3.3418  \n",
      "\n",
      "Fold: 13  Epoch: 524  Training loss = 2.2818  Validation loss = 3.3403  \n",
      "\n",
      "Fold: 13  Epoch: 525  Training loss = 2.2814  Validation loss = 3.3390  \n",
      "\n",
      "Fold: 13  Epoch: 526  Training loss = 2.2812  Validation loss = 3.3386  \n",
      "\n",
      "Fold: 13  Epoch: 527  Training loss = 2.2811  Validation loss = 3.3391  \n",
      "\n",
      "Fold: 13  Epoch: 528  Training loss = 2.2808  Validation loss = 3.3377  \n",
      "\n",
      "Fold: 13  Epoch: 529  Training loss = 2.2808  Validation loss = 3.3380  \n",
      "\n",
      "Fold: 13  Epoch: 530  Training loss = 2.2807  Validation loss = 3.3379  \n",
      "\n",
      "Fold: 13  Epoch: 531  Training loss = 2.2807  Validation loss = 3.3383  \n",
      "\n",
      "Fold: 13  Epoch: 532  Training loss = 2.2805  Validation loss = 3.3381  \n",
      "\n",
      "Fold: 13  Epoch: 533  Training loss = 2.2801  Validation loss = 3.3360  \n",
      "\n",
      "Fold: 13  Epoch: 534  Training loss = 2.2798  Validation loss = 3.3350  \n",
      "\n",
      "Fold: 13  Epoch: 535  Training loss = 2.2795  Validation loss = 3.3337  \n",
      "\n",
      "Fold: 13  Epoch: 536  Training loss = 2.2793  Validation loss = 3.3334  \n",
      "\n",
      "Fold: 13  Epoch: 537  Training loss = 2.2791  Validation loss = 3.3326  \n",
      "\n",
      "Fold: 13  Epoch: 538  Training loss = 2.2789  Validation loss = 3.3322  \n",
      "\n",
      "Fold: 13  Epoch: 539  Training loss = 2.2787  Validation loss = 3.3309  \n",
      "\n",
      "Fold: 13  Epoch: 540  Training loss = 2.2784  Validation loss = 3.3296  \n",
      "\n",
      "Fold: 13  Epoch: 541  Training loss = 2.2781  Validation loss = 3.3287  \n",
      "\n",
      "Fold: 13  Epoch: 542  Training loss = 2.2782  Validation loss = 3.3291  \n",
      "\n",
      "Fold: 13  Epoch: 543  Training loss = 2.2779  Validation loss = 3.3277  \n",
      "\n",
      "Fold: 13  Epoch: 544  Training loss = 2.2778  Validation loss = 3.3273  \n",
      "\n",
      "Fold: 13  Epoch: 545  Training loss = 2.2775  Validation loss = 3.3263  \n",
      "\n",
      "Fold: 13  Epoch: 546  Training loss = 2.2775  Validation loss = 3.3265  \n",
      "\n",
      "Fold: 13  Epoch: 547  Training loss = 2.2770  Validation loss = 3.3248  \n",
      "\n",
      "Fold: 13  Epoch: 548  Training loss = 2.2769  Validation loss = 3.3247  \n",
      "\n",
      "Fold: 13  Epoch: 549  Training loss = 2.2767  Validation loss = 3.3245  \n",
      "\n",
      "Fold: 13  Epoch: 550  Training loss = 2.2763  Validation loss = 3.3228  \n",
      "\n",
      "Fold: 13  Epoch: 551  Training loss = 2.2760  Validation loss = 3.3215  \n",
      "\n",
      "Fold: 13  Epoch: 552  Training loss = 2.2758  Validation loss = 3.3207  \n",
      "\n",
      "Fold: 13  Epoch: 553  Training loss = 2.2756  Validation loss = 3.3201  \n",
      "\n",
      "Fold: 13  Epoch: 554  Training loss = 2.2754  Validation loss = 3.3204  \n",
      "\n",
      "Fold: 13  Epoch: 555  Training loss = 2.2752  Validation loss = 3.3201  \n",
      "\n",
      "Fold: 13  Epoch: 556  Training loss = 2.2750  Validation loss = 3.3196  \n",
      "\n",
      "Fold: 13  Epoch: 557  Training loss = 2.2748  Validation loss = 3.3187  \n",
      "\n",
      "Fold: 13  Epoch: 558  Training loss = 2.2745  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 13  Epoch: 559  Training loss = 2.2744  Validation loss = 3.3171  \n",
      "\n",
      "Fold: 13  Epoch: 560  Training loss = 2.2741  Validation loss = 3.3161  \n",
      "\n",
      "Fold: 13  Epoch: 561  Training loss = 2.2738  Validation loss = 3.3153  \n",
      "\n",
      "Fold: 13  Epoch: 562  Training loss = 2.2736  Validation loss = 3.3145  \n",
      "\n",
      "Fold: 13  Epoch: 563  Training loss = 2.2732  Validation loss = 3.3124  \n",
      "\n",
      "Fold: 13  Epoch: 564  Training loss = 2.2732  Validation loss = 3.3128  \n",
      "\n",
      "Fold: 13  Epoch: 565  Training loss = 2.2728  Validation loss = 3.3104  \n",
      "\n",
      "Fold: 13  Epoch: 566  Training loss = 2.2727  Validation loss = 3.3110  \n",
      "\n",
      "Fold: 13  Epoch: 567  Training loss = 2.2722  Validation loss = 3.3091  \n",
      "\n",
      "Fold: 13  Epoch: 568  Training loss = 2.2721  Validation loss = 3.3086  \n",
      "\n",
      "Fold: 13  Epoch: 569  Training loss = 2.2720  Validation loss = 3.3084  \n",
      "\n",
      "Fold: 13  Epoch: 570  Training loss = 2.2720  Validation loss = 3.3089  \n",
      "\n",
      "Fold: 13  Epoch: 571  Training loss = 2.2717  Validation loss = 3.3081  \n",
      "\n",
      "Fold: 13  Epoch: 572  Training loss = 2.2716  Validation loss = 3.3077  \n",
      "\n",
      "Fold: 13  Epoch: 573  Training loss = 2.2714  Validation loss = 3.3066  \n",
      "\n",
      "Fold: 13  Epoch: 574  Training loss = 2.2711  Validation loss = 3.3057  \n",
      "\n",
      "Fold: 13  Epoch: 575  Training loss = 2.2708  Validation loss = 3.3040  \n",
      "\n",
      "Fold: 13  Epoch: 576  Training loss = 2.2705  Validation loss = 3.3036  \n",
      "\n",
      "Fold: 13  Epoch: 577  Training loss = 2.2703  Validation loss = 3.3028  \n",
      "\n",
      "Fold: 13  Epoch: 578  Training loss = 2.2702  Validation loss = 3.3023  \n",
      "\n",
      "Fold: 13  Epoch: 579  Training loss = 2.2700  Validation loss = 3.3017  \n",
      "\n",
      "Fold: 13  Epoch: 580  Training loss = 2.2698  Validation loss = 3.3009  \n",
      "\n",
      "Fold: 13  Epoch: 581  Training loss = 2.2696  Validation loss = 3.3002  \n",
      "\n",
      "Fold: 13  Epoch: 582  Training loss = 2.2693  Validation loss = 3.2991  \n",
      "\n",
      "Fold: 13  Epoch: 583  Training loss = 2.2692  Validation loss = 3.2987  \n",
      "\n",
      "Fold: 13  Epoch: 584  Training loss = 2.2690  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 13  Epoch: 585  Training loss = 2.2687  Validation loss = 3.2965  \n",
      "\n",
      "Fold: 13  Epoch: 586  Training loss = 2.2686  Validation loss = 3.2965  \n",
      "\n",
      "Fold: 13  Epoch: 587  Training loss = 2.2685  Validation loss = 3.2963  \n",
      "\n",
      "Fold: 13  Epoch: 588  Training loss = 2.2682  Validation loss = 3.2950  \n",
      "\n",
      "Fold: 13  Epoch: 589  Training loss = 2.2680  Validation loss = 3.2941  \n",
      "\n",
      "Fold: 13  Epoch: 590  Training loss = 2.2676  Validation loss = 3.2928  \n",
      "\n",
      "Fold: 13  Epoch: 591  Training loss = 2.2675  Validation loss = 3.2921  \n",
      "\n",
      "Fold: 13  Epoch: 592  Training loss = 2.2673  Validation loss = 3.2909  \n",
      "\n",
      "Fold: 13  Epoch: 593  Training loss = 2.2670  Validation loss = 3.2899  \n",
      "\n",
      "Fold: 13  Epoch: 594  Training loss = 2.2668  Validation loss = 3.2892  \n",
      "\n",
      "Fold: 13  Epoch: 595  Training loss = 2.2666  Validation loss = 3.2881  \n",
      "\n",
      "Fold: 13  Epoch: 596  Training loss = 2.2664  Validation loss = 3.2878  \n",
      "\n",
      "Fold: 13  Epoch: 597  Training loss = 2.2662  Validation loss = 3.2871  \n",
      "\n",
      "Fold: 13  Epoch: 598  Training loss = 2.2660  Validation loss = 3.2861  \n",
      "\n",
      "Fold: 13  Epoch: 599  Training loss = 2.2658  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 13  Epoch: 600  Training loss = 2.2657  Validation loss = 3.2856  \n",
      "\n",
      "Fold: 13  Epoch: 601  Training loss = 2.2656  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 13  Epoch: 602  Training loss = 2.2654  Validation loss = 3.2843  \n",
      "\n",
      "Fold: 13  Epoch: 603  Training loss = 2.2652  Validation loss = 3.2839  \n",
      "\n",
      "Fold: 13  Epoch: 604  Training loss = 2.2651  Validation loss = 3.2835  \n",
      "\n",
      "Fold: 13  Epoch: 605  Training loss = 2.2649  Validation loss = 3.2827  \n",
      "\n",
      "Fold: 13  Epoch: 606  Training loss = 2.2647  Validation loss = 3.2814  \n",
      "\n",
      "Fold: 13  Epoch: 607  Training loss = 2.2645  Validation loss = 3.2804  \n",
      "\n",
      "Fold: 13  Epoch: 608  Training loss = 2.2643  Validation loss = 3.2799  \n",
      "\n",
      "Fold: 13  Epoch: 609  Training loss = 2.2641  Validation loss = 3.2794  \n",
      "\n",
      "Fold: 13  Epoch: 610  Training loss = 2.2640  Validation loss = 3.2789  \n",
      "\n",
      "Fold: 13  Epoch: 611  Training loss = 2.2638  Validation loss = 3.2778  \n",
      "\n",
      "Fold: 13  Epoch: 612  Training loss = 2.2635  Validation loss = 3.2765  \n",
      "\n",
      "Fold: 13  Epoch: 613  Training loss = 2.2633  Validation loss = 3.2750  \n",
      "\n",
      "Fold: 13  Epoch: 614  Training loss = 2.2628  Validation loss = 3.2728  \n",
      "\n",
      "Fold: 13  Epoch: 615  Training loss = 2.2624  Validation loss = 3.2733  \n",
      "\n",
      "Fold: 13  Epoch: 616  Training loss = 2.2619  Validation loss = 3.2730  \n",
      "\n",
      "Fold: 13  Epoch: 617  Training loss = 2.2615  Validation loss = 3.2720  \n",
      "\n",
      "Fold: 13  Epoch: 618  Training loss = 2.2612  Validation loss = 3.2716  \n",
      "\n",
      "Fold: 13  Epoch: 619  Training loss = 2.2610  Validation loss = 3.2706  \n",
      "\n",
      "Fold: 13  Epoch: 620  Training loss = 2.2608  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 13  Epoch: 621  Training loss = 2.2606  Validation loss = 3.2690  \n",
      "\n",
      "Fold: 13  Epoch: 622  Training loss = 2.2604  Validation loss = 3.2692  \n",
      "\n",
      "Fold: 13  Epoch: 623  Training loss = 2.2602  Validation loss = 3.2685  \n",
      "\n",
      "Fold: 13  Epoch: 624  Training loss = 2.2599  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 13  Epoch: 625  Training loss = 2.2597  Validation loss = 3.2674  \n",
      "\n",
      "Fold: 13  Epoch: 626  Training loss = 2.2595  Validation loss = 3.2664  \n",
      "\n",
      "Fold: 13  Epoch: 627  Training loss = 2.2593  Validation loss = 3.2656  \n",
      "\n",
      "Fold: 13  Epoch: 628  Training loss = 2.2591  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 13  Epoch: 629  Training loss = 2.2589  Validation loss = 3.2658  \n",
      "\n",
      "Fold: 13  Epoch: 630  Training loss = 2.2586  Validation loss = 3.2650  \n",
      "\n",
      "Fold: 13  Epoch: 631  Training loss = 2.2583  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 13  Epoch: 632  Training loss = 2.2582  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 13  Epoch: 633  Training loss = 2.2579  Validation loss = 3.2619  \n",
      "\n",
      "Fold: 13  Epoch: 634  Training loss = 2.2579  Validation loss = 3.2618  \n",
      "\n",
      "Fold: 13  Epoch: 635  Training loss = 2.2576  Validation loss = 3.2612  \n",
      "\n",
      "Fold: 13  Epoch: 636  Training loss = 2.2574  Validation loss = 3.2618  \n",
      "\n",
      "Fold: 13  Epoch: 637  Training loss = 2.2572  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 13  Epoch: 638  Training loss = 2.2571  Validation loss = 3.2599  \n",
      "\n",
      "Fold: 13  Epoch: 639  Training loss = 2.2568  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 13  Epoch: 640  Training loss = 2.2565  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 13  Epoch: 641  Training loss = 2.2563  Validation loss = 3.2575  \n",
      "\n",
      "Fold: 13  Epoch: 642  Training loss = 2.2564  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 13  Epoch: 643  Training loss = 2.2560  Validation loss = 3.2571  \n",
      "\n",
      "Fold: 13  Epoch: 644  Training loss = 2.2560  Validation loss = 3.2567  \n",
      "\n",
      "Fold: 13  Epoch: 645  Training loss = 2.2557  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 13  Epoch: 646  Training loss = 2.2557  Validation loss = 3.2556  \n",
      "\n",
      "Fold: 13  Epoch: 647  Training loss = 2.2556  Validation loss = 3.2555  \n",
      "\n",
      "Fold: 13  Epoch: 648  Training loss = 2.2554  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 13  Epoch: 649  Training loss = 2.2552  Validation loss = 3.2542  \n",
      "\n",
      "Fold: 13  Epoch: 650  Training loss = 2.2552  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 13  Epoch: 651  Training loss = 2.2550  Validation loss = 3.2544  \n",
      "\n",
      "Fold: 13  Epoch: 652  Training loss = 2.2548  Validation loss = 3.2539  \n",
      "\n",
      "Fold: 13  Epoch: 653  Training loss = 2.2547  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 13  Epoch: 654  Training loss = 2.2544  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 13  Epoch: 655  Training loss = 2.2542  Validation loss = 3.2515  \n",
      "\n",
      "Fold: 13  Epoch: 656  Training loss = 2.2539  Validation loss = 3.2497  \n",
      "\n",
      "Fold: 13  Epoch: 657  Training loss = 2.2538  Validation loss = 3.2495  \n",
      "\n",
      "Fold: 13  Epoch: 658  Training loss = 2.2535  Validation loss = 3.2493  \n",
      "\n",
      "Fold: 13  Epoch: 659  Training loss = 2.2533  Validation loss = 3.2490  \n",
      "\n",
      "Fold: 13  Epoch: 660  Training loss = 2.2532  Validation loss = 3.2491  \n",
      "\n",
      "Fold: 13  Epoch: 661  Training loss = 2.2530  Validation loss = 3.2479  \n",
      "\n",
      "Fold: 13  Epoch: 662  Training loss = 2.2529  Validation loss = 3.2479  \n",
      "\n",
      "Fold: 13  Epoch: 663  Training loss = 2.2527  Validation loss = 3.2480  \n",
      "\n",
      "Fold: 13  Epoch: 664  Training loss = 2.2525  Validation loss = 3.2471  \n",
      "\n",
      "Fold: 13  Epoch: 665  Training loss = 2.2522  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 13  Epoch: 666  Training loss = 2.2519  Validation loss = 3.2447  \n",
      "\n",
      "Fold: 13  Epoch: 667  Training loss = 2.2519  Validation loss = 3.2452  \n",
      "\n",
      "Fold: 13  Epoch: 668  Training loss = 2.2517  Validation loss = 3.2449  \n",
      "\n",
      "Fold: 13  Epoch: 669  Training loss = 2.2515  Validation loss = 3.2446  \n",
      "\n",
      "Fold: 13  Epoch: 670  Training loss = 2.2513  Validation loss = 3.2441  \n",
      "\n",
      "Fold: 13  Epoch: 671  Training loss = 2.2512  Validation loss = 3.2445  \n",
      "\n",
      "Fold: 13  Epoch: 672  Training loss = 2.2508  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 13  Epoch: 673  Training loss = 2.2507  Validation loss = 3.2421  \n",
      "\n",
      "Fold: 13  Epoch: 674  Training loss = 2.2504  Validation loss = 3.2407  \n",
      "\n",
      "Fold: 13  Epoch: 675  Training loss = 2.2501  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 13  Epoch: 676  Training loss = 2.2498  Validation loss = 3.2379  \n",
      "\n",
      "Fold: 13  Epoch: 677  Training loss = 2.2495  Validation loss = 3.2371  \n",
      "\n",
      "Fold: 13  Epoch: 678  Training loss = 2.2492  Validation loss = 3.2361  \n",
      "\n",
      "Fold: 13  Epoch: 679  Training loss = 2.2492  Validation loss = 3.2366  \n",
      "\n",
      "Fold: 13  Epoch: 680  Training loss = 2.2490  Validation loss = 3.2361  \n",
      "\n",
      "Fold: 13  Epoch: 681  Training loss = 2.2488  Validation loss = 3.2357  \n",
      "\n",
      "Fold: 13  Epoch: 682  Training loss = 2.2486  Validation loss = 3.2347  \n",
      "\n",
      "Fold: 13  Epoch: 683  Training loss = 2.2483  Validation loss = 3.2330  \n",
      "\n",
      "Fold: 13  Epoch: 684  Training loss = 2.2481  Validation loss = 3.2321  \n",
      "\n",
      "Fold: 13  Epoch: 685  Training loss = 2.2477  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 13  Epoch: 686  Training loss = 2.2476  Validation loss = 3.2296  \n",
      "\n",
      "Fold: 13  Epoch: 687  Training loss = 2.2473  Validation loss = 3.2291  \n",
      "\n",
      "Fold: 13  Epoch: 688  Training loss = 2.2471  Validation loss = 3.2280  \n",
      "\n",
      "Fold: 13  Epoch: 689  Training loss = 2.2469  Validation loss = 3.2277  \n",
      "\n",
      "Fold: 13  Epoch: 690  Training loss = 2.2467  Validation loss = 3.2267  \n",
      "\n",
      "Fold: 13  Epoch: 691  Training loss = 2.2464  Validation loss = 3.2253  \n",
      "\n",
      "Fold: 13  Epoch: 692  Training loss = 2.2462  Validation loss = 3.2242  \n",
      "\n",
      "Fold: 13  Epoch: 693  Training loss = 2.2461  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 13  Epoch: 694  Training loss = 2.2459  Validation loss = 3.2238  \n",
      "\n",
      "Fold: 13  Epoch: 695  Training loss = 2.2457  Validation loss = 3.2237  \n",
      "\n",
      "Fold: 13  Epoch: 696  Training loss = 2.2456  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 13  Epoch: 697  Training loss = 2.2453  Validation loss = 3.2210  \n",
      "\n",
      "Fold: 13  Epoch: 698  Training loss = 2.2452  Validation loss = 3.2215  \n",
      "\n",
      "Fold: 13  Epoch: 699  Training loss = 2.2449  Validation loss = 3.2208  \n",
      "\n",
      "Fold: 13  Epoch: 700  Training loss = 2.2447  Validation loss = 3.2204  \n",
      "\n",
      "Fold: 13  Epoch: 701  Training loss = 2.2445  Validation loss = 3.2193  \n",
      "\n",
      "Fold: 13  Epoch: 702  Training loss = 2.2444  Validation loss = 3.2188  \n",
      "\n",
      "Fold: 13  Epoch: 703  Training loss = 2.2442  Validation loss = 3.2178  \n",
      "\n",
      "Fold: 13  Epoch: 704  Training loss = 2.2439  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 13  Epoch: 705  Training loss = 2.2436  Validation loss = 3.2156  \n",
      "\n",
      "Fold: 13  Epoch: 706  Training loss = 2.2435  Validation loss = 3.2149  \n",
      "\n",
      "Fold: 13  Epoch: 707  Training loss = 2.2434  Validation loss = 3.2152  \n",
      "\n",
      "Fold: 13  Epoch: 708  Training loss = 2.2432  Validation loss = 3.2149  \n",
      "\n",
      "Fold: 13  Epoch: 709  Training loss = 2.2432  Validation loss = 3.2153  \n",
      "\n",
      "Fold: 13  Epoch: 710  Training loss = 2.2430  Validation loss = 3.2151  \n",
      "\n",
      "Fold: 13  Epoch: 711  Training loss = 2.2429  Validation loss = 3.2151  \n",
      "\n",
      "Fold: 13  Epoch: 712  Training loss = 2.2426  Validation loss = 3.2143  \n",
      "\n",
      "Fold: 13  Epoch: 713  Training loss = 2.2425  Validation loss = 3.2142  \n",
      "\n",
      "Fold: 13  Epoch: 714  Training loss = 2.2423  Validation loss = 3.2132  \n",
      "\n",
      "Fold: 13  Epoch: 715  Training loss = 2.2420  Validation loss = 3.2117  \n",
      "\n",
      "Fold: 13  Epoch: 716  Training loss = 2.2418  Validation loss = 3.2112  \n",
      "\n",
      "Fold: 13  Epoch: 717  Training loss = 2.2416  Validation loss = 3.2100  \n",
      "\n",
      "Fold: 13  Epoch: 718  Training loss = 2.2413  Validation loss = 3.2091  \n",
      "\n",
      "Fold: 13  Epoch: 719  Training loss = 2.2412  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 13  Epoch: 720  Training loss = 2.2410  Validation loss = 3.2080  \n",
      "\n",
      "Fold: 13  Epoch: 721  Training loss = 2.2408  Validation loss = 3.2074  \n",
      "\n",
      "Fold: 13  Epoch: 722  Training loss = 2.2405  Validation loss = 3.2061  \n",
      "\n",
      "Fold: 13  Epoch: 723  Training loss = 2.2403  Validation loss = 3.2048  \n",
      "\n",
      "Fold: 13  Epoch: 724  Training loss = 2.2401  Validation loss = 3.2040  \n",
      "\n",
      "Fold: 13  Epoch: 725  Training loss = 2.2399  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 13  Epoch: 726  Training loss = 2.2396  Validation loss = 3.2022  \n",
      "\n",
      "Fold: 13  Epoch: 727  Training loss = 2.2396  Validation loss = 3.2026  \n",
      "\n",
      "Fold: 13  Epoch: 728  Training loss = 2.2394  Validation loss = 3.2019  \n",
      "\n",
      "Fold: 13  Epoch: 729  Training loss = 2.2393  Validation loss = 3.2019  \n",
      "\n",
      "Fold: 13  Epoch: 730  Training loss = 2.2391  Validation loss = 3.2013  \n",
      "\n",
      "Fold: 13  Epoch: 731  Training loss = 2.2391  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 13  Epoch: 732  Training loss = 2.2390  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 13  Epoch: 733  Training loss = 2.2389  Validation loss = 3.2009  \n",
      "\n",
      "Fold: 13  Epoch: 734  Training loss = 2.2388  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 13  Epoch: 735  Training loss = 2.2383  Validation loss = 3.1999  \n",
      "\n",
      "Fold: 13  Epoch: 736  Training loss = 2.2382  Validation loss = 3.1995  \n",
      "\n",
      "Fold: 13  Epoch: 737  Training loss = 2.2380  Validation loss = 3.1987  \n",
      "\n",
      "Fold: 13  Epoch: 738  Training loss = 2.2378  Validation loss = 3.1977  \n",
      "\n",
      "Fold: 13  Epoch: 739  Training loss = 2.2375  Validation loss = 3.1962  \n",
      "\n",
      "Fold: 13  Epoch: 740  Training loss = 2.2374  Validation loss = 3.1969  \n",
      "\n",
      "Fold: 13  Epoch: 741  Training loss = 2.2373  Validation loss = 3.1963  \n",
      "\n",
      "Fold: 13  Epoch: 742  Training loss = 2.2370  Validation loss = 3.1951  \n",
      "\n",
      "Fold: 13  Epoch: 743  Training loss = 2.2367  Validation loss = 3.1939  \n",
      "\n",
      "Fold: 13  Epoch: 744  Training loss = 2.2362  Validation loss = 3.1921  \n",
      "\n",
      "Fold: 13  Epoch: 745  Training loss = 2.2363  Validation loss = 3.1929  \n",
      "\n",
      "Fold: 13  Epoch: 746  Training loss = 2.2360  Validation loss = 3.1914  \n",
      "\n",
      "Fold: 13  Epoch: 747  Training loss = 2.2358  Validation loss = 3.1906  \n",
      "\n",
      "Fold: 13  Epoch: 748  Training loss = 2.2354  Validation loss = 3.1888  \n",
      "\n",
      "Fold: 13  Epoch: 749  Training loss = 2.2353  Validation loss = 3.1880  \n",
      "\n",
      "Fold: 13  Epoch: 750  Training loss = 2.2350  Validation loss = 3.1868  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 750  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.3496  Validation loss = 7.1003  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.3496  Validation loss = 7.1001  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.3494  Validation loss = 7.0994  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.3488  Validation loss = 7.0972  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.3484  Validation loss = 7.0958  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.3480  Validation loss = 7.0945  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.3475  Validation loss = 7.0930  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.3471  Validation loss = 7.0917  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.3468  Validation loss = 7.0909  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.3465  Validation loss = 7.0894  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.3458  Validation loss = 7.0864  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.3456  Validation loss = 7.0858  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.3452  Validation loss = 7.0843  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.3448  Validation loss = 7.0829  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.3445  Validation loss = 7.0819  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.3440  Validation loss = 7.0802  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.3437  Validation loss = 7.0791  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 2.3433  Validation loss = 7.0777  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.3430  Validation loss = 7.0767  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.3427  Validation loss = 7.0754  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.3425  Validation loss = 7.0746  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 2.3422  Validation loss = 7.0733  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 2.3418  Validation loss = 7.0721  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 2.3415  Validation loss = 7.0711  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 2.3414  Validation loss = 7.0711  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 2.3413  Validation loss = 7.0706  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 2.3413  Validation loss = 7.0704  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 2.3409  Validation loss = 7.0696  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 2.3406  Validation loss = 7.0684  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.3403  Validation loss = 7.0674  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 2.3400  Validation loss = 7.0663  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 2.3396  Validation loss = 7.0653  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 2.3394  Validation loss = 7.0647  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 2.3392  Validation loss = 7.0638  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 2.3391  Validation loss = 7.0633  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 2.3387  Validation loss = 7.0621  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 2.3384  Validation loss = 7.0609  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 2.3381  Validation loss = 7.0597  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 2.3376  Validation loss = 7.0579  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 2.3373  Validation loss = 7.0569  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 2.3373  Validation loss = 7.0574  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 2.3369  Validation loss = 7.0558  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 2.3366  Validation loss = 7.0548  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 2.3364  Validation loss = 7.0540  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 2.3361  Validation loss = 7.0532  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 2.3358  Validation loss = 7.0517  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 2.3354  Validation loss = 7.0505  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 2.3350  Validation loss = 7.0487  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 2.3347  Validation loss = 7.0473  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 2.3345  Validation loss = 7.0466  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 2.3343  Validation loss = 7.0459  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 2.3340  Validation loss = 7.0448  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 2.3338  Validation loss = 7.0443  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 2.3335  Validation loss = 7.0430  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 2.3331  Validation loss = 7.0410  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 2.3326  Validation loss = 7.0394  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 2.3323  Validation loss = 7.0379  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 2.3321  Validation loss = 7.0366  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 2.3319  Validation loss = 7.0366  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 2.3316  Validation loss = 7.0350  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 2.3315  Validation loss = 7.0353  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 2.3313  Validation loss = 7.0349  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 2.3309  Validation loss = 7.0338  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 2.3307  Validation loss = 7.0329  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 2.3304  Validation loss = 7.0317  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 2.3301  Validation loss = 7.0309  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 2.3298  Validation loss = 7.0297  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 2.3295  Validation loss = 7.0284  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 2.3293  Validation loss = 7.0280  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 2.3290  Validation loss = 7.0269  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 2.3286  Validation loss = 7.0252  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 2.3285  Validation loss = 7.0250  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 2.3282  Validation loss = 7.0235  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 2.3279  Validation loss = 7.0229  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 2.3276  Validation loss = 7.0220  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 2.3275  Validation loss = 7.0213  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 2.3271  Validation loss = 7.0199  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 2.3268  Validation loss = 7.0188  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 2.3266  Validation loss = 7.0181  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 2.3264  Validation loss = 7.0172  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 2.3260  Validation loss = 7.0164  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 2.3257  Validation loss = 7.0151  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 2.3254  Validation loss = 7.0140  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 2.3252  Validation loss = 7.0131  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 2.3248  Validation loss = 7.0115  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 2.3247  Validation loss = 7.0116  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 2.3245  Validation loss = 7.0101  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 2.3241  Validation loss = 7.0086  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 2.3237  Validation loss = 7.0072  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 2.3233  Validation loss = 7.0058  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 2.3230  Validation loss = 7.0044  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 2.3226  Validation loss = 7.0037  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 2.3224  Validation loss = 7.0032  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 2.3219  Validation loss = 7.0016  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 2.3217  Validation loss = 7.0009  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 2.3214  Validation loss = 7.0000  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 2.3213  Validation loss = 6.9999  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 2.3210  Validation loss = 6.9985  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 2.3208  Validation loss = 6.9980  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 2.3206  Validation loss = 6.9975  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 2.3204  Validation loss = 6.9967  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 2.3201  Validation loss = 6.9956  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 2.3199  Validation loss = 6.9952  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 2.3195  Validation loss = 6.9937  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 2.3192  Validation loss = 6.9926  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 2.3191  Validation loss = 6.9916  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 2.3187  Validation loss = 6.9903  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 2.3184  Validation loss = 6.9893  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 2.3181  Validation loss = 6.9884  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 2.3179  Validation loss = 6.9880  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 2.3176  Validation loss = 6.9868  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 2.3175  Validation loss = 6.9866  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 2.3172  Validation loss = 6.9852  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 2.3168  Validation loss = 6.9843  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 2.3166  Validation loss = 6.9832  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 2.3163  Validation loss = 6.9822  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 2.3161  Validation loss = 6.9813  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 2.3159  Validation loss = 6.9804  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 2.3154  Validation loss = 6.9788  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 2.3154  Validation loss = 6.9788  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 2.3152  Validation loss = 6.9785  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 2.3151  Validation loss = 6.9779  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 2.3149  Validation loss = 6.9773  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 2.3146  Validation loss = 6.9759  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 2.3142  Validation loss = 6.9747  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 2.3137  Validation loss = 6.9727  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 2.3135  Validation loss = 6.9718  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 2.3134  Validation loss = 6.9714  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 2.3130  Validation loss = 6.9701  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 2.3127  Validation loss = 6.9689  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 2.3124  Validation loss = 6.9679  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 2.3121  Validation loss = 6.9665  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 2.3119  Validation loss = 6.9658  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 2.3117  Validation loss = 6.9655  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 2.3115  Validation loss = 6.9640  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 2.3112  Validation loss = 6.9628  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 2.3110  Validation loss = 6.9627  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 2.3106  Validation loss = 6.9611  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 2.3104  Validation loss = 6.9604  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 2.3101  Validation loss = 6.9593  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 2.3098  Validation loss = 6.9582  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 2.3094  Validation loss = 6.9569  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 2.3091  Validation loss = 6.9555  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 2.3087  Validation loss = 6.9538  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 2.3083  Validation loss = 6.9518  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 2.3080  Validation loss = 6.9504  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 2.3078  Validation loss = 6.9503  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 2.3075  Validation loss = 6.9490  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 2.3073  Validation loss = 6.9480  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 2.3069  Validation loss = 6.9464  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 2.3067  Validation loss = 6.9460  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 2.3065  Validation loss = 6.9455  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 2.3064  Validation loss = 6.9451  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 2.3061  Validation loss = 6.9435  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 2.3058  Validation loss = 6.9433  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 2.3057  Validation loss = 6.9436  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 2.3057  Validation loss = 6.9432  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 2.3056  Validation loss = 6.9429  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 2.3053  Validation loss = 6.9417  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 2.3051  Validation loss = 6.9409  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 2.3049  Validation loss = 6.9403  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 2.3045  Validation loss = 6.9385  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 2.3041  Validation loss = 6.9373  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 2.3037  Validation loss = 6.9355  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 2.3035  Validation loss = 6.9349  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 2.3029  Validation loss = 6.9323  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 2.3026  Validation loss = 6.9311  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 2.3024  Validation loss = 6.9305  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 2.3022  Validation loss = 6.9296  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 2.3021  Validation loss = 6.9289  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 2.3019  Validation loss = 6.9285  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 2.3016  Validation loss = 6.9275  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 2.3015  Validation loss = 6.9267  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 2.3012  Validation loss = 6.9257  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 2.3008  Validation loss = 6.9246  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 2.3003  Validation loss = 6.9229  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 2.3001  Validation loss = 6.9221  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 2.2999  Validation loss = 6.9214  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 2.2998  Validation loss = 6.9214  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 2.2995  Validation loss = 6.9203  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 2.2993  Validation loss = 6.9194  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 2.2990  Validation loss = 6.9185  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 2.2986  Validation loss = 6.9166  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 2.2983  Validation loss = 6.9155  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 2.2982  Validation loss = 6.9154  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 2.2979  Validation loss = 6.9138  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 2.2976  Validation loss = 6.9127  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 2.2975  Validation loss = 6.9120  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 2.2975  Validation loss = 6.9119  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 2.2970  Validation loss = 6.9092  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 2.2969  Validation loss = 6.9089  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 2.2967  Validation loss = 6.9078  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 2.2962  Validation loss = 6.9059  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 2.2959  Validation loss = 6.9056  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 2.2955  Validation loss = 6.9040  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 2.2955  Validation loss = 6.9034  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 2.2951  Validation loss = 6.9019  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 2.2950  Validation loss = 6.9011  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 2.2946  Validation loss = 6.8993  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 2.2944  Validation loss = 6.8985  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 2.2942  Validation loss = 6.8985  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 2.2940  Validation loss = 6.8982  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 2.2940  Validation loss = 6.8980  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 2.2940  Validation loss = 6.8978  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 2.2936  Validation loss = 6.8966  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 2.2933  Validation loss = 6.8958  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 2.2931  Validation loss = 6.8947  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 2.2926  Validation loss = 6.8925  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 2.2924  Validation loss = 6.8927  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 2.2920  Validation loss = 6.8914  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 2.2918  Validation loss = 6.8902  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 2.2915  Validation loss = 6.8897  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 2.2914  Validation loss = 6.8886  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 2.2912  Validation loss = 6.8877  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 2.2910  Validation loss = 6.8870  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 2.2908  Validation loss = 6.8860  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 2.2907  Validation loss = 6.8840  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 2.2904  Validation loss = 6.8830  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 2.2901  Validation loss = 6.8822  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 2.2896  Validation loss = 6.8809  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 2.2894  Validation loss = 6.8793  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 2.2890  Validation loss = 6.8773  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 2.2885  Validation loss = 6.8761  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 2.2882  Validation loss = 6.8748  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 2.2881  Validation loss = 6.8740  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 2.2877  Validation loss = 6.8729  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 2.2875  Validation loss = 6.8719  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 2.2871  Validation loss = 6.8707  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 2.2868  Validation loss = 6.8691  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 2.2864  Validation loss = 6.8677  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 2.2861  Validation loss = 6.8669  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 2.2859  Validation loss = 6.8653  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 2.2859  Validation loss = 6.8654  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 2.2854  Validation loss = 6.8648  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 2.2851  Validation loss = 6.8638  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 2.2849  Validation loss = 6.8636  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 2.2845  Validation loss = 6.8618  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 2.2844  Validation loss = 6.8604  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 2.2843  Validation loss = 6.8596  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 2.2838  Validation loss = 6.8577  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 2.2836  Validation loss = 6.8565  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 2.2834  Validation loss = 6.8552  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 2.2829  Validation loss = 6.8542  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 2.2825  Validation loss = 6.8531  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 2.2823  Validation loss = 6.8520  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 2.2820  Validation loss = 6.8509  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 2.2817  Validation loss = 6.8504  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 2.2816  Validation loss = 6.8498  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 2.2814  Validation loss = 6.8497  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 2.2813  Validation loss = 6.8481  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 2.2811  Validation loss = 6.8484  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 2.2809  Validation loss = 6.8479  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 2.2807  Validation loss = 6.8470  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 2.2804  Validation loss = 6.8457  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 2.2803  Validation loss = 6.8452  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 2.2798  Validation loss = 6.8432  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 2.2798  Validation loss = 6.8431  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 2.2800  Validation loss = 6.8428  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 2.2794  Validation loss = 6.8423  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 2.2789  Validation loss = 6.8406  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 2.2787  Validation loss = 6.8396  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 2.2783  Validation loss = 6.8378  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 2.2781  Validation loss = 6.8365  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 2.2778  Validation loss = 6.8351  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 2.2775  Validation loss = 6.8340  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 2.2774  Validation loss = 6.8330  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 2.2771  Validation loss = 6.8320  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 2.2769  Validation loss = 6.8314  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 2.2766  Validation loss = 6.8301  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 2.2762  Validation loss = 6.8282  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 2.2760  Validation loss = 6.8272  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 2.2758  Validation loss = 6.8268  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 2.2755  Validation loss = 6.8258  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 2.2752  Validation loss = 6.8241  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 2.2751  Validation loss = 6.8232  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 2.2748  Validation loss = 6.8223  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 2.2744  Validation loss = 6.8203  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 2.2741  Validation loss = 6.8186  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 2.2739  Validation loss = 6.8180  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 2.2736  Validation loss = 6.8169  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 2.2735  Validation loss = 6.8156  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 2.2734  Validation loss = 6.8155  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 2.2730  Validation loss = 6.8155  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 2.2731  Validation loss = 6.8156  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 2.2729  Validation loss = 6.8147  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 2.2723  Validation loss = 6.8127  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 2.2722  Validation loss = 6.8119  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 2.2719  Validation loss = 6.8119  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 2.2715  Validation loss = 6.8096  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 2.2712  Validation loss = 6.8084  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 2.2709  Validation loss = 6.8071  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 2.2708  Validation loss = 6.8063  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 2.2707  Validation loss = 6.8056  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 2.2706  Validation loss = 6.8049  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 2.2702  Validation loss = 6.8037  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 2.2699  Validation loss = 6.8022  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 2.2700  Validation loss = 6.8023  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 2.2697  Validation loss = 6.8019  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 2.2694  Validation loss = 6.8005  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 2.2692  Validation loss = 6.8002  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 2.2690  Validation loss = 6.7990  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 2.2688  Validation loss = 6.7989  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 2.2688  Validation loss = 6.7975  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 2.2687  Validation loss = 6.7977  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 2.2685  Validation loss = 6.7974  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 2.2683  Validation loss = 6.7963  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 2.2680  Validation loss = 6.7955  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 2.2677  Validation loss = 6.7952  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 2.2675  Validation loss = 6.7955  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 2.2672  Validation loss = 6.7936  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 2.2670  Validation loss = 6.7933  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 2.2668  Validation loss = 6.7928  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 2.2665  Validation loss = 6.7917  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 2.2662  Validation loss = 6.7902  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 2.2662  Validation loss = 6.7906  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 2.2662  Validation loss = 6.7899  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 2.2658  Validation loss = 6.7879  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 2.2656  Validation loss = 6.7869  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 2.2654  Validation loss = 6.7867  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 2.2652  Validation loss = 6.7851  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 2.2650  Validation loss = 6.7850  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 2.2647  Validation loss = 6.7840  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 2.2647  Validation loss = 6.7837  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 2.2644  Validation loss = 6.7826  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 2.2641  Validation loss = 6.7817  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 2.2638  Validation loss = 6.7804  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 2.2637  Validation loss = 6.7792  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 2.2639  Validation loss = 6.7779  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 2.2634  Validation loss = 6.7773  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 2.2632  Validation loss = 6.7759  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 2.2630  Validation loss = 6.7752  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 2.2628  Validation loss = 6.7744  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 2.2628  Validation loss = 6.7726  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 2.2626  Validation loss = 6.7718  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 2.2626  Validation loss = 6.7709  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 2.2622  Validation loss = 6.7707  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 2.2618  Validation loss = 6.7688  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 2.2617  Validation loss = 6.7682  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 2.2614  Validation loss = 6.7682  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 2.2610  Validation loss = 6.7674  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 2.2612  Validation loss = 6.7665  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 2.2609  Validation loss = 6.7660  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 2.2606  Validation loss = 6.7647  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 2.2601  Validation loss = 6.7644  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 2.2600  Validation loss = 6.7631  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 2.2593  Validation loss = 6.7620  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 2.2590  Validation loss = 6.7601  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 2.2587  Validation loss = 6.7593  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 2.2586  Validation loss = 6.7583  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 2.2584  Validation loss = 6.7577  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 2.2583  Validation loss = 6.7567  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 2.2584  Validation loss = 6.7559  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 2.2582  Validation loss = 6.7549  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 2.2581  Validation loss = 6.7547  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 2.2580  Validation loss = 6.7539  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 2.2576  Validation loss = 6.7532  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 2.2571  Validation loss = 6.7526  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 2.2567  Validation loss = 6.7516  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 2.2567  Validation loss = 6.7503  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 2.2564  Validation loss = 6.7498  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 2.2562  Validation loss = 6.7495  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 2.2559  Validation loss = 6.7490  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 2.2556  Validation loss = 6.7481  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 2.2555  Validation loss = 6.7471  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 2.2554  Validation loss = 6.7461  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 2.2554  Validation loss = 6.7459  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 2.2551  Validation loss = 6.7448  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 2.2548  Validation loss = 6.7435  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 2.2547  Validation loss = 6.7423  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 2.2542  Validation loss = 6.7417  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 2.2542  Validation loss = 6.7413  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 2.2540  Validation loss = 6.7412  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 2.2538  Validation loss = 6.7409  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 2.2534  Validation loss = 6.7392  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 2.2532  Validation loss = 6.7397  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 2.2531  Validation loss = 6.7388  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 2.2527  Validation loss = 6.7374  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 2.2524  Validation loss = 6.7365  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 2.2521  Validation loss = 6.7349  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 2.2519  Validation loss = 6.7338  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 2.2516  Validation loss = 6.7334  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 2.2517  Validation loss = 6.7332  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 2.2515  Validation loss = 6.7322  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 2.2517  Validation loss = 6.7314  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 2.2515  Validation loss = 6.7293  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 2.2514  Validation loss = 6.7283  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 2.2513  Validation loss = 6.7271  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 2.2509  Validation loss = 6.7264  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 2.2506  Validation loss = 6.7256  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 2.2505  Validation loss = 6.7246  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 2.2505  Validation loss = 6.7236  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 2.2502  Validation loss = 6.7237  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 2.2498  Validation loss = 6.7234  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 2.2495  Validation loss = 6.7220  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 2.2492  Validation loss = 6.7223  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 2.2488  Validation loss = 6.7205  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 2.2488  Validation loss = 6.7193  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 2.2483  Validation loss = 6.7187  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 2.2480  Validation loss = 6.7184  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 2.2480  Validation loss = 6.7186  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 2.2476  Validation loss = 6.7177  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 2.2473  Validation loss = 6.7170  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 2.2471  Validation loss = 6.7158  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 2.2468  Validation loss = 6.7145  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 2.2466  Validation loss = 6.7133  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 2.2464  Validation loss = 6.7131  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 2.2462  Validation loss = 6.7128  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 2.2458  Validation loss = 6.7110  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 2.2454  Validation loss = 6.7101  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 2.2451  Validation loss = 6.7093  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 2.2449  Validation loss = 6.7095  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 2.2447  Validation loss = 6.7087  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 2.2446  Validation loss = 6.7080  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 2.2444  Validation loss = 6.7077  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 2.2441  Validation loss = 6.7067  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 2.2439  Validation loss = 6.7064  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 2.2436  Validation loss = 6.7056  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 2.2436  Validation loss = 6.7046  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 2.2434  Validation loss = 6.7039  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 2.2431  Validation loss = 6.7031  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 2.2428  Validation loss = 6.7026  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 2.2428  Validation loss = 6.7021  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 2.2426  Validation loss = 6.7016  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 2.2427  Validation loss = 6.7001  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 2.2424  Validation loss = 6.6988  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 2.2420  Validation loss = 6.6974  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 2.2418  Validation loss = 6.6961  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 2.2418  Validation loss = 6.6954  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 2.2414  Validation loss = 6.6955  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 2.2410  Validation loss = 6.6944  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 2.2412  Validation loss = 6.6930  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 2.2411  Validation loss = 6.6911  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 2.2409  Validation loss = 6.6909  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 2.2406  Validation loss = 6.6898  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 2.2402  Validation loss = 6.6891  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 2.2401  Validation loss = 6.6891  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 2.2399  Validation loss = 6.6883  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 2.2397  Validation loss = 6.6883  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 2.2396  Validation loss = 6.6878  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 2.2393  Validation loss = 6.6872  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 2.2394  Validation loss = 6.6869  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 2.2396  Validation loss = 6.6851  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 2.2396  Validation loss = 6.6832  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 2.2394  Validation loss = 6.6834  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 2.2390  Validation loss = 6.6831  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 2.2389  Validation loss = 6.6822  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 2.2386  Validation loss = 6.6820  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 2.2380  Validation loss = 6.6807  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 2.2379  Validation loss = 6.6792  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 2.2377  Validation loss = 6.6791  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 2.2376  Validation loss = 6.6784  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 2.2375  Validation loss = 6.6780  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 2.2375  Validation loss = 6.6767  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 2.2375  Validation loss = 6.6760  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 2.2373  Validation loss = 6.6747  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 2.2368  Validation loss = 6.6740  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 2.2363  Validation loss = 6.6739  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 2.2364  Validation loss = 6.6737  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 2.2361  Validation loss = 6.6735  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 2.2357  Validation loss = 6.6720  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 2.2355  Validation loss = 6.6705  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 2.2354  Validation loss = 6.6703  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 2.2351  Validation loss = 6.6708  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 2.2348  Validation loss = 6.6704  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 2.2345  Validation loss = 6.6690  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 2.2341  Validation loss = 6.6678  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 2.2339  Validation loss = 6.6671  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 2.2336  Validation loss = 6.6662  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 2.2333  Validation loss = 6.6653  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 2.2333  Validation loss = 6.6641  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 2.2330  Validation loss = 6.6633  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 2.2327  Validation loss = 6.6620  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 2.2324  Validation loss = 6.6607  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 2.2323  Validation loss = 6.6602  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 2.2322  Validation loss = 6.6598  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 2.2320  Validation loss = 6.6585  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 2.2319  Validation loss = 6.6586  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 2.2320  Validation loss = 6.6589  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 2.2317  Validation loss = 6.6580  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 2.2314  Validation loss = 6.6570  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 2.2315  Validation loss = 6.6565  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 2.2310  Validation loss = 6.6560  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 2.2305  Validation loss = 6.6553  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 2.2305  Validation loss = 6.6542  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 2.2303  Validation loss = 6.6540  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 2.2300  Validation loss = 6.6531  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 2.2296  Validation loss = 6.6520  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 2.2295  Validation loss = 6.6511  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 2.2295  Validation loss = 6.6508  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 2.2299  Validation loss = 6.6507  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 2.2299  Validation loss = 6.6507  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 2.2301  Validation loss = 6.6503  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 2.2297  Validation loss = 6.6501  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 2.2293  Validation loss = 6.6487  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 2.2292  Validation loss = 6.6479  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 2.2284  Validation loss = 6.6470  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 2.2278  Validation loss = 6.6457  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 2.2281  Validation loss = 6.6445  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 2.2276  Validation loss = 6.6439  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 2.2273  Validation loss = 6.6431  \n",
      "\n",
      "Fold: 14  Epoch: 501  Training loss = 2.2271  Validation loss = 6.6431  \n",
      "\n",
      "Fold: 14  Epoch: 502  Training loss = 2.2269  Validation loss = 6.6429  \n",
      "\n",
      "Fold: 14  Epoch: 503  Training loss = 2.2265  Validation loss = 6.6424  \n",
      "\n",
      "Fold: 14  Epoch: 504  Training loss = 2.2263  Validation loss = 6.6408  \n",
      "\n",
      "Fold: 14  Epoch: 505  Training loss = 2.2260  Validation loss = 6.6405  \n",
      "\n",
      "Fold: 14  Epoch: 506  Training loss = 2.2259  Validation loss = 6.6397  \n",
      "\n",
      "Fold: 14  Epoch: 507  Training loss = 2.2258  Validation loss = 6.6387  \n",
      "\n",
      "Fold: 14  Epoch: 508  Training loss = 2.2257  Validation loss = 6.6382  \n",
      "\n",
      "Fold: 14  Epoch: 509  Training loss = 2.2255  Validation loss = 6.6377  \n",
      "\n",
      "Fold: 14  Epoch: 510  Training loss = 2.2250  Validation loss = 6.6365  \n",
      "\n",
      "Fold: 14  Epoch: 511  Training loss = 2.2247  Validation loss = 6.6355  \n",
      "\n",
      "Fold: 14  Epoch: 512  Training loss = 2.2247  Validation loss = 6.6345  \n",
      "\n",
      "Fold: 14  Epoch: 513  Training loss = 2.2243  Validation loss = 6.6335  \n",
      "\n",
      "Fold: 14  Epoch: 514  Training loss = 2.2240  Validation loss = 6.6329  \n",
      "\n",
      "Fold: 14  Epoch: 515  Training loss = 2.2239  Validation loss = 6.6327  \n",
      "\n",
      "Fold: 14  Epoch: 516  Training loss = 2.2236  Validation loss = 6.6316  \n",
      "\n",
      "Fold: 14  Epoch: 517  Training loss = 2.2232  Validation loss = 6.6294  \n",
      "\n",
      "Fold: 14  Epoch: 518  Training loss = 2.2230  Validation loss = 6.6288  \n",
      "\n",
      "Fold: 14  Epoch: 519  Training loss = 2.2227  Validation loss = 6.6271  \n",
      "\n",
      "Fold: 14  Epoch: 520  Training loss = 2.2225  Validation loss = 6.6264  \n",
      "\n",
      "Fold: 14  Epoch: 521  Training loss = 2.2223  Validation loss = 6.6266  \n",
      "\n",
      "Fold: 14  Epoch: 522  Training loss = 2.2222  Validation loss = 6.6263  \n",
      "\n",
      "Fold: 14  Epoch: 523  Training loss = 2.2219  Validation loss = 6.6253  \n",
      "\n",
      "Fold: 14  Epoch: 524  Training loss = 2.2217  Validation loss = 6.6245  \n",
      "\n",
      "Fold: 14  Epoch: 525  Training loss = 2.2214  Validation loss = 6.6228  \n",
      "\n",
      "Fold: 14  Epoch: 526  Training loss = 2.2212  Validation loss = 6.6228  \n",
      "\n",
      "Fold: 14  Epoch: 527  Training loss = 2.2209  Validation loss = 6.6222  \n",
      "\n",
      "Fold: 14  Epoch: 528  Training loss = 2.2207  Validation loss = 6.6217  \n",
      "\n",
      "Fold: 14  Epoch: 529  Training loss = 2.2205  Validation loss = 6.6212  \n",
      "\n",
      "Fold: 14  Epoch: 530  Training loss = 2.2202  Validation loss = 6.6207  \n",
      "\n",
      "Fold: 14  Epoch: 531  Training loss = 2.2201  Validation loss = 6.6195  \n",
      "\n",
      "Fold: 14  Epoch: 532  Training loss = 2.2198  Validation loss = 6.6175  \n",
      "\n",
      "Fold: 14  Epoch: 533  Training loss = 2.2195  Validation loss = 6.6166  \n",
      "\n",
      "Fold: 14  Epoch: 534  Training loss = 2.2195  Validation loss = 6.6163  \n",
      "\n",
      "Fold: 14  Epoch: 535  Training loss = 2.2193  Validation loss = 6.6155  \n",
      "\n",
      "Fold: 14  Epoch: 536  Training loss = 2.2190  Validation loss = 6.6138  \n",
      "\n",
      "Fold: 14  Epoch: 537  Training loss = 2.2189  Validation loss = 6.6134  \n",
      "\n",
      "Fold: 14  Epoch: 538  Training loss = 2.2187  Validation loss = 6.6125  \n",
      "\n",
      "Fold: 14  Epoch: 539  Training loss = 2.2183  Validation loss = 6.6110  \n",
      "\n",
      "Fold: 14  Epoch: 540  Training loss = 2.2180  Validation loss = 6.6114  \n",
      "\n",
      "Fold: 14  Epoch: 541  Training loss = 2.2179  Validation loss = 6.6111  \n",
      "\n",
      "Fold: 14  Epoch: 542  Training loss = 2.2177  Validation loss = 6.6107  \n",
      "\n",
      "Fold: 14  Epoch: 543  Training loss = 2.2174  Validation loss = 6.6099  \n",
      "\n",
      "Fold: 14  Epoch: 544  Training loss = 2.2175  Validation loss = 6.6094  \n",
      "\n",
      "Fold: 14  Epoch: 545  Training loss = 2.2172  Validation loss = 6.6087  \n",
      "\n",
      "Fold: 14  Epoch: 546  Training loss = 2.2168  Validation loss = 6.6077  \n",
      "\n",
      "Fold: 14  Epoch: 547  Training loss = 2.2166  Validation loss = 6.6066  \n",
      "\n",
      "Fold: 14  Epoch: 548  Training loss = 2.2167  Validation loss = 6.6063  \n",
      "\n",
      "Fold: 14  Epoch: 549  Training loss = 2.2170  Validation loss = 6.6060  \n",
      "\n",
      "Fold: 14  Epoch: 550  Training loss = 2.2163  Validation loss = 6.6051  \n",
      "\n",
      "Fold: 14  Epoch: 551  Training loss = 2.2161  Validation loss = 6.6048  \n",
      "\n",
      "Fold: 14  Epoch: 552  Training loss = 2.2160  Validation loss = 6.6047  \n",
      "\n",
      "Fold: 14  Epoch: 553  Training loss = 2.2157  Validation loss = 6.6043  \n",
      "\n",
      "Fold: 14  Epoch: 554  Training loss = 2.2157  Validation loss = 6.6031  \n",
      "\n",
      "Fold: 14  Epoch: 555  Training loss = 2.2154  Validation loss = 6.6025  \n",
      "\n",
      "Fold: 14  Epoch: 556  Training loss = 2.2151  Validation loss = 6.6017  \n",
      "\n",
      "Fold: 14  Epoch: 557  Training loss = 2.2150  Validation loss = 6.6009  \n",
      "\n",
      "Fold: 14  Epoch: 558  Training loss = 2.2148  Validation loss = 6.6005  \n",
      "\n",
      "Fold: 14  Epoch: 559  Training loss = 2.2146  Validation loss = 6.5998  \n",
      "\n",
      "Fold: 14  Epoch: 560  Training loss = 2.2142  Validation loss = 6.5989  \n",
      "\n",
      "Fold: 14  Epoch: 561  Training loss = 2.2141  Validation loss = 6.5981  \n",
      "\n",
      "Fold: 14  Epoch: 562  Training loss = 2.2142  Validation loss = 6.5971  \n",
      "\n",
      "Fold: 14  Epoch: 563  Training loss = 2.2140  Validation loss = 6.5968  \n",
      "\n",
      "Fold: 14  Epoch: 564  Training loss = 2.2133  Validation loss = 6.5953  \n",
      "\n",
      "Fold: 14  Epoch: 565  Training loss = 2.2132  Validation loss = 6.5946  \n",
      "\n",
      "Fold: 14  Epoch: 566  Training loss = 2.2131  Validation loss = 6.5943  \n",
      "\n",
      "Fold: 14  Epoch: 567  Training loss = 2.2132  Validation loss = 6.5937  \n",
      "\n",
      "Fold: 14  Epoch: 568  Training loss = 2.2129  Validation loss = 6.5927  \n",
      "\n",
      "Fold: 14  Epoch: 569  Training loss = 2.2130  Validation loss = 6.5924  \n",
      "\n",
      "Fold: 14  Epoch: 570  Training loss = 2.2126  Validation loss = 6.5915  \n",
      "\n",
      "Fold: 14  Epoch: 571  Training loss = 2.2121  Validation loss = 6.5897  \n",
      "\n",
      "Fold: 14  Epoch: 572  Training loss = 2.2118  Validation loss = 6.5888  \n",
      "\n",
      "Fold: 14  Epoch: 573  Training loss = 2.2120  Validation loss = 6.5882  \n",
      "\n",
      "Fold: 14  Epoch: 574  Training loss = 2.2118  Validation loss = 6.5882  \n",
      "\n",
      "Fold: 14  Epoch: 575  Training loss = 2.2120  Validation loss = 6.5878  \n",
      "\n",
      "Fold: 14  Epoch: 576  Training loss = 2.2116  Validation loss = 6.5869  \n",
      "\n",
      "Fold: 14  Epoch: 577  Training loss = 2.2115  Validation loss = 6.5866  \n",
      "\n",
      "Fold: 14  Epoch: 578  Training loss = 2.2110  Validation loss = 6.5851  \n",
      "\n",
      "Fold: 14  Epoch: 579  Training loss = 2.2104  Validation loss = 6.5840  \n",
      "\n",
      "Fold: 14  Epoch: 580  Training loss = 2.2101  Validation loss = 6.5830  \n",
      "\n",
      "Fold: 14  Epoch: 581  Training loss = 2.2099  Validation loss = 6.5821  \n",
      "\n",
      "Fold: 14  Epoch: 582  Training loss = 2.2100  Validation loss = 6.5825  \n",
      "\n",
      "Fold: 14  Epoch: 583  Training loss = 2.2099  Validation loss = 6.5810  \n",
      "\n",
      "Fold: 14  Epoch: 584  Training loss = 2.2103  Validation loss = 6.5812  \n",
      "\n",
      "Fold: 14  Epoch: 585  Training loss = 2.2091  Validation loss = 6.5809  \n",
      "\n",
      "Fold: 14  Epoch: 586  Training loss = 2.2090  Validation loss = 6.5809  \n",
      "\n",
      "Fold: 14  Epoch: 587  Training loss = 2.2089  Validation loss = 6.5800  \n",
      "\n",
      "Fold: 14  Epoch: 588  Training loss = 2.2082  Validation loss = 6.5778  \n",
      "\n",
      "Fold: 14  Epoch: 589  Training loss = 2.2077  Validation loss = 6.5767  \n",
      "\n",
      "Fold: 14  Epoch: 590  Training loss = 2.2074  Validation loss = 6.5766  \n",
      "\n",
      "Fold: 14  Epoch: 591  Training loss = 2.2074  Validation loss = 6.5761  \n",
      "\n",
      "Fold: 14  Epoch: 592  Training loss = 2.2071  Validation loss = 6.5756  \n",
      "\n",
      "Fold: 14  Epoch: 593  Training loss = 2.2072  Validation loss = 6.5754  \n",
      "\n",
      "Fold: 14  Epoch: 594  Training loss = 2.2072  Validation loss = 6.5750  \n",
      "\n",
      "Fold: 14  Epoch: 595  Training loss = 2.2067  Validation loss = 6.5744  \n",
      "\n",
      "Fold: 14  Epoch: 596  Training loss = 2.2064  Validation loss = 6.5727  \n",
      "\n",
      "Fold: 14  Epoch: 597  Training loss = 2.2059  Validation loss = 6.5714  \n",
      "\n",
      "Fold: 14  Epoch: 598  Training loss = 2.2057  Validation loss = 6.5702  \n",
      "\n",
      "Fold: 14  Epoch: 599  Training loss = 2.2057  Validation loss = 6.5697  \n",
      "\n",
      "Fold: 14  Epoch: 600  Training loss = 2.2055  Validation loss = 6.5692  \n",
      "\n",
      "Fold: 14  Epoch: 601  Training loss = 2.2053  Validation loss = 6.5698  \n",
      "\n",
      "Fold: 14  Epoch: 602  Training loss = 2.2050  Validation loss = 6.5692  \n",
      "\n",
      "Fold: 14  Epoch: 603  Training loss = 2.2049  Validation loss = 6.5683  \n",
      "\n",
      "Fold: 14  Epoch: 604  Training loss = 2.2048  Validation loss = 6.5677  \n",
      "\n",
      "Fold: 14  Epoch: 605  Training loss = 2.2046  Validation loss = 6.5668  \n",
      "\n",
      "Fold: 14  Epoch: 606  Training loss = 2.2043  Validation loss = 6.5659  \n",
      "\n",
      "Fold: 14  Epoch: 607  Training loss = 2.2043  Validation loss = 6.5650  \n",
      "\n",
      "Fold: 14  Epoch: 608  Training loss = 2.2039  Validation loss = 6.5643  \n",
      "\n",
      "Fold: 14  Epoch: 609  Training loss = 2.2037  Validation loss = 6.5636  \n",
      "\n",
      "Fold: 14  Epoch: 610  Training loss = 2.2034  Validation loss = 6.5631  \n",
      "\n",
      "Fold: 14  Epoch: 611  Training loss = 2.2033  Validation loss = 6.5618  \n",
      "\n",
      "Fold: 14  Epoch: 612  Training loss = 2.2031  Validation loss = 6.5614  \n",
      "\n",
      "Fold: 14  Epoch: 613  Training loss = 2.2026  Validation loss = 6.5603  \n",
      "\n",
      "Fold: 14  Epoch: 614  Training loss = 2.2023  Validation loss = 6.5592  \n",
      "\n",
      "Fold: 14  Epoch: 615  Training loss = 2.2022  Validation loss = 6.5588  \n",
      "\n",
      "Fold: 14  Epoch: 616  Training loss = 2.2019  Validation loss = 6.5570  \n",
      "\n",
      "Fold: 14  Epoch: 617  Training loss = 2.2017  Validation loss = 6.5569  \n",
      "\n",
      "Fold: 14  Epoch: 618  Training loss = 2.2015  Validation loss = 6.5560  \n",
      "\n",
      "Fold: 14  Epoch: 619  Training loss = 2.2012  Validation loss = 6.5559  \n",
      "\n",
      "Fold: 14  Epoch: 620  Training loss = 2.2010  Validation loss = 6.5546  \n",
      "\n",
      "Fold: 14  Epoch: 621  Training loss = 2.2009  Validation loss = 6.5544  \n",
      "\n",
      "Fold: 14  Epoch: 622  Training loss = 2.2006  Validation loss = 6.5533  \n",
      "\n",
      "Fold: 14  Epoch: 623  Training loss = 2.2006  Validation loss = 6.5533  \n",
      "\n",
      "Fold: 14  Epoch: 624  Training loss = 2.2005  Validation loss = 6.5530  \n",
      "\n",
      "Fold: 14  Epoch: 625  Training loss = 2.2003  Validation loss = 6.5529  \n",
      "\n",
      "Fold: 14  Epoch: 626  Training loss = 2.2002  Validation loss = 6.5521  \n",
      "\n",
      "Fold: 14  Epoch: 627  Training loss = 2.2000  Validation loss = 6.5517  \n",
      "\n",
      "Fold: 14  Epoch: 628  Training loss = 2.1998  Validation loss = 6.5507  \n",
      "\n",
      "Fold: 14  Epoch: 629  Training loss = 2.1995  Validation loss = 6.5488  \n",
      "\n",
      "Fold: 14  Epoch: 630  Training loss = 2.1994  Validation loss = 6.5481  \n",
      "\n",
      "Fold: 14  Epoch: 631  Training loss = 2.1989  Validation loss = 6.5464  \n",
      "\n",
      "Fold: 14  Epoch: 632  Training loss = 2.1988  Validation loss = 6.5465  \n",
      "\n",
      "Fold: 14  Epoch: 633  Training loss = 2.1985  Validation loss = 6.5449  \n",
      "\n",
      "Fold: 14  Epoch: 634  Training loss = 2.1982  Validation loss = 6.5447  \n",
      "\n",
      "Fold: 14  Epoch: 635  Training loss = 2.1982  Validation loss = 6.5439  \n",
      "\n",
      "Fold: 14  Epoch: 636  Training loss = 2.1981  Validation loss = 6.5435  \n",
      "\n",
      "Fold: 14  Epoch: 637  Training loss = 2.1978  Validation loss = 6.5423  \n",
      "\n",
      "Fold: 14  Epoch: 638  Training loss = 2.1976  Validation loss = 6.5420  \n",
      "\n",
      "Fold: 14  Epoch: 639  Training loss = 2.1973  Validation loss = 6.5411  \n",
      "\n",
      "Fold: 14  Epoch: 640  Training loss = 2.1972  Validation loss = 6.5415  \n",
      "\n",
      "Fold: 14  Epoch: 641  Training loss = 2.1970  Validation loss = 6.5401  \n",
      "\n",
      "Fold: 14  Epoch: 642  Training loss = 2.1965  Validation loss = 6.5390  \n",
      "\n",
      "Fold: 14  Epoch: 643  Training loss = 2.1968  Validation loss = 6.5397  \n",
      "\n",
      "Fold: 14  Epoch: 644  Training loss = 2.1969  Validation loss = 6.5390  \n",
      "\n",
      "Fold: 14  Epoch: 645  Training loss = 2.1964  Validation loss = 6.5380  \n",
      "\n",
      "Fold: 14  Epoch: 646  Training loss = 2.1968  Validation loss = 6.5384  \n",
      "\n",
      "Fold: 14  Epoch: 647  Training loss = 2.1960  Validation loss = 6.5373  \n",
      "\n",
      "Fold: 14  Epoch: 648  Training loss = 2.1959  Validation loss = 6.5366  \n",
      "\n",
      "Fold: 14  Epoch: 649  Training loss = 2.1956  Validation loss = 6.5354  \n",
      "\n",
      "Fold: 14  Epoch: 650  Training loss = 2.1958  Validation loss = 6.5348  \n",
      "\n",
      "Fold: 14  Epoch: 651  Training loss = 2.1955  Validation loss = 6.5349  \n",
      "\n",
      "Fold: 14  Epoch: 652  Training loss = 2.1950  Validation loss = 6.5340  \n",
      "\n",
      "Fold: 14  Epoch: 653  Training loss = 2.1947  Validation loss = 6.5336  \n",
      "\n",
      "Fold: 14  Epoch: 654  Training loss = 2.1945  Validation loss = 6.5327  \n",
      "\n",
      "Fold: 14  Epoch: 655  Training loss = 2.1945  Validation loss = 6.5321  \n",
      "\n",
      "Fold: 14  Epoch: 656  Training loss = 2.1944  Validation loss = 6.5319  \n",
      "\n",
      "Fold: 14  Epoch: 657  Training loss = 2.1940  Validation loss = 6.5313  \n",
      "\n",
      "Fold: 14  Epoch: 658  Training loss = 2.1934  Validation loss = 6.5292  \n",
      "\n",
      "Fold: 14  Epoch: 659  Training loss = 2.1934  Validation loss = 6.5277  \n",
      "\n",
      "Fold: 14  Epoch: 660  Training loss = 2.1927  Validation loss = 6.5256  \n",
      "\n",
      "Fold: 14  Epoch: 661  Training loss = 2.1921  Validation loss = 6.5245  \n",
      "\n",
      "Fold: 14  Epoch: 662  Training loss = 2.1920  Validation loss = 6.5234  \n",
      "\n",
      "Fold: 14  Epoch: 663  Training loss = 2.1919  Validation loss = 6.5225  \n",
      "\n",
      "Fold: 14  Epoch: 664  Training loss = 2.1916  Validation loss = 6.5216  \n",
      "\n",
      "Fold: 14  Epoch: 665  Training loss = 2.1913  Validation loss = 6.5205  \n",
      "\n",
      "Fold: 14  Epoch: 666  Training loss = 2.1909  Validation loss = 6.5200  \n",
      "\n",
      "Fold: 14  Epoch: 667  Training loss = 2.1907  Validation loss = 6.5193  \n",
      "\n",
      "Fold: 14  Epoch: 668  Training loss = 2.1906  Validation loss = 6.5192  \n",
      "\n",
      "Fold: 14  Epoch: 669  Training loss = 2.1902  Validation loss = 6.5177  \n",
      "\n",
      "Fold: 14  Epoch: 670  Training loss = 2.1898  Validation loss = 6.5166  \n",
      "\n",
      "Fold: 14  Epoch: 671  Training loss = 2.1897  Validation loss = 6.5173  \n",
      "\n",
      "Fold: 14  Epoch: 672  Training loss = 2.1895  Validation loss = 6.5157  \n",
      "\n",
      "Fold: 14  Epoch: 673  Training loss = 2.1892  Validation loss = 6.5148  \n",
      "\n",
      "Fold: 14  Epoch: 674  Training loss = 2.1889  Validation loss = 6.5142  \n",
      "\n",
      "Fold: 14  Epoch: 675  Training loss = 2.1886  Validation loss = 6.5127  \n",
      "\n",
      "Fold: 14  Epoch: 676  Training loss = 2.1887  Validation loss = 6.5117  \n",
      "\n",
      "Fold: 14  Epoch: 677  Training loss = 2.1886  Validation loss = 6.5104  \n",
      "\n",
      "Fold: 14  Epoch: 678  Training loss = 2.1884  Validation loss = 6.5091  \n",
      "\n",
      "Fold: 14  Epoch: 679  Training loss = 2.1878  Validation loss = 6.5089  \n",
      "\n",
      "Fold: 14  Epoch: 680  Training loss = 2.1876  Validation loss = 6.5085  \n",
      "\n",
      "Fold: 14  Epoch: 681  Training loss = 2.1874  Validation loss = 6.5074  \n",
      "\n",
      "Fold: 14  Epoch: 682  Training loss = 2.1873  Validation loss = 6.5062  \n",
      "\n",
      "Fold: 14  Epoch: 683  Training loss = 2.1868  Validation loss = 6.5056  \n",
      "\n",
      "Fold: 14  Epoch: 684  Training loss = 2.1866  Validation loss = 6.5052  \n",
      "\n",
      "Fold: 14  Epoch: 685  Training loss = 2.1863  Validation loss = 6.5042  \n",
      "\n",
      "Fold: 14  Epoch: 686  Training loss = 2.1860  Validation loss = 6.5027  \n",
      "\n",
      "Fold: 14  Epoch: 687  Training loss = 2.1856  Validation loss = 6.5007  \n",
      "\n",
      "Fold: 14  Epoch: 688  Training loss = 2.1855  Validation loss = 6.5011  \n",
      "\n",
      "Fold: 14  Epoch: 689  Training loss = 2.1853  Validation loss = 6.5009  \n",
      "\n",
      "Fold: 14  Epoch: 690  Training loss = 2.1851  Validation loss = 6.5003  \n",
      "\n",
      "Fold: 14  Epoch: 691  Training loss = 2.1849  Validation loss = 6.5002  \n",
      "\n",
      "Fold: 14  Epoch: 692  Training loss = 2.1848  Validation loss = 6.4984  \n",
      "\n",
      "Fold: 14  Epoch: 693  Training loss = 2.1845  Validation loss = 6.4976  \n",
      "\n",
      "Fold: 14  Epoch: 694  Training loss = 2.1843  Validation loss = 6.4973  \n",
      "\n",
      "Fold: 14  Epoch: 695  Training loss = 2.1839  Validation loss = 6.4958  \n",
      "\n",
      "Fold: 14  Epoch: 696  Training loss = 2.1836  Validation loss = 6.4949  \n",
      "\n",
      "Fold: 14  Epoch: 697  Training loss = 2.1835  Validation loss = 6.4950  \n",
      "\n",
      "Fold: 14  Epoch: 698  Training loss = 2.1831  Validation loss = 6.4944  \n",
      "\n",
      "Fold: 14  Epoch: 699  Training loss = 2.1829  Validation loss = 6.4928  \n",
      "\n",
      "Fold: 14  Epoch: 700  Training loss = 2.1827  Validation loss = 6.4910  \n",
      "\n",
      "Fold: 14  Epoch: 701  Training loss = 2.1827  Validation loss = 6.4904  \n",
      "\n",
      "Fold: 14  Epoch: 702  Training loss = 2.1828  Validation loss = 6.4896  \n",
      "\n",
      "Fold: 14  Epoch: 703  Training loss = 2.1826  Validation loss = 6.4882  \n",
      "\n",
      "Fold: 14  Epoch: 704  Training loss = 2.1819  Validation loss = 6.4865  \n",
      "\n",
      "Fold: 14  Epoch: 705  Training loss = 2.1824  Validation loss = 6.4865  \n",
      "\n",
      "Fold: 14  Epoch: 706  Training loss = 2.1825  Validation loss = 6.4852  \n",
      "\n",
      "Fold: 14  Epoch: 707  Training loss = 2.1827  Validation loss = 6.4849  \n",
      "\n",
      "Fold: 14  Epoch: 708  Training loss = 2.1809  Validation loss = 6.4833  \n",
      "\n",
      "Fold: 14  Epoch: 709  Training loss = 2.1808  Validation loss = 6.4825  \n",
      "\n",
      "Fold: 14  Epoch: 710  Training loss = 2.1800  Validation loss = 6.4813  \n",
      "\n",
      "Fold: 14  Epoch: 711  Training loss = 2.1798  Validation loss = 6.4816  \n",
      "\n",
      "Fold: 14  Epoch: 712  Training loss = 2.1795  Validation loss = 6.4812  \n",
      "\n",
      "Fold: 14  Epoch: 713  Training loss = 2.1791  Validation loss = 6.4804  \n",
      "\n",
      "Fold: 14  Epoch: 714  Training loss = 2.1790  Validation loss = 6.4796  \n",
      "\n",
      "Fold: 14  Epoch: 715  Training loss = 2.1786  Validation loss = 6.4781  \n",
      "\n",
      "Fold: 14  Epoch: 716  Training loss = 2.1782  Validation loss = 6.4776  \n",
      "\n",
      "Fold: 14  Epoch: 717  Training loss = 2.1779  Validation loss = 6.4766  \n",
      "\n",
      "Fold: 14  Epoch: 718  Training loss = 2.1777  Validation loss = 6.4750  \n",
      "\n",
      "Fold: 14  Epoch: 719  Training loss = 2.1777  Validation loss = 6.4743  \n",
      "\n",
      "Fold: 14  Epoch: 720  Training loss = 2.1771  Validation loss = 6.4738  \n",
      "\n",
      "Fold: 14  Epoch: 721  Training loss = 2.1768  Validation loss = 6.4739  \n",
      "\n",
      "Fold: 14  Epoch: 722  Training loss = 2.1766  Validation loss = 6.4731  \n",
      "\n",
      "Fold: 14  Epoch: 723  Training loss = 2.1763  Validation loss = 6.4730  \n",
      "\n",
      "Fold: 14  Epoch: 724  Training loss = 2.1760  Validation loss = 6.4714  \n",
      "\n",
      "Fold: 14  Epoch: 725  Training loss = 2.1758  Validation loss = 6.4712  \n",
      "\n",
      "Fold: 14  Epoch: 726  Training loss = 2.1756  Validation loss = 6.4709  \n",
      "\n",
      "Fold: 14  Epoch: 727  Training loss = 2.1755  Validation loss = 6.4698  \n",
      "\n",
      "Fold: 14  Epoch: 728  Training loss = 2.1753  Validation loss = 6.4694  \n",
      "\n",
      "Fold: 14  Epoch: 729  Training loss = 2.1751  Validation loss = 6.4676  \n",
      "\n",
      "Fold: 14  Epoch: 730  Training loss = 2.1749  Validation loss = 6.4670  \n",
      "\n",
      "Fold: 14  Epoch: 731  Training loss = 2.1746  Validation loss = 6.4667  \n",
      "\n",
      "Fold: 14  Epoch: 732  Training loss = 2.1744  Validation loss = 6.4664  \n",
      "\n",
      "Fold: 14  Epoch: 733  Training loss = 2.1742  Validation loss = 6.4661  \n",
      "\n",
      "Fold: 14  Epoch: 734  Training loss = 2.1741  Validation loss = 6.4650  \n",
      "\n",
      "Fold: 14  Epoch: 735  Training loss = 2.1741  Validation loss = 6.4643  \n",
      "\n",
      "Fold: 14  Epoch: 736  Training loss = 2.1737  Validation loss = 6.4632  \n",
      "\n",
      "Fold: 14  Epoch: 737  Training loss = 2.1734  Validation loss = 6.4623  \n",
      "\n",
      "Fold: 14  Epoch: 738  Training loss = 2.1729  Validation loss = 6.4618  \n",
      "\n",
      "Fold: 14  Epoch: 739  Training loss = 2.1727  Validation loss = 6.4617  \n",
      "\n",
      "Fold: 14  Epoch: 740  Training loss = 2.1725  Validation loss = 6.4614  \n",
      "\n",
      "Fold: 14  Epoch: 741  Training loss = 2.1725  Validation loss = 6.4607  \n",
      "\n",
      "Fold: 14  Epoch: 742  Training loss = 2.1728  Validation loss = 6.4613  \n",
      "\n",
      "Fold: 14  Epoch: 743  Training loss = 2.1727  Validation loss = 6.4603  \n",
      "\n",
      "Fold: 14  Epoch: 744  Training loss = 2.1727  Validation loss = 6.4596  \n",
      "\n",
      "Fold: 14  Epoch: 745  Training loss = 2.1720  Validation loss = 6.4584  \n",
      "\n",
      "Fold: 14  Epoch: 746  Training loss = 2.1714  Validation loss = 6.4573  \n",
      "\n",
      "Fold: 14  Epoch: 747  Training loss = 2.1711  Validation loss = 6.4563  \n",
      "\n",
      "Fold: 14  Epoch: 748  Training loss = 2.1711  Validation loss = 6.4558  \n",
      "\n",
      "Fold: 14  Epoch: 749  Training loss = 2.1708  Validation loss = 6.4549  \n",
      "\n",
      "Fold: 14  Epoch: 750  Training loss = 2.1706  Validation loss = 6.4540  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 750  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.6775  Validation loss = 7.2939  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.6767  Validation loss = 7.2918  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.6757  Validation loss = 7.2897  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.6752  Validation loss = 7.2887  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.6746  Validation loss = 7.2870  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.6742  Validation loss = 7.2863  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.6734  Validation loss = 7.2845  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.6725  Validation loss = 7.2824  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.6723  Validation loss = 7.2818  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.6717  Validation loss = 7.2807  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.6710  Validation loss = 7.2792  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.6705  Validation loss = 7.2783  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.6701  Validation loss = 7.2775  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.6697  Validation loss = 7.2767  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.6688  Validation loss = 7.2744  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.6681  Validation loss = 7.2730  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.6677  Validation loss = 7.2722  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.6670  Validation loss = 7.2705  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.6664  Validation loss = 7.2689  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.6659  Validation loss = 7.2679  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.6652  Validation loss = 7.2668  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.6651  Validation loss = 7.2662  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.6648  Validation loss = 7.2653  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.6643  Validation loss = 7.2643  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.6641  Validation loss = 7.2633  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 2.6633  Validation loss = 7.2620  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.6625  Validation loss = 7.2602  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 2.6617  Validation loss = 7.2589  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 2.6610  Validation loss = 7.2574  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 2.6604  Validation loss = 7.2560  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 2.6598  Validation loss = 7.2547  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.6591  Validation loss = 7.2532  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 2.6585  Validation loss = 7.2519  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 2.6576  Validation loss = 7.2493  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 2.6568  Validation loss = 7.2476  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 2.6564  Validation loss = 7.2472  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 2.6560  Validation loss = 7.2464  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 2.6555  Validation loss = 7.2454  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 2.6549  Validation loss = 7.2439  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 2.6540  Validation loss = 7.2417  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 2.6536  Validation loss = 7.2410  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 2.6531  Validation loss = 7.2396  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 2.6528  Validation loss = 7.2385  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 2.6519  Validation loss = 7.2369  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 2.6515  Validation loss = 7.2361  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 2.6511  Validation loss = 7.2352  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 2.6502  Validation loss = 7.2330  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 2.6496  Validation loss = 7.2316  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 2.6489  Validation loss = 7.2300  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 2.6488  Validation loss = 7.2298  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 2.6481  Validation loss = 7.2281  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 2.6475  Validation loss = 7.2269  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 2.6472  Validation loss = 7.2262  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 2.6465  Validation loss = 7.2244  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 2.6458  Validation loss = 7.2228  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 2.6451  Validation loss = 7.2209  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 2.6445  Validation loss = 7.2197  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 2.6437  Validation loss = 7.2180  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 2.6432  Validation loss = 7.2166  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 2.6425  Validation loss = 7.2150  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 2.6419  Validation loss = 7.2138  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 2.6420  Validation loss = 7.2137  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 2.6414  Validation loss = 7.2123  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 2.6413  Validation loss = 7.2120  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 2.6409  Validation loss = 7.2109  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 2.6402  Validation loss = 7.2094  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 2.6397  Validation loss = 7.2081  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 2.6390  Validation loss = 7.2060  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 2.6380  Validation loss = 7.2048  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 2.6372  Validation loss = 7.2031  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 2.6365  Validation loss = 7.2017  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 2.6358  Validation loss = 7.2002  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 2.6351  Validation loss = 7.1989  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 2.6347  Validation loss = 7.1978  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 2.6341  Validation loss = 7.1970  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 2.6337  Validation loss = 7.1955  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 2.6331  Validation loss = 7.1949  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 2.6325  Validation loss = 7.1938  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 2.6323  Validation loss = 7.1934  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 2.6312  Validation loss = 7.1913  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 2.6307  Validation loss = 7.1902  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 2.6302  Validation loss = 7.1886  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 2.6297  Validation loss = 7.1872  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 2.6292  Validation loss = 7.1858  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 2.6285  Validation loss = 7.1841  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 2.6280  Validation loss = 7.1832  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 2.6274  Validation loss = 7.1820  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 2.6270  Validation loss = 7.1810  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 2.6263  Validation loss = 7.1801  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 2.6261  Validation loss = 7.1792  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 2.6254  Validation loss = 7.1776  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 2.6246  Validation loss = 7.1755  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 2.6244  Validation loss = 7.1747  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 2.6239  Validation loss = 7.1738  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 2.6235  Validation loss = 7.1725  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 2.6235  Validation loss = 7.1718  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 2.6233  Validation loss = 7.1707  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 2.6223  Validation loss = 7.1684  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 2.6216  Validation loss = 7.1666  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 2.6211  Validation loss = 7.1668  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 2.6205  Validation loss = 7.1649  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 2.6202  Validation loss = 7.1648  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 2.6195  Validation loss = 7.1633  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 2.6186  Validation loss = 7.1613  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 2.6184  Validation loss = 7.1599  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 2.6178  Validation loss = 7.1587  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 2.6174  Validation loss = 7.1575  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 2.6171  Validation loss = 7.1557  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 2.6162  Validation loss = 7.1540  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 2.6155  Validation loss = 7.1539  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 2.6150  Validation loss = 7.1529  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 2.6147  Validation loss = 7.1520  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 2.6141  Validation loss = 7.1507  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 2.6135  Validation loss = 7.1494  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 2.6127  Validation loss = 7.1478  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 2.6125  Validation loss = 7.1475  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 2.6120  Validation loss = 7.1465  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 2.6115  Validation loss = 7.1458  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 2.6114  Validation loss = 7.1453  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 2.6111  Validation loss = 7.1438  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 2.6108  Validation loss = 7.1437  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 2.6103  Validation loss = 7.1428  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 2.6099  Validation loss = 7.1414  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 2.6094  Validation loss = 7.1403  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 2.6090  Validation loss = 7.1391  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 2.6086  Validation loss = 7.1385  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 2.6082  Validation loss = 7.1370  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 2.6074  Validation loss = 7.1367  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 2.6069  Validation loss = 7.1360  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 2.6066  Validation loss = 7.1355  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 2.6059  Validation loss = 7.1340  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 2.6053  Validation loss = 7.1315  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 2.6047  Validation loss = 7.1310  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 2.6044  Validation loss = 7.1308  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 2.6038  Validation loss = 7.1289  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 2.6034  Validation loss = 7.1280  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 2.6028  Validation loss = 7.1270  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 2.6020  Validation loss = 7.1247  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 2.6016  Validation loss = 7.1233  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 2.6007  Validation loss = 7.1212  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 2.6002  Validation loss = 7.1201  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 2.5999  Validation loss = 7.1197  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 2.5995  Validation loss = 7.1186  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 2.5988  Validation loss = 7.1169  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 2.5983  Validation loss = 7.1155  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 2.5975  Validation loss = 7.1135  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 2.5971  Validation loss = 7.1122  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 2.5965  Validation loss = 7.1110  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 2.5961  Validation loss = 7.1104  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 2.5956  Validation loss = 7.1090  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 2.5954  Validation loss = 7.1081  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 2.5950  Validation loss = 7.1080  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 2.5941  Validation loss = 7.1058  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 2.5936  Validation loss = 7.1046  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 2.5930  Validation loss = 7.1031  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 2.5929  Validation loss = 7.1033  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 2.5927  Validation loss = 7.1024  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 2.5921  Validation loss = 7.1007  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 2.5915  Validation loss = 7.0995  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 2.5909  Validation loss = 7.0978  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 2.5904  Validation loss = 7.0966  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 2.5901  Validation loss = 7.0950  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 2.5900  Validation loss = 7.0944  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 2.5894  Validation loss = 7.0935  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 2.5890  Validation loss = 7.0927  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 2.5886  Validation loss = 7.0920  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 2.5873  Validation loss = 7.0891  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 2.5867  Validation loss = 7.0878  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 2.5861  Validation loss = 7.0863  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 2.5856  Validation loss = 7.0854  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 2.5850  Validation loss = 7.0845  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 2.5847  Validation loss = 7.0844  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 2.5843  Validation loss = 7.0831  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 2.5838  Validation loss = 7.0818  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 2.5835  Validation loss = 7.0809  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 2.5827  Validation loss = 7.0793  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 2.5825  Validation loss = 7.0780  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 2.5821  Validation loss = 7.0763  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 2.5812  Validation loss = 7.0753  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 2.5803  Validation loss = 7.0724  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 2.5800  Validation loss = 7.0718  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 2.5796  Validation loss = 7.0724  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 2.5792  Validation loss = 7.0720  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 2.5788  Validation loss = 7.0701  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 2.5782  Validation loss = 7.0691  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 2.5776  Validation loss = 7.0682  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 2.5770  Validation loss = 7.0666  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 2.5766  Validation loss = 7.0663  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 2.5761  Validation loss = 7.0647  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 2.5758  Validation loss = 7.0644  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 2.5751  Validation loss = 7.0619  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 2.5745  Validation loss = 7.0605  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 2.5739  Validation loss = 7.0595  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 2.5735  Validation loss = 7.0595  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 2.5729  Validation loss = 7.0581  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 2.5725  Validation loss = 7.0576  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 2.5720  Validation loss = 7.0562  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 2.5714  Validation loss = 7.0546  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 2.5709  Validation loss = 7.0537  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 2.5706  Validation loss = 7.0540  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 2.5700  Validation loss = 7.0519  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 2.5692  Validation loss = 7.0501  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 2.5689  Validation loss = 7.0500  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 2.5684  Validation loss = 7.0485  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 2.5680  Validation loss = 7.0473  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 2.5675  Validation loss = 7.0461  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 2.5672  Validation loss = 7.0459  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 2.5666  Validation loss = 7.0443  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 2.5660  Validation loss = 7.0428  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 2.5657  Validation loss = 7.0415  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 2.5653  Validation loss = 7.0409  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 2.5650  Validation loss = 7.0401  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 2.5643  Validation loss = 7.0393  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 2.5637  Validation loss = 7.0372  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 2.5633  Validation loss = 7.0366  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 2.5629  Validation loss = 7.0350  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 2.5623  Validation loss = 7.0337  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 2.5616  Validation loss = 7.0321  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 2.5609  Validation loss = 7.0305  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 2.5603  Validation loss = 7.0306  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 2.5596  Validation loss = 7.0284  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 2.5593  Validation loss = 7.0286  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 2.5589  Validation loss = 7.0284  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 2.5582  Validation loss = 7.0264  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 2.5579  Validation loss = 7.0258  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 2.5576  Validation loss = 7.0249  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 2.5572  Validation loss = 7.0239  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 2.5569  Validation loss = 7.0211  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 2.5564  Validation loss = 7.0201  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 2.5558  Validation loss = 7.0192  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 2.5552  Validation loss = 7.0177  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 2.5547  Validation loss = 7.0163  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 2.5544  Validation loss = 7.0145  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 2.5539  Validation loss = 7.0139  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 2.5536  Validation loss = 7.0152  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 2.5530  Validation loss = 7.0139  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 2.5528  Validation loss = 7.0128  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 2.5521  Validation loss = 7.0121  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 2.5518  Validation loss = 7.0101  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 2.5513  Validation loss = 7.0102  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 2.5504  Validation loss = 7.0089  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 2.5501  Validation loss = 7.0089  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 2.5495  Validation loss = 7.0074  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 2.5490  Validation loss = 7.0072  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 2.5485  Validation loss = 7.0045  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 2.5479  Validation loss = 7.0041  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 2.5478  Validation loss = 7.0042  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 2.5470  Validation loss = 7.0024  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 2.5466  Validation loss = 7.0009  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 2.5461  Validation loss = 6.9988  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 2.5460  Validation loss = 6.9992  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 2.5457  Validation loss = 6.9991  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 2.5448  Validation loss = 6.9968  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 2.5442  Validation loss = 6.9951  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 2.5434  Validation loss = 6.9925  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 2.5429  Validation loss = 6.9929  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 2.5428  Validation loss = 6.9936  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 2.5423  Validation loss = 6.9909  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 2.5420  Validation loss = 6.9905  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 2.5417  Validation loss = 6.9915  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 2.5412  Validation loss = 6.9892  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 2.5408  Validation loss = 6.9875  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 2.5403  Validation loss = 6.9843  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 2.5400  Validation loss = 6.9844  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 2.5393  Validation loss = 6.9820  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 2.5389  Validation loss = 6.9830  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 2.5384  Validation loss = 6.9814  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 2.5381  Validation loss = 6.9806  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 2.5379  Validation loss = 6.9809  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 2.5372  Validation loss = 6.9788  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 2.5371  Validation loss = 6.9796  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 2.5366  Validation loss = 6.9791  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 2.5362  Validation loss = 6.9788  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 2.5360  Validation loss = 6.9787  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 2.5352  Validation loss = 6.9779  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 2.5347  Validation loss = 6.9750  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 2.5343  Validation loss = 6.9743  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 2.5344  Validation loss = 6.9751  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 2.5340  Validation loss = 6.9739  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 2.5334  Validation loss = 6.9728  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 2.5330  Validation loss = 6.9724  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 2.5326  Validation loss = 6.9726  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 2.5319  Validation loss = 6.9704  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 2.5313  Validation loss = 6.9689  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 2.5305  Validation loss = 6.9670  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 2.5300  Validation loss = 6.9655  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 2.5295  Validation loss = 6.9653  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 2.5291  Validation loss = 6.9639  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 2.5287  Validation loss = 6.9635  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 2.5285  Validation loss = 6.9631  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 2.5280  Validation loss = 6.9631  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 2.5276  Validation loss = 6.9617  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 2.5274  Validation loss = 6.9614  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 2.5267  Validation loss = 6.9580  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 2.5262  Validation loss = 6.9572  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 2.5257  Validation loss = 6.9581  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 2.5255  Validation loss = 6.9578  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 2.5251  Validation loss = 6.9562  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 2.5247  Validation loss = 6.9573  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 2.5245  Validation loss = 6.9560  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 2.5241  Validation loss = 6.9549  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 2.5235  Validation loss = 6.9540  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 2.5229  Validation loss = 6.9532  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 2.5225  Validation loss = 6.9516  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 2.5220  Validation loss = 6.9495  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 2.5215  Validation loss = 6.9489  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 2.5212  Validation loss = 6.9486  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 2.5207  Validation loss = 6.9458  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 2.5206  Validation loss = 6.9422  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 2.5202  Validation loss = 6.9402  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 2.5203  Validation loss = 6.9399  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 2.5195  Validation loss = 6.9403  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 2.5192  Validation loss = 6.9375  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 2.5183  Validation loss = 6.9368  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 2.5178  Validation loss = 6.9357  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 2.5170  Validation loss = 6.9352  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 2.5168  Validation loss = 6.9354  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 2.5165  Validation loss = 6.9352  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 2.5161  Validation loss = 6.9332  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 2.5155  Validation loss = 6.9312  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 2.5150  Validation loss = 6.9283  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 2.5144  Validation loss = 6.9260  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 2.5139  Validation loss = 6.9254  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 2.5133  Validation loss = 6.9239  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 2.5128  Validation loss = 6.9237  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 2.5120  Validation loss = 6.9217  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 2.5117  Validation loss = 6.9217  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 2.5113  Validation loss = 6.9220  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 2.5110  Validation loss = 6.9206  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 2.5108  Validation loss = 6.9218  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 2.5105  Validation loss = 6.9202  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 2.5100  Validation loss = 6.9200  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 2.5094  Validation loss = 6.9186  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 2.5090  Validation loss = 6.9172  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 2.5084  Validation loss = 6.9163  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 2.5078  Validation loss = 6.9142  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 2.5074  Validation loss = 6.9132  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 2.5071  Validation loss = 6.9128  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 2.5066  Validation loss = 6.9122  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 2.5064  Validation loss = 6.9122  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 2.5059  Validation loss = 6.9104  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 2.5057  Validation loss = 6.9105  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 2.5051  Validation loss = 6.9102  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 2.5046  Validation loss = 6.9103  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 2.5041  Validation loss = 6.9082  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 2.5038  Validation loss = 6.9079  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 2.5033  Validation loss = 6.9059  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 2.5028  Validation loss = 6.9049  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 2.5025  Validation loss = 6.9048  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 2.5021  Validation loss = 6.9035  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 2.5018  Validation loss = 6.9032  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 2.5014  Validation loss = 6.9027  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 2.5010  Validation loss = 6.9017  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 2.5006  Validation loss = 6.9005  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 2.5003  Validation loss = 6.8976  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 2.4997  Validation loss = 6.8981  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 2.4994  Validation loss = 6.8971  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 2.4984  Validation loss = 6.8946  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 2.4980  Validation loss = 6.8934  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 2.4976  Validation loss = 6.8953  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 2.4971  Validation loss = 6.8950  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 2.4965  Validation loss = 6.8949  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 2.4962  Validation loss = 6.8938  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 2.4958  Validation loss = 6.8920  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 2.4954  Validation loss = 6.8926  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 2.4952  Validation loss = 6.8905  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 2.4948  Validation loss = 6.8892  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 2.4942  Validation loss = 6.8897  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 2.4937  Validation loss = 6.8895  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 2.4934  Validation loss = 6.8889  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 2.4931  Validation loss = 6.8881  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 2.4928  Validation loss = 6.8864  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 2.4924  Validation loss = 6.8846  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 2.4919  Validation loss = 6.8852  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 2.4914  Validation loss = 6.8838  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 2.4909  Validation loss = 6.8819  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 2.4905  Validation loss = 6.8829  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 2.4899  Validation loss = 6.8831  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 2.4894  Validation loss = 6.8805  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 2.4890  Validation loss = 6.8799  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 2.4887  Validation loss = 6.8792  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 2.4886  Validation loss = 6.8807  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 2.4881  Validation loss = 6.8792  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 2.4882  Validation loss = 6.8802  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 2.4882  Validation loss = 6.8805  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 2.4883  Validation loss = 6.8801  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 2.4871  Validation loss = 6.8771  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 2.4864  Validation loss = 6.8750  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 2.4860  Validation loss = 6.8749  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 2.4852  Validation loss = 6.8723  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 2.4850  Validation loss = 6.8725  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 2.4843  Validation loss = 6.8707  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 2.4840  Validation loss = 6.8705  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 2.4836  Validation loss = 6.8695  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 2.4831  Validation loss = 6.8692  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 2.4830  Validation loss = 6.8699  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 2.4824  Validation loss = 6.8681  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 2.4818  Validation loss = 6.8667  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 2.4813  Validation loss = 6.8664  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 2.4809  Validation loss = 6.8648  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 2.4805  Validation loss = 6.8636  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 2.4801  Validation loss = 6.8614  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 2.4797  Validation loss = 6.8594  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 2.4796  Validation loss = 6.8602  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 2.4793  Validation loss = 6.8583  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 2.4790  Validation loss = 6.8583  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 2.4786  Validation loss = 6.8573  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 2.4782  Validation loss = 6.8545  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 2.4776  Validation loss = 6.8521  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 2.4773  Validation loss = 6.8519  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 2.4769  Validation loss = 6.8509  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 2.4759  Validation loss = 6.8497  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 2.4758  Validation loss = 6.8490  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 2.4754  Validation loss = 6.8483  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 2.4751  Validation loss = 6.8485  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 2.4747  Validation loss = 6.8495  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 2.4743  Validation loss = 6.8474  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 2.4739  Validation loss = 6.8471  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 2.4733  Validation loss = 6.8462  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 2.4730  Validation loss = 6.8451  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 2.4726  Validation loss = 6.8447  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 2.4723  Validation loss = 6.8449  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 2.4719  Validation loss = 6.8433  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 2.4716  Validation loss = 6.8434  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 2.4712  Validation loss = 6.8413  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 2.4710  Validation loss = 6.8414  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 2.4708  Validation loss = 6.8415  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 2.4702  Validation loss = 6.8399  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 2.4698  Validation loss = 6.8393  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 2.4695  Validation loss = 6.8392  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 2.4687  Validation loss = 6.8368  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 2.4683  Validation loss = 6.8361  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 2.4677  Validation loss = 6.8340  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 2.4674  Validation loss = 6.8335  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 2.4670  Validation loss = 6.8335  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 2.4666  Validation loss = 6.8329  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 2.4661  Validation loss = 6.8317  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 2.4659  Validation loss = 6.8305  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 2.4655  Validation loss = 6.8292  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 2.4651  Validation loss = 6.8280  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 2.4648  Validation loss = 6.8273  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 2.4644  Validation loss = 6.8264  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 2.4638  Validation loss = 6.8259  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 2.4638  Validation loss = 6.8261  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 2.4634  Validation loss = 6.8256  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 2.4629  Validation loss = 6.8241  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 2.4627  Validation loss = 6.8239  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 2.4622  Validation loss = 6.8227  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 2.4620  Validation loss = 6.8219  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 2.4615  Validation loss = 6.8199  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 2.4611  Validation loss = 6.8198  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 2.4609  Validation loss = 6.8186  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 2.4603  Validation loss = 6.8154  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 2.4600  Validation loss = 6.8139  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 2.4596  Validation loss = 6.8125  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 2.4592  Validation loss = 6.8127  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 2.4588  Validation loss = 6.8123  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 2.4582  Validation loss = 6.8138  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 2.4577  Validation loss = 6.8126  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 2.4576  Validation loss = 6.8124  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 2.4572  Validation loss = 6.8115  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 2.4567  Validation loss = 6.8100  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 2.4566  Validation loss = 6.8089  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 2.4565  Validation loss = 6.8090  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 2.4561  Validation loss = 6.8085  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 2.4555  Validation loss = 6.8080  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 2.4551  Validation loss = 6.8070  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 2.4547  Validation loss = 6.8057  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 2.4542  Validation loss = 6.8046  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 2.4538  Validation loss = 6.8046  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 2.4536  Validation loss = 6.8046  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 2.4531  Validation loss = 6.8028  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 2.4526  Validation loss = 6.8025  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 2.4522  Validation loss = 6.8020  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 2.4517  Validation loss = 6.8007  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 2.4517  Validation loss = 6.8001  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 2.4512  Validation loss = 6.7997  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 2.4508  Validation loss = 6.7982  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 2.4500  Validation loss = 6.7965  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 2.4497  Validation loss = 6.7959  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 2.4497  Validation loss = 6.7967  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 2.4498  Validation loss = 6.7964  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 2.4490  Validation loss = 6.7950  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 2.4497  Validation loss = 6.7954  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 2.4489  Validation loss = 6.7942  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 2.4479  Validation loss = 6.7932  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 2.4476  Validation loss = 6.7926  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 2.4474  Validation loss = 6.7922  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 2.4468  Validation loss = 6.7920  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 2.4461  Validation loss = 6.7902  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 2.4457  Validation loss = 6.7887  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 2.4454  Validation loss = 6.7892  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 2.4451  Validation loss = 6.7886  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 2.4449  Validation loss = 6.7885  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 2.4444  Validation loss = 6.7874  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 2.4441  Validation loss = 6.7861  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 2.4437  Validation loss = 6.7853  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 2.4432  Validation loss = 6.7849  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 2.4425  Validation loss = 6.7832  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 2.4419  Validation loss = 6.7812  \n",
      "\n",
      "Fold: 15  Epoch: 501  Training loss = 2.4414  Validation loss = 6.7790  \n",
      "\n",
      "Fold: 15  Epoch: 502  Training loss = 2.4411  Validation loss = 6.7785  \n",
      "\n",
      "Fold: 15  Epoch: 503  Training loss = 2.4407  Validation loss = 6.7783  \n",
      "\n",
      "Fold: 15  Epoch: 504  Training loss = 2.4402  Validation loss = 6.7772  \n",
      "\n",
      "Fold: 15  Epoch: 505  Training loss = 2.4399  Validation loss = 6.7764  \n",
      "\n",
      "Fold: 15  Epoch: 506  Training loss = 2.4397  Validation loss = 6.7755  \n",
      "\n",
      "Fold: 15  Epoch: 507  Training loss = 2.4398  Validation loss = 6.7745  \n",
      "\n",
      "Fold: 15  Epoch: 508  Training loss = 2.4395  Validation loss = 6.7729  \n",
      "\n",
      "Fold: 15  Epoch: 509  Training loss = 2.4390  Validation loss = 6.7715  \n",
      "\n",
      "Fold: 15  Epoch: 510  Training loss = 2.4385  Validation loss = 6.7708  \n",
      "\n",
      "Fold: 15  Epoch: 511  Training loss = 2.4384  Validation loss = 6.7693  \n",
      "\n",
      "Fold: 15  Epoch: 512  Training loss = 2.4377  Validation loss = 6.7691  \n",
      "\n",
      "Fold: 15  Epoch: 513  Training loss = 2.4370  Validation loss = 6.7685  \n",
      "\n",
      "Fold: 15  Epoch: 514  Training loss = 2.4364  Validation loss = 6.7671  \n",
      "\n",
      "Fold: 15  Epoch: 515  Training loss = 2.4364  Validation loss = 6.7657  \n",
      "\n",
      "Fold: 15  Epoch: 516  Training loss = 2.4358  Validation loss = 6.7653  \n",
      "\n",
      "Fold: 15  Epoch: 517  Training loss = 2.4356  Validation loss = 6.7642  \n",
      "\n",
      "Fold: 15  Epoch: 518  Training loss = 2.4354  Validation loss = 6.7621  \n",
      "\n",
      "Fold: 15  Epoch: 519  Training loss = 2.4352  Validation loss = 6.7614  \n",
      "\n",
      "Fold: 15  Epoch: 520  Training loss = 2.4348  Validation loss = 6.7619  \n",
      "\n",
      "Fold: 15  Epoch: 521  Training loss = 2.4338  Validation loss = 6.7600  \n",
      "\n",
      "Fold: 15  Epoch: 522  Training loss = 2.4332  Validation loss = 6.7588  \n",
      "\n",
      "Fold: 15  Epoch: 523  Training loss = 2.4324  Validation loss = 6.7582  \n",
      "\n",
      "Fold: 15  Epoch: 524  Training loss = 2.4324  Validation loss = 6.7570  \n",
      "\n",
      "Fold: 15  Epoch: 525  Training loss = 2.4319  Validation loss = 6.7567  \n",
      "\n",
      "Fold: 15  Epoch: 526  Training loss = 2.4316  Validation loss = 6.7554  \n",
      "\n",
      "Fold: 15  Epoch: 527  Training loss = 2.4311  Validation loss = 6.7550  \n",
      "\n",
      "Fold: 15  Epoch: 528  Training loss = 2.4306  Validation loss = 6.7537  \n",
      "\n",
      "Fold: 15  Epoch: 529  Training loss = 2.4301  Validation loss = 6.7525  \n",
      "\n",
      "Fold: 15  Epoch: 530  Training loss = 2.4296  Validation loss = 6.7529  \n",
      "\n",
      "Fold: 15  Epoch: 531  Training loss = 2.4293  Validation loss = 6.7520  \n",
      "\n",
      "Fold: 15  Epoch: 532  Training loss = 2.4289  Validation loss = 6.7502  \n",
      "\n",
      "Fold: 15  Epoch: 533  Training loss = 2.4281  Validation loss = 6.7482  \n",
      "\n",
      "Fold: 15  Epoch: 534  Training loss = 2.4275  Validation loss = 6.7472  \n",
      "\n",
      "Fold: 15  Epoch: 535  Training loss = 2.4274  Validation loss = 6.7470  \n",
      "\n",
      "Fold: 15  Epoch: 536  Training loss = 2.4276  Validation loss = 6.7467  \n",
      "\n",
      "Fold: 15  Epoch: 537  Training loss = 2.4268  Validation loss = 6.7453  \n",
      "\n",
      "Fold: 15  Epoch: 538  Training loss = 2.4267  Validation loss = 6.7445  \n",
      "\n",
      "Fold: 15  Epoch: 539  Training loss = 2.4260  Validation loss = 6.7432  \n",
      "\n",
      "Fold: 15  Epoch: 540  Training loss = 2.4259  Validation loss = 6.7428  \n",
      "\n",
      "Fold: 15  Epoch: 541  Training loss = 2.4256  Validation loss = 6.7416  \n",
      "\n",
      "Fold: 15  Epoch: 542  Training loss = 2.4253  Validation loss = 6.7410  \n",
      "\n",
      "Fold: 15  Epoch: 543  Training loss = 2.4244  Validation loss = 6.7401  \n",
      "\n",
      "Fold: 15  Epoch: 544  Training loss = 2.4242  Validation loss = 6.7391  \n",
      "\n",
      "Fold: 15  Epoch: 545  Training loss = 2.4233  Validation loss = 6.7382  \n",
      "\n",
      "Fold: 15  Epoch: 546  Training loss = 2.4231  Validation loss = 6.7378  \n",
      "\n",
      "Fold: 15  Epoch: 547  Training loss = 2.4224  Validation loss = 6.7369  \n",
      "\n",
      "Fold: 15  Epoch: 548  Training loss = 2.4220  Validation loss = 6.7362  \n",
      "\n",
      "Fold: 15  Epoch: 549  Training loss = 2.4216  Validation loss = 6.7356  \n",
      "\n",
      "Fold: 15  Epoch: 550  Training loss = 2.4211  Validation loss = 6.7343  \n",
      "\n",
      "Fold: 15  Epoch: 551  Training loss = 2.4205  Validation loss = 6.7328  \n",
      "\n",
      "Fold: 15  Epoch: 552  Training loss = 2.4203  Validation loss = 6.7329  \n",
      "\n",
      "Fold: 15  Epoch: 553  Training loss = 2.4202  Validation loss = 6.7328  \n",
      "\n",
      "Fold: 15  Epoch: 554  Training loss = 2.4198  Validation loss = 6.7323  \n",
      "\n",
      "Fold: 15  Epoch: 555  Training loss = 2.4191  Validation loss = 6.7302  \n",
      "\n",
      "Fold: 15  Epoch: 556  Training loss = 2.4188  Validation loss = 6.7305  \n",
      "\n",
      "Fold: 15  Epoch: 557  Training loss = 2.4186  Validation loss = 6.7294  \n",
      "\n",
      "Fold: 15  Epoch: 558  Training loss = 2.4181  Validation loss = 6.7283  \n",
      "\n",
      "Fold: 15  Epoch: 559  Training loss = 2.4175  Validation loss = 6.7271  \n",
      "\n",
      "Fold: 15  Epoch: 560  Training loss = 2.4174  Validation loss = 6.7268  \n",
      "\n",
      "Fold: 15  Epoch: 561  Training loss = 2.4177  Validation loss = 6.7265  \n",
      "\n",
      "Fold: 15  Epoch: 562  Training loss = 2.4168  Validation loss = 6.7255  \n",
      "\n",
      "Fold: 15  Epoch: 563  Training loss = 2.4163  Validation loss = 6.7250  \n",
      "\n",
      "Fold: 15  Epoch: 564  Training loss = 2.4156  Validation loss = 6.7236  \n",
      "\n",
      "Fold: 15  Epoch: 565  Training loss = 2.4149  Validation loss = 6.7216  \n",
      "\n",
      "Fold: 15  Epoch: 566  Training loss = 2.4145  Validation loss = 6.7205  \n",
      "\n",
      "Fold: 15  Epoch: 567  Training loss = 2.4142  Validation loss = 6.7198  \n",
      "\n",
      "Fold: 15  Epoch: 568  Training loss = 2.4137  Validation loss = 6.7182  \n",
      "\n",
      "Fold: 15  Epoch: 569  Training loss = 2.4136  Validation loss = 6.7181  \n",
      "\n",
      "Fold: 15  Epoch: 570  Training loss = 2.4135  Validation loss = 6.7178  \n",
      "\n",
      "Fold: 15  Epoch: 571  Training loss = 2.4127  Validation loss = 6.7163  \n",
      "\n",
      "Fold: 15  Epoch: 572  Training loss = 2.4120  Validation loss = 6.7157  \n",
      "\n",
      "Fold: 15  Epoch: 573  Training loss = 2.4113  Validation loss = 6.7148  \n",
      "\n",
      "Fold: 15  Epoch: 574  Training loss = 2.4108  Validation loss = 6.7135  \n",
      "\n",
      "Fold: 15  Epoch: 575  Training loss = 2.4104  Validation loss = 6.7124  \n",
      "\n",
      "Fold: 15  Epoch: 576  Training loss = 2.4099  Validation loss = 6.7111  \n",
      "\n",
      "Fold: 15  Epoch: 577  Training loss = 2.4094  Validation loss = 6.7102  \n",
      "\n",
      "Fold: 15  Epoch: 578  Training loss = 2.4091  Validation loss = 6.7098  \n",
      "\n",
      "Fold: 15  Epoch: 579  Training loss = 2.4087  Validation loss = 6.7083  \n",
      "\n",
      "Fold: 15  Epoch: 580  Training loss = 2.4084  Validation loss = 6.7078  \n",
      "\n",
      "Fold: 15  Epoch: 581  Training loss = 2.4078  Validation loss = 6.7060  \n",
      "\n",
      "Fold: 15  Epoch: 582  Training loss = 2.4074  Validation loss = 6.7053  \n",
      "\n",
      "Fold: 15  Epoch: 583  Training loss = 2.4070  Validation loss = 6.7046  \n",
      "\n",
      "Fold: 15  Epoch: 584  Training loss = 2.4064  Validation loss = 6.7031  \n",
      "\n",
      "Fold: 15  Epoch: 585  Training loss = 2.4059  Validation loss = 6.7019  \n",
      "\n",
      "Fold: 15  Epoch: 586  Training loss = 2.4057  Validation loss = 6.7016  \n",
      "\n",
      "Fold: 15  Epoch: 587  Training loss = 2.4048  Validation loss = 6.7002  \n",
      "\n",
      "Fold: 15  Epoch: 588  Training loss = 2.4045  Validation loss = 6.6993  \n",
      "\n",
      "Fold: 15  Epoch: 589  Training loss = 2.4039  Validation loss = 6.6972  \n",
      "\n",
      "Fold: 15  Epoch: 590  Training loss = 2.4036  Validation loss = 6.6965  \n",
      "\n",
      "Fold: 15  Epoch: 591  Training loss = 2.4034  Validation loss = 6.6960  \n",
      "\n",
      "Fold: 15  Epoch: 592  Training loss = 2.4028  Validation loss = 6.6950  \n",
      "\n",
      "Fold: 15  Epoch: 593  Training loss = 2.4021  Validation loss = 6.6934  \n",
      "\n",
      "Fold: 15  Epoch: 594  Training loss = 2.4019  Validation loss = 6.6936  \n",
      "\n",
      "Fold: 15  Epoch: 595  Training loss = 2.4014  Validation loss = 6.6928  \n",
      "\n",
      "Fold: 15  Epoch: 596  Training loss = 2.4007  Validation loss = 6.6915  \n",
      "\n",
      "Fold: 15  Epoch: 597  Training loss = 2.4003  Validation loss = 6.6902  \n",
      "\n",
      "Fold: 15  Epoch: 598  Training loss = 2.4002  Validation loss = 6.6907  \n",
      "\n",
      "Fold: 15  Epoch: 599  Training loss = 2.3997  Validation loss = 6.6898  \n",
      "\n",
      "Fold: 15  Epoch: 600  Training loss = 2.3993  Validation loss = 6.6889  \n",
      "\n",
      "Fold: 15  Epoch: 601  Training loss = 2.3989  Validation loss = 6.6873  \n",
      "\n",
      "Fold: 15  Epoch: 602  Training loss = 2.3984  Validation loss = 6.6859  \n",
      "\n",
      "Fold: 15  Epoch: 603  Training loss = 2.3981  Validation loss = 6.6861  \n",
      "\n",
      "Fold: 15  Epoch: 604  Training loss = 2.3976  Validation loss = 6.6848  \n",
      "\n",
      "Fold: 15  Epoch: 605  Training loss = 2.3972  Validation loss = 6.6833  \n",
      "\n",
      "Fold: 15  Epoch: 606  Training loss = 2.3966  Validation loss = 6.6823  \n",
      "\n",
      "Fold: 15  Epoch: 607  Training loss = 2.3962  Validation loss = 6.6811  \n",
      "\n",
      "Fold: 15  Epoch: 608  Training loss = 2.3957  Validation loss = 6.6797  \n",
      "\n",
      "Fold: 15  Epoch: 609  Training loss = 2.3954  Validation loss = 6.6784  \n",
      "\n",
      "Fold: 15  Epoch: 610  Training loss = 2.3949  Validation loss = 6.6771  \n",
      "\n",
      "Fold: 15  Epoch: 611  Training loss = 2.3944  Validation loss = 6.6763  \n",
      "\n",
      "Fold: 15  Epoch: 612  Training loss = 2.3943  Validation loss = 6.6754  \n",
      "\n",
      "Fold: 15  Epoch: 613  Training loss = 2.3939  Validation loss = 6.6753  \n",
      "\n",
      "Fold: 15  Epoch: 614  Training loss = 2.3936  Validation loss = 6.6753  \n",
      "\n",
      "Fold: 15  Epoch: 615  Training loss = 2.3935  Validation loss = 6.6750  \n",
      "\n",
      "Fold: 15  Epoch: 616  Training loss = 2.3929  Validation loss = 6.6742  \n",
      "\n",
      "Fold: 15  Epoch: 617  Training loss = 2.3926  Validation loss = 6.6737  \n",
      "\n",
      "Fold: 15  Epoch: 618  Training loss = 2.3923  Validation loss = 6.6726  \n",
      "\n",
      "Fold: 15  Epoch: 619  Training loss = 2.3921  Validation loss = 6.6722  \n",
      "\n",
      "Fold: 15  Epoch: 620  Training loss = 2.3917  Validation loss = 6.6717  \n",
      "\n",
      "Fold: 15  Epoch: 621  Training loss = 2.3913  Validation loss = 6.6716  \n",
      "\n",
      "Fold: 15  Epoch: 622  Training loss = 2.3906  Validation loss = 6.6697  \n",
      "\n",
      "Fold: 15  Epoch: 623  Training loss = 2.3903  Validation loss = 6.6703  \n",
      "\n",
      "Fold: 15  Epoch: 624  Training loss = 2.3899  Validation loss = 6.6698  \n",
      "\n",
      "Fold: 15  Epoch: 625  Training loss = 2.3893  Validation loss = 6.6675  \n",
      "\n",
      "Fold: 15  Epoch: 626  Training loss = 2.3888  Validation loss = 6.6663  \n",
      "\n",
      "Fold: 15  Epoch: 627  Training loss = 2.3885  Validation loss = 6.6661  \n",
      "\n",
      "Fold: 15  Epoch: 628  Training loss = 2.3879  Validation loss = 6.6652  \n",
      "\n",
      "Fold: 15  Epoch: 629  Training loss = 2.3876  Validation loss = 6.6646  \n",
      "\n",
      "Fold: 15  Epoch: 630  Training loss = 2.3872  Validation loss = 6.6641  \n",
      "\n",
      "Fold: 15  Epoch: 631  Training loss = 2.3867  Validation loss = 6.6631  \n",
      "\n",
      "Fold: 15  Epoch: 632  Training loss = 2.3861  Validation loss = 6.6618  \n",
      "\n",
      "Fold: 15  Epoch: 633  Training loss = 2.3857  Validation loss = 6.6605  \n",
      "\n",
      "Fold: 15  Epoch: 634  Training loss = 2.3855  Validation loss = 6.6606  \n",
      "\n",
      "Fold: 15  Epoch: 635  Training loss = 2.3856  Validation loss = 6.6612  \n",
      "\n",
      "Fold: 15  Epoch: 636  Training loss = 2.3852  Validation loss = 6.6609  \n",
      "\n",
      "Fold: 15  Epoch: 637  Training loss = 2.3847  Validation loss = 6.6606  \n",
      "\n",
      "Fold: 15  Epoch: 638  Training loss = 2.3844  Validation loss = 6.6602  \n",
      "\n",
      "Fold: 15  Epoch: 639  Training loss = 2.3841  Validation loss = 6.6596  \n",
      "\n",
      "Fold: 15  Epoch: 640  Training loss = 2.3835  Validation loss = 6.6578  \n",
      "\n",
      "Fold: 15  Epoch: 641  Training loss = 2.3827  Validation loss = 6.6555  \n",
      "\n",
      "Fold: 15  Epoch: 642  Training loss = 2.3825  Validation loss = 6.6553  \n",
      "\n",
      "Fold: 15  Epoch: 643  Training loss = 2.3818  Validation loss = 6.6537  \n",
      "\n",
      "Fold: 15  Epoch: 644  Training loss = 2.3813  Validation loss = 6.6523  \n",
      "\n",
      "Fold: 15  Epoch: 645  Training loss = 2.3809  Validation loss = 6.6512  \n",
      "\n",
      "Fold: 15  Epoch: 646  Training loss = 2.3804  Validation loss = 6.6498  \n",
      "\n",
      "Fold: 15  Epoch: 647  Training loss = 2.3799  Validation loss = 6.6481  \n",
      "\n",
      "Fold: 15  Epoch: 648  Training loss = 2.3797  Validation loss = 6.6480  \n",
      "\n",
      "Fold: 15  Epoch: 649  Training loss = 2.3795  Validation loss = 6.6479  \n",
      "\n",
      "Fold: 15  Epoch: 650  Training loss = 2.3791  Validation loss = 6.6474  \n",
      "\n",
      "Fold: 15  Epoch: 651  Training loss = 2.3787  Validation loss = 6.6462  \n",
      "\n",
      "Fold: 15  Epoch: 652  Training loss = 2.3783  Validation loss = 6.6453  \n",
      "\n",
      "Fold: 15  Epoch: 653  Training loss = 2.3782  Validation loss = 6.6450  \n",
      "\n",
      "Fold: 15  Epoch: 654  Training loss = 2.3777  Validation loss = 6.6432  \n",
      "\n",
      "Fold: 15  Epoch: 655  Training loss = 2.3773  Validation loss = 6.6422  \n",
      "\n",
      "Fold: 15  Epoch: 656  Training loss = 2.3766  Validation loss = 6.6410  \n",
      "\n",
      "Fold: 15  Epoch: 657  Training loss = 2.3764  Validation loss = 6.6405  \n",
      "\n",
      "Fold: 15  Epoch: 658  Training loss = 2.3757  Validation loss = 6.6391  \n",
      "\n",
      "Fold: 15  Epoch: 659  Training loss = 2.3752  Validation loss = 6.6382  \n",
      "\n",
      "Fold: 15  Epoch: 660  Training loss = 2.3748  Validation loss = 6.6373  \n",
      "\n",
      "Fold: 15  Epoch: 661  Training loss = 2.3744  Validation loss = 6.6363  \n",
      "\n",
      "Fold: 15  Epoch: 662  Training loss = 2.3740  Validation loss = 6.6355  \n",
      "\n",
      "Fold: 15  Epoch: 663  Training loss = 2.3736  Validation loss = 6.6350  \n",
      "\n",
      "Fold: 15  Epoch: 664  Training loss = 2.3731  Validation loss = 6.6343  \n",
      "\n",
      "Fold: 15  Epoch: 665  Training loss = 2.3729  Validation loss = 6.6331  \n",
      "\n",
      "Fold: 15  Epoch: 666  Training loss = 2.3724  Validation loss = 6.6320  \n",
      "\n",
      "Fold: 15  Epoch: 667  Training loss = 2.3723  Validation loss = 6.6305  \n",
      "\n",
      "Fold: 15  Epoch: 668  Training loss = 2.3722  Validation loss = 6.6302  \n",
      "\n",
      "Fold: 15  Epoch: 669  Training loss = 2.3723  Validation loss = 6.6298  \n",
      "\n",
      "Fold: 15  Epoch: 670  Training loss = 2.3728  Validation loss = 6.6278  \n",
      "\n",
      "Fold: 15  Epoch: 671  Training loss = 2.3723  Validation loss = 6.6262  \n",
      "\n",
      "Fold: 15  Epoch: 672  Training loss = 2.3712  Validation loss = 6.6261  \n",
      "\n",
      "Fold: 15  Epoch: 673  Training loss = 2.3701  Validation loss = 6.6250  \n",
      "\n",
      "Fold: 15  Epoch: 674  Training loss = 2.3695  Validation loss = 6.6246  \n",
      "\n",
      "Fold: 15  Epoch: 675  Training loss = 2.3691  Validation loss = 6.6245  \n",
      "\n",
      "Fold: 15  Epoch: 676  Training loss = 2.3688  Validation loss = 6.6239  \n",
      "\n",
      "Fold: 15  Epoch: 677  Training loss = 2.3683  Validation loss = 6.6216  \n",
      "\n",
      "Fold: 15  Epoch: 678  Training loss = 2.3683  Validation loss = 6.6201  \n",
      "\n",
      "Fold: 15  Epoch: 679  Training loss = 2.3683  Validation loss = 6.6193  \n",
      "\n",
      "Fold: 15  Epoch: 680  Training loss = 2.3676  Validation loss = 6.6179  \n",
      "\n",
      "Fold: 15  Epoch: 681  Training loss = 2.3677  Validation loss = 6.6161  \n",
      "\n",
      "Fold: 15  Epoch: 682  Training loss = 2.3665  Validation loss = 6.6158  \n",
      "\n",
      "Fold: 15  Epoch: 683  Training loss = 2.3663  Validation loss = 6.6146  \n",
      "\n",
      "Fold: 15  Epoch: 684  Training loss = 2.3655  Validation loss = 6.6134  \n",
      "\n",
      "Fold: 15  Epoch: 685  Training loss = 2.3652  Validation loss = 6.6128  \n",
      "\n",
      "Fold: 15  Epoch: 686  Training loss = 2.3652  Validation loss = 6.6109  \n",
      "\n",
      "Fold: 15  Epoch: 687  Training loss = 2.3643  Validation loss = 6.6101  \n",
      "\n",
      "Fold: 15  Epoch: 688  Training loss = 2.3640  Validation loss = 6.6097  \n",
      "\n",
      "Fold: 15  Epoch: 689  Training loss = 2.3636  Validation loss = 6.6093  \n",
      "\n",
      "Fold: 15  Epoch: 690  Training loss = 2.3632  Validation loss = 6.6097  \n",
      "\n",
      "Fold: 15  Epoch: 691  Training loss = 2.3626  Validation loss = 6.6098  \n",
      "\n",
      "Fold: 15  Epoch: 692  Training loss = 2.3625  Validation loss = 6.6096  \n",
      "\n",
      "Fold: 15  Epoch: 693  Training loss = 2.3622  Validation loss = 6.6087  \n",
      "\n",
      "Fold: 15  Epoch: 694  Training loss = 2.3619  Validation loss = 6.6088  \n",
      "\n",
      "Fold: 15  Epoch: 695  Training loss = 2.3614  Validation loss = 6.6072  \n",
      "\n",
      "Fold: 15  Epoch: 696  Training loss = 2.3611  Validation loss = 6.6067  \n",
      "\n",
      "Fold: 15  Epoch: 697  Training loss = 2.3610  Validation loss = 6.6057  \n",
      "\n",
      "Fold: 15  Epoch: 698  Training loss = 2.3608  Validation loss = 6.6043  \n",
      "\n",
      "Fold: 15  Epoch: 699  Training loss = 2.3603  Validation loss = 6.6035  \n",
      "\n",
      "Fold: 15  Epoch: 700  Training loss = 2.3600  Validation loss = 6.6023  \n",
      "\n",
      "Fold: 15  Epoch: 701  Training loss = 2.3594  Validation loss = 6.6006  \n",
      "\n",
      "Fold: 15  Epoch: 702  Training loss = 2.3589  Validation loss = 6.5993  \n",
      "\n",
      "Fold: 15  Epoch: 703  Training loss = 2.3599  Validation loss = 6.5996  \n",
      "\n",
      "Fold: 15  Epoch: 704  Training loss = 2.3603  Validation loss = 6.5993  \n",
      "\n",
      "Fold: 15  Epoch: 705  Training loss = 2.3583  Validation loss = 6.5971  \n",
      "\n",
      "Fold: 15  Epoch: 706  Training loss = 2.3584  Validation loss = 6.5972  \n",
      "\n",
      "Fold: 15  Epoch: 707  Training loss = 2.3575  Validation loss = 6.5961  \n",
      "\n",
      "Fold: 15  Epoch: 708  Training loss = 2.3577  Validation loss = 6.5950  \n",
      "\n",
      "Fold: 15  Epoch: 709  Training loss = 2.3570  Validation loss = 6.5943  \n",
      "\n",
      "Fold: 15  Epoch: 710  Training loss = 2.3566  Validation loss = 6.5941  \n",
      "\n",
      "Fold: 15  Epoch: 711  Training loss = 2.3568  Validation loss = 6.5937  \n",
      "\n",
      "Fold: 15  Epoch: 712  Training loss = 2.3555  Validation loss = 6.5916  \n",
      "\n",
      "Fold: 15  Epoch: 713  Training loss = 2.3551  Validation loss = 6.5904  \n",
      "\n",
      "Fold: 15  Epoch: 714  Training loss = 2.3547  Validation loss = 6.5897  \n",
      "\n",
      "Fold: 15  Epoch: 715  Training loss = 2.3543  Validation loss = 6.5884  \n",
      "\n",
      "Fold: 15  Epoch: 716  Training loss = 2.3540  Validation loss = 6.5868  \n",
      "\n",
      "Fold: 15  Epoch: 717  Training loss = 2.3539  Validation loss = 6.5864  \n",
      "\n",
      "Fold: 15  Epoch: 718  Training loss = 2.3535  Validation loss = 6.5854  \n",
      "\n",
      "Fold: 15  Epoch: 719  Training loss = 2.3532  Validation loss = 6.5839  \n",
      "\n",
      "Fold: 15  Epoch: 720  Training loss = 2.3531  Validation loss = 6.5830  \n",
      "\n",
      "Fold: 15  Epoch: 721  Training loss = 2.3526  Validation loss = 6.5815  \n",
      "\n",
      "Fold: 15  Epoch: 722  Training loss = 2.3521  Validation loss = 6.5808  \n",
      "\n",
      "Fold: 15  Epoch: 723  Training loss = 2.3517  Validation loss = 6.5805  \n",
      "\n",
      "Fold: 15  Epoch: 724  Training loss = 2.3516  Validation loss = 6.5811  \n",
      "\n",
      "Fold: 15  Epoch: 725  Training loss = 2.3512  Validation loss = 6.5800  \n",
      "\n",
      "Fold: 15  Epoch: 726  Training loss = 2.3508  Validation loss = 6.5779  \n",
      "\n",
      "Fold: 15  Epoch: 727  Training loss = 2.3505  Validation loss = 6.5767  \n",
      "\n",
      "Fold: 15  Epoch: 728  Training loss = 2.3500  Validation loss = 6.5759  \n",
      "\n",
      "Fold: 15  Epoch: 729  Training loss = 2.3497  Validation loss = 6.5764  \n",
      "\n",
      "Fold: 15  Epoch: 730  Training loss = 2.3494  Validation loss = 6.5752  \n",
      "\n",
      "Fold: 15  Epoch: 731  Training loss = 2.3490  Validation loss = 6.5735  \n",
      "\n",
      "Fold: 15  Epoch: 732  Training loss = 2.3490  Validation loss = 6.5719  \n",
      "\n",
      "Fold: 15  Epoch: 733  Training loss = 2.3482  Validation loss = 6.5715  \n",
      "\n",
      "Fold: 15  Epoch: 734  Training loss = 2.3477  Validation loss = 6.5700  \n",
      "\n",
      "Fold: 15  Epoch: 735  Training loss = 2.3478  Validation loss = 6.5689  \n",
      "\n",
      "Fold: 15  Epoch: 736  Training loss = 2.3479  Validation loss = 6.5679  \n",
      "\n",
      "Fold: 15  Epoch: 737  Training loss = 2.3470  Validation loss = 6.5674  \n",
      "\n",
      "Fold: 15  Epoch: 738  Training loss = 2.3465  Validation loss = 6.5659  \n",
      "\n",
      "Fold: 15  Epoch: 739  Training loss = 2.3466  Validation loss = 6.5645  \n",
      "\n",
      "Fold: 15  Epoch: 740  Training loss = 2.3463  Validation loss = 6.5655  \n",
      "\n",
      "Fold: 15  Epoch: 741  Training loss = 2.3468  Validation loss = 6.5645  \n",
      "\n",
      "Fold: 15  Epoch: 742  Training loss = 2.3460  Validation loss = 6.5635  \n",
      "\n",
      "Fold: 15  Epoch: 743  Training loss = 2.3459  Validation loss = 6.5614  \n",
      "\n",
      "Fold: 15  Epoch: 744  Training loss = 2.3456  Validation loss = 6.5600  \n",
      "\n",
      "Fold: 15  Epoch: 745  Training loss = 2.3450  Validation loss = 6.5585  \n",
      "\n",
      "Fold: 15  Epoch: 746  Training loss = 2.3437  Validation loss = 6.5582  \n",
      "\n",
      "Fold: 15  Epoch: 747  Training loss = 2.3431  Validation loss = 6.5576  \n",
      "\n",
      "Fold: 15  Epoch: 748  Training loss = 2.3432  Validation loss = 6.5566  \n",
      "\n",
      "Fold: 15  Epoch: 749  Training loss = 2.3424  Validation loss = 6.5568  \n",
      "\n",
      "Fold: 15  Epoch: 750  Training loss = 2.3418  Validation loss = 6.5556  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 750  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.8349  Validation loss = 4.4911  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.8343  Validation loss = 4.4934  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.8332  Validation loss = 4.4961  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.8319  Validation loss = 4.4879  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.8310  Validation loss = 4.4890  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.8300  Validation loss = 4.4866  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.8293  Validation loss = 4.4833  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.8286  Validation loss = 4.4963  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.8269  Validation loss = 4.4897  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.8259  Validation loss = 4.4886  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.8245  Validation loss = 4.4839  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.8222  Validation loss = 4.4839  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.8165  Validation loss = 4.4805  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.8144  Validation loss = 4.4646  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.8128  Validation loss = 4.4659  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.8118  Validation loss = 4.4673  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.8108  Validation loss = 4.4679  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 2.8103  Validation loss = 4.4728  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.8100  Validation loss = 4.4672  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.8093  Validation loss = 4.4606  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 2.8084  Validation loss = 4.4644  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 2.8080  Validation loss = 4.4666  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 2.8072  Validation loss = 4.4675  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 2.8062  Validation loss = 4.4703  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 2.8060  Validation loss = 4.4640  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 2.8055  Validation loss = 4.4638  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 2.8048  Validation loss = 4.4614  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 2.8035  Validation loss = 4.4527  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 2.8018  Validation loss = 4.4473  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 2.8007  Validation loss = 4.4477  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 2.7995  Validation loss = 4.4465  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 2.7984  Validation loss = 4.4490  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 2.7971  Validation loss = 4.4458  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 2.7962  Validation loss = 4.4441  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 2.7953  Validation loss = 4.4431  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 2.7944  Validation loss = 4.4530  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 2.7938  Validation loss = 4.4531  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 2.7933  Validation loss = 4.4540  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 2.7919  Validation loss = 4.4544  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 2.7910  Validation loss = 4.4492  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 2.7895  Validation loss = 4.4573  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 2.7882  Validation loss = 4.4535  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 2.7872  Validation loss = 4.4527  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 2.7862  Validation loss = 4.4555  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 2.7851  Validation loss = 4.4468  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 2.7843  Validation loss = 4.4604  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 35  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.9917  Validation loss = 3.1370  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.9902  Validation loss = 3.1370  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.9838  Validation loss = 3.1474  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.9794  Validation loss = 3.1504  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.9775  Validation loss = 3.1505  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.9763  Validation loss = 3.1514  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.9752  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.9733  Validation loss = 3.1513  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.9714  Validation loss = 3.1500  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.9679  Validation loss = 3.1470  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.9650  Validation loss = 3.1465  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.9623  Validation loss = 3.1417  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.9598  Validation loss = 3.1388  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.9563  Validation loss = 3.1336  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.9557  Validation loss = 3.1337  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 2.9540  Validation loss = 3.1319  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 2.9538  Validation loss = 3.1360  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 2.9515  Validation loss = 3.1321  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 2.9499  Validation loss = 3.1317  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 2.9488  Validation loss = 3.1255  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 2.9460  Validation loss = 3.1249  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 2.9449  Validation loss = 3.1276  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 2.9448  Validation loss = 3.1303  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 2.9436  Validation loss = 3.1315  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 2.9426  Validation loss = 3.1284  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 2.9404  Validation loss = 3.1249  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 2.9381  Validation loss = 3.1237  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 2.9352  Validation loss = 3.1233  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 2.9319  Validation loss = 3.1257  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 2.9290  Validation loss = 3.1194  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 2.9287  Validation loss = 3.1233  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 2.9283  Validation loss = 3.1239  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 2.9258  Validation loss = 3.1260  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 2.9243  Validation loss = 3.1335  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 30  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.0218  Validation loss = 1.3564  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.0197  Validation loss = 1.3562  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.0177  Validation loss = 1.3548  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.0155  Validation loss = 1.3562  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.0145  Validation loss = 1.3554  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.0122  Validation loss = 1.3555  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 3.0114  Validation loss = 1.3563  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 3.0096  Validation loss = 1.3552  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 3.0093  Validation loss = 1.3548  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 3.0076  Validation loss = 1.3556  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.0067  Validation loss = 1.3559  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 3.0049  Validation loss = 1.3537  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 3.0042  Validation loss = 1.3538  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 3.0029  Validation loss = 1.3534  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 3.0024  Validation loss = 1.3543  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 2.9995  Validation loss = 1.3530  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 2.9978  Validation loss = 1.3509  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 2.9970  Validation loss = 1.3513  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 2.9958  Validation loss = 1.3511  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 2.9938  Validation loss = 1.3509  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 2.9925  Validation loss = 1.3505  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 2.9919  Validation loss = 1.3500  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 2.9917  Validation loss = 1.3498  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 2.9905  Validation loss = 1.3489  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 2.9906  Validation loss = 1.3487  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 2.9884  Validation loss = 1.3485  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 2.9870  Validation loss = 1.3477  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 2.9861  Validation loss = 1.3471  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 2.9855  Validation loss = 1.3477  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 2.9843  Validation loss = 1.3480  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 2.9837  Validation loss = 1.3479  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 2.9819  Validation loss = 1.3463  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 2.9808  Validation loss = 1.3463  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 2.9793  Validation loss = 1.3454  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 2.9788  Validation loss = 1.3450  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 2.9780  Validation loss = 1.3460  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 2.9775  Validation loss = 1.3471  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 2.9766  Validation loss = 1.3460  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 2.9757  Validation loss = 1.3458  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 2.9740  Validation loss = 1.3439  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 2.9737  Validation loss = 1.3437  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 2.9734  Validation loss = 1.3451  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 2.9729  Validation loss = 1.3466  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 2.9711  Validation loss = 1.3456  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 2.9703  Validation loss = 1.3456  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 2.9693  Validation loss = 1.3453  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 2.9682  Validation loss = 1.3454  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 2.9668  Validation loss = 1.3448  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 2.9651  Validation loss = 1.3439  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 2.9638  Validation loss = 1.3429  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 2.9629  Validation loss = 1.3416  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 2.9628  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 2.9622  Validation loss = 1.3431  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 2.9618  Validation loss = 1.3426  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 2.9605  Validation loss = 1.3424  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 2.9591  Validation loss = 1.3415  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 2.9582  Validation loss = 1.3409  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 2.9578  Validation loss = 1.3408  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 2.9568  Validation loss = 1.3403  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 2.9566  Validation loss = 1.3409  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 2.9537  Validation loss = 1.3396  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 2.9540  Validation loss = 1.3403  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 2.9522  Validation loss = 1.3398  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 2.9502  Validation loss = 1.3386  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 2.9496  Validation loss = 1.3382  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 2.9478  Validation loss = 1.3365  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 2.9468  Validation loss = 1.3364  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 2.9464  Validation loss = 1.3367  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 2.9460  Validation loss = 1.3369  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 2.9445  Validation loss = 1.3362  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 2.9444  Validation loss = 1.3356  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 2.9434  Validation loss = 1.3358  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 2.9422  Validation loss = 1.3346  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 2.9418  Validation loss = 1.3342  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 2.9414  Validation loss = 1.3344  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 2.9417  Validation loss = 1.3336  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 2.9402  Validation loss = 1.3334  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 2.9392  Validation loss = 1.3328  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 2.9382  Validation loss = 1.3321  \n",
      "\n",
      "Fold: 18  Epoch: 80  Training loss = 2.9374  Validation loss = 1.3324  \n",
      "\n",
      "Fold: 18  Epoch: 81  Training loss = 2.9367  Validation loss = 1.3324  \n",
      "\n",
      "Fold: 18  Epoch: 82  Training loss = 2.9361  Validation loss = 1.3325  \n",
      "\n",
      "Fold: 18  Epoch: 83  Training loss = 2.9349  Validation loss = 1.3328  \n",
      "\n",
      "Fold: 18  Epoch: 84  Training loss = 2.9341  Validation loss = 1.3324  \n",
      "\n",
      "Fold: 18  Epoch: 85  Training loss = 2.9336  Validation loss = 1.3322  \n",
      "\n",
      "Fold: 18  Epoch: 86  Training loss = 2.9327  Validation loss = 1.3321  \n",
      "\n",
      "Fold: 18  Epoch: 87  Training loss = 2.9319  Validation loss = 1.3317  \n",
      "\n",
      "Fold: 18  Epoch: 88  Training loss = 2.9309  Validation loss = 1.3319  \n",
      "\n",
      "Fold: 18  Epoch: 89  Training loss = 2.9302  Validation loss = 1.3324  \n",
      "\n",
      "Fold: 18  Epoch: 90  Training loss = 2.9297  Validation loss = 1.3330  \n",
      "\n",
      "Fold: 18  Epoch: 91  Training loss = 2.9291  Validation loss = 1.3323  \n",
      "\n",
      "Fold: 18  Epoch: 92  Training loss = 2.9283  Validation loss = 1.3322  \n",
      "\n",
      "Fold: 18  Epoch: 93  Training loss = 2.9277  Validation loss = 1.3317  \n",
      "\n",
      "Fold: 18  Epoch: 94  Training loss = 2.9271  Validation loss = 1.3300  \n",
      "\n",
      "Fold: 18  Epoch: 95  Training loss = 2.9267  Validation loss = 1.3295  \n",
      "\n",
      "Fold: 18  Epoch: 96  Training loss = 2.9259  Validation loss = 1.3291  \n",
      "\n",
      "Fold: 18  Epoch: 97  Training loss = 2.9250  Validation loss = 1.3287  \n",
      "\n",
      "Fold: 18  Epoch: 98  Training loss = 2.9244  Validation loss = 1.3270  \n",
      "\n",
      "Fold: 18  Epoch: 99  Training loss = 2.9245  Validation loss = 1.3257  \n",
      "\n",
      "Fold: 18  Epoch: 100  Training loss = 2.9229  Validation loss = 1.3261  \n",
      "\n",
      "Fold: 18  Epoch: 101  Training loss = 2.9221  Validation loss = 1.3266  \n",
      "\n",
      "Fold: 18  Epoch: 102  Training loss = 2.9214  Validation loss = 1.3269  \n",
      "\n",
      "Fold: 18  Epoch: 103  Training loss = 2.9214  Validation loss = 1.3270  \n",
      "\n",
      "Fold: 18  Epoch: 104  Training loss = 2.9213  Validation loss = 1.3273  \n",
      "\n",
      "Fold: 18  Epoch: 105  Training loss = 2.9207  Validation loss = 1.3272  \n",
      "\n",
      "Fold: 18  Epoch: 106  Training loss = 2.9204  Validation loss = 1.3272  \n",
      "\n",
      "Fold: 18  Epoch: 107  Training loss = 2.9211  Validation loss = 1.3280  \n",
      "\n",
      "Fold: 18  Epoch: 108  Training loss = 2.9201  Validation loss = 1.3275  \n",
      "\n",
      "Fold: 18  Epoch: 109  Training loss = 2.9200  Validation loss = 1.3273  \n",
      "\n",
      "Fold: 18  Epoch: 110  Training loss = 2.9211  Validation loss = 1.3280  \n",
      "\n",
      "Fold: 18  Epoch: 111  Training loss = 2.9196  Validation loss = 1.3280  \n",
      "\n",
      "Fold: 18  Epoch: 112  Training loss = 2.9169  Validation loss = 1.3265  \n",
      "\n",
      "Fold: 18  Epoch: 113  Training loss = 2.9168  Validation loss = 1.3265  \n",
      "\n",
      "Fold: 18  Epoch: 114  Training loss = 2.9175  Validation loss = 1.3266  \n",
      "\n",
      "Fold: 18  Epoch: 115  Training loss = 2.9155  Validation loss = 1.3253  \n",
      "\n",
      "Fold: 18  Epoch: 116  Training loss = 2.9142  Validation loss = 1.3244  \n",
      "\n",
      "Fold: 18  Epoch: 117  Training loss = 2.9128  Validation loss = 1.3231  \n",
      "\n",
      "Fold: 18  Epoch: 118  Training loss = 2.9119  Validation loss = 1.3232  \n",
      "\n",
      "Fold: 18  Epoch: 119  Training loss = 2.9111  Validation loss = 1.3232  \n",
      "\n",
      "Fold: 18  Epoch: 120  Training loss = 2.9109  Validation loss = 1.3228  \n",
      "\n",
      "Fold: 18  Epoch: 121  Training loss = 2.9098  Validation loss = 1.3223  \n",
      "\n",
      "Fold: 18  Epoch: 122  Training loss = 2.9086  Validation loss = 1.3215  \n",
      "\n",
      "Fold: 18  Epoch: 123  Training loss = 2.9081  Validation loss = 1.3210  \n",
      "\n",
      "Fold: 18  Epoch: 124  Training loss = 2.9078  Validation loss = 1.3214  \n",
      "\n",
      "Fold: 18  Epoch: 125  Training loss = 2.9069  Validation loss = 1.3211  \n",
      "\n",
      "Fold: 18  Epoch: 126  Training loss = 2.9065  Validation loss = 1.3213  \n",
      "\n",
      "Fold: 18  Epoch: 127  Training loss = 2.9055  Validation loss = 1.3201  \n",
      "\n",
      "Fold: 18  Epoch: 128  Training loss = 2.9054  Validation loss = 1.3193  \n",
      "\n",
      "Fold: 18  Epoch: 129  Training loss = 2.9042  Validation loss = 1.3185  \n",
      "\n",
      "Fold: 18  Epoch: 130  Training loss = 2.9029  Validation loss = 1.3181  \n",
      "\n",
      "Fold: 18  Epoch: 131  Training loss = 2.9024  Validation loss = 1.3175  \n",
      "\n",
      "Fold: 18  Epoch: 132  Training loss = 2.9017  Validation loss = 1.3176  \n",
      "\n",
      "Fold: 18  Epoch: 133  Training loss = 2.9013  Validation loss = 1.3181  \n",
      "\n",
      "Fold: 18  Epoch: 134  Training loss = 2.9006  Validation loss = 1.3181  \n",
      "\n",
      "Fold: 18  Epoch: 135  Training loss = 2.9002  Validation loss = 1.3183  \n",
      "\n",
      "Fold: 18  Epoch: 136  Training loss = 2.8999  Validation loss = 1.3191  \n",
      "\n",
      "Fold: 18  Epoch: 137  Training loss = 2.8992  Validation loss = 1.3191  \n",
      "\n",
      "Fold: 18  Epoch: 138  Training loss = 2.8986  Validation loss = 1.3186  \n",
      "\n",
      "Fold: 18  Epoch: 139  Training loss = 2.8984  Validation loss = 1.3182  \n",
      "\n",
      "Fold: 18  Epoch: 140  Training loss = 2.8978  Validation loss = 1.3176  \n",
      "\n",
      "Fold: 18  Epoch: 141  Training loss = 2.8971  Validation loss = 1.3175  \n",
      "\n",
      "Fold: 18  Epoch: 142  Training loss = 2.8966  Validation loss = 1.3176  \n",
      "\n",
      "Fold: 18  Epoch: 143  Training loss = 2.8958  Validation loss = 1.3172  \n",
      "\n",
      "Fold: 18  Epoch: 144  Training loss = 2.8954  Validation loss = 1.3180  \n",
      "\n",
      "Fold: 18  Epoch: 145  Training loss = 2.8949  Validation loss = 1.3173  \n",
      "\n",
      "Fold: 18  Epoch: 146  Training loss = 2.8942  Validation loss = 1.3173  \n",
      "\n",
      "Fold: 18  Epoch: 147  Training loss = 2.8937  Validation loss = 1.3173  \n",
      "\n",
      "Fold: 18  Epoch: 148  Training loss = 2.8930  Validation loss = 1.3169  \n",
      "\n",
      "Fold: 18  Epoch: 149  Training loss = 2.8922  Validation loss = 1.3171  \n",
      "\n",
      "Fold: 18  Epoch: 150  Training loss = 2.8919  Validation loss = 1.3176  \n",
      "\n",
      "Fold: 18  Epoch: 151  Training loss = 2.8916  Validation loss = 1.3183  \n",
      "\n",
      "Fold: 18  Epoch: 152  Training loss = 2.8908  Validation loss = 1.3177  \n",
      "\n",
      "Fold: 18  Epoch: 153  Training loss = 2.8904  Validation loss = 1.3171  \n",
      "\n",
      "Fold: 18  Epoch: 154  Training loss = 2.8897  Validation loss = 1.3167  \n",
      "\n",
      "Fold: 18  Epoch: 155  Training loss = 2.8891  Validation loss = 1.3162  \n",
      "\n",
      "Fold: 18  Epoch: 156  Training loss = 2.8884  Validation loss = 1.3161  \n",
      "\n",
      "Fold: 18  Epoch: 157  Training loss = 2.8878  Validation loss = 1.3164  \n",
      "\n",
      "Fold: 18  Epoch: 158  Training loss = 2.8874  Validation loss = 1.3156  \n",
      "\n",
      "Fold: 18  Epoch: 159  Training loss = 2.8868  Validation loss = 1.3155  \n",
      "\n",
      "Fold: 18  Epoch: 160  Training loss = 2.8859  Validation loss = 1.3160  \n",
      "\n",
      "Fold: 18  Epoch: 161  Training loss = 2.8852  Validation loss = 1.3171  \n",
      "\n",
      "Fold: 18  Epoch: 162  Training loss = 2.8846  Validation loss = 1.3169  \n",
      "\n",
      "Fold: 18  Epoch: 163  Training loss = 2.8840  Validation loss = 1.3167  \n",
      "\n",
      "Fold: 18  Epoch: 164  Training loss = 2.8832  Validation loss = 1.3162  \n",
      "\n",
      "Fold: 18  Epoch: 165  Training loss = 2.8833  Validation loss = 1.3161  \n",
      "\n",
      "Fold: 18  Epoch: 166  Training loss = 2.8833  Validation loss = 1.3159  \n",
      "\n",
      "Fold: 18  Epoch: 167  Training loss = 2.8828  Validation loss = 1.3166  \n",
      "\n",
      "Fold: 18  Epoch: 168  Training loss = 2.8821  Validation loss = 1.3161  \n",
      "\n",
      "Fold: 18  Epoch: 169  Training loss = 2.8818  Validation loss = 1.3160  \n",
      "\n",
      "Fold: 18  Epoch: 170  Training loss = 2.8810  Validation loss = 1.3150  \n",
      "\n",
      "Fold: 18  Epoch: 171  Training loss = 2.8806  Validation loss = 1.3153  \n",
      "\n",
      "Fold: 18  Epoch: 172  Training loss = 2.8801  Validation loss = 1.3151  \n",
      "\n",
      "Fold: 18  Epoch: 173  Training loss = 2.8797  Validation loss = 1.3154  \n",
      "\n",
      "Fold: 18  Epoch: 174  Training loss = 2.8786  Validation loss = 1.3150  \n",
      "\n",
      "Fold: 18  Epoch: 175  Training loss = 2.8777  Validation loss = 1.3162  \n",
      "\n",
      "Fold: 18  Epoch: 176  Training loss = 2.8770  Validation loss = 1.3165  \n",
      "\n",
      "Fold: 18  Epoch: 177  Training loss = 2.8753  Validation loss = 1.3173  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 174  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.8409  Validation loss = 2.8131  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.8412  Validation loss = 2.8119  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.8404  Validation loss = 2.8088  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.8405  Validation loss = 2.8084  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.8387  Validation loss = 2.8078  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.8373  Validation loss = 2.8062  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.8368  Validation loss = 2.8049  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.8357  Validation loss = 2.8035  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.8341  Validation loss = 2.8026  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.8330  Validation loss = 2.8023  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.8325  Validation loss = 2.8021  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.8319  Validation loss = 2.8018  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.8316  Validation loss = 2.8025  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.8316  Validation loss = 2.8033  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.8309  Validation loss = 2.8033  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.8320  Validation loss = 2.8028  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 2.8286  Validation loss = 2.8042  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 2.8272  Validation loss = 2.8034  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 2.8251  Validation loss = 2.8043  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 2.8243  Validation loss = 2.8033  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 2.8237  Validation loss = 2.8047  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 2.8240  Validation loss = 2.8041  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 2.8229  Validation loss = 2.8032  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 2.8225  Validation loss = 2.8022  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 2.8212  Validation loss = 2.8014  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 2.8207  Validation loss = 2.8012  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 2.8203  Validation loss = 2.8016  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 2.8203  Validation loss = 2.8016  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 2.8220  Validation loss = 2.8012  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 2.8206  Validation loss = 2.8022  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 2.8211  Validation loss = 2.8004  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 2.8192  Validation loss = 2.8006  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 2.8184  Validation loss = 2.8008  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 2.8181  Validation loss = 2.7996  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 2.8175  Validation loss = 2.8008  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 2.8167  Validation loss = 2.8001  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 2.8163  Validation loss = 2.7999  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 2.8154  Validation loss = 2.7996  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 2.8153  Validation loss = 2.7993  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 2.8140  Validation loss = 2.7986  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 2.8129  Validation loss = 2.7972  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 2.8123  Validation loss = 2.7966  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 2.8121  Validation loss = 2.7971  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 2.8117  Validation loss = 2.7965  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 2.8106  Validation loss = 2.7963  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 2.8103  Validation loss = 2.7959  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 2.8095  Validation loss = 2.7955  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 2.8088  Validation loss = 2.7941  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 2.8083  Validation loss = 2.7944  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 2.8079  Validation loss = 2.7934  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 2.8072  Validation loss = 2.7933  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 2.8067  Validation loss = 2.7934  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 2.8063  Validation loss = 2.7930  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 2.8054  Validation loss = 2.7919  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 2.8046  Validation loss = 2.7912  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 2.8038  Validation loss = 2.7912  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 2.8036  Validation loss = 2.7907  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 2.8028  Validation loss = 2.7905  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 2.8025  Validation loss = 2.7902  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 2.8017  Validation loss = 2.7903  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 2.8010  Validation loss = 2.7900  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 2.8008  Validation loss = 2.7901  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 2.7998  Validation loss = 2.7881  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 2.7991  Validation loss = 2.7888  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 2.7984  Validation loss = 2.7881  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 2.7977  Validation loss = 2.7878  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 2.7971  Validation loss = 2.7869  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 2.7968  Validation loss = 2.7854  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 2.7963  Validation loss = 2.7870  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 2.7968  Validation loss = 2.7873  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 2.7957  Validation loss = 2.7863  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 2.7954  Validation loss = 2.7855  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 2.7943  Validation loss = 2.7842  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 2.7938  Validation loss = 2.7839  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 2.7930  Validation loss = 2.7837  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 2.7917  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 2.7912  Validation loss = 2.7815  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 2.7909  Validation loss = 2.7811  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 2.7899  Validation loss = 2.7802  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 2.7894  Validation loss = 2.7786  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 2.7887  Validation loss = 2.7770  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 2.7882  Validation loss = 2.7777  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 2.7878  Validation loss = 2.7788  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 2.7870  Validation loss = 2.7784  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 2.7867  Validation loss = 2.7778  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 2.7864  Validation loss = 2.7782  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 2.7864  Validation loss = 2.7788  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 2.7858  Validation loss = 2.7775  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 2.7847  Validation loss = 2.7775  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 2.7838  Validation loss = 2.7764  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 2.7837  Validation loss = 2.7765  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 2.7837  Validation loss = 2.7761  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 2.7840  Validation loss = 2.7762  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 2.7831  Validation loss = 2.7763  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 2.7816  Validation loss = 2.7760  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 2.7816  Validation loss = 2.7745  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 2.7807  Validation loss = 2.7739  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 2.7800  Validation loss = 2.7735  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 2.7799  Validation loss = 2.7728  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 2.7784  Validation loss = 2.7726  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 2.7783  Validation loss = 2.7725  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 2.7777  Validation loss = 2.7719  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 2.7771  Validation loss = 2.7719  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 2.7766  Validation loss = 2.7714  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 2.7760  Validation loss = 2.7710  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 2.7754  Validation loss = 2.7696  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 2.7749  Validation loss = 2.7687  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 2.7742  Validation loss = 2.7690  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 2.7738  Validation loss = 2.7690  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 2.7734  Validation loss = 2.7686  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 2.7729  Validation loss = 2.7675  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 2.7724  Validation loss = 2.7672  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 2.7717  Validation loss = 2.7663  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 2.7727  Validation loss = 2.7655  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 2.7707  Validation loss = 2.7666  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 2.7702  Validation loss = 2.7666  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 2.7694  Validation loss = 2.7671  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 2.7686  Validation loss = 2.7667  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 2.7682  Validation loss = 2.7671  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 2.7675  Validation loss = 2.7651  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 2.7674  Validation loss = 2.7659  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 2.7669  Validation loss = 2.7657  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 2.7666  Validation loss = 2.7643  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 2.7666  Validation loss = 2.7639  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 2.7666  Validation loss = 2.7633  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 2.7661  Validation loss = 2.7634  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 2.7658  Validation loss = 2.7619  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 2.7660  Validation loss = 2.7615  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 2.7654  Validation loss = 2.7594  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 2.7635  Validation loss = 2.7582  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 2.7635  Validation loss = 2.7573  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 2.7630  Validation loss = 2.7576  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 2.7620  Validation loss = 2.7572  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 2.7612  Validation loss = 2.7559  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 2.7602  Validation loss = 2.7551  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 2.7598  Validation loss = 2.7548  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 2.7596  Validation loss = 2.7536  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 2.7597  Validation loss = 2.7546  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 2.7587  Validation loss = 2.7550  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 2.7579  Validation loss = 2.7535  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 2.7573  Validation loss = 2.7539  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 2.7573  Validation loss = 2.7528  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 2.7567  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 2.7556  Validation loss = 2.7517  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 2.7550  Validation loss = 2.7514  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 2.7545  Validation loss = 2.7524  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 2.7540  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 2.7536  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 2.7532  Validation loss = 2.7525  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 2.7529  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 2.7524  Validation loss = 2.7529  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 2.7526  Validation loss = 2.7533  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 2.7520  Validation loss = 2.7522  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 2.7516  Validation loss = 2.7514  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 2.7513  Validation loss = 2.7521  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 2.7512  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 2.7507  Validation loss = 2.7520  \n",
      "\n",
      "Fold: 19  Epoch: 158  Training loss = 2.7499  Validation loss = 2.7526  \n",
      "\n",
      "Fold: 19  Epoch: 159  Training loss = 2.7500  Validation loss = 2.7520  \n",
      "\n",
      "Fold: 19  Epoch: 160  Training loss = 2.7502  Validation loss = 2.7526  \n",
      "\n",
      "Fold: 19  Epoch: 161  Training loss = 2.7494  Validation loss = 2.7528  \n",
      "\n",
      "Fold: 19  Epoch: 162  Training loss = 2.7491  Validation loss = 2.7517  \n",
      "\n",
      "Fold: 19  Epoch: 163  Training loss = 2.7486  Validation loss = 2.7529  \n",
      "\n",
      "Fold: 19  Epoch: 164  Training loss = 2.7479  Validation loss = 2.7517  \n",
      "\n",
      "Fold: 19  Epoch: 165  Training loss = 2.7468  Validation loss = 2.7507  \n",
      "\n",
      "Fold: 19  Epoch: 166  Training loss = 2.7473  Validation loss = 2.7502  \n",
      "\n",
      "Fold: 19  Epoch: 167  Training loss = 2.7460  Validation loss = 2.7495  \n",
      "\n",
      "Fold: 19  Epoch: 168  Training loss = 2.7459  Validation loss = 2.7495  \n",
      "\n",
      "Fold: 19  Epoch: 169  Training loss = 2.7453  Validation loss = 2.7505  \n",
      "\n",
      "Fold: 19  Epoch: 170  Training loss = 2.7461  Validation loss = 2.7507  \n",
      "\n",
      "Fold: 19  Epoch: 171  Training loss = 2.7447  Validation loss = 2.7500  \n",
      "\n",
      "Fold: 19  Epoch: 172  Training loss = 2.7447  Validation loss = 2.7473  \n",
      "\n",
      "Fold: 19  Epoch: 173  Training loss = 2.7435  Validation loss = 2.7477  \n",
      "\n",
      "Fold: 19  Epoch: 174  Training loss = 2.7429  Validation loss = 2.7485  \n",
      "\n",
      "Fold: 19  Epoch: 175  Training loss = 2.7424  Validation loss = 2.7479  \n",
      "\n",
      "Fold: 19  Epoch: 176  Training loss = 2.7427  Validation loss = 2.7461  \n",
      "\n",
      "Fold: 19  Epoch: 177  Training loss = 2.7418  Validation loss = 2.7476  \n",
      "\n",
      "Fold: 19  Epoch: 178  Training loss = 2.7414  Validation loss = 2.7457  \n",
      "\n",
      "Fold: 19  Epoch: 179  Training loss = 2.7411  Validation loss = 2.7441  \n",
      "\n",
      "Fold: 19  Epoch: 180  Training loss = 2.7466  Validation loss = 2.7425  \n",
      "\n",
      "Fold: 19  Epoch: 181  Training loss = 2.7403  Validation loss = 2.7425  \n",
      "\n",
      "Fold: 19  Epoch: 182  Training loss = 2.7400  Validation loss = 2.7431  \n",
      "\n",
      "Fold: 19  Epoch: 183  Training loss = 2.7400  Validation loss = 2.7437  \n",
      "\n",
      "Fold: 19  Epoch: 184  Training loss = 2.7390  Validation loss = 2.7429  \n",
      "\n",
      "Fold: 19  Epoch: 185  Training loss = 2.7385  Validation loss = 2.7419  \n",
      "\n",
      "Fold: 19  Epoch: 186  Training loss = 2.7387  Validation loss = 2.7402  \n",
      "\n",
      "Fold: 19  Epoch: 187  Training loss = 2.7381  Validation loss = 2.7422  \n",
      "\n",
      "Fold: 19  Epoch: 188  Training loss = 2.7381  Validation loss = 2.7417  \n",
      "\n",
      "Fold: 19  Epoch: 189  Training loss = 2.7374  Validation loss = 2.7394  \n",
      "\n",
      "Fold: 19  Epoch: 190  Training loss = 2.7376  Validation loss = 2.7376  \n",
      "\n",
      "Fold: 19  Epoch: 191  Training loss = 2.7366  Validation loss = 2.7367  \n",
      "\n",
      "Fold: 19  Epoch: 192  Training loss = 2.7444  Validation loss = 2.7345  \n",
      "\n",
      "Fold: 19  Epoch: 193  Training loss = 2.7360  Validation loss = 2.7340  \n",
      "\n",
      "Fold: 19  Epoch: 194  Training loss = 2.7355  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 19  Epoch: 195  Training loss = 2.7349  Validation loss = 2.7319  \n",
      "\n",
      "Fold: 19  Epoch: 196  Training loss = 2.7342  Validation loss = 2.7310  \n",
      "\n",
      "Fold: 19  Epoch: 197  Training loss = 2.7337  Validation loss = 2.7318  \n",
      "\n",
      "Fold: 19  Epoch: 198  Training loss = 2.7338  Validation loss = 2.7329  \n",
      "\n",
      "Fold: 19  Epoch: 199  Training loss = 2.7341  Validation loss = 2.7323  \n",
      "\n",
      "Fold: 19  Epoch: 200  Training loss = 2.7334  Validation loss = 2.7309  \n",
      "\n",
      "Fold: 19  Epoch: 201  Training loss = 2.7328  Validation loss = 2.7305  \n",
      "\n",
      "Fold: 19  Epoch: 202  Training loss = 2.7325  Validation loss = 2.7292  \n",
      "\n",
      "Fold: 19  Epoch: 203  Training loss = 2.7320  Validation loss = 2.7270  \n",
      "\n",
      "Fold: 19  Epoch: 204  Training loss = 2.7309  Validation loss = 2.7255  \n",
      "\n",
      "Fold: 19  Epoch: 205  Training loss = 2.7304  Validation loss = 2.7253  \n",
      "\n",
      "Fold: 19  Epoch: 206  Training loss = 2.7298  Validation loss = 2.7258  \n",
      "\n",
      "Fold: 19  Epoch: 207  Training loss = 2.7294  Validation loss = 2.7262  \n",
      "\n",
      "Fold: 19  Epoch: 208  Training loss = 2.7294  Validation loss = 2.7252  \n",
      "\n",
      "Fold: 19  Epoch: 209  Training loss = 2.7289  Validation loss = 2.7249  \n",
      "\n",
      "Fold: 19  Epoch: 210  Training loss = 2.7285  Validation loss = 2.7259  \n",
      "\n",
      "Fold: 19  Epoch: 211  Training loss = 2.7276  Validation loss = 2.7250  \n",
      "\n",
      "Fold: 19  Epoch: 212  Training loss = 2.7271  Validation loss = 2.7244  \n",
      "\n",
      "Fold: 19  Epoch: 213  Training loss = 2.7272  Validation loss = 2.7256  \n",
      "\n",
      "Fold: 19  Epoch: 214  Training loss = 2.7268  Validation loss = 2.7244  \n",
      "\n",
      "Fold: 19  Epoch: 215  Training loss = 2.7264  Validation loss = 2.7243  \n",
      "\n",
      "Fold: 19  Epoch: 216  Training loss = 2.7260  Validation loss = 2.7249  \n",
      "\n",
      "Fold: 19  Epoch: 217  Training loss = 2.7260  Validation loss = 2.7238  \n",
      "\n",
      "Fold: 19  Epoch: 218  Training loss = 2.7256  Validation loss = 2.7254  \n",
      "\n",
      "Fold: 19  Epoch: 219  Training loss = 2.7254  Validation loss = 2.7257  \n",
      "\n",
      "Fold: 19  Epoch: 220  Training loss = 2.7250  Validation loss = 2.7238  \n",
      "\n",
      "Fold: 19  Epoch: 221  Training loss = 2.7249  Validation loss = 2.7238  \n",
      "\n",
      "Fold: 19  Epoch: 222  Training loss = 2.7244  Validation loss = 2.7228  \n",
      "\n",
      "Fold: 19  Epoch: 223  Training loss = 2.7239  Validation loss = 2.7221  \n",
      "\n",
      "Fold: 19  Epoch: 224  Training loss = 2.7236  Validation loss = 2.7225  \n",
      "\n",
      "Fold: 19  Epoch: 225  Training loss = 2.7231  Validation loss = 2.7215  \n",
      "\n",
      "Fold: 19  Epoch: 226  Training loss = 2.7228  Validation loss = 2.7214  \n",
      "\n",
      "Fold: 19  Epoch: 227  Training loss = 2.7223  Validation loss = 2.7203  \n",
      "\n",
      "Fold: 19  Epoch: 228  Training loss = 2.7221  Validation loss = 2.7187  \n",
      "\n",
      "Fold: 19  Epoch: 229  Training loss = 2.7216  Validation loss = 2.7182  \n",
      "\n",
      "Fold: 19  Epoch: 230  Training loss = 2.7211  Validation loss = 2.7175  \n",
      "\n",
      "Fold: 19  Epoch: 231  Training loss = 2.7218  Validation loss = 2.7162  \n",
      "\n",
      "Fold: 19  Epoch: 232  Training loss = 2.7204  Validation loss = 2.7179  \n",
      "\n",
      "Fold: 19  Epoch: 233  Training loss = 2.7203  Validation loss = 2.7172  \n",
      "\n",
      "Fold: 19  Epoch: 234  Training loss = 2.7197  Validation loss = 2.7170  \n",
      "\n",
      "Fold: 19  Epoch: 235  Training loss = 2.7194  Validation loss = 2.7152  \n",
      "\n",
      "Fold: 19  Epoch: 236  Training loss = 2.7186  Validation loss = 2.7158  \n",
      "\n",
      "Fold: 19  Epoch: 237  Training loss = 2.7186  Validation loss = 2.7158  \n",
      "\n",
      "Fold: 19  Epoch: 238  Training loss = 2.7189  Validation loss = 2.7167  \n",
      "\n",
      "Fold: 19  Epoch: 239  Training loss = 2.7183  Validation loss = 2.7158  \n",
      "\n",
      "Fold: 19  Epoch: 240  Training loss = 2.7177  Validation loss = 2.7154  \n",
      "\n",
      "Fold: 19  Epoch: 241  Training loss = 2.7173  Validation loss = 2.7141  \n",
      "\n",
      "Fold: 19  Epoch: 242  Training loss = 2.7167  Validation loss = 2.7142  \n",
      "\n",
      "Fold: 19  Epoch: 243  Training loss = 2.7163  Validation loss = 2.7146  \n",
      "\n",
      "Fold: 19  Epoch: 244  Training loss = 2.7158  Validation loss = 2.7128  \n",
      "\n",
      "Fold: 19  Epoch: 245  Training loss = 2.7155  Validation loss = 2.7141  \n",
      "\n",
      "Fold: 19  Epoch: 246  Training loss = 2.7150  Validation loss = 2.7127  \n",
      "\n",
      "Fold: 19  Epoch: 247  Training loss = 2.7146  Validation loss = 2.7147  \n",
      "\n",
      "Fold: 19  Epoch: 248  Training loss = 2.7142  Validation loss = 2.7126  \n",
      "\n",
      "Fold: 19  Epoch: 249  Training loss = 2.7137  Validation loss = 2.7123  \n",
      "\n",
      "Fold: 19  Epoch: 250  Training loss = 2.7133  Validation loss = 2.7101  \n",
      "\n",
      "Fold: 19  Epoch: 251  Training loss = 2.7130  Validation loss = 2.7085  \n",
      "\n",
      "Fold: 19  Epoch: 252  Training loss = 2.7130  Validation loss = 2.7090  \n",
      "\n",
      "Fold: 19  Epoch: 253  Training loss = 2.7126  Validation loss = 2.7080  \n",
      "\n",
      "Fold: 19  Epoch: 254  Training loss = 2.7122  Validation loss = 2.7079  \n",
      "\n",
      "Fold: 19  Epoch: 255  Training loss = 2.7117  Validation loss = 2.7072  \n",
      "\n",
      "Fold: 19  Epoch: 256  Training loss = 2.7123  Validation loss = 2.7036  \n",
      "\n",
      "Fold: 19  Epoch: 257  Training loss = 2.7113  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 19  Epoch: 258  Training loss = 2.7111  Validation loss = 2.7071  \n",
      "\n",
      "Fold: 19  Epoch: 259  Training loss = 2.7105  Validation loss = 2.7049  \n",
      "\n",
      "Fold: 19  Epoch: 260  Training loss = 2.7102  Validation loss = 2.7050  \n",
      "\n",
      "Fold: 19  Epoch: 261  Training loss = 2.7094  Validation loss = 2.7050  \n",
      "\n",
      "Fold: 19  Epoch: 262  Training loss = 2.7085  Validation loss = 2.7038  \n",
      "\n",
      "Fold: 19  Epoch: 263  Training loss = 2.7083  Validation loss = 2.7032  \n",
      "\n",
      "Fold: 19  Epoch: 264  Training loss = 2.7078  Validation loss = 2.7026  \n",
      "\n",
      "Fold: 19  Epoch: 265  Training loss = 2.7076  Validation loss = 2.7036  \n",
      "\n",
      "Fold: 19  Epoch: 266  Training loss = 2.7077  Validation loss = 2.7020  \n",
      "\n",
      "Fold: 19  Epoch: 267  Training loss = 2.7071  Validation loss = 2.7018  \n",
      "\n",
      "Fold: 19  Epoch: 268  Training loss = 2.7066  Validation loss = 2.7008  \n",
      "\n",
      "Fold: 19  Epoch: 269  Training loss = 2.7061  Validation loss = 2.7014  \n",
      "\n",
      "Fold: 19  Epoch: 270  Training loss = 2.7057  Validation loss = 2.7025  \n",
      "\n",
      "Fold: 19  Epoch: 271  Training loss = 2.7056  Validation loss = 2.7010  \n",
      "\n",
      "Fold: 19  Epoch: 272  Training loss = 2.7052  Validation loss = 2.7019  \n",
      "\n",
      "Fold: 19  Epoch: 273  Training loss = 2.7050  Validation loss = 2.7017  \n",
      "\n",
      "Fold: 19  Epoch: 274  Training loss = 2.7043  Validation loss = 2.7030  \n",
      "\n",
      "Fold: 19  Epoch: 275  Training loss = 2.7037  Validation loss = 2.7027  \n",
      "\n",
      "Fold: 19  Epoch: 276  Training loss = 2.7034  Validation loss = 2.7023  \n",
      "\n",
      "Fold: 19  Epoch: 277  Training loss = 2.7030  Validation loss = 2.7008  \n",
      "\n",
      "Fold: 19  Epoch: 278  Training loss = 2.7029  Validation loss = 2.6980  \n",
      "\n",
      "Fold: 19  Epoch: 279  Training loss = 2.7022  Validation loss = 2.6984  \n",
      "\n",
      "Fold: 19  Epoch: 280  Training loss = 2.7017  Validation loss = 2.6970  \n",
      "\n",
      "Fold: 19  Epoch: 281  Training loss = 2.7016  Validation loss = 2.6982  \n",
      "\n",
      "Fold: 19  Epoch: 282  Training loss = 2.7012  Validation loss = 2.6985  \n",
      "\n",
      "Fold: 19  Epoch: 283  Training loss = 2.7011  Validation loss = 2.6973  \n",
      "\n",
      "Fold: 19  Epoch: 284  Training loss = 2.7006  Validation loss = 2.6968  \n",
      "\n",
      "Fold: 19  Epoch: 285  Training loss = 2.7001  Validation loss = 2.6984  \n",
      "\n",
      "Fold: 19  Epoch: 286  Training loss = 2.6996  Validation loss = 2.6981  \n",
      "\n",
      "Fold: 19  Epoch: 287  Training loss = 2.6992  Validation loss = 2.6962  \n",
      "\n",
      "Fold: 19  Epoch: 288  Training loss = 2.6989  Validation loss = 2.6950  \n",
      "\n",
      "Fold: 19  Epoch: 289  Training loss = 2.6985  Validation loss = 2.6959  \n",
      "\n",
      "Fold: 19  Epoch: 290  Training loss = 2.6982  Validation loss = 2.6973  \n",
      "\n",
      "Fold: 19  Epoch: 291  Training loss = 2.6980  Validation loss = 2.6953  \n",
      "\n",
      "Fold: 19  Epoch: 292  Training loss = 2.6976  Validation loss = 2.6957  \n",
      "\n",
      "Fold: 19  Epoch: 293  Training loss = 2.6975  Validation loss = 2.6962  \n",
      "\n",
      "Fold: 19  Epoch: 294  Training loss = 2.6972  Validation loss = 2.6952  \n",
      "\n",
      "Fold: 19  Epoch: 295  Training loss = 2.6967  Validation loss = 2.6941  \n",
      "\n",
      "Fold: 19  Epoch: 296  Training loss = 2.6970  Validation loss = 2.6935  \n",
      "\n",
      "Fold: 19  Epoch: 297  Training loss = 2.6964  Validation loss = 2.6932  \n",
      "\n",
      "Fold: 19  Epoch: 298  Training loss = 2.6963  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 19  Epoch: 299  Training loss = 2.6954  Validation loss = 2.6913  \n",
      "\n",
      "Fold: 19  Epoch: 300  Training loss = 2.6950  Validation loss = 2.6896  \n",
      "\n",
      "Fold: 19  Epoch: 301  Training loss = 2.6962  Validation loss = 2.7023  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 300  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.7699  Validation loss = 1.4607  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.7688  Validation loss = 1.4579  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.7682  Validation loss = 1.4564  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.7677  Validation loss = 1.4566  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.7669  Validation loss = 1.4544  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.7657  Validation loss = 1.4524  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.7653  Validation loss = 1.4515  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.7644  Validation loss = 1.4479  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.7636  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.7635  Validation loss = 1.4429  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.7625  Validation loss = 1.4431  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.7616  Validation loss = 1.4400  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 2.7617  Validation loss = 1.4396  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.7608  Validation loss = 1.4374  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.7602  Validation loss = 1.4361  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.7595  Validation loss = 1.4345  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.7588  Validation loss = 1.4298  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.7585  Validation loss = 1.4285  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 2.7580  Validation loss = 1.4253  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 2.7577  Validation loss = 1.4243  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 2.7568  Validation loss = 1.4212  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 2.7567  Validation loss = 1.4178  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 2.7559  Validation loss = 1.4174  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 2.7551  Validation loss = 1.4146  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 2.7545  Validation loss = 1.4133  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 2.7539  Validation loss = 1.4120  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 2.7541  Validation loss = 1.4096  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 2.7537  Validation loss = 1.4091  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 2.7527  Validation loss = 1.4061  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 2.7521  Validation loss = 1.4052  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 2.7520  Validation loss = 1.4050  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 2.7508  Validation loss = 1.4027  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 2.7501  Validation loss = 1.3988  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 2.7495  Validation loss = 1.3965  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 2.7491  Validation loss = 1.3961  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 2.7489  Validation loss = 1.3959  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 2.7484  Validation loss = 1.3945  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 2.7478  Validation loss = 1.3912  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 2.7471  Validation loss = 1.3896  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 2.7464  Validation loss = 1.3880  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 2.7479  Validation loss = 1.3866  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 2.7468  Validation loss = 1.3845  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 2.7464  Validation loss = 1.3842  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 2.7460  Validation loss = 1.3838  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 2.7454  Validation loss = 1.3842  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 2.7449  Validation loss = 1.3832  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 2.7443  Validation loss = 1.3825  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 2.7438  Validation loss = 1.3804  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 2.7428  Validation loss = 1.3783  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 2.7421  Validation loss = 1.3768  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 2.7413  Validation loss = 1.3730  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 2.7410  Validation loss = 1.3731  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 2.7403  Validation loss = 1.3707  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 2.7396  Validation loss = 1.3694  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 2.7391  Validation loss = 1.3694  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 2.7386  Validation loss = 1.3691  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 2.7379  Validation loss = 1.3666  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 2.7373  Validation loss = 1.3646  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 2.7369  Validation loss = 1.3639  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 2.7366  Validation loss = 1.3623  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 2.7361  Validation loss = 1.3621  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 2.7355  Validation loss = 1.3600  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 2.7352  Validation loss = 1.3602  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 2.7348  Validation loss = 1.3578  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 2.7341  Validation loss = 1.3557  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 2.7336  Validation loss = 1.3541  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 2.7329  Validation loss = 1.3516  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 2.7323  Validation loss = 1.3491  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 2.7320  Validation loss = 1.3487  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 2.7317  Validation loss = 1.3464  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 2.7315  Validation loss = 1.3452  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 2.7316  Validation loss = 1.3442  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 2.7352  Validation loss = 1.3437  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 2.7359  Validation loss = 1.3470  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 2.7348  Validation loss = 1.3455  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 2.7339  Validation loss = 1.3426  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 2.7332  Validation loss = 1.3422  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 2.7324  Validation loss = 1.3413  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 2.7334  Validation loss = 1.3379  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 2.7321  Validation loss = 1.3378  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 2.7320  Validation loss = 1.3359  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 2.7311  Validation loss = 1.3313  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 2.7291  Validation loss = 1.3308  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 2.7283  Validation loss = 1.3298  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 2.7275  Validation loss = 1.3282  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 2.7269  Validation loss = 1.3263  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 2.7255  Validation loss = 1.3254  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 2.7241  Validation loss = 1.3223  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 2.7237  Validation loss = 1.3210  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 2.7224  Validation loss = 1.3195  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 2.7214  Validation loss = 1.3179  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 2.7205  Validation loss = 1.3143  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 2.7202  Validation loss = 1.3115  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 2.7192  Validation loss = 1.3112  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 2.7186  Validation loss = 1.3101  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 2.7175  Validation loss = 1.3069  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 2.7172  Validation loss = 1.3068  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 2.7168  Validation loss = 1.3068  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 2.7168  Validation loss = 1.3062  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 2.7160  Validation loss = 1.3056  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 2.7158  Validation loss = 1.3036  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 2.7157  Validation loss = 1.3010  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 2.7155  Validation loss = 1.3003  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 2.7165  Validation loss = 1.2978  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 2.7159  Validation loss = 1.2957  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 2.7144  Validation loss = 1.2923  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 2.7143  Validation loss = 1.2916  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 2.7128  Validation loss = 1.2888  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 2.7129  Validation loss = 1.2880  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 2.7119  Validation loss = 1.2884  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 2.7107  Validation loss = 1.2854  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 2.7099  Validation loss = 1.2847  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 2.7091  Validation loss = 1.2848  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 2.7088  Validation loss = 1.2841  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 2.7082  Validation loss = 1.2839  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 2.7076  Validation loss = 1.2847  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 2.7074  Validation loss = 1.2844  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 2.7070  Validation loss = 1.2841  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 2.7065  Validation loss = 1.2819  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 2.7063  Validation loss = 1.2822  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 2.7059  Validation loss = 1.2821  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 2.7053  Validation loss = 1.2790  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 2.7045  Validation loss = 1.2784  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 2.7042  Validation loss = 1.2764  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 2.7037  Validation loss = 1.2738  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 2.7031  Validation loss = 1.2722  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 2.7030  Validation loss = 1.2709  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 2.7024  Validation loss = 1.2702  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 2.7018  Validation loss = 1.2686  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 2.7013  Validation loss = 1.2689  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 2.7007  Validation loss = 1.2669  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 2.7004  Validation loss = 1.2650  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 2.7006  Validation loss = 1.2610  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 2.7009  Validation loss = 1.2600  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 2.7001  Validation loss = 1.2565  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 2.7010  Validation loss = 1.2554  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 2.6996  Validation loss = 1.2525  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 2.6976  Validation loss = 1.2521  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 2.6965  Validation loss = 1.2501  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 2.6962  Validation loss = 1.2491  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 2.6954  Validation loss = 1.2484  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 2.6958  Validation loss = 1.2473  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 2.6986  Validation loss = 1.2479  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 2.6966  Validation loss = 1.2455  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 2.6959  Validation loss = 1.2431  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 2.6951  Validation loss = 1.2413  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 2.6944  Validation loss = 1.2403  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 2.6932  Validation loss = 1.2385  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 2.6927  Validation loss = 1.2354  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 2.6922  Validation loss = 1.2326  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 2.6910  Validation loss = 1.2294  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 2.6903  Validation loss = 1.2270  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 2.6897  Validation loss = 1.2260  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 2.6893  Validation loss = 1.2251  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 2.6887  Validation loss = 1.2239  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 2.6882  Validation loss = 1.2239  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 2.6879  Validation loss = 1.2222  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 2.6874  Validation loss = 1.2184  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 2.6865  Validation loss = 1.2171  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 2.6862  Validation loss = 1.2154  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 2.6857  Validation loss = 1.2134  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 2.6853  Validation loss = 1.2112  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 2.6850  Validation loss = 1.2113  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 2.6845  Validation loss = 1.2102  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 2.6838  Validation loss = 1.2071  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 2.6840  Validation loss = 1.2082  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 2.6826  Validation loss = 1.2060  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 2.6818  Validation loss = 1.2026  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 2.6819  Validation loss = 1.2000  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 2.6809  Validation loss = 1.2001  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 2.6802  Validation loss = 1.1988  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 2.6797  Validation loss = 1.1967  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 2.6791  Validation loss = 1.1948  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 2.6786  Validation loss = 1.1944  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 2.6784  Validation loss = 1.1950  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 2.6778  Validation loss = 1.1930  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 2.6771  Validation loss = 1.1911  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 2.6766  Validation loss = 1.1900  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 2.6763  Validation loss = 1.1895  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 2.6763  Validation loss = 1.1897  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 2.6758  Validation loss = 1.1890  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 2.6754  Validation loss = 1.1870  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 2.6772  Validation loss = 1.1863  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 2.6771  Validation loss = 1.1865  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 2.6757  Validation loss = 1.1889  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 2.6761  Validation loss = 1.1887  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 2.6755  Validation loss = 1.1873  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 2.6736  Validation loss = 1.1843  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 2.6727  Validation loss = 1.1820  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 2.6713  Validation loss = 1.1813  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 2.6715  Validation loss = 1.1808  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 2.6707  Validation loss = 1.1792  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 2.6700  Validation loss = 1.1766  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 2.6697  Validation loss = 1.1751  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 2.6691  Validation loss = 1.1767  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 2.6686  Validation loss = 1.1723  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 2.6685  Validation loss = 1.1718  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 2.6684  Validation loss = 1.1727  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 2.6685  Validation loss = 1.1718  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 2.6675  Validation loss = 1.1691  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 2.6671  Validation loss = 1.1675  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 2.6668  Validation loss = 1.1698  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 2.6660  Validation loss = 1.1690  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 2.6662  Validation loss = 1.1671  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 2.6661  Validation loss = 1.1647  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 2.6661  Validation loss = 1.1649  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 2.6647  Validation loss = 1.1622  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 2.6636  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 2.6641  Validation loss = 1.1603  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 2.6635  Validation loss = 1.1590  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 2.6632  Validation loss = 1.1595  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 2.6636  Validation loss = 1.1588  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 2.6636  Validation loss = 1.1598  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 2.6651  Validation loss = 1.1565  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 2.6636  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 2.6633  Validation loss = 1.1542  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 2.6637  Validation loss = 1.1539  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 2.6631  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 2.6617  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 2.6616  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 2.6609  Validation loss = 1.1489  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 2.6601  Validation loss = 1.1479  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 2.6595  Validation loss = 1.1467  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 2.6585  Validation loss = 1.1461  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 2.6586  Validation loss = 1.1430  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 2.6578  Validation loss = 1.1421  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 2.6554  Validation loss = 1.1405  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 2.6551  Validation loss = 1.1392  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 2.6542  Validation loss = 1.1381  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 2.6538  Validation loss = 1.1387  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 2.6539  Validation loss = 1.1357  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 2.6529  Validation loss = 1.1356  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 2.6523  Validation loss = 1.1321  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 2.6507  Validation loss = 1.1288  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 2.6503  Validation loss = 1.1293  \n",
      "\n",
      "Fold: 20  Epoch: 236  Training loss = 2.6499  Validation loss = 1.1264  \n",
      "\n",
      "Fold: 20  Epoch: 237  Training loss = 2.6497  Validation loss = 1.1254  \n",
      "\n",
      "Fold: 20  Epoch: 238  Training loss = 2.6487  Validation loss = 1.1248  \n",
      "\n",
      "Fold: 20  Epoch: 239  Training loss = 2.6484  Validation loss = 1.1243  \n",
      "\n",
      "Fold: 20  Epoch: 240  Training loss = 2.6481  Validation loss = 1.1228  \n",
      "\n",
      "Fold: 20  Epoch: 241  Training loss = 2.6479  Validation loss = 1.1229  \n",
      "\n",
      "Fold: 20  Epoch: 242  Training loss = 2.6471  Validation loss = 1.1224  \n",
      "\n",
      "Fold: 20  Epoch: 243  Training loss = 2.6468  Validation loss = 1.1230  \n",
      "\n",
      "Fold: 20  Epoch: 244  Training loss = 2.6472  Validation loss = 1.1255  \n",
      "\n",
      "Fold: 20  Epoch: 245  Training loss = 2.6475  Validation loss = 1.1255  \n",
      "\n",
      "Fold: 20  Epoch: 246  Training loss = 2.6472  Validation loss = 1.1243  \n",
      "\n",
      "Fold: 20  Epoch: 247  Training loss = 2.6468  Validation loss = 1.1246  \n",
      "\n",
      "Fold: 20  Epoch: 248  Training loss = 2.6458  Validation loss = 1.1242  \n",
      "\n",
      "Fold: 20  Epoch: 249  Training loss = 2.6456  Validation loss = 1.1234  \n",
      "\n",
      "Fold: 20  Epoch: 250  Training loss = 2.6452  Validation loss = 1.1225  \n",
      "\n",
      "Fold: 20  Epoch: 251  Training loss = 2.6449  Validation loss = 1.1216  \n",
      "\n",
      "Fold: 20  Epoch: 252  Training loss = 2.6441  Validation loss = 1.1207  \n",
      "\n",
      "Fold: 20  Epoch: 253  Training loss = 2.6438  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 20  Epoch: 254  Training loss = 2.6432  Validation loss = 1.1183  \n",
      "\n",
      "Fold: 20  Epoch: 255  Training loss = 2.6429  Validation loss = 1.1168  \n",
      "\n",
      "Fold: 20  Epoch: 256  Training loss = 2.6424  Validation loss = 1.1156  \n",
      "\n",
      "Fold: 20  Epoch: 257  Training loss = 2.6417  Validation loss = 1.1126  \n",
      "\n",
      "Fold: 20  Epoch: 258  Training loss = 2.6411  Validation loss = 1.1111  \n",
      "\n",
      "Fold: 20  Epoch: 259  Training loss = 2.6412  Validation loss = 1.1084  \n",
      "\n",
      "Fold: 20  Epoch: 260  Training loss = 2.6411  Validation loss = 1.1088  \n",
      "\n",
      "Fold: 20  Epoch: 261  Training loss = 2.6406  Validation loss = 1.1078  \n",
      "\n",
      "Fold: 20  Epoch: 262  Training loss = 2.6388  Validation loss = 1.1054  \n",
      "\n",
      "Fold: 20  Epoch: 263  Training loss = 2.6394  Validation loss = 1.1060  \n",
      "\n",
      "Fold: 20  Epoch: 264  Training loss = 2.6397  Validation loss = 1.1052  \n",
      "\n",
      "Fold: 20  Epoch: 265  Training loss = 2.6393  Validation loss = 1.1050  \n",
      "\n",
      "Fold: 20  Epoch: 266  Training loss = 2.6384  Validation loss = 1.1048  \n",
      "\n",
      "Fold: 20  Epoch: 267  Training loss = 2.6380  Validation loss = 1.1037  \n",
      "\n",
      "Fold: 20  Epoch: 268  Training loss = 2.6377  Validation loss = 1.1024  \n",
      "\n",
      "Fold: 20  Epoch: 269  Training loss = 2.6361  Validation loss = 1.1012  \n",
      "\n",
      "Fold: 20  Epoch: 270  Training loss = 2.6354  Validation loss = 1.0993  \n",
      "\n",
      "Fold: 20  Epoch: 271  Training loss = 2.6350  Validation loss = 1.0990  \n",
      "\n",
      "Fold: 20  Epoch: 272  Training loss = 2.6344  Validation loss = 1.0974  \n",
      "\n",
      "Fold: 20  Epoch: 273  Training loss = 2.6343  Validation loss = 1.1000  \n",
      "\n",
      "Fold: 20  Epoch: 274  Training loss = 2.6344  Validation loss = 1.0997  \n",
      "\n",
      "Fold: 20  Epoch: 275  Training loss = 2.6331  Validation loss = 1.0988  \n",
      "\n",
      "Fold: 20  Epoch: 276  Training loss = 2.6327  Validation loss = 1.0990  \n",
      "\n",
      "Fold: 20  Epoch: 277  Training loss = 2.6325  Validation loss = 1.0980  \n",
      "\n",
      "Fold: 20  Epoch: 278  Training loss = 2.6324  Validation loss = 1.0981  \n",
      "\n",
      "Fold: 20  Epoch: 279  Training loss = 2.6323  Validation loss = 1.0974  \n",
      "\n",
      "Fold: 20  Epoch: 280  Training loss = 2.6322  Validation loss = 1.0951  \n",
      "\n",
      "Fold: 20  Epoch: 281  Training loss = 2.6316  Validation loss = 1.0952  \n",
      "\n",
      "Fold: 20  Epoch: 282  Training loss = 2.6308  Validation loss = 1.0925  \n",
      "\n",
      "Fold: 20  Epoch: 283  Training loss = 2.6306  Validation loss = 1.0924  \n",
      "\n",
      "Fold: 20  Epoch: 284  Training loss = 2.6304  Validation loss = 1.0923  \n",
      "\n",
      "Fold: 20  Epoch: 285  Training loss = 2.6295  Validation loss = 1.0922  \n",
      "\n",
      "Fold: 20  Epoch: 286  Training loss = 2.6290  Validation loss = 1.0907  \n",
      "\n",
      "Fold: 20  Epoch: 287  Training loss = 2.6286  Validation loss = 1.0896  \n",
      "\n",
      "Fold: 20  Epoch: 288  Training loss = 2.6285  Validation loss = 1.0883  \n",
      "\n",
      "Fold: 20  Epoch: 289  Training loss = 2.6281  Validation loss = 1.0877  \n",
      "\n",
      "Fold: 20  Epoch: 290  Training loss = 2.6270  Validation loss = 1.0868  \n",
      "\n",
      "Fold: 20  Epoch: 291  Training loss = 2.6264  Validation loss = 1.0862  \n",
      "\n",
      "Fold: 20  Epoch: 292  Training loss = 2.6274  Validation loss = 1.0857  \n",
      "\n",
      "Fold: 20  Epoch: 293  Training loss = 2.6272  Validation loss = 1.0857  \n",
      "\n",
      "Fold: 20  Epoch: 294  Training loss = 2.6265  Validation loss = 1.0846  \n",
      "\n",
      "Fold: 20  Epoch: 295  Training loss = 2.6256  Validation loss = 1.0858  \n",
      "\n",
      "Fold: 20  Epoch: 296  Training loss = 2.6255  Validation loss = 1.0821  \n",
      "\n",
      "Fold: 20  Epoch: 297  Training loss = 2.6239  Validation loss = 1.0820  \n",
      "\n",
      "Fold: 20  Epoch: 298  Training loss = 2.6235  Validation loss = 1.0822  \n",
      "\n",
      "Fold: 20  Epoch: 299  Training loss = 2.6237  Validation loss = 1.0813  \n",
      "\n",
      "Fold: 20  Epoch: 300  Training loss = 2.6226  Validation loss = 1.0800  \n",
      "\n",
      "Fold: 20  Epoch: 301  Training loss = 2.6220  Validation loss = 1.0806  \n",
      "\n",
      "Fold: 20  Epoch: 302  Training loss = 2.6216  Validation loss = 1.0796  \n",
      "\n",
      "Fold: 20  Epoch: 303  Training loss = 2.6213  Validation loss = 1.0791  \n",
      "\n",
      "Fold: 20  Epoch: 304  Training loss = 2.6214  Validation loss = 1.0779  \n",
      "\n",
      "Fold: 20  Epoch: 305  Training loss = 2.6210  Validation loss = 1.0767  \n",
      "\n",
      "Fold: 20  Epoch: 306  Training loss = 2.6205  Validation loss = 1.0769  \n",
      "\n",
      "Fold: 20  Epoch: 307  Training loss = 2.6203  Validation loss = 1.0768  \n",
      "\n",
      "Fold: 20  Epoch: 308  Training loss = 2.6201  Validation loss = 1.0748  \n",
      "\n",
      "Fold: 20  Epoch: 309  Training loss = 2.6201  Validation loss = 1.0738  \n",
      "\n",
      "Fold: 20  Epoch: 310  Training loss = 2.6214  Validation loss = 1.0735  \n",
      "\n",
      "Fold: 20  Epoch: 311  Training loss = 2.6202  Validation loss = 1.0722  \n",
      "\n",
      "Fold: 20  Epoch: 312  Training loss = 2.6190  Validation loss = 1.0718  \n",
      "\n",
      "Fold: 20  Epoch: 313  Training loss = 2.6187  Validation loss = 1.0700  \n",
      "\n",
      "Fold: 20  Epoch: 314  Training loss = 2.6187  Validation loss = 1.0683  \n",
      "\n",
      "Fold: 20  Epoch: 315  Training loss = 2.6186  Validation loss = 1.0688  \n",
      "\n",
      "Fold: 20  Epoch: 316  Training loss = 2.6177  Validation loss = 1.0686  \n",
      "\n",
      "Fold: 20  Epoch: 317  Training loss = 2.6170  Validation loss = 1.0667  \n",
      "\n",
      "Fold: 20  Epoch: 318  Training loss = 2.6164  Validation loss = 1.0670  \n",
      "\n",
      "Fold: 20  Epoch: 319  Training loss = 2.6163  Validation loss = 1.0663  \n",
      "\n",
      "Fold: 20  Epoch: 320  Training loss = 2.6163  Validation loss = 1.0651  \n",
      "\n",
      "Fold: 20  Epoch: 321  Training loss = 2.6162  Validation loss = 1.0651  \n",
      "\n",
      "Fold: 20  Epoch: 322  Training loss = 2.6156  Validation loss = 1.0629  \n",
      "\n",
      "Fold: 20  Epoch: 323  Training loss = 2.6145  Validation loss = 1.0648  \n",
      "\n",
      "Fold: 20  Epoch: 324  Training loss = 2.6137  Validation loss = 1.0645  \n",
      "\n",
      "Fold: 20  Epoch: 325  Training loss = 2.6137  Validation loss = 1.0648  \n",
      "\n",
      "Fold: 20  Epoch: 326  Training loss = 2.6131  Validation loss = 1.0646  \n",
      "\n",
      "Fold: 20  Epoch: 327  Training loss = 2.6123  Validation loss = 1.0630  \n",
      "\n",
      "Fold: 20  Epoch: 328  Training loss = 2.6120  Validation loss = 1.0621  \n",
      "\n",
      "Fold: 20  Epoch: 329  Training loss = 2.6118  Validation loss = 1.0613  \n",
      "\n",
      "Fold: 20  Epoch: 330  Training loss = 2.6123  Validation loss = 1.0605  \n",
      "\n",
      "Fold: 20  Epoch: 331  Training loss = 2.6134  Validation loss = 1.0598  \n",
      "\n",
      "Fold: 20  Epoch: 332  Training loss = 2.6126  Validation loss = 1.0595  \n",
      "\n",
      "Fold: 20  Epoch: 333  Training loss = 2.6111  Validation loss = 1.0585  \n",
      "\n",
      "Fold: 20  Epoch: 334  Training loss = 2.6103  Validation loss = 1.0586  \n",
      "\n",
      "Fold: 20  Epoch: 335  Training loss = 2.6099  Validation loss = 1.0548  \n",
      "\n",
      "Fold: 20  Epoch: 336  Training loss = 2.6123  Validation loss = 1.0553  \n",
      "\n",
      "Fold: 20  Epoch: 337  Training loss = 2.6103  Validation loss = 1.0537  \n",
      "\n",
      "Fold: 20  Epoch: 338  Training loss = 2.6277  Validation loss = 1.0529  \n",
      "\n",
      "Fold: 20  Epoch: 339  Training loss = 2.6081  Validation loss = 1.0535  \n",
      "\n",
      "Fold: 20  Epoch: 340  Training loss = 2.6067  Validation loss = 1.0533  \n",
      "\n",
      "Fold: 20  Epoch: 341  Training loss = 2.6071  Validation loss = 1.0527  \n",
      "\n",
      "Fold: 20  Epoch: 342  Training loss = 2.6072  Validation loss = 1.0505  \n",
      "\n",
      "Fold: 20  Epoch: 343  Training loss = 2.6057  Validation loss = 1.0510  \n",
      "\n",
      "Fold: 20  Epoch: 344  Training loss = 2.6056  Validation loss = 1.0505  \n",
      "\n",
      "Fold: 20  Epoch: 345  Training loss = 2.6045  Validation loss = 1.0489  \n",
      "\n",
      "Fold: 20  Epoch: 346  Training loss = 2.6039  Validation loss = 1.0493  \n",
      "\n",
      "Fold: 20  Epoch: 347  Training loss = 2.6033  Validation loss = 1.0483  \n",
      "\n",
      "Fold: 20  Epoch: 348  Training loss = 2.6029  Validation loss = 1.0473  \n",
      "\n",
      "Fold: 20  Epoch: 349  Training loss = 2.6024  Validation loss = 1.0473  \n",
      "\n",
      "Fold: 20  Epoch: 350  Training loss = 2.6023  Validation loss = 1.0467  \n",
      "\n",
      "Fold: 20  Epoch: 351  Training loss = 2.6017  Validation loss = 1.0467  \n",
      "\n",
      "Fold: 20  Epoch: 352  Training loss = 2.6015  Validation loss = 1.0454  \n",
      "\n",
      "Fold: 20  Epoch: 353  Training loss = 2.6014  Validation loss = 1.0441  \n",
      "\n",
      "Fold: 20  Epoch: 354  Training loss = 2.6002  Validation loss = 1.0444  \n",
      "\n",
      "Fold: 20  Epoch: 355  Training loss = 2.5999  Validation loss = 1.0429  \n",
      "\n",
      "Fold: 20  Epoch: 356  Training loss = 2.5996  Validation loss = 1.0429  \n",
      "\n",
      "Fold: 20  Epoch: 357  Training loss = 2.5992  Validation loss = 1.0442  \n",
      "\n",
      "Fold: 20  Epoch: 358  Training loss = 2.5984  Validation loss = 1.0428  \n",
      "\n",
      "Fold: 20  Epoch: 359  Training loss = 2.5981  Validation loss = 1.0419  \n",
      "\n",
      "Fold: 20  Epoch: 360  Training loss = 2.5989  Validation loss = 1.0420  \n",
      "\n",
      "Fold: 20  Epoch: 361  Training loss = 2.5988  Validation loss = 1.0429  \n",
      "\n",
      "Fold: 20  Epoch: 362  Training loss = 2.5995  Validation loss = 1.0441  \n",
      "\n",
      "Fold: 20  Epoch: 363  Training loss = 2.5983  Validation loss = 1.0433  \n",
      "\n",
      "Fold: 20  Epoch: 364  Training loss = 2.5982  Validation loss = 1.0434  \n",
      "\n",
      "Fold: 20  Epoch: 365  Training loss = 2.5971  Validation loss = 1.0417  \n",
      "\n",
      "Fold: 20  Epoch: 366  Training loss = 2.5964  Validation loss = 1.0411  \n",
      "\n",
      "Fold: 20  Epoch: 367  Training loss = 2.5966  Validation loss = 1.0413  \n",
      "\n",
      "Fold: 20  Epoch: 368  Training loss = 2.5979  Validation loss = 1.0420  \n",
      "\n",
      "Fold: 20  Epoch: 369  Training loss = 2.5949  Validation loss = 1.0406  \n",
      "\n",
      "Fold: 20  Epoch: 370  Training loss = 2.5950  Validation loss = 1.0409  \n",
      "\n",
      "Fold: 20  Epoch: 371  Training loss = 2.5948  Validation loss = 1.0405  \n",
      "\n",
      "Fold: 20  Epoch: 372  Training loss = 2.5936  Validation loss = 1.0376  \n",
      "\n",
      "Fold: 20  Epoch: 373  Training loss = 2.5929  Validation loss = 1.0363  \n",
      "\n",
      "Fold: 20  Epoch: 374  Training loss = 2.5937  Validation loss = 1.0351  \n",
      "\n",
      "Fold: 20  Epoch: 375  Training loss = 2.5919  Validation loss = 1.0326  \n",
      "\n",
      "Fold: 20  Epoch: 376  Training loss = 2.5915  Validation loss = 1.0326  \n",
      "\n",
      "Fold: 20  Epoch: 377  Training loss = 2.5911  Validation loss = 1.0310  \n",
      "\n",
      "Fold: 20  Epoch: 378  Training loss = 2.5907  Validation loss = 1.0292  \n",
      "\n",
      "Fold: 20  Epoch: 379  Training loss = 2.5904  Validation loss = 1.0289  \n",
      "\n",
      "Fold: 20  Epoch: 380  Training loss = 2.5901  Validation loss = 1.0298  \n",
      "\n",
      "Fold: 20  Epoch: 381  Training loss = 2.5892  Validation loss = 1.0301  \n",
      "\n",
      "Fold: 20  Epoch: 382  Training loss = 2.5890  Validation loss = 1.0307  \n",
      "\n",
      "Fold: 20  Epoch: 383  Training loss = 2.5886  Validation loss = 1.0301  \n",
      "\n",
      "Fold: 20  Epoch: 384  Training loss = 2.5881  Validation loss = 1.0296  \n",
      "\n",
      "Fold: 20  Epoch: 385  Training loss = 2.5884  Validation loss = 1.0275  \n",
      "\n",
      "Fold: 20  Epoch: 386  Training loss = 2.5895  Validation loss = 1.0284  \n",
      "\n",
      "Fold: 20  Epoch: 387  Training loss = 2.5912  Validation loss = 1.0270  \n",
      "\n",
      "Fold: 20  Epoch: 388  Training loss = 2.5938  Validation loss = 1.0272  \n",
      "\n",
      "Fold: 20  Epoch: 389  Training loss = 2.5893  Validation loss = 1.0261  \n",
      "\n",
      "Fold: 20  Epoch: 390  Training loss = 2.5879  Validation loss = 1.0243  \n",
      "\n",
      "Fold: 20  Epoch: 391  Training loss = 2.5870  Validation loss = 1.0223  \n",
      "\n",
      "Fold: 20  Epoch: 392  Training loss = 2.5863  Validation loss = 1.0231  \n",
      "\n",
      "Fold: 20  Epoch: 393  Training loss = 2.5856  Validation loss = 1.0231  \n",
      "\n",
      "Fold: 20  Epoch: 394  Training loss = 2.5845  Validation loss = 1.0221  \n",
      "\n",
      "Fold: 20  Epoch: 395  Training loss = 2.5843  Validation loss = 1.0217  \n",
      "\n",
      "Fold: 20  Epoch: 396  Training loss = 2.5848  Validation loss = 1.0217  \n",
      "\n",
      "Fold: 20  Epoch: 397  Training loss = 2.5832  Validation loss = 1.0214  \n",
      "\n",
      "Fold: 20  Epoch: 398  Training loss = 2.5846  Validation loss = 1.0195  \n",
      "\n",
      "Fold: 20  Epoch: 399  Training loss = 2.5832  Validation loss = 1.0192  \n",
      "\n",
      "Fold: 20  Epoch: 400  Training loss = 2.5819  Validation loss = 1.0185  \n",
      "\n",
      "Fold: 20  Epoch: 401  Training loss = 2.5812  Validation loss = 1.0166  \n",
      "\n",
      "Fold: 20  Epoch: 402  Training loss = 2.5820  Validation loss = 1.0139  \n",
      "\n",
      "Fold: 20  Epoch: 403  Training loss = 2.5842  Validation loss = 1.0160  \n",
      "\n",
      "Fold: 20  Epoch: 404  Training loss = 2.5813  Validation loss = 1.0158  \n",
      "\n",
      "Fold: 20  Epoch: 405  Training loss = 2.5798  Validation loss = 1.0147  \n",
      "\n",
      "Fold: 20  Epoch: 406  Training loss = 2.5800  Validation loss = 1.0125  \n",
      "\n",
      "Fold: 20  Epoch: 407  Training loss = 2.5786  Validation loss = 1.0123  \n",
      "\n",
      "Fold: 20  Epoch: 408  Training loss = 2.5782  Validation loss = 1.0111  \n",
      "\n",
      "Fold: 20  Epoch: 409  Training loss = 2.5781  Validation loss = 1.0092  \n",
      "\n",
      "Fold: 20  Epoch: 410  Training loss = 2.5773  Validation loss = 1.0088  \n",
      "\n",
      "Fold: 20  Epoch: 411  Training loss = 2.5773  Validation loss = 1.0097  \n",
      "\n",
      "Fold: 20  Epoch: 412  Training loss = 2.5769  Validation loss = 1.0086  \n",
      "\n",
      "Fold: 20  Epoch: 413  Training loss = 2.5768  Validation loss = 1.0078  \n",
      "\n",
      "Fold: 20  Epoch: 414  Training loss = 2.5766  Validation loss = 1.0081  \n",
      "\n",
      "Fold: 20  Epoch: 415  Training loss = 2.5768  Validation loss = 1.0088  \n",
      "\n",
      "Fold: 20  Epoch: 416  Training loss = 2.5756  Validation loss = 1.0098  \n",
      "\n",
      "Fold: 20  Epoch: 417  Training loss = 2.5750  Validation loss = 1.0080  \n",
      "\n",
      "Fold: 20  Epoch: 418  Training loss = 2.5747  Validation loss = 1.0064  \n",
      "\n",
      "Fold: 20  Epoch: 419  Training loss = 2.5740  Validation loss = 1.0069  \n",
      "\n",
      "Fold: 20  Epoch: 420  Training loss = 2.5776  Validation loss = 1.0064  \n",
      "\n",
      "Fold: 20  Epoch: 421  Training loss = 2.5749  Validation loss = 1.0059  \n",
      "\n",
      "Fold: 20  Epoch: 422  Training loss = 2.5755  Validation loss = 1.0051  \n",
      "\n",
      "Fold: 20  Epoch: 423  Training loss = 2.5731  Validation loss = 1.0049  \n",
      "\n",
      "Fold: 20  Epoch: 424  Training loss = 2.5730  Validation loss = 1.0046  \n",
      "\n",
      "Fold: 20  Epoch: 425  Training loss = 2.5722  Validation loss = 1.0026  \n",
      "\n",
      "Fold: 20  Epoch: 426  Training loss = 2.5720  Validation loss = 1.0023  \n",
      "\n",
      "Fold: 20  Epoch: 427  Training loss = 2.5714  Validation loss = 0.9989  \n",
      "\n",
      "Fold: 20  Epoch: 428  Training loss = 2.5719  Validation loss = 0.9943  \n",
      "\n",
      "Fold: 20  Epoch: 429  Training loss = 2.5755  Validation loss = 0.9932  \n",
      "\n",
      "Fold: 20  Epoch: 430  Training loss = 2.5727  Validation loss = 0.9935  \n",
      "\n",
      "Fold: 20  Epoch: 431  Training loss = 2.5706  Validation loss = 0.9934  \n",
      "\n",
      "Fold: 20  Epoch: 432  Training loss = 2.5706  Validation loss = 0.9933  \n",
      "\n",
      "Fold: 20  Epoch: 433  Training loss = 2.5709  Validation loss = 0.9939  \n",
      "\n",
      "Fold: 20  Epoch: 434  Training loss = 2.5700  Validation loss = 0.9947  \n",
      "\n",
      "Fold: 20  Epoch: 435  Training loss = 2.5686  Validation loss = 0.9939  \n",
      "\n",
      "Fold: 20  Epoch: 436  Training loss = 2.5680  Validation loss = 0.9950  \n",
      "\n",
      "Fold: 20  Epoch: 437  Training loss = 2.5686  Validation loss = 0.9953  \n",
      "\n",
      "Fold: 20  Epoch: 438  Training loss = 2.5672  Validation loss = 0.9955  \n",
      "\n",
      "Fold: 20  Epoch: 439  Training loss = 2.5665  Validation loss = 0.9953  \n",
      "\n",
      "Fold: 20  Epoch: 440  Training loss = 2.5670  Validation loss = 0.9937  \n",
      "\n",
      "Fold: 20  Epoch: 441  Training loss = 2.5657  Validation loss = 0.9923  \n",
      "\n",
      "Fold: 20  Epoch: 442  Training loss = 2.5696  Validation loss = 0.9900  \n",
      "\n",
      "Fold: 20  Epoch: 443  Training loss = 2.5785  Validation loss = 0.9886  \n",
      "\n",
      "Fold: 20  Epoch: 444  Training loss = 2.5666  Validation loss = 0.9895  \n",
      "\n",
      "Fold: 20  Epoch: 445  Training loss = 2.5656  Validation loss = 0.9895  \n",
      "\n",
      "Fold: 20  Epoch: 446  Training loss = 2.5645  Validation loss = 0.9897  \n",
      "\n",
      "Fold: 20  Epoch: 447  Training loss = 2.5649  Validation loss = 0.9875  \n",
      "\n",
      "Fold: 20  Epoch: 448  Training loss = 2.5651  Validation loss = 0.9868  \n",
      "\n",
      "Fold: 20  Epoch: 449  Training loss = 2.5660  Validation loss = 0.9872  \n",
      "\n",
      "Fold: 20  Epoch: 450  Training loss = 2.5695  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 20  Epoch: 451  Training loss = 2.5645  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 20  Epoch: 452  Training loss = 2.5626  Validation loss = 0.9888  \n",
      "\n",
      "Fold: 20  Epoch: 453  Training loss = 2.5620  Validation loss = 0.9883  \n",
      "\n",
      "Fold: 20  Epoch: 454  Training loss = 2.5613  Validation loss = 0.9876  \n",
      "\n",
      "Fold: 20  Epoch: 455  Training loss = 2.5637  Validation loss = 0.9885  \n",
      "\n",
      "Fold: 20  Epoch: 456  Training loss = 2.5666  Validation loss = 0.9880  \n",
      "\n",
      "Fold: 20  Epoch: 457  Training loss = 2.5635  Validation loss = 0.9873  \n",
      "\n",
      "Fold: 20  Epoch: 458  Training loss = 2.5645  Validation loss = 0.9893  \n",
      "\n",
      "Fold: 20  Epoch: 459  Training loss = 2.5624  Validation loss = 0.9875  \n",
      "\n",
      "Fold: 20  Epoch: 460  Training loss = 2.5627  Validation loss = 0.9857  \n",
      "\n",
      "Fold: 20  Epoch: 461  Training loss = 2.5590  Validation loss = 0.9857  \n",
      "\n",
      "Fold: 20  Epoch: 462  Training loss = 2.5583  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 20  Epoch: 463  Training loss = 2.5582  Validation loss = 0.9831  \n",
      "\n",
      "Fold: 20  Epoch: 464  Training loss = 2.5574  Validation loss = 0.9837  \n",
      "\n",
      "Fold: 20  Epoch: 465  Training loss = 2.5570  Validation loss = 0.9823  \n",
      "\n",
      "Fold: 20  Epoch: 466  Training loss = 2.5571  Validation loss = 0.9841  \n",
      "\n",
      "Fold: 20  Epoch: 467  Training loss = 2.5573  Validation loss = 0.9827  \n",
      "\n",
      "Fold: 20  Epoch: 468  Training loss = 2.5567  Validation loss = 0.9829  \n",
      "\n",
      "Fold: 20  Epoch: 469  Training loss = 2.5575  Validation loss = 0.9826  \n",
      "\n",
      "Fold: 20  Epoch: 470  Training loss = 2.5577  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 471  Training loss = 2.5602  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 472  Training loss = 2.5550  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 20  Epoch: 473  Training loss = 2.5557  Validation loss = 0.9788  \n",
      "\n",
      "Fold: 20  Epoch: 474  Training loss = 2.5552  Validation loss = 0.9789  \n",
      "\n",
      "Fold: 20  Epoch: 475  Training loss = 2.5549  Validation loss = 0.9782  \n",
      "\n",
      "Fold: 20  Epoch: 476  Training loss = 2.5558  Validation loss = 0.9768  \n",
      "\n",
      "Fold: 20  Epoch: 477  Training loss = 2.5556  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 20  Epoch: 478  Training loss = 2.5529  Validation loss = 0.9764  \n",
      "\n",
      "Fold: 20  Epoch: 479  Training loss = 2.5540  Validation loss = 0.9761  \n",
      "\n",
      "Fold: 20  Epoch: 480  Training loss = 2.5554  Validation loss = 0.9762  \n",
      "\n",
      "Fold: 20  Epoch: 481  Training loss = 2.5536  Validation loss = 0.9743  \n",
      "\n",
      "Fold: 20  Epoch: 482  Training loss = 2.5555  Validation loss = 0.9719  \n",
      "\n",
      "Fold: 20  Epoch: 483  Training loss = 2.5527  Validation loss = 0.9750  \n",
      "\n",
      "Fold: 20  Epoch: 484  Training loss = 2.5532  Validation loss = 0.9743  \n",
      "\n",
      "Fold: 20  Epoch: 485  Training loss = 2.5526  Validation loss = 0.9719  \n",
      "\n",
      "Fold: 20  Epoch: 486  Training loss = 2.5524  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 20  Epoch: 487  Training loss = 2.5513  Validation loss = 0.9714  \n",
      "\n",
      "Fold: 20  Epoch: 488  Training loss = 2.5515  Validation loss = 0.9718  \n",
      "\n",
      "Fold: 20  Epoch: 489  Training loss = 2.5505  Validation loss = 0.9693  \n",
      "\n",
      "Fold: 20  Epoch: 490  Training loss = 2.5494  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 20  Epoch: 491  Training loss = 2.5492  Validation loss = 0.9674  \n",
      "\n",
      "Fold: 20  Epoch: 492  Training loss = 2.5499  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 493  Training loss = 2.5487  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 20  Epoch: 494  Training loss = 2.5496  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 20  Epoch: 495  Training loss = 2.5524  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 20  Epoch: 496  Training loss = 2.5501  Validation loss = 0.9628  \n",
      "\n",
      "Fold: 20  Epoch: 497  Training loss = 2.5479  Validation loss = 0.9608  \n",
      "\n",
      "Fold: 20  Epoch: 498  Training loss = 2.5460  Validation loss = 0.9602  \n",
      "\n",
      "Fold: 20  Epoch: 499  Training loss = 2.5464  Validation loss = 0.9593  \n",
      "\n",
      "Fold: 20  Epoch: 500  Training loss = 2.5466  Validation loss = 0.9593  \n",
      "\n",
      "Fold: 20  Epoch: 501  Training loss = 2.5448  Validation loss = 0.9597  \n",
      "\n",
      "Fold: 20  Epoch: 502  Training loss = 2.5444  Validation loss = 0.9588  \n",
      "\n",
      "Fold: 20  Epoch: 503  Training loss = 2.5443  Validation loss = 0.9608  \n",
      "\n",
      "Fold: 20  Epoch: 504  Training loss = 2.5448  Validation loss = 0.9602  \n",
      "\n",
      "Fold: 20  Epoch: 505  Training loss = 2.5456  Validation loss = 0.9597  \n",
      "\n",
      "Fold: 20  Epoch: 506  Training loss = 2.5429  Validation loss = 0.9628  \n",
      "\n",
      "Fold: 20  Epoch: 507  Training loss = 2.5433  Validation loss = 0.9616  \n",
      "\n",
      "Fold: 20  Epoch: 508  Training loss = 2.5417  Validation loss = 0.9608  \n",
      "\n",
      "Fold: 20  Epoch: 509  Training loss = 2.5414  Validation loss = 0.9593  \n",
      "\n",
      "Fold: 20  Epoch: 510  Training loss = 2.5419  Validation loss = 0.9581  \n",
      "\n",
      "Fold: 20  Epoch: 511  Training loss = 2.5413  Validation loss = 0.9574  \n",
      "\n",
      "Fold: 20  Epoch: 512  Training loss = 2.5407  Validation loss = 0.9555  \n",
      "\n",
      "Fold: 20  Epoch: 513  Training loss = 2.5424  Validation loss = 0.9558  \n",
      "\n",
      "Fold: 20  Epoch: 514  Training loss = 2.5410  Validation loss = 0.9569  \n",
      "\n",
      "Fold: 20  Epoch: 515  Training loss = 2.5400  Validation loss = 0.9570  \n",
      "\n",
      "Fold: 20  Epoch: 516  Training loss = 2.5397  Validation loss = 0.9580  \n",
      "\n",
      "Fold: 20  Epoch: 517  Training loss = 2.5393  Validation loss = 0.9568  \n",
      "\n",
      "Fold: 20  Epoch: 518  Training loss = 2.5389  Validation loss = 0.9574  \n",
      "\n",
      "Fold: 20  Epoch: 519  Training loss = 2.5388  Validation loss = 0.9580  \n",
      "\n",
      "Fold: 20  Epoch: 520  Training loss = 2.5386  Validation loss = 0.9567  \n",
      "\n",
      "Fold: 20  Epoch: 521  Training loss = 2.5386  Validation loss = 0.9577  \n",
      "\n",
      "Fold: 20  Epoch: 522  Training loss = 2.5447  Validation loss = 0.9581  \n",
      "\n",
      "Fold: 20  Epoch: 523  Training loss = 2.5403  Validation loss = 0.9592  \n",
      "\n",
      "Fold: 20  Epoch: 524  Training loss = 2.5397  Validation loss = 0.9549  \n",
      "\n",
      "Fold: 20  Epoch: 525  Training loss = 2.5381  Validation loss = 0.9547  \n",
      "\n",
      "Fold: 20  Epoch: 526  Training loss = 2.5372  Validation loss = 0.9531  \n",
      "\n",
      "Fold: 20  Epoch: 527  Training loss = 2.5382  Validation loss = 0.9555  \n",
      "\n",
      "Fold: 20  Epoch: 528  Training loss = 2.5371  Validation loss = 0.9542  \n",
      "\n",
      "Fold: 20  Epoch: 529  Training loss = 2.5364  Validation loss = 0.9550  \n",
      "\n",
      "Fold: 20  Epoch: 530  Training loss = 2.5359  Validation loss = 0.9543  \n",
      "\n",
      "Fold: 20  Epoch: 531  Training loss = 2.5357  Validation loss = 0.9526  \n",
      "\n",
      "Fold: 20  Epoch: 532  Training loss = 2.5355  Validation loss = 0.9538  \n",
      "\n",
      "Fold: 20  Epoch: 533  Training loss = 2.5360  Validation loss = 0.9545  \n",
      "\n",
      "Fold: 20  Epoch: 534  Training loss = 2.5341  Validation loss = 0.9547  \n",
      "\n",
      "Fold: 20  Epoch: 535  Training loss = 2.5346  Validation loss = 0.9552  \n",
      "\n",
      "Fold: 20  Epoch: 536  Training loss = 2.5340  Validation loss = 0.9544  \n",
      "\n",
      "Fold: 20  Epoch: 537  Training loss = 2.5331  Validation loss = 0.9524  \n",
      "\n",
      "Fold: 20  Epoch: 538  Training loss = 2.5334  Validation loss = 0.9528  \n",
      "\n",
      "Fold: 20  Epoch: 539  Training loss = 2.5330  Validation loss = 0.9527  \n",
      "\n",
      "Fold: 20  Epoch: 540  Training loss = 2.5319  Validation loss = 0.9512  \n",
      "\n",
      "Fold: 20  Epoch: 541  Training loss = 2.5315  Validation loss = 0.9527  \n",
      "\n",
      "Fold: 20  Epoch: 542  Training loss = 2.5311  Validation loss = 0.9521  \n",
      "\n",
      "Fold: 20  Epoch: 543  Training loss = 2.5309  Validation loss = 0.9510  \n",
      "\n",
      "Fold: 20  Epoch: 544  Training loss = 2.5302  Validation loss = 0.9509  \n",
      "\n",
      "Fold: 20  Epoch: 545  Training loss = 2.5313  Validation loss = 0.9492  \n",
      "\n",
      "Fold: 20  Epoch: 546  Training loss = 2.5305  Validation loss = 0.9479  \n",
      "\n",
      "Fold: 20  Epoch: 547  Training loss = 2.5316  Validation loss = 0.9474  \n",
      "\n",
      "Fold: 20  Epoch: 548  Training loss = 2.5290  Validation loss = 0.9489  \n",
      "\n",
      "Fold: 20  Epoch: 549  Training loss = 2.5287  Validation loss = 0.9476  \n",
      "\n",
      "Fold: 20  Epoch: 550  Training loss = 2.5289  Validation loss = 0.9446  \n",
      "\n",
      "Fold: 20  Epoch: 551  Training loss = 2.5287  Validation loss = 0.9479  \n",
      "\n",
      "Fold: 20  Epoch: 552  Training loss = 2.5287  Validation loss = 0.9481  \n",
      "\n",
      "Fold: 20  Epoch: 553  Training loss = 2.5286  Validation loss = 0.9484  \n",
      "\n",
      "Fold: 20  Epoch: 554  Training loss = 2.5279  Validation loss = 0.9474  \n",
      "\n",
      "Fold: 20  Epoch: 555  Training loss = 2.5273  Validation loss = 0.9467  \n",
      "\n",
      "Fold: 20  Epoch: 556  Training loss = 2.5272  Validation loss = 0.9464  \n",
      "\n",
      "Fold: 20  Epoch: 557  Training loss = 2.5269  Validation loss = 0.9483  \n",
      "\n",
      "Fold: 20  Epoch: 558  Training loss = 2.5259  Validation loss = 0.9479  \n",
      "\n",
      "Fold: 20  Epoch: 559  Training loss = 2.5262  Validation loss = 0.9504  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 550  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.5054  Validation loss = 3.9216  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.5057  Validation loss = 3.9348  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.5049  Validation loss = 3.9154  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.5044  Validation loss = 3.9052  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.5038  Validation loss = 3.8996  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.5034  Validation loss = 3.9095  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.5046  Validation loss = 3.9626  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.5033  Validation loss = 3.9383  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.5027  Validation loss = 3.9300  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.5018  Validation loss = 3.8920  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.5022  Validation loss = 3.8715  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.5024  Validation loss = 3.8689  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 2.5035  Validation loss = 3.8578  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 2.5012  Validation loss = 3.8966  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 2.5002  Validation loss = 3.9102  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 2.4998  Validation loss = 3.8873  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 2.4990  Validation loss = 3.9238  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 2.5009  Validation loss = 3.8858  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 2.4989  Validation loss = 3.9249  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 2.4988  Validation loss = 3.8819  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 2.4992  Validation loss = 3.8646  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 2.4992  Validation loss = 3.8759  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 2.4980  Validation loss = 3.8927  \n",
      "\n",
      "Fold: 21  Epoch: 24  Training loss = 2.4974  Validation loss = 3.8867  \n",
      "\n",
      "Fold: 21  Epoch: 25  Training loss = 2.4974  Validation loss = 3.8614  \n",
      "\n",
      "Fold: 21  Epoch: 26  Training loss = 2.4970  Validation loss = 3.9454  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 13  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.5837  Validation loss = 2.9722  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.5848  Validation loss = 3.0033  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.5812  Validation loss = 2.9487  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.5796  Validation loss = 2.9235  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.5782  Validation loss = 2.8635  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.5799  Validation loss = 2.9922  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 2.5783  Validation loss = 2.9588  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.5808  Validation loss = 3.0289  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.5753  Validation loss = 2.8809  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.6211  Validation loss = 3.0617  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.6110  Validation loss = 3.0140  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.6042  Validation loss = 2.9398  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.6016  Validation loss = 2.9003  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 2.5945  Validation loss = 2.8071  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 2.5893  Validation loss = 2.7485  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 2.5839  Validation loss = 2.6041  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 2.5844  Validation loss = 2.6710  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 2.5812  Validation loss = 2.6292  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 2.5731  Validation loss = 2.5424  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 2.5666  Validation loss = 2.4752  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 2.5597  Validation loss = 2.3156  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 2.5581  Validation loss = 2.3775  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 2.5567  Validation loss = 2.3933  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 2.5544  Validation loss = 2.1709  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 2.5540  Validation loss = 2.2002  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 2.5540  Validation loss = 2.1683  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 2.5518  Validation loss = 2.4164  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 2.5508  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 2.5490  Validation loss = 2.5540  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 2.5521  Validation loss = 2.6729  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 26  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.5898  Validation loss = 2.1451  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.5628  Validation loss = 1.7419  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.5588  Validation loss = 1.6057  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.5583  Validation loss = 1.6648  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.5530  Validation loss = 1.5814  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.5504  Validation loss = 1.5719  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.5495  Validation loss = 1.4680  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.5484  Validation loss = 1.4544  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.5458  Validation loss = 1.5319  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.5426  Validation loss = 1.4823  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.5410  Validation loss = 1.4483  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.5391  Validation loss = 1.5361  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.5377  Validation loss = 1.5756  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 2.5379  Validation loss = 1.6319  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 2.5382  Validation loss = 1.6514  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 2.5366  Validation loss = 1.6628  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 2.5393  Validation loss = 1.7171  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 11  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.5450  Validation loss = 1.2776  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.5371  Validation loss = 1.2809  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.5313  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.5293  Validation loss = 1.2836  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.5350  Validation loss = 1.2631  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.5266  Validation loss = 1.2677  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.5245  Validation loss = 1.2582  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.5236  Validation loss = 1.2648  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.5230  Validation loss = 1.2586  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.5223  Validation loss = 1.2437  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.5213  Validation loss = 1.2358  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.5189  Validation loss = 1.2562  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.5175  Validation loss = 1.2608  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.5197  Validation loss = 1.2365  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.5190  Validation loss = 1.2303  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.5207  Validation loss = 1.2227  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.5268  Validation loss = 1.2058  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.5238  Validation loss = 1.2142  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.5162  Validation loss = 1.2114  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.5481  Validation loss = 1.2258  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.5432  Validation loss = 1.1988  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.5355  Validation loss = 1.2276  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 2.5284  Validation loss = 1.2497  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 2.5294  Validation loss = 1.2241  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 2.5246  Validation loss = 1.2627  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 21  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.4743  Validation loss = 2.5771  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.4766  Validation loss = 2.5960  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.4793  Validation loss = 2.6209  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.4702  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.4672  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.4651  Validation loss = 2.5255  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.4632  Validation loss = 2.5215  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.4622  Validation loss = 2.5652  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.4604  Validation loss = 2.5023  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.4587  Validation loss = 2.4953  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.4577  Validation loss = 2.5109  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.4560  Validation loss = 2.5160  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.4554  Validation loss = 2.5034  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.4542  Validation loss = 2.5193  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.4924  Validation loss = 2.4856  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.4543  Validation loss = 2.5096  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 2.4532  Validation loss = 2.5087  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 2.4657  Validation loss = 2.6146  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 15  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.4535  Validation loss = 3.5669  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.4612  Validation loss = 3.2688  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.4446  Validation loss = 3.5116  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.4430  Validation loss = 3.4971  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.4434  Validation loss = 3.4740  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.4440  Validation loss = 3.5705  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.4442  Validation loss = 3.3450  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.4407  Validation loss = 3.3424  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.4460  Validation loss = 3.5874  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.4453  Validation loss = 3.5886  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.4410  Validation loss = 3.4921  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.4387  Validation loss = 3.4414  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.4379  Validation loss = 3.5165  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.4367  Validation loss = 3.4548  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.4383  Validation loss = 3.5272  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 2.4347  Validation loss = 3.4268  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 2.4397  Validation loss = 3.5351  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 2.4422  Validation loss = 3.6141  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 2  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.5146  Validation loss = 0.5640  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.4924  Validation loss = 0.5391  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.6033  Validation loss = 0.4944  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.4879  Validation loss = 0.5361  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.4850  Validation loss = 0.5356  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.4678  Validation loss = 0.5216  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.4836  Validation loss = 0.5011  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.4651  Validation loss = 0.5024  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.4488  Validation loss = 0.5190  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.4324  Validation loss = 0.5144  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.4261  Validation loss = 0.5021  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.4291  Validation loss = 0.5069  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.4268  Validation loss = 0.4966  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.4273  Validation loss = 0.4949  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.4717  Validation loss = 0.4799  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.4326  Validation loss = 0.4879  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.4197  Validation loss = 0.4995  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.4375  Validation loss = 0.4897  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.4167  Validation loss = 0.4881  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.4218  Validation loss = 0.4925  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 2.4209  Validation loss = 0.4920  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 2.4221  Validation loss = 0.4844  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 2.4214  Validation loss = 0.4935  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 2.4279  Validation loss = 0.4753  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 2.4155  Validation loss = 0.4858  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 2.4158  Validation loss = 0.4780  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 2.4463  Validation loss = 0.4643  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 2.4105  Validation loss = 0.4797  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 2.4175  Validation loss = 0.4830  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 2.4138  Validation loss = 0.4679  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 2.4165  Validation loss = 0.4748  \n",
      "\n",
      "Fold: 27  Epoch: 32  Training loss = 2.4272  Validation loss = 0.4635  \n",
      "\n",
      "Fold: 27  Epoch: 33  Training loss = 2.4115  Validation loss = 0.4736  \n",
      "\n",
      "Fold: 27  Epoch: 34  Training loss = 2.4191  Validation loss = 0.4625  \n",
      "\n",
      "Fold: 27  Epoch: 35  Training loss = 2.4085  Validation loss = 0.4742  \n",
      "\n",
      "Fold: 27  Epoch: 36  Training loss = 2.4565  Validation loss = 0.4547  \n",
      "\n",
      "Fold: 27  Epoch: 37  Training loss = 2.4061  Validation loss = 0.4706  \n",
      "\n",
      "Fold: 27  Epoch: 38  Training loss = 2.4199  Validation loss = 0.4734  \n",
      "\n",
      "Fold: 27  Epoch: 39  Training loss = 2.4070  Validation loss = 0.4647  \n",
      "\n",
      "Fold: 27  Epoch: 40  Training loss = 2.4106  Validation loss = 0.4660  \n",
      "\n",
      "Fold: 27  Epoch: 41  Training loss = 2.4032  Validation loss = 0.4586  \n",
      "\n",
      "Fold: 27  Epoch: 42  Training loss = 2.4148  Validation loss = 0.4662  \n",
      "\n",
      "Fold: 27  Epoch: 43  Training loss = 2.4110  Validation loss = 0.4656  \n",
      "\n",
      "Fold: 27  Epoch: 44  Training loss = 2.4047  Validation loss = 0.4550  \n",
      "\n",
      "Fold: 27  Epoch: 45  Training loss = 2.4148  Validation loss = 0.4635  \n",
      "\n",
      "Fold: 27  Epoch: 46  Training loss = 2.4137  Validation loss = 0.4615  \n",
      "\n",
      "Fold: 27  Epoch: 47  Training loss = 2.3984  Validation loss = 0.4481  \n",
      "\n",
      "Fold: 27  Epoch: 48  Training loss = 2.4000  Validation loss = 0.4536  \n",
      "\n",
      "Fold: 27  Epoch: 49  Training loss = 2.4452  Validation loss = 0.4689  \n",
      "\n",
      "Fold: 27  Epoch: 50  Training loss = 2.4037  Validation loss = 0.4569  \n",
      "\n",
      "Fold: 27  Epoch: 51  Training loss = 2.4021  Validation loss = 0.4564  \n",
      "\n",
      "Fold: 27  Epoch: 52  Training loss = 2.3975  Validation loss = 0.4526  \n",
      "\n",
      "Fold: 27  Epoch: 53  Training loss = 2.4177  Validation loss = 0.4602  \n",
      "\n",
      "Fold: 27  Epoch: 54  Training loss = 2.3941  Validation loss = 0.4461  \n",
      "\n",
      "Fold: 27  Epoch: 55  Training loss = 2.3992  Validation loss = 0.4310  \n",
      "\n",
      "Fold: 27  Epoch: 56  Training loss = 2.4044  Validation loss = 0.4466  \n",
      "\n",
      "Fold: 27  Epoch: 57  Training loss = 2.3984  Validation loss = 0.4273  \n",
      "\n",
      "Fold: 27  Epoch: 58  Training loss = 2.3976  Validation loss = 0.4374  \n",
      "\n",
      "Fold: 27  Epoch: 59  Training loss = 2.3929  Validation loss = 0.4279  \n",
      "\n",
      "Fold: 27  Epoch: 60  Training loss = 2.4074  Validation loss = 0.4465  \n",
      "\n",
      "Fold: 27  Epoch: 61  Training loss = 2.3943  Validation loss = 0.4278  \n",
      "\n",
      "Fold: 27  Epoch: 62  Training loss = 2.3912  Validation loss = 0.4277  \n",
      "\n",
      "Fold: 27  Epoch: 63  Training loss = 2.3927  Validation loss = 0.4300  \n",
      "\n",
      "Fold: 27  Epoch: 64  Training loss = 2.3853  Validation loss = 0.4297  \n",
      "\n",
      "Fold: 27  Epoch: 65  Training loss = 2.3934  Validation loss = 0.4185  \n",
      "\n",
      "Fold: 27  Epoch: 66  Training loss = 2.4283  Validation loss = 0.4505  \n",
      "\n",
      "Fold: 27  Epoch: 67  Training loss = 2.3926  Validation loss = 0.4246  \n",
      "\n",
      "Fold: 27  Epoch: 68  Training loss = 2.4068  Validation loss = 0.4369  \n",
      "\n",
      "Fold: 27  Epoch: 69  Training loss = 2.4254  Validation loss = 0.4117  \n",
      "\n",
      "Fold: 27  Epoch: 70  Training loss = 2.3896  Validation loss = 0.4168  \n",
      "\n",
      "Fold: 27  Epoch: 71  Training loss = 2.3986  Validation loss = 0.4323  \n",
      "\n",
      "Fold: 27  Epoch: 72  Training loss = 2.4291  Validation loss = 0.4043  \n",
      "\n",
      "Fold: 27  Epoch: 73  Training loss = 2.3982  Validation loss = 0.4088  \n",
      "\n",
      "Fold: 27  Epoch: 74  Training loss = 2.3874  Validation loss = 0.4238  \n",
      "\n",
      "Fold: 27  Epoch: 75  Training loss = 2.4046  Validation loss = 0.4313  \n",
      "\n",
      "Fold: 27  Epoch: 76  Training loss = 2.3781  Validation loss = 0.4178  \n",
      "\n",
      "Fold: 27  Epoch: 77  Training loss = 2.3772  Validation loss = 0.4141  \n",
      "\n",
      "Fold: 27  Epoch: 78  Training loss = 2.3882  Validation loss = 0.4236  \n",
      "\n",
      "Fold: 27  Epoch: 79  Training loss = 2.3871  Validation loss = 0.4203  \n",
      "\n",
      "Fold: 27  Epoch: 80  Training loss = 2.3749  Validation loss = 0.4119  \n",
      "\n",
      "Fold: 27  Epoch: 81  Training loss = 2.3757  Validation loss = 0.4136  \n",
      "\n",
      "Fold: 27  Epoch: 82  Training loss = 2.3764  Validation loss = 0.4088  \n",
      "\n",
      "Fold: 27  Epoch: 83  Training loss = 2.4127  Validation loss = 0.4285  \n",
      "\n",
      "Fold: 27  Epoch: 84  Training loss = 2.3764  Validation loss = 0.4020  \n",
      "\n",
      "Fold: 27  Epoch: 85  Training loss = 2.3816  Validation loss = 0.3980  \n",
      "\n",
      "Fold: 27  Epoch: 86  Training loss = 2.3834  Validation loss = 0.4133  \n",
      "\n",
      "Fold: 27  Epoch: 87  Training loss = 2.4070  Validation loss = 0.3885  \n",
      "\n",
      "Fold: 27  Epoch: 88  Training loss = 2.3920  Validation loss = 0.3933  \n",
      "\n",
      "Fold: 27  Epoch: 89  Training loss = 2.3894  Validation loss = 0.3953  \n",
      "\n",
      "Fold: 27  Epoch: 90  Training loss = 2.3870  Validation loss = 0.4154  \n",
      "\n",
      "Fold: 27  Epoch: 91  Training loss = 2.3774  Validation loss = 0.3985  \n",
      "\n",
      "Fold: 27  Epoch: 92  Training loss = 2.3696  Validation loss = 0.4053  \n",
      "\n",
      "Fold: 27  Epoch: 93  Training loss = 2.3713  Validation loss = 0.3995  \n",
      "\n",
      "Fold: 27  Epoch: 94  Training loss = 2.3701  Validation loss = 0.4027  \n",
      "\n",
      "Fold: 27  Epoch: 95  Training loss = 2.3726  Validation loss = 0.4060  \n",
      "\n",
      "Fold: 27  Epoch: 96  Training loss = 2.3673  Validation loss = 0.3970  \n",
      "\n",
      "Fold: 27  Epoch: 97  Training loss = 2.3841  Validation loss = 0.3872  \n",
      "\n",
      "Fold: 27  Epoch: 98  Training loss = 2.3802  Validation loss = 0.3903  \n",
      "\n",
      "Fold: 27  Epoch: 99  Training loss = 2.3738  Validation loss = 0.4028  \n",
      "\n",
      "Fold: 27  Epoch: 100  Training loss = 2.3814  Validation loss = 0.4037  \n",
      "\n",
      "Fold: 27  Epoch: 101  Training loss = 2.3648  Validation loss = 0.3951  \n",
      "\n",
      "Fold: 27  Epoch: 102  Training loss = 2.3940  Validation loss = 0.3818  \n",
      "\n",
      "Fold: 27  Epoch: 103  Training loss = 2.3681  Validation loss = 0.3986  \n",
      "\n",
      "Fold: 27  Epoch: 104  Training loss = 2.3757  Validation loss = 0.3830  \n",
      "\n",
      "Fold: 27  Epoch: 105  Training loss = 2.3789  Validation loss = 0.3941  \n",
      "\n",
      "Fold: 27  Epoch: 106  Training loss = 2.3708  Validation loss = 0.3817  \n",
      "\n",
      "Fold: 27  Epoch: 107  Training loss = 2.3693  Validation loss = 0.3825  \n",
      "\n",
      "Fold: 27  Epoch: 108  Training loss = 2.3693  Validation loss = 0.3793  \n",
      "\n",
      "Fold: 27  Epoch: 109  Training loss = 2.3607  Validation loss = 0.3877  \n",
      "\n",
      "Fold: 27  Epoch: 110  Training loss = 2.3881  Validation loss = 0.3971  \n",
      "\n",
      "Fold: 27  Epoch: 111  Training loss = 2.3623  Validation loss = 0.3780  \n",
      "\n",
      "Fold: 27  Epoch: 112  Training loss = 2.3586  Validation loss = 0.3825  \n",
      "\n",
      "Fold: 27  Epoch: 113  Training loss = 2.3586  Validation loss = 0.3806  \n",
      "\n",
      "Fold: 27  Epoch: 114  Training loss = 2.3725  Validation loss = 0.3673  \n",
      "\n",
      "Fold: 27  Epoch: 115  Training loss = 2.3626  Validation loss = 0.3734  \n",
      "\n",
      "Fold: 27  Epoch: 116  Training loss = 2.3741  Validation loss = 0.3633  \n",
      "\n",
      "Fold: 27  Epoch: 117  Training loss = 2.3587  Validation loss = 0.3718  \n",
      "\n",
      "Fold: 27  Epoch: 118  Training loss = 2.3609  Validation loss = 0.3687  \n",
      "\n",
      "Fold: 27  Epoch: 119  Training loss = 2.3709  Validation loss = 0.3624  \n",
      "\n",
      "Fold: 27  Epoch: 120  Training loss = 2.3556  Validation loss = 0.3684  \n",
      "\n",
      "Fold: 27  Epoch: 121  Training loss = 2.3548  Validation loss = 0.3685  \n",
      "\n",
      "Fold: 27  Epoch: 122  Training loss = 2.3587  Validation loss = 0.3638  \n",
      "\n",
      "Fold: 27  Epoch: 123  Training loss = 2.3681  Validation loss = 0.3753  \n",
      "\n",
      "Fold: 27  Epoch: 124  Training loss = 2.3597  Validation loss = 0.3612  \n",
      "\n",
      "Fold: 27  Epoch: 125  Training loss = 2.3885  Validation loss = 0.3522  \n",
      "\n",
      "Fold: 27  Epoch: 126  Training loss = 2.3662  Validation loss = 0.3753  \n",
      "\n",
      "Fold: 27  Epoch: 127  Training loss = 2.3903  Validation loss = 0.3514  \n",
      "\n",
      "Fold: 27  Epoch: 128  Training loss = 2.3652  Validation loss = 0.3713  \n",
      "\n",
      "Fold: 27  Epoch: 129  Training loss = 2.3519  Validation loss = 0.3648  \n",
      "\n",
      "Fold: 27  Epoch: 130  Training loss = 2.4000  Validation loss = 0.3560  \n",
      "\n",
      "Fold: 27  Epoch: 131  Training loss = 2.3515  Validation loss = 0.3666  \n",
      "\n",
      "Fold: 27  Epoch: 132  Training loss = 2.3626  Validation loss = 0.3590  \n",
      "\n",
      "Fold: 27  Epoch: 133  Training loss = 2.3525  Validation loss = 0.3646  \n",
      "\n",
      "Fold: 27  Epoch: 134  Training loss = 2.3513  Validation loss = 0.3702  \n",
      "\n",
      "Fold: 27  Epoch: 135  Training loss = 2.3557  Validation loss = 0.3643  \n",
      "\n",
      "Fold: 27  Epoch: 136  Training loss = 2.3686  Validation loss = 0.3527  \n",
      "\n",
      "Fold: 27  Epoch: 137  Training loss = 2.3671  Validation loss = 0.3714  \n",
      "\n",
      "Fold: 27  Epoch: 138  Training loss = 2.3532  Validation loss = 0.3613  \n",
      "\n",
      "Fold: 27  Epoch: 139  Training loss = 2.3599  Validation loss = 0.3699  \n",
      "\n",
      "Fold: 27  Epoch: 140  Training loss = 2.3527  Validation loss = 0.3593  \n",
      "\n",
      "Fold: 27  Epoch: 141  Training loss = 2.3657  Validation loss = 0.3784  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 127  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.3406  Validation loss = 1.1379  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.3312  Validation loss = 1.1344  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.3377  Validation loss = 1.1292  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.3328  Validation loss = 1.1328  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.3397  Validation loss = 1.1334  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.3502  Validation loss = 1.1360  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.3286  Validation loss = 1.1306  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.3375  Validation loss = 1.1259  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.3339  Validation loss = 1.1258  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.3363  Validation loss = 1.1219  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.3286  Validation loss = 1.1223  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.3223  Validation loss = 1.1231  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.3289  Validation loss = 1.1212  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.3259  Validation loss = 1.1217  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.3218  Validation loss = 1.1172  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.3342  Validation loss = 1.1179  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 2.3210  Validation loss = 1.1146  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 2.3225  Validation loss = 1.1137  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 2.3548  Validation loss = 1.1075  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 2.3303  Validation loss = 1.1129  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 2.3296  Validation loss = 1.1073  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 2.3320  Validation loss = 1.1054  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 2.3350  Validation loss = 1.1044  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 2.3284  Validation loss = 1.1050  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 2.3239  Validation loss = 1.1070  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 2.3419  Validation loss = 1.1069  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 2.3350  Validation loss = 1.1004  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 2.3261  Validation loss = 1.1048  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 2.3248  Validation loss = 1.1045  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 2.3174  Validation loss = 1.1019  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 2.3184  Validation loss = 1.1017  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 2.3418  Validation loss = 1.1085  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 2.3408  Validation loss = 1.1064  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 2.3347  Validation loss = 1.1027  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 2.3165  Validation loss = 1.0998  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 2.3137  Validation loss = 1.1013  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 2.3166  Validation loss = 1.1016  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 2.3157  Validation loss = 1.1019  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 2.3135  Validation loss = 1.0986  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 2.3119  Validation loss = 1.0955  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 2.3122  Validation loss = 1.0973  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 2.3187  Validation loss = 1.0978  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 2.3171  Validation loss = 1.0936  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 2.3170  Validation loss = 1.0931  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 2.3102  Validation loss = 1.0918  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 2.3119  Validation loss = 1.0932  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 2.3111  Validation loss = 1.0894  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 2.3117  Validation loss = 1.0913  \n",
      "\n",
      "Fold: 28  Epoch: 49  Training loss = 2.3264  Validation loss = 1.0913  \n",
      "\n",
      "Fold: 28  Epoch: 50  Training loss = 2.3120  Validation loss = 1.0900  \n",
      "\n",
      "Fold: 28  Epoch: 51  Training loss = 2.3077  Validation loss = 1.0907  \n",
      "\n",
      "Fold: 28  Epoch: 52  Training loss = 2.3221  Validation loss = 1.0876  \n",
      "\n",
      "Fold: 28  Epoch: 53  Training loss = 2.3257  Validation loss = 1.0904  \n",
      "\n",
      "Fold: 28  Epoch: 54  Training loss = 2.3058  Validation loss = 1.0863  \n",
      "\n",
      "Fold: 28  Epoch: 55  Training loss = 2.3216  Validation loss = 1.0813  \n",
      "\n",
      "Fold: 28  Epoch: 56  Training loss = 2.3058  Validation loss = 1.0836  \n",
      "\n",
      "Fold: 28  Epoch: 57  Training loss = 2.3054  Validation loss = 1.0798  \n",
      "\n",
      "Fold: 28  Epoch: 58  Training loss = 2.3230  Validation loss = 1.0765  \n",
      "\n",
      "Fold: 28  Epoch: 59  Training loss = 2.3275  Validation loss = 1.0780  \n",
      "\n",
      "Fold: 28  Epoch: 60  Training loss = 2.3115  Validation loss = 1.0793  \n",
      "\n",
      "Fold: 28  Epoch: 61  Training loss = 2.3093  Validation loss = 1.0811  \n",
      "\n",
      "Fold: 28  Epoch: 62  Training loss = 2.3129  Validation loss = 1.0714  \n",
      "\n",
      "Fold: 28  Epoch: 63  Training loss = 2.3108  Validation loss = 1.0717  \n",
      "\n",
      "Fold: 28  Epoch: 64  Training loss = 2.3032  Validation loss = 1.0674  \n",
      "\n",
      "Fold: 28  Epoch: 65  Training loss = 2.3052  Validation loss = 1.0666  \n",
      "\n",
      "Fold: 28  Epoch: 66  Training loss = 2.3167  Validation loss = 1.0698  \n",
      "\n",
      "Fold: 28  Epoch: 67  Training loss = 2.3119  Validation loss = 1.0670  \n",
      "\n",
      "Fold: 28  Epoch: 68  Training loss = 2.3201  Validation loss = 1.0705  \n",
      "\n",
      "Fold: 28  Epoch: 69  Training loss = 2.3188  Validation loss = 1.0694  \n",
      "\n",
      "Fold: 28  Epoch: 70  Training loss = 2.3054  Validation loss = 1.0658  \n",
      "\n",
      "Fold: 28  Epoch: 71  Training loss = 2.3042  Validation loss = 1.0615  \n",
      "\n",
      "Fold: 28  Epoch: 72  Training loss = 2.3013  Validation loss = 1.0586  \n",
      "\n",
      "Fold: 28  Epoch: 73  Training loss = 2.3037  Validation loss = 1.0582  \n",
      "\n",
      "Fold: 28  Epoch: 74  Training loss = 2.2982  Validation loss = 1.0565  \n",
      "\n",
      "Fold: 28  Epoch: 75  Training loss = 2.3204  Validation loss = 1.0470  \n",
      "\n",
      "Fold: 28  Epoch: 76  Training loss = 2.3094  Validation loss = 1.0526  \n",
      "\n",
      "Fold: 28  Epoch: 77  Training loss = 2.3264  Validation loss = 1.0525  \n",
      "\n",
      "Fold: 28  Epoch: 78  Training loss = 2.2988  Validation loss = 1.0497  \n",
      "\n",
      "Fold: 28  Epoch: 79  Training loss = 2.3143  Validation loss = 1.0517  \n",
      "\n",
      "Fold: 28  Epoch: 80  Training loss = 2.3087  Validation loss = 1.0486  \n",
      "\n",
      "Fold: 28  Epoch: 81  Training loss = 2.3086  Validation loss = 1.0477  \n",
      "\n",
      "Fold: 28  Epoch: 82  Training loss = 2.3074  Validation loss = 1.0459  \n",
      "\n",
      "Fold: 28  Epoch: 83  Training loss = 2.2949  Validation loss = 1.0434  \n",
      "\n",
      "Fold: 28  Epoch: 84  Training loss = 2.3403  Validation loss = 1.0471  \n",
      "\n",
      "Fold: 28  Epoch: 85  Training loss = 2.2958  Validation loss = 1.0413  \n",
      "\n",
      "Fold: 28  Epoch: 86  Training loss = 2.3005  Validation loss = 1.0382  \n",
      "\n",
      "Fold: 28  Epoch: 87  Training loss = 2.2945  Validation loss = 1.0370  \n",
      "\n",
      "Fold: 28  Epoch: 88  Training loss = 2.2938  Validation loss = 1.0377  \n",
      "\n",
      "Fold: 28  Epoch: 89  Training loss = 2.2926  Validation loss = 1.0387  \n",
      "\n",
      "Fold: 28  Epoch: 90  Training loss = 2.2937  Validation loss = 1.0386  \n",
      "\n",
      "Fold: 28  Epoch: 91  Training loss = 2.2951  Validation loss = 1.0353  \n",
      "\n",
      "Fold: 28  Epoch: 92  Training loss = 2.2928  Validation loss = 1.0368  \n",
      "\n",
      "Fold: 28  Epoch: 93  Training loss = 2.2932  Validation loss = 1.0388  \n",
      "\n",
      "Fold: 28  Epoch: 94  Training loss = 2.2909  Validation loss = 1.0393  \n",
      "\n",
      "Fold: 28  Epoch: 95  Training loss = 2.3117  Validation loss = 1.0348  \n",
      "\n",
      "Fold: 28  Epoch: 96  Training loss = 2.2936  Validation loss = 1.0363  \n",
      "\n",
      "Fold: 28  Epoch: 97  Training loss = 2.3020  Validation loss = 1.0395  \n",
      "\n",
      "Fold: 28  Epoch: 98  Training loss = 2.2929  Validation loss = 1.0338  \n",
      "\n",
      "Fold: 28  Epoch: 99  Training loss = 2.3122  Validation loss = 1.0365  \n",
      "\n",
      "Fold: 28  Epoch: 100  Training loss = 2.2914  Validation loss = 1.0349  \n",
      "\n",
      "Fold: 28  Epoch: 101  Training loss = 2.2881  Validation loss = 1.0349  \n",
      "\n",
      "Fold: 28  Epoch: 102  Training loss = 2.2931  Validation loss = 1.0341  \n",
      "\n",
      "Fold: 28  Epoch: 103  Training loss = 2.2977  Validation loss = 1.0363  \n",
      "\n",
      "Fold: 28  Epoch: 104  Training loss = 2.2903  Validation loss = 1.0353  \n",
      "\n",
      "Fold: 28  Epoch: 105  Training loss = 2.2950  Validation loss = 1.0387  \n",
      "\n",
      "Fold: 28  Epoch: 106  Training loss = 2.2931  Validation loss = 1.0364  \n",
      "\n",
      "Fold: 28  Epoch: 107  Training loss = 2.2904  Validation loss = 1.0365  \n",
      "\n",
      "Fold: 28  Epoch: 108  Training loss = 2.3228  Validation loss = 1.0416  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 98  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.2618  Validation loss = 1.1321  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.2542  Validation loss = 1.1291  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.2527  Validation loss = 1.1284  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.2578  Validation loss = 1.1287  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.2514  Validation loss = 1.1244  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.2534  Validation loss = 1.1258  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.2507  Validation loss = 1.1239  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.2565  Validation loss = 1.1264  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.2545  Validation loss = 1.1255  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.2488  Validation loss = 1.1274  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.2510  Validation loss = 1.1256  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.2502  Validation loss = 1.1237  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.2547  Validation loss = 1.1248  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.2512  Validation loss = 1.1264  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.2504  Validation loss = 1.1241  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.2645  Validation loss = 1.1226  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 2.2445  Validation loss = 1.1180  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 2.2468  Validation loss = 1.1213  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 2.2448  Validation loss = 1.1222  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.2445  Validation loss = 1.1180  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 2.2430  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 2.2414  Validation loss = 1.1196  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 2.2443  Validation loss = 1.1182  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 2.2523  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 2.2421  Validation loss = 1.1195  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 2.2383  Validation loss = 1.1204  \n",
      "\n",
      "Fold: 29  Epoch: 27  Training loss = 2.2376  Validation loss = 1.1186  \n",
      "\n",
      "Fold: 29  Epoch: 28  Training loss = 2.2391  Validation loss = 1.1182  \n",
      "\n",
      "Fold: 29  Epoch: 29  Training loss = 2.2367  Validation loss = 1.1175  \n",
      "\n",
      "Fold: 29  Epoch: 30  Training loss = 2.2367  Validation loss = 1.1166  \n",
      "\n",
      "Fold: 29  Epoch: 31  Training loss = 2.2363  Validation loss = 1.1140  \n",
      "\n",
      "Fold: 29  Epoch: 32  Training loss = 2.2471  Validation loss = 1.1107  \n",
      "\n",
      "Fold: 29  Epoch: 33  Training loss = 2.2352  Validation loss = 1.1103  \n",
      "\n",
      "Fold: 29  Epoch: 34  Training loss = 2.2399  Validation loss = 1.1112  \n",
      "\n",
      "Fold: 29  Epoch: 35  Training loss = 2.2338  Validation loss = 1.1093  \n",
      "\n",
      "Fold: 29  Epoch: 36  Training loss = 2.2359  Validation loss = 1.1060  \n",
      "\n",
      "Fold: 29  Epoch: 37  Training loss = 2.2327  Validation loss = 1.1054  \n",
      "\n",
      "Fold: 29  Epoch: 38  Training loss = 2.2343  Validation loss = 1.1045  \n",
      "\n",
      "Fold: 29  Epoch: 39  Training loss = 2.2399  Validation loss = 1.0987  \n",
      "\n",
      "Fold: 29  Epoch: 40  Training loss = 2.2374  Validation loss = 1.0984  \n",
      "\n",
      "Fold: 29  Epoch: 41  Training loss = 2.2468  Validation loss = 1.0970  \n",
      "\n",
      "Fold: 29  Epoch: 42  Training loss = 2.2334  Validation loss = 1.0952  \n",
      "\n",
      "Fold: 29  Epoch: 43  Training loss = 2.2264  Validation loss = 1.0945  \n",
      "\n",
      "Fold: 29  Epoch: 44  Training loss = 2.2304  Validation loss = 1.0939  \n",
      "\n",
      "Fold: 29  Epoch: 45  Training loss = 2.2250  Validation loss = 1.0965  \n",
      "\n",
      "Fold: 29  Epoch: 46  Training loss = 2.2381  Validation loss = 1.0926  \n",
      "\n",
      "Fold: 29  Epoch: 47  Training loss = 2.2234  Validation loss = 1.0950  \n",
      "\n",
      "Fold: 29  Epoch: 48  Training loss = 2.2256  Validation loss = 1.0949  \n",
      "\n",
      "Fold: 29  Epoch: 49  Training loss = 2.2310  Validation loss = 1.0915  \n",
      "\n",
      "Fold: 29  Epoch: 50  Training loss = 2.2210  Validation loss = 1.0931  \n",
      "\n",
      "Fold: 29  Epoch: 51  Training loss = 2.2258  Validation loss = 1.0903  \n",
      "\n",
      "Fold: 29  Epoch: 52  Training loss = 2.2242  Validation loss = 1.0886  \n",
      "\n",
      "Fold: 29  Epoch: 53  Training loss = 2.2182  Validation loss = 1.0853  \n",
      "\n",
      "Fold: 29  Epoch: 54  Training loss = 2.2268  Validation loss = 1.0836  \n",
      "\n",
      "Fold: 29  Epoch: 55  Training loss = 2.2169  Validation loss = 1.0838  \n",
      "\n",
      "Fold: 29  Epoch: 56  Training loss = 2.2165  Validation loss = 1.0870  \n",
      "\n",
      "Fold: 29  Epoch: 57  Training loss = 2.2147  Validation loss = 1.0808  \n",
      "\n",
      "Fold: 29  Epoch: 58  Training loss = 2.2231  Validation loss = 1.0812  \n",
      "\n",
      "Fold: 29  Epoch: 59  Training loss = 2.2146  Validation loss = 1.0800  \n",
      "\n",
      "Fold: 29  Epoch: 60  Training loss = 2.2217  Validation loss = 1.0812  \n",
      "\n",
      "Fold: 29  Epoch: 61  Training loss = 2.2137  Validation loss = 1.0786  \n",
      "\n",
      "Fold: 29  Epoch: 62  Training loss = 2.2209  Validation loss = 1.0762  \n",
      "\n",
      "Fold: 29  Epoch: 63  Training loss = 2.2207  Validation loss = 1.0787  \n",
      "\n",
      "Fold: 29  Epoch: 64  Training loss = 2.2140  Validation loss = 1.0782  \n",
      "\n",
      "Fold: 29  Epoch: 65  Training loss = 2.2190  Validation loss = 1.0802  \n",
      "\n",
      "Fold: 29  Epoch: 66  Training loss = 2.2102  Validation loss = 1.0777  \n",
      "\n",
      "Fold: 29  Epoch: 67  Training loss = 2.2092  Validation loss = 1.0773  \n",
      "\n",
      "Fold: 29  Epoch: 68  Training loss = 2.2100  Validation loss = 1.0776  \n",
      "\n",
      "Fold: 29  Epoch: 69  Training loss = 2.2077  Validation loss = 1.0690  \n",
      "\n",
      "Fold: 29  Epoch: 70  Training loss = 2.2109  Validation loss = 1.0698  \n",
      "\n",
      "Fold: 29  Epoch: 71  Training loss = 2.2053  Validation loss = 1.0654  \n",
      "\n",
      "Fold: 29  Epoch: 72  Training loss = 2.2121  Validation loss = 1.0626  \n",
      "\n",
      "Fold: 29  Epoch: 73  Training loss = 2.2049  Validation loss = 1.0617  \n",
      "\n",
      "Fold: 29  Epoch: 74  Training loss = 2.2038  Validation loss = 1.0611  \n",
      "\n",
      "Fold: 29  Epoch: 75  Training loss = 2.2126  Validation loss = 1.0579  \n",
      "\n",
      "Fold: 29  Epoch: 76  Training loss = 2.2190  Validation loss = 1.0578  \n",
      "\n",
      "Fold: 29  Epoch: 77  Training loss = 2.2143  Validation loss = 1.0563  \n",
      "\n",
      "Fold: 29  Epoch: 78  Training loss = 2.2290  Validation loss = 1.0564  \n",
      "\n",
      "Fold: 29  Epoch: 79  Training loss = 2.2229  Validation loss = 1.0546  \n",
      "\n",
      "Fold: 29  Epoch: 80  Training loss = 2.2054  Validation loss = 1.0500  \n",
      "\n",
      "Fold: 29  Epoch: 81  Training loss = 2.2139  Validation loss = 1.0524  \n",
      "\n",
      "Fold: 29  Epoch: 82  Training loss = 2.1997  Validation loss = 1.0492  \n",
      "\n",
      "Fold: 29  Epoch: 83  Training loss = 2.2119  Validation loss = 1.0491  \n",
      "\n",
      "Fold: 29  Epoch: 84  Training loss = 2.2017  Validation loss = 1.0445  \n",
      "\n",
      "Fold: 29  Epoch: 85  Training loss = 2.2254  Validation loss = 1.0459  \n",
      "\n",
      "Fold: 29  Epoch: 86  Training loss = 2.1971  Validation loss = 1.0450  \n",
      "\n",
      "Fold: 29  Epoch: 87  Training loss = 2.1977  Validation loss = 1.0438  \n",
      "\n",
      "Fold: 29  Epoch: 88  Training loss = 2.1957  Validation loss = 1.0402  \n",
      "\n",
      "Fold: 29  Epoch: 89  Training loss = 2.1969  Validation loss = 1.0395  \n",
      "\n",
      "Fold: 29  Epoch: 90  Training loss = 2.1942  Validation loss = 1.0395  \n",
      "\n",
      "Fold: 29  Epoch: 91  Training loss = 2.1929  Validation loss = 1.0342  \n",
      "\n",
      "Fold: 29  Epoch: 92  Training loss = 2.1932  Validation loss = 1.0324  \n",
      "\n",
      "Fold: 29  Epoch: 93  Training loss = 2.2260  Validation loss = 1.0351  \n",
      "\n",
      "Fold: 29  Epoch: 94  Training loss = 2.1923  Validation loss = 1.0338  \n",
      "\n",
      "Fold: 29  Epoch: 95  Training loss = 2.1903  Validation loss = 1.0373  \n",
      "\n",
      "Fold: 29  Epoch: 96  Training loss = 2.2018  Validation loss = 1.0373  \n",
      "\n",
      "Fold: 29  Epoch: 97  Training loss = 2.2020  Validation loss = 1.0370  \n",
      "\n",
      "Fold: 29  Epoch: 98  Training loss = 2.1877  Validation loss = 1.0336  \n",
      "\n",
      "Fold: 29  Epoch: 99  Training loss = 2.1988  Validation loss = 1.0366  \n",
      "\n",
      "Fold: 29  Epoch: 100  Training loss = 2.1960  Validation loss = 1.0376  \n",
      "\n",
      "Fold: 29  Epoch: 101  Training loss = 2.1903  Validation loss = 1.0357  \n",
      "\n",
      "Fold: 29  Epoch: 102  Training loss = 2.1882  Validation loss = 1.0334  \n",
      "\n",
      "Fold: 29  Epoch: 103  Training loss = 2.1852  Validation loss = 1.0310  \n",
      "\n",
      "Fold: 29  Epoch: 104  Training loss = 2.1913  Validation loss = 1.0341  \n",
      "\n",
      "Fold: 29  Epoch: 105  Training loss = 2.1854  Validation loss = 1.0328  \n",
      "\n",
      "Fold: 29  Epoch: 106  Training loss = 2.1857  Validation loss = 1.0282  \n",
      "\n",
      "Fold: 29  Epoch: 107  Training loss = 2.1922  Validation loss = 1.0265  \n",
      "\n",
      "Fold: 29  Epoch: 108  Training loss = 2.1895  Validation loss = 1.0276  \n",
      "\n",
      "Fold: 29  Epoch: 109  Training loss = 2.1850  Validation loss = 1.0258  \n",
      "\n",
      "Fold: 29  Epoch: 110  Training loss = 2.1992  Validation loss = 1.0276  \n",
      "\n",
      "Fold: 29  Epoch: 111  Training loss = 2.1946  Validation loss = 1.0271  \n",
      "\n",
      "Fold: 29  Epoch: 112  Training loss = 2.1933  Validation loss = 1.0289  \n",
      "\n",
      "Fold: 29  Epoch: 113  Training loss = 2.2075  Validation loss = 1.0244  \n",
      "\n",
      "Fold: 29  Epoch: 114  Training loss = 2.1900  Validation loss = 1.0253  \n",
      "\n",
      "Fold: 29  Epoch: 115  Training loss = 2.1843  Validation loss = 1.0281  \n",
      "\n",
      "Fold: 29  Epoch: 116  Training loss = 2.1871  Validation loss = 1.0250  \n",
      "\n",
      "Fold: 29  Epoch: 117  Training loss = 2.1802  Validation loss = 1.0236  \n",
      "\n",
      "Fold: 29  Epoch: 118  Training loss = 2.1774  Validation loss = 1.0239  \n",
      "\n",
      "Fold: 29  Epoch: 119  Training loss = 2.1765  Validation loss = 1.0244  \n",
      "\n",
      "Fold: 29  Epoch: 120  Training loss = 2.1760  Validation loss = 1.0264  \n",
      "\n",
      "Fold: 29  Epoch: 121  Training loss = 2.1837  Validation loss = 1.0245  \n",
      "\n",
      "Fold: 29  Epoch: 122  Training loss = 2.1809  Validation loss = 1.0252  \n",
      "\n",
      "Fold: 29  Epoch: 123  Training loss = 2.1847  Validation loss = 1.0281  \n",
      "\n",
      "Fold: 29  Epoch: 124  Training loss = 2.1787  Validation loss = 1.0238  \n",
      "\n",
      "Fold: 29  Epoch: 125  Training loss = 2.1776  Validation loss = 1.0214  \n",
      "\n",
      "Fold: 29  Epoch: 126  Training loss = 2.1925  Validation loss = 1.0245  \n",
      "\n",
      "Fold: 29  Epoch: 127  Training loss = 2.1914  Validation loss = 1.0232  \n",
      "\n",
      "Fold: 29  Epoch: 128  Training loss = 2.1821  Validation loss = 1.0207  \n",
      "\n",
      "Fold: 29  Epoch: 129  Training loss = 2.1838  Validation loss = 1.0173  \n",
      "\n",
      "Fold: 29  Epoch: 130  Training loss = 2.1774  Validation loss = 1.0174  \n",
      "\n",
      "Fold: 29  Epoch: 131  Training loss = 2.1708  Validation loss = 1.0171  \n",
      "\n",
      "Fold: 29  Epoch: 132  Training loss = 2.1744  Validation loss = 1.0156  \n",
      "\n",
      "Fold: 29  Epoch: 133  Training loss = 2.1702  Validation loss = 1.0224  \n",
      "\n",
      "Fold: 29  Epoch: 134  Training loss = 2.1715  Validation loss = 1.0212  \n",
      "\n",
      "Fold: 29  Epoch: 135  Training loss = 2.2103  Validation loss = 1.0222  \n",
      "\n",
      "Fold: 29  Epoch: 136  Training loss = 2.1703  Validation loss = 1.0213  \n",
      "\n",
      "Fold: 29  Epoch: 137  Training loss = 2.1824  Validation loss = 1.0209  \n",
      "\n",
      "Fold: 29  Epoch: 138  Training loss = 2.1797  Validation loss = 1.0248  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 132  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.1715  Validation loss = 1.1020  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.1751  Validation loss = 1.1096  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.1741  Validation loss = 1.1174  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.1675  Validation loss = 1.1089  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.1748  Validation loss = 1.1156  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.1764  Validation loss = 1.1046  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.1730  Validation loss = 1.1239  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.1948  Validation loss = 1.1277  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.1712  Validation loss = 1.1336  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.1672  Validation loss = 1.1194  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.1645  Validation loss = 1.0987  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.1639  Validation loss = 1.1031  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 2.1723  Validation loss = 1.1002  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.1607  Validation loss = 1.0989  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 2.1695  Validation loss = 1.1225  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 2.1575  Validation loss = 1.1075  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 2.1567  Validation loss = 1.1166  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 2.1724  Validation loss = 1.1337  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 11  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.0563  Validation loss = 0.6534  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.0574  Validation loss = 0.6483  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.0606  Validation loss = 0.6377  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.0576  Validation loss = 0.6411  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.0526  Validation loss = 0.6702  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.0508  Validation loss = 0.6559  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.0610  Validation loss = 0.6423  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.0574  Validation loss = 0.6449  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.0463  Validation loss = 0.6718  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.0460  Validation loss = 0.6728  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.0516  Validation loss = 0.6541  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.0545  Validation loss = 0.6539  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.0516  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.0578  Validation loss = 0.6540  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.0440  Validation loss = 0.6941  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.0512  Validation loss = 0.7060  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 3  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.6804  Validation loss = 1.6719  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.6783  Validation loss = 1.6845  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.6795  Validation loss = 1.7338  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.6797  Validation loss = 1.6536  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.6766  Validation loss = 1.6181  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.6762  Validation loss = 1.6239  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.6758  Validation loss = 1.7802  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.6735  Validation loss = 1.7562  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.6782  Validation loss = 1.8580  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.6748  Validation loss = 1.7458  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.6928  Validation loss = 1.8059  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.7010  Validation loss = 1.7618  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.6802  Validation loss = 1.6987  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.6712  Validation loss = 1.6819  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.6730  Validation loss = 1.7712  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.6684  Validation loss = 1.6516  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.6641  Validation loss = 1.7834  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.6635  Validation loss = 1.8433  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.6613  Validation loss = 2.0480  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 5  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 353\n",
      "Average validation error: 2.77924\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.6047  Test loss = 2.5630  \n",
      "\n",
      "Epoch: 2  Training loss = 1.5999  Test loss = 2.5567  \n",
      "\n",
      "Epoch: 3  Training loss = 1.5957  Test loss = 2.5511  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5920  Test loss = 2.5461  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5888  Test loss = 2.5416  \n",
      "\n",
      "Epoch: 6  Training loss = 1.5861  Test loss = 2.5375  \n",
      "\n",
      "Epoch: 7  Training loss = 1.5836  Test loss = 2.5338  \n",
      "\n",
      "Epoch: 8  Training loss = 1.5815  Test loss = 2.5303  \n",
      "\n",
      "Epoch: 9  Training loss = 1.5795  Test loss = 2.5271  \n",
      "\n",
      "Epoch: 10  Training loss = 1.5778  Test loss = 2.5242  \n",
      "\n",
      "Epoch: 11  Training loss = 1.5763  Test loss = 2.5215  \n",
      "\n",
      "Epoch: 12  Training loss = 1.5749  Test loss = 2.5189  \n",
      "\n",
      "Epoch: 13  Training loss = 1.5737  Test loss = 2.5165  \n",
      "\n",
      "Epoch: 14  Training loss = 1.5725  Test loss = 2.5143  \n",
      "\n",
      "Epoch: 15  Training loss = 1.5714  Test loss = 2.5122  \n",
      "\n",
      "Epoch: 16  Training loss = 1.5705  Test loss = 2.5102  \n",
      "\n",
      "Epoch: 17  Training loss = 1.5696  Test loss = 2.5084  \n",
      "\n",
      "Epoch: 18  Training loss = 1.5687  Test loss = 2.5066  \n",
      "\n",
      "Epoch: 19  Training loss = 1.5679  Test loss = 2.5050  \n",
      "\n",
      "Epoch: 20  Training loss = 1.5671  Test loss = 2.5034  \n",
      "\n",
      "Epoch: 21  Training loss = 1.5664  Test loss = 2.5019  \n",
      "\n",
      "Epoch: 22  Training loss = 1.5657  Test loss = 2.5005  \n",
      "\n",
      "Epoch: 23  Training loss = 1.5651  Test loss = 2.4992  \n",
      "\n",
      "Epoch: 24  Training loss = 1.5644  Test loss = 2.4979  \n",
      "\n",
      "Epoch: 25  Training loss = 1.5638  Test loss = 2.4967  \n",
      "\n",
      "Epoch: 26  Training loss = 1.5632  Test loss = 2.4956  \n",
      "\n",
      "Epoch: 27  Training loss = 1.5627  Test loss = 2.4945  \n",
      "\n",
      "Epoch: 28  Training loss = 1.5621  Test loss = 2.4935  \n",
      "\n",
      "Epoch: 29  Training loss = 1.5616  Test loss = 2.4925  \n",
      "\n",
      "Epoch: 30  Training loss = 1.5610  Test loss = 2.4915  \n",
      "\n",
      "Epoch: 31  Training loss = 1.5605  Test loss = 2.4906  \n",
      "\n",
      "Epoch: 32  Training loss = 1.5600  Test loss = 2.4898  \n",
      "\n",
      "Epoch: 33  Training loss = 1.5595  Test loss = 2.4889  \n",
      "\n",
      "Epoch: 34  Training loss = 1.5590  Test loss = 2.4881  \n",
      "\n",
      "Epoch: 35  Training loss = 1.5586  Test loss = 2.4874  \n",
      "\n",
      "Epoch: 36  Training loss = 1.5581  Test loss = 2.4866  \n",
      "\n",
      "Epoch: 37  Training loss = 1.5576  Test loss = 2.4859  \n",
      "\n",
      "Epoch: 38  Training loss = 1.5572  Test loss = 2.4852  \n",
      "\n",
      "Epoch: 39  Training loss = 1.5567  Test loss = 2.4846  \n",
      "\n",
      "Epoch: 40  Training loss = 1.5563  Test loss = 2.4839  \n",
      "\n",
      "Epoch: 41  Training loss = 1.5558  Test loss = 2.4833  \n",
      "\n",
      "Epoch: 42  Training loss = 1.5554  Test loss = 2.4827  \n",
      "\n",
      "Epoch: 43  Training loss = 1.5550  Test loss = 2.4822  \n",
      "\n",
      "Epoch: 44  Training loss = 1.5545  Test loss = 2.4816  \n",
      "\n",
      "Epoch: 45  Training loss = 1.5541  Test loss = 2.4811  \n",
      "\n",
      "Epoch: 46  Training loss = 1.5537  Test loss = 2.4806  \n",
      "\n",
      "Epoch: 47  Training loss = 1.5533  Test loss = 2.4800  \n",
      "\n",
      "Epoch: 48  Training loss = 1.5528  Test loss = 2.4796  \n",
      "\n",
      "Epoch: 49  Training loss = 1.5524  Test loss = 2.4791  \n",
      "\n",
      "Epoch: 50  Training loss = 1.5520  Test loss = 2.4786  \n",
      "\n",
      "Epoch: 51  Training loss = 1.5516  Test loss = 2.4782  \n",
      "\n",
      "Epoch: 52  Training loss = 1.5512  Test loss = 2.4777  \n",
      "\n",
      "Epoch: 53  Training loss = 1.5508  Test loss = 2.4773  \n",
      "\n",
      "Epoch: 54  Training loss = 1.5504  Test loss = 2.4769  \n",
      "\n",
      "Epoch: 55  Training loss = 1.5500  Test loss = 2.4765  \n",
      "\n",
      "Epoch: 56  Training loss = 1.5496  Test loss = 2.4761  \n",
      "\n",
      "Epoch: 57  Training loss = 1.5493  Test loss = 2.4757  \n",
      "\n",
      "Epoch: 58  Training loss = 1.5489  Test loss = 2.4753  \n",
      "\n",
      "Epoch: 59  Training loss = 1.5485  Test loss = 2.4749  \n",
      "\n",
      "Epoch: 60  Training loss = 1.5481  Test loss = 2.4745  \n",
      "\n",
      "Epoch: 61  Training loss = 1.5477  Test loss = 2.4742  \n",
      "\n",
      "Epoch: 62  Training loss = 1.5474  Test loss = 2.4738  \n",
      "\n",
      "Epoch: 63  Training loss = 1.5470  Test loss = 2.4735  \n",
      "\n",
      "Epoch: 64  Training loss = 1.5466  Test loss = 2.4731  \n",
      "\n",
      "Epoch: 65  Training loss = 1.5463  Test loss = 2.4728  \n",
      "\n",
      "Epoch: 66  Training loss = 1.5459  Test loss = 2.4725  \n",
      "\n",
      "Epoch: 67  Training loss = 1.5455  Test loss = 2.4722  \n",
      "\n",
      "Epoch: 68  Training loss = 1.5452  Test loss = 2.4718  \n",
      "\n",
      "Epoch: 69  Training loss = 1.5448  Test loss = 2.4715  \n",
      "\n",
      "Epoch: 70  Training loss = 1.5445  Test loss = 2.4712  \n",
      "\n",
      "Epoch: 71  Training loss = 1.5441  Test loss = 2.4709  \n",
      "\n",
      "Epoch: 72  Training loss = 1.5438  Test loss = 2.4706  \n",
      "\n",
      "Epoch: 73  Training loss = 1.5434  Test loss = 2.4703  \n",
      "\n",
      "Epoch: 74  Training loss = 1.5431  Test loss = 2.4700  \n",
      "\n",
      "Epoch: 75  Training loss = 1.5427  Test loss = 2.4697  \n",
      "\n",
      "Epoch: 76  Training loss = 1.5424  Test loss = 2.4695  \n",
      "\n",
      "Epoch: 77  Training loss = 1.5420  Test loss = 2.4692  \n",
      "\n",
      "Epoch: 78  Training loss = 1.5417  Test loss = 2.4689  \n",
      "\n",
      "Epoch: 79  Training loss = 1.5414  Test loss = 2.4686  \n",
      "\n",
      "Epoch: 80  Training loss = 1.5410  Test loss = 2.4684  \n",
      "\n",
      "Epoch: 81  Training loss = 1.5407  Test loss = 2.4681  \n",
      "\n",
      "Epoch: 82  Training loss = 1.5404  Test loss = 2.4678  \n",
      "\n",
      "Epoch: 83  Training loss = 1.5401  Test loss = 2.4676  \n",
      "\n",
      "Epoch: 84  Training loss = 1.5397  Test loss = 2.4673  \n",
      "\n",
      "Epoch: 85  Training loss = 1.5394  Test loss = 2.4671  \n",
      "\n",
      "Epoch: 86  Training loss = 1.5391  Test loss = 2.4668  \n",
      "\n",
      "Epoch: 87  Training loss = 1.5388  Test loss = 2.4666  \n",
      "\n",
      "Epoch: 88  Training loss = 1.5384  Test loss = 2.4663  \n",
      "\n",
      "Epoch: 89  Training loss = 1.5381  Test loss = 2.4661  \n",
      "\n",
      "Epoch: 90  Training loss = 1.5378  Test loss = 2.4658  \n",
      "\n",
      "Epoch: 91  Training loss = 1.5375  Test loss = 2.4656  \n",
      "\n",
      "Epoch: 92  Training loss = 1.5372  Test loss = 2.4654  \n",
      "\n",
      "Epoch: 93  Training loss = 1.5369  Test loss = 2.4651  \n",
      "\n",
      "Epoch: 94  Training loss = 1.5366  Test loss = 2.4649  \n",
      "\n",
      "Epoch: 95  Training loss = 1.5363  Test loss = 2.4647  \n",
      "\n",
      "Epoch: 96  Training loss = 1.5360  Test loss = 2.4644  \n",
      "\n",
      "Epoch: 97  Training loss = 1.5357  Test loss = 2.4642  \n",
      "\n",
      "Epoch: 98  Training loss = 1.5354  Test loss = 2.4640  \n",
      "\n",
      "Epoch: 99  Training loss = 1.5351  Test loss = 2.4638  \n",
      "\n",
      "Epoch: 100  Training loss = 1.5348  Test loss = 2.4635  \n",
      "\n",
      "Epoch: 101  Training loss = 1.5345  Test loss = 2.4633  \n",
      "\n",
      "Epoch: 102  Training loss = 1.5342  Test loss = 2.4631  \n",
      "\n",
      "Epoch: 103  Training loss = 1.5339  Test loss = 2.4629  \n",
      "\n",
      "Epoch: 104  Training loss = 1.5336  Test loss = 2.4627  \n",
      "\n",
      "Epoch: 105  Training loss = 1.5333  Test loss = 2.4625  \n",
      "\n",
      "Epoch: 106  Training loss = 1.5330  Test loss = 2.4622  \n",
      "\n",
      "Epoch: 107  Training loss = 1.5327  Test loss = 2.4620  \n",
      "\n",
      "Epoch: 108  Training loss = 1.5325  Test loss = 2.4618  \n",
      "\n",
      "Epoch: 109  Training loss = 1.5322  Test loss = 2.4616  \n",
      "\n",
      "Epoch: 110  Training loss = 1.5319  Test loss = 2.4614  \n",
      "\n",
      "Epoch: 111  Training loss = 1.5316  Test loss = 2.4612  \n",
      "\n",
      "Epoch: 112  Training loss = 1.5313  Test loss = 2.4610  \n",
      "\n",
      "Epoch: 113  Training loss = 1.5310  Test loss = 2.4608  \n",
      "\n",
      "Epoch: 114  Training loss = 1.5308  Test loss = 2.4606  \n",
      "\n",
      "Epoch: 115  Training loss = 1.5305  Test loss = 2.4604  \n",
      "\n",
      "Epoch: 116  Training loss = 1.5302  Test loss = 2.4602  \n",
      "\n",
      "Epoch: 117  Training loss = 1.5300  Test loss = 2.4600  \n",
      "\n",
      "Epoch: 118  Training loss = 1.5297  Test loss = 2.4598  \n",
      "\n",
      "Epoch: 119  Training loss = 1.5294  Test loss = 2.4596  \n",
      "\n",
      "Epoch: 120  Training loss = 1.5291  Test loss = 2.4595  \n",
      "\n",
      "Epoch: 121  Training loss = 1.5289  Test loss = 2.4593  \n",
      "\n",
      "Epoch: 122  Training loss = 1.5286  Test loss = 2.4591  \n",
      "\n",
      "Epoch: 123  Training loss = 1.5283  Test loss = 2.4589  \n",
      "\n",
      "Epoch: 124  Training loss = 1.5281  Test loss = 2.4587  \n",
      "\n",
      "Epoch: 125  Training loss = 1.5278  Test loss = 2.4585  \n",
      "\n",
      "Epoch: 126  Training loss = 1.5276  Test loss = 2.4583  \n",
      "\n",
      "Epoch: 127  Training loss = 1.5273  Test loss = 2.4582  \n",
      "\n",
      "Epoch: 128  Training loss = 1.5270  Test loss = 2.4580  \n",
      "\n",
      "Epoch: 129  Training loss = 1.5268  Test loss = 2.4578  \n",
      "\n",
      "Epoch: 130  Training loss = 1.5265  Test loss = 2.4576  \n",
      "\n",
      "Epoch: 131  Training loss = 1.5263  Test loss = 2.4574  \n",
      "\n",
      "Epoch: 132  Training loss = 1.5260  Test loss = 2.4573  \n",
      "\n",
      "Epoch: 133  Training loss = 1.5258  Test loss = 2.4571  \n",
      "\n",
      "Epoch: 134  Training loss = 1.5255  Test loss = 2.4569  \n",
      "\n",
      "Epoch: 135  Training loss = 1.5253  Test loss = 2.4567  \n",
      "\n",
      "Epoch: 136  Training loss = 1.5250  Test loss = 2.4566  \n",
      "\n",
      "Epoch: 137  Training loss = 1.5248  Test loss = 2.4564  \n",
      "\n",
      "Epoch: 138  Training loss = 1.5245  Test loss = 2.4562  \n",
      "\n",
      "Epoch: 139  Training loss = 1.5243  Test loss = 2.4561  \n",
      "\n",
      "Epoch: 140  Training loss = 1.5240  Test loss = 2.4559  \n",
      "\n",
      "Epoch: 141  Training loss = 1.5238  Test loss = 2.4557  \n",
      "\n",
      "Epoch: 142  Training loss = 1.5236  Test loss = 2.4556  \n",
      "\n",
      "Epoch: 143  Training loss = 1.5233  Test loss = 2.4554  \n",
      "\n",
      "Epoch: 144  Training loss = 1.5231  Test loss = 2.4552  \n",
      "\n",
      "Epoch: 145  Training loss = 1.5228  Test loss = 2.4551  \n",
      "\n",
      "Epoch: 146  Training loss = 1.5226  Test loss = 2.4549  \n",
      "\n",
      "Epoch: 147  Training loss = 1.5224  Test loss = 2.4547  \n",
      "\n",
      "Epoch: 148  Training loss = 1.5221  Test loss = 2.4546  \n",
      "\n",
      "Epoch: 149  Training loss = 1.5219  Test loss = 2.4544  \n",
      "\n",
      "Epoch: 150  Training loss = 1.5216  Test loss = 2.4543  \n",
      "\n",
      "Epoch: 151  Training loss = 1.5214  Test loss = 2.4541  \n",
      "\n",
      "Epoch: 152  Training loss = 1.5212  Test loss = 2.4540  \n",
      "\n",
      "Epoch: 153  Training loss = 1.5210  Test loss = 2.4538  \n",
      "\n",
      "Epoch: 154  Training loss = 1.5207  Test loss = 2.4536  \n",
      "\n",
      "Epoch: 155  Training loss = 1.5205  Test loss = 2.4535  \n",
      "\n",
      "Epoch: 156  Training loss = 1.5203  Test loss = 2.4533  \n",
      "\n",
      "Epoch: 157  Training loss = 1.5200  Test loss = 2.4532  \n",
      "\n",
      "Epoch: 158  Training loss = 1.5198  Test loss = 2.4530  \n",
      "\n",
      "Epoch: 159  Training loss = 1.5196  Test loss = 2.4529  \n",
      "\n",
      "Epoch: 160  Training loss = 1.5194  Test loss = 2.4527  \n",
      "\n",
      "Epoch: 161  Training loss = 1.5191  Test loss = 2.4526  \n",
      "\n",
      "Epoch: 162  Training loss = 1.5189  Test loss = 2.4524  \n",
      "\n",
      "Epoch: 163  Training loss = 1.5187  Test loss = 2.4523  \n",
      "\n",
      "Epoch: 164  Training loss = 1.5185  Test loss = 2.4521  \n",
      "\n",
      "Epoch: 165  Training loss = 1.5182  Test loss = 2.4520  \n",
      "\n",
      "Epoch: 166  Training loss = 1.5180  Test loss = 2.4519  \n",
      "\n",
      "Epoch: 167  Training loss = 1.5178  Test loss = 2.4517  \n",
      "\n",
      "Epoch: 168  Training loss = 1.5176  Test loss = 2.4516  \n",
      "\n",
      "Epoch: 169  Training loss = 1.5174  Test loss = 2.4514  \n",
      "\n",
      "Epoch: 170  Training loss = 1.5172  Test loss = 2.4513  \n",
      "\n",
      "Epoch: 171  Training loss = 1.5169  Test loss = 2.4511  \n",
      "\n",
      "Epoch: 172  Training loss = 1.5167  Test loss = 2.4510  \n",
      "\n",
      "Epoch: 173  Training loss = 1.5165  Test loss = 2.4509  \n",
      "\n",
      "Epoch: 174  Training loss = 1.5163  Test loss = 2.4507  \n",
      "\n",
      "Epoch: 175  Training loss = 1.5161  Test loss = 2.4506  \n",
      "\n",
      "Epoch: 176  Training loss = 1.5159  Test loss = 2.4504  \n",
      "\n",
      "Epoch: 177  Training loss = 1.5157  Test loss = 2.4503  \n",
      "\n",
      "Epoch: 178  Training loss = 1.5155  Test loss = 2.4502  \n",
      "\n",
      "Epoch: 179  Training loss = 1.5152  Test loss = 2.4500  \n",
      "\n",
      "Epoch: 180  Training loss = 1.5150  Test loss = 2.4499  \n",
      "\n",
      "Epoch: 181  Training loss = 1.5148  Test loss = 2.4498  \n",
      "\n",
      "Epoch: 182  Training loss = 1.5146  Test loss = 2.4496  \n",
      "\n",
      "Epoch: 183  Training loss = 1.5144  Test loss = 2.4495  \n",
      "\n",
      "Epoch: 184  Training loss = 1.5142  Test loss = 2.4494  \n",
      "\n",
      "Epoch: 185  Training loss = 1.5140  Test loss = 2.4492  \n",
      "\n",
      "Epoch: 186  Training loss = 1.5138  Test loss = 2.4491  \n",
      "\n",
      "Epoch: 187  Training loss = 1.5136  Test loss = 2.4490  \n",
      "\n",
      "Epoch: 188  Training loss = 1.5134  Test loss = 2.4488  \n",
      "\n",
      "Epoch: 189  Training loss = 1.5132  Test loss = 2.4487  \n",
      "\n",
      "Epoch: 190  Training loss = 1.5130  Test loss = 2.4486  \n",
      "\n",
      "Epoch: 191  Training loss = 1.5128  Test loss = 2.4485  \n",
      "\n",
      "Epoch: 192  Training loss = 1.5126  Test loss = 2.4483  \n",
      "\n",
      "Epoch: 193  Training loss = 1.5124  Test loss = 2.4482  \n",
      "\n",
      "Epoch: 194  Training loss = 1.5122  Test loss = 2.4481  \n",
      "\n",
      "Epoch: 195  Training loss = 1.5120  Test loss = 2.4480  \n",
      "\n",
      "Epoch: 196  Training loss = 1.5118  Test loss = 2.4478  \n",
      "\n",
      "Epoch: 197  Training loss = 1.5116  Test loss = 2.4477  \n",
      "\n",
      "Epoch: 198  Training loss = 1.5114  Test loss = 2.4476  \n",
      "\n",
      "Epoch: 199  Training loss = 1.5112  Test loss = 2.4475  \n",
      "\n",
      "Epoch: 200  Training loss = 1.5110  Test loss = 2.4473  \n",
      "\n",
      "Epoch: 201  Training loss = 1.5108  Test loss = 2.4472  \n",
      "\n",
      "Epoch: 202  Training loss = 1.5106  Test loss = 2.4471  \n",
      "\n",
      "Epoch: 203  Training loss = 1.5104  Test loss = 2.4470  \n",
      "\n",
      "Epoch: 204  Training loss = 1.5102  Test loss = 2.4469  \n",
      "\n",
      "Epoch: 205  Training loss = 1.5100  Test loss = 2.4467  \n",
      "\n",
      "Epoch: 206  Training loss = 1.5099  Test loss = 2.4466  \n",
      "\n",
      "Epoch: 207  Training loss = 1.5097  Test loss = 2.4465  \n",
      "\n",
      "Epoch: 208  Training loss = 1.5095  Test loss = 2.4464  \n",
      "\n",
      "Epoch: 209  Training loss = 1.5093  Test loss = 2.4463  \n",
      "\n",
      "Epoch: 210  Training loss = 1.5091  Test loss = 2.4461  \n",
      "\n",
      "Epoch: 211  Training loss = 1.5089  Test loss = 2.4460  \n",
      "\n",
      "Epoch: 212  Training loss = 1.5087  Test loss = 2.4459  \n",
      "\n",
      "Epoch: 213  Training loss = 1.5085  Test loss = 2.4458  \n",
      "\n",
      "Epoch: 214  Training loss = 1.5084  Test loss = 2.4457  \n",
      "\n",
      "Epoch: 215  Training loss = 1.5082  Test loss = 2.4456  \n",
      "\n",
      "Epoch: 216  Training loss = 1.5080  Test loss = 2.4455  \n",
      "\n",
      "Epoch: 217  Training loss = 1.5078  Test loss = 2.4453  \n",
      "\n",
      "Epoch: 218  Training loss = 1.5076  Test loss = 2.4452  \n",
      "\n",
      "Epoch: 219  Training loss = 1.5074  Test loss = 2.4451  \n",
      "\n",
      "Epoch: 220  Training loss = 1.5072  Test loss = 2.4450  \n",
      "\n",
      "Epoch: 221  Training loss = 1.5071  Test loss = 2.4449  \n",
      "\n",
      "Epoch: 222  Training loss = 1.5069  Test loss = 2.4448  \n",
      "\n",
      "Epoch: 223  Training loss = 1.5067  Test loss = 2.4447  \n",
      "\n",
      "Epoch: 224  Training loss = 1.5065  Test loss = 2.4446  \n",
      "\n",
      "Epoch: 225  Training loss = 1.5063  Test loss = 2.4445  \n",
      "\n",
      "Epoch: 226  Training loss = 1.5062  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 227  Training loss = 1.5060  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 228  Training loss = 1.5058  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 229  Training loss = 1.5056  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 230  Training loss = 1.5054  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 231  Training loss = 1.5053  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 232  Training loss = 1.5051  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 233  Training loss = 1.5049  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 234  Training loss = 1.5047  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 235  Training loss = 1.5046  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 236  Training loss = 1.5044  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 237  Training loss = 1.5042  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 238  Training loss = 1.5040  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 239  Training loss = 1.5039  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 240  Training loss = 1.5037  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 241  Training loss = 1.5035  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 242  Training loss = 1.5034  Test loss = 2.4427  \n",
      "\n",
      "Epoch: 243  Training loss = 1.5032  Test loss = 2.4426  \n",
      "\n",
      "Epoch: 244  Training loss = 1.5030  Test loss = 2.4425  \n",
      "\n",
      "Epoch: 245  Training loss = 1.5029  Test loss = 2.4424  \n",
      "\n",
      "Epoch: 246  Training loss = 1.5027  Test loss = 2.4423  \n",
      "\n",
      "Epoch: 247  Training loss = 1.5025  Test loss = 2.4422  \n",
      "\n",
      "Epoch: 248  Training loss = 1.5023  Test loss = 2.4421  \n",
      "\n",
      "Epoch: 249  Training loss = 1.5022  Test loss = 2.4420  \n",
      "\n",
      "Epoch: 250  Training loss = 1.5020  Test loss = 2.4419  \n",
      "\n",
      "Epoch: 251  Training loss = 1.5018  Test loss = 2.4418  \n",
      "\n",
      "Epoch: 252  Training loss = 1.5017  Test loss = 2.4417  \n",
      "\n",
      "Epoch: 253  Training loss = 1.5015  Test loss = 2.4416  \n",
      "\n",
      "Epoch: 254  Training loss = 1.5013  Test loss = 2.4415  \n",
      "\n",
      "Epoch: 255  Training loss = 1.5012  Test loss = 2.4414  \n",
      "\n",
      "Epoch: 256  Training loss = 1.5010  Test loss = 2.4413  \n",
      "\n",
      "Epoch: 257  Training loss = 1.5009  Test loss = 2.4412  \n",
      "\n",
      "Epoch: 258  Training loss = 1.5007  Test loss = 2.4411  \n",
      "\n",
      "Epoch: 259  Training loss = 1.5005  Test loss = 2.4410  \n",
      "\n",
      "Epoch: 260  Training loss = 1.5004  Test loss = 2.4409  \n",
      "\n",
      "Epoch: 261  Training loss = 1.5002  Test loss = 2.4408  \n",
      "\n",
      "Epoch: 262  Training loss = 1.5000  Test loss = 2.4407  \n",
      "\n",
      "Epoch: 263  Training loss = 1.4999  Test loss = 2.4406  \n",
      "\n",
      "Epoch: 264  Training loss = 1.4997  Test loss = 2.4405  \n",
      "\n",
      "Epoch: 265  Training loss = 1.4996  Test loss = 2.4404  \n",
      "\n",
      "Epoch: 266  Training loss = 1.4994  Test loss = 2.4404  \n",
      "\n",
      "Epoch: 267  Training loss = 1.4992  Test loss = 2.4403  \n",
      "\n",
      "Epoch: 268  Training loss = 1.4991  Test loss = 2.4402  \n",
      "\n",
      "Epoch: 269  Training loss = 1.4989  Test loss = 2.4401  \n",
      "\n",
      "Epoch: 270  Training loss = 1.4988  Test loss = 2.4400  \n",
      "\n",
      "Epoch: 271  Training loss = 1.4986  Test loss = 2.4399  \n",
      "\n",
      "Epoch: 272  Training loss = 1.4984  Test loss = 2.4398  \n",
      "\n",
      "Epoch: 273  Training loss = 1.4983  Test loss = 2.4397  \n",
      "\n",
      "Epoch: 274  Training loss = 1.4981  Test loss = 2.4396  \n",
      "\n",
      "Epoch: 275  Training loss = 1.4980  Test loss = 2.4395  \n",
      "\n",
      "Epoch: 276  Training loss = 1.4978  Test loss = 2.4395  \n",
      "\n",
      "Epoch: 277  Training loss = 1.4977  Test loss = 2.4394  \n",
      "\n",
      "Epoch: 278  Training loss = 1.4975  Test loss = 2.4393  \n",
      "\n",
      "Epoch: 279  Training loss = 1.4974  Test loss = 2.4392  \n",
      "\n",
      "Epoch: 280  Training loss = 1.4972  Test loss = 2.4391  \n",
      "\n",
      "Epoch: 281  Training loss = 1.4970  Test loss = 2.4390  \n",
      "\n",
      "Epoch: 282  Training loss = 1.4969  Test loss = 2.4389  \n",
      "\n",
      "Epoch: 283  Training loss = 1.4967  Test loss = 2.4388  \n",
      "\n",
      "Epoch: 284  Training loss = 1.4966  Test loss = 2.4388  \n",
      "\n",
      "Epoch: 285  Training loss = 1.4964  Test loss = 2.4387  \n",
      "\n",
      "Epoch: 286  Training loss = 1.4963  Test loss = 2.4386  \n",
      "\n",
      "Epoch: 287  Training loss = 1.4961  Test loss = 2.4385  \n",
      "\n",
      "Epoch: 288  Training loss = 1.4960  Test loss = 2.4384  \n",
      "\n",
      "Epoch: 289  Training loss = 1.4958  Test loss = 2.4383  \n",
      "\n",
      "Epoch: 290  Training loss = 1.4957  Test loss = 2.4382  \n",
      "\n",
      "Epoch: 291  Training loss = 1.4955  Test loss = 2.4382  \n",
      "\n",
      "Epoch: 292  Training loss = 1.4954  Test loss = 2.4381  \n",
      "\n",
      "Epoch: 293  Training loss = 1.4952  Test loss = 2.4380  \n",
      "\n",
      "Epoch: 294  Training loss = 1.4951  Test loss = 2.4379  \n",
      "\n",
      "Epoch: 295  Training loss = 1.4949  Test loss = 2.4378  \n",
      "\n",
      "Epoch: 296  Training loss = 1.4948  Test loss = 2.4378  \n",
      "\n",
      "Epoch: 297  Training loss = 1.4946  Test loss = 2.4377  \n",
      "\n",
      "Epoch: 298  Training loss = 1.4945  Test loss = 2.4376  \n",
      "\n",
      "Epoch: 299  Training loss = 1.4943  Test loss = 2.4375  \n",
      "\n",
      "Epoch: 300  Training loss = 1.4942  Test loss = 2.4374  \n",
      "\n",
      "Epoch: 301  Training loss = 1.4941  Test loss = 2.4373  \n",
      "\n",
      "Epoch: 302  Training loss = 1.4939  Test loss = 2.4373  \n",
      "\n",
      "Epoch: 303  Training loss = 1.4938  Test loss = 2.4372  \n",
      "\n",
      "Epoch: 304  Training loss = 1.4936  Test loss = 2.4371  \n",
      "\n",
      "Epoch: 305  Training loss = 1.4935  Test loss = 2.4370  \n",
      "\n",
      "Epoch: 306  Training loss = 1.4933  Test loss = 2.4369  \n",
      "\n",
      "Epoch: 307  Training loss = 1.4932  Test loss = 2.4369  \n",
      "\n",
      "Epoch: 308  Training loss = 1.4930  Test loss = 2.4368  \n",
      "\n",
      "Epoch: 309  Training loss = 1.4929  Test loss = 2.4367  \n",
      "\n",
      "Epoch: 310  Training loss = 1.4928  Test loss = 2.4366  \n",
      "\n",
      "Epoch: 311  Training loss = 1.4926  Test loss = 2.4366  \n",
      "\n",
      "Epoch: 312  Training loss = 1.4925  Test loss = 2.4365  \n",
      "\n",
      "Epoch: 313  Training loss = 1.4923  Test loss = 2.4364  \n",
      "\n",
      "Epoch: 314  Training loss = 1.4922  Test loss = 2.4363  \n",
      "\n",
      "Epoch: 315  Training loss = 1.4920  Test loss = 2.4362  \n",
      "\n",
      "Epoch: 316  Training loss = 1.4919  Test loss = 2.4362  \n",
      "\n",
      "Epoch: 317  Training loss = 1.4918  Test loss = 2.4361  \n",
      "\n",
      "Epoch: 318  Training loss = 1.4916  Test loss = 2.4360  \n",
      "\n",
      "Epoch: 319  Training loss = 1.4915  Test loss = 2.4359  \n",
      "\n",
      "Epoch: 320  Training loss = 1.4913  Test loss = 2.4359  \n",
      "\n",
      "Epoch: 321  Training loss = 1.4912  Test loss = 2.4358  \n",
      "\n",
      "Epoch: 322  Training loss = 1.4911  Test loss = 2.4357  \n",
      "\n",
      "Epoch: 323  Training loss = 1.4909  Test loss = 2.4356  \n",
      "\n",
      "Epoch: 324  Training loss = 1.4908  Test loss = 2.4356  \n",
      "\n",
      "Epoch: 325  Training loss = 1.4907  Test loss = 2.4355  \n",
      "\n",
      "Epoch: 326  Training loss = 1.4905  Test loss = 2.4354  \n",
      "\n",
      "Epoch: 327  Training loss = 1.4904  Test loss = 2.4354  \n",
      "\n",
      "Epoch: 328  Training loss = 1.4902  Test loss = 2.4353  \n",
      "\n",
      "Epoch: 329  Training loss = 1.4901  Test loss = 2.4352  \n",
      "\n",
      "Epoch: 330  Training loss = 1.4900  Test loss = 2.4351  \n",
      "\n",
      "Epoch: 331  Training loss = 1.4898  Test loss = 2.4351  \n",
      "\n",
      "Epoch: 332  Training loss = 1.4897  Test loss = 2.4350  \n",
      "\n",
      "Epoch: 333  Training loss = 1.4896  Test loss = 2.4349  \n",
      "\n",
      "Epoch: 334  Training loss = 1.4894  Test loss = 2.4348  \n",
      "\n",
      "Epoch: 335  Training loss = 1.4893  Test loss = 2.4348  \n",
      "\n",
      "Epoch: 336  Training loss = 1.4892  Test loss = 2.4347  \n",
      "\n",
      "Epoch: 337  Training loss = 1.4890  Test loss = 2.4346  \n",
      "\n",
      "Epoch: 338  Training loss = 1.4889  Test loss = 2.4346  \n",
      "\n",
      "Epoch: 339  Training loss = 1.4888  Test loss = 2.4345  \n",
      "\n",
      "Epoch: 340  Training loss = 1.4886  Test loss = 2.4344  \n",
      "\n",
      "Epoch: 341  Training loss = 1.4885  Test loss = 2.4344  \n",
      "\n",
      "Epoch: 342  Training loss = 1.4884  Test loss = 2.4343  \n",
      "\n",
      "Epoch: 343  Training loss = 1.4882  Test loss = 2.4342  \n",
      "\n",
      "Epoch: 344  Training loss = 1.4881  Test loss = 2.4341  \n",
      "\n",
      "Epoch: 345  Training loss = 1.4880  Test loss = 2.4341  \n",
      "\n",
      "Epoch: 346  Training loss = 1.4879  Test loss = 2.4340  \n",
      "\n",
      "Epoch: 347  Training loss = 1.4877  Test loss = 2.4339  \n",
      "\n",
      "Epoch: 348  Training loss = 1.4876  Test loss = 2.4339  \n",
      "\n",
      "Epoch: 349  Training loss = 1.4875  Test loss = 2.4338  \n",
      "\n",
      "Epoch: 350  Training loss = 1.4873  Test loss = 2.4337  \n",
      "\n",
      "Epoch: 351  Training loss = 1.4872  Test loss = 2.4337  \n",
      "\n",
      "Epoch: 352  Training loss = 1.4871  Test loss = 2.4336  \n",
      "\n",
      "Epoch: 353  Training loss = 1.4870  Test loss = 2.4335  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEHQMv4B2u+WMVTZ5DoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb788048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc8e1b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.43353796636 \n",
      "Fixed scheme MAE:  1.50139664894\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.4870  Test loss = 1.9576  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.4986  Test loss = 1.5563  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.4533  Test loss = 1.2226  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.4596  Test loss = 1.7137  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.3964  Test loss = 0.5984  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.3524  Test loss = 0.4002  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.3258  Test loss = 0.0057  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.2964  Test loss = 0.0998  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.2398  Test loss = 0.2142  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.2305  Test loss = 0.4155  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.1832  Test loss = 0.0116  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.1730  Test loss = 0.8854  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.1348  Test loss = 0.2096  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.1350  Test loss = 1.5873  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.1509  Test loss = 2.7469  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.1999  Test loss = 3.9146  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.2502  Test loss = 0.7699  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.2415  Test loss = 0.7930  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.2454  Test loss = 0.6809  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.1274  Test loss = 0.6091  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.1016  Test loss = 2.2835  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.1372  Test loss = 3.8446  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.2129  Test loss = 0.7752  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.2015  Test loss = 2.1590  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.1445  Test loss = 1.1529  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.1516  Test loss = 0.5019  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.1527  Test loss = 0.1979  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1439  Test loss = 2.5616  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.1197  Test loss = 0.7607  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.1165  Test loss = 1.0566  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.1187  Test loss = 4.3880  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.2334  Test loss = 1.3836  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.1567  Test loss = 0.9342  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.1594  Test loss = 0.6128  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.1348  Test loss = 0.1003  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.1207  Test loss = 4.8802  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.2278  Test loss = 0.9939  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2210  Test loss = 1.0833  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.1921  Test loss = 1.9043  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2152  Test loss = 1.6135  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.1802  Test loss = 0.5845  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.1819  Test loss = 1.1408  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.1888  Test loss = 2.3637  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.2211  Test loss = 13.4198  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0427  Test loss = 7.7259  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2531  Test loss = 1.9899  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2660  Test loss = 0.5271  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2669  Test loss = 1.0433  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.8476  Test loss = 2.5682  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.8639  Test loss = 0.3082  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.8638  Test loss = 1.5265  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.8726  Test loss = 0.5054  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.8327  Test loss = 1.4204  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.8411  Test loss = 2.6298  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.8687  Test loss = 0.7113  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.8621  Test loss = 0.9018  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.8345  Test loss = 0.9342  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.8365  Test loss = 2.6153  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.8627  Test loss = 0.3303  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.8629  Test loss = 0.5124  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.8357  Test loss = 0.9364  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.8348  Test loss = 2.4179  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.8571  Test loss = 0.3274  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.8495  Test loss = 0.4022  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.8287  Test loss = 0.0942  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.8285  Test loss = 0.1010  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.8269  Test loss = 1.5285  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.8367  Test loss = 1.9333  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.8364  Test loss = 4.5821  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.9224  Test loss = 0.0311  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.9222  Test loss = 0.5283  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.9150  Test loss = 2.2706  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.8972  Test loss = 2.3828  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.9197  Test loss = 1.7930  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.9276  Test loss = 1.5426  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.9343  Test loss = 0.1109  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.8755  Test loss = 1.6620  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsAdBEHQZUdiDIAi6jCjsQRAEXcY/z/Z4eCP8MnwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd505e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.45210556205 \n",
      "Updating scheme MAE:  1.55822430539\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
