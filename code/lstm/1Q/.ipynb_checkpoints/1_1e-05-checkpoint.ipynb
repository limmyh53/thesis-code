{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/1_cell/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 750\n",
    "learning_rate = 1e-5\n",
    "batch_size = 5\n",
    "early_stop_iters = 15\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 12 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell]*1, state_is_tuple = True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 12 \n",
      "Learning rate = 1e-05 \n",
      "Epochs = 750 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 15 \n",
      "Learning rate = 1e-05\n",
      "Fold: 1  Epoch: 1  Training loss = 3.1082  Validation loss = 3.1253  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.1078  Validation loss = 3.1243  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.1069  Validation loss = 3.1225  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.1063  Validation loss = 3.1213  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.1059  Validation loss = 3.1204  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.1052  Validation loss = 3.1189  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.1045  Validation loss = 3.1174  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.1040  Validation loss = 3.1164  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.1035  Validation loss = 3.1154  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.1030  Validation loss = 3.1143  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.1023  Validation loss = 3.1128  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.1017  Validation loss = 3.1117  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.1013  Validation loss = 3.1108  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.1007  Validation loss = 3.1096  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.1002  Validation loss = 3.1084  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.0995  Validation loss = 3.1069  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.0990  Validation loss = 3.1060  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.0985  Validation loss = 3.1049  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.0979  Validation loss = 3.1037  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.0975  Validation loss = 3.1028  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.0970  Validation loss = 3.1018  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.0963  Validation loss = 3.1004  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.0957  Validation loss = 3.0990  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.0952  Validation loss = 3.0980  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.0946  Validation loss = 3.0966  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.0940  Validation loss = 3.0954  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.0936  Validation loss = 3.0946  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.0930  Validation loss = 3.0933  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.0924  Validation loss = 3.0920  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.0919  Validation loss = 3.0908  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.0913  Validation loss = 3.0895  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.0905  Validation loss = 3.0880  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.0899  Validation loss = 3.0866  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.0894  Validation loss = 3.0855  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.0888  Validation loss = 3.0844  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.0884  Validation loss = 3.0836  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.0879  Validation loss = 3.0823  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.0875  Validation loss = 3.0814  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.0868  Validation loss = 3.0802  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.0862  Validation loss = 3.0789  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.0857  Validation loss = 3.0777  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.0850  Validation loss = 3.0763  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.0842  Validation loss = 3.0745  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.0835  Validation loss = 3.0730  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.0830  Validation loss = 3.0719  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.0823  Validation loss = 3.0704  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.0817  Validation loss = 3.0691  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.0811  Validation loss = 3.0679  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.0805  Validation loss = 3.0667  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.0800  Validation loss = 3.0655  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.0794  Validation loss = 3.0642  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.0790  Validation loss = 3.0633  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.0786  Validation loss = 3.0624  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.0780  Validation loss = 3.0611  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.0774  Validation loss = 3.0599  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.0769  Validation loss = 3.0587  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.0764  Validation loss = 3.0577  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.0757  Validation loss = 3.0561  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.0750  Validation loss = 3.0546  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.0743  Validation loss = 3.0531  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.0737  Validation loss = 3.0519  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.0731  Validation loss = 3.0506  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.0725  Validation loss = 3.0494  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.0720  Validation loss = 3.0482  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.0715  Validation loss = 3.0471  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.0709  Validation loss = 3.0457  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.0704  Validation loss = 3.0447  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.0700  Validation loss = 3.0438  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.0695  Validation loss = 3.0426  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.0690  Validation loss = 3.0415  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.0687  Validation loss = 3.0409  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.0682  Validation loss = 3.0397  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.0676  Validation loss = 3.0386  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.0671  Validation loss = 3.0375  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.0666  Validation loss = 3.0363  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.0659  Validation loss = 3.0347  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.0654  Validation loss = 3.0337  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.0649  Validation loss = 3.0327  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.0644  Validation loss = 3.0315  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.0638  Validation loss = 3.0302  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.0632  Validation loss = 3.0289  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.0627  Validation loss = 3.0278  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.0620  Validation loss = 3.0263  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.0616  Validation loss = 3.0253  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.0609  Validation loss = 3.0239  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.0603  Validation loss = 3.0225  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.0598  Validation loss = 3.0215  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.0593  Validation loss = 3.0203  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.0587  Validation loss = 3.0189  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.0582  Validation loss = 3.0178  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.0576  Validation loss = 3.0166  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.0570  Validation loss = 3.0151  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.0562  Validation loss = 3.0135  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.0558  Validation loss = 3.0126  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.0552  Validation loss = 3.0112  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.0547  Validation loss = 3.0101  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.0542  Validation loss = 3.0091  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.0537  Validation loss = 3.0080  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.0532  Validation loss = 3.0069  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.0529  Validation loss = 3.0060  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.0523  Validation loss = 3.0048  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.0518  Validation loss = 3.0036  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.0513  Validation loss = 3.0026  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.0507  Validation loss = 3.0013  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.0502  Validation loss = 3.0002  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.0498  Validation loss = 2.9993  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.0493  Validation loss = 2.9982  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.0488  Validation loss = 2.9970  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.0483  Validation loss = 2.9958  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.0479  Validation loss = 2.9950  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.0475  Validation loss = 2.9940  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.0471  Validation loss = 2.9932  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.0464  Validation loss = 2.9917  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.0457  Validation loss = 2.9900  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.0453  Validation loss = 2.9892  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.0450  Validation loss = 2.9885  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.0443  Validation loss = 2.9869  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.0440  Validation loss = 2.9862  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.0436  Validation loss = 2.9853  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.0431  Validation loss = 2.9843  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.0426  Validation loss = 2.9832  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.0422  Validation loss = 2.9821  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.0417  Validation loss = 2.9812  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.0412  Validation loss = 2.9800  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.0407  Validation loss = 2.9789  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.0402  Validation loss = 2.9776  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.0397  Validation loss = 2.9765  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.0392  Validation loss = 2.9754  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.0387  Validation loss = 2.9744  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.0382  Validation loss = 2.9731  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.0377  Validation loss = 2.9719  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.0371  Validation loss = 2.9707  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.0367  Validation loss = 2.9698  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.0363  Validation loss = 2.9688  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.0358  Validation loss = 2.9677  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.0353  Validation loss = 2.9665  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.0349  Validation loss = 2.9656  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.0344  Validation loss = 2.9645  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.0340  Validation loss = 2.9635  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.0335  Validation loss = 2.9625  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.0332  Validation loss = 2.9619  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.0326  Validation loss = 2.9604  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.0321  Validation loss = 2.9594  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.0316  Validation loss = 2.9581  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.0310  Validation loss = 2.9567  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.0304  Validation loss = 2.9555  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.0299  Validation loss = 2.9544  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.0291  Validation loss = 2.9525  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.0287  Validation loss = 2.9517  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.0281  Validation loss = 2.9503  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.0277  Validation loss = 2.9493  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.0272  Validation loss = 2.9481  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.0267  Validation loss = 2.9470  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.0263  Validation loss = 2.9462  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.0257  Validation loss = 2.9448  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.0252  Validation loss = 2.9435  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.0247  Validation loss = 2.9423  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.0243  Validation loss = 2.9414  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.0238  Validation loss = 2.9402  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.0233  Validation loss = 2.9392  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.0230  Validation loss = 2.9383  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.0223  Validation loss = 2.9368  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.0218  Validation loss = 2.9356  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.0211  Validation loss = 2.9340  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.0205  Validation loss = 2.9328  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.0202  Validation loss = 2.9320  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.0196  Validation loss = 2.9306  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.0190  Validation loss = 2.9291  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.0186  Validation loss = 2.9283  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.0181  Validation loss = 2.9272  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.0178  Validation loss = 2.9264  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.0172  Validation loss = 2.9251  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.0168  Validation loss = 2.9241  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.0163  Validation loss = 2.9228  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.0158  Validation loss = 2.9217  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.0152  Validation loss = 2.9203  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.0147  Validation loss = 2.9192  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.0142  Validation loss = 2.9180  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.0136  Validation loss = 2.9166  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.0131  Validation loss = 2.9155  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.0126  Validation loss = 2.9143  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.0122  Validation loss = 2.9134  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.0118  Validation loss = 2.9123  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.0114  Validation loss = 2.9116  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.0111  Validation loss = 2.9107  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.0106  Validation loss = 2.9097  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.0101  Validation loss = 2.9084  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.0098  Validation loss = 2.9077  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.0093  Validation loss = 2.9065  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.0088  Validation loss = 2.9054  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.0084  Validation loss = 2.9044  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.0080  Validation loss = 2.9033  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.0075  Validation loss = 2.9023  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.0070  Validation loss = 2.9012  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.0067  Validation loss = 2.9005  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.0061  Validation loss = 2.8991  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.0056  Validation loss = 2.8980  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.0052  Validation loss = 2.8970  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.0048  Validation loss = 2.8960  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.0043  Validation loss = 2.8948  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.0038  Validation loss = 2.8937  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.0033  Validation loss = 2.8924  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.0028  Validation loss = 2.8912  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.0024  Validation loss = 2.8902  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.0020  Validation loss = 2.8894  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.0015  Validation loss = 2.8882  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.0008  Validation loss = 2.8864  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.0003  Validation loss = 2.8853  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.0000  Validation loss = 2.8846  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 2.9993  Validation loss = 2.8831  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 2.9990  Validation loss = 2.8823  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 2.9984  Validation loss = 2.8807  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 2.9981  Validation loss = 2.8801  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 2.9976  Validation loss = 2.8789  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 2.9971  Validation loss = 2.8777  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 2.9966  Validation loss = 2.8766  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 2.9962  Validation loss = 2.8754  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 2.9958  Validation loss = 2.8745  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 2.9955  Validation loss = 2.8738  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 2.9952  Validation loss = 2.8731  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 2.9948  Validation loss = 2.8720  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 2.9944  Validation loss = 2.8712  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 2.9940  Validation loss = 2.8702  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 2.9936  Validation loss = 2.8692  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 2.9932  Validation loss = 2.8682  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 2.9929  Validation loss = 2.8675  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 2.9926  Validation loss = 2.8667  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 2.9921  Validation loss = 2.8657  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 2.9917  Validation loss = 2.8646  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 2.9911  Validation loss = 2.8634  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 2.9907  Validation loss = 2.8624  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 2.9903  Validation loss = 2.8612  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 2.9900  Validation loss = 2.8605  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 2.9892  Validation loss = 2.8588  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 2.9889  Validation loss = 2.8579  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 2.9884  Validation loss = 2.8567  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 2.9880  Validation loss = 2.8557  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 2.9877  Validation loss = 2.8550  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 2.9873  Validation loss = 2.8540  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 2.9869  Validation loss = 2.8531  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 2.9865  Validation loss = 2.8522  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 2.9860  Validation loss = 2.8510  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 2.9856  Validation loss = 2.8498  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 2.9853  Validation loss = 2.8492  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 2.9846  Validation loss = 2.8476  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 2.9843  Validation loss = 2.8467  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 2.9839  Validation loss = 2.8458  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 2.9835  Validation loss = 2.8449  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 2.9830  Validation loss = 2.8437  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 2.9827  Validation loss = 2.8428  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 2.9823  Validation loss = 2.8418  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 2.9819  Validation loss = 2.8409  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 2.9813  Validation loss = 2.8395  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 2.9808  Validation loss = 2.8383  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 2.9804  Validation loss = 2.8372  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 2.9799  Validation loss = 2.8359  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 2.9794  Validation loss = 2.8348  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 2.9788  Validation loss = 2.8333  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 2.9784  Validation loss = 2.8323  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 2.9779  Validation loss = 2.8310  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 2.9773  Validation loss = 2.8297  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 2.9768  Validation loss = 2.8284  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 2.9764  Validation loss = 2.8275  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 2.9762  Validation loss = 2.8268  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 2.9758  Validation loss = 2.8258  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 2.9755  Validation loss = 2.8250  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 2.9751  Validation loss = 2.8241  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 2.9747  Validation loss = 2.8230  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 2.9743  Validation loss = 2.8223  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 2.9737  Validation loss = 2.8207  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 2.9733  Validation loss = 2.8196  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 2.9729  Validation loss = 2.8186  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 2.9726  Validation loss = 2.8179  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 2.9723  Validation loss = 2.8172  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 2.9718  Validation loss = 2.8159  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 2.9714  Validation loss = 2.8150  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 2.9711  Validation loss = 2.8142  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 2.9709  Validation loss = 2.8137  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 2.9705  Validation loss = 2.8127  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 2.9701  Validation loss = 2.8116  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 2.9697  Validation loss = 2.8107  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 2.9693  Validation loss = 2.8098  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 2.9690  Validation loss = 2.8090  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 2.9686  Validation loss = 2.8081  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 2.9681  Validation loss = 2.8069  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 2.9677  Validation loss = 2.8059  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 2.9673  Validation loss = 2.8048  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 2.9670  Validation loss = 2.8041  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 2.9666  Validation loss = 2.8031  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 2.9663  Validation loss = 2.8022  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 2.9660  Validation loss = 2.8015  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 2.9655  Validation loss = 2.8003  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 2.9651  Validation loss = 2.7993  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 2.9646  Validation loss = 2.7980  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 2.9641  Validation loss = 2.7969  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 2.9636  Validation loss = 2.7955  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 2.9630  Validation loss = 2.7940  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 2.9626  Validation loss = 2.7931  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 2.9622  Validation loss = 2.7920  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 2.9618  Validation loss = 2.7911  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 2.9615  Validation loss = 2.7904  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 2.9611  Validation loss = 2.7893  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 2.9607  Validation loss = 2.7884  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 2.9605  Validation loss = 2.7878  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 2.9600  Validation loss = 2.7866  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 2.9596  Validation loss = 2.7855  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 2.9593  Validation loss = 2.7847  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 2.9587  Validation loss = 2.7832  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 2.9583  Validation loss = 2.7823  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 2.9579  Validation loss = 2.7813  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 2.9576  Validation loss = 2.7805  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 2.9571  Validation loss = 2.7793  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 2.9569  Validation loss = 2.7785  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 2.9564  Validation loss = 2.7773  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 2.9560  Validation loss = 2.7764  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 2.9556  Validation loss = 2.7753  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 2.9552  Validation loss = 2.7742  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 2.9548  Validation loss = 2.7733  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 2.9544  Validation loss = 2.7724  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 2.9542  Validation loss = 2.7717  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 2.9537  Validation loss = 2.7704  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 2.9532  Validation loss = 2.7693  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 2.9529  Validation loss = 2.7684  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 2.9525  Validation loss = 2.7673  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 2.9522  Validation loss = 2.7666  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 2.9520  Validation loss = 2.7661  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 2.9518  Validation loss = 2.7655  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 2.9513  Validation loss = 2.7644  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 2.9511  Validation loss = 2.7637  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 2.9508  Validation loss = 2.7629  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 2.9503  Validation loss = 2.7617  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 2.9499  Validation loss = 2.7606  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 2.9496  Validation loss = 2.7600  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 2.9494  Validation loss = 2.7594  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 2.9490  Validation loss = 2.7582  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 2.9485  Validation loss = 2.7571  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 2.9482  Validation loss = 2.7563  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 2.9477  Validation loss = 2.7550  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 2.9474  Validation loss = 2.7541  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 2.9471  Validation loss = 2.7534  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 2.9468  Validation loss = 2.7526  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 2.9464  Validation loss = 2.7516  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 2.9460  Validation loss = 2.7505  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 2.9457  Validation loss = 2.7498  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 2.9453  Validation loss = 2.7487  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 2.9449  Validation loss = 2.7477  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 2.9446  Validation loss = 2.7468  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 2.9442  Validation loss = 2.7459  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 2.9439  Validation loss = 2.7451  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 2.9436  Validation loss = 2.7442  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 2.9433  Validation loss = 2.7433  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 2.9429  Validation loss = 2.7425  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 2.9426  Validation loss = 2.7416  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 2.9423  Validation loss = 2.7408  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 2.9419  Validation loss = 2.7396  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 2.9415  Validation loss = 2.7386  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 2.9410  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 2.9405  Validation loss = 2.7362  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 2.9401  Validation loss = 2.7349  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 2.9397  Validation loss = 2.7342  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 2.9394  Validation loss = 2.7333  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 2.9390  Validation loss = 2.7323  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 2.9384  Validation loss = 2.7306  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 2.9381  Validation loss = 2.7297  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 2.9377  Validation loss = 2.7287  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 2.9374  Validation loss = 2.7278  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 2.9370  Validation loss = 2.7270  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 2.9367  Validation loss = 2.7262  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 2.9362  Validation loss = 2.7248  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 2.9359  Validation loss = 2.7241  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 2.9356  Validation loss = 2.7232  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 2.9353  Validation loss = 2.7223  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 2.9351  Validation loss = 2.7218  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 2.9347  Validation loss = 2.7208  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 2.9343  Validation loss = 2.7198  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 2.9339  Validation loss = 2.7187  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 2.9334  Validation loss = 2.7174  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 2.9332  Validation loss = 2.7168  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 2.9328  Validation loss = 2.7157  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 2.9324  Validation loss = 2.7147  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 2.9322  Validation loss = 2.7142  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 2.9319  Validation loss = 2.7134  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 2.9316  Validation loss = 2.7124  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 2.9312  Validation loss = 2.7116  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 2.9310  Validation loss = 2.7110  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 2.9307  Validation loss = 2.7103  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 2.9303  Validation loss = 2.7090  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 2.9299  Validation loss = 2.7079  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 2.9297  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 2.9292  Validation loss = 2.7061  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 2.9288  Validation loss = 2.7050  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 2.9285  Validation loss = 2.7042  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 2.9280  Validation loss = 2.7031  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 2.9277  Validation loss = 2.7021  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 2.9273  Validation loss = 2.7012  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 2.9270  Validation loss = 2.7003  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 2.9267  Validation loss = 2.6993  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 2.9264  Validation loss = 2.6986  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 2.9260  Validation loss = 2.6976  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 2.9256  Validation loss = 2.6966  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 2.9254  Validation loss = 2.6959  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 2.9250  Validation loss = 2.6948  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 2.9246  Validation loss = 2.6938  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 2.9242  Validation loss = 2.6928  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 2.9238  Validation loss = 2.6917  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 2.9236  Validation loss = 2.6910  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 2.9234  Validation loss = 2.6905  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 2.9231  Validation loss = 2.6897  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 2.9227  Validation loss = 2.6888  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 2.9225  Validation loss = 2.6883  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 2.9222  Validation loss = 2.6874  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 2.9220  Validation loss = 2.6867  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 2.9217  Validation loss = 2.6859  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 2.9214  Validation loss = 2.6852  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 2.9209  Validation loss = 2.6840  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 2.9207  Validation loss = 2.6834  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 2.9204  Validation loss = 2.6824  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 2.9201  Validation loss = 2.6816  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 2.9199  Validation loss = 2.6810  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 2.9196  Validation loss = 2.6803  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 2.9193  Validation loss = 2.6794  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 2.9191  Validation loss = 2.6789  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 2.9188  Validation loss = 2.6782  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 2.9185  Validation loss = 2.6772  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 2.9182  Validation loss = 2.6764  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 2.9179  Validation loss = 2.6757  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 2.9175  Validation loss = 2.6745  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 2.9173  Validation loss = 2.6740  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 2.9169  Validation loss = 2.6730  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 2.9165  Validation loss = 2.6718  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 2.9163  Validation loss = 2.6712  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 2.9160  Validation loss = 2.6705  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 2.9157  Validation loss = 2.6697  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 2.9153  Validation loss = 2.6685  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 2.9151  Validation loss = 2.6679  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 2.9147  Validation loss = 2.6669  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 2.9145  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 2.9142  Validation loss = 2.6653  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 2.9138  Validation loss = 2.6643  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 2.9135  Validation loss = 2.6634  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 2.9133  Validation loss = 2.6629  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 2.9131  Validation loss = 2.6623  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 2.9127  Validation loss = 2.6614  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 2.9124  Validation loss = 2.6604  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 2.9121  Validation loss = 2.6596  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 2.9117  Validation loss = 2.6584  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 2.9114  Validation loss = 2.6577  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 2.9111  Validation loss = 2.6569  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 2.9107  Validation loss = 2.6557  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 2.9105  Validation loss = 2.6553  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 2.9103  Validation loss = 2.6546  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 2.9100  Validation loss = 2.6538  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 2.9096  Validation loss = 2.6528  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 2.9094  Validation loss = 2.6520  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 2.9091  Validation loss = 2.6513  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 2.9087  Validation loss = 2.6501  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 2.9085  Validation loss = 2.6496  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 2.9082  Validation loss = 2.6488  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 2.9080  Validation loss = 2.6483  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 2.9076  Validation loss = 2.6471  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 2.9074  Validation loss = 2.6467  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 2.9070  Validation loss = 2.6454  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 2.9067  Validation loss = 2.6445  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 2.9064  Validation loss = 2.6436  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 2.9060  Validation loss = 2.6425  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 2.9056  Validation loss = 2.6415  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 2.9053  Validation loss = 2.6405  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 2.9051  Validation loss = 2.6401  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 2.9048  Validation loss = 2.6392  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 2.9043  Validation loss = 2.6377  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 2.9040  Validation loss = 2.6369  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 2.9036  Validation loss = 2.6358  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 2.9031  Validation loss = 2.6345  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 2.9028  Validation loss = 2.6336  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 2.9023  Validation loss = 2.6323  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 2.9019  Validation loss = 2.6312  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 2.9016  Validation loss = 2.6302  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 2.9013  Validation loss = 2.6295  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 2.9010  Validation loss = 2.6287  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 2.9004  Validation loss = 2.6272  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 2.9003  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 2.9001  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 2.8998  Validation loss = 2.6253  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 2.8995  Validation loss = 2.6244  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 2.8992  Validation loss = 2.6236  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 2.8990  Validation loss = 2.6230  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 2.8987  Validation loss = 2.6222  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 2.8984  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 2.8981  Validation loss = 2.6204  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 2.8978  Validation loss = 2.6195  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 2.8974  Validation loss = 2.6185  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 2.8972  Validation loss = 2.6178  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 2.8969  Validation loss = 2.6172  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 2.8967  Validation loss = 2.6166  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 2.8963  Validation loss = 2.6153  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 2.8960  Validation loss = 2.6144  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 2.8957  Validation loss = 2.6138  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 2.8954  Validation loss = 2.6128  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 2.8952  Validation loss = 2.6124  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 2.8949  Validation loss = 2.6114  \n",
      "\n",
      "Fold: 1  Epoch: 501  Training loss = 2.8946  Validation loss = 2.6106  \n",
      "\n",
      "Fold: 1  Epoch: 502  Training loss = 2.8944  Validation loss = 2.6099  \n",
      "\n",
      "Fold: 1  Epoch: 503  Training loss = 2.8941  Validation loss = 2.6092  \n",
      "\n",
      "Fold: 1  Epoch: 504  Training loss = 2.8938  Validation loss = 2.6083  \n",
      "\n",
      "Fold: 1  Epoch: 505  Training loss = 2.8937  Validation loss = 2.6081  \n",
      "\n",
      "Fold: 1  Epoch: 506  Training loss = 2.8936  Validation loss = 2.6076  \n",
      "\n",
      "Fold: 1  Epoch: 507  Training loss = 2.8933  Validation loss = 2.6069  \n",
      "\n",
      "Fold: 1  Epoch: 508  Training loss = 2.8931  Validation loss = 2.6063  \n",
      "\n",
      "Fold: 1  Epoch: 509  Training loss = 2.8928  Validation loss = 2.6055  \n",
      "\n",
      "Fold: 1  Epoch: 510  Training loss = 2.8927  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 1  Epoch: 511  Training loss = 2.8922  Validation loss = 2.6038  \n",
      "\n",
      "Fold: 1  Epoch: 512  Training loss = 2.8919  Validation loss = 2.6029  \n",
      "\n",
      "Fold: 1  Epoch: 513  Training loss = 2.8917  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 1  Epoch: 514  Training loss = 2.8913  Validation loss = 2.6012  \n",
      "\n",
      "Fold: 1  Epoch: 515  Training loss = 2.8912  Validation loss = 2.6008  \n",
      "\n",
      "Fold: 1  Epoch: 516  Training loss = 2.8910  Validation loss = 2.6003  \n",
      "\n",
      "Fold: 1  Epoch: 517  Training loss = 2.8908  Validation loss = 2.5996  \n",
      "\n",
      "Fold: 1  Epoch: 518  Training loss = 2.8904  Validation loss = 2.5983  \n",
      "\n",
      "Fold: 1  Epoch: 519  Training loss = 2.8900  Validation loss = 2.5971  \n",
      "\n",
      "Fold: 1  Epoch: 520  Training loss = 2.8899  Validation loss = 2.5970  \n",
      "\n",
      "Fold: 1  Epoch: 521  Training loss = 2.8898  Validation loss = 2.5966  \n",
      "\n",
      "Fold: 1  Epoch: 522  Training loss = 2.8896  Validation loss = 2.5961  \n",
      "\n",
      "Fold: 1  Epoch: 523  Training loss = 2.8892  Validation loss = 2.5949  \n",
      "\n",
      "Fold: 1  Epoch: 524  Training loss = 2.8884  Validation loss = 2.5928  \n",
      "\n",
      "Fold: 1  Epoch: 525  Training loss = 2.8881  Validation loss = 2.5919  \n",
      "\n",
      "Fold: 1  Epoch: 526  Training loss = 2.8878  Validation loss = 2.5909  \n",
      "\n",
      "Fold: 1  Epoch: 527  Training loss = 2.8875  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 1  Epoch: 528  Training loss = 2.8872  Validation loss = 2.5891  \n",
      "\n",
      "Fold: 1  Epoch: 529  Training loss = 2.8868  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 1  Epoch: 530  Training loss = 2.8865  Validation loss = 2.5870  \n",
      "\n",
      "Fold: 1  Epoch: 531  Training loss = 2.8862  Validation loss = 2.5863  \n",
      "\n",
      "Fold: 1  Epoch: 532  Training loss = 2.8858  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 1  Epoch: 533  Training loss = 2.8855  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 1  Epoch: 534  Training loss = 2.8851  Validation loss = 2.5829  \n",
      "\n",
      "Fold: 1  Epoch: 535  Training loss = 2.8847  Validation loss = 2.5819  \n",
      "\n",
      "Fold: 1  Epoch: 536  Training loss = 2.8844  Validation loss = 2.5811  \n",
      "\n",
      "Fold: 1  Epoch: 537  Training loss = 2.8841  Validation loss = 2.5801  \n",
      "\n",
      "Fold: 1  Epoch: 538  Training loss = 2.8839  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 1  Epoch: 539  Training loss = 2.8835  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 1  Epoch: 540  Training loss = 2.8832  Validation loss = 2.5775  \n",
      "\n",
      "Fold: 1  Epoch: 541  Training loss = 2.8830  Validation loss = 2.5769  \n",
      "\n",
      "Fold: 1  Epoch: 542  Training loss = 2.8826  Validation loss = 2.5757  \n",
      "\n",
      "Fold: 1  Epoch: 543  Training loss = 2.8820  Validation loss = 2.5741  \n",
      "\n",
      "Fold: 1  Epoch: 544  Training loss = 2.8818  Validation loss = 2.5735  \n",
      "\n",
      "Fold: 1  Epoch: 545  Training loss = 2.8816  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 1  Epoch: 546  Training loss = 2.8813  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 1  Epoch: 547  Training loss = 2.8810  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 1  Epoch: 548  Training loss = 2.8808  Validation loss = 2.5704  \n",
      "\n",
      "Fold: 1  Epoch: 549  Training loss = 2.8805  Validation loss = 2.5695  \n",
      "\n",
      "Fold: 1  Epoch: 550  Training loss = 2.8803  Validation loss = 2.5690  \n",
      "\n",
      "Fold: 1  Epoch: 551  Training loss = 2.8799  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 1  Epoch: 552  Training loss = 2.8798  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 1  Epoch: 553  Training loss = 2.8796  Validation loss = 2.5669  \n",
      "\n",
      "Fold: 1  Epoch: 554  Training loss = 2.8794  Validation loss = 2.5663  \n",
      "\n",
      "Fold: 1  Epoch: 555  Training loss = 2.8791  Validation loss = 2.5653  \n",
      "\n",
      "Fold: 1  Epoch: 556  Training loss = 2.8789  Validation loss = 2.5649  \n",
      "\n",
      "Fold: 1  Epoch: 557  Training loss = 2.8787  Validation loss = 2.5641  \n",
      "\n",
      "Fold: 1  Epoch: 558  Training loss = 2.8784  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 1  Epoch: 559  Training loss = 2.8783  Validation loss = 2.5629  \n",
      "\n",
      "Fold: 1  Epoch: 560  Training loss = 2.8780  Validation loss = 2.5621  \n",
      "\n",
      "Fold: 1  Epoch: 561  Training loss = 2.8778  Validation loss = 2.5616  \n",
      "\n",
      "Fold: 1  Epoch: 562  Training loss = 2.8777  Validation loss = 2.5612  \n",
      "\n",
      "Fold: 1  Epoch: 563  Training loss = 2.8774  Validation loss = 2.5605  \n",
      "\n",
      "Fold: 1  Epoch: 564  Training loss = 2.8772  Validation loss = 2.5598  \n",
      "\n",
      "Fold: 1  Epoch: 565  Training loss = 2.8770  Validation loss = 2.5592  \n",
      "\n",
      "Fold: 1  Epoch: 566  Training loss = 2.8767  Validation loss = 2.5581  \n",
      "\n",
      "Fold: 1  Epoch: 567  Training loss = 2.8762  Validation loss = 2.5568  \n",
      "\n",
      "Fold: 1  Epoch: 568  Training loss = 2.8759  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 1  Epoch: 569  Training loss = 2.8757  Validation loss = 2.5551  \n",
      "\n",
      "Fold: 1  Epoch: 570  Training loss = 2.8752  Validation loss = 2.5537  \n",
      "\n",
      "Fold: 1  Epoch: 571  Training loss = 2.8749  Validation loss = 2.5531  \n",
      "\n",
      "Fold: 1  Epoch: 572  Training loss = 2.8746  Validation loss = 2.5521  \n",
      "\n",
      "Fold: 1  Epoch: 573  Training loss = 2.8743  Validation loss = 2.5511  \n",
      "\n",
      "Fold: 1  Epoch: 574  Training loss = 2.8741  Validation loss = 2.5506  \n",
      "\n",
      "Fold: 1  Epoch: 575  Training loss = 2.8738  Validation loss = 2.5496  \n",
      "\n",
      "Fold: 1  Epoch: 576  Training loss = 2.8735  Validation loss = 2.5488  \n",
      "\n",
      "Fold: 1  Epoch: 577  Training loss = 2.8732  Validation loss = 2.5478  \n",
      "\n",
      "Fold: 1  Epoch: 578  Training loss = 2.8729  Validation loss = 2.5469  \n",
      "\n",
      "Fold: 1  Epoch: 579  Training loss = 2.8727  Validation loss = 2.5462  \n",
      "\n",
      "Fold: 1  Epoch: 580  Training loss = 2.8724  Validation loss = 2.5455  \n",
      "\n",
      "Fold: 1  Epoch: 581  Training loss = 2.8722  Validation loss = 2.5448  \n",
      "\n",
      "Fold: 1  Epoch: 582  Training loss = 2.8719  Validation loss = 2.5438  \n",
      "\n",
      "Fold: 1  Epoch: 583  Training loss = 2.8716  Validation loss = 2.5431  \n",
      "\n",
      "Fold: 1  Epoch: 584  Training loss = 2.8714  Validation loss = 2.5425  \n",
      "\n",
      "Fold: 1  Epoch: 585  Training loss = 2.8712  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 1  Epoch: 586  Training loss = 2.8708  Validation loss = 2.5406  \n",
      "\n",
      "Fold: 1  Epoch: 587  Training loss = 2.8705  Validation loss = 2.5397  \n",
      "\n",
      "Fold: 1  Epoch: 588  Training loss = 2.8702  Validation loss = 2.5388  \n",
      "\n",
      "Fold: 1  Epoch: 589  Training loss = 2.8700  Validation loss = 2.5383  \n",
      "\n",
      "Fold: 1  Epoch: 590  Training loss = 2.8698  Validation loss = 2.5376  \n",
      "\n",
      "Fold: 1  Epoch: 591  Training loss = 2.8695  Validation loss = 2.5368  \n",
      "\n",
      "Fold: 1  Epoch: 592  Training loss = 2.8693  Validation loss = 2.5362  \n",
      "\n",
      "Fold: 1  Epoch: 593  Training loss = 2.8691  Validation loss = 2.5356  \n",
      "\n",
      "Fold: 1  Epoch: 594  Training loss = 2.8689  Validation loss = 2.5349  \n",
      "\n",
      "Fold: 1  Epoch: 595  Training loss = 2.8687  Validation loss = 2.5342  \n",
      "\n",
      "Fold: 1  Epoch: 596  Training loss = 2.8686  Validation loss = 2.5338  \n",
      "\n",
      "Fold: 1  Epoch: 597  Training loss = 2.8683  Validation loss = 2.5331  \n",
      "\n",
      "Fold: 1  Epoch: 598  Training loss = 2.8681  Validation loss = 2.5323  \n",
      "\n",
      "Fold: 1  Epoch: 599  Training loss = 2.8679  Validation loss = 2.5317  \n",
      "\n",
      "Fold: 1  Epoch: 600  Training loss = 2.8675  Validation loss = 2.5304  \n",
      "\n",
      "Fold: 1  Epoch: 601  Training loss = 2.8672  Validation loss = 2.5296  \n",
      "\n",
      "Fold: 1  Epoch: 602  Training loss = 2.8670  Validation loss = 2.5290  \n",
      "\n",
      "Fold: 1  Epoch: 603  Training loss = 2.8668  Validation loss = 2.5284  \n",
      "\n",
      "Fold: 1  Epoch: 604  Training loss = 2.8667  Validation loss = 2.5280  \n",
      "\n",
      "Fold: 1  Epoch: 605  Training loss = 2.8664  Validation loss = 2.5273  \n",
      "\n",
      "Fold: 1  Epoch: 606  Training loss = 2.8661  Validation loss = 2.5264  \n",
      "\n",
      "Fold: 1  Epoch: 607  Training loss = 2.8660  Validation loss = 2.5260  \n",
      "\n",
      "Fold: 1  Epoch: 608  Training loss = 2.8657  Validation loss = 2.5251  \n",
      "\n",
      "Fold: 1  Epoch: 609  Training loss = 2.8655  Validation loss = 2.5245  \n",
      "\n",
      "Fold: 1  Epoch: 610  Training loss = 2.8651  Validation loss = 2.5234  \n",
      "\n",
      "Fold: 1  Epoch: 611  Training loss = 2.8650  Validation loss = 2.5229  \n",
      "\n",
      "Fold: 1  Epoch: 612  Training loss = 2.8647  Validation loss = 2.5221  \n",
      "\n",
      "Fold: 1  Epoch: 613  Training loss = 2.8646  Validation loss = 2.5217  \n",
      "\n",
      "Fold: 1  Epoch: 614  Training loss = 2.8643  Validation loss = 2.5207  \n",
      "\n",
      "Fold: 1  Epoch: 615  Training loss = 2.8640  Validation loss = 2.5199  \n",
      "\n",
      "Fold: 1  Epoch: 616  Training loss = 2.8637  Validation loss = 2.5190  \n",
      "\n",
      "Fold: 1  Epoch: 617  Training loss = 2.8635  Validation loss = 2.5183  \n",
      "\n",
      "Fold: 1  Epoch: 618  Training loss = 2.8633  Validation loss = 2.5176  \n",
      "\n",
      "Fold: 1  Epoch: 619  Training loss = 2.8628  Validation loss = 2.5163  \n",
      "\n",
      "Fold: 1  Epoch: 620  Training loss = 2.8627  Validation loss = 2.5160  \n",
      "\n",
      "Fold: 1  Epoch: 621  Training loss = 2.8624  Validation loss = 2.5149  \n",
      "\n",
      "Fold: 1  Epoch: 622  Training loss = 2.8621  Validation loss = 2.5142  \n",
      "\n",
      "Fold: 1  Epoch: 623  Training loss = 2.8617  Validation loss = 2.5129  \n",
      "\n",
      "Fold: 1  Epoch: 624  Training loss = 2.8615  Validation loss = 2.5124  \n",
      "\n",
      "Fold: 1  Epoch: 625  Training loss = 2.8613  Validation loss = 2.5115  \n",
      "\n",
      "Fold: 1  Epoch: 626  Training loss = 2.8610  Validation loss = 2.5108  \n",
      "\n",
      "Fold: 1  Epoch: 627  Training loss = 2.8608  Validation loss = 2.5101  \n",
      "\n",
      "Fold: 1  Epoch: 628  Training loss = 2.8606  Validation loss = 2.5095  \n",
      "\n",
      "Fold: 1  Epoch: 629  Training loss = 2.8603  Validation loss = 2.5085  \n",
      "\n",
      "Fold: 1  Epoch: 630  Training loss = 2.8602  Validation loss = 2.5081  \n",
      "\n",
      "Fold: 1  Epoch: 631  Training loss = 2.8601  Validation loss = 2.5077  \n",
      "\n",
      "Fold: 1  Epoch: 632  Training loss = 2.8598  Validation loss = 2.5069  \n",
      "\n",
      "Fold: 1  Epoch: 633  Training loss = 2.8595  Validation loss = 2.5060  \n",
      "\n",
      "Fold: 1  Epoch: 634  Training loss = 2.8593  Validation loss = 2.5053  \n",
      "\n",
      "Fold: 1  Epoch: 635  Training loss = 2.8589  Validation loss = 2.5042  \n",
      "\n",
      "Fold: 1  Epoch: 636  Training loss = 2.8586  Validation loss = 2.5032  \n",
      "\n",
      "Fold: 1  Epoch: 637  Training loss = 2.8583  Validation loss = 2.5023  \n",
      "\n",
      "Fold: 1  Epoch: 638  Training loss = 2.8582  Validation loss = 2.5018  \n",
      "\n",
      "Fold: 1  Epoch: 639  Training loss = 2.8579  Validation loss = 2.5011  \n",
      "\n",
      "Fold: 1  Epoch: 640  Training loss = 2.8577  Validation loss = 2.5005  \n",
      "\n",
      "Fold: 1  Epoch: 641  Training loss = 2.8575  Validation loss = 2.4998  \n",
      "\n",
      "Fold: 1  Epoch: 642  Training loss = 2.8573  Validation loss = 2.4991  \n",
      "\n",
      "Fold: 1  Epoch: 643  Training loss = 2.8571  Validation loss = 2.4986  \n",
      "\n",
      "Fold: 1  Epoch: 644  Training loss = 2.8568  Validation loss = 2.4977  \n",
      "\n",
      "Fold: 1  Epoch: 645  Training loss = 2.8566  Validation loss = 2.4969  \n",
      "\n",
      "Fold: 1  Epoch: 646  Training loss = 2.8563  Validation loss = 2.4961  \n",
      "\n",
      "Fold: 1  Epoch: 647  Training loss = 2.8562  Validation loss = 2.4957  \n",
      "\n",
      "Fold: 1  Epoch: 648  Training loss = 2.8558  Validation loss = 2.4943  \n",
      "\n",
      "Fold: 1  Epoch: 649  Training loss = 2.8556  Validation loss = 2.4937  \n",
      "\n",
      "Fold: 1  Epoch: 650  Training loss = 2.8552  Validation loss = 2.4925  \n",
      "\n",
      "Fold: 1  Epoch: 651  Training loss = 2.8549  Validation loss = 2.4918  \n",
      "\n",
      "Fold: 1  Epoch: 652  Training loss = 2.8545  Validation loss = 2.4905  \n",
      "\n",
      "Fold: 1  Epoch: 653  Training loss = 2.8543  Validation loss = 2.4896  \n",
      "\n",
      "Fold: 1  Epoch: 654  Training loss = 2.8541  Validation loss = 2.4890  \n",
      "\n",
      "Fold: 1  Epoch: 655  Training loss = 2.8539  Validation loss = 2.4884  \n",
      "\n",
      "Fold: 1  Epoch: 656  Training loss = 2.8536  Validation loss = 2.4875  \n",
      "\n",
      "Fold: 1  Epoch: 657  Training loss = 2.8533  Validation loss = 2.4866  \n",
      "\n",
      "Fold: 1  Epoch: 658  Training loss = 2.8531  Validation loss = 2.4859  \n",
      "\n",
      "Fold: 1  Epoch: 659  Training loss = 2.8527  Validation loss = 2.4846  \n",
      "\n",
      "Fold: 1  Epoch: 660  Training loss = 2.8525  Validation loss = 2.4840  \n",
      "\n",
      "Fold: 1  Epoch: 661  Training loss = 2.8522  Validation loss = 2.4830  \n",
      "\n",
      "Fold: 1  Epoch: 662  Training loss = 2.8518  Validation loss = 2.4817  \n",
      "\n",
      "Fold: 1  Epoch: 663  Training loss = 2.8516  Validation loss = 2.4811  \n",
      "\n",
      "Fold: 1  Epoch: 664  Training loss = 2.8513  Validation loss = 2.4802  \n",
      "\n",
      "Fold: 1  Epoch: 665  Training loss = 2.8511  Validation loss = 2.4797  \n",
      "\n",
      "Fold: 1  Epoch: 666  Training loss = 2.8509  Validation loss = 2.4790  \n",
      "\n",
      "Fold: 1  Epoch: 667  Training loss = 2.8508  Validation loss = 2.4786  \n",
      "\n",
      "Fold: 1  Epoch: 668  Training loss = 2.8507  Validation loss = 2.4783  \n",
      "\n",
      "Fold: 1  Epoch: 669  Training loss = 2.8504  Validation loss = 2.4773  \n",
      "\n",
      "Fold: 1  Epoch: 670  Training loss = 2.8500  Validation loss = 2.4762  \n",
      "\n",
      "Fold: 1  Epoch: 671  Training loss = 2.8497  Validation loss = 2.4753  \n",
      "\n",
      "Fold: 1  Epoch: 672  Training loss = 2.8494  Validation loss = 2.4740  \n",
      "\n",
      "Fold: 1  Epoch: 673  Training loss = 2.8491  Validation loss = 2.4733  \n",
      "\n",
      "Fold: 1  Epoch: 674  Training loss = 2.8489  Validation loss = 2.4725  \n",
      "\n",
      "Fold: 1  Epoch: 675  Training loss = 2.8486  Validation loss = 2.4717  \n",
      "\n",
      "Fold: 1  Epoch: 676  Training loss = 2.8482  Validation loss = 2.4705  \n",
      "\n",
      "Fold: 1  Epoch: 677  Training loss = 2.8481  Validation loss = 2.4700  \n",
      "\n",
      "Fold: 1  Epoch: 678  Training loss = 2.8477  Validation loss = 2.4690  \n",
      "\n",
      "Fold: 1  Epoch: 679  Training loss = 2.8475  Validation loss = 2.4681  \n",
      "\n",
      "Fold: 1  Epoch: 680  Training loss = 2.8474  Validation loss = 2.4680  \n",
      "\n",
      "Fold: 1  Epoch: 681  Training loss = 2.8473  Validation loss = 2.4675  \n",
      "\n",
      "Fold: 1  Epoch: 682  Training loss = 2.8471  Validation loss = 2.4668  \n",
      "\n",
      "Fold: 1  Epoch: 683  Training loss = 2.8470  Validation loss = 2.4664  \n",
      "\n",
      "Fold: 1  Epoch: 684  Training loss = 2.8465  Validation loss = 2.4651  \n",
      "\n",
      "Fold: 1  Epoch: 685  Training loss = 2.8463  Validation loss = 2.4642  \n",
      "\n",
      "Fold: 1  Epoch: 686  Training loss = 2.8461  Validation loss = 2.4637  \n",
      "\n",
      "Fold: 1  Epoch: 687  Training loss = 2.8458  Validation loss = 2.4629  \n",
      "\n",
      "Fold: 1  Epoch: 688  Training loss = 2.8455  Validation loss = 2.4620  \n",
      "\n",
      "Fold: 1  Epoch: 689  Training loss = 2.8454  Validation loss = 2.4613  \n",
      "\n",
      "Fold: 1  Epoch: 690  Training loss = 2.8452  Validation loss = 2.4607  \n",
      "\n",
      "Fold: 1  Epoch: 691  Training loss = 2.8450  Validation loss = 2.4601  \n",
      "\n",
      "Fold: 1  Epoch: 692  Training loss = 2.8449  Validation loss = 2.4598  \n",
      "\n",
      "Fold: 1  Epoch: 693  Training loss = 2.8446  Validation loss = 2.4589  \n",
      "\n",
      "Fold: 1  Epoch: 694  Training loss = 2.8443  Validation loss = 2.4580  \n",
      "\n",
      "Fold: 1  Epoch: 695  Training loss = 2.8442  Validation loss = 2.4575  \n",
      "\n",
      "Fold: 1  Epoch: 696  Training loss = 2.8439  Validation loss = 2.4566  \n",
      "\n",
      "Fold: 1  Epoch: 697  Training loss = 2.8437  Validation loss = 2.4560  \n",
      "\n",
      "Fold: 1  Epoch: 698  Training loss = 2.8435  Validation loss = 2.4554  \n",
      "\n",
      "Fold: 1  Epoch: 699  Training loss = 2.8433  Validation loss = 2.4545  \n",
      "\n",
      "Fold: 1  Epoch: 700  Training loss = 2.8431  Validation loss = 2.4540  \n",
      "\n",
      "Fold: 1  Epoch: 701  Training loss = 2.8428  Validation loss = 2.4532  \n",
      "\n",
      "Fold: 1  Epoch: 702  Training loss = 2.8427  Validation loss = 2.4527  \n",
      "\n",
      "Fold: 1  Epoch: 703  Training loss = 2.8425  Validation loss = 2.4521  \n",
      "\n",
      "Fold: 1  Epoch: 704  Training loss = 2.8422  Validation loss = 2.4512  \n",
      "\n",
      "Fold: 1  Epoch: 705  Training loss = 2.8420  Validation loss = 2.4503  \n",
      "\n",
      "Fold: 1  Epoch: 706  Training loss = 2.8418  Validation loss = 2.4499  \n",
      "\n",
      "Fold: 1  Epoch: 707  Training loss = 2.8416  Validation loss = 2.4491  \n",
      "\n",
      "Fold: 1  Epoch: 708  Training loss = 2.8414  Validation loss = 2.4485  \n",
      "\n",
      "Fold: 1  Epoch: 709  Training loss = 2.8412  Validation loss = 2.4479  \n",
      "\n",
      "Fold: 1  Epoch: 710  Training loss = 2.8408  Validation loss = 2.4465  \n",
      "\n",
      "Fold: 1  Epoch: 711  Training loss = 2.8405  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 1  Epoch: 712  Training loss = 2.8404  Validation loss = 2.4453  \n",
      "\n",
      "Fold: 1  Epoch: 713  Training loss = 2.8401  Validation loss = 2.4444  \n",
      "\n",
      "Fold: 1  Epoch: 714  Training loss = 2.8399  Validation loss = 2.4437  \n",
      "\n",
      "Fold: 1  Epoch: 715  Training loss = 2.8398  Validation loss = 2.4432  \n",
      "\n",
      "Fold: 1  Epoch: 716  Training loss = 2.8395  Validation loss = 2.4423  \n",
      "\n",
      "Fold: 1  Epoch: 717  Training loss = 2.8392  Validation loss = 2.4415  \n",
      "\n",
      "Fold: 1  Epoch: 718  Training loss = 2.8391  Validation loss = 2.4410  \n",
      "\n",
      "Fold: 1  Epoch: 719  Training loss = 2.8389  Validation loss = 2.4405  \n",
      "\n",
      "Fold: 1  Epoch: 720  Training loss = 2.8388  Validation loss = 2.4399  \n",
      "\n",
      "Fold: 1  Epoch: 721  Training loss = 2.8384  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 1  Epoch: 722  Training loss = 2.8383  Validation loss = 2.4383  \n",
      "\n",
      "Fold: 1  Epoch: 723  Training loss = 2.8381  Validation loss = 2.4378  \n",
      "\n",
      "Fold: 1  Epoch: 724  Training loss = 2.8380  Validation loss = 2.4374  \n",
      "\n",
      "Fold: 1  Epoch: 725  Training loss = 2.8378  Validation loss = 2.4366  \n",
      "\n",
      "Fold: 1  Epoch: 726  Training loss = 2.8375  Validation loss = 2.4358  \n",
      "\n",
      "Fold: 1  Epoch: 727  Training loss = 2.8371  Validation loss = 2.4343  \n",
      "\n",
      "Fold: 1  Epoch: 728  Training loss = 2.8369  Validation loss = 2.4337  \n",
      "\n",
      "Fold: 1  Epoch: 729  Training loss = 2.8366  Validation loss = 2.4326  \n",
      "\n",
      "Fold: 1  Epoch: 730  Training loss = 2.8363  Validation loss = 2.4319  \n",
      "\n",
      "Fold: 1  Epoch: 731  Training loss = 2.8362  Validation loss = 2.4315  \n",
      "\n",
      "Fold: 1  Epoch: 732  Training loss = 2.8361  Validation loss = 2.4309  \n",
      "\n",
      "Fold: 1  Epoch: 733  Training loss = 2.8359  Validation loss = 2.4305  \n",
      "\n",
      "Fold: 1  Epoch: 734  Training loss = 2.8357  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 1  Epoch: 735  Training loss = 2.8355  Validation loss = 2.4291  \n",
      "\n",
      "Fold: 1  Epoch: 736  Training loss = 2.8353  Validation loss = 2.4284  \n",
      "\n",
      "Fold: 1  Epoch: 737  Training loss = 2.8351  Validation loss = 2.4277  \n",
      "\n",
      "Fold: 1  Epoch: 738  Training loss = 2.8348  Validation loss = 2.4270  \n",
      "\n",
      "Fold: 1  Epoch: 739  Training loss = 2.8345  Validation loss = 2.4259  \n",
      "\n",
      "Fold: 1  Epoch: 740  Training loss = 2.8343  Validation loss = 2.4252  \n",
      "\n",
      "Fold: 1  Epoch: 741  Training loss = 2.8340  Validation loss = 2.4242  \n",
      "\n",
      "Fold: 1  Epoch: 742  Training loss = 2.8338  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 1  Epoch: 743  Training loss = 2.8336  Validation loss = 2.4228  \n",
      "\n",
      "Fold: 1  Epoch: 744  Training loss = 2.8333  Validation loss = 2.4220  \n",
      "\n",
      "Fold: 1  Epoch: 745  Training loss = 2.8331  Validation loss = 2.4212  \n",
      "\n",
      "Fold: 1  Epoch: 746  Training loss = 2.8328  Validation loss = 2.4202  \n",
      "\n",
      "Fold: 1  Epoch: 747  Training loss = 2.8326  Validation loss = 2.4194  \n",
      "\n",
      "Fold: 1  Epoch: 748  Training loss = 2.8321  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 1  Epoch: 749  Training loss = 2.8319  Validation loss = 2.4172  \n",
      "\n",
      "Fold: 1  Epoch: 750  Training loss = 2.8317  Validation loss = 2.4166  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 750  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.7477  Validation loss = 2.7295  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.7473  Validation loss = 2.7287  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.7469  Validation loss = 2.7277  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.7466  Validation loss = 2.7271  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.7462  Validation loss = 2.7262  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.7458  Validation loss = 2.7253  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.7457  Validation loss = 2.7250  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.7454  Validation loss = 2.7242  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.7450  Validation loss = 2.7233  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.7447  Validation loss = 2.7227  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.7444  Validation loss = 2.7220  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.7442  Validation loss = 2.7213  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.7440  Validation loss = 2.7206  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.7438  Validation loss = 2.7199  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.7435  Validation loss = 2.7193  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.7434  Validation loss = 2.7189  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.7430  Validation loss = 2.7179  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.7428  Validation loss = 2.7175  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.7425  Validation loss = 2.7169  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.7423  Validation loss = 2.7162  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.7421  Validation loss = 2.7159  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.7419  Validation loss = 2.7154  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.7416  Validation loss = 2.7146  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.7415  Validation loss = 2.7142  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.7413  Validation loss = 2.7137  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.7412  Validation loss = 2.7134  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.7409  Validation loss = 2.7127  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.7406  Validation loss = 2.7120  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.7404  Validation loss = 2.7114  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.7401  Validation loss = 2.7108  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.7398  Validation loss = 2.7101  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.7395  Validation loss = 2.7093  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.7393  Validation loss = 2.7088  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.7392  Validation loss = 2.7085  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.7390  Validation loss = 2.7081  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.7388  Validation loss = 2.7075  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.7385  Validation loss = 2.7066  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.7383  Validation loss = 2.7062  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.7381  Validation loss = 2.7056  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.7380  Validation loss = 2.7053  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.7379  Validation loss = 2.7050  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.7377  Validation loss = 2.7043  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.7375  Validation loss = 2.7037  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.7372  Validation loss = 2.7031  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.7369  Validation loss = 2.7023  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.7366  Validation loss = 2.7015  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.7366  Validation loss = 2.7015  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.7364  Validation loss = 2.7010  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.7361  Validation loss = 2.7002  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.7359  Validation loss = 2.6997  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.7358  Validation loss = 2.6992  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.7356  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.7354  Validation loss = 2.6982  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.7353  Validation loss = 2.6978  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.7349  Validation loss = 2.6970  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.7346  Validation loss = 2.6962  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.7342  Validation loss = 2.6952  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.7340  Validation loss = 2.6946  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.7337  Validation loss = 2.6939  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.7335  Validation loss = 2.6934  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.7332  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.7328  Validation loss = 2.6917  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.7326  Validation loss = 2.6913  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.7323  Validation loss = 2.6906  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.7323  Validation loss = 2.6903  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.7320  Validation loss = 2.6893  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.7318  Validation loss = 2.6889  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.7317  Validation loss = 2.6885  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.7314  Validation loss = 2.6878  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.7313  Validation loss = 2.6875  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.7310  Validation loss = 2.6869  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.7308  Validation loss = 2.6863  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.7304  Validation loss = 2.6853  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.7302  Validation loss = 2.6846  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.7300  Validation loss = 2.6841  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.7297  Validation loss = 2.6833  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.7296  Validation loss = 2.6831  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.7293  Validation loss = 2.6822  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.7291  Validation loss = 2.6816  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.7288  Validation loss = 2.6809  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.7286  Validation loss = 2.6805  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.7285  Validation loss = 2.6801  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.7282  Validation loss = 2.6792  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.7280  Validation loss = 2.6787  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.7279  Validation loss = 2.6783  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.7276  Validation loss = 2.6776  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.7274  Validation loss = 2.6768  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.7272  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.7268  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.7266  Validation loss = 2.6748  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.7263  Validation loss = 2.6742  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.7262  Validation loss = 2.6737  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.7260  Validation loss = 2.6733  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.7259  Validation loss = 2.6728  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.7258  Validation loss = 2.6725  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.7256  Validation loss = 2.6720  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.7255  Validation loss = 2.6717  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.7253  Validation loss = 2.6711  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.7251  Validation loss = 2.6707  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.7250  Validation loss = 2.6703  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.7249  Validation loss = 2.6700  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.7247  Validation loss = 2.6695  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.7244  Validation loss = 2.6688  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.7242  Validation loss = 2.6682  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.7239  Validation loss = 2.6675  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.7238  Validation loss = 2.6670  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.7234  Validation loss = 2.6662  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.7230  Validation loss = 2.6653  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.7228  Validation loss = 2.6648  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.7226  Validation loss = 2.6642  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.7224  Validation loss = 2.6636  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.7222  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.7220  Validation loss = 2.6625  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.7218  Validation loss = 2.6620  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.7215  Validation loss = 2.6613  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.7213  Validation loss = 2.6607  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.7211  Validation loss = 2.6602  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.7210  Validation loss = 2.6598  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.7208  Validation loss = 2.6592  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.7205  Validation loss = 2.6585  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.7204  Validation loss = 2.6581  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.7200  Validation loss = 2.6572  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.7199  Validation loss = 2.6567  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.7195  Validation loss = 2.6557  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.7194  Validation loss = 2.6553  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.7193  Validation loss = 2.6549  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.7192  Validation loss = 2.6545  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.7189  Validation loss = 2.6539  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.7185  Validation loss = 2.6529  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.7183  Validation loss = 2.6523  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.7180  Validation loss = 2.6515  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.7178  Validation loss = 2.6510  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.7176  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.7173  Validation loss = 2.6496  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.7172  Validation loss = 2.6493  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.7169  Validation loss = 2.6486  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.7167  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.7166  Validation loss = 2.6476  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.7165  Validation loss = 2.6474  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.7164  Validation loss = 2.6470  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.7162  Validation loss = 2.6464  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.7161  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.7157  Validation loss = 2.6451  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.7156  Validation loss = 2.6448  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.7153  Validation loss = 2.6441  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.7150  Validation loss = 2.6435  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.7149  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.7146  Validation loss = 2.6421  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.7143  Validation loss = 2.6414  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.7140  Validation loss = 2.6406  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.7138  Validation loss = 2.6402  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.7137  Validation loss = 2.6398  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.7135  Validation loss = 2.6393  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.7133  Validation loss = 2.6389  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.7132  Validation loss = 2.6384  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.7130  Validation loss = 2.6378  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.7129  Validation loss = 2.6374  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.7127  Validation loss = 2.6367  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.7126  Validation loss = 2.6364  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.7123  Validation loss = 2.6357  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.7120  Validation loss = 2.6349  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.7118  Validation loss = 2.6344  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.7116  Validation loss = 2.6338  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.7114  Validation loss = 2.6332  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.7111  Validation loss = 2.6325  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.7110  Validation loss = 2.6323  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.7107  Validation loss = 2.6317  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.7103  Validation loss = 2.6305  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.7101  Validation loss = 2.6300  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.7100  Validation loss = 2.6295  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.7099  Validation loss = 2.6292  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.7097  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.7096  Validation loss = 2.6284  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.7095  Validation loss = 2.6280  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.7091  Validation loss = 2.6271  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.7089  Validation loss = 2.6266  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.7088  Validation loss = 2.6263  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.7087  Validation loss = 2.6260  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.7085  Validation loss = 2.6256  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.7083  Validation loss = 2.6251  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.7081  Validation loss = 2.6246  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.7079  Validation loss = 2.6239  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.7077  Validation loss = 2.6235  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.7076  Validation loss = 2.6232  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.7075  Validation loss = 2.6227  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.7073  Validation loss = 2.6224  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.7072  Validation loss = 2.6218  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.7070  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.7068  Validation loss = 2.6208  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.7067  Validation loss = 2.6203  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.7064  Validation loss = 2.6194  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.7062  Validation loss = 2.6189  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.7061  Validation loss = 2.6185  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.7060  Validation loss = 2.6182  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.7059  Validation loss = 2.6178  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.7056  Validation loss = 2.6170  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.7053  Validation loss = 2.6162  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.7052  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.7049  Validation loss = 2.6152  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.7048  Validation loss = 2.6147  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.7045  Validation loss = 2.6138  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.7042  Validation loss = 2.6131  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.7040  Validation loss = 2.6124  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.7038  Validation loss = 2.6118  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.7036  Validation loss = 2.6112  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.7033  Validation loss = 2.6104  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.7031  Validation loss = 2.6099  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.7030  Validation loss = 2.6097  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.7028  Validation loss = 2.6091  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.7027  Validation loss = 2.6087  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.7024  Validation loss = 2.6080  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.7022  Validation loss = 2.6074  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.7020  Validation loss = 2.6069  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.7018  Validation loss = 2.6062  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.7015  Validation loss = 2.6055  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.7014  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.7013  Validation loss = 2.6049  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.7012  Validation loss = 2.6044  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.7010  Validation loss = 2.6040  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.7008  Validation loss = 2.6035  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.7006  Validation loss = 2.6028  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.7003  Validation loss = 2.6019  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.7002  Validation loss = 2.6015  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.7000  Validation loss = 2.6012  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.6999  Validation loss = 2.6007  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.6998  Validation loss = 2.6003  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.6996  Validation loss = 2.5997  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.6994  Validation loss = 2.5991  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.6992  Validation loss = 2.5986  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.6991  Validation loss = 2.5983  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.6991  Validation loss = 2.5982  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.6989  Validation loss = 2.5977  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.6988  Validation loss = 2.5973  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.6986  Validation loss = 2.5967  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.6985  Validation loss = 2.5961  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.6983  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.6981  Validation loss = 2.5951  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.6979  Validation loss = 2.5947  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.6977  Validation loss = 2.5942  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.6977  Validation loss = 2.5939  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.6974  Validation loss = 2.5933  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.6974  Validation loss = 2.5931  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.6971  Validation loss = 2.5923  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.6969  Validation loss = 2.5917  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.6967  Validation loss = 2.5910  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.6965  Validation loss = 2.5904  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.6963  Validation loss = 2.5899  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.6961  Validation loss = 2.5892  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.6957  Validation loss = 2.5882  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.6955  Validation loss = 2.5877  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.6953  Validation loss = 2.5872  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.6952  Validation loss = 2.5867  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.6949  Validation loss = 2.5860  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.6947  Validation loss = 2.5854  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.6945  Validation loss = 2.5850  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.6943  Validation loss = 2.5843  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.6941  Validation loss = 2.5838  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.6940  Validation loss = 2.5836  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.6939  Validation loss = 2.5830  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.6937  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.6936  Validation loss = 2.5822  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.6933  Validation loss = 2.5814  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.6932  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.6931  Validation loss = 2.5808  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.6928  Validation loss = 2.5801  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.6926  Validation loss = 2.5795  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.6925  Validation loss = 2.5792  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.6923  Validation loss = 2.5787  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.6921  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.6920  Validation loss = 2.5778  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.6918  Validation loss = 2.5773  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.6917  Validation loss = 2.5769  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.6915  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.6914  Validation loss = 2.5758  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.6911  Validation loss = 2.5751  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.6909  Validation loss = 2.5744  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.6907  Validation loss = 2.5740  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.6905  Validation loss = 2.5732  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.6903  Validation loss = 2.5726  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.6901  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.6899  Validation loss = 2.5715  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.6898  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.6896  Validation loss = 2.5702  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.6894  Validation loss = 2.5697  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.6892  Validation loss = 2.5690  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.6889  Validation loss = 2.5683  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.6888  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.6885  Validation loss = 2.5670  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.6883  Validation loss = 2.5664  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.6882  Validation loss = 2.5660  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.6881  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.6879  Validation loss = 2.5648  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.6878  Validation loss = 2.5646  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.6877  Validation loss = 2.5644  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.6875  Validation loss = 2.5638  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.6873  Validation loss = 2.5632  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.6872  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.6870  Validation loss = 2.5622  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.6869  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.6867  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.6864  Validation loss = 2.5604  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.6863  Validation loss = 2.5601  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.6861  Validation loss = 2.5596  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.6859  Validation loss = 2.5588  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.6857  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.6856  Validation loss = 2.5577  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.6853  Validation loss = 2.5572  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.6852  Validation loss = 2.5566  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.6850  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.6848  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.6846  Validation loss = 2.5548  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.6844  Validation loss = 2.5543  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.6842  Validation loss = 2.5537  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.6841  Validation loss = 2.5533  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.6840  Validation loss = 2.5529  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.6838  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.6837  Validation loss = 2.5519  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.6834  Validation loss = 2.5509  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.6833  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.6829  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.6828  Validation loss = 2.5491  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.6825  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.6824  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.6820  Validation loss = 2.5468  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.6817  Validation loss = 2.5459  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.6816  Validation loss = 2.5457  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.6815  Validation loss = 2.5453  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.6814  Validation loss = 2.5450  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.6812  Validation loss = 2.5444  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.6812  Validation loss = 2.5444  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.6811  Validation loss = 2.5439  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.6809  Validation loss = 2.5434  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.6806  Validation loss = 2.5426  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.6804  Validation loss = 2.5421  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.6802  Validation loss = 2.5414  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.6799  Validation loss = 2.5407  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.6797  Validation loss = 2.5402  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.6797  Validation loss = 2.5398  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.6795  Validation loss = 2.5391  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.6793  Validation loss = 2.5385  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.6792  Validation loss = 2.5383  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.6790  Validation loss = 2.5375  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.6787  Validation loss = 2.5369  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.6787  Validation loss = 2.5367  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.6785  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.6783  Validation loss = 2.5357  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.6783  Validation loss = 2.5357  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.6781  Validation loss = 2.5349  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.6780  Validation loss = 2.5347  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.6779  Validation loss = 2.5344  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.6778  Validation loss = 2.5339  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.6775  Validation loss = 2.5332  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.6774  Validation loss = 2.5326  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.6773  Validation loss = 2.5324  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.6772  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.6771  Validation loss = 2.5315  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.6768  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.6767  Validation loss = 2.5302  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.6766  Validation loss = 2.5300  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.6765  Validation loss = 2.5297  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.6764  Validation loss = 2.5294  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.6763  Validation loss = 2.5291  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.6762  Validation loss = 2.5287  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.6760  Validation loss = 2.5280  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.6758  Validation loss = 2.5276  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.6757  Validation loss = 2.5271  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.6755  Validation loss = 2.5264  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.6754  Validation loss = 2.5262  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.6753  Validation loss = 2.5257  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.6752  Validation loss = 2.5254  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.6750  Validation loss = 2.5248  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.6749  Validation loss = 2.5244  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.6746  Validation loss = 2.5237  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.6745  Validation loss = 2.5231  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.6743  Validation loss = 2.5224  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.6741  Validation loss = 2.5219  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.6738  Validation loss = 2.5213  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.6738  Validation loss = 2.5210  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.6736  Validation loss = 2.5206  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.6735  Validation loss = 2.5203  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.6734  Validation loss = 2.5198  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.6734  Validation loss = 2.5199  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.6733  Validation loss = 2.5197  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.6731  Validation loss = 2.5190  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.6729  Validation loss = 2.5185  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.6727  Validation loss = 2.5177  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.6726  Validation loss = 2.5175  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.6725  Validation loss = 2.5170  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.6723  Validation loss = 2.5163  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.6721  Validation loss = 2.5157  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.6719  Validation loss = 2.5152  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.6718  Validation loss = 2.5148  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.6718  Validation loss = 2.5147  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.6716  Validation loss = 2.5141  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.6715  Validation loss = 2.5137  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.6712  Validation loss = 2.5129  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.6711  Validation loss = 2.5125  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.6709  Validation loss = 2.5118  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.6708  Validation loss = 2.5113  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.6706  Validation loss = 2.5108  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.6705  Validation loss = 2.5101  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.6703  Validation loss = 2.5095  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.6701  Validation loss = 2.5092  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.6700  Validation loss = 2.5087  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.6699  Validation loss = 2.5083  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.6697  Validation loss = 2.5078  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.6695  Validation loss = 2.5072  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.6694  Validation loss = 2.5067  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.6692  Validation loss = 2.5061  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.6690  Validation loss = 2.5056  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.6689  Validation loss = 2.5051  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.6687  Validation loss = 2.5043  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.6686  Validation loss = 2.5040  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.6683  Validation loss = 2.5033  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.6681  Validation loss = 2.5025  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.6680  Validation loss = 2.5021  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.6679  Validation loss = 2.5017  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.6678  Validation loss = 2.5012  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.6675  Validation loss = 2.5005  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.6674  Validation loss = 2.5001  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.6673  Validation loss = 2.4998  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.6672  Validation loss = 2.4995  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.6670  Validation loss = 2.4989  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.6669  Validation loss = 2.4985  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.6669  Validation loss = 2.4983  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.6666  Validation loss = 2.4974  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.6665  Validation loss = 2.4973  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.6663  Validation loss = 2.4967  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.6663  Validation loss = 2.4964  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.6662  Validation loss = 2.4959  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.6661  Validation loss = 2.4955  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.6660  Validation loss = 2.4952  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.6658  Validation loss = 2.4946  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.6656  Validation loss = 2.4942  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.6654  Validation loss = 2.4936  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.6653  Validation loss = 2.4931  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.6652  Validation loss = 2.4927  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.6650  Validation loss = 2.4920  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.6648  Validation loss = 2.4915  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.6646  Validation loss = 2.4910  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.6646  Validation loss = 2.4906  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.6644  Validation loss = 2.4901  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.6643  Validation loss = 2.4897  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.6643  Validation loss = 2.4893  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.6641  Validation loss = 2.4889  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.6639  Validation loss = 2.4884  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.6638  Validation loss = 2.4879  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.6637  Validation loss = 2.4874  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.6635  Validation loss = 2.4869  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.6635  Validation loss = 2.4869  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.6633  Validation loss = 2.4862  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.6630  Validation loss = 2.4854  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.6629  Validation loss = 2.4851  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.6629  Validation loss = 2.4849  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.6628  Validation loss = 2.4844  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.6626  Validation loss = 2.4839  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.6625  Validation loss = 2.4834  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.6624  Validation loss = 2.4830  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.6622  Validation loss = 2.4825  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.6621  Validation loss = 2.4820  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.6619  Validation loss = 2.4815  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.6617  Validation loss = 2.4807  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.6616  Validation loss = 2.4803  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.6614  Validation loss = 2.4794  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.6611  Validation loss = 2.4788  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.6608  Validation loss = 2.4778  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.6607  Validation loss = 2.4772  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.6606  Validation loss = 2.4769  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.6604  Validation loss = 2.4764  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.6602  Validation loss = 2.4759  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.6601  Validation loss = 2.4755  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.6600  Validation loss = 2.4750  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.6598  Validation loss = 2.4742  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.6597  Validation loss = 2.4739  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.6595  Validation loss = 2.4734  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.6594  Validation loss = 2.4730  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.6594  Validation loss = 2.4728  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.6592  Validation loss = 2.4723  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.6590  Validation loss = 2.4716  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.6588  Validation loss = 2.4708  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.6587  Validation loss = 2.4705  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.6584  Validation loss = 2.4698  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.6584  Validation loss = 2.4696  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.6583  Validation loss = 2.4690  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.6583  Validation loss = 2.4688  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.6581  Validation loss = 2.4685  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.6580  Validation loss = 2.4679  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.6578  Validation loss = 2.4674  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.6577  Validation loss = 2.4672  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.6576  Validation loss = 2.4666  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.6575  Validation loss = 2.4664  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.6573  Validation loss = 2.4660  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.6572  Validation loss = 2.4655  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.6571  Validation loss = 2.4650  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.6571  Validation loss = 2.4648  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.6570  Validation loss = 2.4647  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.6570  Validation loss = 2.4645  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.6569  Validation loss = 2.4643  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.6568  Validation loss = 2.4639  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.6567  Validation loss = 2.4636  \n",
      "\n",
      "Fold: 2  Epoch: 501  Training loss = 2.6566  Validation loss = 2.4631  \n",
      "\n",
      "Fold: 2  Epoch: 502  Training loss = 2.6565  Validation loss = 2.4627  \n",
      "\n",
      "Fold: 2  Epoch: 503  Training loss = 2.6565  Validation loss = 2.4626  \n",
      "\n",
      "Fold: 2  Epoch: 504  Training loss = 2.6564  Validation loss = 2.4622  \n",
      "\n",
      "Fold: 2  Epoch: 505  Training loss = 2.6561  Validation loss = 2.4613  \n",
      "\n",
      "Fold: 2  Epoch: 506  Training loss = 2.6560  Validation loss = 2.4610  \n",
      "\n",
      "Fold: 2  Epoch: 507  Training loss = 2.6559  Validation loss = 2.4606  \n",
      "\n",
      "Fold: 2  Epoch: 508  Training loss = 2.6557  Validation loss = 2.4598  \n",
      "\n",
      "Fold: 2  Epoch: 509  Training loss = 2.6556  Validation loss = 2.4594  \n",
      "\n",
      "Fold: 2  Epoch: 510  Training loss = 2.6555  Validation loss = 2.4591  \n",
      "\n",
      "Fold: 2  Epoch: 511  Training loss = 2.6554  Validation loss = 2.4588  \n",
      "\n",
      "Fold: 2  Epoch: 512  Training loss = 2.6552  Validation loss = 2.4582  \n",
      "\n",
      "Fold: 2  Epoch: 513  Training loss = 2.6551  Validation loss = 2.4578  \n",
      "\n",
      "Fold: 2  Epoch: 514  Training loss = 2.6548  Validation loss = 2.4571  \n",
      "\n",
      "Fold: 2  Epoch: 515  Training loss = 2.6548  Validation loss = 2.4568  \n",
      "\n",
      "Fold: 2  Epoch: 516  Training loss = 2.6546  Validation loss = 2.4562  \n",
      "\n",
      "Fold: 2  Epoch: 517  Training loss = 2.6545  Validation loss = 2.4558  \n",
      "\n",
      "Fold: 2  Epoch: 518  Training loss = 2.6544  Validation loss = 2.4555  \n",
      "\n",
      "Fold: 2  Epoch: 519  Training loss = 2.6543  Validation loss = 2.4551  \n",
      "\n",
      "Fold: 2  Epoch: 520  Training loss = 2.6542  Validation loss = 2.4549  \n",
      "\n",
      "Fold: 2  Epoch: 521  Training loss = 2.6541  Validation loss = 2.4547  \n",
      "\n",
      "Fold: 2  Epoch: 522  Training loss = 2.6540  Validation loss = 2.4543  \n",
      "\n",
      "Fold: 2  Epoch: 523  Training loss = 2.6538  Validation loss = 2.4539  \n",
      "\n",
      "Fold: 2  Epoch: 524  Training loss = 2.6537  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 2  Epoch: 525  Training loss = 2.6536  Validation loss = 2.4530  \n",
      "\n",
      "Fold: 2  Epoch: 526  Training loss = 2.6536  Validation loss = 2.4527  \n",
      "\n",
      "Fold: 2  Epoch: 527  Training loss = 2.6535  Validation loss = 2.4525  \n",
      "\n",
      "Fold: 2  Epoch: 528  Training loss = 2.6535  Validation loss = 2.4524  \n",
      "\n",
      "Fold: 2  Epoch: 529  Training loss = 2.6534  Validation loss = 2.4521  \n",
      "\n",
      "Fold: 2  Epoch: 530  Training loss = 2.6534  Validation loss = 2.4520  \n",
      "\n",
      "Fold: 2  Epoch: 531  Training loss = 2.6532  Validation loss = 2.4515  \n",
      "\n",
      "Fold: 2  Epoch: 532  Training loss = 2.6531  Validation loss = 2.4512  \n",
      "\n",
      "Fold: 2  Epoch: 533  Training loss = 2.6531  Validation loss = 2.4509  \n",
      "\n",
      "Fold: 2  Epoch: 534  Training loss = 2.6530  Validation loss = 2.4507  \n",
      "\n",
      "Fold: 2  Epoch: 535  Training loss = 2.6528  Validation loss = 2.4502  \n",
      "\n",
      "Fold: 2  Epoch: 536  Training loss = 2.6526  Validation loss = 2.4494  \n",
      "\n",
      "Fold: 2  Epoch: 537  Training loss = 2.6524  Validation loss = 2.4488  \n",
      "\n",
      "Fold: 2  Epoch: 538  Training loss = 2.6522  Validation loss = 2.4482  \n",
      "\n",
      "Fold: 2  Epoch: 539  Training loss = 2.6521  Validation loss = 2.4476  \n",
      "\n",
      "Fold: 2  Epoch: 540  Training loss = 2.6519  Validation loss = 2.4470  \n",
      "\n",
      "Fold: 2  Epoch: 541  Training loss = 2.6518  Validation loss = 2.4467  \n",
      "\n",
      "Fold: 2  Epoch: 542  Training loss = 2.6517  Validation loss = 2.4463  \n",
      "\n",
      "Fold: 2  Epoch: 543  Training loss = 2.6517  Validation loss = 2.4462  \n",
      "\n",
      "Fold: 2  Epoch: 544  Training loss = 2.6516  Validation loss = 2.4460  \n",
      "\n",
      "Fold: 2  Epoch: 545  Training loss = 2.6516  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 2  Epoch: 546  Training loss = 2.6514  Validation loss = 2.4452  \n",
      "\n",
      "Fold: 2  Epoch: 547  Training loss = 2.6514  Validation loss = 2.4451  \n",
      "\n",
      "Fold: 2  Epoch: 548  Training loss = 2.6512  Validation loss = 2.4444  \n",
      "\n",
      "Fold: 2  Epoch: 549  Training loss = 2.6512  Validation loss = 2.4443  \n",
      "\n",
      "Fold: 2  Epoch: 550  Training loss = 2.6511  Validation loss = 2.4441  \n",
      "\n",
      "Fold: 2  Epoch: 551  Training loss = 2.6510  Validation loss = 2.4436  \n",
      "\n",
      "Fold: 2  Epoch: 552  Training loss = 2.6508  Validation loss = 2.4432  \n",
      "\n",
      "Fold: 2  Epoch: 553  Training loss = 2.6507  Validation loss = 2.4425  \n",
      "\n",
      "Fold: 2  Epoch: 554  Training loss = 2.6505  Validation loss = 2.4420  \n",
      "\n",
      "Fold: 2  Epoch: 555  Training loss = 2.6505  Validation loss = 2.4416  \n",
      "\n",
      "Fold: 2  Epoch: 556  Training loss = 2.6503  Validation loss = 2.4409  \n",
      "\n",
      "Fold: 2  Epoch: 557  Training loss = 2.6502  Validation loss = 2.4406  \n",
      "\n",
      "Fold: 2  Epoch: 558  Training loss = 2.6500  Validation loss = 2.4399  \n",
      "\n",
      "Fold: 2  Epoch: 559  Training loss = 2.6499  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 2  Epoch: 560  Training loss = 2.6496  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 2  Epoch: 561  Training loss = 2.6495  Validation loss = 2.4384  \n",
      "\n",
      "Fold: 2  Epoch: 562  Training loss = 2.6494  Validation loss = 2.4378  \n",
      "\n",
      "Fold: 2  Epoch: 563  Training loss = 2.6492  Validation loss = 2.4371  \n",
      "\n",
      "Fold: 2  Epoch: 564  Training loss = 2.6490  Validation loss = 2.4364  \n",
      "\n",
      "Fold: 2  Epoch: 565  Training loss = 2.6488  Validation loss = 2.4358  \n",
      "\n",
      "Fold: 2  Epoch: 566  Training loss = 2.6488  Validation loss = 2.4355  \n",
      "\n",
      "Fold: 2  Epoch: 567  Training loss = 2.6485  Validation loss = 2.4346  \n",
      "\n",
      "Fold: 2  Epoch: 568  Training loss = 2.6484  Validation loss = 2.4341  \n",
      "\n",
      "Fold: 2  Epoch: 569  Training loss = 2.6482  Validation loss = 2.4337  \n",
      "\n",
      "Fold: 2  Epoch: 570  Training loss = 2.6482  Validation loss = 2.4335  \n",
      "\n",
      "Fold: 2  Epoch: 571  Training loss = 2.6480  Validation loss = 2.4328  \n",
      "\n",
      "Fold: 2  Epoch: 572  Training loss = 2.6479  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 2  Epoch: 573  Training loss = 2.6477  Validation loss = 2.4319  \n",
      "\n",
      "Fold: 2  Epoch: 574  Training loss = 2.6476  Validation loss = 2.4315  \n",
      "\n",
      "Fold: 2  Epoch: 575  Training loss = 2.6474  Validation loss = 2.4308  \n",
      "\n",
      "Fold: 2  Epoch: 576  Training loss = 2.6474  Validation loss = 2.4304  \n",
      "\n",
      "Fold: 2  Epoch: 577  Training loss = 2.6473  Validation loss = 2.4300  \n",
      "\n",
      "Fold: 2  Epoch: 578  Training loss = 2.6471  Validation loss = 2.4293  \n",
      "\n",
      "Fold: 2  Epoch: 579  Training loss = 2.6470  Validation loss = 2.4291  \n",
      "\n",
      "Fold: 2  Epoch: 580  Training loss = 2.6469  Validation loss = 2.4288  \n",
      "\n",
      "Fold: 2  Epoch: 581  Training loss = 2.6469  Validation loss = 2.4286  \n",
      "\n",
      "Fold: 2  Epoch: 582  Training loss = 2.6468  Validation loss = 2.4282  \n",
      "\n",
      "Fold: 2  Epoch: 583  Training loss = 2.6465  Validation loss = 2.4274  \n",
      "\n",
      "Fold: 2  Epoch: 584  Training loss = 2.6464  Validation loss = 2.4270  \n",
      "\n",
      "Fold: 2  Epoch: 585  Training loss = 2.6464  Validation loss = 2.4268  \n",
      "\n",
      "Fold: 2  Epoch: 586  Training loss = 2.6462  Validation loss = 2.4264  \n",
      "\n",
      "Fold: 2  Epoch: 587  Training loss = 2.6461  Validation loss = 2.4261  \n",
      "\n",
      "Fold: 2  Epoch: 588  Training loss = 2.6460  Validation loss = 2.4254  \n",
      "\n",
      "Fold: 2  Epoch: 589  Training loss = 2.6457  Validation loss = 2.4248  \n",
      "\n",
      "Fold: 2  Epoch: 590  Training loss = 2.6457  Validation loss = 2.4246  \n",
      "\n",
      "Fold: 2  Epoch: 591  Training loss = 2.6457  Validation loss = 2.4243  \n",
      "\n",
      "Fold: 2  Epoch: 592  Training loss = 2.6456  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 2  Epoch: 593  Training loss = 2.6455  Validation loss = 2.4235  \n",
      "\n",
      "Fold: 2  Epoch: 594  Training loss = 2.6454  Validation loss = 2.4232  \n",
      "\n",
      "Fold: 2  Epoch: 595  Training loss = 2.6453  Validation loss = 2.4229  \n",
      "\n",
      "Fold: 2  Epoch: 596  Training loss = 2.6452  Validation loss = 2.4223  \n",
      "\n",
      "Fold: 2  Epoch: 597  Training loss = 2.6451  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 2  Epoch: 598  Training loss = 2.6450  Validation loss = 2.4215  \n",
      "\n",
      "Fold: 2  Epoch: 599  Training loss = 2.6449  Validation loss = 2.4213  \n",
      "\n",
      "Fold: 2  Epoch: 600  Training loss = 2.6448  Validation loss = 2.4209  \n",
      "\n",
      "Fold: 2  Epoch: 601  Training loss = 2.6447  Validation loss = 2.4206  \n",
      "\n",
      "Fold: 2  Epoch: 602  Training loss = 2.6444  Validation loss = 2.4200  \n",
      "\n",
      "Fold: 2  Epoch: 603  Training loss = 2.6443  Validation loss = 2.4196  \n",
      "\n",
      "Fold: 2  Epoch: 604  Training loss = 2.6442  Validation loss = 2.4195  \n",
      "\n",
      "Fold: 2  Epoch: 605  Training loss = 2.6441  Validation loss = 2.4189  \n",
      "\n",
      "Fold: 2  Epoch: 606  Training loss = 2.6439  Validation loss = 2.4183  \n",
      "\n",
      "Fold: 2  Epoch: 607  Training loss = 2.6439  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 2  Epoch: 608  Training loss = 2.6438  Validation loss = 2.4176  \n",
      "\n",
      "Fold: 2  Epoch: 609  Training loss = 2.6437  Validation loss = 2.4172  \n",
      "\n",
      "Fold: 2  Epoch: 610  Training loss = 2.6436  Validation loss = 2.4169  \n",
      "\n",
      "Fold: 2  Epoch: 611  Training loss = 2.6434  Validation loss = 2.4163  \n",
      "\n",
      "Fold: 2  Epoch: 612  Training loss = 2.6432  Validation loss = 2.4159  \n",
      "\n",
      "Fold: 2  Epoch: 613  Training loss = 2.6431  Validation loss = 2.4154  \n",
      "\n",
      "Fold: 2  Epoch: 614  Training loss = 2.6429  Validation loss = 2.4147  \n",
      "\n",
      "Fold: 2  Epoch: 615  Training loss = 2.6428  Validation loss = 2.4141  \n",
      "\n",
      "Fold: 2  Epoch: 616  Training loss = 2.6428  Validation loss = 2.4139  \n",
      "\n",
      "Fold: 2  Epoch: 617  Training loss = 2.6427  Validation loss = 2.4136  \n",
      "\n",
      "Fold: 2  Epoch: 618  Training loss = 2.6425  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 2  Epoch: 619  Training loss = 2.6424  Validation loss = 2.4125  \n",
      "\n",
      "Fold: 2  Epoch: 620  Training loss = 2.6423  Validation loss = 2.4122  \n",
      "\n",
      "Fold: 2  Epoch: 621  Training loss = 2.6421  Validation loss = 2.4115  \n",
      "\n",
      "Fold: 2  Epoch: 622  Training loss = 2.6420  Validation loss = 2.4111  \n",
      "\n",
      "Fold: 2  Epoch: 623  Training loss = 2.6419  Validation loss = 2.4107  \n",
      "\n",
      "Fold: 2  Epoch: 624  Training loss = 2.6419  Validation loss = 2.4106  \n",
      "\n",
      "Fold: 2  Epoch: 625  Training loss = 2.6418  Validation loss = 2.4103  \n",
      "\n",
      "Fold: 2  Epoch: 626  Training loss = 2.6418  Validation loss = 2.4101  \n",
      "\n",
      "Fold: 2  Epoch: 627  Training loss = 2.6416  Validation loss = 2.4095  \n",
      "\n",
      "Fold: 2  Epoch: 628  Training loss = 2.6415  Validation loss = 2.4088  \n",
      "\n",
      "Fold: 2  Epoch: 629  Training loss = 2.6414  Validation loss = 2.4084  \n",
      "\n",
      "Fold: 2  Epoch: 630  Training loss = 2.6413  Validation loss = 2.4081  \n",
      "\n",
      "Fold: 2  Epoch: 631  Training loss = 2.6413  Validation loss = 2.4081  \n",
      "\n",
      "Fold: 2  Epoch: 632  Training loss = 2.6412  Validation loss = 2.4077  \n",
      "\n",
      "Fold: 2  Epoch: 633  Training loss = 2.6411  Validation loss = 2.4072  \n",
      "\n",
      "Fold: 2  Epoch: 634  Training loss = 2.6410  Validation loss = 2.4070  \n",
      "\n",
      "Fold: 2  Epoch: 635  Training loss = 2.6408  Validation loss = 2.4062  \n",
      "\n",
      "Fold: 2  Epoch: 636  Training loss = 2.6407  Validation loss = 2.4059  \n",
      "\n",
      "Fold: 2  Epoch: 637  Training loss = 2.6407  Validation loss = 2.4059  \n",
      "\n",
      "Fold: 2  Epoch: 638  Training loss = 2.6407  Validation loss = 2.4057  \n",
      "\n",
      "Fold: 2  Epoch: 639  Training loss = 2.6407  Validation loss = 2.4056  \n",
      "\n",
      "Fold: 2  Epoch: 640  Training loss = 2.6405  Validation loss = 2.4049  \n",
      "\n",
      "Fold: 2  Epoch: 641  Training loss = 2.6405  Validation loss = 2.4045  \n",
      "\n",
      "Fold: 2  Epoch: 642  Training loss = 2.6404  Validation loss = 2.4044  \n",
      "\n",
      "Fold: 2  Epoch: 643  Training loss = 2.6403  Validation loss = 2.4039  \n",
      "\n",
      "Fold: 2  Epoch: 644  Training loss = 2.6401  Validation loss = 2.4033  \n",
      "\n",
      "Fold: 2  Epoch: 645  Training loss = 2.6401  Validation loss = 2.4030  \n",
      "\n",
      "Fold: 2  Epoch: 646  Training loss = 2.6399  Validation loss = 2.4023  \n",
      "\n",
      "Fold: 2  Epoch: 647  Training loss = 2.6398  Validation loss = 2.4019  \n",
      "\n",
      "Fold: 2  Epoch: 648  Training loss = 2.6397  Validation loss = 2.4017  \n",
      "\n",
      "Fold: 2  Epoch: 649  Training loss = 2.6397  Validation loss = 2.4014  \n",
      "\n",
      "Fold: 2  Epoch: 650  Training loss = 2.6396  Validation loss = 2.4011  \n",
      "\n",
      "Fold: 2  Epoch: 651  Training loss = 2.6395  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 2  Epoch: 652  Training loss = 2.6394  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 2  Epoch: 653  Training loss = 2.6393  Validation loss = 2.4003  \n",
      "\n",
      "Fold: 2  Epoch: 654  Training loss = 2.6392  Validation loss = 2.3997  \n",
      "\n",
      "Fold: 2  Epoch: 655  Training loss = 2.6390  Validation loss = 2.3992  \n",
      "\n",
      "Fold: 2  Epoch: 656  Training loss = 2.6390  Validation loss = 2.3992  \n",
      "\n",
      "Fold: 2  Epoch: 657  Training loss = 2.6388  Validation loss = 2.3983  \n",
      "\n",
      "Fold: 2  Epoch: 658  Training loss = 2.6388  Validation loss = 2.3983  \n",
      "\n",
      "Fold: 2  Epoch: 659  Training loss = 2.6387  Validation loss = 2.3979  \n",
      "\n",
      "Fold: 2  Epoch: 660  Training loss = 2.6385  Validation loss = 2.3973  \n",
      "\n",
      "Fold: 2  Epoch: 661  Training loss = 2.6384  Validation loss = 2.3967  \n",
      "\n",
      "Fold: 2  Epoch: 662  Training loss = 2.6383  Validation loss = 2.3963  \n",
      "\n",
      "Fold: 2  Epoch: 663  Training loss = 2.6380  Validation loss = 2.3953  \n",
      "\n",
      "Fold: 2  Epoch: 664  Training loss = 2.6379  Validation loss = 2.3947  \n",
      "\n",
      "Fold: 2  Epoch: 665  Training loss = 2.6378  Validation loss = 2.3943  \n",
      "\n",
      "Fold: 2  Epoch: 666  Training loss = 2.6377  Validation loss = 2.3937  \n",
      "\n",
      "Fold: 2  Epoch: 667  Training loss = 2.6376  Validation loss = 2.3934  \n",
      "\n",
      "Fold: 2  Epoch: 668  Training loss = 2.6376  Validation loss = 2.3932  \n",
      "\n",
      "Fold: 2  Epoch: 669  Training loss = 2.6375  Validation loss = 2.3927  \n",
      "\n",
      "Fold: 2  Epoch: 670  Training loss = 2.6374  Validation loss = 2.3926  \n",
      "\n",
      "Fold: 2  Epoch: 671  Training loss = 2.6373  Validation loss = 2.3921  \n",
      "\n",
      "Fold: 2  Epoch: 672  Training loss = 2.6372  Validation loss = 2.3916  \n",
      "\n",
      "Fold: 2  Epoch: 673  Training loss = 2.6372  Validation loss = 2.3917  \n",
      "\n",
      "Fold: 2  Epoch: 674  Training loss = 2.6372  Validation loss = 2.3915  \n",
      "\n",
      "Fold: 2  Epoch: 675  Training loss = 2.6371  Validation loss = 2.3912  \n",
      "\n",
      "Fold: 2  Epoch: 676  Training loss = 2.6371  Validation loss = 2.3910  \n",
      "\n",
      "Fold: 2  Epoch: 677  Training loss = 2.6370  Validation loss = 2.3908  \n",
      "\n",
      "Fold: 2  Epoch: 678  Training loss = 2.6369  Validation loss = 2.3902  \n",
      "\n",
      "Fold: 2  Epoch: 679  Training loss = 2.6368  Validation loss = 2.3897  \n",
      "\n",
      "Fold: 2  Epoch: 680  Training loss = 2.6364  Validation loss = 2.3886  \n",
      "\n",
      "Fold: 2  Epoch: 681  Training loss = 2.6362  Validation loss = 2.3876  \n",
      "\n",
      "Fold: 2  Epoch: 682  Training loss = 2.6361  Validation loss = 2.3872  \n",
      "\n",
      "Fold: 2  Epoch: 683  Training loss = 2.6359  Validation loss = 2.3865  \n",
      "\n",
      "Fold: 2  Epoch: 684  Training loss = 2.6358  Validation loss = 2.3864  \n",
      "\n",
      "Fold: 2  Epoch: 685  Training loss = 2.6357  Validation loss = 2.3859  \n",
      "\n",
      "Fold: 2  Epoch: 686  Training loss = 2.6356  Validation loss = 2.3854  \n",
      "\n",
      "Fold: 2  Epoch: 687  Training loss = 2.6355  Validation loss = 2.3850  \n",
      "\n",
      "Fold: 2  Epoch: 688  Training loss = 2.6354  Validation loss = 2.3847  \n",
      "\n",
      "Fold: 2  Epoch: 689  Training loss = 2.6353  Validation loss = 2.3841  \n",
      "\n",
      "Fold: 2  Epoch: 690  Training loss = 2.6352  Validation loss = 2.3839  \n",
      "\n",
      "Fold: 2  Epoch: 691  Training loss = 2.6350  Validation loss = 2.3833  \n",
      "\n",
      "Fold: 2  Epoch: 692  Training loss = 2.6349  Validation loss = 2.3828  \n",
      "\n",
      "Fold: 2  Epoch: 693  Training loss = 2.6348  Validation loss = 2.3825  \n",
      "\n",
      "Fold: 2  Epoch: 694  Training loss = 2.6346  Validation loss = 2.3818  \n",
      "\n",
      "Fold: 2  Epoch: 695  Training loss = 2.6345  Validation loss = 2.3811  \n",
      "\n",
      "Fold: 2  Epoch: 696  Training loss = 2.6343  Validation loss = 2.3806  \n",
      "\n",
      "Fold: 2  Epoch: 697  Training loss = 2.6341  Validation loss = 2.3801  \n",
      "\n",
      "Fold: 2  Epoch: 698  Training loss = 2.6341  Validation loss = 2.3797  \n",
      "\n",
      "Fold: 2  Epoch: 699  Training loss = 2.6340  Validation loss = 2.3792  \n",
      "\n",
      "Fold: 2  Epoch: 700  Training loss = 2.6338  Validation loss = 2.3787  \n",
      "\n",
      "Fold: 2  Epoch: 701  Training loss = 2.6337  Validation loss = 2.3779  \n",
      "\n",
      "Fold: 2  Epoch: 702  Training loss = 2.6336  Validation loss = 2.3778  \n",
      "\n",
      "Fold: 2  Epoch: 703  Training loss = 2.6337  Validation loss = 2.3778  \n",
      "\n",
      "Fold: 2  Epoch: 704  Training loss = 2.6336  Validation loss = 2.3777  \n",
      "\n",
      "Fold: 2  Epoch: 705  Training loss = 2.6336  Validation loss = 2.3775  \n",
      "\n",
      "Fold: 2  Epoch: 706  Training loss = 2.6334  Validation loss = 2.3770  \n",
      "\n",
      "Fold: 2  Epoch: 707  Training loss = 2.6333  Validation loss = 2.3765  \n",
      "\n",
      "Fold: 2  Epoch: 708  Training loss = 2.6332  Validation loss = 2.3760  \n",
      "\n",
      "Fold: 2  Epoch: 709  Training loss = 2.6330  Validation loss = 2.3752  \n",
      "\n",
      "Fold: 2  Epoch: 710  Training loss = 2.6330  Validation loss = 2.3748  \n",
      "\n",
      "Fold: 2  Epoch: 711  Training loss = 2.6329  Validation loss = 2.3745  \n",
      "\n",
      "Fold: 2  Epoch: 712  Training loss = 2.6327  Validation loss = 2.3740  \n",
      "\n",
      "Fold: 2  Epoch: 713  Training loss = 2.6326  Validation loss = 2.3735  \n",
      "\n",
      "Fold: 2  Epoch: 714  Training loss = 2.6325  Validation loss = 2.3731  \n",
      "\n",
      "Fold: 2  Epoch: 715  Training loss = 2.6323  Validation loss = 2.3723  \n",
      "\n",
      "Fold: 2  Epoch: 716  Training loss = 2.6323  Validation loss = 2.3720  \n",
      "\n",
      "Fold: 2  Epoch: 717  Training loss = 2.6322  Validation loss = 2.3718  \n",
      "\n",
      "Fold: 2  Epoch: 718  Training loss = 2.6322  Validation loss = 2.3719  \n",
      "\n",
      "Fold: 2  Epoch: 719  Training loss = 2.6321  Validation loss = 2.3714  \n",
      "\n",
      "Fold: 2  Epoch: 720  Training loss = 2.6321  Validation loss = 2.3710  \n",
      "\n",
      "Fold: 2  Epoch: 721  Training loss = 2.6321  Validation loss = 2.3710  \n",
      "\n",
      "Fold: 2  Epoch: 722  Training loss = 2.6320  Validation loss = 2.3708  \n",
      "\n",
      "Fold: 2  Epoch: 723  Training loss = 2.6320  Validation loss = 2.3706  \n",
      "\n",
      "Fold: 2  Epoch: 724  Training loss = 2.6319  Validation loss = 2.3702  \n",
      "\n",
      "Fold: 2  Epoch: 725  Training loss = 2.6318  Validation loss = 2.3699  \n",
      "\n",
      "Fold: 2  Epoch: 726  Training loss = 2.6317  Validation loss = 2.3693  \n",
      "\n",
      "Fold: 2  Epoch: 727  Training loss = 2.6316  Validation loss = 2.3689  \n",
      "\n",
      "Fold: 2  Epoch: 728  Training loss = 2.6315  Validation loss = 2.3683  \n",
      "\n",
      "Fold: 2  Epoch: 729  Training loss = 2.6314  Validation loss = 2.3680  \n",
      "\n",
      "Fold: 2  Epoch: 730  Training loss = 2.6313  Validation loss = 2.3677  \n",
      "\n",
      "Fold: 2  Epoch: 731  Training loss = 2.6312  Validation loss = 2.3673  \n",
      "\n",
      "Fold: 2  Epoch: 732  Training loss = 2.6312  Validation loss = 2.3672  \n",
      "\n",
      "Fold: 2  Epoch: 733  Training loss = 2.6310  Validation loss = 2.3667  \n",
      "\n",
      "Fold: 2  Epoch: 734  Training loss = 2.6310  Validation loss = 2.3666  \n",
      "\n",
      "Fold: 2  Epoch: 735  Training loss = 2.6309  Validation loss = 2.3662  \n",
      "\n",
      "Fold: 2  Epoch: 736  Training loss = 2.6309  Validation loss = 2.3661  \n",
      "\n",
      "Fold: 2  Epoch: 737  Training loss = 2.6308  Validation loss = 2.3657  \n",
      "\n",
      "Fold: 2  Epoch: 738  Training loss = 2.6307  Validation loss = 2.3654  \n",
      "\n",
      "Fold: 2  Epoch: 739  Training loss = 2.6306  Validation loss = 2.3650  \n",
      "\n",
      "Fold: 2  Epoch: 740  Training loss = 2.6306  Validation loss = 2.3649  \n",
      "\n",
      "Fold: 2  Epoch: 741  Training loss = 2.6306  Validation loss = 2.3646  \n",
      "\n",
      "Fold: 2  Epoch: 742  Training loss = 2.6305  Validation loss = 2.3643  \n",
      "\n",
      "Fold: 2  Epoch: 743  Training loss = 2.6303  Validation loss = 2.3635  \n",
      "\n",
      "Fold: 2  Epoch: 744  Training loss = 2.6303  Validation loss = 2.3634  \n",
      "\n",
      "Fold: 2  Epoch: 745  Training loss = 2.6302  Validation loss = 2.3630  \n",
      "\n",
      "Fold: 2  Epoch: 746  Training loss = 2.6302  Validation loss = 2.3628  \n",
      "\n",
      "Fold: 2  Epoch: 747  Training loss = 2.6301  Validation loss = 2.3625  \n",
      "\n",
      "Fold: 2  Epoch: 748  Training loss = 2.6300  Validation loss = 2.3619  \n",
      "\n",
      "Fold: 2  Epoch: 749  Training loss = 2.6299  Validation loss = 2.3616  \n",
      "\n",
      "Fold: 2  Epoch: 750  Training loss = 2.6298  Validation loss = 2.3609  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 750  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.5945  Validation loss = 3.2977  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.5945  Validation loss = 3.2974  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.5943  Validation loss = 3.2965  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.5942  Validation loss = 3.2957  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.5941  Validation loss = 3.2955  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.5941  Validation loss = 3.2953  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.5940  Validation loss = 3.2949  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.5940  Validation loss = 3.2946  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.5939  Validation loss = 3.2944  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.5939  Validation loss = 3.2941  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.5939  Validation loss = 3.2941  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.5938  Validation loss = 3.2934  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.5936  Validation loss = 3.2926  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.5935  Validation loss = 3.2918  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.5935  Validation loss = 3.2917  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.5933  Validation loss = 3.2908  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.5933  Validation loss = 3.2908  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.5932  Validation loss = 3.2907  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.5931  Validation loss = 3.2895  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.5930  Validation loss = 3.2890  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.5929  Validation loss = 3.2883  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.5928  Validation loss = 3.2881  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.5926  Validation loss = 3.2871  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.5925  Validation loss = 3.2865  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.5924  Validation loss = 3.2854  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.5923  Validation loss = 3.2851  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.5922  Validation loss = 3.2847  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.5921  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.5921  Validation loss = 3.2837  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.5919  Validation loss = 3.2826  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.5917  Validation loss = 3.2815  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.5915  Validation loss = 3.2804  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.5914  Validation loss = 3.2799  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.5912  Validation loss = 3.2787  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.5912  Validation loss = 3.2785  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.5911  Validation loss = 3.2781  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.5910  Validation loss = 3.2772  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.5909  Validation loss = 3.2767  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.5908  Validation loss = 3.2761  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.5907  Validation loss = 3.2758  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.5906  Validation loss = 3.2754  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.5905  Validation loss = 3.2744  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.5904  Validation loss = 3.2738  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.5903  Validation loss = 3.2736  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.5903  Validation loss = 3.2736  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.5903  Validation loss = 3.2732  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.5901  Validation loss = 3.2721  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.5901  Validation loss = 3.2719  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.5900  Validation loss = 3.2715  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.5900  Validation loss = 3.2714  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.5898  Validation loss = 3.2703  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.5897  Validation loss = 3.2698  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.5895  Validation loss = 3.2688  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.5895  Validation loss = 3.2688  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.5894  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.5893  Validation loss = 3.2676  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.5892  Validation loss = 3.2674  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.5892  Validation loss = 3.2672  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.5892  Validation loss = 3.2670  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.5890  Validation loss = 3.2664  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.5889  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.5888  Validation loss = 3.2649  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.5886  Validation loss = 3.2638  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.5886  Validation loss = 3.2636  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.5884  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.5882  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.5882  Validation loss = 3.2612  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.5881  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.5881  Validation loss = 3.2608  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.5880  Validation loss = 3.2603  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.5879  Validation loss = 3.2595  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.5877  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.5876  Validation loss = 3.2579  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.5876  Validation loss = 3.2577  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.5875  Validation loss = 3.2573  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.5873  Validation loss = 3.2563  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.5872  Validation loss = 3.2556  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.5871  Validation loss = 3.2550  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.5871  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.5869  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.5869  Validation loss = 3.2534  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.5868  Validation loss = 3.2529  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.5867  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.5867  Validation loss = 3.2521  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.5866  Validation loss = 3.2518  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.5865  Validation loss = 3.2512  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.5864  Validation loss = 3.2510  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.5863  Validation loss = 3.2505  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.5863  Validation loss = 3.2501  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.5862  Validation loss = 3.2497  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.5862  Validation loss = 3.2497  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.5861  Validation loss = 3.2494  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.5860  Validation loss = 3.2485  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.5859  Validation loss = 3.2483  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.5858  Validation loss = 3.2475  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.5858  Validation loss = 3.2473  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.5857  Validation loss = 3.2469  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.5857  Validation loss = 3.2467  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.5856  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.5856  Validation loss = 3.2461  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.5855  Validation loss = 3.2456  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.5854  Validation loss = 3.2451  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.5853  Validation loss = 3.2447  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.5852  Validation loss = 3.2443  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.5852  Validation loss = 3.2442  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.5852  Validation loss = 3.2444  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.5851  Validation loss = 3.2438  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.5850  Validation loss = 3.2433  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.5849  Validation loss = 3.2426  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.5849  Validation loss = 3.2426  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.5848  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.5847  Validation loss = 3.2415  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.5846  Validation loss = 3.2409  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.5845  Validation loss = 3.2405  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.5844  Validation loss = 3.2400  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.5843  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.5842  Validation loss = 3.2390  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.5842  Validation loss = 3.2387  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.5841  Validation loss = 3.2382  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.5840  Validation loss = 3.2379  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.5840  Validation loss = 3.2374  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.5839  Validation loss = 3.2371  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.5838  Validation loss = 3.2366  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.5838  Validation loss = 3.2365  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.5837  Validation loss = 3.2360  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.5836  Validation loss = 3.2355  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.5836  Validation loss = 3.2353  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.5834  Validation loss = 3.2346  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.5833  Validation loss = 3.2339  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.5833  Validation loss = 3.2338  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.5833  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.5832  Validation loss = 3.2333  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.5830  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.5829  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.5829  Validation loss = 3.2314  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.5828  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.5827  Validation loss = 3.2305  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.5827  Validation loss = 3.2303  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.5826  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.5826  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.5826  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.5825  Validation loss = 3.2292  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.5824  Validation loss = 3.2288  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.5824  Validation loss = 3.2287  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.5823  Validation loss = 3.2285  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.5823  Validation loss = 3.2284  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.5822  Validation loss = 3.2276  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.5820  Validation loss = 3.2268  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.5819  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.5819  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.5818  Validation loss = 3.2256  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.5817  Validation loss = 3.2248  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.5816  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.5816  Validation loss = 3.2240  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.5815  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.5814  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.5813  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.5812  Validation loss = 3.2217  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.5811  Validation loss = 3.2214  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.5811  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.5811  Validation loss = 3.2211  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.5810  Validation loss = 3.2206  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.5809  Validation loss = 3.2200  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.5807  Validation loss = 3.2189  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.5806  Validation loss = 3.2182  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.5805  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.5804  Validation loss = 3.2175  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.5804  Validation loss = 3.2172  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.5803  Validation loss = 3.2168  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.5802  Validation loss = 3.2164  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.5802  Validation loss = 3.2164  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.5802  Validation loss = 3.2164  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.5802  Validation loss = 3.2162  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.5801  Validation loss = 3.2161  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.5801  Validation loss = 3.2156  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.5800  Validation loss = 3.2149  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.5799  Validation loss = 3.2147  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.5799  Validation loss = 3.2144  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.5798  Validation loss = 3.2137  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.5797  Validation loss = 3.2130  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.5796  Validation loss = 3.2126  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.5796  Validation loss = 3.2124  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.5795  Validation loss = 3.2122  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.5794  Validation loss = 3.2118  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.5794  Validation loss = 3.2119  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.5794  Validation loss = 3.2115  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.5793  Validation loss = 3.2111  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.5793  Validation loss = 3.2108  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.5792  Validation loss = 3.2103  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.5791  Validation loss = 3.2096  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.5791  Validation loss = 3.2098  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.5789  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.5788  Validation loss = 3.2079  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.5787  Validation loss = 3.2074  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.5787  Validation loss = 3.2073  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.5786  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.5786  Validation loss = 3.2069  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.5786  Validation loss = 3.2067  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.5784  Validation loss = 3.2059  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.5784  Validation loss = 3.2058  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.5783  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.5782  Validation loss = 3.2046  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.5782  Validation loss = 3.2045  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.5781  Validation loss = 3.2042  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.5781  Validation loss = 3.2042  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.5781  Validation loss = 3.2039  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.5780  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.5780  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.5779  Validation loss = 3.2033  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.5779  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.5779  Validation loss = 3.2033  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.5778  Validation loss = 3.2030  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.5777  Validation loss = 3.2025  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.5777  Validation loss = 3.2022  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.5776  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.5776  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.5775  Validation loss = 3.2009  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.5774  Validation loss = 3.2006  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.5774  Validation loss = 3.2005  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.5773  Validation loss = 3.2000  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.5772  Validation loss = 3.2000  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.5771  Validation loss = 3.1994  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.5771  Validation loss = 3.1989  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.5771  Validation loss = 3.1992  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.5770  Validation loss = 3.1989  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.5769  Validation loss = 3.1981  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.5769  Validation loss = 3.1982  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.5768  Validation loss = 3.1978  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.5768  Validation loss = 3.1973  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.5767  Validation loss = 3.1969  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.5766  Validation loss = 3.1964  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.5765  Validation loss = 3.1956  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.5763  Validation loss = 3.1946  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.5763  Validation loss = 3.1943  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.5762  Validation loss = 3.1937  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.5761  Validation loss = 3.1933  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.5761  Validation loss = 3.1930  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.5760  Validation loss = 3.1927  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.5760  Validation loss = 3.1927  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.5759  Validation loss = 3.1920  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.5758  Validation loss = 3.1915  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.5757  Validation loss = 3.1910  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.5757  Validation loss = 3.1906  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.5756  Validation loss = 3.1903  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.5755  Validation loss = 3.1897  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.5755  Validation loss = 3.1894  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.5754  Validation loss = 3.1894  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.5754  Validation loss = 3.1891  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.5753  Validation loss = 3.1888  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.5753  Validation loss = 3.1885  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.5753  Validation loss = 3.1884  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.5752  Validation loss = 3.1883  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.5752  Validation loss = 3.1881  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.5752  Validation loss = 3.1879  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.5751  Validation loss = 3.1877  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.5751  Validation loss = 3.1873  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.5750  Validation loss = 3.1867  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.5749  Validation loss = 3.1862  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.5749  Validation loss = 3.1862  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.5748  Validation loss = 3.1860  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.5748  Validation loss = 3.1856  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.5747  Validation loss = 3.1852  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.5746  Validation loss = 3.1844  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.5746  Validation loss = 3.1847  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.5745  Validation loss = 3.1845  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.5745  Validation loss = 3.1842  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.5744  Validation loss = 3.1838  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.5744  Validation loss = 3.1839  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.5744  Validation loss = 3.1838  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.5744  Validation loss = 3.1838  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.5743  Validation loss = 3.1835  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.5743  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.5742  Validation loss = 3.1830  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.5742  Validation loss = 3.1829  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.5741  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.5741  Validation loss = 3.1823  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.5740  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.5740  Validation loss = 3.1819  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.5739  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.5739  Validation loss = 3.1815  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.5737  Validation loss = 3.1806  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.5737  Validation loss = 3.1802  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.5736  Validation loss = 3.1799  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.5736  Validation loss = 3.1797  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.5735  Validation loss = 3.1790  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.5735  Validation loss = 3.1788  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.5733  Validation loss = 3.1781  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.5733  Validation loss = 3.1777  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.5733  Validation loss = 3.1777  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.5732  Validation loss = 3.1773  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.5731  Validation loss = 3.1769  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.5731  Validation loss = 3.1767  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.5731  Validation loss = 3.1766  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.5730  Validation loss = 3.1761  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.5729  Validation loss = 3.1757  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.5729  Validation loss = 3.1756  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.5729  Validation loss = 3.1755  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.5728  Validation loss = 3.1751  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.5728  Validation loss = 3.1749  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.5727  Validation loss = 3.1743  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.5726  Validation loss = 3.1741  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.5725  Validation loss = 3.1734  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.5724  Validation loss = 3.1727  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.5724  Validation loss = 3.1725  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.5723  Validation loss = 3.1724  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.5723  Validation loss = 3.1722  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.5722  Validation loss = 3.1719  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.5722  Validation loss = 3.1716  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.5721  Validation loss = 3.1713  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.5721  Validation loss = 3.1709  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.5720  Validation loss = 3.1707  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.5719  Validation loss = 3.1703  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.5719  Validation loss = 3.1700  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.5718  Validation loss = 3.1695  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.5718  Validation loss = 3.1691  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.5717  Validation loss = 3.1686  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.5716  Validation loss = 3.1682  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.5715  Validation loss = 3.1675  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.5715  Validation loss = 3.1675  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.5714  Validation loss = 3.1672  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.5713  Validation loss = 3.1666  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.5713  Validation loss = 3.1665  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.5712  Validation loss = 3.1661  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.5712  Validation loss = 3.1658  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.5711  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.5711  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.5710  Validation loss = 3.1647  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.5710  Validation loss = 3.1646  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.5709  Validation loss = 3.1637  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.5707  Validation loss = 3.1630  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.5707  Validation loss = 3.1631  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.5706  Validation loss = 3.1625  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.5706  Validation loss = 3.1620  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.5705  Validation loss = 3.1620  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.5705  Validation loss = 3.1616  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.5703  Validation loss = 3.1605  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.5702  Validation loss = 3.1601  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.5702  Validation loss = 3.1597  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.5701  Validation loss = 3.1596  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.5701  Validation loss = 3.1591  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.5700  Validation loss = 3.1586  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.5699  Validation loss = 3.1583  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.5699  Validation loss = 3.1580  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.5698  Validation loss = 3.1579  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.5698  Validation loss = 3.1579  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.5697  Validation loss = 3.1573  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.5697  Validation loss = 3.1571  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.5696  Validation loss = 3.1566  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.5696  Validation loss = 3.1564  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.5696  Validation loss = 3.1563  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.5695  Validation loss = 3.1557  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.5694  Validation loss = 3.1556  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.5694  Validation loss = 3.1558  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.5694  Validation loss = 3.1555  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.5693  Validation loss = 3.1547  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.5692  Validation loss = 3.1543  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.5692  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.5691  Validation loss = 3.1536  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.5691  Validation loss = 3.1537  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.5690  Validation loss = 3.1532  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.5690  Validation loss = 3.1530  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.5689  Validation loss = 3.1531  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.5689  Validation loss = 3.1531  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.5689  Validation loss = 3.1530  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.5688  Validation loss = 3.1527  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.5688  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.5687  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.5687  Validation loss = 3.1520  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.5687  Validation loss = 3.1520  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.5687  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.5687  Validation loss = 3.1523  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.5686  Validation loss = 3.1521  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.5686  Validation loss = 3.1517  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.5685  Validation loss = 3.1514  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.5685  Validation loss = 3.1511  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.5684  Validation loss = 3.1508  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.5683  Validation loss = 3.1505  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.5683  Validation loss = 3.1504  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.5683  Validation loss = 3.1501  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.5682  Validation loss = 3.1499  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.5682  Validation loss = 3.1496  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.5681  Validation loss = 3.1496  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.5681  Validation loss = 3.1497  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.5681  Validation loss = 3.1494  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.5681  Validation loss = 3.1494  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.5680  Validation loss = 3.1492  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.5679  Validation loss = 3.1487  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.5679  Validation loss = 3.1486  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.5678  Validation loss = 3.1480  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.5677  Validation loss = 3.1475  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.5677  Validation loss = 3.1472  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.5677  Validation loss = 3.1473  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.5676  Validation loss = 3.1466  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.5675  Validation loss = 3.1461  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.5674  Validation loss = 3.1458  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.5674  Validation loss = 3.1455  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.5673  Validation loss = 3.1450  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.5672  Validation loss = 3.1445  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.5672  Validation loss = 3.1444  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.5672  Validation loss = 3.1444  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.5670  Validation loss = 3.1437  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.5670  Validation loss = 3.1433  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.5669  Validation loss = 3.1431  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.5669  Validation loss = 3.1426  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.5668  Validation loss = 3.1426  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.5667  Validation loss = 3.1420  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.5667  Validation loss = 3.1416  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.5666  Validation loss = 3.1409  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.5665  Validation loss = 3.1406  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.5665  Validation loss = 3.1406  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.5664  Validation loss = 3.1400  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.5663  Validation loss = 3.1395  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.5662  Validation loss = 3.1393  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.5661  Validation loss = 3.1386  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.5661  Validation loss = 3.1383  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.5661  Validation loss = 3.1383  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.5660  Validation loss = 3.1379  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.5659  Validation loss = 3.1374  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.5658  Validation loss = 3.1370  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.5658  Validation loss = 3.1368  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.5657  Validation loss = 3.1365  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.5657  Validation loss = 3.1364  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.5657  Validation loss = 3.1361  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.5656  Validation loss = 3.1357  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.5655  Validation loss = 3.1354  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.5655  Validation loss = 3.1352  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.5654  Validation loss = 3.1350  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.5654  Validation loss = 3.1347  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.5654  Validation loss = 3.1345  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.5653  Validation loss = 3.1338  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.5652  Validation loss = 3.1334  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.5652  Validation loss = 3.1330  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.5651  Validation loss = 3.1327  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.5651  Validation loss = 3.1326  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.5650  Validation loss = 3.1320  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.5650  Validation loss = 3.1319  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.5649  Validation loss = 3.1314  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.5648  Validation loss = 3.1311  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.5648  Validation loss = 3.1306  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.5647  Validation loss = 3.1304  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.5646  Validation loss = 3.1300  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.5646  Validation loss = 3.1298  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.5646  Validation loss = 3.1296  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.5645  Validation loss = 3.1292  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.5645  Validation loss = 3.1296  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.5645  Validation loss = 3.1295  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.5644  Validation loss = 3.1294  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.5644  Validation loss = 3.1290  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.5643  Validation loss = 3.1285  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.5643  Validation loss = 3.1285  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.5642  Validation loss = 3.1280  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.5641  Validation loss = 3.1275  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.5641  Validation loss = 3.1272  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.5640  Validation loss = 3.1271  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.5640  Validation loss = 3.1268  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.5639  Validation loss = 3.1259  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.5638  Validation loss = 3.1259  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.5638  Validation loss = 3.1259  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.5638  Validation loss = 3.1258  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.5637  Validation loss = 3.1253  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.5637  Validation loss = 3.1252  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.5636  Validation loss = 3.1251  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.5636  Validation loss = 3.1249  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.5636  Validation loss = 3.1250  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.5635  Validation loss = 3.1248  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.5635  Validation loss = 3.1246  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.5634  Validation loss = 3.1246  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.5634  Validation loss = 3.1243  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.5634  Validation loss = 3.1242  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.5633  Validation loss = 3.1237  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.5632  Validation loss = 3.1232  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.5632  Validation loss = 3.1230  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.5632  Validation loss = 3.1230  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.5631  Validation loss = 3.1229  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.5631  Validation loss = 3.1225  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.5631  Validation loss = 3.1226  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.5630  Validation loss = 3.1223  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.5630  Validation loss = 3.1225  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.5630  Validation loss = 3.1224  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.5629  Validation loss = 3.1221  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.5629  Validation loss = 3.1220  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.5628  Validation loss = 3.1212  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.5627  Validation loss = 3.1209  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.5627  Validation loss = 3.1206  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.5627  Validation loss = 3.1207  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.5626  Validation loss = 3.1206  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.5625  Validation loss = 3.1200  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.5625  Validation loss = 3.1197  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.5624  Validation loss = 3.1195  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.5624  Validation loss = 3.1195  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.5624  Validation loss = 3.1193  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.5623  Validation loss = 3.1194  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.5623  Validation loss = 3.1196  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.5623  Validation loss = 3.1195  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.5623  Validation loss = 3.1193  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.5622  Validation loss = 3.1191  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.5622  Validation loss = 3.1189  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.5621  Validation loss = 3.1187  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.5621  Validation loss = 3.1183  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.5620  Validation loss = 3.1179  \n",
      "\n",
      "Fold: 3  Epoch: 501  Training loss = 1.5619  Validation loss = 3.1176  \n",
      "\n",
      "Fold: 3  Epoch: 502  Training loss = 1.5619  Validation loss = 3.1171  \n",
      "\n",
      "Fold: 3  Epoch: 503  Training loss = 1.5618  Validation loss = 3.1169  \n",
      "\n",
      "Fold: 3  Epoch: 504  Training loss = 1.5618  Validation loss = 3.1170  \n",
      "\n",
      "Fold: 3  Epoch: 505  Training loss = 1.5618  Validation loss = 3.1170  \n",
      "\n",
      "Fold: 3  Epoch: 506  Training loss = 1.5617  Validation loss = 3.1170  \n",
      "\n",
      "Fold: 3  Epoch: 507  Training loss = 1.5617  Validation loss = 3.1169  \n",
      "\n",
      "Fold: 3  Epoch: 508  Training loss = 1.5616  Validation loss = 3.1166  \n",
      "\n",
      "Fold: 3  Epoch: 509  Training loss = 1.5616  Validation loss = 3.1165  \n",
      "\n",
      "Fold: 3  Epoch: 510  Training loss = 1.5615  Validation loss = 3.1162  \n",
      "\n",
      "Fold: 3  Epoch: 511  Training loss = 1.5615  Validation loss = 3.1157  \n",
      "\n",
      "Fold: 3  Epoch: 512  Training loss = 1.5614  Validation loss = 3.1152  \n",
      "\n",
      "Fold: 3  Epoch: 513  Training loss = 1.5613  Validation loss = 3.1150  \n",
      "\n",
      "Fold: 3  Epoch: 514  Training loss = 1.5613  Validation loss = 3.1145  \n",
      "\n",
      "Fold: 3  Epoch: 515  Training loss = 1.5612  Validation loss = 3.1142  \n",
      "\n",
      "Fold: 3  Epoch: 516  Training loss = 1.5612  Validation loss = 3.1140  \n",
      "\n",
      "Fold: 3  Epoch: 517  Training loss = 1.5612  Validation loss = 3.1142  \n",
      "\n",
      "Fold: 3  Epoch: 518  Training loss = 1.5611  Validation loss = 3.1140  \n",
      "\n",
      "Fold: 3  Epoch: 519  Training loss = 1.5611  Validation loss = 3.1139  \n",
      "\n",
      "Fold: 3  Epoch: 520  Training loss = 1.5610  Validation loss = 3.1138  \n",
      "\n",
      "Fold: 3  Epoch: 521  Training loss = 1.5610  Validation loss = 3.1136  \n",
      "\n",
      "Fold: 3  Epoch: 522  Training loss = 1.5609  Validation loss = 3.1133  \n",
      "\n",
      "Fold: 3  Epoch: 523  Training loss = 1.5608  Validation loss = 3.1128  \n",
      "\n",
      "Fold: 3  Epoch: 524  Training loss = 1.5608  Validation loss = 3.1126  \n",
      "\n",
      "Fold: 3  Epoch: 525  Training loss = 1.5608  Validation loss = 3.1124  \n",
      "\n",
      "Fold: 3  Epoch: 526  Training loss = 1.5607  Validation loss = 3.1121  \n",
      "\n",
      "Fold: 3  Epoch: 527  Training loss = 1.5606  Validation loss = 3.1113  \n",
      "\n",
      "Fold: 3  Epoch: 528  Training loss = 1.5606  Validation loss = 3.1113  \n",
      "\n",
      "Fold: 3  Epoch: 529  Training loss = 1.5605  Validation loss = 3.1110  \n",
      "\n",
      "Fold: 3  Epoch: 530  Training loss = 1.5605  Validation loss = 3.1107  \n",
      "\n",
      "Fold: 3  Epoch: 531  Training loss = 1.5604  Validation loss = 3.1100  \n",
      "\n",
      "Fold: 3  Epoch: 532  Training loss = 1.5603  Validation loss = 3.1095  \n",
      "\n",
      "Fold: 3  Epoch: 533  Training loss = 1.5603  Validation loss = 3.1092  \n",
      "\n",
      "Fold: 3  Epoch: 534  Training loss = 1.5602  Validation loss = 3.1091  \n",
      "\n",
      "Fold: 3  Epoch: 535  Training loss = 1.5602  Validation loss = 3.1090  \n",
      "\n",
      "Fold: 3  Epoch: 536  Training loss = 1.5601  Validation loss = 3.1086  \n",
      "\n",
      "Fold: 3  Epoch: 537  Training loss = 1.5601  Validation loss = 3.1079  \n",
      "\n",
      "Fold: 3  Epoch: 538  Training loss = 1.5600  Validation loss = 3.1076  \n",
      "\n",
      "Fold: 3  Epoch: 539  Training loss = 1.5599  Validation loss = 3.1070  \n",
      "\n",
      "Fold: 3  Epoch: 540  Training loss = 1.5599  Validation loss = 3.1068  \n",
      "\n",
      "Fold: 3  Epoch: 541  Training loss = 1.5598  Validation loss = 3.1063  \n",
      "\n",
      "Fold: 3  Epoch: 542  Training loss = 1.5598  Validation loss = 3.1060  \n",
      "\n",
      "Fold: 3  Epoch: 543  Training loss = 1.5597  Validation loss = 3.1058  \n",
      "\n",
      "Fold: 3  Epoch: 544  Training loss = 1.5597  Validation loss = 3.1057  \n",
      "\n",
      "Fold: 3  Epoch: 545  Training loss = 1.5596  Validation loss = 3.1053  \n",
      "\n",
      "Fold: 3  Epoch: 546  Training loss = 1.5596  Validation loss = 3.1050  \n",
      "\n",
      "Fold: 3  Epoch: 547  Training loss = 1.5595  Validation loss = 3.1045  \n",
      "\n",
      "Fold: 3  Epoch: 548  Training loss = 1.5595  Validation loss = 3.1041  \n",
      "\n",
      "Fold: 3  Epoch: 549  Training loss = 1.5594  Validation loss = 3.1041  \n",
      "\n",
      "Fold: 3  Epoch: 550  Training loss = 1.5594  Validation loss = 3.1039  \n",
      "\n",
      "Fold: 3  Epoch: 551  Training loss = 1.5593  Validation loss = 3.1033  \n",
      "\n",
      "Fold: 3  Epoch: 552  Training loss = 1.5593  Validation loss = 3.1033  \n",
      "\n",
      "Fold: 3  Epoch: 553  Training loss = 1.5592  Validation loss = 3.1030  \n",
      "\n",
      "Fold: 3  Epoch: 554  Training loss = 1.5592  Validation loss = 3.1030  \n",
      "\n",
      "Fold: 3  Epoch: 555  Training loss = 1.5591  Validation loss = 3.1026  \n",
      "\n",
      "Fold: 3  Epoch: 556  Training loss = 1.5591  Validation loss = 3.1024  \n",
      "\n",
      "Fold: 3  Epoch: 557  Training loss = 1.5590  Validation loss = 3.1020  \n",
      "\n",
      "Fold: 3  Epoch: 558  Training loss = 1.5590  Validation loss = 3.1019  \n",
      "\n",
      "Fold: 3  Epoch: 559  Training loss = 1.5589  Validation loss = 3.1010  \n",
      "\n",
      "Fold: 3  Epoch: 560  Training loss = 1.5588  Validation loss = 3.1006  \n",
      "\n",
      "Fold: 3  Epoch: 561  Training loss = 1.5588  Validation loss = 3.1002  \n",
      "\n",
      "Fold: 3  Epoch: 562  Training loss = 1.5587  Validation loss = 3.1000  \n",
      "\n",
      "Fold: 3  Epoch: 563  Training loss = 1.5587  Validation loss = 3.0997  \n",
      "\n",
      "Fold: 3  Epoch: 564  Training loss = 1.5586  Validation loss = 3.0996  \n",
      "\n",
      "Fold: 3  Epoch: 565  Training loss = 1.5586  Validation loss = 3.0993  \n",
      "\n",
      "Fold: 3  Epoch: 566  Training loss = 1.5586  Validation loss = 3.0998  \n",
      "\n",
      "Fold: 3  Epoch: 567  Training loss = 1.5586  Validation loss = 3.0993  \n",
      "\n",
      "Fold: 3  Epoch: 568  Training loss = 1.5585  Validation loss = 3.0994  \n",
      "\n",
      "Fold: 3  Epoch: 569  Training loss = 1.5585  Validation loss = 3.0992  \n",
      "\n",
      "Fold: 3  Epoch: 570  Training loss = 1.5584  Validation loss = 3.0988  \n",
      "\n",
      "Fold: 3  Epoch: 571  Training loss = 1.5584  Validation loss = 3.0985  \n",
      "\n",
      "Fold: 3  Epoch: 572  Training loss = 1.5584  Validation loss = 3.0987  \n",
      "\n",
      "Fold: 3  Epoch: 573  Training loss = 1.5583  Validation loss = 3.0988  \n",
      "\n",
      "Fold: 3  Epoch: 574  Training loss = 1.5583  Validation loss = 3.0985  \n",
      "\n",
      "Fold: 3  Epoch: 575  Training loss = 1.5583  Validation loss = 3.0984  \n",
      "\n",
      "Fold: 3  Epoch: 576  Training loss = 1.5582  Validation loss = 3.0979  \n",
      "\n",
      "Fold: 3  Epoch: 577  Training loss = 1.5582  Validation loss = 3.0977  \n",
      "\n",
      "Fold: 3  Epoch: 578  Training loss = 1.5581  Validation loss = 3.0972  \n",
      "\n",
      "Fold: 3  Epoch: 579  Training loss = 1.5580  Validation loss = 3.0968  \n",
      "\n",
      "Fold: 3  Epoch: 580  Training loss = 1.5580  Validation loss = 3.0968  \n",
      "\n",
      "Fold: 3  Epoch: 581  Training loss = 1.5579  Validation loss = 3.0965  \n",
      "\n",
      "Fold: 3  Epoch: 582  Training loss = 1.5579  Validation loss = 3.0962  \n",
      "\n",
      "Fold: 3  Epoch: 583  Training loss = 1.5578  Validation loss = 3.0958  \n",
      "\n",
      "Fold: 3  Epoch: 584  Training loss = 1.5578  Validation loss = 3.0956  \n",
      "\n",
      "Fold: 3  Epoch: 585  Training loss = 1.5577  Validation loss = 3.0949  \n",
      "\n",
      "Fold: 3  Epoch: 586  Training loss = 1.5576  Validation loss = 3.0948  \n",
      "\n",
      "Fold: 3  Epoch: 587  Training loss = 1.5575  Validation loss = 3.0942  \n",
      "\n",
      "Fold: 3  Epoch: 588  Training loss = 1.5575  Validation loss = 3.0936  \n",
      "\n",
      "Fold: 3  Epoch: 589  Training loss = 1.5574  Validation loss = 3.0935  \n",
      "\n",
      "Fold: 3  Epoch: 590  Training loss = 1.5574  Validation loss = 3.0931  \n",
      "\n",
      "Fold: 3  Epoch: 591  Training loss = 1.5573  Validation loss = 3.0931  \n",
      "\n",
      "Fold: 3  Epoch: 592  Training loss = 1.5573  Validation loss = 3.0927  \n",
      "\n",
      "Fold: 3  Epoch: 593  Training loss = 1.5572  Validation loss = 3.0923  \n",
      "\n",
      "Fold: 3  Epoch: 594  Training loss = 1.5571  Validation loss = 3.0919  \n",
      "\n",
      "Fold: 3  Epoch: 595  Training loss = 1.5571  Validation loss = 3.0916  \n",
      "\n",
      "Fold: 3  Epoch: 596  Training loss = 1.5571  Validation loss = 3.0915  \n",
      "\n",
      "Fold: 3  Epoch: 597  Training loss = 1.5570  Validation loss = 3.0911  \n",
      "\n",
      "Fold: 3  Epoch: 598  Training loss = 1.5570  Validation loss = 3.0910  \n",
      "\n",
      "Fold: 3  Epoch: 599  Training loss = 1.5569  Validation loss = 3.0904  \n",
      "\n",
      "Fold: 3  Epoch: 600  Training loss = 1.5569  Validation loss = 3.0903  \n",
      "\n",
      "Fold: 3  Epoch: 601  Training loss = 1.5568  Validation loss = 3.0900  \n",
      "\n",
      "Fold: 3  Epoch: 602  Training loss = 1.5567  Validation loss = 3.0893  \n",
      "\n",
      "Fold: 3  Epoch: 603  Training loss = 1.5567  Validation loss = 3.0893  \n",
      "\n",
      "Fold: 3  Epoch: 604  Training loss = 1.5566  Validation loss = 3.0889  \n",
      "\n",
      "Fold: 3  Epoch: 605  Training loss = 1.5566  Validation loss = 3.0889  \n",
      "\n",
      "Fold: 3  Epoch: 606  Training loss = 1.5566  Validation loss = 3.0888  \n",
      "\n",
      "Fold: 3  Epoch: 607  Training loss = 1.5565  Validation loss = 3.0887  \n",
      "\n",
      "Fold: 3  Epoch: 608  Training loss = 1.5565  Validation loss = 3.0882  \n",
      "\n",
      "Fold: 3  Epoch: 609  Training loss = 1.5564  Validation loss = 3.0881  \n",
      "\n",
      "Fold: 3  Epoch: 610  Training loss = 1.5564  Validation loss = 3.0879  \n",
      "\n",
      "Fold: 3  Epoch: 611  Training loss = 1.5563  Validation loss = 3.0878  \n",
      "\n",
      "Fold: 3  Epoch: 612  Training loss = 1.5563  Validation loss = 3.0878  \n",
      "\n",
      "Fold: 3  Epoch: 613  Training loss = 1.5563  Validation loss = 3.0876  \n",
      "\n",
      "Fold: 3  Epoch: 614  Training loss = 1.5562  Validation loss = 3.0875  \n",
      "\n",
      "Fold: 3  Epoch: 615  Training loss = 1.5562  Validation loss = 3.0874  \n",
      "\n",
      "Fold: 3  Epoch: 616  Training loss = 1.5561  Validation loss = 3.0871  \n",
      "\n",
      "Fold: 3  Epoch: 617  Training loss = 1.5561  Validation loss = 3.0871  \n",
      "\n",
      "Fold: 3  Epoch: 618  Training loss = 1.5561  Validation loss = 3.0869  \n",
      "\n",
      "Fold: 3  Epoch: 619  Training loss = 1.5560  Validation loss = 3.0867  \n",
      "\n",
      "Fold: 3  Epoch: 620  Training loss = 1.5560  Validation loss = 3.0862  \n",
      "\n",
      "Fold: 3  Epoch: 621  Training loss = 1.5559  Validation loss = 3.0859  \n",
      "\n",
      "Fold: 3  Epoch: 622  Training loss = 1.5559  Validation loss = 3.0857  \n",
      "\n",
      "Fold: 3  Epoch: 623  Training loss = 1.5558  Validation loss = 3.0850  \n",
      "\n",
      "Fold: 3  Epoch: 624  Training loss = 1.5557  Validation loss = 3.0846  \n",
      "\n",
      "Fold: 3  Epoch: 625  Training loss = 1.5557  Validation loss = 3.0843  \n",
      "\n",
      "Fold: 3  Epoch: 626  Training loss = 1.5556  Validation loss = 3.0842  \n",
      "\n",
      "Fold: 3  Epoch: 627  Training loss = 1.5556  Validation loss = 3.0837  \n",
      "\n",
      "Fold: 3  Epoch: 628  Training loss = 1.5555  Validation loss = 3.0835  \n",
      "\n",
      "Fold: 3  Epoch: 629  Training loss = 1.5555  Validation loss = 3.0832  \n",
      "\n",
      "Fold: 3  Epoch: 630  Training loss = 1.5554  Validation loss = 3.0830  \n",
      "\n",
      "Fold: 3  Epoch: 631  Training loss = 1.5554  Validation loss = 3.0829  \n",
      "\n",
      "Fold: 3  Epoch: 632  Training loss = 1.5554  Validation loss = 3.0828  \n",
      "\n",
      "Fold: 3  Epoch: 633  Training loss = 1.5553  Validation loss = 3.0827  \n",
      "\n",
      "Fold: 3  Epoch: 634  Training loss = 1.5553  Validation loss = 3.0826  \n",
      "\n",
      "Fold: 3  Epoch: 635  Training loss = 1.5552  Validation loss = 3.0822  \n",
      "\n",
      "Fold: 3  Epoch: 636  Training loss = 1.5552  Validation loss = 3.0823  \n",
      "\n",
      "Fold: 3  Epoch: 637  Training loss = 1.5551  Validation loss = 3.0819  \n",
      "\n",
      "Fold: 3  Epoch: 638  Training loss = 1.5551  Validation loss = 3.0817  \n",
      "\n",
      "Fold: 3  Epoch: 639  Training loss = 1.5550  Validation loss = 3.0818  \n",
      "\n",
      "Fold: 3  Epoch: 640  Training loss = 1.5550  Validation loss = 3.0815  \n",
      "\n",
      "Fold: 3  Epoch: 641  Training loss = 1.5549  Validation loss = 3.0812  \n",
      "\n",
      "Fold: 3  Epoch: 642  Training loss = 1.5549  Validation loss = 3.0807  \n",
      "\n",
      "Fold: 3  Epoch: 643  Training loss = 1.5548  Validation loss = 3.0806  \n",
      "\n",
      "Fold: 3  Epoch: 644  Training loss = 1.5548  Validation loss = 3.0800  \n",
      "\n",
      "Fold: 3  Epoch: 645  Training loss = 1.5548  Validation loss = 3.0803  \n",
      "\n",
      "Fold: 3  Epoch: 646  Training loss = 1.5547  Validation loss = 3.0800  \n",
      "\n",
      "Fold: 3  Epoch: 647  Training loss = 1.5547  Validation loss = 3.0799  \n",
      "\n",
      "Fold: 3  Epoch: 648  Training loss = 1.5547  Validation loss = 3.0802  \n",
      "\n",
      "Fold: 3  Epoch: 649  Training loss = 1.5547  Validation loss = 3.0802  \n",
      "\n",
      "Fold: 3  Epoch: 650  Training loss = 1.5546  Validation loss = 3.0799  \n",
      "\n",
      "Fold: 3  Epoch: 651  Training loss = 1.5546  Validation loss = 3.0796  \n",
      "\n",
      "Fold: 3  Epoch: 652  Training loss = 1.5545  Validation loss = 3.0794  \n",
      "\n",
      "Fold: 3  Epoch: 653  Training loss = 1.5545  Validation loss = 3.0793  \n",
      "\n",
      "Fold: 3  Epoch: 654  Training loss = 1.5544  Validation loss = 3.0791  \n",
      "\n",
      "Fold: 3  Epoch: 655  Training loss = 1.5544  Validation loss = 3.0788  \n",
      "\n",
      "Fold: 3  Epoch: 656  Training loss = 1.5543  Validation loss = 3.0784  \n",
      "\n",
      "Fold: 3  Epoch: 657  Training loss = 1.5543  Validation loss = 3.0780  \n",
      "\n",
      "Fold: 3  Epoch: 658  Training loss = 1.5542  Validation loss = 3.0777  \n",
      "\n",
      "Fold: 3  Epoch: 659  Training loss = 1.5542  Validation loss = 3.0776  \n",
      "\n",
      "Fold: 3  Epoch: 660  Training loss = 1.5542  Validation loss = 3.0773  \n",
      "\n",
      "Fold: 3  Epoch: 661  Training loss = 1.5541  Validation loss = 3.0772  \n",
      "\n",
      "Fold: 3  Epoch: 662  Training loss = 1.5541  Validation loss = 3.0771  \n",
      "\n",
      "Fold: 3  Epoch: 663  Training loss = 1.5540  Validation loss = 3.0770  \n",
      "\n",
      "Fold: 3  Epoch: 664  Training loss = 1.5540  Validation loss = 3.0770  \n",
      "\n",
      "Fold: 3  Epoch: 665  Training loss = 1.5540  Validation loss = 3.0768  \n",
      "\n",
      "Fold: 3  Epoch: 666  Training loss = 1.5539  Validation loss = 3.0766  \n",
      "\n",
      "Fold: 3  Epoch: 667  Training loss = 1.5539  Validation loss = 3.0765  \n",
      "\n",
      "Fold: 3  Epoch: 668  Training loss = 1.5538  Validation loss = 3.0762  \n",
      "\n",
      "Fold: 3  Epoch: 669  Training loss = 1.5538  Validation loss = 3.0759  \n",
      "\n",
      "Fold: 3  Epoch: 670  Training loss = 1.5537  Validation loss = 3.0754  \n",
      "\n",
      "Fold: 3  Epoch: 671  Training loss = 1.5536  Validation loss = 3.0751  \n",
      "\n",
      "Fold: 3  Epoch: 672  Training loss = 1.5536  Validation loss = 3.0745  \n",
      "\n",
      "Fold: 3  Epoch: 673  Training loss = 1.5535  Validation loss = 3.0742  \n",
      "\n",
      "Fold: 3  Epoch: 674  Training loss = 1.5534  Validation loss = 3.0739  \n",
      "\n",
      "Fold: 3  Epoch: 675  Training loss = 1.5534  Validation loss = 3.0736  \n",
      "\n",
      "Fold: 3  Epoch: 676  Training loss = 1.5533  Validation loss = 3.0732  \n",
      "\n",
      "Fold: 3  Epoch: 677  Training loss = 1.5533  Validation loss = 3.0730  \n",
      "\n",
      "Fold: 3  Epoch: 678  Training loss = 1.5532  Validation loss = 3.0727  \n",
      "\n",
      "Fold: 3  Epoch: 679  Training loss = 1.5532  Validation loss = 3.0722  \n",
      "\n",
      "Fold: 3  Epoch: 680  Training loss = 1.5531  Validation loss = 3.0718  \n",
      "\n",
      "Fold: 3  Epoch: 681  Training loss = 1.5531  Validation loss = 3.0718  \n",
      "\n",
      "Fold: 3  Epoch: 682  Training loss = 1.5530  Validation loss = 3.0718  \n",
      "\n",
      "Fold: 3  Epoch: 683  Training loss = 1.5530  Validation loss = 3.0717  \n",
      "\n",
      "Fold: 3  Epoch: 684  Training loss = 1.5530  Validation loss = 3.0714  \n",
      "\n",
      "Fold: 3  Epoch: 685  Training loss = 1.5529  Validation loss = 3.0709  \n",
      "\n",
      "Fold: 3  Epoch: 686  Training loss = 1.5529  Validation loss = 3.0712  \n",
      "\n",
      "Fold: 3  Epoch: 687  Training loss = 1.5529  Validation loss = 3.0713  \n",
      "\n",
      "Fold: 3  Epoch: 688  Training loss = 1.5528  Validation loss = 3.0711  \n",
      "\n",
      "Fold: 3  Epoch: 689  Training loss = 1.5528  Validation loss = 3.0709  \n",
      "\n",
      "Fold: 3  Epoch: 690  Training loss = 1.5528  Validation loss = 3.0711  \n",
      "\n",
      "Fold: 3  Epoch: 691  Training loss = 1.5527  Validation loss = 3.0708  \n",
      "\n",
      "Fold: 3  Epoch: 692  Training loss = 1.5527  Validation loss = 3.0706  \n",
      "\n",
      "Fold: 3  Epoch: 693  Training loss = 1.5526  Validation loss = 3.0703  \n",
      "\n",
      "Fold: 3  Epoch: 694  Training loss = 1.5526  Validation loss = 3.0701  \n",
      "\n",
      "Fold: 3  Epoch: 695  Training loss = 1.5526  Validation loss = 3.0701  \n",
      "\n",
      "Fold: 3  Epoch: 696  Training loss = 1.5525  Validation loss = 3.0700  \n",
      "\n",
      "Fold: 3  Epoch: 697  Training loss = 1.5524  Validation loss = 3.0693  \n",
      "\n",
      "Fold: 3  Epoch: 698  Training loss = 1.5523  Validation loss = 3.0691  \n",
      "\n",
      "Fold: 3  Epoch: 699  Training loss = 1.5523  Validation loss = 3.0688  \n",
      "\n",
      "Fold: 3  Epoch: 700  Training loss = 1.5522  Validation loss = 3.0685  \n",
      "\n",
      "Fold: 3  Epoch: 701  Training loss = 1.5522  Validation loss = 3.0684  \n",
      "\n",
      "Fold: 3  Epoch: 702  Training loss = 1.5522  Validation loss = 3.0683  \n",
      "\n",
      "Fold: 3  Epoch: 703  Training loss = 1.5521  Validation loss = 3.0682  \n",
      "\n",
      "Fold: 3  Epoch: 704  Training loss = 1.5521  Validation loss = 3.0680  \n",
      "\n",
      "Fold: 3  Epoch: 705  Training loss = 1.5520  Validation loss = 3.0676  \n",
      "\n",
      "Fold: 3  Epoch: 706  Training loss = 1.5520  Validation loss = 3.0673  \n",
      "\n",
      "Fold: 3  Epoch: 707  Training loss = 1.5519  Validation loss = 3.0669  \n",
      "\n",
      "Fold: 3  Epoch: 708  Training loss = 1.5519  Validation loss = 3.0667  \n",
      "\n",
      "Fold: 3  Epoch: 709  Training loss = 1.5518  Validation loss = 3.0661  \n",
      "\n",
      "Fold: 3  Epoch: 710  Training loss = 1.5517  Validation loss = 3.0660  \n",
      "\n",
      "Fold: 3  Epoch: 711  Training loss = 1.5517  Validation loss = 3.0657  \n",
      "\n",
      "Fold: 3  Epoch: 712  Training loss = 1.5516  Validation loss = 3.0653  \n",
      "\n",
      "Fold: 3  Epoch: 713  Training loss = 1.5516  Validation loss = 3.0649  \n",
      "\n",
      "Fold: 3  Epoch: 714  Training loss = 1.5515  Validation loss = 3.0648  \n",
      "\n",
      "Fold: 3  Epoch: 715  Training loss = 1.5515  Validation loss = 3.0646  \n",
      "\n",
      "Fold: 3  Epoch: 716  Training loss = 1.5515  Validation loss = 3.0644  \n",
      "\n",
      "Fold: 3  Epoch: 717  Training loss = 1.5514  Validation loss = 3.0643  \n",
      "\n",
      "Fold: 3  Epoch: 718  Training loss = 1.5514  Validation loss = 3.0642  \n",
      "\n",
      "Fold: 3  Epoch: 719  Training loss = 1.5514  Validation loss = 3.0641  \n",
      "\n",
      "Fold: 3  Epoch: 720  Training loss = 1.5514  Validation loss = 3.0640  \n",
      "\n",
      "Fold: 3  Epoch: 721  Training loss = 1.5513  Validation loss = 3.0638  \n",
      "\n",
      "Fold: 3  Epoch: 722  Training loss = 1.5513  Validation loss = 3.0635  \n",
      "\n",
      "Fold: 3  Epoch: 723  Training loss = 1.5512  Validation loss = 3.0634  \n",
      "\n",
      "Fold: 3  Epoch: 724  Training loss = 1.5512  Validation loss = 3.0631  \n",
      "\n",
      "Fold: 3  Epoch: 725  Training loss = 1.5511  Validation loss = 3.0627  \n",
      "\n",
      "Fold: 3  Epoch: 726  Training loss = 1.5511  Validation loss = 3.0624  \n",
      "\n",
      "Fold: 3  Epoch: 727  Training loss = 1.5510  Validation loss = 3.0621  \n",
      "\n",
      "Fold: 3  Epoch: 728  Training loss = 1.5510  Validation loss = 3.0620  \n",
      "\n",
      "Fold: 3  Epoch: 729  Training loss = 1.5510  Validation loss = 3.0618  \n",
      "\n",
      "Fold: 3  Epoch: 730  Training loss = 1.5509  Validation loss = 3.0616  \n",
      "\n",
      "Fold: 3  Epoch: 731  Training loss = 1.5509  Validation loss = 3.0614  \n",
      "\n",
      "Fold: 3  Epoch: 732  Training loss = 1.5509  Validation loss = 3.0614  \n",
      "\n",
      "Fold: 3  Epoch: 733  Training loss = 1.5508  Validation loss = 3.0614  \n",
      "\n",
      "Fold: 3  Epoch: 734  Training loss = 1.5508  Validation loss = 3.0613  \n",
      "\n",
      "Fold: 3  Epoch: 735  Training loss = 1.5507  Validation loss = 3.0610  \n",
      "\n",
      "Fold: 3  Epoch: 736  Training loss = 1.5507  Validation loss = 3.0609  \n",
      "\n",
      "Fold: 3  Epoch: 737  Training loss = 1.5507  Validation loss = 3.0606  \n",
      "\n",
      "Fold: 3  Epoch: 738  Training loss = 1.5506  Validation loss = 3.0604  \n",
      "\n",
      "Fold: 3  Epoch: 739  Training loss = 1.5506  Validation loss = 3.0600  \n",
      "\n",
      "Fold: 3  Epoch: 740  Training loss = 1.5505  Validation loss = 3.0593  \n",
      "\n",
      "Fold: 3  Epoch: 741  Training loss = 1.5504  Validation loss = 3.0590  \n",
      "\n",
      "Fold: 3  Epoch: 742  Training loss = 1.5504  Validation loss = 3.0590  \n",
      "\n",
      "Fold: 3  Epoch: 743  Training loss = 1.5503  Validation loss = 3.0592  \n",
      "\n",
      "Fold: 3  Epoch: 744  Training loss = 1.5503  Validation loss = 3.0589  \n",
      "\n",
      "Fold: 3  Epoch: 745  Training loss = 1.5503  Validation loss = 3.0590  \n",
      "\n",
      "Fold: 3  Epoch: 746  Training loss = 1.5502  Validation loss = 3.0587  \n",
      "\n",
      "Fold: 3  Epoch: 747  Training loss = 1.5502  Validation loss = 3.0585  \n",
      "\n",
      "Fold: 3  Epoch: 748  Training loss = 1.5502  Validation loss = 3.0583  \n",
      "\n",
      "Fold: 3  Epoch: 749  Training loss = 1.5501  Validation loss = 3.0584  \n",
      "\n",
      "Fold: 3  Epoch: 750  Training loss = 1.5501  Validation loss = 3.0585  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 748  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.6259  Validation loss = 4.3556  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.6258  Validation loss = 4.3551  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.6257  Validation loss = 4.3547  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.6257  Validation loss = 4.3545  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.6257  Validation loss = 4.3545  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.6256  Validation loss = 4.3543  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.6255  Validation loss = 4.3538  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.6254  Validation loss = 4.3533  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.6253  Validation loss = 4.3525  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.6252  Validation loss = 4.3522  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.6251  Validation loss = 4.3519  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.6251  Validation loss = 4.3516  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.6250  Validation loss = 4.3514  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.6249  Validation loss = 4.3506  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.6247  Validation loss = 4.3496  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.6246  Validation loss = 4.3490  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.6245  Validation loss = 4.3485  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.6243  Validation loss = 4.3476  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.6242  Validation loss = 4.3472  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.6241  Validation loss = 4.3467  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.6240  Validation loss = 4.3460  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.6240  Validation loss = 4.3458  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.6239  Validation loss = 4.3454  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.6238  Validation loss = 4.3447  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.6236  Validation loss = 4.3438  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.6235  Validation loss = 4.3431  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.6234  Validation loss = 4.3429  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.6234  Validation loss = 4.3425  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.6233  Validation loss = 4.3421  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.6232  Validation loss = 4.3420  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.6232  Validation loss = 4.3416  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.6230  Validation loss = 4.3405  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.6229  Validation loss = 4.3400  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.6228  Validation loss = 4.3398  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.6227  Validation loss = 4.3395  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.6227  Validation loss = 4.3391  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.6226  Validation loss = 4.3388  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.6225  Validation loss = 4.3382  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.6224  Validation loss = 4.3376  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.6223  Validation loss = 4.3373  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.6222  Validation loss = 4.3369  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.6221  Validation loss = 4.3363  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.6220  Validation loss = 4.3360  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.6220  Validation loss = 4.3358  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.6219  Validation loss = 4.3354  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.6218  Validation loss = 4.3347  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.6216  Validation loss = 4.3342  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.6215  Validation loss = 4.3337  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.6214  Validation loss = 4.3331  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.6214  Validation loss = 4.3328  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.6213  Validation loss = 4.3326  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.6212  Validation loss = 4.3319  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.6211  Validation loss = 4.3314  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.6210  Validation loss = 4.3308  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.6210  Validation loss = 4.3307  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.6209  Validation loss = 4.3305  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.6208  Validation loss = 4.3298  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.6207  Validation loss = 4.3293  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.6207  Validation loss = 4.3294  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.6207  Validation loss = 4.3294  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.6206  Validation loss = 4.3291  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.6205  Validation loss = 4.3289  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.6204  Validation loss = 4.3285  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.6204  Validation loss = 4.3283  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.6203  Validation loss = 4.3278  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.6202  Validation loss = 4.3275  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.6201  Validation loss = 4.3272  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.6200  Validation loss = 4.3263  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.6199  Validation loss = 4.3261  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.6198  Validation loss = 4.3257  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.6197  Validation loss = 4.3251  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.6196  Validation loss = 4.3245  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.6195  Validation loss = 4.3241  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.6194  Validation loss = 4.3236  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.6194  Validation loss = 4.3232  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.6193  Validation loss = 4.3229  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.6192  Validation loss = 4.3224  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.6191  Validation loss = 4.3219  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.6191  Validation loss = 4.3218  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.6190  Validation loss = 4.3214  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.6189  Validation loss = 4.3208  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.6187  Validation loss = 4.3201  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.6187  Validation loss = 4.3201  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.6186  Validation loss = 4.3195  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.6185  Validation loss = 4.3189  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.6184  Validation loss = 4.3185  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.6182  Validation loss = 4.3175  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.6182  Validation loss = 4.3175  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.6181  Validation loss = 4.3170  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.6180  Validation loss = 4.3163  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.6179  Validation loss = 4.3159  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.6178  Validation loss = 4.3153  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.6177  Validation loss = 4.3151  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.6176  Validation loss = 4.3144  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.6175  Validation loss = 4.3140  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.6174  Validation loss = 4.3134  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.6173  Validation loss = 4.3131  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.6173  Validation loss = 4.3130  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.6171  Validation loss = 4.3122  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.6170  Validation loss = 4.3113  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.6168  Validation loss = 4.3105  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.6168  Validation loss = 4.3102  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.6167  Validation loss = 4.3098  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.6166  Validation loss = 4.3095  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.6165  Validation loss = 4.3091  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.6165  Validation loss = 4.3093  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.6165  Validation loss = 4.3088  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.6164  Validation loss = 4.3085  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.6163  Validation loss = 4.3081  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.6162  Validation loss = 4.3078  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.6162  Validation loss = 4.3074  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.6161  Validation loss = 4.3069  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.6160  Validation loss = 4.3067  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.6159  Validation loss = 4.3057  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.6157  Validation loss = 4.3051  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.6156  Validation loss = 4.3045  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.6155  Validation loss = 4.3041  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.6155  Validation loss = 4.3037  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.6154  Validation loss = 4.3031  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.6152  Validation loss = 4.3022  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.6150  Validation loss = 4.3013  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.6150  Validation loss = 4.3011  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.6149  Validation loss = 4.3008  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.6148  Validation loss = 4.3000  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.6147  Validation loss = 4.2996  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.6146  Validation loss = 4.2993  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.6146  Validation loss = 4.2991  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.6145  Validation loss = 4.2988  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.6144  Validation loss = 4.2984  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.6144  Validation loss = 4.2982  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.6143  Validation loss = 4.2978  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.6142  Validation loss = 4.2974  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.6142  Validation loss = 4.2973  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.6141  Validation loss = 4.2968  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.6140  Validation loss = 4.2964  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.6139  Validation loss = 4.2959  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.6138  Validation loss = 4.2953  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.6137  Validation loss = 4.2949  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.6136  Validation loss = 4.2942  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.6135  Validation loss = 4.2940  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.6134  Validation loss = 4.2934  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.6133  Validation loss = 4.2929  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.6132  Validation loss = 4.2920  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.6131  Validation loss = 4.2919  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.6130  Validation loss = 4.2913  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.6130  Validation loss = 4.2912  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.6129  Validation loss = 4.2910  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.6128  Validation loss = 4.2905  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.6127  Validation loss = 4.2899  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.6126  Validation loss = 4.2893  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.6126  Validation loss = 4.2892  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.6125  Validation loss = 4.2889  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.6125  Validation loss = 4.2884  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.6124  Validation loss = 4.2880  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.6123  Validation loss = 4.2878  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.6123  Validation loss = 4.2875  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.6122  Validation loss = 4.2872  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.6122  Validation loss = 4.2871  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.6121  Validation loss = 4.2867  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.6120  Validation loss = 4.2862  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.6120  Validation loss = 4.2860  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.6119  Validation loss = 4.2857  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.6118  Validation loss = 4.2852  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.6117  Validation loss = 4.2848  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.6117  Validation loss = 4.2846  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.6115  Validation loss = 4.2839  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.6114  Validation loss = 4.2831  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.6112  Validation loss = 4.2823  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.6111  Validation loss = 4.2816  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.6110  Validation loss = 4.2812  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.6109  Validation loss = 4.2807  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.6108  Validation loss = 4.2798  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.6107  Validation loss = 4.2794  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.6106  Validation loss = 4.2789  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.6105  Validation loss = 4.2786  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.6104  Validation loss = 4.2781  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.6103  Validation loss = 4.2774  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.6102  Validation loss = 4.2768  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.6101  Validation loss = 4.2764  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.6101  Validation loss = 4.2761  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.6100  Validation loss = 4.2757  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.6099  Validation loss = 4.2753  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.6098  Validation loss = 4.2749  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.6097  Validation loss = 4.2746  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.6096  Validation loss = 4.2740  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.6095  Validation loss = 4.2734  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.6095  Validation loss = 4.2733  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.6094  Validation loss = 4.2727  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.6092  Validation loss = 4.2717  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.6091  Validation loss = 4.2713  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.6090  Validation loss = 4.2708  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.6089  Validation loss = 4.2703  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.6088  Validation loss = 4.2696  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.6087  Validation loss = 4.2691  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.6085  Validation loss = 4.2685  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.6085  Validation loss = 4.2680  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.6084  Validation loss = 4.2675  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.6082  Validation loss = 4.2668  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.6081  Validation loss = 4.2662  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.6081  Validation loss = 4.2659  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.6080  Validation loss = 4.2655  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.6078  Validation loss = 4.2646  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.6077  Validation loss = 4.2642  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.6077  Validation loss = 4.2643  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.6076  Validation loss = 4.2641  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.6076  Validation loss = 4.2637  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.6075  Validation loss = 4.2632  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.6073  Validation loss = 4.2625  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.6072  Validation loss = 4.2620  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.6072  Validation loss = 4.2616  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.6071  Validation loss = 4.2613  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.6070  Validation loss = 4.2609  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.6069  Validation loss = 4.2607  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.6068  Validation loss = 4.2603  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.6068  Validation loss = 4.2601  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.6066  Validation loss = 4.2594  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.6066  Validation loss = 4.2590  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.6064  Validation loss = 4.2579  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.6063  Validation loss = 4.2575  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.6061  Validation loss = 4.2568  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.6061  Validation loss = 4.2565  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.6059  Validation loss = 4.2556  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.6058  Validation loss = 4.2550  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.6058  Validation loss = 4.2550  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.6057  Validation loss = 4.2546  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.6056  Validation loss = 4.2541  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.6055  Validation loss = 4.2533  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.6054  Validation loss = 4.2531  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.6054  Validation loss = 4.2529  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.6052  Validation loss = 4.2523  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.6052  Validation loss = 4.2520  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.6051  Validation loss = 4.2516  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.6050  Validation loss = 4.2512  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.6049  Validation loss = 4.2505  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.6048  Validation loss = 4.2500  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.6047  Validation loss = 4.2497  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.6046  Validation loss = 4.2493  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.6046  Validation loss = 4.2493  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.6045  Validation loss = 4.2486  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.6044  Validation loss = 4.2484  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.6043  Validation loss = 4.2475  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.6042  Validation loss = 4.2470  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.6041  Validation loss = 4.2464  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.6040  Validation loss = 4.2463  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.6039  Validation loss = 4.2460  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.6038  Validation loss = 4.2450  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.6036  Validation loss = 4.2444  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.6036  Validation loss = 4.2441  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.6034  Validation loss = 4.2435  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.6033  Validation loss = 4.2431  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.6033  Validation loss = 4.2428  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.6032  Validation loss = 4.2425  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.6032  Validation loss = 4.2423  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.6030  Validation loss = 4.2417  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.6030  Validation loss = 4.2414  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.6029  Validation loss = 4.2411  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.6029  Validation loss = 4.2410  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.6028  Validation loss = 4.2407  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.6027  Validation loss = 4.2401  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.6026  Validation loss = 4.2398  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.6026  Validation loss = 4.2396  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.6025  Validation loss = 4.2393  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.6024  Validation loss = 4.2391  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.6023  Validation loss = 4.2385  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.6022  Validation loss = 4.2381  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.6021  Validation loss = 4.2375  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.6020  Validation loss = 4.2369  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.6019  Validation loss = 4.2366  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.6019  Validation loss = 4.2364  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.6018  Validation loss = 4.2359  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.6017  Validation loss = 4.2354  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.6016  Validation loss = 4.2351  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.6015  Validation loss = 4.2347  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.6014  Validation loss = 4.2341  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.6013  Validation loss = 4.2333  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.6012  Validation loss = 4.2327  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.6010  Validation loss = 4.2321  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.6010  Validation loss = 4.2321  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.6009  Validation loss = 4.2315  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.6008  Validation loss = 4.2310  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.6007  Validation loss = 4.2306  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.6006  Validation loss = 4.2303  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.6005  Validation loss = 4.2297  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.6004  Validation loss = 4.2292  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.6003  Validation loss = 4.2285  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.6002  Validation loss = 4.2280  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.6001  Validation loss = 4.2275  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.6000  Validation loss = 4.2273  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.6000  Validation loss = 4.2270  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.5999  Validation loss = 4.2265  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.5998  Validation loss = 4.2259  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.5998  Validation loss = 4.2258  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.5997  Validation loss = 4.2258  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.5997  Validation loss = 4.2253  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.5995  Validation loss = 4.2245  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.5994  Validation loss = 4.2239  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.5993  Validation loss = 4.2232  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.5992  Validation loss = 4.2229  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.5991  Validation loss = 4.2224  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.5990  Validation loss = 4.2222  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.5989  Validation loss = 4.2217  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.5988  Validation loss = 4.2210  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.5987  Validation loss = 4.2202  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.5986  Validation loss = 4.2197  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.5984  Validation loss = 4.2190  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.5984  Validation loss = 4.2187  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.5983  Validation loss = 4.2184  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.5982  Validation loss = 4.2181  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.5981  Validation loss = 4.2172  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.5980  Validation loss = 4.2169  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.5980  Validation loss = 4.2167  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.5979  Validation loss = 4.2165  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.5978  Validation loss = 4.2159  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.5977  Validation loss = 4.2157  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.5977  Validation loss = 4.2154  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.5976  Validation loss = 4.2150  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.5975  Validation loss = 4.2147  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.5974  Validation loss = 4.2142  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.5974  Validation loss = 4.2142  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.5973  Validation loss = 4.2135  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.5972  Validation loss = 4.2132  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.5971  Validation loss = 4.2128  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.5970  Validation loss = 4.2123  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.5969  Validation loss = 4.2119  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.5969  Validation loss = 4.2119  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.5968  Validation loss = 4.2112  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.5967  Validation loss = 4.2108  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.5966  Validation loss = 4.2106  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.5965  Validation loss = 4.2104  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.5964  Validation loss = 4.2095  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.5963  Validation loss = 4.2091  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.5962  Validation loss = 4.2086  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.5961  Validation loss = 4.2084  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.5961  Validation loss = 4.2079  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.5959  Validation loss = 4.2075  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.5959  Validation loss = 4.2072  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.5958  Validation loss = 4.2069  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.5957  Validation loss = 4.2065  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.5957  Validation loss = 4.2064  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.5956  Validation loss = 4.2061  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.5954  Validation loss = 4.2057  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.5954  Validation loss = 4.2057  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.5953  Validation loss = 4.2050  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.5952  Validation loss = 4.2046  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.5951  Validation loss = 4.2040  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.5950  Validation loss = 4.2036  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.5949  Validation loss = 4.2030  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.5948  Validation loss = 4.2025  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.5947  Validation loss = 4.2019  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.5945  Validation loss = 4.2011  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.5944  Validation loss = 4.2006  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.5943  Validation loss = 4.2003  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.5943  Validation loss = 4.2002  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.5942  Validation loss = 4.1997  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.5941  Validation loss = 4.1993  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.5940  Validation loss = 4.1990  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.5939  Validation loss = 4.1987  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.5938  Validation loss = 4.1980  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.5937  Validation loss = 4.1974  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.5936  Validation loss = 4.1969  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.5935  Validation loss = 4.1967  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.5935  Validation loss = 4.1966  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.5933  Validation loss = 4.1958  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.5933  Validation loss = 4.1955  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.5932  Validation loss = 4.1953  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.5931  Validation loss = 4.1949  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.5931  Validation loss = 4.1947  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.5930  Validation loss = 4.1944  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.5930  Validation loss = 4.1945  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.5929  Validation loss = 4.1941  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.5928  Validation loss = 4.1939  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.5928  Validation loss = 4.1936  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.5927  Validation loss = 4.1930  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.5926  Validation loss = 4.1927  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.5925  Validation loss = 4.1923  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.5924  Validation loss = 4.1920  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.5923  Validation loss = 4.1914  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.5922  Validation loss = 4.1909  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.5922  Validation loss = 4.1908  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.5921  Validation loss = 4.1906  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.5920  Validation loss = 4.1899  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.5919  Validation loss = 4.1897  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.5919  Validation loss = 4.1896  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.5919  Validation loss = 4.1898  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.5918  Validation loss = 4.1893  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.5916  Validation loss = 4.1885  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.5915  Validation loss = 4.1878  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.5914  Validation loss = 4.1872  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.5913  Validation loss = 4.1872  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.5913  Validation loss = 4.1871  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.5912  Validation loss = 4.1869  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.5912  Validation loss = 4.1868  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.5911  Validation loss = 4.1864  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.5910  Validation loss = 4.1860  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.5909  Validation loss = 4.1855  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.5909  Validation loss = 4.1854  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.5908  Validation loss = 4.1854  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.5908  Validation loss = 4.1850  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.5907  Validation loss = 4.1846  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.5906  Validation loss = 4.1841  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.5905  Validation loss = 4.1837  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.5904  Validation loss = 4.1832  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.5903  Validation loss = 4.1829  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.5902  Validation loss = 4.1827  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.5901  Validation loss = 4.1822  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.5899  Validation loss = 4.1810  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.5898  Validation loss = 4.1807  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.5898  Validation loss = 4.1805  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.5897  Validation loss = 4.1805  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.5897  Validation loss = 4.1802  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.5896  Validation loss = 4.1801  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.5896  Validation loss = 4.1797  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.5895  Validation loss = 4.1794  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.5894  Validation loss = 4.1794  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.5894  Validation loss = 4.1790  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.5893  Validation loss = 4.1789  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.5892  Validation loss = 4.1784  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.5891  Validation loss = 4.1781  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.5891  Validation loss = 4.1779  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.5890  Validation loss = 4.1776  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.5889  Validation loss = 4.1771  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.5888  Validation loss = 4.1764  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.5887  Validation loss = 4.1763  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.5887  Validation loss = 4.1760  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.5886  Validation loss = 4.1757  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.5886  Validation loss = 4.1757  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.5884  Validation loss = 4.1749  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.5884  Validation loss = 4.1747  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.5883  Validation loss = 4.1747  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.5883  Validation loss = 4.1745  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.5882  Validation loss = 4.1740  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.5880  Validation loss = 4.1735  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.5880  Validation loss = 4.1732  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.5879  Validation loss = 4.1728  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.5878  Validation loss = 4.1726  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.5877  Validation loss = 4.1721  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.5876  Validation loss = 4.1719  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.5876  Validation loss = 4.1716  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.5875  Validation loss = 4.1711  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.5874  Validation loss = 4.1710  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.5874  Validation loss = 4.1709  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.5874  Validation loss = 4.1709  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.5874  Validation loss = 4.1709  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.5873  Validation loss = 4.1704  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.5872  Validation loss = 4.1701  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.5871  Validation loss = 4.1696  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.5870  Validation loss = 4.1690  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.5869  Validation loss = 4.1689  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.5868  Validation loss = 4.1686  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.5867  Validation loss = 4.1681  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.5867  Validation loss = 4.1679  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.5866  Validation loss = 4.1678  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.5866  Validation loss = 4.1677  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.5865  Validation loss = 4.1671  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.5864  Validation loss = 4.1667  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.5863  Validation loss = 4.1664  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.5862  Validation loss = 4.1660  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.5861  Validation loss = 4.1655  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.5860  Validation loss = 4.1653  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.5859  Validation loss = 4.1646  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.5857  Validation loss = 4.1641  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.5856  Validation loss = 4.1637  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.5856  Validation loss = 4.1633  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.5855  Validation loss = 4.1628  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.5854  Validation loss = 4.1625  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.5853  Validation loss = 4.1621  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.5852  Validation loss = 4.1619  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.5851  Validation loss = 4.1615  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.5851  Validation loss = 4.1617  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.5850  Validation loss = 4.1613  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.5850  Validation loss = 4.1613  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.5849  Validation loss = 4.1609  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.5848  Validation loss = 4.1608  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.5848  Validation loss = 4.1606  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.5847  Validation loss = 4.1602  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.5846  Validation loss = 4.1598  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.5845  Validation loss = 4.1594  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.5845  Validation loss = 4.1589  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.5844  Validation loss = 4.1586  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.5843  Validation loss = 4.1584  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.5843  Validation loss = 4.1583  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.5842  Validation loss = 4.1579  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.5841  Validation loss = 4.1576  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.5841  Validation loss = 4.1575  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.5841  Validation loss = 4.1574  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.5840  Validation loss = 4.1569  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.5839  Validation loss = 4.1569  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.5838  Validation loss = 4.1566  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.5837  Validation loss = 4.1560  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.5837  Validation loss = 4.1557  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.5835  Validation loss = 4.1552  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.5835  Validation loss = 4.1549  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.5834  Validation loss = 4.1544  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.5832  Validation loss = 4.1538  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.5831  Validation loss = 4.1533  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.5830  Validation loss = 4.1532  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.5829  Validation loss = 4.1527  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.5828  Validation loss = 4.1522  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.5827  Validation loss = 4.1517  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.5826  Validation loss = 4.1511  \n",
      "\n",
      "Fold: 4  Epoch: 501  Training loss = 1.5825  Validation loss = 4.1505  \n",
      "\n",
      "Fold: 4  Epoch: 502  Training loss = 1.5824  Validation loss = 4.1500  \n",
      "\n",
      "Fold: 4  Epoch: 503  Training loss = 1.5823  Validation loss = 4.1496  \n",
      "\n",
      "Fold: 4  Epoch: 504  Training loss = 1.5822  Validation loss = 4.1494  \n",
      "\n",
      "Fold: 4  Epoch: 505  Training loss = 1.5821  Validation loss = 4.1489  \n",
      "\n",
      "Fold: 4  Epoch: 506  Training loss = 1.5821  Validation loss = 4.1489  \n",
      "\n",
      "Fold: 4  Epoch: 507  Training loss = 1.5820  Validation loss = 4.1486  \n",
      "\n",
      "Fold: 4  Epoch: 508  Training loss = 1.5819  Validation loss = 4.1483  \n",
      "\n",
      "Fold: 4  Epoch: 509  Training loss = 1.5818  Validation loss = 4.1481  \n",
      "\n",
      "Fold: 4  Epoch: 510  Training loss = 1.5818  Validation loss = 4.1479  \n",
      "\n",
      "Fold: 4  Epoch: 511  Training loss = 1.5817  Validation loss = 4.1476  \n",
      "\n",
      "Fold: 4  Epoch: 512  Training loss = 1.5816  Validation loss = 4.1470  \n",
      "\n",
      "Fold: 4  Epoch: 513  Training loss = 1.5815  Validation loss = 4.1470  \n",
      "\n",
      "Fold: 4  Epoch: 514  Training loss = 1.5815  Validation loss = 4.1467  \n",
      "\n",
      "Fold: 4  Epoch: 515  Training loss = 1.5814  Validation loss = 4.1464  \n",
      "\n",
      "Fold: 4  Epoch: 516  Training loss = 1.5813  Validation loss = 4.1460  \n",
      "\n",
      "Fold: 4  Epoch: 517  Training loss = 1.5811  Validation loss = 4.1456  \n",
      "\n",
      "Fold: 4  Epoch: 518  Training loss = 1.5811  Validation loss = 4.1455  \n",
      "\n",
      "Fold: 4  Epoch: 519  Training loss = 1.5811  Validation loss = 4.1455  \n",
      "\n",
      "Fold: 4  Epoch: 520  Training loss = 1.5809  Validation loss = 4.1449  \n",
      "\n",
      "Fold: 4  Epoch: 521  Training loss = 1.5809  Validation loss = 4.1447  \n",
      "\n",
      "Fold: 4  Epoch: 522  Training loss = 1.5808  Validation loss = 4.1446  \n",
      "\n",
      "Fold: 4  Epoch: 523  Training loss = 1.5808  Validation loss = 4.1445  \n",
      "\n",
      "Fold: 4  Epoch: 524  Training loss = 1.5807  Validation loss = 4.1440  \n",
      "\n",
      "Fold: 4  Epoch: 525  Training loss = 1.5805  Validation loss = 4.1433  \n",
      "\n",
      "Fold: 4  Epoch: 526  Training loss = 1.5804  Validation loss = 4.1428  \n",
      "\n",
      "Fold: 4  Epoch: 527  Training loss = 1.5804  Validation loss = 4.1424  \n",
      "\n",
      "Fold: 4  Epoch: 528  Training loss = 1.5803  Validation loss = 4.1422  \n",
      "\n",
      "Fold: 4  Epoch: 529  Training loss = 1.5802  Validation loss = 4.1419  \n",
      "\n",
      "Fold: 4  Epoch: 530  Training loss = 1.5802  Validation loss = 4.1419  \n",
      "\n",
      "Fold: 4  Epoch: 531  Training loss = 1.5802  Validation loss = 4.1421  \n",
      "\n",
      "Fold: 4  Epoch: 532  Training loss = 1.5801  Validation loss = 4.1419  \n",
      "\n",
      "Fold: 4  Epoch: 533  Training loss = 1.5800  Validation loss = 4.1413  \n",
      "\n",
      "Fold: 4  Epoch: 534  Training loss = 1.5800  Validation loss = 4.1411  \n",
      "\n",
      "Fold: 4  Epoch: 535  Training loss = 1.5799  Validation loss = 4.1408  \n",
      "\n",
      "Fold: 4  Epoch: 536  Training loss = 1.5798  Validation loss = 4.1402  \n",
      "\n",
      "Fold: 4  Epoch: 537  Training loss = 1.5797  Validation loss = 4.1401  \n",
      "\n",
      "Fold: 4  Epoch: 538  Training loss = 1.5797  Validation loss = 4.1398  \n",
      "\n",
      "Fold: 4  Epoch: 539  Training loss = 1.5796  Validation loss = 4.1396  \n",
      "\n",
      "Fold: 4  Epoch: 540  Training loss = 1.5795  Validation loss = 4.1392  \n",
      "\n",
      "Fold: 4  Epoch: 541  Training loss = 1.5795  Validation loss = 4.1391  \n",
      "\n",
      "Fold: 4  Epoch: 542  Training loss = 1.5794  Validation loss = 4.1389  \n",
      "\n",
      "Fold: 4  Epoch: 543  Training loss = 1.5793  Validation loss = 4.1383  \n",
      "\n",
      "Fold: 4  Epoch: 544  Training loss = 1.5791  Validation loss = 4.1377  \n",
      "\n",
      "Fold: 4  Epoch: 545  Training loss = 1.5791  Validation loss = 4.1378  \n",
      "\n",
      "Fold: 4  Epoch: 546  Training loss = 1.5790  Validation loss = 4.1374  \n",
      "\n",
      "Fold: 4  Epoch: 547  Training loss = 1.5788  Validation loss = 4.1364  \n",
      "\n",
      "Fold: 4  Epoch: 548  Training loss = 1.5787  Validation loss = 4.1363  \n",
      "\n",
      "Fold: 4  Epoch: 549  Training loss = 1.5786  Validation loss = 4.1358  \n",
      "\n",
      "Fold: 4  Epoch: 550  Training loss = 1.5786  Validation loss = 4.1358  \n",
      "\n",
      "Fold: 4  Epoch: 551  Training loss = 1.5786  Validation loss = 4.1358  \n",
      "\n",
      "Fold: 4  Epoch: 552  Training loss = 1.5785  Validation loss = 4.1358  \n",
      "\n",
      "Fold: 4  Epoch: 553  Training loss = 1.5784  Validation loss = 4.1354  \n",
      "\n",
      "Fold: 4  Epoch: 554  Training loss = 1.5784  Validation loss = 4.1352  \n",
      "\n",
      "Fold: 4  Epoch: 555  Training loss = 1.5783  Validation loss = 4.1351  \n",
      "\n",
      "Fold: 4  Epoch: 556  Training loss = 1.5783  Validation loss = 4.1347  \n",
      "\n",
      "Fold: 4  Epoch: 557  Training loss = 1.5783  Validation loss = 4.1351  \n",
      "\n",
      "Fold: 4  Epoch: 558  Training loss = 1.5781  Validation loss = 4.1344  \n",
      "\n",
      "Fold: 4  Epoch: 559  Training loss = 1.5781  Validation loss = 4.1343  \n",
      "\n",
      "Fold: 4  Epoch: 560  Training loss = 1.5780  Validation loss = 4.1339  \n",
      "\n",
      "Fold: 4  Epoch: 561  Training loss = 1.5780  Validation loss = 4.1335  \n",
      "\n",
      "Fold: 4  Epoch: 562  Training loss = 1.5778  Validation loss = 4.1332  \n",
      "\n",
      "Fold: 4  Epoch: 563  Training loss = 1.5777  Validation loss = 4.1329  \n",
      "\n",
      "Fold: 4  Epoch: 564  Training loss = 1.5777  Validation loss = 4.1329  \n",
      "\n",
      "Fold: 4  Epoch: 565  Training loss = 1.5776  Validation loss = 4.1327  \n",
      "\n",
      "Fold: 4  Epoch: 566  Training loss = 1.5775  Validation loss = 4.1323  \n",
      "\n",
      "Fold: 4  Epoch: 567  Training loss = 1.5775  Validation loss = 4.1322  \n",
      "\n",
      "Fold: 4  Epoch: 568  Training loss = 1.5773  Validation loss = 4.1317  \n",
      "\n",
      "Fold: 4  Epoch: 569  Training loss = 1.5773  Validation loss = 4.1314  \n",
      "\n",
      "Fold: 4  Epoch: 570  Training loss = 1.5772  Validation loss = 4.1313  \n",
      "\n",
      "Fold: 4  Epoch: 571  Training loss = 1.5771  Validation loss = 4.1309  \n",
      "\n",
      "Fold: 4  Epoch: 572  Training loss = 1.5771  Validation loss = 4.1312  \n",
      "\n",
      "Fold: 4  Epoch: 573  Training loss = 1.5770  Validation loss = 4.1307  \n",
      "\n",
      "Fold: 4  Epoch: 574  Training loss = 1.5770  Validation loss = 4.1307  \n",
      "\n",
      "Fold: 4  Epoch: 575  Training loss = 1.5769  Validation loss = 4.1304  \n",
      "\n",
      "Fold: 4  Epoch: 576  Training loss = 1.5769  Validation loss = 4.1302  \n",
      "\n",
      "Fold: 4  Epoch: 577  Training loss = 1.5769  Validation loss = 4.1304  \n",
      "\n",
      "Fold: 4  Epoch: 578  Training loss = 1.5768  Validation loss = 4.1301  \n",
      "\n",
      "Fold: 4  Epoch: 579  Training loss = 1.5768  Validation loss = 4.1303  \n",
      "\n",
      "Fold: 4  Epoch: 580  Training loss = 1.5767  Validation loss = 4.1299  \n",
      "\n",
      "Fold: 4  Epoch: 581  Training loss = 1.5765  Validation loss = 4.1293  \n",
      "\n",
      "Fold: 4  Epoch: 582  Training loss = 1.5764  Validation loss = 4.1288  \n",
      "\n",
      "Fold: 4  Epoch: 583  Training loss = 1.5764  Validation loss = 4.1286  \n",
      "\n",
      "Fold: 4  Epoch: 584  Training loss = 1.5764  Validation loss = 4.1288  \n",
      "\n",
      "Fold: 4  Epoch: 585  Training loss = 1.5762  Validation loss = 4.1281  \n",
      "\n",
      "Fold: 4  Epoch: 586  Training loss = 1.5762  Validation loss = 4.1279  \n",
      "\n",
      "Fold: 4  Epoch: 587  Training loss = 1.5761  Validation loss = 4.1274  \n",
      "\n",
      "Fold: 4  Epoch: 588  Training loss = 1.5759  Validation loss = 4.1267  \n",
      "\n",
      "Fold: 4  Epoch: 589  Training loss = 1.5759  Validation loss = 4.1263  \n",
      "\n",
      "Fold: 4  Epoch: 590  Training loss = 1.5758  Validation loss = 4.1261  \n",
      "\n",
      "Fold: 4  Epoch: 591  Training loss = 1.5757  Validation loss = 4.1258  \n",
      "\n",
      "Fold: 4  Epoch: 592  Training loss = 1.5757  Validation loss = 4.1254  \n",
      "\n",
      "Fold: 4  Epoch: 593  Training loss = 1.5756  Validation loss = 4.1253  \n",
      "\n",
      "Fold: 4  Epoch: 594  Training loss = 1.5755  Validation loss = 4.1248  \n",
      "\n",
      "Fold: 4  Epoch: 595  Training loss = 1.5755  Validation loss = 4.1245  \n",
      "\n",
      "Fold: 4  Epoch: 596  Training loss = 1.5753  Validation loss = 4.1239  \n",
      "\n",
      "Fold: 4  Epoch: 597  Training loss = 1.5753  Validation loss = 4.1238  \n",
      "\n",
      "Fold: 4  Epoch: 598  Training loss = 1.5753  Validation loss = 4.1237  \n",
      "\n",
      "Fold: 4  Epoch: 599  Training loss = 1.5750  Validation loss = 4.1226  \n",
      "\n",
      "Fold: 4  Epoch: 600  Training loss = 1.5749  Validation loss = 4.1223  \n",
      "\n",
      "Fold: 4  Epoch: 601  Training loss = 1.5749  Validation loss = 4.1221  \n",
      "\n",
      "Fold: 4  Epoch: 602  Training loss = 1.5748  Validation loss = 4.1216  \n",
      "\n",
      "Fold: 4  Epoch: 603  Training loss = 1.5747  Validation loss = 4.1209  \n",
      "\n",
      "Fold: 4  Epoch: 604  Training loss = 1.5746  Validation loss = 4.1203  \n",
      "\n",
      "Fold: 4  Epoch: 605  Training loss = 1.5744  Validation loss = 4.1200  \n",
      "\n",
      "Fold: 4  Epoch: 606  Training loss = 1.5744  Validation loss = 4.1197  \n",
      "\n",
      "Fold: 4  Epoch: 607  Training loss = 1.5743  Validation loss = 4.1194  \n",
      "\n",
      "Fold: 4  Epoch: 608  Training loss = 1.5742  Validation loss = 4.1188  \n",
      "\n",
      "Fold: 4  Epoch: 609  Training loss = 1.5741  Validation loss = 4.1185  \n",
      "\n",
      "Fold: 4  Epoch: 610  Training loss = 1.5741  Validation loss = 4.1185  \n",
      "\n",
      "Fold: 4  Epoch: 611  Training loss = 1.5741  Validation loss = 4.1182  \n",
      "\n",
      "Fold: 4  Epoch: 612  Training loss = 1.5740  Validation loss = 4.1181  \n",
      "\n",
      "Fold: 4  Epoch: 613  Training loss = 1.5740  Validation loss = 4.1180  \n",
      "\n",
      "Fold: 4  Epoch: 614  Training loss = 1.5739  Validation loss = 4.1178  \n",
      "\n",
      "Fold: 4  Epoch: 615  Training loss = 1.5739  Validation loss = 4.1176  \n",
      "\n",
      "Fold: 4  Epoch: 616  Training loss = 1.5738  Validation loss = 4.1173  \n",
      "\n",
      "Fold: 4  Epoch: 617  Training loss = 1.5737  Validation loss = 4.1171  \n",
      "\n",
      "Fold: 4  Epoch: 618  Training loss = 1.5737  Validation loss = 4.1169  \n",
      "\n",
      "Fold: 4  Epoch: 619  Training loss = 1.5737  Validation loss = 4.1168  \n",
      "\n",
      "Fold: 4  Epoch: 620  Training loss = 1.5735  Validation loss = 4.1163  \n",
      "\n",
      "Fold: 4  Epoch: 621  Training loss = 1.5734  Validation loss = 4.1159  \n",
      "\n",
      "Fold: 4  Epoch: 622  Training loss = 1.5734  Validation loss = 4.1158  \n",
      "\n",
      "Fold: 4  Epoch: 623  Training loss = 1.5733  Validation loss = 4.1153  \n",
      "\n",
      "Fold: 4  Epoch: 624  Training loss = 1.5732  Validation loss = 4.1150  \n",
      "\n",
      "Fold: 4  Epoch: 625  Training loss = 1.5732  Validation loss = 4.1148  \n",
      "\n",
      "Fold: 4  Epoch: 626  Training loss = 1.5730  Validation loss = 4.1142  \n",
      "\n",
      "Fold: 4  Epoch: 627  Training loss = 1.5730  Validation loss = 4.1139  \n",
      "\n",
      "Fold: 4  Epoch: 628  Training loss = 1.5730  Validation loss = 4.1139  \n",
      "\n",
      "Fold: 4  Epoch: 629  Training loss = 1.5729  Validation loss = 4.1137  \n",
      "\n",
      "Fold: 4  Epoch: 630  Training loss = 1.5728  Validation loss = 4.1130  \n",
      "\n",
      "Fold: 4  Epoch: 631  Training loss = 1.5728  Validation loss = 4.1130  \n",
      "\n",
      "Fold: 4  Epoch: 632  Training loss = 1.5727  Validation loss = 4.1128  \n",
      "\n",
      "Fold: 4  Epoch: 633  Training loss = 1.5726  Validation loss = 4.1126  \n",
      "\n",
      "Fold: 4  Epoch: 634  Training loss = 1.5726  Validation loss = 4.1126  \n",
      "\n",
      "Fold: 4  Epoch: 635  Training loss = 1.5725  Validation loss = 4.1123  \n",
      "\n",
      "Fold: 4  Epoch: 636  Training loss = 1.5725  Validation loss = 4.1122  \n",
      "\n",
      "Fold: 4  Epoch: 637  Training loss = 1.5724  Validation loss = 4.1118  \n",
      "\n",
      "Fold: 4  Epoch: 638  Training loss = 1.5722  Validation loss = 4.1113  \n",
      "\n",
      "Fold: 4  Epoch: 639  Training loss = 1.5722  Validation loss = 4.1111  \n",
      "\n",
      "Fold: 4  Epoch: 640  Training loss = 1.5721  Validation loss = 4.1110  \n",
      "\n",
      "Fold: 4  Epoch: 641  Training loss = 1.5721  Validation loss = 4.1107  \n",
      "\n",
      "Fold: 4  Epoch: 642  Training loss = 1.5720  Validation loss = 4.1104  \n",
      "\n",
      "Fold: 4  Epoch: 643  Training loss = 1.5719  Validation loss = 4.1104  \n",
      "\n",
      "Fold: 4  Epoch: 644  Training loss = 1.5719  Validation loss = 4.1104  \n",
      "\n",
      "Fold: 4  Epoch: 645  Training loss = 1.5719  Validation loss = 4.1105  \n",
      "\n",
      "Fold: 4  Epoch: 646  Training loss = 1.5717  Validation loss = 4.1098  \n",
      "\n",
      "Fold: 4  Epoch: 647  Training loss = 1.5717  Validation loss = 4.1097  \n",
      "\n",
      "Fold: 4  Epoch: 648  Training loss = 1.5716  Validation loss = 4.1095  \n",
      "\n",
      "Fold: 4  Epoch: 649  Training loss = 1.5715  Validation loss = 4.1088  \n",
      "\n",
      "Fold: 4  Epoch: 650  Training loss = 1.5714  Validation loss = 4.1086  \n",
      "\n",
      "Fold: 4  Epoch: 651  Training loss = 1.5714  Validation loss = 4.1083  \n",
      "\n",
      "Fold: 4  Epoch: 652  Training loss = 1.5713  Validation loss = 4.1080  \n",
      "\n",
      "Fold: 4  Epoch: 653  Training loss = 1.5712  Validation loss = 4.1075  \n",
      "\n",
      "Fold: 4  Epoch: 654  Training loss = 1.5712  Validation loss = 4.1071  \n",
      "\n",
      "Fold: 4  Epoch: 655  Training loss = 1.5711  Validation loss = 4.1067  \n",
      "\n",
      "Fold: 4  Epoch: 656  Training loss = 1.5710  Validation loss = 4.1065  \n",
      "\n",
      "Fold: 4  Epoch: 657  Training loss = 1.5710  Validation loss = 4.1063  \n",
      "\n",
      "Fold: 4  Epoch: 658  Training loss = 1.5708  Validation loss = 4.1057  \n",
      "\n",
      "Fold: 4  Epoch: 659  Training loss = 1.5708  Validation loss = 4.1058  \n",
      "\n",
      "Fold: 4  Epoch: 660  Training loss = 1.5708  Validation loss = 4.1055  \n",
      "\n",
      "Fold: 4  Epoch: 661  Training loss = 1.5707  Validation loss = 4.1051  \n",
      "\n",
      "Fold: 4  Epoch: 662  Training loss = 1.5706  Validation loss = 4.1048  \n",
      "\n",
      "Fold: 4  Epoch: 663  Training loss = 1.5705  Validation loss = 4.1041  \n",
      "\n",
      "Fold: 4  Epoch: 664  Training loss = 1.5704  Validation loss = 4.1040  \n",
      "\n",
      "Fold: 4  Epoch: 665  Training loss = 1.5704  Validation loss = 4.1039  \n",
      "\n",
      "Fold: 4  Epoch: 666  Training loss = 1.5703  Validation loss = 4.1036  \n",
      "\n",
      "Fold: 4  Epoch: 667  Training loss = 1.5703  Validation loss = 4.1035  \n",
      "\n",
      "Fold: 4  Epoch: 668  Training loss = 1.5702  Validation loss = 4.1031  \n",
      "\n",
      "Fold: 4  Epoch: 669  Training loss = 1.5701  Validation loss = 4.1030  \n",
      "\n",
      "Fold: 4  Epoch: 670  Training loss = 1.5701  Validation loss = 4.1030  \n",
      "\n",
      "Fold: 4  Epoch: 671  Training loss = 1.5700  Validation loss = 4.1026  \n",
      "\n",
      "Fold: 4  Epoch: 672  Training loss = 1.5700  Validation loss = 4.1023  \n",
      "\n",
      "Fold: 4  Epoch: 673  Training loss = 1.5699  Validation loss = 4.1019  \n",
      "\n",
      "Fold: 4  Epoch: 674  Training loss = 1.5698  Validation loss = 4.1016  \n",
      "\n",
      "Fold: 4  Epoch: 675  Training loss = 1.5697  Validation loss = 4.1014  \n",
      "\n",
      "Fold: 4  Epoch: 676  Training loss = 1.5697  Validation loss = 4.1014  \n",
      "\n",
      "Fold: 4  Epoch: 677  Training loss = 1.5697  Validation loss = 4.1011  \n",
      "\n",
      "Fold: 4  Epoch: 678  Training loss = 1.5696  Validation loss = 4.1008  \n",
      "\n",
      "Fold: 4  Epoch: 679  Training loss = 1.5696  Validation loss = 4.1007  \n",
      "\n",
      "Fold: 4  Epoch: 680  Training loss = 1.5695  Validation loss = 4.1004  \n",
      "\n",
      "Fold: 4  Epoch: 681  Training loss = 1.5694  Validation loss = 4.1003  \n",
      "\n",
      "Fold: 4  Epoch: 682  Training loss = 1.5693  Validation loss = 4.0998  \n",
      "\n",
      "Fold: 4  Epoch: 683  Training loss = 1.5693  Validation loss = 4.0997  \n",
      "\n",
      "Fold: 4  Epoch: 684  Training loss = 1.5692  Validation loss = 4.0990  \n",
      "\n",
      "Fold: 4  Epoch: 685  Training loss = 1.5691  Validation loss = 4.0992  \n",
      "\n",
      "Fold: 4  Epoch: 686  Training loss = 1.5691  Validation loss = 4.0989  \n",
      "\n",
      "Fold: 4  Epoch: 687  Training loss = 1.5689  Validation loss = 4.0982  \n",
      "\n",
      "Fold: 4  Epoch: 688  Training loss = 1.5689  Validation loss = 4.0978  \n",
      "\n",
      "Fold: 4  Epoch: 689  Training loss = 1.5688  Validation loss = 4.0979  \n",
      "\n",
      "Fold: 4  Epoch: 690  Training loss = 1.5688  Validation loss = 4.0976  \n",
      "\n",
      "Fold: 4  Epoch: 691  Training loss = 1.5687  Validation loss = 4.0974  \n",
      "\n",
      "Fold: 4  Epoch: 692  Training loss = 1.5687  Validation loss = 4.0972  \n",
      "\n",
      "Fold: 4  Epoch: 693  Training loss = 1.5686  Validation loss = 4.0970  \n",
      "\n",
      "Fold: 4  Epoch: 694  Training loss = 1.5686  Validation loss = 4.0970  \n",
      "\n",
      "Fold: 4  Epoch: 695  Training loss = 1.5686  Validation loss = 4.0970  \n",
      "\n",
      "Fold: 4  Epoch: 696  Training loss = 1.5685  Validation loss = 4.0968  \n",
      "\n",
      "Fold: 4  Epoch: 697  Training loss = 1.5684  Validation loss = 4.0967  \n",
      "\n",
      "Fold: 4  Epoch: 698  Training loss = 1.5684  Validation loss = 4.0965  \n",
      "\n",
      "Fold: 4  Epoch: 699  Training loss = 1.5683  Validation loss = 4.0962  \n",
      "\n",
      "Fold: 4  Epoch: 700  Training loss = 1.5683  Validation loss = 4.0961  \n",
      "\n",
      "Fold: 4  Epoch: 701  Training loss = 1.5682  Validation loss = 4.0957  \n",
      "\n",
      "Fold: 4  Epoch: 702  Training loss = 1.5682  Validation loss = 4.0955  \n",
      "\n",
      "Fold: 4  Epoch: 703  Training loss = 1.5681  Validation loss = 4.0954  \n",
      "\n",
      "Fold: 4  Epoch: 704  Training loss = 1.5681  Validation loss = 4.0955  \n",
      "\n",
      "Fold: 4  Epoch: 705  Training loss = 1.5680  Validation loss = 4.0953  \n",
      "\n",
      "Fold: 4  Epoch: 706  Training loss = 1.5679  Validation loss = 4.0948  \n",
      "\n",
      "Fold: 4  Epoch: 707  Training loss = 1.5679  Validation loss = 4.0948  \n",
      "\n",
      "Fold: 4  Epoch: 708  Training loss = 1.5678  Validation loss = 4.0947  \n",
      "\n",
      "Fold: 4  Epoch: 709  Training loss = 1.5678  Validation loss = 4.0948  \n",
      "\n",
      "Fold: 4  Epoch: 710  Training loss = 1.5678  Validation loss = 4.0947  \n",
      "\n",
      "Fold: 4  Epoch: 711  Training loss = 1.5677  Validation loss = 4.0944  \n",
      "\n",
      "Fold: 4  Epoch: 712  Training loss = 1.5677  Validation loss = 4.0940  \n",
      "\n",
      "Fold: 4  Epoch: 713  Training loss = 1.5676  Validation loss = 4.0939  \n",
      "\n",
      "Fold: 4  Epoch: 714  Training loss = 1.5675  Validation loss = 4.0936  \n",
      "\n",
      "Fold: 4  Epoch: 715  Training loss = 1.5675  Validation loss = 4.0934  \n",
      "\n",
      "Fold: 4  Epoch: 716  Training loss = 1.5674  Validation loss = 4.0933  \n",
      "\n",
      "Fold: 4  Epoch: 717  Training loss = 1.5674  Validation loss = 4.0932  \n",
      "\n",
      "Fold: 4  Epoch: 718  Training loss = 1.5673  Validation loss = 4.0927  \n",
      "\n",
      "Fold: 4  Epoch: 719  Training loss = 1.5673  Validation loss = 4.0926  \n",
      "\n",
      "Fold: 4  Epoch: 720  Training loss = 1.5672  Validation loss = 4.0919  \n",
      "\n",
      "Fold: 4  Epoch: 721  Training loss = 1.5671  Validation loss = 4.0914  \n",
      "\n",
      "Fold: 4  Epoch: 722  Training loss = 1.5671  Validation loss = 4.0912  \n",
      "\n",
      "Fold: 4  Epoch: 723  Training loss = 1.5670  Validation loss = 4.0910  \n",
      "\n",
      "Fold: 4  Epoch: 724  Training loss = 1.5670  Validation loss = 4.0908  \n",
      "\n",
      "Fold: 4  Epoch: 725  Training loss = 1.5669  Validation loss = 4.0907  \n",
      "\n",
      "Fold: 4  Epoch: 726  Training loss = 1.5669  Validation loss = 4.0905  \n",
      "\n",
      "Fold: 4  Epoch: 727  Training loss = 1.5668  Validation loss = 4.0904  \n",
      "\n",
      "Fold: 4  Epoch: 728  Training loss = 1.5668  Validation loss = 4.0904  \n",
      "\n",
      "Fold: 4  Epoch: 729  Training loss = 1.5667  Validation loss = 4.0901  \n",
      "\n",
      "Fold: 4  Epoch: 730  Training loss = 1.5667  Validation loss = 4.0900  \n",
      "\n",
      "Fold: 4  Epoch: 731  Training loss = 1.5666  Validation loss = 4.0898  \n",
      "\n",
      "Fold: 4  Epoch: 732  Training loss = 1.5665  Validation loss = 4.0891  \n",
      "\n",
      "Fold: 4  Epoch: 733  Training loss = 1.5665  Validation loss = 4.0892  \n",
      "\n",
      "Fold: 4  Epoch: 734  Training loss = 1.5665  Validation loss = 4.0892  \n",
      "\n",
      "Fold: 4  Epoch: 735  Training loss = 1.5665  Validation loss = 4.0894  \n",
      "\n",
      "Fold: 4  Epoch: 736  Training loss = 1.5664  Validation loss = 4.0893  \n",
      "\n",
      "Fold: 4  Epoch: 737  Training loss = 1.5664  Validation loss = 4.0893  \n",
      "\n",
      "Fold: 4  Epoch: 738  Training loss = 1.5663  Validation loss = 4.0889  \n",
      "\n",
      "Fold: 4  Epoch: 739  Training loss = 1.5663  Validation loss = 4.0889  \n",
      "\n",
      "Fold: 4  Epoch: 740  Training loss = 1.5663  Validation loss = 4.0887  \n",
      "\n",
      "Fold: 4  Epoch: 741  Training loss = 1.5662  Validation loss = 4.0886  \n",
      "\n",
      "Fold: 4  Epoch: 742  Training loss = 1.5662  Validation loss = 4.0883  \n",
      "\n",
      "Fold: 4  Epoch: 743  Training loss = 1.5661  Validation loss = 4.0882  \n",
      "\n",
      "Fold: 4  Epoch: 744  Training loss = 1.5660  Validation loss = 4.0879  \n",
      "\n",
      "Fold: 4  Epoch: 745  Training loss = 1.5660  Validation loss = 4.0877  \n",
      "\n",
      "Fold: 4  Epoch: 746  Training loss = 1.5659  Validation loss = 4.0871  \n",
      "\n",
      "Fold: 4  Epoch: 747  Training loss = 1.5658  Validation loss = 4.0869  \n",
      "\n",
      "Fold: 4  Epoch: 748  Training loss = 1.5657  Validation loss = 4.0866  \n",
      "\n",
      "Fold: 4  Epoch: 749  Training loss = 1.5657  Validation loss = 4.0862  \n",
      "\n",
      "Fold: 4  Epoch: 750  Training loss = 1.5655  Validation loss = 4.0856  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 750  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.8135  Validation loss = 3.8548  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.8133  Validation loss = 3.8543  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.8132  Validation loss = 3.8543  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.8131  Validation loss = 3.8540  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.8129  Validation loss = 3.8528  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.8126  Validation loss = 3.8515  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.8124  Validation loss = 3.8505  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.8122  Validation loss = 3.8498  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.8121  Validation loss = 3.8495  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.8120  Validation loss = 3.8495  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.8118  Validation loss = 3.8493  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.8117  Validation loss = 3.8490  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.8117  Validation loss = 3.8489  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.8115  Validation loss = 3.8484  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.8113  Validation loss = 3.8476  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.8111  Validation loss = 3.8469  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.8109  Validation loss = 3.8460  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.8106  Validation loss = 3.8446  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.8104  Validation loss = 3.8438  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.8102  Validation loss = 3.8430  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.8101  Validation loss = 3.8425  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.8100  Validation loss = 3.8421  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.8099  Validation loss = 3.8417  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.8098  Validation loss = 3.8414  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.8096  Validation loss = 3.8407  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.8094  Validation loss = 3.8400  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.8093  Validation loss = 3.8399  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.8091  Validation loss = 3.8392  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.8090  Validation loss = 3.8387  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.8089  Validation loss = 3.8381  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.8086  Validation loss = 3.8373  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.8084  Validation loss = 3.8360  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.8082  Validation loss = 3.8353  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.8081  Validation loss = 3.8349  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.8079  Validation loss = 3.8344  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.8078  Validation loss = 3.8340  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.8076  Validation loss = 3.8331  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.8074  Validation loss = 3.8325  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.8072  Validation loss = 3.8318  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.8071  Validation loss = 3.8316  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.8069  Validation loss = 3.8310  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.8069  Validation loss = 3.8308  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.8067  Validation loss = 3.8307  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.8064  Validation loss = 3.8291  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.8063  Validation loss = 3.8289  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.8061  Validation loss = 3.8280  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.8059  Validation loss = 3.8276  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.8057  Validation loss = 3.8266  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.8056  Validation loss = 3.8265  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.8054  Validation loss = 3.8261  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.8052  Validation loss = 3.8251  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.8050  Validation loss = 3.8241  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.8048  Validation loss = 3.8240  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.8047  Validation loss = 3.8232  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.8045  Validation loss = 3.8227  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.8043  Validation loss = 3.8221  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.8042  Validation loss = 3.8213  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.8041  Validation loss = 3.8209  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.8041  Validation loss = 3.8214  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.8039  Validation loss = 3.8213  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.8038  Validation loss = 3.8206  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.8037  Validation loss = 3.8206  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.8036  Validation loss = 3.8206  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.8035  Validation loss = 3.8203  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.8034  Validation loss = 3.8196  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.8032  Validation loss = 3.8192  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.8031  Validation loss = 3.8186  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.8029  Validation loss = 3.8181  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.8027  Validation loss = 3.8172  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.8025  Validation loss = 3.8168  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.8024  Validation loss = 3.8162  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.8023  Validation loss = 3.8160  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.8021  Validation loss = 3.8153  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.8020  Validation loss = 3.8152  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.8018  Validation loss = 3.8140  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.8016  Validation loss = 3.8136  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.8013  Validation loss = 3.8123  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 1.8012  Validation loss = 3.8118  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 1.8010  Validation loss = 3.8113  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 1.8009  Validation loss = 3.8111  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 1.8008  Validation loss = 3.8104  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 1.8006  Validation loss = 3.8096  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 1.8005  Validation loss = 3.8093  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 1.8003  Validation loss = 3.8084  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 1.8001  Validation loss = 3.8077  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 1.8000  Validation loss = 3.8078  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 1.7999  Validation loss = 3.8076  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 1.7997  Validation loss = 3.8070  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 1.7996  Validation loss = 3.8066  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 1.7994  Validation loss = 3.8055  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 1.7994  Validation loss = 3.8054  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 1.7992  Validation loss = 3.8047  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 1.7990  Validation loss = 3.8039  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 1.7988  Validation loss = 3.8030  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 1.7986  Validation loss = 3.8024  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 1.7986  Validation loss = 3.8025  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 1.7986  Validation loss = 3.8029  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 1.7984  Validation loss = 3.8024  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 1.7984  Validation loss = 3.8027  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 1.7982  Validation loss = 3.8020  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 1.7980  Validation loss = 3.8007  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 1.7978  Validation loss = 3.7999  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 1.7977  Validation loss = 3.7991  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 1.7975  Validation loss = 3.7984  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 1.7974  Validation loss = 3.7980  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 1.7973  Validation loss = 3.7977  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 1.7971  Validation loss = 3.7970  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 1.7969  Validation loss = 3.7968  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 1.7968  Validation loss = 3.7962  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 1.7967  Validation loss = 3.7951  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 1.7965  Validation loss = 3.7944  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 1.7964  Validation loss = 3.7939  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 1.7964  Validation loss = 3.7936  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 1.7963  Validation loss = 3.7934  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 1.7962  Validation loss = 3.7931  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 1.7961  Validation loss = 3.7928  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 1.7960  Validation loss = 3.7926  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 1.7959  Validation loss = 3.7926  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 1.7957  Validation loss = 3.7916  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 1.7956  Validation loss = 3.7913  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 1.7955  Validation loss = 3.7905  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 1.7954  Validation loss = 3.7901  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 1.7952  Validation loss = 3.7893  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 1.7950  Validation loss = 3.7886  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 1.7948  Validation loss = 3.7868  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 1.7946  Validation loss = 3.7861  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 1.7944  Validation loss = 3.7856  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 1.7944  Validation loss = 3.7853  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 1.7943  Validation loss = 3.7852  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 1.7942  Validation loss = 3.7848  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 1.7941  Validation loss = 3.7838  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 1.7940  Validation loss = 3.7835  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 1.7938  Validation loss = 3.7828  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 1.7937  Validation loss = 3.7818  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 1.7935  Validation loss = 3.7810  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 1.7934  Validation loss = 3.7802  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 1.7931  Validation loss = 3.7793  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 1.7929  Validation loss = 3.7783  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 1.7928  Validation loss = 3.7777  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 1.7926  Validation loss = 3.7769  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 1.7926  Validation loss = 3.7766  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 1.7924  Validation loss = 3.7758  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 1.7922  Validation loss = 3.7748  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 1.7920  Validation loss = 3.7741  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 1.7920  Validation loss = 3.7736  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 1.7919  Validation loss = 3.7734  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 1.7918  Validation loss = 3.7731  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 1.7917  Validation loss = 3.7723  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 1.7915  Validation loss = 3.7711  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 1.7914  Validation loss = 3.7711  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 1.7912  Validation loss = 3.7702  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 1.7911  Validation loss = 3.7700  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 1.7910  Validation loss = 3.7694  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 1.7908  Validation loss = 3.7687  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 1.7907  Validation loss = 3.7685  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 1.7907  Validation loss = 3.7685  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 1.7905  Validation loss = 3.7674  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 1.7904  Validation loss = 3.7673  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 1.7902  Validation loss = 3.7662  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 1.7900  Validation loss = 3.7653  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 1.7899  Validation loss = 3.7643  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 1.7897  Validation loss = 3.7635  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 1.7897  Validation loss = 3.7634  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 1.7895  Validation loss = 3.7626  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 1.7894  Validation loss = 3.7630  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 1.7894  Validation loss = 3.7626  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 1.7893  Validation loss = 3.7626  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 1.7892  Validation loss = 3.7620  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 1.7891  Validation loss = 3.7612  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 1.7890  Validation loss = 3.7608  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 1.7888  Validation loss = 3.7598  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 1.7886  Validation loss = 3.7593  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 1.7885  Validation loss = 3.7586  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 1.7884  Validation loss = 3.7585  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 1.7883  Validation loss = 3.7582  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 1.7881  Validation loss = 3.7568  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 1.7880  Validation loss = 3.7564  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 1.7880  Validation loss = 3.7563  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 1.7878  Validation loss = 3.7556  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 1.7877  Validation loss = 3.7553  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 1.7876  Validation loss = 3.7545  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 1.7875  Validation loss = 3.7543  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 1.7874  Validation loss = 3.7536  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 1.7873  Validation loss = 3.7535  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 1.7871  Validation loss = 3.7528  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 1.7870  Validation loss = 3.7524  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 1.7868  Validation loss = 3.7514  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 1.7868  Validation loss = 3.7515  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 1.7866  Validation loss = 3.7507  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 1.7864  Validation loss = 3.7494  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 1.7863  Validation loss = 3.7492  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 1.7861  Validation loss = 3.7482  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 1.7860  Validation loss = 3.7473  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 1.7858  Validation loss = 3.7469  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 1.7856  Validation loss = 3.7456  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 1.7854  Validation loss = 3.7447  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 1.7853  Validation loss = 3.7443  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 1.7853  Validation loss = 3.7446  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 1.7852  Validation loss = 3.7439  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 1.7850  Validation loss = 3.7431  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 1.7849  Validation loss = 3.7427  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 1.7848  Validation loss = 3.7418  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 1.7847  Validation loss = 3.7413  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 1.7845  Validation loss = 3.7407  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 1.7844  Validation loss = 3.7405  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 1.7843  Validation loss = 3.7405  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 1.7842  Validation loss = 3.7398  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 1.7841  Validation loss = 3.7396  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 1.7840  Validation loss = 3.7385  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 1.7838  Validation loss = 3.7378  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 1.7838  Validation loss = 3.7380  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 1.7837  Validation loss = 3.7376  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 1.7836  Validation loss = 3.7378  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 1.7836  Validation loss = 3.7376  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 1.7835  Validation loss = 3.7374  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 1.7833  Validation loss = 3.7365  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 1.7831  Validation loss = 3.7356  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 1.7830  Validation loss = 3.7355  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 1.7829  Validation loss = 3.7355  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 1.7828  Validation loss = 3.7350  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 1.7828  Validation loss = 3.7350  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 1.7826  Validation loss = 3.7343  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 1.7826  Validation loss = 3.7343  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 1.7825  Validation loss = 3.7342  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 1.7824  Validation loss = 3.7338  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 1.7824  Validation loss = 3.7337  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 1.7822  Validation loss = 3.7331  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 1.7821  Validation loss = 3.7330  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 1.7820  Validation loss = 3.7325  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 1.7818  Validation loss = 3.7318  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 1.7818  Validation loss = 3.7315  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 1.7816  Validation loss = 3.7305  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 1.7814  Validation loss = 3.7293  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 1.7813  Validation loss = 3.7292  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 1.7812  Validation loss = 3.7290  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 1.7811  Validation loss = 3.7286  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 1.7809  Validation loss = 3.7273  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 1.7808  Validation loss = 3.7270  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 1.7808  Validation loss = 3.7272  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 1.7807  Validation loss = 3.7267  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 1.7806  Validation loss = 3.7264  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 1.7805  Validation loss = 3.7256  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 1.7804  Validation loss = 3.7256  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 1.7802  Validation loss = 3.7248  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 1.7801  Validation loss = 3.7245  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 1.7800  Validation loss = 3.7242  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 1.7799  Validation loss = 3.7234  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 1.7798  Validation loss = 3.7229  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 1.7797  Validation loss = 3.7222  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 1.7794  Validation loss = 3.7208  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 1.7793  Validation loss = 3.7199  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 1.7792  Validation loss = 3.7199  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 1.7791  Validation loss = 3.7202  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 1.7790  Validation loss = 3.7194  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 1.7789  Validation loss = 3.7186  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 1.7787  Validation loss = 3.7179  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 1.7786  Validation loss = 3.7176  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 1.7785  Validation loss = 3.7168  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 1.7783  Validation loss = 3.7163  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 1.7783  Validation loss = 3.7163  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 1.7782  Validation loss = 3.7159  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 1.7780  Validation loss = 3.7151  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 1.7779  Validation loss = 3.7147  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 1.7778  Validation loss = 3.7141  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 1.7778  Validation loss = 3.7146  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 1.7777  Validation loss = 3.7146  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 1.7776  Validation loss = 3.7147  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 1.7775  Validation loss = 3.7139  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 1.7774  Validation loss = 3.7129  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 1.7772  Validation loss = 3.7118  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 1.7770  Validation loss = 3.7111  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 1.7769  Validation loss = 3.7108  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 1.7769  Validation loss = 3.7107  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 1.7768  Validation loss = 3.7100  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 1.7767  Validation loss = 3.7096  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 1.7767  Validation loss = 3.7095  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 1.7767  Validation loss = 3.7091  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 1.7766  Validation loss = 3.7090  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 1.7765  Validation loss = 3.7085  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 1.7764  Validation loss = 3.7087  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 1.7763  Validation loss = 3.7085  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 1.7762  Validation loss = 3.7079  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 1.7761  Validation loss = 3.7072  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 1.7760  Validation loss = 3.7069  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 1.7758  Validation loss = 3.7059  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 1.7758  Validation loss = 3.7054  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 1.7757  Validation loss = 3.7051  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 1.7757  Validation loss = 3.7049  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 1.7756  Validation loss = 3.7046  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 1.7755  Validation loss = 3.7046  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 1.7754  Validation loss = 3.7045  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 1.7753  Validation loss = 3.7042  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 1.7752  Validation loss = 3.7039  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 1.7750  Validation loss = 3.7029  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 1.7750  Validation loss = 3.7029  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 1.7748  Validation loss = 3.7027  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 1.7748  Validation loss = 3.7024  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 1.7747  Validation loss = 3.7018  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 1.7745  Validation loss = 3.7011  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 1.7744  Validation loss = 3.7006  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 1.7742  Validation loss = 3.6995  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 1.7742  Validation loss = 3.6994  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 1.7740  Validation loss = 3.6980  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 1.7740  Validation loss = 3.6981  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 1.7739  Validation loss = 3.6975  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 1.7737  Validation loss = 3.6964  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 1.7737  Validation loss = 3.6964  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 1.7734  Validation loss = 3.6951  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 1.7733  Validation loss = 3.6942  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 1.7732  Validation loss = 3.6930  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 1.7731  Validation loss = 3.6929  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 1.7731  Validation loss = 3.6927  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 1.7729  Validation loss = 3.6921  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 1.7728  Validation loss = 3.6916  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 1.7726  Validation loss = 3.6901  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 1.7725  Validation loss = 3.6897  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 1.7724  Validation loss = 3.6887  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 1.7723  Validation loss = 3.6883  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 1.7722  Validation loss = 3.6878  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 1.7721  Validation loss = 3.6875  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 1.7720  Validation loss = 3.6870  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 1.7718  Validation loss = 3.6863  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 1.7717  Validation loss = 3.6856  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 1.7716  Validation loss = 3.6850  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 1.7716  Validation loss = 3.6862  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 1.7714  Validation loss = 3.6854  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 1.7714  Validation loss = 3.6851  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 1.7712  Validation loss = 3.6841  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 1.7711  Validation loss = 3.6842  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 1.7711  Validation loss = 3.6843  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 1.7710  Validation loss = 3.6846  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 1.7709  Validation loss = 3.6837  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 1.7708  Validation loss = 3.6831  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 1.7707  Validation loss = 3.6825  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 1.7706  Validation loss = 3.6824  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 1.7705  Validation loss = 3.6818  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 1.7704  Validation loss = 3.6814  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 1.7703  Validation loss = 3.6816  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 1.7702  Validation loss = 3.6809  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 1.7701  Validation loss = 3.6801  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 1.7700  Validation loss = 3.6799  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 1.7699  Validation loss = 3.6798  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 1.7698  Validation loss = 3.6790  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 1.7697  Validation loss = 3.6784  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 1.7696  Validation loss = 3.6782  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 1.7696  Validation loss = 3.6785  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 1.7696  Validation loss = 3.6786  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 1.7695  Validation loss = 3.6785  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 1.7693  Validation loss = 3.6777  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 1.7692  Validation loss = 3.6773  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 1.7691  Validation loss = 3.6766  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 1.7690  Validation loss = 3.6761  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 1.7689  Validation loss = 3.6757  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 1.7688  Validation loss = 3.6759  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 1.7688  Validation loss = 3.6757  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 1.7687  Validation loss = 3.6754  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 1.7686  Validation loss = 3.6755  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 1.7685  Validation loss = 3.6752  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 1.7684  Validation loss = 3.6746  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 1.7683  Validation loss = 3.6750  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 1.7682  Validation loss = 3.6743  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 1.7681  Validation loss = 3.6741  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 1.7680  Validation loss = 3.6738  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 1.7679  Validation loss = 3.6737  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 1.7679  Validation loss = 3.6734  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 1.7678  Validation loss = 3.6727  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 1.7677  Validation loss = 3.6716  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 1.7676  Validation loss = 3.6711  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 1.7675  Validation loss = 3.6701  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 1.7674  Validation loss = 3.6695  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 1.7673  Validation loss = 3.6691  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 1.7672  Validation loss = 3.6691  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 1.7671  Validation loss = 3.6689  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 1.7670  Validation loss = 3.6681  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 1.7669  Validation loss = 3.6674  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 1.7669  Validation loss = 3.6676  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 1.7668  Validation loss = 3.6672  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 1.7667  Validation loss = 3.6666  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 1.7665  Validation loss = 3.6658  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 1.7664  Validation loss = 3.6652  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 1.7663  Validation loss = 3.6654  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 1.7662  Validation loss = 3.6645  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 1.7660  Validation loss = 3.6635  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 1.7658  Validation loss = 3.6624  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 1.7657  Validation loss = 3.6614  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 1.7656  Validation loss = 3.6609  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 1.7655  Validation loss = 3.6604  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 1.7654  Validation loss = 3.6606  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 1.7653  Validation loss = 3.6606  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 1.7653  Validation loss = 3.6610  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 1.7652  Validation loss = 3.6608  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 1.7651  Validation loss = 3.6605  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 1.7650  Validation loss = 3.6597  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 1.7649  Validation loss = 3.6591  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 1.7649  Validation loss = 3.6592  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 1.7648  Validation loss = 3.6593  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 1.7648  Validation loss = 3.6593  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 1.7647  Validation loss = 3.6586  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 1.7647  Validation loss = 3.6593  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 1.7645  Validation loss = 3.6579  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 1.7645  Validation loss = 3.6579  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 1.7643  Validation loss = 3.6573  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 1.7642  Validation loss = 3.6564  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 1.7641  Validation loss = 3.6558  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 1.7640  Validation loss = 3.6551  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 1.7639  Validation loss = 3.6548  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 1.7638  Validation loss = 3.6544  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 1.7637  Validation loss = 3.6540  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 1.7637  Validation loss = 3.6532  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 1.7636  Validation loss = 3.6532  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 1.7635  Validation loss = 3.6532  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 1.7634  Validation loss = 3.6523  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 1.7634  Validation loss = 3.6524  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 1.7633  Validation loss = 3.6524  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 1.7632  Validation loss = 3.6518  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 1.7631  Validation loss = 3.6516  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 1.7631  Validation loss = 3.6523  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 1.7630  Validation loss = 3.6515  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 1.7629  Validation loss = 3.6513  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 1.7628  Validation loss = 3.6508  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 1.7628  Validation loss = 3.6504  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 1.7627  Validation loss = 3.6503  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 1.7626  Validation loss = 3.6499  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 1.7625  Validation loss = 3.6493  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 1.7623  Validation loss = 3.6485  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 1.7622  Validation loss = 3.6475  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 1.7621  Validation loss = 3.6473  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 1.7620  Validation loss = 3.6469  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 1.7620  Validation loss = 3.6469  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 1.7619  Validation loss = 3.6466  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 1.7618  Validation loss = 3.6459  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 1.7616  Validation loss = 3.6449  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 1.7616  Validation loss = 3.6447  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 1.7615  Validation loss = 3.6448  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 1.7615  Validation loss = 3.6447  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 1.7614  Validation loss = 3.6442  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 1.7613  Validation loss = 3.6437  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 1.7612  Validation loss = 3.6429  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 1.7611  Validation loss = 3.6425  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 1.7610  Validation loss = 3.6415  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 1.7608  Validation loss = 3.6407  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 1.7608  Validation loss = 3.6413  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 1.7608  Validation loss = 3.6409  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 1.7607  Validation loss = 3.6409  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 1.7607  Validation loss = 3.6401  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 1.7605  Validation loss = 3.6393  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 1.7605  Validation loss = 3.6387  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 1.7604  Validation loss = 3.6381  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 1.7602  Validation loss = 3.6377  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 1.7602  Validation loss = 3.6376  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 1.7601  Validation loss = 3.6370  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 1.7600  Validation loss = 3.6363  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 1.7599  Validation loss = 3.6358  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 1.7599  Validation loss = 3.6358  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 1.7598  Validation loss = 3.6356  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 1.7597  Validation loss = 3.6350  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 1.7596  Validation loss = 3.6349  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 1.7595  Validation loss = 3.6343  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 1.7595  Validation loss = 3.6339  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 1.7594  Validation loss = 3.6342  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 1.7594  Validation loss = 3.6343  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 1.7593  Validation loss = 3.6333  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 1.7591  Validation loss = 3.6327  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 1.7591  Validation loss = 3.6322  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 1.7590  Validation loss = 3.6326  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 1.7590  Validation loss = 3.6330  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 1.7589  Validation loss = 3.6326  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 1.7589  Validation loss = 3.6324  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 1.7588  Validation loss = 3.6319  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 1.7587  Validation loss = 3.6311  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 1.7586  Validation loss = 3.6308  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 1.7585  Validation loss = 3.6300  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 1.7584  Validation loss = 3.6293  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 1.7583  Validation loss = 3.6285  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 1.7583  Validation loss = 3.6283  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 1.7582  Validation loss = 3.6283  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 1.7580  Validation loss = 3.6273  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 1.7579  Validation loss = 3.6269  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 1.7578  Validation loss = 3.6260  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 1.7577  Validation loss = 3.6260  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 1.7576  Validation loss = 3.6257  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 1.7575  Validation loss = 3.6249  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 1.7574  Validation loss = 3.6237  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 1.7573  Validation loss = 3.6230  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 1.7572  Validation loss = 3.6227  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 1.7570  Validation loss = 3.6215  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 1.7569  Validation loss = 3.6212  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 1.7569  Validation loss = 3.6210  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 1.7568  Validation loss = 3.6203  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 1.7567  Validation loss = 3.6203  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 1.7566  Validation loss = 3.6196  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 1.7565  Validation loss = 3.6191  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 1.7564  Validation loss = 3.6193  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 1.7564  Validation loss = 3.6181  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 1.7563  Validation loss = 3.6183  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 1.7563  Validation loss = 3.6183  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 1.7563  Validation loss = 3.6188  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 1.7561  Validation loss = 3.6171  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 1.7560  Validation loss = 3.6167  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 1.7559  Validation loss = 3.6162  \n",
      "\n",
      "Fold: 5  Epoch: 501  Training loss = 1.7558  Validation loss = 3.6158  \n",
      "\n",
      "Fold: 5  Epoch: 502  Training loss = 1.7557  Validation loss = 3.6153  \n",
      "\n",
      "Fold: 5  Epoch: 503  Training loss = 1.7557  Validation loss = 3.6148  \n",
      "\n",
      "Fold: 5  Epoch: 504  Training loss = 1.7556  Validation loss = 3.6146  \n",
      "\n",
      "Fold: 5  Epoch: 505  Training loss = 1.7555  Validation loss = 3.6143  \n",
      "\n",
      "Fold: 5  Epoch: 506  Training loss = 1.7554  Validation loss = 3.6130  \n",
      "\n",
      "Fold: 5  Epoch: 507  Training loss = 1.7553  Validation loss = 3.6130  \n",
      "\n",
      "Fold: 5  Epoch: 508  Training loss = 1.7553  Validation loss = 3.6130  \n",
      "\n",
      "Fold: 5  Epoch: 509  Training loss = 1.7551  Validation loss = 3.6120  \n",
      "\n",
      "Fold: 5  Epoch: 510  Training loss = 1.7550  Validation loss = 3.6113  \n",
      "\n",
      "Fold: 5  Epoch: 511  Training loss = 1.7550  Validation loss = 3.6112  \n",
      "\n",
      "Fold: 5  Epoch: 512  Training loss = 1.7550  Validation loss = 3.6117  \n",
      "\n",
      "Fold: 5  Epoch: 513  Training loss = 1.7548  Validation loss = 3.6107  \n",
      "\n",
      "Fold: 5  Epoch: 514  Training loss = 1.7547  Validation loss = 3.6100  \n",
      "\n",
      "Fold: 5  Epoch: 515  Training loss = 1.7547  Validation loss = 3.6099  \n",
      "\n",
      "Fold: 5  Epoch: 516  Training loss = 1.7545  Validation loss = 3.6094  \n",
      "\n",
      "Fold: 5  Epoch: 517  Training loss = 1.7545  Validation loss = 3.6093  \n",
      "\n",
      "Fold: 5  Epoch: 518  Training loss = 1.7544  Validation loss = 3.6090  \n",
      "\n",
      "Fold: 5  Epoch: 519  Training loss = 1.7542  Validation loss = 3.6079  \n",
      "\n",
      "Fold: 5  Epoch: 520  Training loss = 1.7542  Validation loss = 3.6073  \n",
      "\n",
      "Fold: 5  Epoch: 521  Training loss = 1.7541  Validation loss = 3.6070  \n",
      "\n",
      "Fold: 5  Epoch: 522  Training loss = 1.7540  Validation loss = 3.6060  \n",
      "\n",
      "Fold: 5  Epoch: 523  Training loss = 1.7539  Validation loss = 3.6056  \n",
      "\n",
      "Fold: 5  Epoch: 524  Training loss = 1.7538  Validation loss = 3.6055  \n",
      "\n",
      "Fold: 5  Epoch: 525  Training loss = 1.7537  Validation loss = 3.6052  \n",
      "\n",
      "Fold: 5  Epoch: 526  Training loss = 1.7537  Validation loss = 3.6048  \n",
      "\n",
      "Fold: 5  Epoch: 527  Training loss = 1.7536  Validation loss = 3.6043  \n",
      "\n",
      "Fold: 5  Epoch: 528  Training loss = 1.7535  Validation loss = 3.6034  \n",
      "\n",
      "Fold: 5  Epoch: 529  Training loss = 1.7534  Validation loss = 3.6031  \n",
      "\n",
      "Fold: 5  Epoch: 530  Training loss = 1.7534  Validation loss = 3.6027  \n",
      "\n",
      "Fold: 5  Epoch: 531  Training loss = 1.7532  Validation loss = 3.6018  \n",
      "\n",
      "Fold: 5  Epoch: 532  Training loss = 1.7532  Validation loss = 3.6016  \n",
      "\n",
      "Fold: 5  Epoch: 533  Training loss = 1.7531  Validation loss = 3.6014  \n",
      "\n",
      "Fold: 5  Epoch: 534  Training loss = 1.7530  Validation loss = 3.6008  \n",
      "\n",
      "Fold: 5  Epoch: 535  Training loss = 1.7529  Validation loss = 3.6005  \n",
      "\n",
      "Fold: 5  Epoch: 536  Training loss = 1.7528  Validation loss = 3.5997  \n",
      "\n",
      "Fold: 5  Epoch: 537  Training loss = 1.7528  Validation loss = 3.6002  \n",
      "\n",
      "Fold: 5  Epoch: 538  Training loss = 1.7527  Validation loss = 3.5997  \n",
      "\n",
      "Fold: 5  Epoch: 539  Training loss = 1.7526  Validation loss = 3.5995  \n",
      "\n",
      "Fold: 5  Epoch: 540  Training loss = 1.7525  Validation loss = 3.5992  \n",
      "\n",
      "Fold: 5  Epoch: 541  Training loss = 1.7524  Validation loss = 3.5989  \n",
      "\n",
      "Fold: 5  Epoch: 542  Training loss = 1.7523  Validation loss = 3.5988  \n",
      "\n",
      "Fold: 5  Epoch: 543  Training loss = 1.7522  Validation loss = 3.5981  \n",
      "\n",
      "Fold: 5  Epoch: 544  Training loss = 1.7521  Validation loss = 3.5983  \n",
      "\n",
      "Fold: 5  Epoch: 545  Training loss = 1.7520  Validation loss = 3.5978  \n",
      "\n",
      "Fold: 5  Epoch: 546  Training loss = 1.7520  Validation loss = 3.5977  \n",
      "\n",
      "Fold: 5  Epoch: 547  Training loss = 1.7519  Validation loss = 3.5979  \n",
      "\n",
      "Fold: 5  Epoch: 548  Training loss = 1.7518  Validation loss = 3.5974  \n",
      "\n",
      "Fold: 5  Epoch: 549  Training loss = 1.7517  Validation loss = 3.5964  \n",
      "\n",
      "Fold: 5  Epoch: 550  Training loss = 1.7517  Validation loss = 3.5965  \n",
      "\n",
      "Fold: 5  Epoch: 551  Training loss = 1.7515  Validation loss = 3.5953  \n",
      "\n",
      "Fold: 5  Epoch: 552  Training loss = 1.7514  Validation loss = 3.5941  \n",
      "\n",
      "Fold: 5  Epoch: 553  Training loss = 1.7513  Validation loss = 3.5944  \n",
      "\n",
      "Fold: 5  Epoch: 554  Training loss = 1.7512  Validation loss = 3.5933  \n",
      "\n",
      "Fold: 5  Epoch: 555  Training loss = 1.7511  Validation loss = 3.5929  \n",
      "\n",
      "Fold: 5  Epoch: 556  Training loss = 1.7511  Validation loss = 3.5926  \n",
      "\n",
      "Fold: 5  Epoch: 557  Training loss = 1.7509  Validation loss = 3.5915  \n",
      "\n",
      "Fold: 5  Epoch: 558  Training loss = 1.7509  Validation loss = 3.5917  \n",
      "\n",
      "Fold: 5  Epoch: 559  Training loss = 1.7508  Validation loss = 3.5912  \n",
      "\n",
      "Fold: 5  Epoch: 560  Training loss = 1.7507  Validation loss = 3.5917  \n",
      "\n",
      "Fold: 5  Epoch: 561  Training loss = 1.7506  Validation loss = 3.5913  \n",
      "\n",
      "Fold: 5  Epoch: 562  Training loss = 1.7506  Validation loss = 3.5910  \n",
      "\n",
      "Fold: 5  Epoch: 563  Training loss = 1.7505  Validation loss = 3.5903  \n",
      "\n",
      "Fold: 5  Epoch: 564  Training loss = 1.7505  Validation loss = 3.5906  \n",
      "\n",
      "Fold: 5  Epoch: 565  Training loss = 1.7504  Validation loss = 3.5903  \n",
      "\n",
      "Fold: 5  Epoch: 566  Training loss = 1.7504  Validation loss = 3.5900  \n",
      "\n",
      "Fold: 5  Epoch: 567  Training loss = 1.7503  Validation loss = 3.5895  \n",
      "\n",
      "Fold: 5  Epoch: 568  Training loss = 1.7502  Validation loss = 3.5891  \n",
      "\n",
      "Fold: 5  Epoch: 569  Training loss = 1.7501  Validation loss = 3.5891  \n",
      "\n",
      "Fold: 5  Epoch: 570  Training loss = 1.7501  Validation loss = 3.5894  \n",
      "\n",
      "Fold: 5  Epoch: 571  Training loss = 1.7500  Validation loss = 3.5887  \n",
      "\n",
      "Fold: 5  Epoch: 572  Training loss = 1.7500  Validation loss = 3.5885  \n",
      "\n",
      "Fold: 5  Epoch: 573  Training loss = 1.7499  Validation loss = 3.5886  \n",
      "\n",
      "Fold: 5  Epoch: 574  Training loss = 1.7498  Validation loss = 3.5875  \n",
      "\n",
      "Fold: 5  Epoch: 575  Training loss = 1.7497  Validation loss = 3.5870  \n",
      "\n",
      "Fold: 5  Epoch: 576  Training loss = 1.7496  Validation loss = 3.5869  \n",
      "\n",
      "Fold: 5  Epoch: 577  Training loss = 1.7496  Validation loss = 3.5871  \n",
      "\n",
      "Fold: 5  Epoch: 578  Training loss = 1.7495  Validation loss = 3.5865  \n",
      "\n",
      "Fold: 5  Epoch: 579  Training loss = 1.7494  Validation loss = 3.5860  \n",
      "\n",
      "Fold: 5  Epoch: 580  Training loss = 1.7492  Validation loss = 3.5848  \n",
      "\n",
      "Fold: 5  Epoch: 581  Training loss = 1.7492  Validation loss = 3.5846  \n",
      "\n",
      "Fold: 5  Epoch: 582  Training loss = 1.7491  Validation loss = 3.5847  \n",
      "\n",
      "Fold: 5  Epoch: 583  Training loss = 1.7490  Validation loss = 3.5844  \n",
      "\n",
      "Fold: 5  Epoch: 584  Training loss = 1.7489  Validation loss = 3.5837  \n",
      "\n",
      "Fold: 5  Epoch: 585  Training loss = 1.7488  Validation loss = 3.5835  \n",
      "\n",
      "Fold: 5  Epoch: 586  Training loss = 1.7488  Validation loss = 3.5835  \n",
      "\n",
      "Fold: 5  Epoch: 587  Training loss = 1.7487  Validation loss = 3.5837  \n",
      "\n",
      "Fold: 5  Epoch: 588  Training loss = 1.7486  Validation loss = 3.5831  \n",
      "\n",
      "Fold: 5  Epoch: 589  Training loss = 1.7485  Validation loss = 3.5828  \n",
      "\n",
      "Fold: 5  Epoch: 590  Training loss = 1.7484  Validation loss = 3.5818  \n",
      "\n",
      "Fold: 5  Epoch: 591  Training loss = 1.7484  Validation loss = 3.5818  \n",
      "\n",
      "Fold: 5  Epoch: 592  Training loss = 1.7483  Validation loss = 3.5823  \n",
      "\n",
      "Fold: 5  Epoch: 593  Training loss = 1.7482  Validation loss = 3.5820  \n",
      "\n",
      "Fold: 5  Epoch: 594  Training loss = 1.7482  Validation loss = 3.5821  \n",
      "\n",
      "Fold: 5  Epoch: 595  Training loss = 1.7481  Validation loss = 3.5813  \n",
      "\n",
      "Fold: 5  Epoch: 596  Training loss = 1.7481  Validation loss = 3.5816  \n",
      "\n",
      "Fold: 5  Epoch: 597  Training loss = 1.7480  Validation loss = 3.5808  \n",
      "\n",
      "Fold: 5  Epoch: 598  Training loss = 1.7480  Validation loss = 3.5808  \n",
      "\n",
      "Fold: 5  Epoch: 599  Training loss = 1.7479  Validation loss = 3.5804  \n",
      "\n",
      "Fold: 5  Epoch: 600  Training loss = 1.7478  Validation loss = 3.5800  \n",
      "\n",
      "Fold: 5  Epoch: 601  Training loss = 1.7477  Validation loss = 3.5794  \n",
      "\n",
      "Fold: 5  Epoch: 602  Training loss = 1.7475  Validation loss = 3.5782  \n",
      "\n",
      "Fold: 5  Epoch: 603  Training loss = 1.7475  Validation loss = 3.5776  \n",
      "\n",
      "Fold: 5  Epoch: 604  Training loss = 1.7474  Validation loss = 3.5772  \n",
      "\n",
      "Fold: 5  Epoch: 605  Training loss = 1.7473  Validation loss = 3.5768  \n",
      "\n",
      "Fold: 5  Epoch: 606  Training loss = 1.7472  Validation loss = 3.5754  \n",
      "\n",
      "Fold: 5  Epoch: 607  Training loss = 1.7471  Validation loss = 3.5749  \n",
      "\n",
      "Fold: 5  Epoch: 608  Training loss = 1.7470  Validation loss = 3.5743  \n",
      "\n",
      "Fold: 5  Epoch: 609  Training loss = 1.7469  Validation loss = 3.5739  \n",
      "\n",
      "Fold: 5  Epoch: 610  Training loss = 1.7468  Validation loss = 3.5731  \n",
      "\n",
      "Fold: 5  Epoch: 611  Training loss = 1.7468  Validation loss = 3.5733  \n",
      "\n",
      "Fold: 5  Epoch: 612  Training loss = 1.7467  Validation loss = 3.5720  \n",
      "\n",
      "Fold: 5  Epoch: 613  Training loss = 1.7466  Validation loss = 3.5718  \n",
      "\n",
      "Fold: 5  Epoch: 614  Training loss = 1.7466  Validation loss = 3.5720  \n",
      "\n",
      "Fold: 5  Epoch: 615  Training loss = 1.7465  Validation loss = 3.5730  \n",
      "\n",
      "Fold: 5  Epoch: 616  Training loss = 1.7465  Validation loss = 3.5738  \n",
      "\n",
      "Fold: 5  Epoch: 617  Training loss = 1.7464  Validation loss = 3.5735  \n",
      "\n",
      "Fold: 5  Epoch: 618  Training loss = 1.7463  Validation loss = 3.5720  \n",
      "\n",
      "Fold: 5  Epoch: 619  Training loss = 1.7461  Validation loss = 3.5710  \n",
      "\n",
      "Fold: 5  Epoch: 620  Training loss = 1.7461  Validation loss = 3.5708  \n",
      "\n",
      "Fold: 5  Epoch: 621  Training loss = 1.7460  Validation loss = 3.5698  \n",
      "\n",
      "Fold: 5  Epoch: 622  Training loss = 1.7459  Validation loss = 3.5695  \n",
      "\n",
      "Fold: 5  Epoch: 623  Training loss = 1.7458  Validation loss = 3.5688  \n",
      "\n",
      "Fold: 5  Epoch: 624  Training loss = 1.7458  Validation loss = 3.5681  \n",
      "\n",
      "Fold: 5  Epoch: 625  Training loss = 1.7458  Validation loss = 3.5683  \n",
      "\n",
      "Fold: 5  Epoch: 626  Training loss = 1.7456  Validation loss = 3.5676  \n",
      "\n",
      "Fold: 5  Epoch: 627  Training loss = 1.7455  Validation loss = 3.5661  \n",
      "\n",
      "Fold: 5  Epoch: 628  Training loss = 1.7454  Validation loss = 3.5660  \n",
      "\n",
      "Fold: 5  Epoch: 629  Training loss = 1.7453  Validation loss = 3.5650  \n",
      "\n",
      "Fold: 5  Epoch: 630  Training loss = 1.7452  Validation loss = 3.5641  \n",
      "\n",
      "Fold: 5  Epoch: 631  Training loss = 1.7451  Validation loss = 3.5644  \n",
      "\n",
      "Fold: 5  Epoch: 632  Training loss = 1.7451  Validation loss = 3.5641  \n",
      "\n",
      "Fold: 5  Epoch: 633  Training loss = 1.7449  Validation loss = 3.5637  \n",
      "\n",
      "Fold: 5  Epoch: 634  Training loss = 1.7449  Validation loss = 3.5639  \n",
      "\n",
      "Fold: 5  Epoch: 635  Training loss = 1.7448  Validation loss = 3.5630  \n",
      "\n",
      "Fold: 5  Epoch: 636  Training loss = 1.7448  Validation loss = 3.5633  \n",
      "\n",
      "Fold: 5  Epoch: 637  Training loss = 1.7447  Validation loss = 3.5624  \n",
      "\n",
      "Fold: 5  Epoch: 638  Training loss = 1.7445  Validation loss = 3.5611  \n",
      "\n",
      "Fold: 5  Epoch: 639  Training loss = 1.7445  Validation loss = 3.5612  \n",
      "\n",
      "Fold: 5  Epoch: 640  Training loss = 1.7444  Validation loss = 3.5605  \n",
      "\n",
      "Fold: 5  Epoch: 641  Training loss = 1.7443  Validation loss = 3.5598  \n",
      "\n",
      "Fold: 5  Epoch: 642  Training loss = 1.7443  Validation loss = 3.5600  \n",
      "\n",
      "Fold: 5  Epoch: 643  Training loss = 1.7441  Validation loss = 3.5592  \n",
      "\n",
      "Fold: 5  Epoch: 644  Training loss = 1.7441  Validation loss = 3.5591  \n",
      "\n",
      "Fold: 5  Epoch: 645  Training loss = 1.7439  Validation loss = 3.5582  \n",
      "\n",
      "Fold: 5  Epoch: 646  Training loss = 1.7439  Validation loss = 3.5575  \n",
      "\n",
      "Fold: 5  Epoch: 647  Training loss = 1.7438  Validation loss = 3.5568  \n",
      "\n",
      "Fold: 5  Epoch: 648  Training loss = 1.7437  Validation loss = 3.5565  \n",
      "\n",
      "Fold: 5  Epoch: 649  Training loss = 1.7436  Validation loss = 3.5562  \n",
      "\n",
      "Fold: 5  Epoch: 650  Training loss = 1.7436  Validation loss = 3.5567  \n",
      "\n",
      "Fold: 5  Epoch: 651  Training loss = 1.7435  Validation loss = 3.5565  \n",
      "\n",
      "Fold: 5  Epoch: 652  Training loss = 1.7434  Validation loss = 3.5560  \n",
      "\n",
      "Fold: 5  Epoch: 653  Training loss = 1.7434  Validation loss = 3.5557  \n",
      "\n",
      "Fold: 5  Epoch: 654  Training loss = 1.7433  Validation loss = 3.5557  \n",
      "\n",
      "Fold: 5  Epoch: 655  Training loss = 1.7432  Validation loss = 3.5544  \n",
      "\n",
      "Fold: 5  Epoch: 656  Training loss = 1.7431  Validation loss = 3.5539  \n",
      "\n",
      "Fold: 5  Epoch: 657  Training loss = 1.7431  Validation loss = 3.5546  \n",
      "\n",
      "Fold: 5  Epoch: 658  Training loss = 1.7430  Validation loss = 3.5551  \n",
      "\n",
      "Fold: 5  Epoch: 659  Training loss = 1.7429  Validation loss = 3.5546  \n",
      "\n",
      "Fold: 5  Epoch: 660  Training loss = 1.7429  Validation loss = 3.5545  \n",
      "\n",
      "Fold: 5  Epoch: 661  Training loss = 1.7428  Validation loss = 3.5544  \n",
      "\n",
      "Fold: 5  Epoch: 662  Training loss = 1.7427  Validation loss = 3.5533  \n",
      "\n",
      "Fold: 5  Epoch: 663  Training loss = 1.7427  Validation loss = 3.5531  \n",
      "\n",
      "Fold: 5  Epoch: 664  Training loss = 1.7425  Validation loss = 3.5515  \n",
      "\n",
      "Fold: 5  Epoch: 665  Training loss = 1.7424  Validation loss = 3.5515  \n",
      "\n",
      "Fold: 5  Epoch: 666  Training loss = 1.7424  Validation loss = 3.5525  \n",
      "\n",
      "Fold: 5  Epoch: 667  Training loss = 1.7423  Validation loss = 3.5521  \n",
      "\n",
      "Fold: 5  Epoch: 668  Training loss = 1.7422  Validation loss = 3.5516  \n",
      "\n",
      "Fold: 5  Epoch: 669  Training loss = 1.7421  Validation loss = 3.5508  \n",
      "\n",
      "Fold: 5  Epoch: 670  Training loss = 1.7421  Validation loss = 3.5510  \n",
      "\n",
      "Fold: 5  Epoch: 671  Training loss = 1.7420  Validation loss = 3.5508  \n",
      "\n",
      "Fold: 5  Epoch: 672  Training loss = 1.7420  Validation loss = 3.5506  \n",
      "\n",
      "Fold: 5  Epoch: 673  Training loss = 1.7419  Validation loss = 3.5503  \n",
      "\n",
      "Fold: 5  Epoch: 674  Training loss = 1.7418  Validation loss = 3.5500  \n",
      "\n",
      "Fold: 5  Epoch: 675  Training loss = 1.7417  Validation loss = 3.5492  \n",
      "\n",
      "Fold: 5  Epoch: 676  Training loss = 1.7416  Validation loss = 3.5487  \n",
      "\n",
      "Fold: 5  Epoch: 677  Training loss = 1.7415  Validation loss = 3.5480  \n",
      "\n",
      "Fold: 5  Epoch: 678  Training loss = 1.7415  Validation loss = 3.5483  \n",
      "\n",
      "Fold: 5  Epoch: 679  Training loss = 1.7414  Validation loss = 3.5482  \n",
      "\n",
      "Fold: 5  Epoch: 680  Training loss = 1.7414  Validation loss = 3.5479  \n",
      "\n",
      "Fold: 5  Epoch: 681  Training loss = 1.7413  Validation loss = 3.5472  \n",
      "\n",
      "Fold: 5  Epoch: 682  Training loss = 1.7412  Validation loss = 3.5463  \n",
      "\n",
      "Fold: 5  Epoch: 683  Training loss = 1.7411  Validation loss = 3.5460  \n",
      "\n",
      "Fold: 5  Epoch: 684  Training loss = 1.7410  Validation loss = 3.5450  \n",
      "\n",
      "Fold: 5  Epoch: 685  Training loss = 1.7409  Validation loss = 3.5442  \n",
      "\n",
      "Fold: 5  Epoch: 686  Training loss = 1.7408  Validation loss = 3.5429  \n",
      "\n",
      "Fold: 5  Epoch: 687  Training loss = 1.7407  Validation loss = 3.5424  \n",
      "\n",
      "Fold: 5  Epoch: 688  Training loss = 1.7407  Validation loss = 3.5422  \n",
      "\n",
      "Fold: 5  Epoch: 689  Training loss = 1.7407  Validation loss = 3.5428  \n",
      "\n",
      "Fold: 5  Epoch: 690  Training loss = 1.7407  Validation loss = 3.5428  \n",
      "\n",
      "Fold: 5  Epoch: 691  Training loss = 1.7406  Validation loss = 3.5429  \n",
      "\n",
      "Fold: 5  Epoch: 692  Training loss = 1.7405  Validation loss = 3.5425  \n",
      "\n",
      "Fold: 5  Epoch: 693  Training loss = 1.7404  Validation loss = 3.5424  \n",
      "\n",
      "Fold: 5  Epoch: 694  Training loss = 1.7404  Validation loss = 3.5426  \n",
      "\n",
      "Fold: 5  Epoch: 695  Training loss = 1.7403  Validation loss = 3.5421  \n",
      "\n",
      "Fold: 5  Epoch: 696  Training loss = 1.7402  Validation loss = 3.5419  \n",
      "\n",
      "Fold: 5  Epoch: 697  Training loss = 1.7402  Validation loss = 3.5420  \n",
      "\n",
      "Fold: 5  Epoch: 698  Training loss = 1.7402  Validation loss = 3.5421  \n",
      "\n",
      "Fold: 5  Epoch: 699  Training loss = 1.7401  Validation loss = 3.5423  \n",
      "\n",
      "Fold: 5  Epoch: 700  Training loss = 1.7400  Validation loss = 3.5419  \n",
      "\n",
      "Fold: 5  Epoch: 701  Training loss = 1.7400  Validation loss = 3.5419  \n",
      "\n",
      "Fold: 5  Epoch: 702  Training loss = 1.7399  Validation loss = 3.5408  \n",
      "\n",
      "Fold: 5  Epoch: 703  Training loss = 1.7398  Validation loss = 3.5408  \n",
      "\n",
      "Fold: 5  Epoch: 704  Training loss = 1.7397  Validation loss = 3.5408  \n",
      "\n",
      "Fold: 5  Epoch: 705  Training loss = 1.7396  Validation loss = 3.5400  \n",
      "\n",
      "Fold: 5  Epoch: 706  Training loss = 1.7396  Validation loss = 3.5397  \n",
      "\n",
      "Fold: 5  Epoch: 707  Training loss = 1.7395  Validation loss = 3.5392  \n",
      "\n",
      "Fold: 5  Epoch: 708  Training loss = 1.7393  Validation loss = 3.5371  \n",
      "\n",
      "Fold: 5  Epoch: 709  Training loss = 1.7393  Validation loss = 3.5363  \n",
      "\n",
      "Fold: 5  Epoch: 710  Training loss = 1.7392  Validation loss = 3.5361  \n",
      "\n",
      "Fold: 5  Epoch: 711  Training loss = 1.7391  Validation loss = 3.5357  \n",
      "\n",
      "Fold: 5  Epoch: 712  Training loss = 1.7391  Validation loss = 3.5362  \n",
      "\n",
      "Fold: 5  Epoch: 713  Training loss = 1.7390  Validation loss = 3.5359  \n",
      "\n",
      "Fold: 5  Epoch: 714  Training loss = 1.7390  Validation loss = 3.5356  \n",
      "\n",
      "Fold: 5  Epoch: 715  Training loss = 1.7389  Validation loss = 3.5341  \n",
      "\n",
      "Fold: 5  Epoch: 716  Training loss = 1.7388  Validation loss = 3.5334  \n",
      "\n",
      "Fold: 5  Epoch: 717  Training loss = 1.7387  Validation loss = 3.5322  \n",
      "\n",
      "Fold: 5  Epoch: 718  Training loss = 1.7386  Validation loss = 3.5318  \n",
      "\n",
      "Fold: 5  Epoch: 719  Training loss = 1.7386  Validation loss = 3.5313  \n",
      "\n",
      "Fold: 5  Epoch: 720  Training loss = 1.7385  Validation loss = 3.5308  \n",
      "\n",
      "Fold: 5  Epoch: 721  Training loss = 1.7384  Validation loss = 3.5302  \n",
      "\n",
      "Fold: 5  Epoch: 722  Training loss = 1.7383  Validation loss = 3.5298  \n",
      "\n",
      "Fold: 5  Epoch: 723  Training loss = 1.7383  Validation loss = 3.5296  \n",
      "\n",
      "Fold: 5  Epoch: 724  Training loss = 1.7382  Validation loss = 3.5298  \n",
      "\n",
      "Fold: 5  Epoch: 725  Training loss = 1.7381  Validation loss = 3.5292  \n",
      "\n",
      "Fold: 5  Epoch: 726  Training loss = 1.7381  Validation loss = 3.5283  \n",
      "\n",
      "Fold: 5  Epoch: 727  Training loss = 1.7380  Validation loss = 3.5280  \n",
      "\n",
      "Fold: 5  Epoch: 728  Training loss = 1.7379  Validation loss = 3.5270  \n",
      "\n",
      "Fold: 5  Epoch: 729  Training loss = 1.7378  Validation loss = 3.5264  \n",
      "\n",
      "Fold: 5  Epoch: 730  Training loss = 1.7378  Validation loss = 3.5260  \n",
      "\n",
      "Fold: 5  Epoch: 731  Training loss = 1.7377  Validation loss = 3.5253  \n",
      "\n",
      "Fold: 5  Epoch: 732  Training loss = 1.7376  Validation loss = 3.5253  \n",
      "\n",
      "Fold: 5  Epoch: 733  Training loss = 1.7375  Validation loss = 3.5249  \n",
      "\n",
      "Fold: 5  Epoch: 734  Training loss = 1.7375  Validation loss = 3.5246  \n",
      "\n",
      "Fold: 5  Epoch: 735  Training loss = 1.7375  Validation loss = 3.5252  \n",
      "\n",
      "Fold: 5  Epoch: 736  Training loss = 1.7374  Validation loss = 3.5247  \n",
      "\n",
      "Fold: 5  Epoch: 737  Training loss = 1.7374  Validation loss = 3.5246  \n",
      "\n",
      "Fold: 5  Epoch: 738  Training loss = 1.7373  Validation loss = 3.5247  \n",
      "\n",
      "Fold: 5  Epoch: 739  Training loss = 1.7373  Validation loss = 3.5243  \n",
      "\n",
      "Fold: 5  Epoch: 740  Training loss = 1.7372  Validation loss = 3.5242  \n",
      "\n",
      "Fold: 5  Epoch: 741  Training loss = 1.7372  Validation loss = 3.5245  \n",
      "\n",
      "Fold: 5  Epoch: 742  Training loss = 1.7371  Validation loss = 3.5238  \n",
      "\n",
      "Fold: 5  Epoch: 743  Training loss = 1.7371  Validation loss = 3.5233  \n",
      "\n",
      "Fold: 5  Epoch: 744  Training loss = 1.7370  Validation loss = 3.5221  \n",
      "\n",
      "Fold: 5  Epoch: 745  Training loss = 1.7368  Validation loss = 3.5211  \n",
      "\n",
      "Fold: 5  Epoch: 746  Training loss = 1.7368  Validation loss = 3.5207  \n",
      "\n",
      "Fold: 5  Epoch: 747  Training loss = 1.7368  Validation loss = 3.5204  \n",
      "\n",
      "Fold: 5  Epoch: 748  Training loss = 1.7366  Validation loss = 3.5192  \n",
      "\n",
      "Fold: 5  Epoch: 749  Training loss = 1.7366  Validation loss = 3.5193  \n",
      "\n",
      "Fold: 5  Epoch: 750  Training loss = 1.7365  Validation loss = 3.5186  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 750  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.9157  Validation loss = 1.3987  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.9154  Validation loss = 1.3984  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.9151  Validation loss = 1.3982  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.9145  Validation loss = 1.3973  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.9142  Validation loss = 1.3966  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.9139  Validation loss = 1.3961  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.9136  Validation loss = 1.3954  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.9133  Validation loss = 1.3950  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.9130  Validation loss = 1.3947  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.9125  Validation loss = 1.3939  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.9121  Validation loss = 1.3931  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.9118  Validation loss = 1.3930  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.9113  Validation loss = 1.3920  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.9109  Validation loss = 1.3912  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 1.9105  Validation loss = 1.3903  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 1.9101  Validation loss = 1.3895  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 1.9098  Validation loss = 1.3886  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 1.9095  Validation loss = 1.3882  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 1.9090  Validation loss = 1.3877  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 1.9086  Validation loss = 1.3872  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 1.9082  Validation loss = 1.3863  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 1.9079  Validation loss = 1.3858  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 1.9077  Validation loss = 1.3857  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 1.9074  Validation loss = 1.3853  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 1.9072  Validation loss = 1.3849  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 1.9066  Validation loss = 1.3836  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 1.9063  Validation loss = 1.3829  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 1.9060  Validation loss = 1.3827  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 1.9057  Validation loss = 1.3824  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 1.9053  Validation loss = 1.3815  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 1.9050  Validation loss = 1.3812  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 1.9047  Validation loss = 1.3808  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 1.9046  Validation loss = 1.3807  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 1.9044  Validation loss = 1.3803  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 1.9041  Validation loss = 1.3798  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 1.9037  Validation loss = 1.3791  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 1.9035  Validation loss = 1.3787  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 1.9032  Validation loss = 1.3783  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 1.9030  Validation loss = 1.3780  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 1.9029  Validation loss = 1.3779  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 1.9026  Validation loss = 1.3774  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 1.9023  Validation loss = 1.3769  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 1.9021  Validation loss = 1.3767  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 1.9018  Validation loss = 1.3762  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 1.9015  Validation loss = 1.3756  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 1.9012  Validation loss = 1.3752  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 1.9010  Validation loss = 1.3749  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 1.9007  Validation loss = 1.3742  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 1.9003  Validation loss = 1.3734  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 1.9000  Validation loss = 1.3725  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 1.8997  Validation loss = 1.3717  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 1.8994  Validation loss = 1.3712  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 1.8990  Validation loss = 1.3703  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 1.8988  Validation loss = 1.3699  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 1.8986  Validation loss = 1.3695  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 1.8984  Validation loss = 1.3691  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 1.8981  Validation loss = 1.3686  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 1.8979  Validation loss = 1.3680  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 1.8975  Validation loss = 1.3672  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 1.8974  Validation loss = 1.3673  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 1.8971  Validation loss = 1.3667  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 1.8967  Validation loss = 1.3659  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 1.8966  Validation loss = 1.3660  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 1.8963  Validation loss = 1.3655  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 1.8960  Validation loss = 1.3648  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 1.8956  Validation loss = 1.3643  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 1.8953  Validation loss = 1.3637  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 1.8951  Validation loss = 1.3630  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 1.8947  Validation loss = 1.3621  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 1.8942  Validation loss = 1.3610  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 1.8939  Validation loss = 1.3605  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 1.8937  Validation loss = 1.3600  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 1.8933  Validation loss = 1.3592  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 1.8930  Validation loss = 1.3586  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 1.8928  Validation loss = 1.3581  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 1.8924  Validation loss = 1.3572  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 1.8921  Validation loss = 1.3567  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 1.8920  Validation loss = 1.3566  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 1.8917  Validation loss = 1.3560  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 1.8914  Validation loss = 1.3554  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 1.8912  Validation loss = 1.3551  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 1.8909  Validation loss = 1.3546  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 1.8906  Validation loss = 1.3541  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 1.8904  Validation loss = 1.3535  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 1.8901  Validation loss = 1.3530  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 1.8899  Validation loss = 1.3527  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 1.8897  Validation loss = 1.3523  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 1.8894  Validation loss = 1.3516  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 1.8892  Validation loss = 1.3512  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 1.8890  Validation loss = 1.3504  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 1.8887  Validation loss = 1.3497  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 1.8883  Validation loss = 1.3489  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 1.8881  Validation loss = 1.3485  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 1.8879  Validation loss = 1.3480  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 1.8877  Validation loss = 1.3478  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 1.8875  Validation loss = 1.3474  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 1.8872  Validation loss = 1.3466  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 1.8870  Validation loss = 1.3461  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 1.8866  Validation loss = 1.3452  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 1.8864  Validation loss = 1.3447  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 1.8861  Validation loss = 1.3440  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 1.8859  Validation loss = 1.3436  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 1.8857  Validation loss = 1.3431  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 1.8855  Validation loss = 1.3427  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 1.8853  Validation loss = 1.3426  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 1.8851  Validation loss = 1.3421  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 1.8849  Validation loss = 1.3415  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 1.8847  Validation loss = 1.3412  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 1.8844  Validation loss = 1.3404  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 1.8842  Validation loss = 1.3401  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 1.8839  Validation loss = 1.3396  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 1.8837  Validation loss = 1.3390  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 1.8833  Validation loss = 1.3382  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 1.8831  Validation loss = 1.3378  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 1.8829  Validation loss = 1.3374  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 1.8828  Validation loss = 1.3373  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 1.8824  Validation loss = 1.3364  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 1.8822  Validation loss = 1.3360  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 1.8821  Validation loss = 1.3357  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 1.8819  Validation loss = 1.3352  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 1.8815  Validation loss = 1.3344  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 1.8813  Validation loss = 1.3339  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 1.8811  Validation loss = 1.3335  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 1.8808  Validation loss = 1.3329  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 1.8806  Validation loss = 1.3325  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 1.8803  Validation loss = 1.3319  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 1.8801  Validation loss = 1.3313  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 1.8798  Validation loss = 1.3305  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 1.8796  Validation loss = 1.3302  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 1.8795  Validation loss = 1.3299  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 1.8791  Validation loss = 1.3290  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 1.8789  Validation loss = 1.3283  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 1.8787  Validation loss = 1.3277  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 1.8784  Validation loss = 1.3271  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 1.8782  Validation loss = 1.3266  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 1.8779  Validation loss = 1.3259  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 1.8777  Validation loss = 1.3257  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 1.8775  Validation loss = 1.3250  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 1.8772  Validation loss = 1.3242  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 1.8769  Validation loss = 1.3235  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 1.8768  Validation loss = 1.3233  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 1.8766  Validation loss = 1.3228  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 1.8763  Validation loss = 1.3222  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 1.8761  Validation loss = 1.3218  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 1.8758  Validation loss = 1.3211  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 1.8756  Validation loss = 1.3206  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 1.8754  Validation loss = 1.3202  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 1.8753  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 1.8751  Validation loss = 1.3193  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 1.8748  Validation loss = 1.3189  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 1.8745  Validation loss = 1.3177  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 1.8743  Validation loss = 1.3172  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 1.8740  Validation loss = 1.3167  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 1.8738  Validation loss = 1.3160  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 1.8736  Validation loss = 1.3157  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 1.8734  Validation loss = 1.3152  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 1.8731  Validation loss = 1.3143  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 1.8728  Validation loss = 1.3137  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 1.8726  Validation loss = 1.3131  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 1.8726  Validation loss = 1.3133  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 1.8725  Validation loss = 1.3134  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 1.8723  Validation loss = 1.3131  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 1.8721  Validation loss = 1.3126  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 1.8719  Validation loss = 1.3119  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 1.8717  Validation loss = 1.3115  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 1.8713  Validation loss = 1.3104  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 1.8711  Validation loss = 1.3097  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 1.8710  Validation loss = 1.3095  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 1.8708  Validation loss = 1.3089  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 1.8705  Validation loss = 1.3082  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 1.8703  Validation loss = 1.3076  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 1.8700  Validation loss = 1.3070  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 1.8698  Validation loss = 1.3063  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 1.8696  Validation loss = 1.3059  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 1.8693  Validation loss = 1.3055  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 1.8691  Validation loss = 1.3050  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 1.8689  Validation loss = 1.3043  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 1.8686  Validation loss = 1.3036  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 1.8685  Validation loss = 1.3033  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 1.8683  Validation loss = 1.3030  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 1.8681  Validation loss = 1.3026  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 1.8679  Validation loss = 1.3021  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 1.8678  Validation loss = 1.3019  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 1.8676  Validation loss = 1.3015  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 1.8674  Validation loss = 1.3010  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 1.8673  Validation loss = 1.3007  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 1.8671  Validation loss = 1.3002  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 1.8669  Validation loss = 1.2996  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 1.8667  Validation loss = 1.2992  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 1.8665  Validation loss = 1.2986  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 1.8663  Validation loss = 1.2984  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 1.8662  Validation loss = 1.2981  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 1.8660  Validation loss = 1.2976  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 1.8658  Validation loss = 1.2972  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 1.8657  Validation loss = 1.2969  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 1.8654  Validation loss = 1.2962  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 1.8652  Validation loss = 1.2956  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 1.8649  Validation loss = 1.2948  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 1.8647  Validation loss = 1.2942  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 1.8645  Validation loss = 1.2937  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 1.8643  Validation loss = 1.2933  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 1.8642  Validation loss = 1.2932  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 1.8639  Validation loss = 1.2927  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 1.8637  Validation loss = 1.2923  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 1.8636  Validation loss = 1.2920  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 1.8633  Validation loss = 1.2913  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 1.8631  Validation loss = 1.2908  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 1.8629  Validation loss = 1.2903  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 1.8627  Validation loss = 1.2899  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 1.8627  Validation loss = 1.2900  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 1.8624  Validation loss = 1.2894  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 1.8623  Validation loss = 1.2890  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 1.8621  Validation loss = 1.2885  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 1.8620  Validation loss = 1.2884  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 1.8618  Validation loss = 1.2880  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 1.8616  Validation loss = 1.2877  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 1.8615  Validation loss = 1.2873  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 1.8612  Validation loss = 1.2861  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 1.8611  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 1.8609  Validation loss = 1.2854  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 1.8607  Validation loss = 1.2848  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 1.8604  Validation loss = 1.2842  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 1.8603  Validation loss = 1.2840  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 1.8602  Validation loss = 1.2838  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 1.8600  Validation loss = 1.2835  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 1.8599  Validation loss = 1.2832  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 1.8597  Validation loss = 1.2830  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 1.8595  Validation loss = 1.2823  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 1.8593  Validation loss = 1.2817  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 1.8591  Validation loss = 1.2812  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 1.8589  Validation loss = 1.2806  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 1.8587  Validation loss = 1.2799  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 1.8585  Validation loss = 1.2793  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 1.8584  Validation loss = 1.2790  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 1.8582  Validation loss = 1.2788  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 1.8581  Validation loss = 1.2788  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 1.8579  Validation loss = 1.2784  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 1.8577  Validation loss = 1.2779  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 1.8576  Validation loss = 1.2776  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 1.8575  Validation loss = 1.2773  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 1.8572  Validation loss = 1.2764  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 1.8569  Validation loss = 1.2754  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 1.8567  Validation loss = 1.2748  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 1.8566  Validation loss = 1.2747  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 1.8564  Validation loss = 1.2742  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 1.8563  Validation loss = 1.2740  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 1.8562  Validation loss = 1.2740  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 1.8559  Validation loss = 1.2731  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 1.8558  Validation loss = 1.2729  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 1.8556  Validation loss = 1.2723  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 1.8555  Validation loss = 1.2721  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 1.8552  Validation loss = 1.2713  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 1.8549  Validation loss = 1.2705  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 1.8547  Validation loss = 1.2702  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 1.8544  Validation loss = 1.2694  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 1.8542  Validation loss = 1.2687  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 1.8540  Validation loss = 1.2680  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 1.8539  Validation loss = 1.2678  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 1.8536  Validation loss = 1.2672  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 1.8535  Validation loss = 1.2670  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 1.8534  Validation loss = 1.2668  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 1.8534  Validation loss = 1.2667  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 1.8532  Validation loss = 1.2664  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 1.8530  Validation loss = 1.2659  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 1.8528  Validation loss = 1.2655  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 1.8526  Validation loss = 1.2652  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 1.8525  Validation loss = 1.2648  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 1.8523  Validation loss = 1.2645  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 1.8522  Validation loss = 1.2643  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 1.8520  Validation loss = 1.2637  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 1.8518  Validation loss = 1.2632  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 1.8518  Validation loss = 1.2632  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 1.8515  Validation loss = 1.2626  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 1.8514  Validation loss = 1.2621  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 1.8511  Validation loss = 1.2615  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 1.8510  Validation loss = 1.2611  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 1.8508  Validation loss = 1.2606  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 1.8507  Validation loss = 1.2604  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 1.8505  Validation loss = 1.2601  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 1.8504  Validation loss = 1.2597  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 1.8502  Validation loss = 1.2592  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 1.8501  Validation loss = 1.2589  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 1.8498  Validation loss = 1.2582  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 1.8496  Validation loss = 1.2577  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 1.8494  Validation loss = 1.2573  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 1.8493  Validation loss = 1.2570  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 1.8491  Validation loss = 1.2563  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 1.8488  Validation loss = 1.2555  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 1.8487  Validation loss = 1.2552  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 1.8486  Validation loss = 1.2551  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 1.8484  Validation loss = 1.2547  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 1.8483  Validation loss = 1.2545  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 1.8482  Validation loss = 1.2544  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 1.8480  Validation loss = 1.2540  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 1.8479  Validation loss = 1.2536  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 1.8477  Validation loss = 1.2531  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 1.8474  Validation loss = 1.2525  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 1.8473  Validation loss = 1.2519  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 1.8471  Validation loss = 1.2517  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 1.8470  Validation loss = 1.2514  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 1.8469  Validation loss = 1.2513  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 1.8467  Validation loss = 1.2510  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 1.8466  Validation loss = 1.2507  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 1.8465  Validation loss = 1.2501  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 1.8463  Validation loss = 1.2496  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 1.8461  Validation loss = 1.2492  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 1.8458  Validation loss = 1.2484  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 1.8457  Validation loss = 1.2479  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 1.8455  Validation loss = 1.2476  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 1.8454  Validation loss = 1.2475  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 1.8453  Validation loss = 1.2472  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 1.8451  Validation loss = 1.2467  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 1.8449  Validation loss = 1.2461  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 1.8448  Validation loss = 1.2459  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 1.8446  Validation loss = 1.2457  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 1.8445  Validation loss = 1.2454  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 1.8444  Validation loss = 1.2451  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 1.8443  Validation loss = 1.2452  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 1.8442  Validation loss = 1.2453  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 1.8441  Validation loss = 1.2448  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 1.8439  Validation loss = 1.2444  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 1.8437  Validation loss = 1.2440  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 1.8435  Validation loss = 1.2434  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 1.8434  Validation loss = 1.2432  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 1.8432  Validation loss = 1.2429  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 1.8431  Validation loss = 1.2427  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 1.8430  Validation loss = 1.2423  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 1.8428  Validation loss = 1.2420  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 1.8427  Validation loss = 1.2415  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 1.8425  Validation loss = 1.2413  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 1.8423  Validation loss = 1.2406  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 1.8421  Validation loss = 1.2399  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 1.8419  Validation loss = 1.2394  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 1.8418  Validation loss = 1.2393  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 1.8417  Validation loss = 1.2388  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 1.8415  Validation loss = 1.2386  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 1.8414  Validation loss = 1.2382  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 1.8412  Validation loss = 1.2378  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 1.8411  Validation loss = 1.2378  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 1.8409  Validation loss = 1.2374  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 1.8408  Validation loss = 1.2372  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 1.8407  Validation loss = 1.2368  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 1.8405  Validation loss = 1.2362  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 1.8404  Validation loss = 1.2360  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 1.8403  Validation loss = 1.2357  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 1.8401  Validation loss = 1.2351  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 1.8400  Validation loss = 1.2350  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 1.8398  Validation loss = 1.2347  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 1.8397  Validation loss = 1.2345  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 1.8396  Validation loss = 1.2341  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 1.8395  Validation loss = 1.2343  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 1.8394  Validation loss = 1.2341  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 1.8393  Validation loss = 1.2339  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 1.8391  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 1.8391  Validation loss = 1.2339  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 1.8390  Validation loss = 1.2336  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 1.8388  Validation loss = 1.2333  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 1.8387  Validation loss = 1.2333  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 1.8386  Validation loss = 1.2328  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 1.8385  Validation loss = 1.2330  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 1.8384  Validation loss = 1.2326  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 1.8382  Validation loss = 1.2324  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 1.8380  Validation loss = 1.2318  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 1.8378  Validation loss = 1.2312  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 1.8378  Validation loss = 1.2312  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 1.8376  Validation loss = 1.2307  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 1.8374  Validation loss = 1.2300  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 1.8373  Validation loss = 1.2298  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 1.8372  Validation loss = 1.2294  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 1.8370  Validation loss = 1.2288  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 1.8369  Validation loss = 1.2286  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 1.8368  Validation loss = 1.2284  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 1.8367  Validation loss = 1.2283  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 1.8366  Validation loss = 1.2282  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 1.8364  Validation loss = 1.2278  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 1.8363  Validation loss = 1.2275  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 1.8361  Validation loss = 1.2271  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 1.8360  Validation loss = 1.2265  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 1.8358  Validation loss = 1.2261  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 1.8357  Validation loss = 1.2260  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 1.8355  Validation loss = 1.2256  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 1.8354  Validation loss = 1.2253  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 1.8352  Validation loss = 1.2251  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 1.8350  Validation loss = 1.2245  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 1.8349  Validation loss = 1.2240  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 1.8348  Validation loss = 1.2238  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 1.8345  Validation loss = 1.2229  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 1.8344  Validation loss = 1.2226  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 1.8343  Validation loss = 1.2225  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 1.8341  Validation loss = 1.2221  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 1.8340  Validation loss = 1.2217  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 1.8338  Validation loss = 1.2215  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 1.8337  Validation loss = 1.2210  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 1.8336  Validation loss = 1.2210  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 1.8335  Validation loss = 1.2210  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 1.8334  Validation loss = 1.2210  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 1.8333  Validation loss = 1.2207  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 1.8333  Validation loss = 1.2208  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 1.8331  Validation loss = 1.2205  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 1.8330  Validation loss = 1.2204  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 1.8329  Validation loss = 1.2201  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 1.8328  Validation loss = 1.2198  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 1.8326  Validation loss = 1.2194  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 1.8325  Validation loss = 1.2190  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 1.8323  Validation loss = 1.2186  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 1.8322  Validation loss = 1.2183  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 1.8320  Validation loss = 1.2177  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 1.8319  Validation loss = 1.2175  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 1.8317  Validation loss = 1.2169  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 1.8316  Validation loss = 1.2166  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 1.8315  Validation loss = 1.2164  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 1.8314  Validation loss = 1.2163  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 1.8312  Validation loss = 1.2157  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 1.8311  Validation loss = 1.2157  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 1.8309  Validation loss = 1.2149  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 1.8307  Validation loss = 1.2148  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 1.8306  Validation loss = 1.2146  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 1.8306  Validation loss = 1.2145  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 1.8304  Validation loss = 1.2141  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 1.8303  Validation loss = 1.2140  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 1.8302  Validation loss = 1.2135  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 1.8299  Validation loss = 1.2127  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 1.8299  Validation loss = 1.2127  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 1.8297  Validation loss = 1.2121  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 1.8296  Validation loss = 1.2120  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 1.8294  Validation loss = 1.2115  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 1.8293  Validation loss = 1.2113  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 1.8291  Validation loss = 1.2109  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 1.8290  Validation loss = 1.2106  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 1.8289  Validation loss = 1.2106  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 1.8288  Validation loss = 1.2101  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 1.8286  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 1.8284  Validation loss = 1.2090  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 1.8281  Validation loss = 1.2081  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 1.8280  Validation loss = 1.2077  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 1.8279  Validation loss = 1.2074  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 1.8277  Validation loss = 1.2069  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 1.8277  Validation loss = 1.2070  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 1.8275  Validation loss = 1.2065  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 1.8273  Validation loss = 1.2059  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 1.8272  Validation loss = 1.2056  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 1.8270  Validation loss = 1.2053  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 1.8269  Validation loss = 1.2050  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 1.8268  Validation loss = 1.2049  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 1.8267  Validation loss = 1.2050  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 1.8266  Validation loss = 1.2050  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 1.8265  Validation loss = 1.2046  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 1.8263  Validation loss = 1.2044  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 1.8262  Validation loss = 1.2040  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 1.8260  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 1.8258  Validation loss = 1.2029  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 1.8257  Validation loss = 1.2025  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 1.8255  Validation loss = 1.2022  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 1.8255  Validation loss = 1.2021  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 1.8254  Validation loss = 1.2021  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 1.8252  Validation loss = 1.2019  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 1.8251  Validation loss = 1.2014  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 1.8249  Validation loss = 1.2006  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 1.8246  Validation loss = 1.2001  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 1.8246  Validation loss = 1.2002  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 1.8244  Validation loss = 1.1997  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 1.8243  Validation loss = 1.1995  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 1.8241  Validation loss = 1.1989  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 1.8239  Validation loss = 1.1983  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 1.8237  Validation loss = 1.1979  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 1.8236  Validation loss = 1.1974  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 1.8235  Validation loss = 1.1974  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 1.8234  Validation loss = 1.1972  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 1.8232  Validation loss = 1.1966  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 1.8230  Validation loss = 1.1960  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 1.8229  Validation loss = 1.1954  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 1.8227  Validation loss = 1.1947  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 1.8226  Validation loss = 1.1944  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 1.8224  Validation loss = 1.1940  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 1.8223  Validation loss = 1.1937  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 1.8221  Validation loss = 1.1932  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 1.8220  Validation loss = 1.1932  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 1.8219  Validation loss = 1.1928  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 1.8217  Validation loss = 1.1925  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 1.8216  Validation loss = 1.1923  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 1.8215  Validation loss = 1.1920  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 1.8214  Validation loss = 1.1918  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 1.8212  Validation loss = 1.1915  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 1.8212  Validation loss = 1.1915  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 1.8211  Validation loss = 1.1914  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 1.8210  Validation loss = 1.1915  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 1.8209  Validation loss = 1.1912  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 1.8207  Validation loss = 1.1906  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 1.8205  Validation loss = 1.1901  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 1.8203  Validation loss = 1.1894  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 1.8201  Validation loss = 1.1891  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 1.8199  Validation loss = 1.1885  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 1.8198  Validation loss = 1.1879  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 1.8196  Validation loss = 1.1875  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 1.8194  Validation loss = 1.1873  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 1.8192  Validation loss = 1.1866  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 1.8191  Validation loss = 1.1863  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 1.8190  Validation loss = 1.1863  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 1.8189  Validation loss = 1.1862  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 1.8188  Validation loss = 1.1857  \n",
      "\n",
      "Fold: 6  Epoch: 501  Training loss = 1.8186  Validation loss = 1.1851  \n",
      "\n",
      "Fold: 6  Epoch: 502  Training loss = 1.8185  Validation loss = 1.1847  \n",
      "\n",
      "Fold: 6  Epoch: 503  Training loss = 1.8184  Validation loss = 1.1845  \n",
      "\n",
      "Fold: 6  Epoch: 504  Training loss = 1.8182  Validation loss = 1.1842  \n",
      "\n",
      "Fold: 6  Epoch: 505  Training loss = 1.8180  Validation loss = 1.1835  \n",
      "\n",
      "Fold: 6  Epoch: 506  Training loss = 1.8179  Validation loss = 1.1832  \n",
      "\n",
      "Fold: 6  Epoch: 507  Training loss = 1.8177  Validation loss = 1.1826  \n",
      "\n",
      "Fold: 6  Epoch: 508  Training loss = 1.8176  Validation loss = 1.1824  \n",
      "\n",
      "Fold: 6  Epoch: 509  Training loss = 1.8175  Validation loss = 1.1823  \n",
      "\n",
      "Fold: 6  Epoch: 510  Training loss = 1.8173  Validation loss = 1.1818  \n",
      "\n",
      "Fold: 6  Epoch: 511  Training loss = 1.8172  Validation loss = 1.1816  \n",
      "\n",
      "Fold: 6  Epoch: 512  Training loss = 1.8171  Validation loss = 1.1813  \n",
      "\n",
      "Fold: 6  Epoch: 513  Training loss = 1.8169  Validation loss = 1.1812  \n",
      "\n",
      "Fold: 6  Epoch: 514  Training loss = 1.8168  Validation loss = 1.1808  \n",
      "\n",
      "Fold: 6  Epoch: 515  Training loss = 1.8167  Validation loss = 1.1807  \n",
      "\n",
      "Fold: 6  Epoch: 516  Training loss = 1.8166  Validation loss = 1.1806  \n",
      "\n",
      "Fold: 6  Epoch: 517  Training loss = 1.8164  Validation loss = 1.1803  \n",
      "\n",
      "Fold: 6  Epoch: 518  Training loss = 1.8163  Validation loss = 1.1798  \n",
      "\n",
      "Fold: 6  Epoch: 519  Training loss = 1.8162  Validation loss = 1.1798  \n",
      "\n",
      "Fold: 6  Epoch: 520  Training loss = 1.8161  Validation loss = 1.1795  \n",
      "\n",
      "Fold: 6  Epoch: 521  Training loss = 1.8159  Validation loss = 1.1792  \n",
      "\n",
      "Fold: 6  Epoch: 522  Training loss = 1.8158  Validation loss = 1.1789  \n",
      "\n",
      "Fold: 6  Epoch: 523  Training loss = 1.8157  Validation loss = 1.1789  \n",
      "\n",
      "Fold: 6  Epoch: 524  Training loss = 1.8156  Validation loss = 1.1788  \n",
      "\n",
      "Fold: 6  Epoch: 525  Training loss = 1.8156  Validation loss = 1.1789  \n",
      "\n",
      "Fold: 6  Epoch: 526  Training loss = 1.8154  Validation loss = 1.1783  \n",
      "\n",
      "Fold: 6  Epoch: 527  Training loss = 1.8153  Validation loss = 1.1778  \n",
      "\n",
      "Fold: 6  Epoch: 528  Training loss = 1.8151  Validation loss = 1.1773  \n",
      "\n",
      "Fold: 6  Epoch: 529  Training loss = 1.8150  Validation loss = 1.1769  \n",
      "\n",
      "Fold: 6  Epoch: 530  Training loss = 1.8148  Validation loss = 1.1764  \n",
      "\n",
      "Fold: 6  Epoch: 531  Training loss = 1.8147  Validation loss = 1.1763  \n",
      "\n",
      "Fold: 6  Epoch: 532  Training loss = 1.8145  Validation loss = 1.1753  \n",
      "\n",
      "Fold: 6  Epoch: 533  Training loss = 1.8143  Validation loss = 1.1748  \n",
      "\n",
      "Fold: 6  Epoch: 534  Training loss = 1.8142  Validation loss = 1.1747  \n",
      "\n",
      "Fold: 6  Epoch: 535  Training loss = 1.8141  Validation loss = 1.1745  \n",
      "\n",
      "Fold: 6  Epoch: 536  Training loss = 1.8140  Validation loss = 1.1742  \n",
      "\n",
      "Fold: 6  Epoch: 537  Training loss = 1.8138  Validation loss = 1.1740  \n",
      "\n",
      "Fold: 6  Epoch: 538  Training loss = 1.8137  Validation loss = 1.1736  \n",
      "\n",
      "Fold: 6  Epoch: 539  Training loss = 1.8136  Validation loss = 1.1732  \n",
      "\n",
      "Fold: 6  Epoch: 540  Training loss = 1.8135  Validation loss = 1.1732  \n",
      "\n",
      "Fold: 6  Epoch: 541  Training loss = 1.8134  Validation loss = 1.1728  \n",
      "\n",
      "Fold: 6  Epoch: 542  Training loss = 1.8133  Validation loss = 1.1727  \n",
      "\n",
      "Fold: 6  Epoch: 543  Training loss = 1.8131  Validation loss = 1.1722  \n",
      "\n",
      "Fold: 6  Epoch: 544  Training loss = 1.8129  Validation loss = 1.1717  \n",
      "\n",
      "Fold: 6  Epoch: 545  Training loss = 1.8128  Validation loss = 1.1712  \n",
      "\n",
      "Fold: 6  Epoch: 546  Training loss = 1.8126  Validation loss = 1.1708  \n",
      "\n",
      "Fold: 6  Epoch: 547  Training loss = 1.8125  Validation loss = 1.1704  \n",
      "\n",
      "Fold: 6  Epoch: 548  Training loss = 1.8123  Validation loss = 1.1697  \n",
      "\n",
      "Fold: 6  Epoch: 549  Training loss = 1.8122  Validation loss = 1.1698  \n",
      "\n",
      "Fold: 6  Epoch: 550  Training loss = 1.8121  Validation loss = 1.1693  \n",
      "\n",
      "Fold: 6  Epoch: 551  Training loss = 1.8119  Validation loss = 1.1689  \n",
      "\n",
      "Fold: 6  Epoch: 552  Training loss = 1.8118  Validation loss = 1.1689  \n",
      "\n",
      "Fold: 6  Epoch: 553  Training loss = 1.8116  Validation loss = 1.1679  \n",
      "\n",
      "Fold: 6  Epoch: 554  Training loss = 1.8114  Validation loss = 1.1676  \n",
      "\n",
      "Fold: 6  Epoch: 555  Training loss = 1.8113  Validation loss = 1.1672  \n",
      "\n",
      "Fold: 6  Epoch: 556  Training loss = 1.8112  Validation loss = 1.1672  \n",
      "\n",
      "Fold: 6  Epoch: 557  Training loss = 1.8111  Validation loss = 1.1669  \n",
      "\n",
      "Fold: 6  Epoch: 558  Training loss = 1.8109  Validation loss = 1.1663  \n",
      "\n",
      "Fold: 6  Epoch: 559  Training loss = 1.8108  Validation loss = 1.1660  \n",
      "\n",
      "Fold: 6  Epoch: 560  Training loss = 1.8107  Validation loss = 1.1657  \n",
      "\n",
      "Fold: 6  Epoch: 561  Training loss = 1.8106  Validation loss = 1.1655  \n",
      "\n",
      "Fold: 6  Epoch: 562  Training loss = 1.8103  Validation loss = 1.1648  \n",
      "\n",
      "Fold: 6  Epoch: 563  Training loss = 1.8102  Validation loss = 1.1645  \n",
      "\n",
      "Fold: 6  Epoch: 564  Training loss = 1.8100  Validation loss = 1.1640  \n",
      "\n",
      "Fold: 6  Epoch: 565  Training loss = 1.8098  Validation loss = 1.1632  \n",
      "\n",
      "Fold: 6  Epoch: 566  Training loss = 1.8096  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 6  Epoch: 567  Training loss = 1.8096  Validation loss = 1.1630  \n",
      "\n",
      "Fold: 6  Epoch: 568  Training loss = 1.8094  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 6  Epoch: 569  Training loss = 1.8093  Validation loss = 1.1625  \n",
      "\n",
      "Fold: 6  Epoch: 570  Training loss = 1.8092  Validation loss = 1.1624  \n",
      "\n",
      "Fold: 6  Epoch: 571  Training loss = 1.8091  Validation loss = 1.1621  \n",
      "\n",
      "Fold: 6  Epoch: 572  Training loss = 1.8089  Validation loss = 1.1614  \n",
      "\n",
      "Fold: 6  Epoch: 573  Training loss = 1.8087  Validation loss = 1.1608  \n",
      "\n",
      "Fold: 6  Epoch: 574  Training loss = 1.8086  Validation loss = 1.1605  \n",
      "\n",
      "Fold: 6  Epoch: 575  Training loss = 1.8084  Validation loss = 1.1603  \n",
      "\n",
      "Fold: 6  Epoch: 576  Training loss = 1.8083  Validation loss = 1.1599  \n",
      "\n",
      "Fold: 6  Epoch: 577  Training loss = 1.8082  Validation loss = 1.1597  \n",
      "\n",
      "Fold: 6  Epoch: 578  Training loss = 1.8081  Validation loss = 1.1596  \n",
      "\n",
      "Fold: 6  Epoch: 579  Training loss = 1.8080  Validation loss = 1.1596  \n",
      "\n",
      "Fold: 6  Epoch: 580  Training loss = 1.8079  Validation loss = 1.1594  \n",
      "\n",
      "Fold: 6  Epoch: 581  Training loss = 1.8078  Validation loss = 1.1594  \n",
      "\n",
      "Fold: 6  Epoch: 582  Training loss = 1.8076  Validation loss = 1.1587  \n",
      "\n",
      "Fold: 6  Epoch: 583  Training loss = 1.8074  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 6  Epoch: 584  Training loss = 1.8073  Validation loss = 1.1583  \n",
      "\n",
      "Fold: 6  Epoch: 585  Training loss = 1.8071  Validation loss = 1.1580  \n",
      "\n",
      "Fold: 6  Epoch: 586  Training loss = 1.8070  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 6  Epoch: 587  Training loss = 1.8069  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 6  Epoch: 588  Training loss = 1.8067  Validation loss = 1.1572  \n",
      "\n",
      "Fold: 6  Epoch: 589  Training loss = 1.8067  Validation loss = 1.1571  \n",
      "\n",
      "Fold: 6  Epoch: 590  Training loss = 1.8064  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 6  Epoch: 591  Training loss = 1.8062  Validation loss = 1.1557  \n",
      "\n",
      "Fold: 6  Epoch: 592  Training loss = 1.8061  Validation loss = 1.1552  \n",
      "\n",
      "Fold: 6  Epoch: 593  Training loss = 1.8060  Validation loss = 1.1547  \n",
      "\n",
      "Fold: 6  Epoch: 594  Training loss = 1.8059  Validation loss = 1.1548  \n",
      "\n",
      "Fold: 6  Epoch: 595  Training loss = 1.8058  Validation loss = 1.1546  \n",
      "\n",
      "Fold: 6  Epoch: 596  Training loss = 1.8057  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 6  Epoch: 597  Training loss = 1.8055  Validation loss = 1.1537  \n",
      "\n",
      "Fold: 6  Epoch: 598  Training loss = 1.8054  Validation loss = 1.1536  \n",
      "\n",
      "Fold: 6  Epoch: 599  Training loss = 1.8052  Validation loss = 1.1527  \n",
      "\n",
      "Fold: 6  Epoch: 600  Training loss = 1.8051  Validation loss = 1.1525  \n",
      "\n",
      "Fold: 6  Epoch: 601  Training loss = 1.8049  Validation loss = 1.1521  \n",
      "\n",
      "Fold: 6  Epoch: 602  Training loss = 1.8048  Validation loss = 1.1519  \n",
      "\n",
      "Fold: 6  Epoch: 603  Training loss = 1.8046  Validation loss = 1.1514  \n",
      "\n",
      "Fold: 6  Epoch: 604  Training loss = 1.8045  Validation loss = 1.1513  \n",
      "\n",
      "Fold: 6  Epoch: 605  Training loss = 1.8044  Validation loss = 1.1512  \n",
      "\n",
      "Fold: 6  Epoch: 606  Training loss = 1.8042  Validation loss = 1.1509  \n",
      "\n",
      "Fold: 6  Epoch: 607  Training loss = 1.8041  Validation loss = 1.1503  \n",
      "\n",
      "Fold: 6  Epoch: 608  Training loss = 1.8039  Validation loss = 1.1499  \n",
      "\n",
      "Fold: 6  Epoch: 609  Training loss = 1.8037  Validation loss = 1.1495  \n",
      "\n",
      "Fold: 6  Epoch: 610  Training loss = 1.8037  Validation loss = 1.1496  \n",
      "\n",
      "Fold: 6  Epoch: 611  Training loss = 1.8036  Validation loss = 1.1496  \n",
      "\n",
      "Fold: 6  Epoch: 612  Training loss = 1.8034  Validation loss = 1.1490  \n",
      "\n",
      "Fold: 6  Epoch: 613  Training loss = 1.8032  Validation loss = 1.1482  \n",
      "\n",
      "Fold: 6  Epoch: 614  Training loss = 1.8031  Validation loss = 1.1481  \n",
      "\n",
      "Fold: 6  Epoch: 615  Training loss = 1.8030  Validation loss = 1.1480  \n",
      "\n",
      "Fold: 6  Epoch: 616  Training loss = 1.8029  Validation loss = 1.1477  \n",
      "\n",
      "Fold: 6  Epoch: 617  Training loss = 1.8028  Validation loss = 1.1475  \n",
      "\n",
      "Fold: 6  Epoch: 618  Training loss = 1.8026  Validation loss = 1.1468  \n",
      "\n",
      "Fold: 6  Epoch: 619  Training loss = 1.8024  Validation loss = 1.1461  \n",
      "\n",
      "Fold: 6  Epoch: 620  Training loss = 1.8023  Validation loss = 1.1460  \n",
      "\n",
      "Fold: 6  Epoch: 621  Training loss = 1.8021  Validation loss = 1.1457  \n",
      "\n",
      "Fold: 6  Epoch: 622  Training loss = 1.8020  Validation loss = 1.1452  \n",
      "\n",
      "Fold: 6  Epoch: 623  Training loss = 1.8018  Validation loss = 1.1449  \n",
      "\n",
      "Fold: 6  Epoch: 624  Training loss = 1.8018  Validation loss = 1.1451  \n",
      "\n",
      "Fold: 6  Epoch: 625  Training loss = 1.8017  Validation loss = 1.1448  \n",
      "\n",
      "Fold: 6  Epoch: 626  Training loss = 1.8015  Validation loss = 1.1440  \n",
      "\n",
      "Fold: 6  Epoch: 627  Training loss = 1.8013  Validation loss = 1.1433  \n",
      "\n",
      "Fold: 6  Epoch: 628  Training loss = 1.8012  Validation loss = 1.1438  \n",
      "\n",
      "Fold: 6  Epoch: 629  Training loss = 1.8011  Validation loss = 1.1434  \n",
      "\n",
      "Fold: 6  Epoch: 630  Training loss = 1.8009  Validation loss = 1.1430  \n",
      "\n",
      "Fold: 6  Epoch: 631  Training loss = 1.8007  Validation loss = 1.1425  \n",
      "\n",
      "Fold: 6  Epoch: 632  Training loss = 1.8006  Validation loss = 1.1418  \n",
      "\n",
      "Fold: 6  Epoch: 633  Training loss = 1.8003  Validation loss = 1.1411  \n",
      "\n",
      "Fold: 6  Epoch: 634  Training loss = 1.8003  Validation loss = 1.1412  \n",
      "\n",
      "Fold: 6  Epoch: 635  Training loss = 1.8002  Validation loss = 1.1412  \n",
      "\n",
      "Fold: 6  Epoch: 636  Training loss = 1.8001  Validation loss = 1.1409  \n",
      "\n",
      "Fold: 6  Epoch: 637  Training loss = 1.8000  Validation loss = 1.1407  \n",
      "\n",
      "Fold: 6  Epoch: 638  Training loss = 1.7999  Validation loss = 1.1408  \n",
      "\n",
      "Fold: 6  Epoch: 639  Training loss = 1.7998  Validation loss = 1.1406  \n",
      "\n",
      "Fold: 6  Epoch: 640  Training loss = 1.7996  Validation loss = 1.1403  \n",
      "\n",
      "Fold: 6  Epoch: 641  Training loss = 1.7995  Validation loss = 1.1400  \n",
      "\n",
      "Fold: 6  Epoch: 642  Training loss = 1.7994  Validation loss = 1.1399  \n",
      "\n",
      "Fold: 6  Epoch: 643  Training loss = 1.7993  Validation loss = 1.1397  \n",
      "\n",
      "Fold: 6  Epoch: 644  Training loss = 1.7992  Validation loss = 1.1395  \n",
      "\n",
      "Fold: 6  Epoch: 645  Training loss = 1.7991  Validation loss = 1.1392  \n",
      "\n",
      "Fold: 6  Epoch: 646  Training loss = 1.7990  Validation loss = 1.1392  \n",
      "\n",
      "Fold: 6  Epoch: 647  Training loss = 1.7988  Validation loss = 1.1389  \n",
      "\n",
      "Fold: 6  Epoch: 648  Training loss = 1.7987  Validation loss = 1.1383  \n",
      "\n",
      "Fold: 6  Epoch: 649  Training loss = 1.7985  Validation loss = 1.1382  \n",
      "\n",
      "Fold: 6  Epoch: 650  Training loss = 1.7984  Validation loss = 1.1379  \n",
      "\n",
      "Fold: 6  Epoch: 651  Training loss = 1.7983  Validation loss = 1.1375  \n",
      "\n",
      "Fold: 6  Epoch: 652  Training loss = 1.7981  Validation loss = 1.1369  \n",
      "\n",
      "Fold: 6  Epoch: 653  Training loss = 1.7979  Validation loss = 1.1364  \n",
      "\n",
      "Fold: 6  Epoch: 654  Training loss = 1.7978  Validation loss = 1.1363  \n",
      "\n",
      "Fold: 6  Epoch: 655  Training loss = 1.7976  Validation loss = 1.1356  \n",
      "\n",
      "Fold: 6  Epoch: 656  Training loss = 1.7974  Validation loss = 1.1353  \n",
      "\n",
      "Fold: 6  Epoch: 657  Training loss = 1.7973  Validation loss = 1.1353  \n",
      "\n",
      "Fold: 6  Epoch: 658  Training loss = 1.7972  Validation loss = 1.1350  \n",
      "\n",
      "Fold: 6  Epoch: 659  Training loss = 1.7971  Validation loss = 1.1349  \n",
      "\n",
      "Fold: 6  Epoch: 660  Training loss = 1.7970  Validation loss = 1.1346  \n",
      "\n",
      "Fold: 6  Epoch: 661  Training loss = 1.7968  Validation loss = 1.1340  \n",
      "\n",
      "Fold: 6  Epoch: 662  Training loss = 1.7967  Validation loss = 1.1338  \n",
      "\n",
      "Fold: 6  Epoch: 663  Training loss = 1.7965  Validation loss = 1.1335  \n",
      "\n",
      "Fold: 6  Epoch: 664  Training loss = 1.7964  Validation loss = 1.1331  \n",
      "\n",
      "Fold: 6  Epoch: 665  Training loss = 1.7962  Validation loss = 1.1327  \n",
      "\n",
      "Fold: 6  Epoch: 666  Training loss = 1.7961  Validation loss = 1.1323  \n",
      "\n",
      "Fold: 6  Epoch: 667  Training loss = 1.7960  Validation loss = 1.1326  \n",
      "\n",
      "Fold: 6  Epoch: 668  Training loss = 1.7959  Validation loss = 1.1325  \n",
      "\n",
      "Fold: 6  Epoch: 669  Training loss = 1.7958  Validation loss = 1.1320  \n",
      "\n",
      "Fold: 6  Epoch: 670  Training loss = 1.7957  Validation loss = 1.1318  \n",
      "\n",
      "Fold: 6  Epoch: 671  Training loss = 1.7955  Validation loss = 1.1313  \n",
      "\n",
      "Fold: 6  Epoch: 672  Training loss = 1.7954  Validation loss = 1.1311  \n",
      "\n",
      "Fold: 6  Epoch: 673  Training loss = 1.7953  Validation loss = 1.1307  \n",
      "\n",
      "Fold: 6  Epoch: 674  Training loss = 1.7951  Validation loss = 1.1303  \n",
      "\n",
      "Fold: 6  Epoch: 675  Training loss = 1.7951  Validation loss = 1.1305  \n",
      "\n",
      "Fold: 6  Epoch: 676  Training loss = 1.7949  Validation loss = 1.1299  \n",
      "\n",
      "Fold: 6  Epoch: 677  Training loss = 1.7948  Validation loss = 1.1296  \n",
      "\n",
      "Fold: 6  Epoch: 678  Training loss = 1.7947  Validation loss = 1.1293  \n",
      "\n",
      "Fold: 6  Epoch: 679  Training loss = 1.7947  Validation loss = 1.1298  \n",
      "\n",
      "Fold: 6  Epoch: 680  Training loss = 1.7945  Validation loss = 1.1295  \n",
      "\n",
      "Fold: 6  Epoch: 681  Training loss = 1.7945  Validation loss = 1.1296  \n",
      "\n",
      "Fold: 6  Epoch: 682  Training loss = 1.7944  Validation loss = 1.1296  \n",
      "\n",
      "Fold: 6  Epoch: 683  Training loss = 1.7942  Validation loss = 1.1292  \n",
      "\n",
      "Fold: 6  Epoch: 684  Training loss = 1.7941  Validation loss = 1.1288  \n",
      "\n",
      "Fold: 6  Epoch: 685  Training loss = 1.7940  Validation loss = 1.1285  \n",
      "\n",
      "Fold: 6  Epoch: 686  Training loss = 1.7937  Validation loss = 1.1278  \n",
      "\n",
      "Fold: 6  Epoch: 687  Training loss = 1.7936  Validation loss = 1.1275  \n",
      "\n",
      "Fold: 6  Epoch: 688  Training loss = 1.7934  Validation loss = 1.1268  \n",
      "\n",
      "Fold: 6  Epoch: 689  Training loss = 1.7933  Validation loss = 1.1267  \n",
      "\n",
      "Fold: 6  Epoch: 690  Training loss = 1.7932  Validation loss = 1.1263  \n",
      "\n",
      "Fold: 6  Epoch: 691  Training loss = 1.7930  Validation loss = 1.1260  \n",
      "\n",
      "Fold: 6  Epoch: 692  Training loss = 1.7930  Validation loss = 1.1260  \n",
      "\n",
      "Fold: 6  Epoch: 693  Training loss = 1.7928  Validation loss = 1.1254  \n",
      "\n",
      "Fold: 6  Epoch: 694  Training loss = 1.7926  Validation loss = 1.1252  \n",
      "\n",
      "Fold: 6  Epoch: 695  Training loss = 1.7925  Validation loss = 1.1246  \n",
      "\n",
      "Fold: 6  Epoch: 696  Training loss = 1.7924  Validation loss = 1.1245  \n",
      "\n",
      "Fold: 6  Epoch: 697  Training loss = 1.7922  Validation loss = 1.1240  \n",
      "\n",
      "Fold: 6  Epoch: 698  Training loss = 1.7921  Validation loss = 1.1237  \n",
      "\n",
      "Fold: 6  Epoch: 699  Training loss = 1.7919  Validation loss = 1.1231  \n",
      "\n",
      "Fold: 6  Epoch: 700  Training loss = 1.7917  Validation loss = 1.1227  \n",
      "\n",
      "Fold: 6  Epoch: 701  Training loss = 1.7916  Validation loss = 1.1220  \n",
      "\n",
      "Fold: 6  Epoch: 702  Training loss = 1.7915  Validation loss = 1.1221  \n",
      "\n",
      "Fold: 6  Epoch: 703  Training loss = 1.7914  Validation loss = 1.1219  \n",
      "\n",
      "Fold: 6  Epoch: 704  Training loss = 1.7913  Validation loss = 1.1217  \n",
      "\n",
      "Fold: 6  Epoch: 705  Training loss = 1.7911  Validation loss = 1.1212  \n",
      "\n",
      "Fold: 6  Epoch: 706  Training loss = 1.7911  Validation loss = 1.1213  \n",
      "\n",
      "Fold: 6  Epoch: 707  Training loss = 1.7909  Validation loss = 1.1207  \n",
      "\n",
      "Fold: 6  Epoch: 708  Training loss = 1.7908  Validation loss = 1.1205  \n",
      "\n",
      "Fold: 6  Epoch: 709  Training loss = 1.7907  Validation loss = 1.1203  \n",
      "\n",
      "Fold: 6  Epoch: 710  Training loss = 1.7905  Validation loss = 1.1195  \n",
      "\n",
      "Fold: 6  Epoch: 711  Training loss = 1.7903  Validation loss = 1.1190  \n",
      "\n",
      "Fold: 6  Epoch: 712  Training loss = 1.7902  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 6  Epoch: 713  Training loss = 1.7901  Validation loss = 1.1181  \n",
      "\n",
      "Fold: 6  Epoch: 714  Training loss = 1.7900  Validation loss = 1.1180  \n",
      "\n",
      "Fold: 6  Epoch: 715  Training loss = 1.7898  Validation loss = 1.1175  \n",
      "\n",
      "Fold: 6  Epoch: 716  Training loss = 1.7896  Validation loss = 1.1172  \n",
      "\n",
      "Fold: 6  Epoch: 717  Training loss = 1.7895  Validation loss = 1.1168  \n",
      "\n",
      "Fold: 6  Epoch: 718  Training loss = 1.7894  Validation loss = 1.1172  \n",
      "\n",
      "Fold: 6  Epoch: 719  Training loss = 1.7893  Validation loss = 1.1171  \n",
      "\n",
      "Fold: 6  Epoch: 720  Training loss = 1.7892  Validation loss = 1.1166  \n",
      "\n",
      "Fold: 6  Epoch: 721  Training loss = 1.7890  Validation loss = 1.1160  \n",
      "\n",
      "Fold: 6  Epoch: 722  Training loss = 1.7889  Validation loss = 1.1155  \n",
      "\n",
      "Fold: 6  Epoch: 723  Training loss = 1.7888  Validation loss = 1.1159  \n",
      "\n",
      "Fold: 6  Epoch: 724  Training loss = 1.7887  Validation loss = 1.1158  \n",
      "\n",
      "Fold: 6  Epoch: 725  Training loss = 1.7885  Validation loss = 1.1153  \n",
      "\n",
      "Fold: 6  Epoch: 726  Training loss = 1.7884  Validation loss = 1.1153  \n",
      "\n",
      "Fold: 6  Epoch: 727  Training loss = 1.7883  Validation loss = 1.1150  \n",
      "\n",
      "Fold: 6  Epoch: 728  Training loss = 1.7882  Validation loss = 1.1148  \n",
      "\n",
      "Fold: 6  Epoch: 729  Training loss = 1.7881  Validation loss = 1.1148  \n",
      "\n",
      "Fold: 6  Epoch: 730  Training loss = 1.7880  Validation loss = 1.1147  \n",
      "\n",
      "Fold: 6  Epoch: 731  Training loss = 1.7879  Validation loss = 1.1144  \n",
      "\n",
      "Fold: 6  Epoch: 732  Training loss = 1.7877  Validation loss = 1.1139  \n",
      "\n",
      "Fold: 6  Epoch: 733  Training loss = 1.7876  Validation loss = 1.1138  \n",
      "\n",
      "Fold: 6  Epoch: 734  Training loss = 1.7875  Validation loss = 1.1136  \n",
      "\n",
      "Fold: 6  Epoch: 735  Training loss = 1.7873  Validation loss = 1.1130  \n",
      "\n",
      "Fold: 6  Epoch: 736  Training loss = 1.7871  Validation loss = 1.1127  \n",
      "\n",
      "Fold: 6  Epoch: 737  Training loss = 1.7870  Validation loss = 1.1124  \n",
      "\n",
      "Fold: 6  Epoch: 738  Training loss = 1.7868  Validation loss = 1.1116  \n",
      "\n",
      "Fold: 6  Epoch: 739  Training loss = 1.7867  Validation loss = 1.1116  \n",
      "\n",
      "Fold: 6  Epoch: 740  Training loss = 1.7866  Validation loss = 1.1114  \n",
      "\n",
      "Fold: 6  Epoch: 741  Training loss = 1.7864  Validation loss = 1.1113  \n",
      "\n",
      "Fold: 6  Epoch: 742  Training loss = 1.7864  Validation loss = 1.1114  \n",
      "\n",
      "Fold: 6  Epoch: 743  Training loss = 1.7862  Validation loss = 1.1112  \n",
      "\n",
      "Fold: 6  Epoch: 744  Training loss = 1.7862  Validation loss = 1.1112  \n",
      "\n",
      "Fold: 6  Epoch: 745  Training loss = 1.7860  Validation loss = 1.1105  \n",
      "\n",
      "Fold: 6  Epoch: 746  Training loss = 1.7858  Validation loss = 1.1105  \n",
      "\n",
      "Fold: 6  Epoch: 747  Training loss = 1.7857  Validation loss = 1.1100  \n",
      "\n",
      "Fold: 6  Epoch: 748  Training loss = 1.7856  Validation loss = 1.1096  \n",
      "\n",
      "Fold: 6  Epoch: 749  Training loss = 1.7854  Validation loss = 1.1092  \n",
      "\n",
      "Fold: 6  Epoch: 750  Training loss = 1.7853  Validation loss = 1.1089  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 750  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.7122  Validation loss = 1.0156  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.7121  Validation loss = 1.0153  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.7120  Validation loss = 1.0153  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.7118  Validation loss = 1.0147  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.7116  Validation loss = 1.0144  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.7114  Validation loss = 1.0140  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.7112  Validation loss = 1.0135  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.7109  Validation loss = 1.0128  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.7107  Validation loss = 1.0124  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.7104  Validation loss = 1.0117  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.7102  Validation loss = 1.0116  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.7100  Validation loss = 1.0109  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.7099  Validation loss = 1.0109  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.7098  Validation loss = 1.0108  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.7096  Validation loss = 1.0106  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.7095  Validation loss = 1.0104  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.7094  Validation loss = 1.0102  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.7092  Validation loss = 1.0098  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.7089  Validation loss = 1.0092  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.7088  Validation loss = 1.0089  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.7086  Validation loss = 1.0085  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.7084  Validation loss = 1.0083  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 1.7082  Validation loss = 1.0079  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 1.7081  Validation loss = 1.0078  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 1.7079  Validation loss = 1.0074  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 1.7077  Validation loss = 1.0069  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 1.7074  Validation loss = 1.0063  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 1.7073  Validation loss = 1.0062  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 1.7071  Validation loss = 1.0056  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 1.7070  Validation loss = 1.0056  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 1.7068  Validation loss = 1.0051  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 1.7065  Validation loss = 1.0045  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 1.7063  Validation loss = 1.0042  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 1.7062  Validation loss = 1.0039  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 1.7060  Validation loss = 1.0035  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 1.7057  Validation loss = 1.0026  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 1.7055  Validation loss = 1.0022  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 1.7053  Validation loss = 1.0015  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 1.7050  Validation loss = 1.0010  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 1.7049  Validation loss = 1.0007  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 1.7047  Validation loss = 1.0003  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 1.7046  Validation loss = 1.0003  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 1.7043  Validation loss = 0.9996  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 1.7041  Validation loss = 0.9992  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 1.7038  Validation loss = 0.9984  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 1.7037  Validation loss = 0.9981  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 1.7034  Validation loss = 0.9976  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 1.7032  Validation loss = 0.9969  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 1.7031  Validation loss = 0.9969  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 1.7030  Validation loss = 0.9969  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 1.7029  Validation loss = 0.9968  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 1.7027  Validation loss = 0.9962  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 1.7025  Validation loss = 0.9958  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 1.7023  Validation loss = 0.9956  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 1.7021  Validation loss = 0.9952  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 1.7020  Validation loss = 0.9951  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 1.7019  Validation loss = 0.9951  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 1.7017  Validation loss = 0.9946  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 1.7015  Validation loss = 0.9942  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 1.7015  Validation loss = 0.9943  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 1.7013  Validation loss = 0.9940  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 1.7012  Validation loss = 0.9940  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 1.7011  Validation loss = 0.9935  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 1.7009  Validation loss = 0.9932  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 1.7007  Validation loss = 0.9930  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 1.7005  Validation loss = 0.9921  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 1.7003  Validation loss = 0.9917  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 1.7001  Validation loss = 0.9914  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 1.6999  Validation loss = 0.9909  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 1.6997  Validation loss = 0.9902  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 1.6994  Validation loss = 0.9896  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 1.6993  Validation loss = 0.9893  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 1.6992  Validation loss = 0.9891  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 1.6989  Validation loss = 0.9884  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 1.6986  Validation loss = 0.9878  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 1.6984  Validation loss = 0.9873  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 1.6983  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 1.6981  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 1.6979  Validation loss = 0.9863  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 1.6978  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 1.6975  Validation loss = 0.9855  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 1.6974  Validation loss = 0.9854  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 1.6971  Validation loss = 0.9849  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 1.6970  Validation loss = 0.9847  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 1.6970  Validation loss = 0.9848  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 1.6967  Validation loss = 0.9840  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 1.6966  Validation loss = 0.9841  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 1.6965  Validation loss = 0.9839  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 1.6963  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 1.6962  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 1.6959  Validation loss = 0.9826  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 1.6958  Validation loss = 0.9823  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 1.6956  Validation loss = 0.9822  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 1.6954  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 1.6951  Validation loss = 0.9810  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 1.6949  Validation loss = 0.9807  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 1.6947  Validation loss = 0.9803  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 1.6946  Validation loss = 0.9803  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 1.6945  Validation loss = 0.9803  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 1.6944  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 1.6943  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 1.6942  Validation loss = 0.9798  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 1.6941  Validation loss = 0.9800  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 1.6940  Validation loss = 0.9796  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 1.6938  Validation loss = 0.9794  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 1.6936  Validation loss = 0.9790  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 1.6935  Validation loss = 0.9789  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 1.6934  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 1.6930  Validation loss = 0.9777  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 1.6929  Validation loss = 0.9773  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 1.6927  Validation loss = 0.9768  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 1.6925  Validation loss = 0.9763  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 1.6922  Validation loss = 0.9756  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 1.6921  Validation loss = 0.9752  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 1.6918  Validation loss = 0.9746  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 1.6917  Validation loss = 0.9744  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 1.6914  Validation loss = 0.9738  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 1.6913  Validation loss = 0.9736  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 1.6911  Validation loss = 0.9732  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 1.6909  Validation loss = 0.9727  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 1.6907  Validation loss = 0.9723  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 1.6905  Validation loss = 0.9715  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 1.6903  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 1.6902  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 1.6900  Validation loss = 0.9707  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 1.6897  Validation loss = 0.9701  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 1.6895  Validation loss = 0.9695  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 1.6893  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 1.6891  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 1.6889  Validation loss = 0.9680  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 1.6887  Validation loss = 0.9676  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 1.6885  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 1.6883  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 1.6880  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 1.6878  Validation loss = 0.9660  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 1.6877  Validation loss = 0.9660  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 1.6875  Validation loss = 0.9653  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 1.6874  Validation loss = 0.9652  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 1.6872  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 1.6870  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 1.6868  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 1.6866  Validation loss = 0.9637  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 1.6864  Validation loss = 0.9634  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 1.6863  Validation loss = 0.9631  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 1.6862  Validation loss = 0.9631  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 1.6860  Validation loss = 0.9628  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 1.6859  Validation loss = 0.9628  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 1.6857  Validation loss = 0.9625  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 1.6855  Validation loss = 0.9619  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 1.6853  Validation loss = 0.9616  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 1.6851  Validation loss = 0.9611  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 1.6849  Validation loss = 0.9606  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 1.6848  Validation loss = 0.9605  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 1.6847  Validation loss = 0.9604  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 1.6845  Validation loss = 0.9596  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 1.6843  Validation loss = 0.9596  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 1.6842  Validation loss = 0.9592  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 1.6839  Validation loss = 0.9587  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 1.6839  Validation loss = 0.9590  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 1.6837  Validation loss = 0.9588  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 1.6836  Validation loss = 0.9585  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 1.6834  Validation loss = 0.9582  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 1.6832  Validation loss = 0.9576  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 1.6830  Validation loss = 0.9572  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 1.6829  Validation loss = 0.9574  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 1.6827  Validation loss = 0.9572  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 1.6826  Validation loss = 0.9571  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 1.6824  Validation loss = 0.9568  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 1.6822  Validation loss = 0.9561  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 1.6821  Validation loss = 0.9561  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 1.6819  Validation loss = 0.9559  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 1.6817  Validation loss = 0.9554  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 1.6815  Validation loss = 0.9549  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 1.6814  Validation loss = 0.9550  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 1.6813  Validation loss = 0.9549  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 1.6811  Validation loss = 0.9545  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 1.6810  Validation loss = 0.9545  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 1.6809  Validation loss = 0.9543  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 1.6808  Validation loss = 0.9542  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 1.6807  Validation loss = 0.9540  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 1.6804  Validation loss = 0.9534  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 1.6802  Validation loss = 0.9532  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 1.6801  Validation loss = 0.9529  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 1.6799  Validation loss = 0.9525  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 1.6797  Validation loss = 0.9523  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 1.6796  Validation loss = 0.9520  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 1.6794  Validation loss = 0.9515  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 1.6793  Validation loss = 0.9519  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 1.6792  Validation loss = 0.9517  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 1.6790  Validation loss = 0.9514  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 1.6788  Validation loss = 0.9510  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 1.6787  Validation loss = 0.9508  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 1.6785  Validation loss = 0.9504  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 1.6783  Validation loss = 0.9498  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 1.6782  Validation loss = 0.9498  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 1.6780  Validation loss = 0.9497  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 1.6778  Validation loss = 0.9492  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 1.6776  Validation loss = 0.9488  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 1.6774  Validation loss = 0.9485  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 1.6773  Validation loss = 0.9482  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 1.6772  Validation loss = 0.9479  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 1.6770  Validation loss = 0.9478  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 1.6769  Validation loss = 0.9478  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 1.6768  Validation loss = 0.9476  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 1.6766  Validation loss = 0.9472  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 1.6765  Validation loss = 0.9470  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 1.6764  Validation loss = 0.9469  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 1.6762  Validation loss = 0.9466  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 1.6761  Validation loss = 0.9465  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 1.6759  Validation loss = 0.9462  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 1.6759  Validation loss = 0.9464  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 1.6758  Validation loss = 0.9467  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 1.6757  Validation loss = 0.9465  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 1.6756  Validation loss = 0.9462  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 1.6754  Validation loss = 0.9460  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 1.6753  Validation loss = 0.9462  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 1.6752  Validation loss = 0.9458  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 1.6750  Validation loss = 0.9456  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 1.6749  Validation loss = 0.9454  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 1.6746  Validation loss = 0.9448  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 1.6745  Validation loss = 0.9445  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 1.6744  Validation loss = 0.9444  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 1.6741  Validation loss = 0.9438  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 1.6738  Validation loss = 0.9432  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 1.6737  Validation loss = 0.9432  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 1.6736  Validation loss = 0.9428  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 1.6734  Validation loss = 0.9425  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 1.6732  Validation loss = 0.9420  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 1.6731  Validation loss = 0.9422  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 1.6730  Validation loss = 0.9418  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 1.6728  Validation loss = 0.9415  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 1.6727  Validation loss = 0.9413  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 1.6725  Validation loss = 0.9411  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 1.6723  Validation loss = 0.9407  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 1.6721  Validation loss = 0.9404  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 1.6719  Validation loss = 0.9396  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 1.6717  Validation loss = 0.9393  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 1.6715  Validation loss = 0.9388  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 1.6713  Validation loss = 0.9383  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 1.6712  Validation loss = 0.9382  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 1.6711  Validation loss = 0.9383  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 1.6709  Validation loss = 0.9380  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 1.6708  Validation loss = 0.9375  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 1.6706  Validation loss = 0.9373  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 1.6704  Validation loss = 0.9371  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 1.6703  Validation loss = 0.9367  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 1.6700  Validation loss = 0.9362  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 1.6699  Validation loss = 0.9359  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 1.6697  Validation loss = 0.9355  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 1.6695  Validation loss = 0.9350  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 1.6693  Validation loss = 0.9349  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 1.6692  Validation loss = 0.9349  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 1.6691  Validation loss = 0.9347  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 1.6690  Validation loss = 0.9346  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 1.6688  Validation loss = 0.9343  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 1.6687  Validation loss = 0.9343  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 1.6685  Validation loss = 0.9339  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 1.6685  Validation loss = 0.9340  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 1.6683  Validation loss = 0.9338  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 1.6682  Validation loss = 0.9335  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 1.6680  Validation loss = 0.9334  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 1.6678  Validation loss = 0.9330  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 1.6678  Validation loss = 0.9332  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 1.6676  Validation loss = 0.9332  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 1.6675  Validation loss = 0.9330  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 1.6673  Validation loss = 0.9323  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 1.6672  Validation loss = 0.9322  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 1.6670  Validation loss = 0.9318  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 1.6668  Validation loss = 0.9312  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 1.6666  Validation loss = 0.9312  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 1.6665  Validation loss = 0.9309  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 1.6664  Validation loss = 0.9310  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 1.6662  Validation loss = 0.9306  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 1.6661  Validation loss = 0.9304  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 1.6659  Validation loss = 0.9303  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 1.6659  Validation loss = 0.9305  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 1.6658  Validation loss = 0.9305  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 1.6657  Validation loss = 0.9308  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 1.6654  Validation loss = 0.9303  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 1.6653  Validation loss = 0.9303  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 1.6652  Validation loss = 0.9301  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 1.6651  Validation loss = 0.9305  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 1.6650  Validation loss = 0.9305  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 1.6648  Validation loss = 0.9299  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 1.6646  Validation loss = 0.9294  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 1.6644  Validation loss = 0.9291  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 1.6642  Validation loss = 0.9287  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 1.6641  Validation loss = 0.9287  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 1.6640  Validation loss = 0.9284  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 1.6638  Validation loss = 0.9279  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 1.6636  Validation loss = 0.9277  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 1.6635  Validation loss = 0.9278  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 1.6633  Validation loss = 0.9272  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 1.6632  Validation loss = 0.9269  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 1.6631  Validation loss = 0.9270  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 1.6629  Validation loss = 0.9265  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 1.6627  Validation loss = 0.9265  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 1.6625  Validation loss = 0.9258  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 1.6623  Validation loss = 0.9254  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 1.6621  Validation loss = 0.9247  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 1.6619  Validation loss = 0.9242  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 1.6617  Validation loss = 0.9240  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 1.6615  Validation loss = 0.9234  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 1.6614  Validation loss = 0.9234  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 1.6613  Validation loss = 0.9236  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 1.6610  Validation loss = 0.9230  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 1.6609  Validation loss = 0.9228  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 1.6607  Validation loss = 0.9224  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 1.6606  Validation loss = 0.9222  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 1.6604  Validation loss = 0.9220  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 1.6603  Validation loss = 0.9219  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 1.6601  Validation loss = 0.9214  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 1.6599  Validation loss = 0.9212  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 1.6596  Validation loss = 0.9201  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 1.6594  Validation loss = 0.9196  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 1.6593  Validation loss = 0.9198  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 1.6591  Validation loss = 0.9193  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 1.6591  Validation loss = 0.9195  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 1.6589  Validation loss = 0.9193  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 1.6588  Validation loss = 0.9192  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 1.6586  Validation loss = 0.9188  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 1.6584  Validation loss = 0.9185  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 1.6582  Validation loss = 0.9181  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 1.6580  Validation loss = 0.9178  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 1.6579  Validation loss = 0.9175  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 1.6577  Validation loss = 0.9174  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 1.6576  Validation loss = 0.9177  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 1.6574  Validation loss = 0.9173  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 1.6573  Validation loss = 0.9172  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 1.6572  Validation loss = 0.9170  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 1.6570  Validation loss = 0.9168  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 1.6569  Validation loss = 0.9165  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 1.6568  Validation loss = 0.9167  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 1.6567  Validation loss = 0.9167  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 1.6565  Validation loss = 0.9165  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 1.6563  Validation loss = 0.9163  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 1.6562  Validation loss = 0.9162  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 1.6560  Validation loss = 0.9160  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 1.6559  Validation loss = 0.9160  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 1.6558  Validation loss = 0.9160  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 1.6556  Validation loss = 0.9158  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 1.6555  Validation loss = 0.9159  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 1.6553  Validation loss = 0.9154  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 1.6551  Validation loss = 0.9151  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 1.6550  Validation loss = 0.9151  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 1.6548  Validation loss = 0.9148  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 1.6546  Validation loss = 0.9143  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 1.6544  Validation loss = 0.9139  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 1.6542  Validation loss = 0.9138  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 1.6541  Validation loss = 0.9134  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 1.6539  Validation loss = 0.9132  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 1.6538  Validation loss = 0.9127  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 1.6536  Validation loss = 0.9126  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 1.6535  Validation loss = 0.9125  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 1.6533  Validation loss = 0.9123  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 1.6532  Validation loss = 0.9122  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 1.6530  Validation loss = 0.9117  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 1.6529  Validation loss = 0.9116  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 1.6527  Validation loss = 0.9115  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 1.6525  Validation loss = 0.9110  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 1.6524  Validation loss = 0.9107  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 1.6522  Validation loss = 0.9106  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 1.6521  Validation loss = 0.9103  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 1.6520  Validation loss = 0.9101  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 1.6518  Validation loss = 0.9096  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 1.6516  Validation loss = 0.9093  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 1.6515  Validation loss = 0.9090  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 1.6513  Validation loss = 0.9088  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 1.6512  Validation loss = 0.9085  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 1.6510  Validation loss = 0.9082  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 1.6508  Validation loss = 0.9080  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 1.6507  Validation loss = 0.9079  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 1.6504  Validation loss = 0.9073  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 1.6503  Validation loss = 0.9069  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 1.6501  Validation loss = 0.9069  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 1.6500  Validation loss = 0.9068  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 1.6500  Validation loss = 0.9071  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 1.6498  Validation loss = 0.9070  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 1.6496  Validation loss = 0.9066  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 1.6495  Validation loss = 0.9063  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 1.6494  Validation loss = 0.9066  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 1.6493  Validation loss = 0.9067  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 1.6491  Validation loss = 0.9065  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 1.6489  Validation loss = 0.9062  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 1.6488  Validation loss = 0.9060  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 1.6487  Validation loss = 0.9061  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 1.6486  Validation loss = 0.9061  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 1.6484  Validation loss = 0.9056  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 1.6483  Validation loss = 0.9055  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 1.6481  Validation loss = 0.9054  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 1.6480  Validation loss = 0.9051  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 1.6478  Validation loss = 0.9048  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 1.6476  Validation loss = 0.9044  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 1.6475  Validation loss = 0.9040  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 1.6473  Validation loss = 0.9034  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 1.6472  Validation loss = 0.9033  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 1.6470  Validation loss = 0.9031  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 1.6469  Validation loss = 0.9030  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 1.6468  Validation loss = 0.9029  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 1.6466  Validation loss = 0.9026  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 1.6464  Validation loss = 0.9020  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 1.6463  Validation loss = 0.9018  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 1.6461  Validation loss = 0.9014  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 1.6460  Validation loss = 0.9010  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 1.6458  Validation loss = 0.9009  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 1.6457  Validation loss = 0.9008  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 1.6455  Validation loss = 0.9002  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 1.6454  Validation loss = 0.8999  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 1.6453  Validation loss = 0.9001  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 1.6452  Validation loss = 0.9002  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 1.6450  Validation loss = 0.8998  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 1.6449  Validation loss = 0.8996  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 1.6447  Validation loss = 0.8998  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 1.6446  Validation loss = 0.8997  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 1.6445  Validation loss = 0.8999  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 1.6444  Validation loss = 0.8997  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 1.6443  Validation loss = 0.8996  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 1.6441  Validation loss = 0.8991  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 1.6439  Validation loss = 0.8990  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 1.6438  Validation loss = 0.8987  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 1.6435  Validation loss = 0.8981  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 1.6434  Validation loss = 0.8978  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 1.6432  Validation loss = 0.8970  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 1.6431  Validation loss = 0.8969  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 1.6429  Validation loss = 0.8966  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 1.6428  Validation loss = 0.8967  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 1.6427  Validation loss = 0.8965  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 1.6425  Validation loss = 0.8962  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 1.6424  Validation loss = 0.8961  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 1.6422  Validation loss = 0.8959  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 1.6421  Validation loss = 0.8955  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 1.6419  Validation loss = 0.8951  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 1.6417  Validation loss = 0.8947  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 1.6416  Validation loss = 0.8945  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 1.6414  Validation loss = 0.8945  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 1.6413  Validation loss = 0.8943  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 1.6412  Validation loss = 0.8943  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 1.6411  Validation loss = 0.8939  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 1.6410  Validation loss = 0.8939  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 1.6409  Validation loss = 0.8940  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 1.6407  Validation loss = 0.8937  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 1.6406  Validation loss = 0.8936  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 1.6405  Validation loss = 0.8935  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 1.6403  Validation loss = 0.8933  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 1.6401  Validation loss = 0.8929  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 1.6399  Validation loss = 0.8925  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 1.6397  Validation loss = 0.8923  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 1.6395  Validation loss = 0.8919  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 1.6394  Validation loss = 0.8919  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 1.6392  Validation loss = 0.8915  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 1.6391  Validation loss = 0.8910  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 1.6390  Validation loss = 0.8909  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 1.6388  Validation loss = 0.8907  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 1.6386  Validation loss = 0.8905  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 1.6385  Validation loss = 0.8902  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 1.6383  Validation loss = 0.8893  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 1.6381  Validation loss = 0.8889  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 1.6380  Validation loss = 0.8890  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 1.6378  Validation loss = 0.8887  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 1.6377  Validation loss = 0.8887  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 1.6376  Validation loss = 0.8886  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 1.6376  Validation loss = 0.8888  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 1.6374  Validation loss = 0.8885  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 1.6373  Validation loss = 0.8884  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 1.6372  Validation loss = 0.8885  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 1.6371  Validation loss = 0.8888  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 1.6369  Validation loss = 0.8884  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 1.6369  Validation loss = 0.8887  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 1.6367  Validation loss = 0.8883  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 1.6365  Validation loss = 0.8880  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 1.6364  Validation loss = 0.8877  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 1.6363  Validation loss = 0.8878  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 1.6361  Validation loss = 0.8873  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 1.6360  Validation loss = 0.8872  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 1.6358  Validation loss = 0.8869  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 1.6357  Validation loss = 0.8865  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 1.6355  Validation loss = 0.8863  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 1.6353  Validation loss = 0.8859  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 1.6352  Validation loss = 0.8860  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 1.6350  Validation loss = 0.8854  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 1.6349  Validation loss = 0.8854  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 1.6347  Validation loss = 0.8848  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 1.6345  Validation loss = 0.8845  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 1.6343  Validation loss = 0.8842  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 1.6343  Validation loss = 0.8844  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 1.6341  Validation loss = 0.8841  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 1.6339  Validation loss = 0.8839  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 1.6338  Validation loss = 0.8841  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 1.6337  Validation loss = 0.8839  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 1.6336  Validation loss = 0.8841  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 1.6335  Validation loss = 0.8844  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 1.6334  Validation loss = 0.8842  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 1.6332  Validation loss = 0.8841  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 1.6330  Validation loss = 0.8838  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 1.6328  Validation loss = 0.8832  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 1.6327  Validation loss = 0.8833  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 1.6325  Validation loss = 0.8834  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 1.6323  Validation loss = 0.8828  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 1.6322  Validation loss = 0.8829  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 1.6321  Validation loss = 0.8829  \n",
      "\n",
      "Fold: 7  Epoch: 501  Training loss = 1.6320  Validation loss = 0.8831  \n",
      "\n",
      "Fold: 7  Epoch: 502  Training loss = 1.6319  Validation loss = 0.8826  \n",
      "\n",
      "Fold: 7  Epoch: 503  Training loss = 1.6318  Validation loss = 0.8825  \n",
      "\n",
      "Fold: 7  Epoch: 504  Training loss = 1.6316  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 7  Epoch: 505  Training loss = 1.6314  Validation loss = 0.8817  \n",
      "\n",
      "Fold: 7  Epoch: 506  Training loss = 1.6313  Validation loss = 0.8818  \n",
      "\n",
      "Fold: 7  Epoch: 507  Training loss = 1.6312  Validation loss = 0.8816  \n",
      "\n",
      "Fold: 7  Epoch: 508  Training loss = 1.6310  Validation loss = 0.8810  \n",
      "\n",
      "Fold: 7  Epoch: 509  Training loss = 1.6309  Validation loss = 0.8810  \n",
      "\n",
      "Fold: 7  Epoch: 510  Training loss = 1.6307  Validation loss = 0.8806  \n",
      "\n",
      "Fold: 7  Epoch: 511  Training loss = 1.6305  Validation loss = 0.8802  \n",
      "\n",
      "Fold: 7  Epoch: 512  Training loss = 1.6304  Validation loss = 0.8802  \n",
      "\n",
      "Fold: 7  Epoch: 513  Training loss = 1.6303  Validation loss = 0.8800  \n",
      "\n",
      "Fold: 7  Epoch: 514  Training loss = 1.6302  Validation loss = 0.8804  \n",
      "\n",
      "Fold: 7  Epoch: 515  Training loss = 1.6301  Validation loss = 0.8802  \n",
      "\n",
      "Fold: 7  Epoch: 516  Training loss = 1.6299  Validation loss = 0.8798  \n",
      "\n",
      "Fold: 7  Epoch: 517  Training loss = 1.6298  Validation loss = 0.8798  \n",
      "\n",
      "Fold: 7  Epoch: 518  Training loss = 1.6296  Validation loss = 0.8798  \n",
      "\n",
      "Fold: 7  Epoch: 519  Training loss = 1.6295  Validation loss = 0.8796  \n",
      "\n",
      "Fold: 7  Epoch: 520  Training loss = 1.6293  Validation loss = 0.8794  \n",
      "\n",
      "Fold: 7  Epoch: 521  Training loss = 1.6292  Validation loss = 0.8792  \n",
      "\n",
      "Fold: 7  Epoch: 522  Training loss = 1.6290  Validation loss = 0.8788  \n",
      "\n",
      "Fold: 7  Epoch: 523  Training loss = 1.6289  Validation loss = 0.8789  \n",
      "\n",
      "Fold: 7  Epoch: 524  Training loss = 1.6288  Validation loss = 0.8792  \n",
      "\n",
      "Fold: 7  Epoch: 525  Training loss = 1.6286  Validation loss = 0.8791  \n",
      "\n",
      "Fold: 7  Epoch: 526  Training loss = 1.6285  Validation loss = 0.8790  \n",
      "\n",
      "Fold: 7  Epoch: 527  Training loss = 1.6283  Validation loss = 0.8785  \n",
      "\n",
      "Fold: 7  Epoch: 528  Training loss = 1.6282  Validation loss = 0.8783  \n",
      "\n",
      "Fold: 7  Epoch: 529  Training loss = 1.6280  Validation loss = 0.8783  \n",
      "\n",
      "Fold: 7  Epoch: 530  Training loss = 1.6279  Validation loss = 0.8782  \n",
      "\n",
      "Fold: 7  Epoch: 531  Training loss = 1.6278  Validation loss = 0.8781  \n",
      "\n",
      "Fold: 7  Epoch: 532  Training loss = 1.6277  Validation loss = 0.8783  \n",
      "\n",
      "Fold: 7  Epoch: 533  Training loss = 1.6275  Validation loss = 0.8782  \n",
      "\n",
      "Fold: 7  Epoch: 534  Training loss = 1.6274  Validation loss = 0.8782  \n",
      "\n",
      "Fold: 7  Epoch: 535  Training loss = 1.6272  Validation loss = 0.8779  \n",
      "\n",
      "Fold: 7  Epoch: 536  Training loss = 1.6270  Validation loss = 0.8774  \n",
      "\n",
      "Fold: 7  Epoch: 537  Training loss = 1.6269  Validation loss = 0.8774  \n",
      "\n",
      "Fold: 7  Epoch: 538  Training loss = 1.6268  Validation loss = 0.8775  \n",
      "\n",
      "Fold: 7  Epoch: 539  Training loss = 1.6266  Validation loss = 0.8770  \n",
      "\n",
      "Fold: 7  Epoch: 540  Training loss = 1.6265  Validation loss = 0.8768  \n",
      "\n",
      "Fold: 7  Epoch: 541  Training loss = 1.6264  Validation loss = 0.8766  \n",
      "\n",
      "Fold: 7  Epoch: 542  Training loss = 1.6262  Validation loss = 0.8766  \n",
      "\n",
      "Fold: 7  Epoch: 543  Training loss = 1.6261  Validation loss = 0.8761  \n",
      "\n",
      "Fold: 7  Epoch: 544  Training loss = 1.6260  Validation loss = 0.8761  \n",
      "\n",
      "Fold: 7  Epoch: 545  Training loss = 1.6258  Validation loss = 0.8754  \n",
      "\n",
      "Fold: 7  Epoch: 546  Training loss = 1.6257  Validation loss = 0.8755  \n",
      "\n",
      "Fold: 7  Epoch: 547  Training loss = 1.6256  Validation loss = 0.8759  \n",
      "\n",
      "Fold: 7  Epoch: 548  Training loss = 1.6255  Validation loss = 0.8758  \n",
      "\n",
      "Fold: 7  Epoch: 549  Training loss = 1.6254  Validation loss = 0.8757  \n",
      "\n",
      "Fold: 7  Epoch: 550  Training loss = 1.6254  Validation loss = 0.8761  \n",
      "\n",
      "Fold: 7  Epoch: 551  Training loss = 1.6252  Validation loss = 0.8758  \n",
      "\n",
      "Fold: 7  Epoch: 552  Training loss = 1.6251  Validation loss = 0.8758  \n",
      "\n",
      "Fold: 7  Epoch: 553  Training loss = 1.6250  Validation loss = 0.8761  \n",
      "\n",
      "Fold: 7  Epoch: 554  Training loss = 1.6249  Validation loss = 0.8758  \n",
      "\n",
      "Fold: 7  Epoch: 555  Training loss = 1.6247  Validation loss = 0.8758  \n",
      "\n",
      "Fold: 7  Epoch: 556  Training loss = 1.6245  Validation loss = 0.8753  \n",
      "\n",
      "Fold: 7  Epoch: 557  Training loss = 1.6244  Validation loss = 0.8748  \n",
      "\n",
      "Fold: 7  Epoch: 558  Training loss = 1.6243  Validation loss = 0.8748  \n",
      "\n",
      "Fold: 7  Epoch: 559  Training loss = 1.6241  Validation loss = 0.8742  \n",
      "\n",
      "Fold: 7  Epoch: 560  Training loss = 1.6240  Validation loss = 0.8742  \n",
      "\n",
      "Fold: 7  Epoch: 561  Training loss = 1.6239  Validation loss = 0.8744  \n",
      "\n",
      "Fold: 7  Epoch: 562  Training loss = 1.6238  Validation loss = 0.8746  \n",
      "\n",
      "Fold: 7  Epoch: 563  Training loss = 1.6237  Validation loss = 0.8746  \n",
      "\n",
      "Fold: 7  Epoch: 564  Training loss = 1.6236  Validation loss = 0.8747  \n",
      "\n",
      "Fold: 7  Epoch: 565  Training loss = 1.6234  Validation loss = 0.8745  \n",
      "\n",
      "Fold: 7  Epoch: 566  Training loss = 1.6233  Validation loss = 0.8746  \n",
      "\n",
      "Fold: 7  Epoch: 567  Training loss = 1.6232  Validation loss = 0.8744  \n",
      "\n",
      "Fold: 7  Epoch: 568  Training loss = 1.6231  Validation loss = 0.8744  \n",
      "\n",
      "Fold: 7  Epoch: 569  Training loss = 1.6229  Validation loss = 0.8739  \n",
      "\n",
      "Fold: 7  Epoch: 570  Training loss = 1.6227  Validation loss = 0.8731  \n",
      "\n",
      "Fold: 7  Epoch: 571  Training loss = 1.6225  Validation loss = 0.8732  \n",
      "\n",
      "Fold: 7  Epoch: 572  Training loss = 1.6224  Validation loss = 0.8732  \n",
      "\n",
      "Fold: 7  Epoch: 573  Training loss = 1.6223  Validation loss = 0.8731  \n",
      "\n",
      "Fold: 7  Epoch: 574  Training loss = 1.6222  Validation loss = 0.8732  \n",
      "\n",
      "Fold: 7  Epoch: 575  Training loss = 1.6221  Validation loss = 0.8732  \n",
      "\n",
      "Fold: 7  Epoch: 576  Training loss = 1.6219  Validation loss = 0.8729  \n",
      "\n",
      "Fold: 7  Epoch: 577  Training loss = 1.6217  Validation loss = 0.8726  \n",
      "\n",
      "Fold: 7  Epoch: 578  Training loss = 1.6216  Validation loss = 0.8723  \n",
      "\n",
      "Fold: 7  Epoch: 579  Training loss = 1.6214  Validation loss = 0.8716  \n",
      "\n",
      "Fold: 7  Epoch: 580  Training loss = 1.6213  Validation loss = 0.8714  \n",
      "\n",
      "Fold: 7  Epoch: 581  Training loss = 1.6212  Validation loss = 0.8712  \n",
      "\n",
      "Fold: 7  Epoch: 582  Training loss = 1.6211  Validation loss = 0.8711  \n",
      "\n",
      "Fold: 7  Epoch: 583  Training loss = 1.6210  Validation loss = 0.8714  \n",
      "\n",
      "Fold: 7  Epoch: 584  Training loss = 1.6209  Validation loss = 0.8713  \n",
      "\n",
      "Fold: 7  Epoch: 585  Training loss = 1.6207  Validation loss = 0.8709  \n",
      "\n",
      "Fold: 7  Epoch: 586  Training loss = 1.6206  Validation loss = 0.8711  \n",
      "\n",
      "Fold: 7  Epoch: 587  Training loss = 1.6205  Validation loss = 0.8707  \n",
      "\n",
      "Fold: 7  Epoch: 588  Training loss = 1.6203  Validation loss = 0.8703  \n",
      "\n",
      "Fold: 7  Epoch: 589  Training loss = 1.6202  Validation loss = 0.8702  \n",
      "\n",
      "Fold: 7  Epoch: 590  Training loss = 1.6200  Validation loss = 0.8700  \n",
      "\n",
      "Fold: 7  Epoch: 591  Training loss = 1.6199  Validation loss = 0.8697  \n",
      "\n",
      "Fold: 7  Epoch: 592  Training loss = 1.6198  Validation loss = 0.8699  \n",
      "\n",
      "Fold: 7  Epoch: 593  Training loss = 1.6196  Validation loss = 0.8695  \n",
      "\n",
      "Fold: 7  Epoch: 594  Training loss = 1.6195  Validation loss = 0.8692  \n",
      "\n",
      "Fold: 7  Epoch: 595  Training loss = 1.6194  Validation loss = 0.8696  \n",
      "\n",
      "Fold: 7  Epoch: 596  Training loss = 1.6193  Validation loss = 0.8696  \n",
      "\n",
      "Fold: 7  Epoch: 597  Training loss = 1.6192  Validation loss = 0.8695  \n",
      "\n",
      "Fold: 7  Epoch: 598  Training loss = 1.6190  Validation loss = 0.8692  \n",
      "\n",
      "Fold: 7  Epoch: 599  Training loss = 1.6189  Validation loss = 0.8692  \n",
      "\n",
      "Fold: 7  Epoch: 600  Training loss = 1.6188  Validation loss = 0.8692  \n",
      "\n",
      "Fold: 7  Epoch: 601  Training loss = 1.6186  Validation loss = 0.8689  \n",
      "\n",
      "Fold: 7  Epoch: 602  Training loss = 1.6185  Validation loss = 0.8690  \n",
      "\n",
      "Fold: 7  Epoch: 603  Training loss = 1.6183  Validation loss = 0.8687  \n",
      "\n",
      "Fold: 7  Epoch: 604  Training loss = 1.6182  Validation loss = 0.8685  \n",
      "\n",
      "Fold: 7  Epoch: 605  Training loss = 1.6180  Validation loss = 0.8680  \n",
      "\n",
      "Fold: 7  Epoch: 606  Training loss = 1.6180  Validation loss = 0.8682  \n",
      "\n",
      "Fold: 7  Epoch: 607  Training loss = 1.6179  Validation loss = 0.8677  \n",
      "\n",
      "Fold: 7  Epoch: 608  Training loss = 1.6178  Validation loss = 0.8682  \n",
      "\n",
      "Fold: 7  Epoch: 609  Training loss = 1.6176  Validation loss = 0.8682  \n",
      "\n",
      "Fold: 7  Epoch: 610  Training loss = 1.6175  Validation loss = 0.8682  \n",
      "\n",
      "Fold: 7  Epoch: 611  Training loss = 1.6174  Validation loss = 0.8680  \n",
      "\n",
      "Fold: 7  Epoch: 612  Training loss = 1.6173  Validation loss = 0.8677  \n",
      "\n",
      "Fold: 7  Epoch: 613  Training loss = 1.6171  Validation loss = 0.8671  \n",
      "\n",
      "Fold: 7  Epoch: 614  Training loss = 1.6169  Validation loss = 0.8671  \n",
      "\n",
      "Fold: 7  Epoch: 615  Training loss = 1.6168  Validation loss = 0.8673  \n",
      "\n",
      "Fold: 7  Epoch: 616  Training loss = 1.6167  Validation loss = 0.8670  \n",
      "\n",
      "Fold: 7  Epoch: 617  Training loss = 1.6166  Validation loss = 0.8668  \n",
      "\n",
      "Fold: 7  Epoch: 618  Training loss = 1.6164  Validation loss = 0.8664  \n",
      "\n",
      "Fold: 7  Epoch: 619  Training loss = 1.6163  Validation loss = 0.8665  \n",
      "\n",
      "Fold: 7  Epoch: 620  Training loss = 1.6161  Validation loss = 0.8662  \n",
      "\n",
      "Fold: 7  Epoch: 621  Training loss = 1.6159  Validation loss = 0.8657  \n",
      "\n",
      "Fold: 7  Epoch: 622  Training loss = 1.6158  Validation loss = 0.8653  \n",
      "\n",
      "Fold: 7  Epoch: 623  Training loss = 1.6156  Validation loss = 0.8650  \n",
      "\n",
      "Fold: 7  Epoch: 624  Training loss = 1.6155  Validation loss = 0.8649  \n",
      "\n",
      "Fold: 7  Epoch: 625  Training loss = 1.6154  Validation loss = 0.8647  \n",
      "\n",
      "Fold: 7  Epoch: 626  Training loss = 1.6153  Validation loss = 0.8645  \n",
      "\n",
      "Fold: 7  Epoch: 627  Training loss = 1.6151  Validation loss = 0.8645  \n",
      "\n",
      "Fold: 7  Epoch: 628  Training loss = 1.6150  Validation loss = 0.8645  \n",
      "\n",
      "Fold: 7  Epoch: 629  Training loss = 1.6148  Validation loss = 0.8642  \n",
      "\n",
      "Fold: 7  Epoch: 630  Training loss = 1.6146  Validation loss = 0.8638  \n",
      "\n",
      "Fold: 7  Epoch: 631  Training loss = 1.6145  Validation loss = 0.8635  \n",
      "\n",
      "Fold: 7  Epoch: 632  Training loss = 1.6144  Validation loss = 0.8634  \n",
      "\n",
      "Fold: 7  Epoch: 633  Training loss = 1.6142  Validation loss = 0.8630  \n",
      "\n",
      "Fold: 7  Epoch: 634  Training loss = 1.6141  Validation loss = 0.8630  \n",
      "\n",
      "Fold: 7  Epoch: 635  Training loss = 1.6139  Validation loss = 0.8628  \n",
      "\n",
      "Fold: 7  Epoch: 636  Training loss = 1.6137  Validation loss = 0.8625  \n",
      "\n",
      "Fold: 7  Epoch: 637  Training loss = 1.6136  Validation loss = 0.8624  \n",
      "\n",
      "Fold: 7  Epoch: 638  Training loss = 1.6135  Validation loss = 0.8624  \n",
      "\n",
      "Fold: 7  Epoch: 639  Training loss = 1.6134  Validation loss = 0.8626  \n",
      "\n",
      "Fold: 7  Epoch: 640  Training loss = 1.6132  Validation loss = 0.8626  \n",
      "\n",
      "Fold: 7  Epoch: 641  Training loss = 1.6131  Validation loss = 0.8622  \n",
      "\n",
      "Fold: 7  Epoch: 642  Training loss = 1.6130  Validation loss = 0.8625  \n",
      "\n",
      "Fold: 7  Epoch: 643  Training loss = 1.6129  Validation loss = 0.8625  \n",
      "\n",
      "Fold: 7  Epoch: 644  Training loss = 1.6128  Validation loss = 0.8624  \n",
      "\n",
      "Fold: 7  Epoch: 645  Training loss = 1.6128  Validation loss = 0.8625  \n",
      "\n",
      "Fold: 7  Epoch: 646  Training loss = 1.6126  Validation loss = 0.8626  \n",
      "\n",
      "Fold: 7  Epoch: 647  Training loss = 1.6125  Validation loss = 0.8624  \n",
      "\n",
      "Fold: 7  Epoch: 648  Training loss = 1.6124  Validation loss = 0.8628  \n",
      "\n",
      "Fold: 7  Epoch: 649  Training loss = 1.6123  Validation loss = 0.8629  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 641  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.5722  Validation loss = 5.8931  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.5720  Validation loss = 5.8929  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.5719  Validation loss = 5.8930  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.5718  Validation loss = 5.8926  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.5717  Validation loss = 5.8924  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.5714  Validation loss = 5.8913  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.5713  Validation loss = 5.8907  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.5712  Validation loss = 5.8905  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.5711  Validation loss = 5.8905  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.5708  Validation loss = 5.8894  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.5707  Validation loss = 5.8893  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.5705  Validation loss = 5.8891  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.5703  Validation loss = 5.8884  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.5703  Validation loss = 5.8886  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.5702  Validation loss = 5.8885  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.5701  Validation loss = 5.8887  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.5699  Validation loss = 5.8884  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.5698  Validation loss = 5.8883  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.5696  Validation loss = 5.8876  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 1.5694  Validation loss = 5.8867  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 1.5692  Validation loss = 5.8862  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 1.5691  Validation loss = 5.8859  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 1.5689  Validation loss = 5.8855  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 1.5687  Validation loss = 5.8849  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 1.5685  Validation loss = 5.8848  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 1.5683  Validation loss = 5.8842  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 1.5681  Validation loss = 5.8835  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 1.5679  Validation loss = 5.8831  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 1.5679  Validation loss = 5.8830  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 1.5678  Validation loss = 5.8833  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 1.5677  Validation loss = 5.8832  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 1.5676  Validation loss = 5.8832  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 1.5675  Validation loss = 5.8832  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 1.5674  Validation loss = 5.8830  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 1.5672  Validation loss = 5.8830  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 1.5671  Validation loss = 5.8828  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 1.5670  Validation loss = 5.8826  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 1.5669  Validation loss = 5.8824  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 1.5668  Validation loss = 5.8825  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 1.5666  Validation loss = 5.8822  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 1.5665  Validation loss = 5.8818  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 1.5664  Validation loss = 5.8817  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 1.5662  Validation loss = 5.8814  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 1.5661  Validation loss = 5.8812  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 1.5660  Validation loss = 5.8812  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 1.5659  Validation loss = 5.8809  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 1.5658  Validation loss = 5.8808  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 1.5656  Validation loss = 5.8808  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 1.5655  Validation loss = 5.8803  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 1.5654  Validation loss = 5.8801  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 1.5651  Validation loss = 5.8793  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 1.5650  Validation loss = 5.8785  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 1.5648  Validation loss = 5.8779  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 1.5647  Validation loss = 5.8777  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 1.5646  Validation loss = 5.8774  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 1.5645  Validation loss = 5.8769  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 1.5644  Validation loss = 5.8770  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 1.5643  Validation loss = 5.8771  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 1.5643  Validation loss = 5.8773  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 1.5641  Validation loss = 5.8770  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 1.5640  Validation loss = 5.8769  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 1.5640  Validation loss = 5.8772  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 1.5639  Validation loss = 5.8771  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 1.5638  Validation loss = 5.8768  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 1.5636  Validation loss = 5.8764  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 1.5635  Validation loss = 5.8764  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 1.5634  Validation loss = 5.8761  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 1.5632  Validation loss = 5.8754  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 1.5632  Validation loss = 5.8755  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 1.5631  Validation loss = 5.8755  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 1.5630  Validation loss = 5.8754  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 1.5629  Validation loss = 5.8754  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 1.5627  Validation loss = 5.8751  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 1.5625  Validation loss = 5.8745  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 1.5625  Validation loss = 5.8746  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 1.5623  Validation loss = 5.8742  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 1.5621  Validation loss = 5.8735  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 1.5619  Validation loss = 5.8731  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 1.5617  Validation loss = 5.8728  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 1.5616  Validation loss = 5.8726  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 1.5614  Validation loss = 5.8726  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 1.5613  Validation loss = 5.8721  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 1.5611  Validation loss = 5.8714  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 1.5609  Validation loss = 5.8707  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 1.5608  Validation loss = 5.8703  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 1.5606  Validation loss = 5.8698  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 1.5604  Validation loss = 5.8691  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 1.5603  Validation loss = 5.8689  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 1.5601  Validation loss = 5.8682  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 1.5600  Validation loss = 5.8679  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 1.5598  Validation loss = 5.8674  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 1.5596  Validation loss = 5.8664  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 1.5594  Validation loss = 5.8658  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 1.5592  Validation loss = 5.8654  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 1.5592  Validation loss = 5.8653  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 1.5590  Validation loss = 5.8647  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 1.5588  Validation loss = 5.8644  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 1.5587  Validation loss = 5.8642  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 1.5585  Validation loss = 5.8636  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 1.5584  Validation loss = 5.8635  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 1.5583  Validation loss = 5.8633  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 1.5581  Validation loss = 5.8630  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 1.5579  Validation loss = 5.8625  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 1.5579  Validation loss = 5.8625  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 1.5576  Validation loss = 5.8616  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 1.5575  Validation loss = 5.8611  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 1.5574  Validation loss = 5.8609  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 1.5573  Validation loss = 5.8607  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 1.5571  Validation loss = 5.8603  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 1.5569  Validation loss = 5.8593  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 1.5568  Validation loss = 5.8592  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 1.5567  Validation loss = 5.8591  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 1.5566  Validation loss = 5.8590  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 1.5564  Validation loss = 5.8585  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 1.5563  Validation loss = 5.8582  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 1.5561  Validation loss = 5.8574  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 1.5560  Validation loss = 5.8573  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 1.5559  Validation loss = 5.8568  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 1.5557  Validation loss = 5.8565  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 1.5556  Validation loss = 5.8560  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 1.5555  Validation loss = 5.8557  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 1.5553  Validation loss = 5.8550  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 1.5551  Validation loss = 5.8550  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 1.5550  Validation loss = 5.8544  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 1.5548  Validation loss = 5.8542  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 1.5547  Validation loss = 5.8537  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 1.5545  Validation loss = 5.8537  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 1.5544  Validation loss = 5.8536  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 1.5543  Validation loss = 5.8529  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 1.5542  Validation loss = 5.8529  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 1.5540  Validation loss = 5.8524  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 1.5539  Validation loss = 5.8520  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 1.5538  Validation loss = 5.8514  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 1.5536  Validation loss = 5.8508  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 1.5535  Validation loss = 5.8509  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 1.5534  Validation loss = 5.8507  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 1.5532  Validation loss = 5.8505  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 1.5531  Validation loss = 5.8501  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 1.5529  Validation loss = 5.8494  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 1.5527  Validation loss = 5.8487  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 1.5526  Validation loss = 5.8482  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 1.5525  Validation loss = 5.8481  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 1.5524  Validation loss = 5.8478  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 1.5522  Validation loss = 5.8477  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 1.5521  Validation loss = 5.8467  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 1.5520  Validation loss = 5.8467  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 1.5519  Validation loss = 5.8466  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 1.5517  Validation loss = 5.8461  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 1.5515  Validation loss = 5.8455  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 1.5514  Validation loss = 5.8452  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 1.5512  Validation loss = 5.8450  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 1.5511  Validation loss = 5.8450  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 1.5510  Validation loss = 5.8450  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 1.5508  Validation loss = 5.8443  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 1.5507  Validation loss = 5.8443  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 1.5506  Validation loss = 5.8440  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 1.5505  Validation loss = 5.8438  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 1.5503  Validation loss = 5.8429  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 1.5501  Validation loss = 5.8425  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 1.5500  Validation loss = 5.8424  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 1.5499  Validation loss = 5.8421  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 1.5497  Validation loss = 5.8418  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 1.5496  Validation loss = 5.8409  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 1.5495  Validation loss = 5.8408  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 1.5493  Validation loss = 5.8405  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 1.5492  Validation loss = 5.8402  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 1.5491  Validation loss = 5.8406  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 1.5490  Validation loss = 5.8407  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 1.5489  Validation loss = 5.8406  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 1.5487  Validation loss = 5.8404  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 1.5486  Validation loss = 5.8400  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 1.5485  Validation loss = 5.8397  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 1.5484  Validation loss = 5.8399  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 1.5483  Validation loss = 5.8394  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 1.5481  Validation loss = 5.8391  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 1.5479  Validation loss = 5.8384  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 1.5477  Validation loss = 5.8379  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 1.5477  Validation loss = 5.8382  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 1.5476  Validation loss = 5.8379  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 1.5475  Validation loss = 5.8378  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 1.5474  Validation loss = 5.8377  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 1.5473  Validation loss = 5.8373  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 1.5471  Validation loss = 5.8367  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 1.5469  Validation loss = 5.8362  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 1.5468  Validation loss = 5.8361  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 1.5466  Validation loss = 5.8354  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 1.5465  Validation loss = 5.8359  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 1.5464  Validation loss = 5.8359  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 1.5464  Validation loss = 5.8361  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 1.5462  Validation loss = 5.8357  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 1.5461  Validation loss = 5.8348  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 1.5459  Validation loss = 5.8345  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 1.5458  Validation loss = 5.8347  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 1.5456  Validation loss = 5.8341  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 1.5455  Validation loss = 5.8335  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 1.5453  Validation loss = 5.8330  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 1.5452  Validation loss = 5.8326  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 1.5450  Validation loss = 5.8321  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 1.5449  Validation loss = 5.8316  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 1.5448  Validation loss = 5.8317  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 1.5446  Validation loss = 5.8310  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 1.5444  Validation loss = 5.8307  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 1.5443  Validation loss = 5.8306  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 1.5441  Validation loss = 5.8302  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 1.5440  Validation loss = 5.8297  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 1.5439  Validation loss = 5.8293  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 1.5437  Validation loss = 5.8283  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 1.5435  Validation loss = 5.8281  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 1.5434  Validation loss = 5.8275  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 1.5432  Validation loss = 5.8272  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 1.5432  Validation loss = 5.8273  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 1.5430  Validation loss = 5.8270  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 1.5428  Validation loss = 5.8263  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 1.5427  Validation loss = 5.8262  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 1.5426  Validation loss = 5.8263  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 1.5424  Validation loss = 5.8255  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 1.5423  Validation loss = 5.8252  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 1.5421  Validation loss = 5.8246  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 1.5419  Validation loss = 5.8233  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 1.5418  Validation loss = 5.8235  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 1.5416  Validation loss = 5.8227  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 1.5415  Validation loss = 5.8228  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 1.5414  Validation loss = 5.8223  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 1.5412  Validation loss = 5.8221  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 1.5412  Validation loss = 5.8225  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 1.5411  Validation loss = 5.8226  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 1.5409  Validation loss = 5.8220  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 1.5407  Validation loss = 5.8210  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 1.5406  Validation loss = 5.8213  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 1.5405  Validation loss = 5.8207  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 1.5404  Validation loss = 5.8210  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 1.5403  Validation loss = 5.8207  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 1.5401  Validation loss = 5.8203  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 1.5399  Validation loss = 5.8199  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 1.5397  Validation loss = 5.8187  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 1.5396  Validation loss = 5.8183  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 1.5396  Validation loss = 5.8189  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 1.5394  Validation loss = 5.8188  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 1.5393  Validation loss = 5.8188  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 1.5393  Validation loss = 5.8192  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 1.5391  Validation loss = 5.8191  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 1.5390  Validation loss = 5.8184  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 1.5388  Validation loss = 5.8178  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 1.5387  Validation loss = 5.8178  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 1.5386  Validation loss = 5.8172  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 1.5384  Validation loss = 5.8161  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 1.5383  Validation loss = 5.8163  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 1.5382  Validation loss = 5.8162  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 1.5380  Validation loss = 5.8158  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 1.5378  Validation loss = 5.8149  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 1.5378  Validation loss = 5.8152  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 1.5377  Validation loss = 5.8151  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 1.5376  Validation loss = 5.8152  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 1.5375  Validation loss = 5.8144  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 1.5373  Validation loss = 5.8137  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 1.5372  Validation loss = 5.8132  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 1.5371  Validation loss = 5.8132  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 1.5369  Validation loss = 5.8124  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 1.5368  Validation loss = 5.8124  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 1.5366  Validation loss = 5.8120  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 1.5365  Validation loss = 5.8110  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 1.5363  Validation loss = 5.8106  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 1.5361  Validation loss = 5.8102  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 1.5360  Validation loss = 5.8099  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 1.5359  Validation loss = 5.8098  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 1.5358  Validation loss = 5.8092  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 1.5356  Validation loss = 5.8092  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 1.5355  Validation loss = 5.8086  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 1.5353  Validation loss = 5.8082  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 1.5352  Validation loss = 5.8076  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 1.5351  Validation loss = 5.8072  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 1.5349  Validation loss = 5.8067  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 1.5348  Validation loss = 5.8065  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 1.5346  Validation loss = 5.8056  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 1.5345  Validation loss = 5.8051  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 1.5345  Validation loss = 5.8057  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 1.5344  Validation loss = 5.8056  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 1.5343  Validation loss = 5.8062  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 1.5342  Validation loss = 5.8062  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 1.5341  Validation loss = 5.8061  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 1.5341  Validation loss = 5.8065  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 1.5339  Validation loss = 5.8063  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 1.5339  Validation loss = 5.8064  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 1.5337  Validation loss = 5.8062  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 1.5336  Validation loss = 5.8059  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 1.5335  Validation loss = 5.8059  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 1.5334  Validation loss = 5.8060  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 1.5333  Validation loss = 5.8064  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 1.5332  Validation loss = 5.8066  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 275  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.0858  Validation loss = 9.2937  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.0855  Validation loss = 9.2924  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.0851  Validation loss = 9.2906  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.0848  Validation loss = 9.2889  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.0846  Validation loss = 9.2875  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.0843  Validation loss = 9.2862  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.0840  Validation loss = 9.2844  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.0836  Validation loss = 9.2817  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.0832  Validation loss = 9.2800  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.0829  Validation loss = 9.2784  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.0826  Validation loss = 9.2776  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.0825  Validation loss = 9.2772  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.0822  Validation loss = 9.2764  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.0822  Validation loss = 9.2762  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.0820  Validation loss = 9.2756  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.0817  Validation loss = 9.2744  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.0815  Validation loss = 9.2729  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.0812  Validation loss = 9.2710  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.0808  Validation loss = 9.2693  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.0805  Validation loss = 9.2675  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.0802  Validation loss = 9.2661  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.0800  Validation loss = 9.2653  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.0797  Validation loss = 9.2638  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.0793  Validation loss = 9.2621  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.0791  Validation loss = 9.2614  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.0790  Validation loss = 9.2604  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.0788  Validation loss = 9.2597  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.0786  Validation loss = 9.2588  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.0785  Validation loss = 9.2584  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.0782  Validation loss = 9.2566  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.0778  Validation loss = 9.2546  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.0776  Validation loss = 9.2541  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.0774  Validation loss = 9.2530  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.0773  Validation loss = 9.2526  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.0772  Validation loss = 9.2523  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.0769  Validation loss = 9.2506  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.0766  Validation loss = 9.2493  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.0764  Validation loss = 9.2484  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.0760  Validation loss = 9.2462  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.0758  Validation loss = 9.2452  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.0756  Validation loss = 9.2442  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.0754  Validation loss = 9.2434  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.0753  Validation loss = 9.2430  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.0749  Validation loss = 9.2413  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.0746  Validation loss = 9.2399  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.0745  Validation loss = 9.2394  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.0742  Validation loss = 9.2383  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.0739  Validation loss = 9.2368  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.0736  Validation loss = 9.2346  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.0734  Validation loss = 9.2334  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.0730  Validation loss = 9.2319  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.0729  Validation loss = 9.2310  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.0728  Validation loss = 9.2302  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.0726  Validation loss = 9.2295  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.0724  Validation loss = 9.2289  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.0721  Validation loss = 9.2273  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.0719  Validation loss = 9.2265  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.0717  Validation loss = 9.2255  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.0715  Validation loss = 9.2242  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.0712  Validation loss = 9.2232  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.0710  Validation loss = 9.2222  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.0710  Validation loss = 9.2219  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.0708  Validation loss = 9.2213  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.0707  Validation loss = 9.2205  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.0704  Validation loss = 9.2187  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.0701  Validation loss = 9.2175  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.0700  Validation loss = 9.2171  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.0698  Validation loss = 9.2158  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.0696  Validation loss = 9.2148  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.0694  Validation loss = 9.2143  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.0689  Validation loss = 9.2119  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.0686  Validation loss = 9.2104  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.0683  Validation loss = 9.2097  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.0681  Validation loss = 9.2087  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.0680  Validation loss = 9.2080  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.0677  Validation loss = 9.2064  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.0675  Validation loss = 9.2058  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.0673  Validation loss = 9.2050  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.0670  Validation loss = 9.2038  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.0668  Validation loss = 9.2026  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.0664  Validation loss = 9.2009  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.0662  Validation loss = 9.1996  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.0659  Validation loss = 9.1984  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.0658  Validation loss = 9.1979  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.0656  Validation loss = 9.1972  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.0655  Validation loss = 9.1965  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.0652  Validation loss = 9.1957  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.0650  Validation loss = 9.1946  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.0646  Validation loss = 9.1929  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.0643  Validation loss = 9.1914  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.0640  Validation loss = 9.1900  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.0637  Validation loss = 9.1886  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.0635  Validation loss = 9.1872  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.0632  Validation loss = 9.1857  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.0629  Validation loss = 9.1836  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.0625  Validation loss = 9.1812  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.0620  Validation loss = 9.1782  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.0617  Validation loss = 9.1767  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.0617  Validation loss = 9.1765  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.0615  Validation loss = 9.1752  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.0612  Validation loss = 9.1736  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.0611  Validation loss = 9.1733  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.0608  Validation loss = 9.1719  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.0605  Validation loss = 9.1706  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.0603  Validation loss = 9.1694  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.0601  Validation loss = 9.1684  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.0598  Validation loss = 9.1671  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.0594  Validation loss = 9.1656  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.0591  Validation loss = 9.1641  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.0590  Validation loss = 9.1631  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.0589  Validation loss = 9.1627  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.0588  Validation loss = 9.1618  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.0584  Validation loss = 9.1603  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.0581  Validation loss = 9.1591  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.0578  Validation loss = 9.1574  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.0577  Validation loss = 9.1568  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.0576  Validation loss = 9.1563  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.0574  Validation loss = 9.1554  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.0571  Validation loss = 9.1539  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.0569  Validation loss = 9.1531  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.0567  Validation loss = 9.1518  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.0566  Validation loss = 9.1515  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.0563  Validation loss = 9.1502  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.0560  Validation loss = 9.1488  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.0557  Validation loss = 9.1468  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.0554  Validation loss = 9.1459  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.0551  Validation loss = 9.1441  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.0549  Validation loss = 9.1433  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.0546  Validation loss = 9.1413  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.0543  Validation loss = 9.1393  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.0541  Validation loss = 9.1383  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.0539  Validation loss = 9.1371  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.0536  Validation loss = 9.1355  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.0535  Validation loss = 9.1351  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.0532  Validation loss = 9.1336  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.0528  Validation loss = 9.1318  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.0526  Validation loss = 9.1301  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.0524  Validation loss = 9.1290  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.0522  Validation loss = 9.1281  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.0519  Validation loss = 9.1266  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.0518  Validation loss = 9.1261  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.0515  Validation loss = 9.1245  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.0513  Validation loss = 9.1234  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.0510  Validation loss = 9.1220  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.0506  Validation loss = 9.1203  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.0503  Validation loss = 9.1181  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.0499  Validation loss = 9.1162  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.0497  Validation loss = 9.1156  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.0495  Validation loss = 9.1145  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.0492  Validation loss = 9.1133  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.0490  Validation loss = 9.1119  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.0488  Validation loss = 9.1109  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.0487  Validation loss = 9.1105  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.0484  Validation loss = 9.1090  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.0483  Validation loss = 9.1082  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.0479  Validation loss = 9.1061  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.0475  Validation loss = 9.1045  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.0473  Validation loss = 9.1032  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.0470  Validation loss = 9.1011  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.0468  Validation loss = 9.0998  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.0465  Validation loss = 9.0989  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.0462  Validation loss = 9.0971  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.0460  Validation loss = 9.0956  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.0457  Validation loss = 9.0941  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.0455  Validation loss = 9.0932  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.0453  Validation loss = 9.0925  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.0452  Validation loss = 9.0916  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.0450  Validation loss = 9.0908  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.0448  Validation loss = 9.0903  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.0447  Validation loss = 9.0899  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.0446  Validation loss = 9.0891  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.0444  Validation loss = 9.0874  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.0443  Validation loss = 9.0872  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.0440  Validation loss = 9.0859  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.0438  Validation loss = 9.0848  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.0436  Validation loss = 9.0833  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.0433  Validation loss = 9.0822  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.0432  Validation loss = 9.0815  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.0430  Validation loss = 9.0810  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.0428  Validation loss = 9.0801  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.0427  Validation loss = 9.0792  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.0423  Validation loss = 9.0777  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.0421  Validation loss = 9.0767  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.0420  Validation loss = 9.0758  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.0418  Validation loss = 9.0747  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.0414  Validation loss = 9.0730  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.0413  Validation loss = 9.0723  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.0410  Validation loss = 9.0712  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.0409  Validation loss = 9.0702  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.0405  Validation loss = 9.0683  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.0403  Validation loss = 9.0674  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.0400  Validation loss = 9.0658  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.0399  Validation loss = 9.0651  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.0398  Validation loss = 9.0648  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.0396  Validation loss = 9.0639  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.0395  Validation loss = 9.0636  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.0394  Validation loss = 9.0630  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.0393  Validation loss = 9.0628  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.0392  Validation loss = 9.0622  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.0389  Validation loss = 9.0611  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.0388  Validation loss = 9.0608  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.0386  Validation loss = 9.0598  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.0383  Validation loss = 9.0579  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.0382  Validation loss = 9.0567  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.0379  Validation loss = 9.0552  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.0377  Validation loss = 9.0540  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.0375  Validation loss = 9.0534  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.0372  Validation loss = 9.0523  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.0370  Validation loss = 9.0513  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.0369  Validation loss = 9.0505  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.0367  Validation loss = 9.0497  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.0365  Validation loss = 9.0491  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.0363  Validation loss = 9.0484  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.0362  Validation loss = 9.0475  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.0361  Validation loss = 9.0472  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.0360  Validation loss = 9.0467  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.0356  Validation loss = 9.0453  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.0353  Validation loss = 9.0433  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.0352  Validation loss = 9.0423  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.0350  Validation loss = 9.0416  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.0348  Validation loss = 9.0405  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.0345  Validation loss = 9.0388  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.0343  Validation loss = 9.0382  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.0340  Validation loss = 9.0372  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.0338  Validation loss = 9.0361  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.0337  Validation loss = 9.0355  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.0334  Validation loss = 9.0342  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.0332  Validation loss = 9.0331  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.0331  Validation loss = 9.0326  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.0329  Validation loss = 9.0312  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.0327  Validation loss = 9.0306  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.0323  Validation loss = 9.0280  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.0321  Validation loss = 9.0271  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.0319  Validation loss = 9.0259  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.0316  Validation loss = 9.0245  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.0314  Validation loss = 9.0234  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.0312  Validation loss = 9.0224  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.0309  Validation loss = 9.0210  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.0308  Validation loss = 9.0201  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.0306  Validation loss = 9.0190  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.0303  Validation loss = 9.0177  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.0303  Validation loss = 9.0177  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.0302  Validation loss = 9.0173  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.0300  Validation loss = 9.0164  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.0298  Validation loss = 9.0154  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.0296  Validation loss = 9.0146  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.0294  Validation loss = 9.0136  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.0293  Validation loss = 9.0133  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.0291  Validation loss = 9.0123  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.0288  Validation loss = 9.0110  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.0285  Validation loss = 9.0093  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.0283  Validation loss = 9.0080  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.0281  Validation loss = 9.0070  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.0277  Validation loss = 9.0048  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.0275  Validation loss = 9.0036  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.0273  Validation loss = 9.0030  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.0271  Validation loss = 9.0022  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 2.0269  Validation loss = 9.0008  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 2.0267  Validation loss = 8.9999  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 2.0265  Validation loss = 8.9988  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 2.0263  Validation loss = 8.9979  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 2.0262  Validation loss = 8.9976  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 2.0261  Validation loss = 8.9971  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 2.0260  Validation loss = 8.9966  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 2.0258  Validation loss = 8.9960  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 2.0256  Validation loss = 8.9951  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 2.0254  Validation loss = 8.9939  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 2.0251  Validation loss = 8.9924  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 2.0249  Validation loss = 8.9920  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 2.0248  Validation loss = 8.9914  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 2.0247  Validation loss = 8.9912  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 2.0246  Validation loss = 8.9904  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 2.0244  Validation loss = 8.9896  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 2.0243  Validation loss = 8.9889  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 2.0240  Validation loss = 8.9877  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 2.0238  Validation loss = 8.9867  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 2.0236  Validation loss = 8.9858  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 2.0233  Validation loss = 8.9838  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 2.0231  Validation loss = 8.9834  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 2.0231  Validation loss = 8.9831  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 2.0229  Validation loss = 8.9819  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 2.0227  Validation loss = 8.9810  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 2.0225  Validation loss = 8.9802  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 2.0222  Validation loss = 8.9791  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 2.0220  Validation loss = 8.9776  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 2.0218  Validation loss = 8.9765  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 2.0217  Validation loss = 8.9763  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 2.0216  Validation loss = 8.9756  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 2.0214  Validation loss = 8.9754  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 2.0213  Validation loss = 8.9745  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 2.0210  Validation loss = 8.9736  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 2.0209  Validation loss = 8.9733  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 2.0207  Validation loss = 8.9719  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 2.0204  Validation loss = 8.9706  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 2.0203  Validation loss = 8.9701  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 2.0201  Validation loss = 8.9691  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 2.0198  Validation loss = 8.9678  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 2.0197  Validation loss = 8.9674  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 2.0194  Validation loss = 8.9661  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 2.0192  Validation loss = 8.9650  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 2.0190  Validation loss = 8.9641  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 2.0189  Validation loss = 8.9638  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 2.0188  Validation loss = 8.9634  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 2.0186  Validation loss = 8.9622  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 2.0184  Validation loss = 8.9615  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 2.0182  Validation loss = 8.9606  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 2.0179  Validation loss = 8.9589  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 2.0177  Validation loss = 8.9577  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 2.0175  Validation loss = 8.9569  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 2.0172  Validation loss = 8.9551  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 2.0170  Validation loss = 8.9540  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 2.0168  Validation loss = 8.9533  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 2.0166  Validation loss = 8.9521  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 2.0163  Validation loss = 8.9506  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 2.0162  Validation loss = 8.9504  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 2.0160  Validation loss = 8.9495  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 2.0159  Validation loss = 8.9489  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 2.0157  Validation loss = 8.9478  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 2.0155  Validation loss = 8.9471  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 2.0153  Validation loss = 8.9463  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 2.0150  Validation loss = 8.9451  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 2.0148  Validation loss = 8.9441  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 2.0147  Validation loss = 8.9435  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 2.0144  Validation loss = 8.9422  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 2.0141  Validation loss = 8.9405  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 2.0139  Validation loss = 8.9398  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 2.0138  Validation loss = 8.9392  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 2.0136  Validation loss = 8.9385  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 2.0134  Validation loss = 8.9375  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 2.0133  Validation loss = 8.9370  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 2.0131  Validation loss = 8.9360  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 2.0129  Validation loss = 8.9356  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 2.0127  Validation loss = 8.9345  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 2.0123  Validation loss = 8.9327  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 2.0122  Validation loss = 8.9321  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 2.0119  Validation loss = 8.9308  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 2.0117  Validation loss = 8.9299  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 2.0114  Validation loss = 8.9282  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 2.0113  Validation loss = 8.9276  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 2.0110  Validation loss = 8.9265  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 2.0107  Validation loss = 8.9246  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 2.0106  Validation loss = 8.9243  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 2.0105  Validation loss = 8.9239  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 2.0103  Validation loss = 8.9231  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 2.0100  Validation loss = 8.9218  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 2.0100  Validation loss = 8.9216  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 2.0097  Validation loss = 8.9205  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 2.0095  Validation loss = 8.9197  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 2.0094  Validation loss = 8.9193  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 2.0092  Validation loss = 8.9184  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 2.0090  Validation loss = 8.9175  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 2.0088  Validation loss = 8.9165  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 2.0086  Validation loss = 8.9157  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 2.0084  Validation loss = 8.9149  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 2.0082  Validation loss = 8.9139  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 2.0080  Validation loss = 8.9132  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 2.0079  Validation loss = 8.9130  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 2.0078  Validation loss = 8.9123  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 2.0076  Validation loss = 8.9118  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 2.0075  Validation loss = 8.9112  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 2.0073  Validation loss = 8.9103  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 2.0072  Validation loss = 8.9098  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 2.0070  Validation loss = 8.9091  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 2.0068  Validation loss = 8.9081  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 2.0065  Validation loss = 8.9068  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 2.0064  Validation loss = 8.9063  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 2.0063  Validation loss = 8.9058  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 2.0061  Validation loss = 8.9052  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 2.0059  Validation loss = 8.9043  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 2.0057  Validation loss = 8.9033  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 2.0056  Validation loss = 8.9028  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 2.0054  Validation loss = 8.9020  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 2.0051  Validation loss = 8.9010  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 2.0049  Validation loss = 8.9001  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 2.0048  Validation loss = 8.8992  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 2.0046  Validation loss = 8.8988  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 2.0046  Validation loss = 8.8992  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 2.0045  Validation loss = 8.8985  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 2.0042  Validation loss = 8.8970  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 2.0041  Validation loss = 8.8971  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 2.0040  Validation loss = 8.8965  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 2.0038  Validation loss = 8.8957  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 2.0037  Validation loss = 8.8953  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 2.0035  Validation loss = 8.8946  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 2.0035  Validation loss = 8.8944  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 2.0032  Validation loss = 8.8932  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 2.0030  Validation loss = 8.8920  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 2.0027  Validation loss = 8.8909  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 2.0026  Validation loss = 8.8906  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 2.0025  Validation loss = 8.8901  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 2.0024  Validation loss = 8.8897  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 2.0022  Validation loss = 8.8887  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 2.0020  Validation loss = 8.8880  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 2.0017  Validation loss = 8.8865  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 2.0015  Validation loss = 8.8857  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 2.0014  Validation loss = 8.8850  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 2.0012  Validation loss = 8.8840  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 2.0010  Validation loss = 8.8835  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 2.0008  Validation loss = 8.8824  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 2.0007  Validation loss = 8.8818  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 2.0006  Validation loss = 8.8813  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 2.0004  Validation loss = 8.8808  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 2.0003  Validation loss = 8.8802  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 2.0001  Validation loss = 8.8793  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 1.9999  Validation loss = 8.8783  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 1.9997  Validation loss = 8.8774  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 1.9995  Validation loss = 8.8768  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 1.9994  Validation loss = 8.8762  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 1.9992  Validation loss = 8.8751  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 1.9989  Validation loss = 8.8740  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 1.9986  Validation loss = 8.8726  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 1.9985  Validation loss = 8.8721  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 1.9983  Validation loss = 8.8712  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 1.9981  Validation loss = 8.8705  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 1.9979  Validation loss = 8.8692  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 1.9977  Validation loss = 8.8681  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 1.9974  Validation loss = 8.8670  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 1.9973  Validation loss = 8.8665  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 1.9971  Validation loss = 8.8658  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 1.9968  Validation loss = 8.8640  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 1.9967  Validation loss = 8.8638  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 1.9965  Validation loss = 8.8628  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 1.9963  Validation loss = 8.8621  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 1.9961  Validation loss = 8.8610  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 1.9960  Validation loss = 8.8606  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 1.9958  Validation loss = 8.8597  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 1.9956  Validation loss = 8.8589  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 1.9954  Validation loss = 8.8582  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 1.9954  Validation loss = 8.8585  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 1.9953  Validation loss = 8.8579  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 1.9952  Validation loss = 8.8578  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 1.9951  Validation loss = 8.8575  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 1.9949  Validation loss = 8.8565  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 1.9947  Validation loss = 8.8557  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 1.9945  Validation loss = 8.8549  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 1.9944  Validation loss = 8.8543  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 1.9942  Validation loss = 8.8534  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 1.9941  Validation loss = 8.8531  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 1.9938  Validation loss = 8.8520  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 1.9936  Validation loss = 8.8510  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 1.9934  Validation loss = 8.8500  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 1.9932  Validation loss = 8.8492  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 1.9931  Validation loss = 8.8488  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 1.9928  Validation loss = 8.8468  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 1.9926  Validation loss = 8.8460  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 1.9925  Validation loss = 8.8455  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 1.9922  Validation loss = 8.8444  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 1.9921  Validation loss = 8.8440  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 1.9919  Validation loss = 8.8430  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 1.9918  Validation loss = 8.8422  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 1.9915  Validation loss = 8.8410  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 1.9914  Validation loss = 8.8405  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 1.9911  Validation loss = 8.8392  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 1.9909  Validation loss = 8.8382  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 1.9906  Validation loss = 8.8363  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 1.9905  Validation loss = 8.8358  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 1.9903  Validation loss = 8.8351  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 1.9901  Validation loss = 8.8340  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 1.9899  Validation loss = 8.8330  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 1.9897  Validation loss = 8.8324  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 1.9896  Validation loss = 8.8321  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 1.9896  Validation loss = 8.8319  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 1.9894  Validation loss = 8.8313  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 1.9893  Validation loss = 8.8307  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 1.9890  Validation loss = 8.8295  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 1.9889  Validation loss = 8.8292  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 1.9887  Validation loss = 8.8282  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 1.9884  Validation loss = 8.8269  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 1.9883  Validation loss = 8.8263  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 1.9881  Validation loss = 8.8254  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 1.9879  Validation loss = 8.8247  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 1.9878  Validation loss = 8.8237  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 1.9876  Validation loss = 8.8233  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 1.9875  Validation loss = 8.8225  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 1.9873  Validation loss = 8.8219  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 1.9870  Validation loss = 8.8204  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 1.9868  Validation loss = 8.8199  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 1.9867  Validation loss = 8.8195  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 1.9866  Validation loss = 8.8192  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 1.9865  Validation loss = 8.8187  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 1.9863  Validation loss = 8.8181  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 1.9861  Validation loss = 8.8168  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 1.9859  Validation loss = 8.8159  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 1.9857  Validation loss = 8.8150  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 1.9854  Validation loss = 8.8137  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 1.9853  Validation loss = 8.8129  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 1.9851  Validation loss = 8.8120  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 1.9849  Validation loss = 8.8109  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 1.9847  Validation loss = 8.8104  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 1.9846  Validation loss = 8.8101  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 1.9845  Validation loss = 8.8097  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 1.9843  Validation loss = 8.8091  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 1.9842  Validation loss = 8.8088  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 1.9840  Validation loss = 8.8083  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 1.9839  Validation loss = 8.8074  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 1.9837  Validation loss = 8.8065  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 1.9835  Validation loss = 8.8058  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 1.9833  Validation loss = 8.8048  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 1.9832  Validation loss = 8.8046  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 1.9830  Validation loss = 8.8031  \n",
      "\n",
      "Fold: 9  Epoch: 501  Training loss = 1.9828  Validation loss = 8.8022  \n",
      "\n",
      "Fold: 9  Epoch: 502  Training loss = 1.9826  Validation loss = 8.8016  \n",
      "\n",
      "Fold: 9  Epoch: 503  Training loss = 1.9824  Validation loss = 8.8006  \n",
      "\n",
      "Fold: 9  Epoch: 504  Training loss = 1.9823  Validation loss = 8.8000  \n",
      "\n",
      "Fold: 9  Epoch: 505  Training loss = 1.9821  Validation loss = 8.7997  \n",
      "\n",
      "Fold: 9  Epoch: 506  Training loss = 1.9819  Validation loss = 8.7986  \n",
      "\n",
      "Fold: 9  Epoch: 507  Training loss = 1.9817  Validation loss = 8.7977  \n",
      "\n",
      "Fold: 9  Epoch: 508  Training loss = 1.9816  Validation loss = 8.7971  \n",
      "\n",
      "Fold: 9  Epoch: 509  Training loss = 1.9813  Validation loss = 8.7952  \n",
      "\n",
      "Fold: 9  Epoch: 510  Training loss = 1.9811  Validation loss = 8.7940  \n",
      "\n",
      "Fold: 9  Epoch: 511  Training loss = 1.9809  Validation loss = 8.7931  \n",
      "\n",
      "Fold: 9  Epoch: 512  Training loss = 1.9806  Validation loss = 8.7915  \n",
      "\n",
      "Fold: 9  Epoch: 513  Training loss = 1.9804  Validation loss = 8.7908  \n",
      "\n",
      "Fold: 9  Epoch: 514  Training loss = 1.9803  Validation loss = 8.7902  \n",
      "\n",
      "Fold: 9  Epoch: 515  Training loss = 1.9802  Validation loss = 8.7899  \n",
      "\n",
      "Fold: 9  Epoch: 516  Training loss = 1.9800  Validation loss = 8.7891  \n",
      "\n",
      "Fold: 9  Epoch: 517  Training loss = 1.9799  Validation loss = 8.7889  \n",
      "\n",
      "Fold: 9  Epoch: 518  Training loss = 1.9797  Validation loss = 8.7879  \n",
      "\n",
      "Fold: 9  Epoch: 519  Training loss = 1.9796  Validation loss = 8.7874  \n",
      "\n",
      "Fold: 9  Epoch: 520  Training loss = 1.9794  Validation loss = 8.7864  \n",
      "\n",
      "Fold: 9  Epoch: 521  Training loss = 1.9793  Validation loss = 8.7863  \n",
      "\n",
      "Fold: 9  Epoch: 522  Training loss = 1.9792  Validation loss = 8.7861  \n",
      "\n",
      "Fold: 9  Epoch: 523  Training loss = 1.9790  Validation loss = 8.7853  \n",
      "\n",
      "Fold: 9  Epoch: 524  Training loss = 1.9789  Validation loss = 8.7845  \n",
      "\n",
      "Fold: 9  Epoch: 525  Training loss = 1.9786  Validation loss = 8.7832  \n",
      "\n",
      "Fold: 9  Epoch: 526  Training loss = 1.9785  Validation loss = 8.7827  \n",
      "\n",
      "Fold: 9  Epoch: 527  Training loss = 1.9783  Validation loss = 8.7818  \n",
      "\n",
      "Fold: 9  Epoch: 528  Training loss = 1.9781  Validation loss = 8.7814  \n",
      "\n",
      "Fold: 9  Epoch: 529  Training loss = 1.9780  Validation loss = 8.7811  \n",
      "\n",
      "Fold: 9  Epoch: 530  Training loss = 1.9778  Validation loss = 8.7801  \n",
      "\n",
      "Fold: 9  Epoch: 531  Training loss = 1.9776  Validation loss = 8.7794  \n",
      "\n",
      "Fold: 9  Epoch: 532  Training loss = 1.9775  Validation loss = 8.7787  \n",
      "\n",
      "Fold: 9  Epoch: 533  Training loss = 1.9772  Validation loss = 8.7775  \n",
      "\n",
      "Fold: 9  Epoch: 534  Training loss = 1.9770  Validation loss = 8.7765  \n",
      "\n",
      "Fold: 9  Epoch: 535  Training loss = 1.9768  Validation loss = 8.7754  \n",
      "\n",
      "Fold: 9  Epoch: 536  Training loss = 1.9767  Validation loss = 8.7747  \n",
      "\n",
      "Fold: 9  Epoch: 537  Training loss = 1.9766  Validation loss = 8.7745  \n",
      "\n",
      "Fold: 9  Epoch: 538  Training loss = 1.9764  Validation loss = 8.7739  \n",
      "\n",
      "Fold: 9  Epoch: 539  Training loss = 1.9762  Validation loss = 8.7730  \n",
      "\n",
      "Fold: 9  Epoch: 540  Training loss = 1.9761  Validation loss = 8.7726  \n",
      "\n",
      "Fold: 9  Epoch: 541  Training loss = 1.9759  Validation loss = 8.7720  \n",
      "\n",
      "Fold: 9  Epoch: 542  Training loss = 1.9758  Validation loss = 8.7716  \n",
      "\n",
      "Fold: 9  Epoch: 543  Training loss = 1.9757  Validation loss = 8.7715  \n",
      "\n",
      "Fold: 9  Epoch: 544  Training loss = 1.9755  Validation loss = 8.7705  \n",
      "\n",
      "Fold: 9  Epoch: 545  Training loss = 1.9754  Validation loss = 8.7700  \n",
      "\n",
      "Fold: 9  Epoch: 546  Training loss = 1.9753  Validation loss = 8.7697  \n",
      "\n",
      "Fold: 9  Epoch: 547  Training loss = 1.9751  Validation loss = 8.7689  \n",
      "\n",
      "Fold: 9  Epoch: 548  Training loss = 1.9750  Validation loss = 8.7684  \n",
      "\n",
      "Fold: 9  Epoch: 549  Training loss = 1.9749  Validation loss = 8.7678  \n",
      "\n",
      "Fold: 9  Epoch: 550  Training loss = 1.9747  Validation loss = 8.7670  \n",
      "\n",
      "Fold: 9  Epoch: 551  Training loss = 1.9745  Validation loss = 8.7664  \n",
      "\n",
      "Fold: 9  Epoch: 552  Training loss = 1.9744  Validation loss = 8.7658  \n",
      "\n",
      "Fold: 9  Epoch: 553  Training loss = 1.9742  Validation loss = 8.7648  \n",
      "\n",
      "Fold: 9  Epoch: 554  Training loss = 1.9740  Validation loss = 8.7638  \n",
      "\n",
      "Fold: 9  Epoch: 555  Training loss = 1.9738  Validation loss = 8.7628  \n",
      "\n",
      "Fold: 9  Epoch: 556  Training loss = 1.9736  Validation loss = 8.7617  \n",
      "\n",
      "Fold: 9  Epoch: 557  Training loss = 1.9735  Validation loss = 8.7613  \n",
      "\n",
      "Fold: 9  Epoch: 558  Training loss = 1.9734  Validation loss = 8.7614  \n",
      "\n",
      "Fold: 9  Epoch: 559  Training loss = 1.9732  Validation loss = 8.7603  \n",
      "\n",
      "Fold: 9  Epoch: 560  Training loss = 1.9731  Validation loss = 8.7597  \n",
      "\n",
      "Fold: 9  Epoch: 561  Training loss = 1.9730  Validation loss = 8.7594  \n",
      "\n",
      "Fold: 9  Epoch: 562  Training loss = 1.9727  Validation loss = 8.7578  \n",
      "\n",
      "Fold: 9  Epoch: 563  Training loss = 1.9725  Validation loss = 8.7572  \n",
      "\n",
      "Fold: 9  Epoch: 564  Training loss = 1.9723  Validation loss = 8.7563  \n",
      "\n",
      "Fold: 9  Epoch: 565  Training loss = 1.9721  Validation loss = 8.7550  \n",
      "\n",
      "Fold: 9  Epoch: 566  Training loss = 1.9719  Validation loss = 8.7540  \n",
      "\n",
      "Fold: 9  Epoch: 567  Training loss = 1.9717  Validation loss = 8.7531  \n",
      "\n",
      "Fold: 9  Epoch: 568  Training loss = 1.9717  Validation loss = 8.7533  \n",
      "\n",
      "Fold: 9  Epoch: 569  Training loss = 1.9714  Validation loss = 8.7524  \n",
      "\n",
      "Fold: 9  Epoch: 570  Training loss = 1.9713  Validation loss = 8.7518  \n",
      "\n",
      "Fold: 9  Epoch: 571  Training loss = 1.9712  Validation loss = 8.7515  \n",
      "\n",
      "Fold: 9  Epoch: 572  Training loss = 1.9711  Validation loss = 8.7513  \n",
      "\n",
      "Fold: 9  Epoch: 573  Training loss = 1.9710  Validation loss = 8.7508  \n",
      "\n",
      "Fold: 9  Epoch: 574  Training loss = 1.9709  Validation loss = 8.7504  \n",
      "\n",
      "Fold: 9  Epoch: 575  Training loss = 1.9707  Validation loss = 8.7499  \n",
      "\n",
      "Fold: 9  Epoch: 576  Training loss = 1.9706  Validation loss = 8.7496  \n",
      "\n",
      "Fold: 9  Epoch: 577  Training loss = 1.9704  Validation loss = 8.7488  \n",
      "\n",
      "Fold: 9  Epoch: 578  Training loss = 1.9702  Validation loss = 8.7478  \n",
      "\n",
      "Fold: 9  Epoch: 579  Training loss = 1.9701  Validation loss = 8.7471  \n",
      "\n",
      "Fold: 9  Epoch: 580  Training loss = 1.9700  Validation loss = 8.7465  \n",
      "\n",
      "Fold: 9  Epoch: 581  Training loss = 1.9698  Validation loss = 8.7458  \n",
      "\n",
      "Fold: 9  Epoch: 582  Training loss = 1.9697  Validation loss = 8.7454  \n",
      "\n",
      "Fold: 9  Epoch: 583  Training loss = 1.9695  Validation loss = 8.7445  \n",
      "\n",
      "Fold: 9  Epoch: 584  Training loss = 1.9693  Validation loss = 8.7436  \n",
      "\n",
      "Fold: 9  Epoch: 585  Training loss = 1.9691  Validation loss = 8.7422  \n",
      "\n",
      "Fold: 9  Epoch: 586  Training loss = 1.9689  Validation loss = 8.7416  \n",
      "\n",
      "Fold: 9  Epoch: 587  Training loss = 1.9688  Validation loss = 8.7411  \n",
      "\n",
      "Fold: 9  Epoch: 588  Training loss = 1.9687  Validation loss = 8.7406  \n",
      "\n",
      "Fold: 9  Epoch: 589  Training loss = 1.9684  Validation loss = 8.7392  \n",
      "\n",
      "Fold: 9  Epoch: 590  Training loss = 1.9682  Validation loss = 8.7382  \n",
      "\n",
      "Fold: 9  Epoch: 591  Training loss = 1.9680  Validation loss = 8.7373  \n",
      "\n",
      "Fold: 9  Epoch: 592  Training loss = 1.9679  Validation loss = 8.7368  \n",
      "\n",
      "Fold: 9  Epoch: 593  Training loss = 1.9677  Validation loss = 8.7358  \n",
      "\n",
      "Fold: 9  Epoch: 594  Training loss = 1.9676  Validation loss = 8.7353  \n",
      "\n",
      "Fold: 9  Epoch: 595  Training loss = 1.9674  Validation loss = 8.7345  \n",
      "\n",
      "Fold: 9  Epoch: 596  Training loss = 1.9673  Validation loss = 8.7341  \n",
      "\n",
      "Fold: 9  Epoch: 597  Training loss = 1.9671  Validation loss = 8.7339  \n",
      "\n",
      "Fold: 9  Epoch: 598  Training loss = 1.9670  Validation loss = 8.7333  \n",
      "\n",
      "Fold: 9  Epoch: 599  Training loss = 1.9668  Validation loss = 8.7329  \n",
      "\n",
      "Fold: 9  Epoch: 600  Training loss = 1.9667  Validation loss = 8.7324  \n",
      "\n",
      "Fold: 9  Epoch: 601  Training loss = 1.9665  Validation loss = 8.7314  \n",
      "\n",
      "Fold: 9  Epoch: 602  Training loss = 1.9664  Validation loss = 8.7313  \n",
      "\n",
      "Fold: 9  Epoch: 603  Training loss = 1.9662  Validation loss = 8.7307  \n",
      "\n",
      "Fold: 9  Epoch: 604  Training loss = 1.9660  Validation loss = 8.7295  \n",
      "\n",
      "Fold: 9  Epoch: 605  Training loss = 1.9658  Validation loss = 8.7285  \n",
      "\n",
      "Fold: 9  Epoch: 606  Training loss = 1.9656  Validation loss = 8.7275  \n",
      "\n",
      "Fold: 9  Epoch: 607  Training loss = 1.9654  Validation loss = 8.7270  \n",
      "\n",
      "Fold: 9  Epoch: 608  Training loss = 1.9652  Validation loss = 8.7265  \n",
      "\n",
      "Fold: 9  Epoch: 609  Training loss = 1.9650  Validation loss = 8.7255  \n",
      "\n",
      "Fold: 9  Epoch: 610  Training loss = 1.9648  Validation loss = 8.7245  \n",
      "\n",
      "Fold: 9  Epoch: 611  Training loss = 1.9647  Validation loss = 8.7239  \n",
      "\n",
      "Fold: 9  Epoch: 612  Training loss = 1.9646  Validation loss = 8.7234  \n",
      "\n",
      "Fold: 9  Epoch: 613  Training loss = 1.9644  Validation loss = 8.7227  \n",
      "\n",
      "Fold: 9  Epoch: 614  Training loss = 1.9642  Validation loss = 8.7218  \n",
      "\n",
      "Fold: 9  Epoch: 615  Training loss = 1.9642  Validation loss = 8.7219  \n",
      "\n",
      "Fold: 9  Epoch: 616  Training loss = 1.9640  Validation loss = 8.7212  \n",
      "\n",
      "Fold: 9  Epoch: 617  Training loss = 1.9638  Validation loss = 8.7209  \n",
      "\n",
      "Fold: 9  Epoch: 618  Training loss = 1.9637  Validation loss = 8.7204  \n",
      "\n",
      "Fold: 9  Epoch: 619  Training loss = 1.9636  Validation loss = 8.7199  \n",
      "\n",
      "Fold: 9  Epoch: 620  Training loss = 1.9635  Validation loss = 8.7192  \n",
      "\n",
      "Fold: 9  Epoch: 621  Training loss = 1.9633  Validation loss = 8.7186  \n",
      "\n",
      "Fold: 9  Epoch: 622  Training loss = 1.9631  Validation loss = 8.7178  \n",
      "\n",
      "Fold: 9  Epoch: 623  Training loss = 1.9630  Validation loss = 8.7173  \n",
      "\n",
      "Fold: 9  Epoch: 624  Training loss = 1.9628  Validation loss = 8.7164  \n",
      "\n",
      "Fold: 9  Epoch: 625  Training loss = 1.9627  Validation loss = 8.7161  \n",
      "\n",
      "Fold: 9  Epoch: 626  Training loss = 1.9626  Validation loss = 8.7156  \n",
      "\n",
      "Fold: 9  Epoch: 627  Training loss = 1.9623  Validation loss = 8.7140  \n",
      "\n",
      "Fold: 9  Epoch: 628  Training loss = 1.9622  Validation loss = 8.7135  \n",
      "\n",
      "Fold: 9  Epoch: 629  Training loss = 1.9620  Validation loss = 8.7123  \n",
      "\n",
      "Fold: 9  Epoch: 630  Training loss = 1.9618  Validation loss = 8.7111  \n",
      "\n",
      "Fold: 9  Epoch: 631  Training loss = 1.9616  Validation loss = 8.7106  \n",
      "\n",
      "Fold: 9  Epoch: 632  Training loss = 1.9615  Validation loss = 8.7100  \n",
      "\n",
      "Fold: 9  Epoch: 633  Training loss = 1.9613  Validation loss = 8.7091  \n",
      "\n",
      "Fold: 9  Epoch: 634  Training loss = 1.9612  Validation loss = 8.7088  \n",
      "\n",
      "Fold: 9  Epoch: 635  Training loss = 1.9610  Validation loss = 8.7081  \n",
      "\n",
      "Fold: 9  Epoch: 636  Training loss = 1.9609  Validation loss = 8.7073  \n",
      "\n",
      "Fold: 9  Epoch: 637  Training loss = 1.9608  Validation loss = 8.7071  \n",
      "\n",
      "Fold: 9  Epoch: 638  Training loss = 1.9606  Validation loss = 8.7064  \n",
      "\n",
      "Fold: 9  Epoch: 639  Training loss = 1.9605  Validation loss = 8.7061  \n",
      "\n",
      "Fold: 9  Epoch: 640  Training loss = 1.9603  Validation loss = 8.7059  \n",
      "\n",
      "Fold: 9  Epoch: 641  Training loss = 1.9602  Validation loss = 8.7055  \n",
      "\n",
      "Fold: 9  Epoch: 642  Training loss = 1.9601  Validation loss = 8.7048  \n",
      "\n",
      "Fold: 9  Epoch: 643  Training loss = 1.9599  Validation loss = 8.7040  \n",
      "\n",
      "Fold: 9  Epoch: 644  Training loss = 1.9597  Validation loss = 8.7029  \n",
      "\n",
      "Fold: 9  Epoch: 645  Training loss = 1.9595  Validation loss = 8.7021  \n",
      "\n",
      "Fold: 9  Epoch: 646  Training loss = 1.9593  Validation loss = 8.7014  \n",
      "\n",
      "Fold: 9  Epoch: 647  Training loss = 1.9592  Validation loss = 8.7008  \n",
      "\n",
      "Fold: 9  Epoch: 648  Training loss = 1.9591  Validation loss = 8.7005  \n",
      "\n",
      "Fold: 9  Epoch: 649  Training loss = 1.9590  Validation loss = 8.7001  \n",
      "\n",
      "Fold: 9  Epoch: 650  Training loss = 1.9589  Validation loss = 8.6999  \n",
      "\n",
      "Fold: 9  Epoch: 651  Training loss = 1.9587  Validation loss = 8.6993  \n",
      "\n",
      "Fold: 9  Epoch: 652  Training loss = 1.9586  Validation loss = 8.6991  \n",
      "\n",
      "Fold: 9  Epoch: 653  Training loss = 1.9585  Validation loss = 8.6984  \n",
      "\n",
      "Fold: 9  Epoch: 654  Training loss = 1.9583  Validation loss = 8.6978  \n",
      "\n",
      "Fold: 9  Epoch: 655  Training loss = 1.9582  Validation loss = 8.6973  \n",
      "\n",
      "Fold: 9  Epoch: 656  Training loss = 1.9579  Validation loss = 8.6952  \n",
      "\n",
      "Fold: 9  Epoch: 657  Training loss = 1.9577  Validation loss = 8.6945  \n",
      "\n",
      "Fold: 9  Epoch: 658  Training loss = 1.9576  Validation loss = 8.6940  \n",
      "\n",
      "Fold: 9  Epoch: 659  Training loss = 1.9574  Validation loss = 8.6936  \n",
      "\n",
      "Fold: 9  Epoch: 660  Training loss = 1.9573  Validation loss = 8.6931  \n",
      "\n",
      "Fold: 9  Epoch: 661  Training loss = 1.9572  Validation loss = 8.6929  \n",
      "\n",
      "Fold: 9  Epoch: 662  Training loss = 1.9570  Validation loss = 8.6917  \n",
      "\n",
      "Fold: 9  Epoch: 663  Training loss = 1.9568  Validation loss = 8.6907  \n",
      "\n",
      "Fold: 9  Epoch: 664  Training loss = 1.9566  Validation loss = 8.6898  \n",
      "\n",
      "Fold: 9  Epoch: 665  Training loss = 1.9565  Validation loss = 8.6890  \n",
      "\n",
      "Fold: 9  Epoch: 666  Training loss = 1.9563  Validation loss = 8.6885  \n",
      "\n",
      "Fold: 9  Epoch: 667  Training loss = 1.9562  Validation loss = 8.6877  \n",
      "\n",
      "Fold: 9  Epoch: 668  Training loss = 1.9560  Validation loss = 8.6869  \n",
      "\n",
      "Fold: 9  Epoch: 669  Training loss = 1.9558  Validation loss = 8.6858  \n",
      "\n",
      "Fold: 9  Epoch: 670  Training loss = 1.9557  Validation loss = 8.6855  \n",
      "\n",
      "Fold: 9  Epoch: 671  Training loss = 1.9555  Validation loss = 8.6849  \n",
      "\n",
      "Fold: 9  Epoch: 672  Training loss = 1.9553  Validation loss = 8.6838  \n",
      "\n",
      "Fold: 9  Epoch: 673  Training loss = 1.9552  Validation loss = 8.6837  \n",
      "\n",
      "Fold: 9  Epoch: 674  Training loss = 1.9550  Validation loss = 8.6833  \n",
      "\n",
      "Fold: 9  Epoch: 675  Training loss = 1.9549  Validation loss = 8.6827  \n",
      "\n",
      "Fold: 9  Epoch: 676  Training loss = 1.9547  Validation loss = 8.6819  \n",
      "\n",
      "Fold: 9  Epoch: 677  Training loss = 1.9546  Validation loss = 8.6814  \n",
      "\n",
      "Fold: 9  Epoch: 678  Training loss = 1.9545  Validation loss = 8.6810  \n",
      "\n",
      "Fold: 9  Epoch: 679  Training loss = 1.9543  Validation loss = 8.6800  \n",
      "\n",
      "Fold: 9  Epoch: 680  Training loss = 1.9542  Validation loss = 8.6798  \n",
      "\n",
      "Fold: 9  Epoch: 681  Training loss = 1.9541  Validation loss = 8.6798  \n",
      "\n",
      "Fold: 9  Epoch: 682  Training loss = 1.9539  Validation loss = 8.6790  \n",
      "\n",
      "Fold: 9  Epoch: 683  Training loss = 1.9537  Validation loss = 8.6776  \n",
      "\n",
      "Fold: 9  Epoch: 684  Training loss = 1.9535  Validation loss = 8.6765  \n",
      "\n",
      "Fold: 9  Epoch: 685  Training loss = 1.9533  Validation loss = 8.6758  \n",
      "\n",
      "Fold: 9  Epoch: 686  Training loss = 1.9531  Validation loss = 8.6752  \n",
      "\n",
      "Fold: 9  Epoch: 687  Training loss = 1.9529  Validation loss = 8.6744  \n",
      "\n",
      "Fold: 9  Epoch: 688  Training loss = 1.9528  Validation loss = 8.6742  \n",
      "\n",
      "Fold: 9  Epoch: 689  Training loss = 1.9527  Validation loss = 8.6737  \n",
      "\n",
      "Fold: 9  Epoch: 690  Training loss = 1.9525  Validation loss = 8.6729  \n",
      "\n",
      "Fold: 9  Epoch: 691  Training loss = 1.9522  Validation loss = 8.6712  \n",
      "\n",
      "Fold: 9  Epoch: 692  Training loss = 1.9521  Validation loss = 8.6704  \n",
      "\n",
      "Fold: 9  Epoch: 693  Training loss = 1.9520  Validation loss = 8.6703  \n",
      "\n",
      "Fold: 9  Epoch: 694  Training loss = 1.9518  Validation loss = 8.6697  \n",
      "\n",
      "Fold: 9  Epoch: 695  Training loss = 1.9518  Validation loss = 8.6699  \n",
      "\n",
      "Fold: 9  Epoch: 696  Training loss = 1.9516  Validation loss = 8.6695  \n",
      "\n",
      "Fold: 9  Epoch: 697  Training loss = 1.9514  Validation loss = 8.6687  \n",
      "\n",
      "Fold: 9  Epoch: 698  Training loss = 1.9513  Validation loss = 8.6681  \n",
      "\n",
      "Fold: 9  Epoch: 699  Training loss = 1.9512  Validation loss = 8.6678  \n",
      "\n",
      "Fold: 9  Epoch: 700  Training loss = 1.9511  Validation loss = 8.6678  \n",
      "\n",
      "Fold: 9  Epoch: 701  Training loss = 1.9510  Validation loss = 8.6675  \n",
      "\n",
      "Fold: 9  Epoch: 702  Training loss = 1.9508  Validation loss = 8.6671  \n",
      "\n",
      "Fold: 9  Epoch: 703  Training loss = 1.9507  Validation loss = 8.6665  \n",
      "\n",
      "Fold: 9  Epoch: 704  Training loss = 1.9506  Validation loss = 8.6662  \n",
      "\n",
      "Fold: 9  Epoch: 705  Training loss = 1.9504  Validation loss = 8.6654  \n",
      "\n",
      "Fold: 9  Epoch: 706  Training loss = 1.9502  Validation loss = 8.6644  \n",
      "\n",
      "Fold: 9  Epoch: 707  Training loss = 1.9501  Validation loss = 8.6640  \n",
      "\n",
      "Fold: 9  Epoch: 708  Training loss = 1.9499  Validation loss = 8.6631  \n",
      "\n",
      "Fold: 9  Epoch: 709  Training loss = 1.9497  Validation loss = 8.6624  \n",
      "\n",
      "Fold: 9  Epoch: 710  Training loss = 1.9496  Validation loss = 8.6624  \n",
      "\n",
      "Fold: 9  Epoch: 711  Training loss = 1.9495  Validation loss = 8.6620  \n",
      "\n",
      "Fold: 9  Epoch: 712  Training loss = 1.9494  Validation loss = 8.6616  \n",
      "\n",
      "Fold: 9  Epoch: 713  Training loss = 1.9492  Validation loss = 8.6611  \n",
      "\n",
      "Fold: 9  Epoch: 714  Training loss = 1.9490  Validation loss = 8.6596  \n",
      "\n",
      "Fold: 9  Epoch: 715  Training loss = 1.9489  Validation loss = 8.6594  \n",
      "\n",
      "Fold: 9  Epoch: 716  Training loss = 1.9487  Validation loss = 8.6589  \n",
      "\n",
      "Fold: 9  Epoch: 717  Training loss = 1.9485  Validation loss = 8.6578  \n",
      "\n",
      "Fold: 9  Epoch: 718  Training loss = 1.9483  Validation loss = 8.6569  \n",
      "\n",
      "Fold: 9  Epoch: 719  Training loss = 1.9483  Validation loss = 8.6569  \n",
      "\n",
      "Fold: 9  Epoch: 720  Training loss = 1.9481  Validation loss = 8.6566  \n",
      "\n",
      "Fold: 9  Epoch: 721  Training loss = 1.9480  Validation loss = 8.6562  \n",
      "\n",
      "Fold: 9  Epoch: 722  Training loss = 1.9479  Validation loss = 8.6555  \n",
      "\n",
      "Fold: 9  Epoch: 723  Training loss = 1.9477  Validation loss = 8.6547  \n",
      "\n",
      "Fold: 9  Epoch: 724  Training loss = 1.9475  Validation loss = 8.6539  \n",
      "\n",
      "Fold: 9  Epoch: 725  Training loss = 1.9474  Validation loss = 8.6537  \n",
      "\n",
      "Fold: 9  Epoch: 726  Training loss = 1.9472  Validation loss = 8.6530  \n",
      "\n",
      "Fold: 9  Epoch: 727  Training loss = 1.9471  Validation loss = 8.6525  \n",
      "\n",
      "Fold: 9  Epoch: 728  Training loss = 1.9469  Validation loss = 8.6522  \n",
      "\n",
      "Fold: 9  Epoch: 729  Training loss = 1.9468  Validation loss = 8.6516  \n",
      "\n",
      "Fold: 9  Epoch: 730  Training loss = 1.9467  Validation loss = 8.6513  \n",
      "\n",
      "Fold: 9  Epoch: 731  Training loss = 1.9465  Validation loss = 8.6510  \n",
      "\n",
      "Fold: 9  Epoch: 732  Training loss = 1.9463  Validation loss = 8.6499  \n",
      "\n",
      "Fold: 9  Epoch: 733  Training loss = 1.9462  Validation loss = 8.6497  \n",
      "\n",
      "Fold: 9  Epoch: 734  Training loss = 1.9460  Validation loss = 8.6487  \n",
      "\n",
      "Fold: 9  Epoch: 735  Training loss = 1.9459  Validation loss = 8.6482  \n",
      "\n",
      "Fold: 9  Epoch: 736  Training loss = 1.9457  Validation loss = 8.6474  \n",
      "\n",
      "Fold: 9  Epoch: 737  Training loss = 1.9455  Validation loss = 8.6459  \n",
      "\n",
      "Fold: 9  Epoch: 738  Training loss = 1.9453  Validation loss = 8.6450  \n",
      "\n",
      "Fold: 9  Epoch: 739  Training loss = 1.9451  Validation loss = 8.6442  \n",
      "\n",
      "Fold: 9  Epoch: 740  Training loss = 1.9450  Validation loss = 8.6438  \n",
      "\n",
      "Fold: 9  Epoch: 741  Training loss = 1.9448  Validation loss = 8.6433  \n",
      "\n",
      "Fold: 9  Epoch: 742  Training loss = 1.9447  Validation loss = 8.6425  \n",
      "\n",
      "Fold: 9  Epoch: 743  Training loss = 1.9446  Validation loss = 8.6426  \n",
      "\n",
      "Fold: 9  Epoch: 744  Training loss = 1.9445  Validation loss = 8.6423  \n",
      "\n",
      "Fold: 9  Epoch: 745  Training loss = 1.9444  Validation loss = 8.6420  \n",
      "\n",
      "Fold: 9  Epoch: 746  Training loss = 1.9442  Validation loss = 8.6408  \n",
      "\n",
      "Fold: 9  Epoch: 747  Training loss = 1.9439  Validation loss = 8.6398  \n",
      "\n",
      "Fold: 9  Epoch: 748  Training loss = 1.9437  Validation loss = 8.6384  \n",
      "\n",
      "Fold: 9  Epoch: 749  Training loss = 1.9435  Validation loss = 8.6379  \n",
      "\n",
      "Fold: 9  Epoch: 750  Training loss = 1.9434  Validation loss = 8.6372  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 750  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.8541  Validation loss = 4.2174  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.8532  Validation loss = 4.2160  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.8523  Validation loss = 4.2146  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.8517  Validation loss = 4.2135  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.8507  Validation loss = 4.2118  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.8493  Validation loss = 4.2097  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.8485  Validation loss = 4.2088  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.8481  Validation loss = 4.2080  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.8477  Validation loss = 4.2077  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.8467  Validation loss = 4.2059  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.8458  Validation loss = 4.2043  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.8447  Validation loss = 4.2023  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.8437  Validation loss = 4.2010  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.8434  Validation loss = 4.2006  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 2.8422  Validation loss = 4.1982  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.8411  Validation loss = 4.1967  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 2.8404  Validation loss = 4.1955  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 2.8394  Validation loss = 4.1933  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 2.8385  Validation loss = 4.1915  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.8380  Validation loss = 4.1906  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 2.8375  Validation loss = 4.1895  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 2.8366  Validation loss = 4.1878  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 2.8361  Validation loss = 4.1870  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 2.8355  Validation loss = 4.1858  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 2.8346  Validation loss = 4.1840  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 2.8340  Validation loss = 4.1828  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 2.8333  Validation loss = 4.1818  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 2.8326  Validation loss = 4.1800  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 2.8320  Validation loss = 4.1789  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 2.8317  Validation loss = 4.1784  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 2.8307  Validation loss = 4.1766  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 2.8300  Validation loss = 4.1749  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 2.8293  Validation loss = 4.1734  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 2.8286  Validation loss = 4.1717  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 2.8282  Validation loss = 4.1714  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 2.8280  Validation loss = 4.1710  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 2.8272  Validation loss = 4.1690  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 2.8264  Validation loss = 4.1676  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 2.8257  Validation loss = 4.1662  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 2.8251  Validation loss = 4.1649  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 2.8246  Validation loss = 4.1641  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 2.8241  Validation loss = 4.1630  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 2.8237  Validation loss = 4.1623  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 2.8229  Validation loss = 4.1606  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 2.8225  Validation loss = 4.1599  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 2.8217  Validation loss = 4.1582  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 2.8213  Validation loss = 4.1573  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 2.8204  Validation loss = 4.1553  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 2.8199  Validation loss = 4.1539  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 2.8192  Validation loss = 4.1524  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 2.8185  Validation loss = 4.1510  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 2.8180  Validation loss = 4.1498  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 2.8174  Validation loss = 4.1483  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 2.8169  Validation loss = 4.1472  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 2.8166  Validation loss = 4.1467  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 2.8161  Validation loss = 4.1456  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 2.8154  Validation loss = 4.1440  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 2.8149  Validation loss = 4.1427  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 2.8142  Validation loss = 4.1412  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 2.8133  Validation loss = 4.1388  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 2.8127  Validation loss = 4.1374  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 2.8123  Validation loss = 4.1365  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 2.8118  Validation loss = 4.1354  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 2.8113  Validation loss = 4.1344  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 2.8109  Validation loss = 4.1334  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 2.8103  Validation loss = 4.1323  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 2.8094  Validation loss = 4.1304  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 2.8087  Validation loss = 4.1289  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 2.8083  Validation loss = 4.1280  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 2.8077  Validation loss = 4.1265  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 2.8069  Validation loss = 4.1241  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 2.8066  Validation loss = 4.1234  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 2.8060  Validation loss = 4.1222  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 2.8057  Validation loss = 4.1218  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 2.8052  Validation loss = 4.1207  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 2.8046  Validation loss = 4.1187  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 2.8023  Validation loss = 4.1061  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 2.7764  Validation loss = 3.8894  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 2.7761  Validation loss = 3.8888  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 2.7754  Validation loss = 3.8875  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 2.7752  Validation loss = 3.8871  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 2.7745  Validation loss = 3.8855  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 2.7741  Validation loss = 3.8847  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 2.7736  Validation loss = 3.8838  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 2.7730  Validation loss = 3.8824  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 2.7725  Validation loss = 3.8810  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 2.7718  Validation loss = 3.8796  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 2.7713  Validation loss = 3.8784  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 2.7707  Validation loss = 3.8770  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 2.7704  Validation loss = 3.8766  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 2.7697  Validation loss = 3.8749  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 2.7691  Validation loss = 3.8734  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 2.7686  Validation loss = 3.8724  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 2.7679  Validation loss = 3.8709  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 2.7673  Validation loss = 3.8696  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 2.7669  Validation loss = 3.8688  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 2.7666  Validation loss = 3.8683  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 2.7662  Validation loss = 3.8674  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 2.7659  Validation loss = 3.8667  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 2.7652  Validation loss = 3.8652  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 2.7647  Validation loss = 3.8642  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 2.7640  Validation loss = 3.8623  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 2.7634  Validation loss = 3.8611  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 2.7629  Validation loss = 3.8600  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 2.7625  Validation loss = 3.8590  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 2.7619  Validation loss = 3.8577  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 2.7615  Validation loss = 3.8566  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 2.7610  Validation loss = 3.8555  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 2.7607  Validation loss = 3.8552  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 2.7604  Validation loss = 3.8546  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 2.7602  Validation loss = 3.8543  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 2.7597  Validation loss = 3.8530  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 2.7591  Validation loss = 3.8518  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 2.7585  Validation loss = 3.8502  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 2.7577  Validation loss = 3.8479  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 2.7571  Validation loss = 3.8466  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 2.7563  Validation loss = 3.8448  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 2.7556  Validation loss = 3.8427  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 2.7552  Validation loss = 3.8419  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 2.7545  Validation loss = 3.8403  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 2.7539  Validation loss = 3.8386  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 2.7533  Validation loss = 3.8375  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 2.7530  Validation loss = 3.8370  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 2.7525  Validation loss = 3.8358  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 2.7520  Validation loss = 3.8345  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 2.7516  Validation loss = 3.8334  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 2.7510  Validation loss = 3.8319  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 2.7504  Validation loss = 3.8305  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 2.7498  Validation loss = 3.8290  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 2.7493  Validation loss = 3.8278  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 2.7490  Validation loss = 3.8272  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 2.7484  Validation loss = 3.8257  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 2.7479  Validation loss = 3.8241  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 2.7474  Validation loss = 3.8229  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 2.7469  Validation loss = 3.8218  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 2.7466  Validation loss = 3.8213  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 2.7462  Validation loss = 3.8203  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 2.7458  Validation loss = 3.8195  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 2.7452  Validation loss = 3.8180  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 2.7447  Validation loss = 3.8166  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 2.7440  Validation loss = 3.8152  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 2.7433  Validation loss = 3.8135  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 2.7426  Validation loss = 3.8117  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 2.7421  Validation loss = 3.8104  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 2.7415  Validation loss = 3.8089  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 2.7409  Validation loss = 3.8073  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 2.7406  Validation loss = 3.8069  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 2.7400  Validation loss = 3.8053  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 2.7395  Validation loss = 3.8041  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 2.7388  Validation loss = 3.8025  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 2.7384  Validation loss = 3.8016  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 2.7382  Validation loss = 3.8013  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 2.7377  Validation loss = 3.8001  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 2.7370  Validation loss = 3.7982  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 2.7366  Validation loss = 3.7972  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 2.7361  Validation loss = 3.7959  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 2.7355  Validation loss = 3.7947  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 2.7352  Validation loss = 3.7938  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 2.7347  Validation loss = 3.7926  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 2.7340  Validation loss = 3.7910  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 2.7336  Validation loss = 3.7898  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 2.7333  Validation loss = 3.7893  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 2.7330  Validation loss = 3.7885  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 2.7327  Validation loss = 3.7880  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 2.7320  Validation loss = 3.7861  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 2.7316  Validation loss = 3.7851  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 2.7312  Validation loss = 3.7843  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 2.7308  Validation loss = 3.7832  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 2.7301  Validation loss = 3.7812  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 2.7297  Validation loss = 3.7801  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 2.7291  Validation loss = 3.7786  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 2.7287  Validation loss = 3.7778  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 2.7284  Validation loss = 3.7771  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 2.7282  Validation loss = 3.7771  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 2.7278  Validation loss = 3.7762  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 2.7274  Validation loss = 3.7750  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 2.7270  Validation loss = 3.7743  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 2.7266  Validation loss = 3.7731  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 2.7261  Validation loss = 3.7718  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 2.7254  Validation loss = 3.7700  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 2.7250  Validation loss = 3.7691  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 2.7244  Validation loss = 3.7674  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 2.7240  Validation loss = 3.7663  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 2.7234  Validation loss = 3.7647  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 2.7229  Validation loss = 3.7637  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 2.7225  Validation loss = 3.7626  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 2.7221  Validation loss = 3.7612  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 2.7217  Validation loss = 3.7605  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 2.7213  Validation loss = 3.7596  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 2.7209  Validation loss = 3.7585  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 2.7205  Validation loss = 3.7577  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 2.7200  Validation loss = 3.7565  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 2.7196  Validation loss = 3.7555  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 2.7192  Validation loss = 3.7546  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 2.7188  Validation loss = 3.7536  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 2.7181  Validation loss = 3.7515  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 2.7177  Validation loss = 3.7506  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 2.7173  Validation loss = 3.7496  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 2.7169  Validation loss = 3.7488  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 2.7166  Validation loss = 3.7483  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 2.7162  Validation loss = 3.7473  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 2.7161  Validation loss = 3.7471  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 2.7157  Validation loss = 3.7463  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 2.7153  Validation loss = 3.7450  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 2.7149  Validation loss = 3.7446  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 2.7142  Validation loss = 3.7423  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 2.7136  Validation loss = 3.7408  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 2.7132  Validation loss = 3.7399  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 2.7127  Validation loss = 3.7383  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 2.7122  Validation loss = 3.7371  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 2.7120  Validation loss = 3.7367  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 2.7116  Validation loss = 3.7355  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 2.7112  Validation loss = 3.7346  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 2.7109  Validation loss = 3.7339  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 2.7104  Validation loss = 3.7323  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 2.7101  Validation loss = 3.7316  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 2.7097  Validation loss = 3.7302  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 2.7095  Validation loss = 3.7299  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 2.7090  Validation loss = 3.7287  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 2.7087  Validation loss = 3.7278  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 2.7083  Validation loss = 3.7267  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 2.7079  Validation loss = 3.7249  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 2.7075  Validation loss = 3.7234  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 2.7072  Validation loss = 3.7220  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 2.7068  Validation loss = 3.7210  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 2.7064  Validation loss = 3.7188  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 2.7058  Validation loss = 3.7176  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 2.7052  Validation loss = 3.7161  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 2.7048  Validation loss = 3.7148  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 2.7040  Validation loss = 3.7124  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 2.7036  Validation loss = 3.7112  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 2.7030  Validation loss = 3.7089  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 2.7025  Validation loss = 3.7070  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 2.7019  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 2.7015  Validation loss = 3.7047  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 2.7012  Validation loss = 3.7032  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 2.7008  Validation loss = 3.7028  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 2.7002  Validation loss = 3.7004  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 2.7000  Validation loss = 3.6990  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 2.6995  Validation loss = 3.6968  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 2.6989  Validation loss = 3.6945  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 2.6986  Validation loss = 3.6939  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 2.6979  Validation loss = 3.6906  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 2.6976  Validation loss = 3.6897  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 2.6972  Validation loss = 3.6882  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 2.6967  Validation loss = 3.6894  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 2.6964  Validation loss = 3.6902  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 2.6960  Validation loss = 3.6882  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 2.6958  Validation loss = 3.6890  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 2.6953  Validation loss = 3.6852  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 2.6949  Validation loss = 3.6828  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 2.6946  Validation loss = 3.6834  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 2.6943  Validation loss = 3.6841  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 2.6938  Validation loss = 3.6828  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 2.6933  Validation loss = 3.6812  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 2.6931  Validation loss = 3.6817  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 2.6928  Validation loss = 3.6818  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 2.6923  Validation loss = 3.6796  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 2.6918  Validation loss = 3.6769  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 2.6914  Validation loss = 3.6719  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 2.6911  Validation loss = 3.6738  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 2.6906  Validation loss = 3.6730  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 2.6902  Validation loss = 3.6734  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 2.6900  Validation loss = 3.6733  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 2.6895  Validation loss = 3.6731  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 2.6890  Validation loss = 3.6726  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 2.6886  Validation loss = 3.6715  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 2.6881  Validation loss = 3.6701  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 2.6878  Validation loss = 3.6708  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 2.6873  Validation loss = 3.6697  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 2.6870  Validation loss = 3.6687  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 2.6864  Validation loss = 3.6646  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 2.6862  Validation loss = 3.6648  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 2.6859  Validation loss = 3.6646  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 2.6853  Validation loss = 3.6623  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 2.6847  Validation loss = 3.6604  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 2.6842  Validation loss = 3.6585  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 2.6839  Validation loss = 3.6579  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 2.6835  Validation loss = 3.6555  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 2.6831  Validation loss = 3.6538  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 2.6827  Validation loss = 3.6531  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 2.6825  Validation loss = 3.6511  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 2.6822  Validation loss = 3.6525  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 2.6820  Validation loss = 3.6511  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 2.6817  Validation loss = 3.6482  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 2.6814  Validation loss = 3.6500  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 2.6810  Validation loss = 3.6489  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 2.6806  Validation loss = 3.6441  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 2.6801  Validation loss = 3.6421  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 2.6795  Validation loss = 3.6398  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 2.6791  Validation loss = 3.6436  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 2.6788  Validation loss = 3.6411  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 2.6784  Validation loss = 3.6411  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 2.6777  Validation loss = 3.6416  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 2.6771  Validation loss = 3.6380  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 2.6768  Validation loss = 3.6364  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 2.6763  Validation loss = 3.6362  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 2.6760  Validation loss = 3.6320  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 2.6757  Validation loss = 3.6301  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 2.6753  Validation loss = 3.6280  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 2.6750  Validation loss = 3.6277  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 2.6746  Validation loss = 3.6305  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 2.6743  Validation loss = 3.6308  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 2.6739  Validation loss = 3.6307  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 2.6736  Validation loss = 3.6279  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 2.6731  Validation loss = 3.6269  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 2.6728  Validation loss = 3.6259  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 2.6724  Validation loss = 3.6247  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 2.6720  Validation loss = 3.6244  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 2.6715  Validation loss = 3.6207  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 2.6711  Validation loss = 3.6215  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 2.6708  Validation loss = 3.6206  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 2.6705  Validation loss = 3.6210  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 2.6701  Validation loss = 3.6209  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 2.6697  Validation loss = 3.6200  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 2.6693  Validation loss = 3.6193  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 2.6689  Validation loss = 3.6170  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 2.6687  Validation loss = 3.6170  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 2.6684  Validation loss = 3.6132  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 2.6680  Validation loss = 3.6108  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 2.6677  Validation loss = 3.6101  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 2.6672  Validation loss = 3.6106  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 2.6669  Validation loss = 3.6074  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 2.6665  Validation loss = 3.6111  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 2.6664  Validation loss = 3.6100  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 2.6660  Validation loss = 3.6098  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 2.6655  Validation loss = 3.6095  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 2.6651  Validation loss = 3.6076  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 2.6648  Validation loss = 3.6069  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 2.6645  Validation loss = 3.6068  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 2.6640  Validation loss = 3.6053  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 2.6635  Validation loss = 3.6049  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 2.6631  Validation loss = 3.6019  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 2.6626  Validation loss = 3.5988  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 2.6623  Validation loss = 3.5980  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 2.6620  Validation loss = 3.5977  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 2.6615  Validation loss = 3.5974  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 2.6612  Validation loss = 3.5956  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 2.6607  Validation loss = 3.5964  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 2.6603  Validation loss = 3.5958  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 2.6599  Validation loss = 3.5941  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 2.6596  Validation loss = 3.5924  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 2.6590  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 2.6585  Validation loss = 3.5900  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 2.6583  Validation loss = 3.5894  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 2.6579  Validation loss = 3.5894  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 2.6575  Validation loss = 3.5882  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 2.6570  Validation loss = 3.5859  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 2.6566  Validation loss = 3.5850  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 2.6562  Validation loss = 3.5833  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 2.6559  Validation loss = 3.5821  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 2.6554  Validation loss = 3.5806  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 2.6551  Validation loss = 3.5799  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 2.6548  Validation loss = 3.5796  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 2.6545  Validation loss = 3.5789  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 2.6541  Validation loss = 3.5777  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 2.6538  Validation loss = 3.5792  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 2.6533  Validation loss = 3.5753  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 2.6529  Validation loss = 3.5742  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 2.6526  Validation loss = 3.5732  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 2.6521  Validation loss = 3.5718  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 2.6517  Validation loss = 3.5701  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 2.6514  Validation loss = 3.5685  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 2.6510  Validation loss = 3.5668  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 2.6506  Validation loss = 3.5666  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 2.6505  Validation loss = 3.5666  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 2.6501  Validation loss = 3.5676  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 2.6497  Validation loss = 3.5664  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 2.6494  Validation loss = 3.5656  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 2.6489  Validation loss = 3.5642  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 2.6485  Validation loss = 3.5623  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 2.6482  Validation loss = 3.5605  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 2.6476  Validation loss = 3.5596  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 2.6472  Validation loss = 3.5597  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 2.6466  Validation loss = 3.5603  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 2.6463  Validation loss = 3.5587  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 2.6461  Validation loss = 3.5584  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 2.6457  Validation loss = 3.5580  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 2.6454  Validation loss = 3.5564  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 2.6447  Validation loss = 3.5538  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 2.6443  Validation loss = 3.5534  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 2.6440  Validation loss = 3.5506  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 2.6437  Validation loss = 3.5514  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 2.6435  Validation loss = 3.5510  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 2.6430  Validation loss = 3.5496  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 2.6426  Validation loss = 3.5493  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 2.6420  Validation loss = 3.5448  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 2.6418  Validation loss = 3.5423  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 2.6415  Validation loss = 3.5421  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 2.6412  Validation loss = 3.5403  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 2.6408  Validation loss = 3.5419  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 2.6404  Validation loss = 3.5422  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 2.6402  Validation loss = 3.5422  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 2.6398  Validation loss = 3.5388  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 2.6395  Validation loss = 3.5377  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 2.6390  Validation loss = 3.5386  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 2.6383  Validation loss = 3.5355  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 2.6377  Validation loss = 3.5329  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 2.6375  Validation loss = 3.5325  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 2.6372  Validation loss = 3.5299  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 2.6365  Validation loss = 3.5291  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 2.6362  Validation loss = 3.5291  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 2.6361  Validation loss = 3.5291  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 2.6356  Validation loss = 3.5270  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 2.6353  Validation loss = 3.5259  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 2.6350  Validation loss = 3.5245  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 2.6347  Validation loss = 3.5211  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 2.6343  Validation loss = 3.5237  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 2.6338  Validation loss = 3.5244  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 2.6335  Validation loss = 3.5232  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 2.6330  Validation loss = 3.5200  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 2.6327  Validation loss = 3.5196  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 2.6324  Validation loss = 3.5198  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 2.6319  Validation loss = 3.5182  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 2.6316  Validation loss = 3.5177  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 2.6313  Validation loss = 3.5163  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 2.6311  Validation loss = 3.5176  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 2.6305  Validation loss = 3.5157  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 2.6301  Validation loss = 3.5150  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 2.6299  Validation loss = 3.5153  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 2.6295  Validation loss = 3.5140  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 2.6292  Validation loss = 3.5116  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 2.6290  Validation loss = 3.5112  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 2.6287  Validation loss = 3.5098  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 2.6284  Validation loss = 3.5074  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 2.6279  Validation loss = 3.5045  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 2.6276  Validation loss = 3.5020  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 2.6271  Validation loss = 3.5039  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 2.6267  Validation loss = 3.5029  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 2.6263  Validation loss = 3.5035  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 2.6259  Validation loss = 3.5023  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 2.6256  Validation loss = 3.5020  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 2.6253  Validation loss = 3.5008  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 2.6248  Validation loss = 3.4995  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 2.6243  Validation loss = 3.5003  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 2.6238  Validation loss = 3.4963  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 2.6234  Validation loss = 3.4969  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 2.6232  Validation loss = 3.4959  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 2.6228  Validation loss = 3.4946  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 2.6226  Validation loss = 3.4942  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 2.6223  Validation loss = 3.4922  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 2.6218  Validation loss = 3.4909  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 2.6216  Validation loss = 3.4898  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 2.6213  Validation loss = 3.4883  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 2.6208  Validation loss = 3.4879  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 2.6203  Validation loss = 3.4870  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 2.6198  Validation loss = 3.4853  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 2.6192  Validation loss = 3.4831  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 2.6190  Validation loss = 3.4832  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 2.6186  Validation loss = 3.4806  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 2.6183  Validation loss = 3.4795  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 2.6180  Validation loss = 3.4782  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 2.6177  Validation loss = 3.4772  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 2.6173  Validation loss = 3.4751  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 2.6170  Validation loss = 3.4771  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 2.6167  Validation loss = 3.4757  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 2.6165  Validation loss = 3.4752  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 2.6162  Validation loss = 3.4720  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 2.6159  Validation loss = 3.4717  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 2.6155  Validation loss = 3.4711  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 2.6152  Validation loss = 3.4691  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 2.6150  Validation loss = 3.4688  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 2.6145  Validation loss = 3.4703  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 2.6142  Validation loss = 3.4698  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 2.6139  Validation loss = 3.4700  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 2.6136  Validation loss = 3.4696  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 2.6133  Validation loss = 3.4689  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 2.6129  Validation loss = 3.4674  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 2.6125  Validation loss = 3.4645  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 2.6120  Validation loss = 3.4643  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 2.6114  Validation loss = 3.4629  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 2.6112  Validation loss = 3.4618  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 2.6109  Validation loss = 3.4623  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 2.6107  Validation loss = 3.4615  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 2.6105  Validation loss = 3.4607  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 2.6103  Validation loss = 3.4607  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 2.6098  Validation loss = 3.4596  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 2.6093  Validation loss = 3.4583  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 2.6091  Validation loss = 3.4581  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 2.6085  Validation loss = 3.4554  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 2.6082  Validation loss = 3.4540  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 2.6080  Validation loss = 3.4532  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 2.6075  Validation loss = 3.4522  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 2.6071  Validation loss = 3.4488  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 2.6068  Validation loss = 3.4487  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 2.6066  Validation loss = 3.4486  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 2.6063  Validation loss = 3.4489  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 2.6059  Validation loss = 3.4457  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 2.6058  Validation loss = 3.4457  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 2.6054  Validation loss = 3.4452  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 2.6051  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 2.6046  Validation loss = 3.4414  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 2.6042  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 2.6038  Validation loss = 3.4410  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 2.6033  Validation loss = 3.4394  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 2.6031  Validation loss = 3.4411  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 2.6029  Validation loss = 3.4402  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 2.6026  Validation loss = 3.4394  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 2.6024  Validation loss = 3.4396  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 2.6021  Validation loss = 3.4400  \n",
      "\n",
      "Fold: 10  Epoch: 501  Training loss = 2.6018  Validation loss = 3.4362  \n",
      "\n",
      "Fold: 10  Epoch: 502  Training loss = 2.6015  Validation loss = 3.4361  \n",
      "\n",
      "Fold: 10  Epoch: 503  Training loss = 2.6012  Validation loss = 3.4343  \n",
      "\n",
      "Fold: 10  Epoch: 504  Training loss = 2.6008  Validation loss = 3.4332  \n",
      "\n",
      "Fold: 10  Epoch: 505  Training loss = 2.6004  Validation loss = 3.4342  \n",
      "\n",
      "Fold: 10  Epoch: 506  Training loss = 2.5998  Validation loss = 3.4316  \n",
      "\n",
      "Fold: 10  Epoch: 507  Training loss = 2.5995  Validation loss = 3.4319  \n",
      "\n",
      "Fold: 10  Epoch: 508  Training loss = 2.5992  Validation loss = 3.4317  \n",
      "\n",
      "Fold: 10  Epoch: 509  Training loss = 2.5989  Validation loss = 3.4305  \n",
      "\n",
      "Fold: 10  Epoch: 510  Training loss = 2.5986  Validation loss = 3.4300  \n",
      "\n",
      "Fold: 10  Epoch: 511  Training loss = 2.5982  Validation loss = 3.4300  \n",
      "\n",
      "Fold: 10  Epoch: 512  Training loss = 2.5979  Validation loss = 3.4288  \n",
      "\n",
      "Fold: 10  Epoch: 513  Training loss = 2.5976  Validation loss = 3.4282  \n",
      "\n",
      "Fold: 10  Epoch: 514  Training loss = 2.5974  Validation loss = 3.4272  \n",
      "\n",
      "Fold: 10  Epoch: 515  Training loss = 2.5971  Validation loss = 3.4275  \n",
      "\n",
      "Fold: 10  Epoch: 516  Training loss = 2.5969  Validation loss = 3.4261  \n",
      "\n",
      "Fold: 10  Epoch: 517  Training loss = 2.5966  Validation loss = 3.4255  \n",
      "\n",
      "Fold: 10  Epoch: 518  Training loss = 2.5961  Validation loss = 3.4240  \n",
      "\n",
      "Fold: 10  Epoch: 519  Training loss = 2.5958  Validation loss = 3.4232  \n",
      "\n",
      "Fold: 10  Epoch: 520  Training loss = 2.5957  Validation loss = 3.4230  \n",
      "\n",
      "Fold: 10  Epoch: 521  Training loss = 2.5953  Validation loss = 3.4236  \n",
      "\n",
      "Fold: 10  Epoch: 522  Training loss = 2.5950  Validation loss = 3.4233  \n",
      "\n",
      "Fold: 10  Epoch: 523  Training loss = 2.5946  Validation loss = 3.4225  \n",
      "\n",
      "Fold: 10  Epoch: 524  Training loss = 2.5944  Validation loss = 3.4219  \n",
      "\n",
      "Fold: 10  Epoch: 525  Training loss = 2.5941  Validation loss = 3.4205  \n",
      "\n",
      "Fold: 10  Epoch: 526  Training loss = 2.5938  Validation loss = 3.4204  \n",
      "\n",
      "Fold: 10  Epoch: 527  Training loss = 2.5935  Validation loss = 3.4197  \n",
      "\n",
      "Fold: 10  Epoch: 528  Training loss = 2.5932  Validation loss = 3.4172  \n",
      "\n",
      "Fold: 10  Epoch: 529  Training loss = 2.5928  Validation loss = 3.4158  \n",
      "\n",
      "Fold: 10  Epoch: 530  Training loss = 2.5924  Validation loss = 3.4141  \n",
      "\n",
      "Fold: 10  Epoch: 531  Training loss = 2.5921  Validation loss = 3.4143  \n",
      "\n",
      "Fold: 10  Epoch: 532  Training loss = 2.5917  Validation loss = 3.4110  \n",
      "\n",
      "Fold: 10  Epoch: 533  Training loss = 2.5916  Validation loss = 3.4112  \n",
      "\n",
      "Fold: 10  Epoch: 534  Training loss = 2.5912  Validation loss = 3.4099  \n",
      "\n",
      "Fold: 10  Epoch: 535  Training loss = 2.5909  Validation loss = 3.4103  \n",
      "\n",
      "Fold: 10  Epoch: 536  Training loss = 2.5905  Validation loss = 3.4087  \n",
      "\n",
      "Fold: 10  Epoch: 537  Training loss = 2.5902  Validation loss = 3.4075  \n",
      "\n",
      "Fold: 10  Epoch: 538  Training loss = 2.5897  Validation loss = 3.4066  \n",
      "\n",
      "Fold: 10  Epoch: 539  Training loss = 2.5895  Validation loss = 3.4063  \n",
      "\n",
      "Fold: 10  Epoch: 540  Training loss = 2.5891  Validation loss = 3.4050  \n",
      "\n",
      "Fold: 10  Epoch: 541  Training loss = 2.5888  Validation loss = 3.4053  \n",
      "\n",
      "Fold: 10  Epoch: 542  Training loss = 2.5886  Validation loss = 3.4047  \n",
      "\n",
      "Fold: 10  Epoch: 543  Training loss = 2.5884  Validation loss = 3.4044  \n",
      "\n",
      "Fold: 10  Epoch: 544  Training loss = 2.5881  Validation loss = 3.4042  \n",
      "\n",
      "Fold: 10  Epoch: 545  Training loss = 2.5876  Validation loss = 3.4012  \n",
      "\n",
      "Fold: 10  Epoch: 546  Training loss = 2.5873  Validation loss = 3.4007  \n",
      "\n",
      "Fold: 10  Epoch: 547  Training loss = 2.5870  Validation loss = 3.4009  \n",
      "\n",
      "Fold: 10  Epoch: 548  Training loss = 2.5866  Validation loss = 3.3999  \n",
      "\n",
      "Fold: 10  Epoch: 549  Training loss = 2.5863  Validation loss = 3.3990  \n",
      "\n",
      "Fold: 10  Epoch: 550  Training loss = 2.5859  Validation loss = 3.3978  \n",
      "\n",
      "Fold: 10  Epoch: 551  Training loss = 2.5857  Validation loss = 3.3967  \n",
      "\n",
      "Fold: 10  Epoch: 552  Training loss = 2.5853  Validation loss = 3.3957  \n",
      "\n",
      "Fold: 10  Epoch: 553  Training loss = 2.5850  Validation loss = 3.3959  \n",
      "\n",
      "Fold: 10  Epoch: 554  Training loss = 2.5849  Validation loss = 3.3957  \n",
      "\n",
      "Fold: 10  Epoch: 555  Training loss = 2.5845  Validation loss = 3.3951  \n",
      "\n",
      "Fold: 10  Epoch: 556  Training loss = 2.5842  Validation loss = 3.3924  \n",
      "\n",
      "Fold: 10  Epoch: 557  Training loss = 2.5839  Validation loss = 3.3921  \n",
      "\n",
      "Fold: 10  Epoch: 558  Training loss = 2.5836  Validation loss = 3.3922  \n",
      "\n",
      "Fold: 10  Epoch: 559  Training loss = 2.5831  Validation loss = 3.3908  \n",
      "\n",
      "Fold: 10  Epoch: 560  Training loss = 2.5829  Validation loss = 3.3907  \n",
      "\n",
      "Fold: 10  Epoch: 561  Training loss = 2.5826  Validation loss = 3.3907  \n",
      "\n",
      "Fold: 10  Epoch: 562  Training loss = 2.5823  Validation loss = 3.3905  \n",
      "\n",
      "Fold: 10  Epoch: 563  Training loss = 2.5820  Validation loss = 3.3901  \n",
      "\n",
      "Fold: 10  Epoch: 564  Training loss = 2.5816  Validation loss = 3.3891  \n",
      "\n",
      "Fold: 10  Epoch: 565  Training loss = 2.5812  Validation loss = 3.3860  \n",
      "\n",
      "Fold: 10  Epoch: 566  Training loss = 2.5808  Validation loss = 3.3862  \n",
      "\n",
      "Fold: 10  Epoch: 567  Training loss = 2.5804  Validation loss = 3.3858  \n",
      "\n",
      "Fold: 10  Epoch: 568  Training loss = 2.5800  Validation loss = 3.3852  \n",
      "\n",
      "Fold: 10  Epoch: 569  Training loss = 2.5796  Validation loss = 3.3837  \n",
      "\n",
      "Fold: 10  Epoch: 570  Training loss = 2.5793  Validation loss = 3.3827  \n",
      "\n",
      "Fold: 10  Epoch: 571  Training loss = 2.5789  Validation loss = 3.3804  \n",
      "\n",
      "Fold: 10  Epoch: 572  Training loss = 2.5784  Validation loss = 3.3789  \n",
      "\n",
      "Fold: 10  Epoch: 573  Training loss = 2.5780  Validation loss = 3.3777  \n",
      "\n",
      "Fold: 10  Epoch: 574  Training loss = 2.5778  Validation loss = 3.3778  \n",
      "\n",
      "Fold: 10  Epoch: 575  Training loss = 2.5773  Validation loss = 3.3748  \n",
      "\n",
      "Fold: 10  Epoch: 576  Training loss = 2.5768  Validation loss = 3.3734  \n",
      "\n",
      "Fold: 10  Epoch: 577  Training loss = 2.5765  Validation loss = 3.3730  \n",
      "\n",
      "Fold: 10  Epoch: 578  Training loss = 2.5760  Validation loss = 3.3711  \n",
      "\n",
      "Fold: 10  Epoch: 579  Training loss = 2.5756  Validation loss = 3.3695  \n",
      "\n",
      "Fold: 10  Epoch: 580  Training loss = 2.5755  Validation loss = 3.3686  \n",
      "\n",
      "Fold: 10  Epoch: 581  Training loss = 2.5753  Validation loss = 3.3686  \n",
      "\n",
      "Fold: 10  Epoch: 582  Training loss = 2.5751  Validation loss = 3.3670  \n",
      "\n",
      "Fold: 10  Epoch: 583  Training loss = 2.5746  Validation loss = 3.3677  \n",
      "\n",
      "Fold: 10  Epoch: 584  Training loss = 2.5743  Validation loss = 3.3672  \n",
      "\n",
      "Fold: 10  Epoch: 585  Training loss = 2.5740  Validation loss = 3.3669  \n",
      "\n",
      "Fold: 10  Epoch: 586  Training loss = 2.5737  Validation loss = 3.3663  \n",
      "\n",
      "Fold: 10  Epoch: 587  Training loss = 2.5734  Validation loss = 3.3661  \n",
      "\n",
      "Fold: 10  Epoch: 588  Training loss = 2.5730  Validation loss = 3.3641  \n",
      "\n",
      "Fold: 10  Epoch: 589  Training loss = 2.5728  Validation loss = 3.3625  \n",
      "\n",
      "Fold: 10  Epoch: 590  Training loss = 2.5725  Validation loss = 3.3616  \n",
      "\n",
      "Fold: 10  Epoch: 591  Training loss = 2.5721  Validation loss = 3.3624  \n",
      "\n",
      "Fold: 10  Epoch: 592  Training loss = 2.5717  Validation loss = 3.3611  \n",
      "\n",
      "Fold: 10  Epoch: 593  Training loss = 2.5711  Validation loss = 3.3578  \n",
      "\n",
      "Fold: 10  Epoch: 594  Training loss = 2.5705  Validation loss = 3.3569  \n",
      "\n",
      "Fold: 10  Epoch: 595  Training loss = 2.5703  Validation loss = 3.3565  \n",
      "\n",
      "Fold: 10  Epoch: 596  Training loss = 2.5699  Validation loss = 3.3554  \n",
      "\n",
      "Fold: 10  Epoch: 597  Training loss = 2.5696  Validation loss = 3.3543  \n",
      "\n",
      "Fold: 10  Epoch: 598  Training loss = 2.5692  Validation loss = 3.3542  \n",
      "\n",
      "Fold: 10  Epoch: 599  Training loss = 2.5691  Validation loss = 3.3542  \n",
      "\n",
      "Fold: 10  Epoch: 600  Training loss = 2.5685  Validation loss = 3.3507  \n",
      "\n",
      "Fold: 10  Epoch: 601  Training loss = 2.5681  Validation loss = 3.3508  \n",
      "\n",
      "Fold: 10  Epoch: 602  Training loss = 2.5677  Validation loss = 3.3480  \n",
      "\n",
      "Fold: 10  Epoch: 603  Training loss = 2.5674  Validation loss = 3.3472  \n",
      "\n",
      "Fold: 10  Epoch: 604  Training loss = 2.5669  Validation loss = 3.3449  \n",
      "\n",
      "Fold: 10  Epoch: 605  Training loss = 2.5668  Validation loss = 3.3452  \n",
      "\n",
      "Fold: 10  Epoch: 606  Training loss = 2.5666  Validation loss = 3.3456  \n",
      "\n",
      "Fold: 10  Epoch: 607  Training loss = 2.5662  Validation loss = 3.3439  \n",
      "\n",
      "Fold: 10  Epoch: 608  Training loss = 2.5661  Validation loss = 3.3442  \n",
      "\n",
      "Fold: 10  Epoch: 609  Training loss = 2.5656  Validation loss = 3.3438  \n",
      "\n",
      "Fold: 10  Epoch: 610  Training loss = 2.5653  Validation loss = 3.3437  \n",
      "\n",
      "Fold: 10  Epoch: 611  Training loss = 2.5648  Validation loss = 3.3421  \n",
      "\n",
      "Fold: 10  Epoch: 612  Training loss = 2.5644  Validation loss = 3.3403  \n",
      "\n",
      "Fold: 10  Epoch: 613  Training loss = 2.5641  Validation loss = 3.3398  \n",
      "\n",
      "Fold: 10  Epoch: 614  Training loss = 2.5637  Validation loss = 3.3379  \n",
      "\n",
      "Fold: 10  Epoch: 615  Training loss = 2.5634  Validation loss = 3.3368  \n",
      "\n",
      "Fold: 10  Epoch: 616  Training loss = 2.5629  Validation loss = 3.3357  \n",
      "\n",
      "Fold: 10  Epoch: 617  Training loss = 2.5626  Validation loss = 3.3344  \n",
      "\n",
      "Fold: 10  Epoch: 618  Training loss = 2.5624  Validation loss = 3.3340  \n",
      "\n",
      "Fold: 10  Epoch: 619  Training loss = 2.5621  Validation loss = 3.3334  \n",
      "\n",
      "Fold: 10  Epoch: 620  Training loss = 2.5617  Validation loss = 3.3336  \n",
      "\n",
      "Fold: 10  Epoch: 621  Training loss = 2.5614  Validation loss = 3.3335  \n",
      "\n",
      "Fold: 10  Epoch: 622  Training loss = 2.5610  Validation loss = 3.3319  \n",
      "\n",
      "Fold: 10  Epoch: 623  Training loss = 2.5608  Validation loss = 3.3308  \n",
      "\n",
      "Fold: 10  Epoch: 624  Training loss = 2.5604  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 10  Epoch: 625  Training loss = 2.5600  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 10  Epoch: 626  Training loss = 2.5598  Validation loss = 3.3291  \n",
      "\n",
      "Fold: 10  Epoch: 627  Training loss = 2.5596  Validation loss = 3.3274  \n",
      "\n",
      "Fold: 10  Epoch: 628  Training loss = 2.5593  Validation loss = 3.3260  \n",
      "\n",
      "Fold: 10  Epoch: 629  Training loss = 2.5590  Validation loss = 3.3250  \n",
      "\n",
      "Fold: 10  Epoch: 630  Training loss = 2.5586  Validation loss = 3.3238  \n",
      "\n",
      "Fold: 10  Epoch: 631  Training loss = 2.5581  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 10  Epoch: 632  Training loss = 2.5577  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 10  Epoch: 633  Training loss = 2.5575  Validation loss = 3.3228  \n",
      "\n",
      "Fold: 10  Epoch: 634  Training loss = 2.5573  Validation loss = 3.3227  \n",
      "\n",
      "Fold: 10  Epoch: 635  Training loss = 2.5570  Validation loss = 3.3226  \n",
      "\n",
      "Fold: 10  Epoch: 636  Training loss = 2.5568  Validation loss = 3.3209  \n",
      "\n",
      "Fold: 10  Epoch: 637  Training loss = 2.5565  Validation loss = 3.3199  \n",
      "\n",
      "Fold: 10  Epoch: 638  Training loss = 2.5563  Validation loss = 3.3199  \n",
      "\n",
      "Fold: 10  Epoch: 639  Training loss = 2.5559  Validation loss = 3.3195  \n",
      "\n",
      "Fold: 10  Epoch: 640  Training loss = 2.5555  Validation loss = 3.3184  \n",
      "\n",
      "Fold: 10  Epoch: 641  Training loss = 2.5549  Validation loss = 3.3162  \n",
      "\n",
      "Fold: 10  Epoch: 642  Training loss = 2.5546  Validation loss = 3.3153  \n",
      "\n",
      "Fold: 10  Epoch: 643  Training loss = 2.5542  Validation loss = 3.3142  \n",
      "\n",
      "Fold: 10  Epoch: 644  Training loss = 2.5539  Validation loss = 3.3126  \n",
      "\n",
      "Fold: 10  Epoch: 645  Training loss = 2.5536  Validation loss = 3.3121  \n",
      "\n",
      "Fold: 10  Epoch: 646  Training loss = 2.5533  Validation loss = 3.3117  \n",
      "\n",
      "Fold: 10  Epoch: 647  Training loss = 2.5528  Validation loss = 3.3103  \n",
      "\n",
      "Fold: 10  Epoch: 648  Training loss = 2.5526  Validation loss = 3.3098  \n",
      "\n",
      "Fold: 10  Epoch: 649  Training loss = 2.5521  Validation loss = 3.3083  \n",
      "\n",
      "Fold: 10  Epoch: 650  Training loss = 2.5519  Validation loss = 3.3083  \n",
      "\n",
      "Fold: 10  Epoch: 651  Training loss = 2.5517  Validation loss = 3.3083  \n",
      "\n",
      "Fold: 10  Epoch: 652  Training loss = 2.5514  Validation loss = 3.3072  \n",
      "\n",
      "Fold: 10  Epoch: 653  Training loss = 2.5508  Validation loss = 3.3049  \n",
      "\n",
      "Fold: 10  Epoch: 654  Training loss = 2.5506  Validation loss = 3.3047  \n",
      "\n",
      "Fold: 10  Epoch: 655  Training loss = 2.5504  Validation loss = 3.3044  \n",
      "\n",
      "Fold: 10  Epoch: 656  Training loss = 2.5500  Validation loss = 3.3033  \n",
      "\n",
      "Fold: 10  Epoch: 657  Training loss = 2.5497  Validation loss = 3.3017  \n",
      "\n",
      "Fold: 10  Epoch: 658  Training loss = 2.5494  Validation loss = 3.3016  \n",
      "\n",
      "Fold: 10  Epoch: 659  Training loss = 2.5491  Validation loss = 3.3007  \n",
      "\n",
      "Fold: 10  Epoch: 660  Training loss = 2.5489  Validation loss = 3.3006  \n",
      "\n",
      "Fold: 10  Epoch: 661  Training loss = 2.5485  Validation loss = 3.2992  \n",
      "\n",
      "Fold: 10  Epoch: 662  Training loss = 2.5483  Validation loss = 3.2995  \n",
      "\n",
      "Fold: 10  Epoch: 663  Training loss = 2.5481  Validation loss = 3.2994  \n",
      "\n",
      "Fold: 10  Epoch: 664  Training loss = 2.5478  Validation loss = 3.2993  \n",
      "\n",
      "Fold: 10  Epoch: 665  Training loss = 2.5473  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 10  Epoch: 666  Training loss = 2.5470  Validation loss = 3.2980  \n",
      "\n",
      "Fold: 10  Epoch: 667  Training loss = 2.5467  Validation loss = 3.2975  \n",
      "\n",
      "Fold: 10  Epoch: 668  Training loss = 2.5464  Validation loss = 3.2966  \n",
      "\n",
      "Fold: 10  Epoch: 669  Training loss = 2.5461  Validation loss = 3.2965  \n",
      "\n",
      "Fold: 10  Epoch: 670  Training loss = 2.5459  Validation loss = 3.2963  \n",
      "\n",
      "Fold: 10  Epoch: 671  Training loss = 2.5458  Validation loss = 3.2967  \n",
      "\n",
      "Fold: 10  Epoch: 672  Training loss = 2.5455  Validation loss = 3.2964  \n",
      "\n",
      "Fold: 10  Epoch: 673  Training loss = 2.5453  Validation loss = 3.2967  \n",
      "\n",
      "Fold: 10  Epoch: 674  Training loss = 2.5449  Validation loss = 3.2956  \n",
      "\n",
      "Fold: 10  Epoch: 675  Training loss = 2.5446  Validation loss = 3.2952  \n",
      "\n",
      "Fold: 10  Epoch: 676  Training loss = 2.5440  Validation loss = 3.2933  \n",
      "\n",
      "Fold: 10  Epoch: 677  Training loss = 2.5437  Validation loss = 3.2918  \n",
      "\n",
      "Fold: 10  Epoch: 678  Training loss = 2.5433  Validation loss = 3.2909  \n",
      "\n",
      "Fold: 10  Epoch: 679  Training loss = 2.5430  Validation loss = 3.2897  \n",
      "\n",
      "Fold: 10  Epoch: 680  Training loss = 2.5426  Validation loss = 3.2885  \n",
      "\n",
      "Fold: 10  Epoch: 681  Training loss = 2.5424  Validation loss = 3.2878  \n",
      "\n",
      "Fold: 10  Epoch: 682  Training loss = 2.5418  Validation loss = 3.2865  \n",
      "\n",
      "Fold: 10  Epoch: 683  Training loss = 2.5415  Validation loss = 3.2862  \n",
      "\n",
      "Fold: 10  Epoch: 684  Training loss = 2.5413  Validation loss = 3.2866  \n",
      "\n",
      "Fold: 10  Epoch: 685  Training loss = 2.5409  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 10  Epoch: 686  Training loss = 2.5406  Validation loss = 3.2835  \n",
      "\n",
      "Fold: 10  Epoch: 687  Training loss = 2.5402  Validation loss = 3.2825  \n",
      "\n",
      "Fold: 10  Epoch: 688  Training loss = 2.5399  Validation loss = 3.2819  \n",
      "\n",
      "Fold: 10  Epoch: 689  Training loss = 2.5395  Validation loss = 3.2806  \n",
      "\n",
      "Fold: 10  Epoch: 690  Training loss = 2.5392  Validation loss = 3.2798  \n",
      "\n",
      "Fold: 10  Epoch: 691  Training loss = 2.5391  Validation loss = 3.2802  \n",
      "\n",
      "Fold: 10  Epoch: 692  Training loss = 2.5385  Validation loss = 3.2783  \n",
      "\n",
      "Fold: 10  Epoch: 693  Training loss = 2.5382  Validation loss = 3.2779  \n",
      "\n",
      "Fold: 10  Epoch: 694  Training loss = 2.5377  Validation loss = 3.2761  \n",
      "\n",
      "Fold: 10  Epoch: 695  Training loss = 2.5374  Validation loss = 3.2750  \n",
      "\n",
      "Fold: 10  Epoch: 696  Training loss = 2.5370  Validation loss = 3.2740  \n",
      "\n",
      "Fold: 10  Epoch: 697  Training loss = 2.5366  Validation loss = 3.2728  \n",
      "\n",
      "Fold: 10  Epoch: 698  Training loss = 2.5361  Validation loss = 3.2713  \n",
      "\n",
      "Fold: 10  Epoch: 699  Training loss = 2.5357  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 10  Epoch: 700  Training loss = 2.5353  Validation loss = 3.2699  \n",
      "\n",
      "Fold: 10  Epoch: 701  Training loss = 2.5351  Validation loss = 3.2695  \n",
      "\n",
      "Fold: 10  Epoch: 702  Training loss = 2.5346  Validation loss = 3.2677  \n",
      "\n",
      "Fold: 10  Epoch: 703  Training loss = 2.5344  Validation loss = 3.2673  \n",
      "\n",
      "Fold: 10  Epoch: 704  Training loss = 2.5340  Validation loss = 3.2662  \n",
      "\n",
      "Fold: 10  Epoch: 705  Training loss = 2.5337  Validation loss = 3.2651  \n",
      "\n",
      "Fold: 10  Epoch: 706  Training loss = 2.5335  Validation loss = 3.2646  \n",
      "\n",
      "Fold: 10  Epoch: 707  Training loss = 2.5330  Validation loss = 3.2635  \n",
      "\n",
      "Fold: 10  Epoch: 708  Training loss = 2.5326  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 10  Epoch: 709  Training loss = 2.5323  Validation loss = 3.2631  \n",
      "\n",
      "Fold: 10  Epoch: 710  Training loss = 2.5320  Validation loss = 3.2625  \n",
      "\n",
      "Fold: 10  Epoch: 711  Training loss = 2.5312  Validation loss = 3.2600  \n",
      "\n",
      "Fold: 10  Epoch: 712  Training loss = 2.5308  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 10  Epoch: 713  Training loss = 2.5306  Validation loss = 3.2579  \n",
      "\n",
      "Fold: 10  Epoch: 714  Training loss = 2.5305  Validation loss = 3.2579  \n",
      "\n",
      "Fold: 10  Epoch: 715  Training loss = 2.5300  Validation loss = 3.2569  \n",
      "\n",
      "Fold: 10  Epoch: 716  Training loss = 2.5298  Validation loss = 3.2570  \n",
      "\n",
      "Fold: 10  Epoch: 717  Training loss = 2.5293  Validation loss = 3.2555  \n",
      "\n",
      "Fold: 10  Epoch: 718  Training loss = 2.5292  Validation loss = 3.2562  \n",
      "\n",
      "Fold: 10  Epoch: 719  Training loss = 2.5288  Validation loss = 3.2551  \n",
      "\n",
      "Fold: 10  Epoch: 720  Training loss = 2.5286  Validation loss = 3.2550  \n",
      "\n",
      "Fold: 10  Epoch: 721  Training loss = 2.5283  Validation loss = 3.2548  \n",
      "\n",
      "Fold: 10  Epoch: 722  Training loss = 2.5279  Validation loss = 3.2543  \n",
      "\n",
      "Fold: 10  Epoch: 723  Training loss = 2.5276  Validation loss = 3.2543  \n",
      "\n",
      "Fold: 10  Epoch: 724  Training loss = 2.5274  Validation loss = 3.2535  \n",
      "\n",
      "Fold: 10  Epoch: 725  Training loss = 2.5271  Validation loss = 3.2522  \n",
      "\n",
      "Fold: 10  Epoch: 726  Training loss = 2.5267  Validation loss = 3.2516  \n",
      "\n",
      "Fold: 10  Epoch: 727  Training loss = 2.5264  Validation loss = 3.2517  \n",
      "\n",
      "Fold: 10  Epoch: 728  Training loss = 2.5262  Validation loss = 3.2512  \n",
      "\n",
      "Fold: 10  Epoch: 729  Training loss = 2.5260  Validation loss = 3.2514  \n",
      "\n",
      "Fold: 10  Epoch: 730  Training loss = 2.5258  Validation loss = 3.2500  \n",
      "\n",
      "Fold: 10  Epoch: 731  Training loss = 2.5254  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 10  Epoch: 732  Training loss = 2.5250  Validation loss = 3.2492  \n",
      "\n",
      "Fold: 10  Epoch: 733  Training loss = 2.5247  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 10  Epoch: 734  Training loss = 2.5244  Validation loss = 3.2478  \n",
      "\n",
      "Fold: 10  Epoch: 735  Training loss = 2.5240  Validation loss = 3.2457  \n",
      "\n",
      "Fold: 10  Epoch: 736  Training loss = 2.5236  Validation loss = 3.2451  \n",
      "\n",
      "Fold: 10  Epoch: 737  Training loss = 2.5234  Validation loss = 3.2443  \n",
      "\n",
      "Fold: 10  Epoch: 738  Training loss = 2.5232  Validation loss = 3.2438  \n",
      "\n",
      "Fold: 10  Epoch: 739  Training loss = 2.5230  Validation loss = 3.2433  \n",
      "\n",
      "Fold: 10  Epoch: 740  Training loss = 2.5227  Validation loss = 3.2418  \n",
      "\n",
      "Fold: 10  Epoch: 741  Training loss = 2.5225  Validation loss = 3.2414  \n",
      "\n",
      "Fold: 10  Epoch: 742  Training loss = 2.5222  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 10  Epoch: 743  Training loss = 2.5220  Validation loss = 3.2391  \n",
      "\n",
      "Fold: 10  Epoch: 744  Training loss = 2.5217  Validation loss = 3.2387  \n",
      "\n",
      "Fold: 10  Epoch: 745  Training loss = 2.5213  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 10  Epoch: 746  Training loss = 2.5210  Validation loss = 3.2377  \n",
      "\n",
      "Fold: 10  Epoch: 747  Training loss = 2.5207  Validation loss = 3.2372  \n",
      "\n",
      "Fold: 10  Epoch: 748  Training loss = 2.5204  Validation loss = 3.2357  \n",
      "\n",
      "Fold: 10  Epoch: 749  Training loss = 2.5202  Validation loss = 3.2348  \n",
      "\n",
      "Fold: 10  Epoch: 750  Training loss = 2.5198  Validation loss = 3.2319  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 750  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 2.5833  Validation loss = 1.2726  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 2.5830  Validation loss = 1.2725  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 2.5825  Validation loss = 1.2715  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 2.5819  Validation loss = 1.2707  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 2.5813  Validation loss = 1.2701  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 2.5806  Validation loss = 1.2690  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 2.5802  Validation loss = 1.2684  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 2.5801  Validation loss = 1.2687  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 2.5796  Validation loss = 1.2679  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 2.5794  Validation loss = 1.2679  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 2.5791  Validation loss = 1.2677  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 2.5782  Validation loss = 1.2665  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 2.5779  Validation loss = 1.2660  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 2.5774  Validation loss = 1.2654  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 2.5768  Validation loss = 1.2646  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 2.5763  Validation loss = 1.2637  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 2.5758  Validation loss = 1.2629  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 2.5756  Validation loss = 1.2626  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 2.5753  Validation loss = 1.2624  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 2.5748  Validation loss = 1.2615  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 2.5746  Validation loss = 1.2615  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 2.5743  Validation loss = 1.2611  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 2.5739  Validation loss = 1.2607  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 2.5735  Validation loss = 1.2600  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 2.5733  Validation loss = 1.2599  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 2.5729  Validation loss = 1.2591  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 2.5725  Validation loss = 1.2586  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 2.5720  Validation loss = 1.2579  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 2.5717  Validation loss = 1.2579  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 2.5714  Validation loss = 1.2575  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 2.5709  Validation loss = 1.2568  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 2.5705  Validation loss = 1.2567  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 2.5697  Validation loss = 1.2558  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 2.5694  Validation loss = 1.2563  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 2.5687  Validation loss = 1.2547  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 2.5681  Validation loss = 1.2539  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 2.5677  Validation loss = 1.2535  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 2.5675  Validation loss = 1.2536  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 2.5672  Validation loss = 1.2531  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 2.5670  Validation loss = 1.2533  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 2.5668  Validation loss = 1.2530  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 2.5662  Validation loss = 1.2521  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 2.5657  Validation loss = 1.2515  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 2.5653  Validation loss = 1.2516  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 2.5651  Validation loss = 1.2511  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 2.5648  Validation loss = 1.2508  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 2.5641  Validation loss = 1.2495  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 2.5636  Validation loss = 1.2487  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 2.5631  Validation loss = 1.2478  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 2.5625  Validation loss = 1.2470  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 2.5620  Validation loss = 1.2466  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 2.5616  Validation loss = 1.2458  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 2.5610  Validation loss = 1.2453  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 2.5607  Validation loss = 1.2454  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 2.5602  Validation loss = 1.2452  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 2.5598  Validation loss = 1.2448  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 2.5593  Validation loss = 1.2439  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 2.5589  Validation loss = 1.2435  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 2.5581  Validation loss = 1.2420  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 2.5576  Validation loss = 1.2414  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 2.5573  Validation loss = 1.2414  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 2.5569  Validation loss = 1.2409  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 2.5562  Validation loss = 1.2407  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 2.5556  Validation loss = 1.2393  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 2.5550  Validation loss = 1.2386  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 2.5544  Validation loss = 1.2380  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 2.5539  Validation loss = 1.2380  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 2.5530  Validation loss = 1.2381  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 2.5472  Validation loss = 1.2376  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 2.5468  Validation loss = 1.2375  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 2.5464  Validation loss = 1.2367  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 2.5459  Validation loss = 1.2356  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 2.5454  Validation loss = 1.2348  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 2.5450  Validation loss = 1.2344  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 2.5445  Validation loss = 1.2335  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 2.5440  Validation loss = 1.2336  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 2.5436  Validation loss = 1.2332  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 2.5432  Validation loss = 1.2328  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 2.5426  Validation loss = 1.2313  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 2.5422  Validation loss = 1.2310  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 2.5419  Validation loss = 1.2310  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 2.5418  Validation loss = 1.2315  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 2.5413  Validation loss = 1.2306  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 2.5412  Validation loss = 1.2313  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 2.5408  Validation loss = 1.2314  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 2.5405  Validation loss = 1.2309  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 2.5402  Validation loss = 1.2304  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 2.5398  Validation loss = 1.2304  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 2.5394  Validation loss = 1.2296  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 2.5389  Validation loss = 1.2287  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 2.5386  Validation loss = 1.2285  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 2.5381  Validation loss = 1.2281  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 2.5377  Validation loss = 1.2279  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 2.5373  Validation loss = 1.2285  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 2.5366  Validation loss = 1.2272  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 2.5362  Validation loss = 1.2265  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 2.5359  Validation loss = 1.2262  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 2.5355  Validation loss = 1.2251  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 2.5348  Validation loss = 1.2235  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 2.5347  Validation loss = 1.2239  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 2.5344  Validation loss = 1.2240  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 2.5337  Validation loss = 1.2231  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 2.5332  Validation loss = 1.2230  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 2.5329  Validation loss = 1.2233  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 2.5326  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 2.5321  Validation loss = 1.2232  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 2.5317  Validation loss = 1.2228  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 2.5310  Validation loss = 1.2218  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 2.5304  Validation loss = 1.2211  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 2.5300  Validation loss = 1.2215  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 2.5296  Validation loss = 1.2221  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 2.5293  Validation loss = 1.2212  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 2.5290  Validation loss = 1.2211  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 2.5286  Validation loss = 1.2216  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 2.5283  Validation loss = 1.2218  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 2.5280  Validation loss = 1.2209  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 2.5278  Validation loss = 1.2211  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 2.5276  Validation loss = 1.2207  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 2.5271  Validation loss = 1.2205  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 2.5266  Validation loss = 1.2200  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 2.5261  Validation loss = 1.2197  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 2.5257  Validation loss = 1.2193  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 2.5252  Validation loss = 1.2182  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 2.5248  Validation loss = 1.2186  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 2.5247  Validation loss = 1.2184  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 2.5243  Validation loss = 1.2185  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 2.5238  Validation loss = 1.2178  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 2.5234  Validation loss = 1.2177  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 2.5229  Validation loss = 1.2170  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 2.5225  Validation loss = 1.2169  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 2.5221  Validation loss = 1.2160  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 2.5216  Validation loss = 1.2169  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 2.5211  Validation loss = 1.2159  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 2.5207  Validation loss = 1.2156  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 2.5202  Validation loss = 1.2143  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 2.5197  Validation loss = 1.2129  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 2.5192  Validation loss = 1.2119  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 2.5189  Validation loss = 1.2124  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 2.5185  Validation loss = 1.2129  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 2.5180  Validation loss = 1.2127  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 2.5176  Validation loss = 1.2118  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 2.5173  Validation loss = 1.2118  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 2.5170  Validation loss = 1.2118  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 2.5170  Validation loss = 1.2121  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 2.5167  Validation loss = 1.2123  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 2.5164  Validation loss = 1.2124  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 2.5160  Validation loss = 1.2123  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 2.5154  Validation loss = 1.2117  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 2.5152  Validation loss = 1.2122  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 2.5149  Validation loss = 1.2137  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 148  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 2.5023  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.5017  Validation loss = 2.3198  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 2.5014  Validation loss = 2.3224  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.5011  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 2.5010  Validation loss = 2.3265  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.5006  Validation loss = 2.3248  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 2.5000  Validation loss = 2.3206  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 2.4997  Validation loss = 2.3220  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.4996  Validation loss = 2.3244  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 2.4994  Validation loss = 2.3284  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 2.4990  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 2.4983  Validation loss = 2.3206  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 2.4979  Validation loss = 2.3167  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 2.4974  Validation loss = 2.3170  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 2.4973  Validation loss = 2.3193  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 2.4968  Validation loss = 2.3236  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 2.4964  Validation loss = 2.3220  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 2.4958  Validation loss = 2.3143  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 2.4955  Validation loss = 2.3159  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 2.4953  Validation loss = 2.3263  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 2.4946  Validation loss = 2.3235  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 2.4942  Validation loss = 2.3265  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 2.4938  Validation loss = 2.3218  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 2.4934  Validation loss = 2.3205  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 2.4927  Validation loss = 2.3054  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 2.4925  Validation loss = 2.3060  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 2.4922  Validation loss = 2.3092  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 2.4918  Validation loss = 2.3090  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 2.4916  Validation loss = 2.3131  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 2.4912  Validation loss = 2.3114  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 2.4907  Validation loss = 2.3064  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 2.4903  Validation loss = 2.2997  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 2.4898  Validation loss = 2.2998  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 2.4894  Validation loss = 2.2997  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 2.4889  Validation loss = 2.3021  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 2.4885  Validation loss = 2.3056  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 2.4878  Validation loss = 2.2958  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 2.4876  Validation loss = 2.3007  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 2.4873  Validation loss = 2.3074  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 2.4868  Validation loss = 2.3013  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 2.4865  Validation loss = 2.3067  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 2.4861  Validation loss = 2.3053  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 2.4855  Validation loss = 2.2898  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 2.4849  Validation loss = 2.2906  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 2.4845  Validation loss = 2.2907  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 2.4842  Validation loss = 2.2932  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 2.4838  Validation loss = 2.2912  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 2.4831  Validation loss = 2.2802  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 2.4828  Validation loss = 2.2806  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 2.4824  Validation loss = 2.2806  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 2.4818  Validation loss = 2.2634  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 2.4813  Validation loss = 2.2596  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 2.4810  Validation loss = 2.2567  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 2.4806  Validation loss = 2.2640  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 2.4803  Validation loss = 2.2667  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 2.4799  Validation loss = 2.2620  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 2.4797  Validation loss = 2.2655  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 2.4791  Validation loss = 2.2557  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 2.4785  Validation loss = 2.2529  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 2.4778  Validation loss = 2.2453  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 2.4775  Validation loss = 2.2540  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 2.4770  Validation loss = 2.2577  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 2.4767  Validation loss = 2.2536  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 2.4763  Validation loss = 2.2407  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 2.4760  Validation loss = 2.2363  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 2.4756  Validation loss = 2.2347  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 2.4752  Validation loss = 2.2303  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 2.4748  Validation loss = 2.2276  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 2.4745  Validation loss = 2.2255  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 2.4741  Validation loss = 2.2187  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 2.4738  Validation loss = 2.2205  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 2.4736  Validation loss = 2.2140  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 2.4734  Validation loss = 2.2148  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 2.4730  Validation loss = 2.2149  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 2.4725  Validation loss = 2.2140  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 2.4722  Validation loss = 2.2097  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 2.4719  Validation loss = 2.2155  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 2.4717  Validation loss = 2.2134  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 2.4712  Validation loss = 2.2087  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 2.4710  Validation loss = 2.2100  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 2.4704  Validation loss = 2.2025  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 2.4702  Validation loss = 2.1974  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 2.4697  Validation loss = 2.2035  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 2.4693  Validation loss = 2.1943  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 2.4689  Validation loss = 2.1948  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 2.4688  Validation loss = 2.1963  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 2.4685  Validation loss = 2.1945  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 2.4683  Validation loss = 2.1972  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 2.4680  Validation loss = 2.2023  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 2.4677  Validation loss = 2.2042  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 2.4674  Validation loss = 2.2016  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 2.4669  Validation loss = 2.1958  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 2.4665  Validation loss = 2.2010  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 2.4661  Validation loss = 2.2061  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 2.4658  Validation loss = 2.2131  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 84  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.4830  Validation loss = 3.9323  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.4815  Validation loss = 3.9296  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.4796  Validation loss = 3.9281  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.4788  Validation loss = 3.9264  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 2.4766  Validation loss = 3.9242  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 2.4749  Validation loss = 3.9221  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 2.4741  Validation loss = 3.9199  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 2.4734  Validation loss = 3.9181  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 2.4725  Validation loss = 3.9158  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 2.4718  Validation loss = 3.9146  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 2.4708  Validation loss = 3.9125  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 2.4704  Validation loss = 3.9117  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.4699  Validation loss = 3.9109  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.4686  Validation loss = 3.9081  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.4681  Validation loss = 3.9066  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.4674  Validation loss = 3.9054  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 2.4670  Validation loss = 3.9042  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 2.4661  Validation loss = 3.9021  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 2.4654  Validation loss = 3.9003  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 2.4648  Validation loss = 3.8989  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 2.4641  Validation loss = 3.8972  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.4635  Validation loss = 3.8957  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.4630  Validation loss = 3.8947  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 2.4626  Validation loss = 3.8939  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.4619  Validation loss = 3.8916  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 2.4611  Validation loss = 3.8893  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 2.4606  Validation loss = 3.8876  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 2.4600  Validation loss = 3.8861  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 2.4595  Validation loss = 3.8844  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 2.4592  Validation loss = 3.8835  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 2.4588  Validation loss = 3.8825  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 2.4583  Validation loss = 3.8809  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 2.4578  Validation loss = 3.8794  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 2.4572  Validation loss = 3.8774  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 2.4567  Validation loss = 3.8759  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 2.4564  Validation loss = 3.8750  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 2.4557  Validation loss = 3.8730  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 2.4551  Validation loss = 3.8713  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 2.4549  Validation loss = 3.8708  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 2.4544  Validation loss = 3.8696  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 2.4539  Validation loss = 3.8679  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 2.4535  Validation loss = 3.8668  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 2.4530  Validation loss = 3.8654  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 2.4524  Validation loss = 3.8631  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 2.4521  Validation loss = 3.8623  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 2.4516  Validation loss = 3.8607  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 2.4513  Validation loss = 3.8594  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 2.4510  Validation loss = 3.8588  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 2.4504  Validation loss = 3.8568  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 2.4501  Validation loss = 3.8561  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 2.4496  Validation loss = 3.8548  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 2.4489  Validation loss = 3.8528  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 2.4483  Validation loss = 3.8507  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 2.4476  Validation loss = 3.8483  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 2.4475  Validation loss = 3.8483  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 2.4469  Validation loss = 3.8464  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 2.4465  Validation loss = 3.8453  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 2.4460  Validation loss = 3.8437  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 2.4457  Validation loss = 3.8428  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 2.4452  Validation loss = 3.8417  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 2.4450  Validation loss = 3.8413  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 2.4447  Validation loss = 3.8404  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 2.4444  Validation loss = 3.8395  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 2.4438  Validation loss = 3.8377  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 2.4435  Validation loss = 3.8372  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 2.4432  Validation loss = 3.8364  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 2.4430  Validation loss = 3.8354  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 2.4427  Validation loss = 3.8343  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 2.4421  Validation loss = 3.8325  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 2.4419  Validation loss = 3.8322  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 2.4413  Validation loss = 3.8299  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 2.4411  Validation loss = 3.8292  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 2.4407  Validation loss = 3.8278  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 2.4403  Validation loss = 3.8269  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 2.4400  Validation loss = 3.8259  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 2.4395  Validation loss = 3.8246  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 2.4391  Validation loss = 3.8232  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 2.4387  Validation loss = 3.8221  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 2.4385  Validation loss = 3.8211  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 2.4382  Validation loss = 3.8202  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 2.4379  Validation loss = 3.8192  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 2.4376  Validation loss = 3.8182  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 2.4372  Validation loss = 3.8171  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 2.4369  Validation loss = 3.8164  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 2.4365  Validation loss = 3.8150  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 2.4361  Validation loss = 3.8137  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 2.4356  Validation loss = 3.8123  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 2.4352  Validation loss = 3.8109  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 2.4348  Validation loss = 3.8095  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 2.4344  Validation loss = 3.8082  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 2.4341  Validation loss = 3.8074  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 2.4337  Validation loss = 3.8060  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 2.4334  Validation loss = 3.8052  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 2.4330  Validation loss = 3.8040  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 2.4325  Validation loss = 3.8025  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 2.4321  Validation loss = 3.8016  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 2.4318  Validation loss = 3.8005  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 2.4315  Validation loss = 3.7996  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 2.4310  Validation loss = 3.7978  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 2.4308  Validation loss = 3.7972  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 2.4305  Validation loss = 3.7962  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 2.4300  Validation loss = 3.7947  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 2.4295  Validation loss = 3.7932  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 2.4292  Validation loss = 3.7921  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 2.4287  Validation loss = 3.7901  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 2.4283  Validation loss = 3.7894  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 2.4278  Validation loss = 3.7877  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 2.4274  Validation loss = 3.7863  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 2.4272  Validation loss = 3.7858  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 2.4268  Validation loss = 3.7846  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 2.4263  Validation loss = 3.7832  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 2.4258  Validation loss = 3.7814  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 2.4255  Validation loss = 3.7804  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 2.4251  Validation loss = 3.7790  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 2.4248  Validation loss = 3.7781  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 2.4245  Validation loss = 3.7775  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 2.4241  Validation loss = 3.7763  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 2.4236  Validation loss = 3.7745  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 2.4232  Validation loss = 3.7735  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 2.4228  Validation loss = 3.7724  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 2.4225  Validation loss = 3.7712  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 2.4221  Validation loss = 3.7699  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 2.4218  Validation loss = 3.7687  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 2.4214  Validation loss = 3.7677  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 2.4209  Validation loss = 3.7660  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 2.4207  Validation loss = 3.7657  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 2.4203  Validation loss = 3.7639  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 2.4198  Validation loss = 3.7622  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 2.4195  Validation loss = 3.7612  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 2.4192  Validation loss = 3.7607  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 2.4190  Validation loss = 3.7597  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 2.4186  Validation loss = 3.7588  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 2.4184  Validation loss = 3.7577  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 2.4179  Validation loss = 3.7562  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 2.4174  Validation loss = 3.7542  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 2.4170  Validation loss = 3.7531  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 2.4166  Validation loss = 3.7515  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 2.4162  Validation loss = 3.7500  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 2.4160  Validation loss = 3.7493  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 2.4156  Validation loss = 3.7479  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 2.4154  Validation loss = 3.7473  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 2.4151  Validation loss = 3.7465  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 2.4147  Validation loss = 3.7450  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 2.4143  Validation loss = 3.7431  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 2.4140  Validation loss = 3.7424  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 2.4136  Validation loss = 3.7410  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 2.4133  Validation loss = 3.7403  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 2.4131  Validation loss = 3.7398  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 2.4128  Validation loss = 3.7389  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 2.4125  Validation loss = 3.7382  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 2.4122  Validation loss = 3.7371  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 2.4117  Validation loss = 3.7350  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 2.4115  Validation loss = 3.7346  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 2.4112  Validation loss = 3.7336  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 2.4109  Validation loss = 3.7330  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 2.4105  Validation loss = 3.7316  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 2.4101  Validation loss = 3.7306  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 2.4097  Validation loss = 3.7293  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 2.4094  Validation loss = 3.7284  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 2.4092  Validation loss = 3.7277  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 2.4088  Validation loss = 3.7266  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 2.4083  Validation loss = 3.7252  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 2.4080  Validation loss = 3.7245  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 2.4076  Validation loss = 3.7233  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 2.4072  Validation loss = 3.7219  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 2.4071  Validation loss = 3.7220  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 2.4065  Validation loss = 3.7200  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 2.4060  Validation loss = 3.7178  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 2.4058  Validation loss = 3.7171  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 2.4054  Validation loss = 3.7157  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 2.4049  Validation loss = 3.7142  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 2.4047  Validation loss = 3.7137  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 2.4044  Validation loss = 3.7135  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 2.4040  Validation loss = 3.7120  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 2.4038  Validation loss = 3.7118  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 2.4034  Validation loss = 3.7101  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 2.4030  Validation loss = 3.7087  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 2.4028  Validation loss = 3.7080  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 2.4025  Validation loss = 3.7072  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 2.4020  Validation loss = 3.7056  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 2.4017  Validation loss = 3.7048  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 2.4013  Validation loss = 3.7033  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 2.4010  Validation loss = 3.7026  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 2.4006  Validation loss = 3.7014  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 2.4002  Validation loss = 3.7005  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 2.3998  Validation loss = 3.6988  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 2.3997  Validation loss = 3.6986  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 2.3994  Validation loss = 3.6976  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 2.3992  Validation loss = 3.6973  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 2.3991  Validation loss = 3.6977  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 2.3987  Validation loss = 3.6963  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 2.3984  Validation loss = 3.6954  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 2.3982  Validation loss = 3.6948  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 2.3978  Validation loss = 3.6937  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 2.3974  Validation loss = 3.6920  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 2.3972  Validation loss = 3.6909  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 2.3968  Validation loss = 3.6900  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 2.3966  Validation loss = 3.6894  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 2.3962  Validation loss = 3.6881  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 2.3957  Validation loss = 3.6861  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 2.3951  Validation loss = 3.6837  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 2.3946  Validation loss = 3.6815  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 2.3941  Validation loss = 3.6806  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 2.3939  Validation loss = 3.6801  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 2.3937  Validation loss = 3.6798  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 2.3935  Validation loss = 3.6797  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 2.3929  Validation loss = 3.6781  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 2.3925  Validation loss = 3.6764  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 2.3920  Validation loss = 3.6746  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 2.3916  Validation loss = 3.6731  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 2.3914  Validation loss = 3.6727  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 2.3912  Validation loss = 3.6719  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 2.3907  Validation loss = 3.6703  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 2.3902  Validation loss = 3.6685  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 2.3899  Validation loss = 3.6676  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 2.3896  Validation loss = 3.6666  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 2.3891  Validation loss = 3.6646  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 2.3889  Validation loss = 3.6641  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 2.3886  Validation loss = 3.6630  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 2.3884  Validation loss = 3.6622  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 2.3882  Validation loss = 3.6620  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 2.3878  Validation loss = 3.6607  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 2.3875  Validation loss = 3.6598  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 2.3871  Validation loss = 3.6586  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 2.3869  Validation loss = 3.6582  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 2.3866  Validation loss = 3.6571  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 2.3862  Validation loss = 3.6564  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 2.3858  Validation loss = 3.6552  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 2.3855  Validation loss = 3.6539  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 2.3849  Validation loss = 3.6521  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 2.3845  Validation loss = 3.6510  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 2.3843  Validation loss = 3.6505  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 2.3838  Validation loss = 3.6486  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 2.3836  Validation loss = 3.6476  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 2.3833  Validation loss = 3.6465  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 2.3828  Validation loss = 3.6446  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 2.3825  Validation loss = 3.6438  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 2.3824  Validation loss = 3.6436  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 2.3821  Validation loss = 3.6422  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 2.3819  Validation loss = 3.6419  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 2.3817  Validation loss = 3.6419  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 2.3814  Validation loss = 3.6411  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 2.3809  Validation loss = 3.6397  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 2.3806  Validation loss = 3.6390  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 2.3804  Validation loss = 3.6377  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 2.3801  Validation loss = 3.6377  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 2.3800  Validation loss = 3.6377  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 2.3797  Validation loss = 3.6370  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 2.3795  Validation loss = 3.6367  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 2.3791  Validation loss = 3.6351  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 2.3787  Validation loss = 3.6332  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 2.3782  Validation loss = 3.6320  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 2.3781  Validation loss = 3.6316  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 2.3776  Validation loss = 3.6300  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 2.3772  Validation loss = 3.6282  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 2.3770  Validation loss = 3.6275  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 2.3768  Validation loss = 3.6271  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 2.3763  Validation loss = 3.6258  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 2.3763  Validation loss = 3.6259  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 2.3759  Validation loss = 3.6248  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 2.3757  Validation loss = 3.6244  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 2.3755  Validation loss = 3.6241  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 2.3753  Validation loss = 3.6234  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 2.3749  Validation loss = 3.6220  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 2.3746  Validation loss = 3.6212  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 2.3742  Validation loss = 3.6200  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 2.3741  Validation loss = 3.6201  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 2.3739  Validation loss = 3.6195  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 2.3735  Validation loss = 3.6178  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 2.3732  Validation loss = 3.6171  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 2.3728  Validation loss = 3.6153  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 2.3726  Validation loss = 3.6151  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 2.3722  Validation loss = 3.6135  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 2.3718  Validation loss = 3.6114  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 2.3716  Validation loss = 3.6109  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 2.3712  Validation loss = 3.6096  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 2.3710  Validation loss = 3.6094  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 2.3708  Validation loss = 3.6093  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 2.3705  Validation loss = 3.6083  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 2.3702  Validation loss = 3.6072  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 2.3697  Validation loss = 3.6057  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 2.3693  Validation loss = 3.6042  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 2.3691  Validation loss = 3.6036  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 2.3688  Validation loss = 3.6021  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 2.3685  Validation loss = 3.6008  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 2.3681  Validation loss = 3.6002  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 2.3678  Validation loss = 3.5985  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 2.3676  Validation loss = 3.5985  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 2.3671  Validation loss = 3.5971  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 2.3669  Validation loss = 3.5972  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 2.3666  Validation loss = 3.5955  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 2.3661  Validation loss = 3.5942  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 2.3657  Validation loss = 3.5934  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 2.3652  Validation loss = 3.5917  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 2.3650  Validation loss = 3.5916  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 2.3646  Validation loss = 3.5903  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 2.3645  Validation loss = 3.5898  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 2.3642  Validation loss = 3.5884  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 2.3638  Validation loss = 3.5874  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 2.3636  Validation loss = 3.5867  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 2.3632  Validation loss = 3.5855  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 2.3630  Validation loss = 3.5846  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 2.3627  Validation loss = 3.5829  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 2.3624  Validation loss = 3.5815  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 2.3621  Validation loss = 3.5808  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 2.3617  Validation loss = 3.5790  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 2.3615  Validation loss = 3.5785  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 2.3611  Validation loss = 3.5773  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 2.3607  Validation loss = 3.5763  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 2.3604  Validation loss = 3.5755  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 2.3602  Validation loss = 3.5750  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 2.3601  Validation loss = 3.5750  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 2.3597  Validation loss = 3.5742  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 2.3594  Validation loss = 3.5730  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 2.3592  Validation loss = 3.5724  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 2.3590  Validation loss = 3.5720  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 2.3586  Validation loss = 3.5698  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 2.3584  Validation loss = 3.5692  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 2.3580  Validation loss = 3.5675  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 2.3579  Validation loss = 3.5672  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 2.3576  Validation loss = 3.5672  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 2.3574  Validation loss = 3.5669  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 2.3572  Validation loss = 3.5662  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 2.3569  Validation loss = 3.5647  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 2.3564  Validation loss = 3.5628  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 2.3561  Validation loss = 3.5617  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 2.3557  Validation loss = 3.5607  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 2.3555  Validation loss = 3.5602  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 2.3552  Validation loss = 3.5590  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 2.3548  Validation loss = 3.5574  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 2.3544  Validation loss = 3.5556  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 2.3541  Validation loss = 3.5551  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 2.3538  Validation loss = 3.5542  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 2.3536  Validation loss = 3.5538  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 2.3532  Validation loss = 3.5519  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 2.3531  Validation loss = 3.5519  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 2.3530  Validation loss = 3.5517  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 2.3527  Validation loss = 3.5511  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 2.3525  Validation loss = 3.5509  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 2.3522  Validation loss = 3.5503  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 2.3517  Validation loss = 3.5484  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 2.3513  Validation loss = 3.5473  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 2.3509  Validation loss = 3.5456  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 2.3508  Validation loss = 3.5455  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 2.3505  Validation loss = 3.5446  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 2.3501  Validation loss = 3.5434  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 2.3495  Validation loss = 3.5414  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 2.3492  Validation loss = 3.5404  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 2.3491  Validation loss = 3.5399  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 2.3488  Validation loss = 3.5385  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 2.3482  Validation loss = 3.5357  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 2.3479  Validation loss = 3.5346  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 2.3477  Validation loss = 3.5339  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 2.3474  Validation loss = 3.5324  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 2.3471  Validation loss = 3.5319  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 2.3468  Validation loss = 3.5311  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 2.3464  Validation loss = 3.5296  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 2.3459  Validation loss = 3.5274  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 2.3456  Validation loss = 3.5260  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 2.3454  Validation loss = 3.5253  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 2.3453  Validation loss = 3.5249  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 2.3450  Validation loss = 3.5239  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 2.3447  Validation loss = 3.5228  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 2.3445  Validation loss = 3.5222  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 2.3441  Validation loss = 3.5213  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 2.3439  Validation loss = 3.5212  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 2.3436  Validation loss = 3.5199  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 2.3433  Validation loss = 3.5187  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 2.3429  Validation loss = 3.5176  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 2.3426  Validation loss = 3.5167  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 2.3422  Validation loss = 3.5152  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 2.3417  Validation loss = 3.5135  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 2.3414  Validation loss = 3.5127  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 2.3414  Validation loss = 3.5131  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 2.3410  Validation loss = 3.5118  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 2.3406  Validation loss = 3.5098  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 2.3405  Validation loss = 3.5103  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 2.3401  Validation loss = 3.5091  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 2.3401  Validation loss = 3.5096  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 2.3397  Validation loss = 3.5083  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 2.3395  Validation loss = 3.5075  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 2.3392  Validation loss = 3.5064  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 2.3388  Validation loss = 3.5048  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 2.3385  Validation loss = 3.5037  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 2.3382  Validation loss = 3.5023  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 2.3379  Validation loss = 3.5015  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 2.3375  Validation loss = 3.5004  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 2.3372  Validation loss = 3.4989  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 2.3369  Validation loss = 3.4980  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 2.3366  Validation loss = 3.4967  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 2.3364  Validation loss = 3.4959  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 2.3359  Validation loss = 3.4932  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 2.3356  Validation loss = 3.4927  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 2.3351  Validation loss = 3.4909  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 2.3348  Validation loss = 3.4892  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 2.3346  Validation loss = 3.4891  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 2.3344  Validation loss = 3.4888  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 2.3341  Validation loss = 3.4882  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 2.3337  Validation loss = 3.4865  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 2.3334  Validation loss = 3.4855  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 2.3331  Validation loss = 3.4844  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 2.3328  Validation loss = 3.4833  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 2.3324  Validation loss = 3.4818  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 2.3321  Validation loss = 3.4811  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 2.3319  Validation loss = 3.4807  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 2.3317  Validation loss = 3.4803  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 2.3316  Validation loss = 3.4800  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 2.3311  Validation loss = 3.4778  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 2.3307  Validation loss = 3.4769  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 2.3306  Validation loss = 3.4764  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 2.3303  Validation loss = 3.4756  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 2.3301  Validation loss = 3.4754  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 2.3298  Validation loss = 3.4739  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 2.3295  Validation loss = 3.4727  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 2.3293  Validation loss = 3.4718  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 2.3288  Validation loss = 3.4695  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 2.3285  Validation loss = 3.4691  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 2.3283  Validation loss = 3.4681  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 2.3283  Validation loss = 3.4678  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 2.3280  Validation loss = 3.4674  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 2.3279  Validation loss = 3.4673  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 2.3277  Validation loss = 3.4666  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 2.3274  Validation loss = 3.4657  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 2.3270  Validation loss = 3.4643  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 2.3267  Validation loss = 3.4635  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 2.3262  Validation loss = 3.4616  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 2.3260  Validation loss = 3.4610  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 2.3258  Validation loss = 3.4606  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 2.3256  Validation loss = 3.4608  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 2.3254  Validation loss = 3.4597  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 2.3253  Validation loss = 3.4596  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 2.3252  Validation loss = 3.4597  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 2.3249  Validation loss = 3.4585  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 2.3246  Validation loss = 3.4575  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 2.3243  Validation loss = 3.4564  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 2.3240  Validation loss = 3.4557  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 2.3235  Validation loss = 3.4541  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 2.3233  Validation loss = 3.4535  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 2.3231  Validation loss = 3.4529  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 2.3228  Validation loss = 3.4515  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 2.3227  Validation loss = 3.4514  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 2.3224  Validation loss = 3.4504  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 2.3223  Validation loss = 3.4501  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 2.3220  Validation loss = 3.4497  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 2.3218  Validation loss = 3.4495  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 2.3215  Validation loss = 3.4481  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 2.3213  Validation loss = 3.4479  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 2.3212  Validation loss = 3.4476  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 2.3211  Validation loss = 3.4481  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 2.3208  Validation loss = 3.4468  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 2.3205  Validation loss = 3.4454  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 2.3202  Validation loss = 3.4437  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 2.3201  Validation loss = 3.4438  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 2.3199  Validation loss = 3.4437  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 2.3199  Validation loss = 3.4444  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 2.3195  Validation loss = 3.4428  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 2.3192  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 2.3189  Validation loss = 3.4408  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 2.3186  Validation loss = 3.4405  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 2.3185  Validation loss = 3.4405  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 2.3183  Validation loss = 3.4401  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 2.3180  Validation loss = 3.4389  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 2.3176  Validation loss = 3.4372  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 2.3174  Validation loss = 3.4368  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 2.3171  Validation loss = 3.4357  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 2.3167  Validation loss = 3.4340  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 2.3165  Validation loss = 3.4332  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 2.3164  Validation loss = 3.4331  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 2.3162  Validation loss = 3.4328  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 2.3158  Validation loss = 3.4311  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 2.3156  Validation loss = 3.4300  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 2.3153  Validation loss = 3.4290  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 2.3152  Validation loss = 3.4286  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 2.3150  Validation loss = 3.4290  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 2.3147  Validation loss = 3.4275  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 2.3144  Validation loss = 3.4263  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 2.3141  Validation loss = 3.4253  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 2.3139  Validation loss = 3.4243  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 2.3136  Validation loss = 3.4237  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 2.3133  Validation loss = 3.4220  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 2.3131  Validation loss = 3.4209  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 2.3127  Validation loss = 3.4201  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 2.3125  Validation loss = 3.4188  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 2.3124  Validation loss = 3.4181  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 2.3121  Validation loss = 3.4174  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 2.3118  Validation loss = 3.4160  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 2.3117  Validation loss = 3.4158  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 2.3115  Validation loss = 3.4156  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 2.3111  Validation loss = 3.4156  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 2.3111  Validation loss = 3.4162  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 2.3109  Validation loss = 3.4152  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 2.3106  Validation loss = 3.4136  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 2.3104  Validation loss = 3.4119  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 2.3100  Validation loss = 3.4110  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 2.3099  Validation loss = 3.4106  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 2.3095  Validation loss = 3.4098  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 2.3092  Validation loss = 3.4090  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 2.3089  Validation loss = 3.4087  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 2.3086  Validation loss = 3.4080  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 2.3083  Validation loss = 3.4069  \n",
      "\n",
      "Fold: 13  Epoch: 501  Training loss = 2.3081  Validation loss = 3.4066  \n",
      "\n",
      "Fold: 13  Epoch: 502  Training loss = 2.3078  Validation loss = 3.4057  \n",
      "\n",
      "Fold: 13  Epoch: 503  Training loss = 2.3075  Validation loss = 3.4044  \n",
      "\n",
      "Fold: 13  Epoch: 504  Training loss = 2.3072  Validation loss = 3.4037  \n",
      "\n",
      "Fold: 13  Epoch: 505  Training loss = 2.3067  Validation loss = 3.4023  \n",
      "\n",
      "Fold: 13  Epoch: 506  Training loss = 2.3065  Validation loss = 3.4027  \n",
      "\n",
      "Fold: 13  Epoch: 507  Training loss = 2.3062  Validation loss = 3.4023  \n",
      "\n",
      "Fold: 13  Epoch: 508  Training loss = 2.3056  Validation loss = 3.4016  \n",
      "\n",
      "Fold: 13  Epoch: 509  Training loss = 2.3053  Validation loss = 3.4008  \n",
      "\n",
      "Fold: 13  Epoch: 510  Training loss = 2.3050  Validation loss = 3.3994  \n",
      "\n",
      "Fold: 13  Epoch: 511  Training loss = 2.3047  Validation loss = 3.3985  \n",
      "\n",
      "Fold: 13  Epoch: 512  Training loss = 2.3047  Validation loss = 3.3986  \n",
      "\n",
      "Fold: 13  Epoch: 513  Training loss = 2.3043  Validation loss = 3.3975  \n",
      "\n",
      "Fold: 13  Epoch: 514  Training loss = 2.3040  Validation loss = 3.3960  \n",
      "\n",
      "Fold: 13  Epoch: 515  Training loss = 2.3037  Validation loss = 3.3955  \n",
      "\n",
      "Fold: 13  Epoch: 516  Training loss = 2.3030  Validation loss = 3.3923  \n",
      "\n",
      "Fold: 13  Epoch: 517  Training loss = 2.3027  Validation loss = 3.3912  \n",
      "\n",
      "Fold: 13  Epoch: 518  Training loss = 2.3025  Validation loss = 3.3903  \n",
      "\n",
      "Fold: 13  Epoch: 519  Training loss = 2.3023  Validation loss = 3.3899  \n",
      "\n",
      "Fold: 13  Epoch: 520  Training loss = 2.3020  Validation loss = 3.3885  \n",
      "\n",
      "Fold: 13  Epoch: 521  Training loss = 2.3018  Validation loss = 3.3880  \n",
      "\n",
      "Fold: 13  Epoch: 522  Training loss = 2.3018  Validation loss = 3.3878  \n",
      "\n",
      "Fold: 13  Epoch: 523  Training loss = 2.3015  Validation loss = 3.3866  \n",
      "\n",
      "Fold: 13  Epoch: 524  Training loss = 2.3013  Validation loss = 3.3858  \n",
      "\n",
      "Fold: 13  Epoch: 525  Training loss = 2.3010  Validation loss = 3.3846  \n",
      "\n",
      "Fold: 13  Epoch: 526  Training loss = 2.3009  Validation loss = 3.3846  \n",
      "\n",
      "Fold: 13  Epoch: 527  Training loss = 2.3006  Validation loss = 3.3841  \n",
      "\n",
      "Fold: 13  Epoch: 528  Training loss = 2.3004  Validation loss = 3.3834  \n",
      "\n",
      "Fold: 13  Epoch: 529  Training loss = 2.3002  Validation loss = 3.3821  \n",
      "\n",
      "Fold: 13  Epoch: 530  Training loss = 2.2998  Validation loss = 3.3812  \n",
      "\n",
      "Fold: 13  Epoch: 531  Training loss = 2.2994  Validation loss = 3.3795  \n",
      "\n",
      "Fold: 13  Epoch: 532  Training loss = 2.2993  Validation loss = 3.3788  \n",
      "\n",
      "Fold: 13  Epoch: 533  Training loss = 2.2990  Validation loss = 3.3781  \n",
      "\n",
      "Fold: 13  Epoch: 534  Training loss = 2.2989  Validation loss = 3.3766  \n",
      "\n",
      "Fold: 13  Epoch: 535  Training loss = 2.2987  Validation loss = 3.3763  \n",
      "\n",
      "Fold: 13  Epoch: 536  Training loss = 2.2985  Validation loss = 3.3756  \n",
      "\n",
      "Fold: 13  Epoch: 537  Training loss = 2.2983  Validation loss = 3.3751  \n",
      "\n",
      "Fold: 13  Epoch: 538  Training loss = 2.2979  Validation loss = 3.3739  \n",
      "\n",
      "Fold: 13  Epoch: 539  Training loss = 2.2976  Validation loss = 3.3732  \n",
      "\n",
      "Fold: 13  Epoch: 540  Training loss = 2.2975  Validation loss = 3.3727  \n",
      "\n",
      "Fold: 13  Epoch: 541  Training loss = 2.2973  Validation loss = 3.3721  \n",
      "\n",
      "Fold: 13  Epoch: 542  Training loss = 2.2970  Validation loss = 3.3717  \n",
      "\n",
      "Fold: 13  Epoch: 543  Training loss = 2.2967  Validation loss = 3.3708  \n",
      "\n",
      "Fold: 13  Epoch: 544  Training loss = 2.2963  Validation loss = 3.3692  \n",
      "\n",
      "Fold: 13  Epoch: 545  Training loss = 2.2960  Validation loss = 3.3682  \n",
      "\n",
      "Fold: 13  Epoch: 546  Training loss = 2.2957  Validation loss = 3.3674  \n",
      "\n",
      "Fold: 13  Epoch: 547  Training loss = 2.2955  Validation loss = 3.3668  \n",
      "\n",
      "Fold: 13  Epoch: 548  Training loss = 2.2952  Validation loss = 3.3650  \n",
      "\n",
      "Fold: 13  Epoch: 549  Training loss = 2.2947  Validation loss = 3.3626  \n",
      "\n",
      "Fold: 13  Epoch: 550  Training loss = 2.2947  Validation loss = 3.3635  \n",
      "\n",
      "Fold: 13  Epoch: 551  Training loss = 2.2943  Validation loss = 3.3613  \n",
      "\n",
      "Fold: 13  Epoch: 552  Training loss = 2.2941  Validation loss = 3.3608  \n",
      "\n",
      "Fold: 13  Epoch: 553  Training loss = 2.2940  Validation loss = 3.3608  \n",
      "\n",
      "Fold: 13  Epoch: 554  Training loss = 2.2938  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 13  Epoch: 555  Training loss = 2.2936  Validation loss = 3.3590  \n",
      "\n",
      "Fold: 13  Epoch: 556  Training loss = 2.2933  Validation loss = 3.3578  \n",
      "\n",
      "Fold: 13  Epoch: 557  Training loss = 2.2931  Validation loss = 3.3571  \n",
      "\n",
      "Fold: 13  Epoch: 558  Training loss = 2.2929  Validation loss = 3.3571  \n",
      "\n",
      "Fold: 13  Epoch: 559  Training loss = 2.2928  Validation loss = 3.3569  \n",
      "\n",
      "Fold: 13  Epoch: 560  Training loss = 2.2927  Validation loss = 3.3562  \n",
      "\n",
      "Fold: 13  Epoch: 561  Training loss = 2.2925  Validation loss = 3.3562  \n",
      "\n",
      "Fold: 13  Epoch: 562  Training loss = 2.2923  Validation loss = 3.3558  \n",
      "\n",
      "Fold: 13  Epoch: 563  Training loss = 2.2921  Validation loss = 3.3547  \n",
      "\n",
      "Fold: 13  Epoch: 564  Training loss = 2.2919  Validation loss = 3.3539  \n",
      "\n",
      "Fold: 13  Epoch: 565  Training loss = 2.2917  Validation loss = 3.3535  \n",
      "\n",
      "Fold: 13  Epoch: 566  Training loss = 2.2916  Validation loss = 3.3537  \n",
      "\n",
      "Fold: 13  Epoch: 567  Training loss = 2.2913  Validation loss = 3.3525  \n",
      "\n",
      "Fold: 13  Epoch: 568  Training loss = 2.2911  Validation loss = 3.3523  \n",
      "\n",
      "Fold: 13  Epoch: 569  Training loss = 2.2908  Validation loss = 3.3507  \n",
      "\n",
      "Fold: 13  Epoch: 570  Training loss = 2.2905  Validation loss = 3.3498  \n",
      "\n",
      "Fold: 13  Epoch: 571  Training loss = 2.2903  Validation loss = 3.3490  \n",
      "\n",
      "Fold: 13  Epoch: 572  Training loss = 2.2900  Validation loss = 3.3481  \n",
      "\n",
      "Fold: 13  Epoch: 573  Training loss = 2.2897  Validation loss = 3.3467  \n",
      "\n",
      "Fold: 13  Epoch: 574  Training loss = 2.2895  Validation loss = 3.3458  \n",
      "\n",
      "Fold: 13  Epoch: 575  Training loss = 2.2893  Validation loss = 3.3453  \n",
      "\n",
      "Fold: 13  Epoch: 576  Training loss = 2.2891  Validation loss = 3.3441  \n",
      "\n",
      "Fold: 13  Epoch: 577  Training loss = 2.2888  Validation loss = 3.3431  \n",
      "\n",
      "Fold: 13  Epoch: 578  Training loss = 2.2886  Validation loss = 3.3427  \n",
      "\n",
      "Fold: 13  Epoch: 579  Training loss = 2.2883  Validation loss = 3.3420  \n",
      "\n",
      "Fold: 13  Epoch: 580  Training loss = 2.2880  Validation loss = 3.3412  \n",
      "\n",
      "Fold: 13  Epoch: 581  Training loss = 2.2879  Validation loss = 3.3408  \n",
      "\n",
      "Fold: 13  Epoch: 582  Training loss = 2.2877  Validation loss = 3.3409  \n",
      "\n",
      "Fold: 13  Epoch: 583  Training loss = 2.2876  Validation loss = 3.3411  \n",
      "\n",
      "Fold: 13  Epoch: 584  Training loss = 2.2876  Validation loss = 3.3416  \n",
      "\n",
      "Fold: 13  Epoch: 585  Training loss = 2.2874  Validation loss = 3.3409  \n",
      "\n",
      "Fold: 13  Epoch: 586  Training loss = 2.2872  Validation loss = 3.3404  \n",
      "\n",
      "Fold: 13  Epoch: 587  Training loss = 2.2870  Validation loss = 3.3398  \n",
      "\n",
      "Fold: 13  Epoch: 588  Training loss = 2.2867  Validation loss = 3.3390  \n",
      "\n",
      "Fold: 13  Epoch: 589  Training loss = 2.2865  Validation loss = 3.3381  \n",
      "\n",
      "Fold: 13  Epoch: 590  Training loss = 2.2862  Validation loss = 3.3373  \n",
      "\n",
      "Fold: 13  Epoch: 591  Training loss = 2.2861  Validation loss = 3.3376  \n",
      "\n",
      "Fold: 13  Epoch: 592  Training loss = 2.2861  Validation loss = 3.3378  \n",
      "\n",
      "Fold: 13  Epoch: 593  Training loss = 2.2859  Validation loss = 3.3374  \n",
      "\n",
      "Fold: 13  Epoch: 594  Training loss = 2.2856  Validation loss = 3.3360  \n",
      "\n",
      "Fold: 13  Epoch: 595  Training loss = 2.2858  Validation loss = 3.3359  \n",
      "\n",
      "Fold: 13  Epoch: 596  Training loss = 2.2850  Validation loss = 3.3346  \n",
      "\n",
      "Fold: 13  Epoch: 597  Training loss = 2.2847  Validation loss = 3.3336  \n",
      "\n",
      "Fold: 13  Epoch: 598  Training loss = 2.2844  Validation loss = 3.3330  \n",
      "\n",
      "Fold: 13  Epoch: 599  Training loss = 2.2842  Validation loss = 3.3318  \n",
      "\n",
      "Fold: 13  Epoch: 600  Training loss = 2.2841  Validation loss = 3.3320  \n",
      "\n",
      "Fold: 13  Epoch: 601  Training loss = 2.2839  Validation loss = 3.3308  \n",
      "\n",
      "Fold: 13  Epoch: 602  Training loss = 2.2838  Validation loss = 3.3314  \n",
      "\n",
      "Fold: 13  Epoch: 603  Training loss = 2.2836  Validation loss = 3.3312  \n",
      "\n",
      "Fold: 13  Epoch: 604  Training loss = 2.2834  Validation loss = 3.3303  \n",
      "\n",
      "Fold: 13  Epoch: 605  Training loss = 2.2831  Validation loss = 3.3297  \n",
      "\n",
      "Fold: 13  Epoch: 606  Training loss = 2.2829  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 13  Epoch: 607  Training loss = 2.2827  Validation loss = 3.3285  \n",
      "\n",
      "Fold: 13  Epoch: 608  Training loss = 2.2824  Validation loss = 3.3273  \n",
      "\n",
      "Fold: 13  Epoch: 609  Training loss = 2.2823  Validation loss = 3.3278  \n",
      "\n",
      "Fold: 13  Epoch: 610  Training loss = 2.2822  Validation loss = 3.3275  \n",
      "\n",
      "Fold: 13  Epoch: 611  Training loss = 2.2819  Validation loss = 3.3266  \n",
      "\n",
      "Fold: 13  Epoch: 612  Training loss = 2.2816  Validation loss = 3.3251  \n",
      "\n",
      "Fold: 13  Epoch: 613  Training loss = 2.2814  Validation loss = 3.3245  \n",
      "\n",
      "Fold: 13  Epoch: 614  Training loss = 2.2810  Validation loss = 3.3232  \n",
      "\n",
      "Fold: 13  Epoch: 615  Training loss = 2.2807  Validation loss = 3.3217  \n",
      "\n",
      "Fold: 13  Epoch: 616  Training loss = 2.2805  Validation loss = 3.3213  \n",
      "\n",
      "Fold: 13  Epoch: 617  Training loss = 2.2802  Validation loss = 3.3200  \n",
      "\n",
      "Fold: 13  Epoch: 618  Training loss = 2.2799  Validation loss = 3.3189  \n",
      "\n",
      "Fold: 13  Epoch: 619  Training loss = 2.2797  Validation loss = 3.3187  \n",
      "\n",
      "Fold: 13  Epoch: 620  Training loss = 2.2796  Validation loss = 3.3192  \n",
      "\n",
      "Fold: 13  Epoch: 621  Training loss = 2.2793  Validation loss = 3.3176  \n",
      "\n",
      "Fold: 13  Epoch: 622  Training loss = 2.2792  Validation loss = 3.3174  \n",
      "\n",
      "Fold: 13  Epoch: 623  Training loss = 2.2788  Validation loss = 3.3153  \n",
      "\n",
      "Fold: 13  Epoch: 624  Training loss = 2.2786  Validation loss = 3.3150  \n",
      "\n",
      "Fold: 13  Epoch: 625  Training loss = 2.2785  Validation loss = 3.3146  \n",
      "\n",
      "Fold: 13  Epoch: 626  Training loss = 2.2783  Validation loss = 3.3144  \n",
      "\n",
      "Fold: 13  Epoch: 627  Training loss = 2.2779  Validation loss = 3.3128  \n",
      "\n",
      "Fold: 13  Epoch: 628  Training loss = 2.2776  Validation loss = 3.3114  \n",
      "\n",
      "Fold: 13  Epoch: 629  Training loss = 2.2775  Validation loss = 3.3106  \n",
      "\n",
      "Fold: 13  Epoch: 630  Training loss = 2.2773  Validation loss = 3.3102  \n",
      "\n",
      "Fold: 13  Epoch: 631  Training loss = 2.2770  Validation loss = 3.3094  \n",
      "\n",
      "Fold: 13  Epoch: 632  Training loss = 2.2768  Validation loss = 3.3082  \n",
      "\n",
      "Fold: 13  Epoch: 633  Training loss = 2.2765  Validation loss = 3.3070  \n",
      "\n",
      "Fold: 13  Epoch: 634  Training loss = 2.2763  Validation loss = 3.3074  \n",
      "\n",
      "Fold: 13  Epoch: 635  Training loss = 2.2761  Validation loss = 3.3065  \n",
      "\n",
      "Fold: 13  Epoch: 636  Training loss = 2.2759  Validation loss = 3.3058  \n",
      "\n",
      "Fold: 13  Epoch: 637  Training loss = 2.2756  Validation loss = 3.3049  \n",
      "\n",
      "Fold: 13  Epoch: 638  Training loss = 2.2755  Validation loss = 3.3049  \n",
      "\n",
      "Fold: 13  Epoch: 639  Training loss = 2.2752  Validation loss = 3.3037  \n",
      "\n",
      "Fold: 13  Epoch: 640  Training loss = 2.2751  Validation loss = 3.3028  \n",
      "\n",
      "Fold: 13  Epoch: 641  Training loss = 2.2748  Validation loss = 3.3021  \n",
      "\n",
      "Fold: 13  Epoch: 642  Training loss = 2.2746  Validation loss = 3.3014  \n",
      "\n",
      "Fold: 13  Epoch: 643  Training loss = 2.2743  Validation loss = 3.2999  \n",
      "\n",
      "Fold: 13  Epoch: 644  Training loss = 2.2742  Validation loss = 3.2994  \n",
      "\n",
      "Fold: 13  Epoch: 645  Training loss = 2.2739  Validation loss = 3.2986  \n",
      "\n",
      "Fold: 13  Epoch: 646  Training loss = 2.2736  Validation loss = 3.2968  \n",
      "\n",
      "Fold: 13  Epoch: 647  Training loss = 2.2733  Validation loss = 3.2959  \n",
      "\n",
      "Fold: 13  Epoch: 648  Training loss = 2.2731  Validation loss = 3.2950  \n",
      "\n",
      "Fold: 13  Epoch: 649  Training loss = 2.2730  Validation loss = 3.2948  \n",
      "\n",
      "Fold: 13  Epoch: 650  Training loss = 2.2728  Validation loss = 3.2944  \n",
      "\n",
      "Fold: 13  Epoch: 651  Training loss = 2.2726  Validation loss = 3.2935  \n",
      "\n",
      "Fold: 13  Epoch: 652  Training loss = 2.2725  Validation loss = 3.2934  \n",
      "\n",
      "Fold: 13  Epoch: 653  Training loss = 2.2724  Validation loss = 3.2938  \n",
      "\n",
      "Fold: 13  Epoch: 654  Training loss = 2.2721  Validation loss = 3.2924  \n",
      "\n",
      "Fold: 13  Epoch: 655  Training loss = 2.2718  Validation loss = 3.2906  \n",
      "\n",
      "Fold: 13  Epoch: 656  Training loss = 2.2717  Validation loss = 3.2908  \n",
      "\n",
      "Fold: 13  Epoch: 657  Training loss = 2.2714  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 13  Epoch: 658  Training loss = 2.2713  Validation loss = 3.2895  \n",
      "\n",
      "Fold: 13  Epoch: 659  Training loss = 2.2712  Validation loss = 3.2893  \n",
      "\n",
      "Fold: 13  Epoch: 660  Training loss = 2.2709  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 13  Epoch: 661  Training loss = 2.2706  Validation loss = 3.2876  \n",
      "\n",
      "Fold: 13  Epoch: 662  Training loss = 2.2704  Validation loss = 3.2867  \n",
      "\n",
      "Fold: 13  Epoch: 663  Training loss = 2.2702  Validation loss = 3.2861  \n",
      "\n",
      "Fold: 13  Epoch: 664  Training loss = 2.2699  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 13  Epoch: 665  Training loss = 2.2698  Validation loss = 3.2833  \n",
      "\n",
      "Fold: 13  Epoch: 666  Training loss = 2.2695  Validation loss = 3.2834  \n",
      "\n",
      "Fold: 13  Epoch: 667  Training loss = 2.2694  Validation loss = 3.2836  \n",
      "\n",
      "Fold: 13  Epoch: 668  Training loss = 2.2692  Validation loss = 3.2834  \n",
      "\n",
      "Fold: 13  Epoch: 669  Training loss = 2.2690  Validation loss = 3.2816  \n",
      "\n",
      "Fold: 13  Epoch: 670  Training loss = 2.2689  Validation loss = 3.2815  \n",
      "\n",
      "Fold: 13  Epoch: 671  Training loss = 2.2688  Validation loss = 3.2808  \n",
      "\n",
      "Fold: 13  Epoch: 672  Training loss = 2.2686  Validation loss = 3.2805  \n",
      "\n",
      "Fold: 13  Epoch: 673  Training loss = 2.2685  Validation loss = 3.2807  \n",
      "\n",
      "Fold: 13  Epoch: 674  Training loss = 2.2683  Validation loss = 3.2793  \n",
      "\n",
      "Fold: 13  Epoch: 675  Training loss = 2.2680  Validation loss = 3.2791  \n",
      "\n",
      "Fold: 13  Epoch: 676  Training loss = 2.2677  Validation loss = 3.2777  \n",
      "\n",
      "Fold: 13  Epoch: 677  Training loss = 2.2674  Validation loss = 3.2768  \n",
      "\n",
      "Fold: 13  Epoch: 678  Training loss = 2.2672  Validation loss = 3.2765  \n",
      "\n",
      "Fold: 13  Epoch: 679  Training loss = 2.2671  Validation loss = 3.2762  \n",
      "\n",
      "Fold: 13  Epoch: 680  Training loss = 2.2670  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 13  Epoch: 681  Training loss = 2.2667  Validation loss = 3.2746  \n",
      "\n",
      "Fold: 13  Epoch: 682  Training loss = 2.2664  Validation loss = 3.2735  \n",
      "\n",
      "Fold: 13  Epoch: 683  Training loss = 2.2662  Validation loss = 3.2726  \n",
      "\n",
      "Fold: 13  Epoch: 684  Training loss = 2.2660  Validation loss = 3.2723  \n",
      "\n",
      "Fold: 13  Epoch: 685  Training loss = 2.2659  Validation loss = 3.2722  \n",
      "\n",
      "Fold: 13  Epoch: 686  Training loss = 2.2655  Validation loss = 3.2709  \n",
      "\n",
      "Fold: 13  Epoch: 687  Training loss = 2.2654  Validation loss = 3.2705  \n",
      "\n",
      "Fold: 13  Epoch: 688  Training loss = 2.2652  Validation loss = 3.2705  \n",
      "\n",
      "Fold: 13  Epoch: 689  Training loss = 2.2649  Validation loss = 3.2697  \n",
      "\n",
      "Fold: 13  Epoch: 690  Training loss = 2.2646  Validation loss = 3.2689  \n",
      "\n",
      "Fold: 13  Epoch: 691  Training loss = 2.2645  Validation loss = 3.2688  \n",
      "\n",
      "Fold: 13  Epoch: 692  Training loss = 2.2643  Validation loss = 3.2686  \n",
      "\n",
      "Fold: 13  Epoch: 693  Training loss = 2.2642  Validation loss = 3.2679  \n",
      "\n",
      "Fold: 13  Epoch: 694  Training loss = 2.2640  Validation loss = 3.2676  \n",
      "\n",
      "Fold: 13  Epoch: 695  Training loss = 2.2639  Validation loss = 3.2679  \n",
      "\n",
      "Fold: 13  Epoch: 696  Training loss = 2.2637  Validation loss = 3.2675  \n",
      "\n",
      "Fold: 13  Epoch: 697  Training loss = 2.2636  Validation loss = 3.2678  \n",
      "\n",
      "Fold: 13  Epoch: 698  Training loss = 2.2634  Validation loss = 3.2664  \n",
      "\n",
      "Fold: 13  Epoch: 699  Training loss = 2.2630  Validation loss = 3.2638  \n",
      "\n",
      "Fold: 13  Epoch: 700  Training loss = 2.2628  Validation loss = 3.2636  \n",
      "\n",
      "Fold: 13  Epoch: 701  Training loss = 2.2627  Validation loss = 3.2640  \n",
      "\n",
      "Fold: 13  Epoch: 702  Training loss = 2.2625  Validation loss = 3.2628  \n",
      "\n",
      "Fold: 13  Epoch: 703  Training loss = 2.2621  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 13  Epoch: 704  Training loss = 2.2618  Validation loss = 3.2613  \n",
      "\n",
      "Fold: 13  Epoch: 705  Training loss = 2.2616  Validation loss = 3.2602  \n",
      "\n",
      "Fold: 13  Epoch: 706  Training loss = 2.2614  Validation loss = 3.2594  \n",
      "\n",
      "Fold: 13  Epoch: 707  Training loss = 2.2610  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 13  Epoch: 708  Training loss = 2.2608  Validation loss = 3.2573  \n",
      "\n",
      "Fold: 13  Epoch: 709  Training loss = 2.2606  Validation loss = 3.2567  \n",
      "\n",
      "Fold: 13  Epoch: 710  Training loss = 2.2603  Validation loss = 3.2551  \n",
      "\n",
      "Fold: 13  Epoch: 711  Training loss = 2.2601  Validation loss = 3.2542  \n",
      "\n",
      "Fold: 13  Epoch: 712  Training loss = 2.2597  Validation loss = 3.2532  \n",
      "\n",
      "Fold: 13  Epoch: 713  Training loss = 2.2596  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 13  Epoch: 714  Training loss = 2.2593  Validation loss = 3.2514  \n",
      "\n",
      "Fold: 13  Epoch: 715  Training loss = 2.2590  Validation loss = 3.2500  \n",
      "\n",
      "Fold: 13  Epoch: 716  Training loss = 2.2588  Validation loss = 3.2492  \n",
      "\n",
      "Fold: 13  Epoch: 717  Training loss = 2.2587  Validation loss = 3.2483  \n",
      "\n",
      "Fold: 13  Epoch: 718  Training loss = 2.2585  Validation loss = 3.2487  \n",
      "\n",
      "Fold: 13  Epoch: 719  Training loss = 2.2583  Validation loss = 3.2484  \n",
      "\n",
      "Fold: 13  Epoch: 720  Training loss = 2.2582  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 13  Epoch: 721  Training loss = 2.2578  Validation loss = 3.2468  \n",
      "\n",
      "Fold: 13  Epoch: 722  Training loss = 2.2575  Validation loss = 3.2457  \n",
      "\n",
      "Fold: 13  Epoch: 723  Training loss = 2.2573  Validation loss = 3.2444  \n",
      "\n",
      "Fold: 13  Epoch: 724  Training loss = 2.2570  Validation loss = 3.2432  \n",
      "\n",
      "Fold: 13  Epoch: 725  Training loss = 2.2567  Validation loss = 3.2417  \n",
      "\n",
      "Fold: 13  Epoch: 726  Training loss = 2.2564  Validation loss = 3.2398  \n",
      "\n",
      "Fold: 13  Epoch: 727  Training loss = 2.2562  Validation loss = 3.2388  \n",
      "\n",
      "Fold: 13  Epoch: 728  Training loss = 2.2560  Validation loss = 3.2380  \n",
      "\n",
      "Fold: 13  Epoch: 729  Training loss = 2.2558  Validation loss = 3.2381  \n",
      "\n",
      "Fold: 13  Epoch: 730  Training loss = 2.2555  Validation loss = 3.2370  \n",
      "\n",
      "Fold: 13  Epoch: 731  Training loss = 2.2552  Validation loss = 3.2360  \n",
      "\n",
      "Fold: 13  Epoch: 732  Training loss = 2.2550  Validation loss = 3.2347  \n",
      "\n",
      "Fold: 13  Epoch: 733  Training loss = 2.2549  Validation loss = 3.2341  \n",
      "\n",
      "Fold: 13  Epoch: 734  Training loss = 2.2546  Validation loss = 3.2331  \n",
      "\n",
      "Fold: 13  Epoch: 735  Training loss = 2.2544  Validation loss = 3.2311  \n",
      "\n",
      "Fold: 13  Epoch: 736  Training loss = 2.2542  Validation loss = 3.2300  \n",
      "\n",
      "Fold: 13  Epoch: 737  Training loss = 2.2540  Validation loss = 3.2290  \n",
      "\n",
      "Fold: 13  Epoch: 738  Training loss = 2.2537  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 13  Epoch: 739  Training loss = 2.2536  Validation loss = 3.2281  \n",
      "\n",
      "Fold: 13  Epoch: 740  Training loss = 2.2533  Validation loss = 3.2261  \n",
      "\n",
      "Fold: 13  Epoch: 741  Training loss = 2.2531  Validation loss = 3.2267  \n",
      "\n",
      "Fold: 13  Epoch: 742  Training loss = 2.2530  Validation loss = 3.2258  \n",
      "\n",
      "Fold: 13  Epoch: 743  Training loss = 2.2529  Validation loss = 3.2259  \n",
      "\n",
      "Fold: 13  Epoch: 744  Training loss = 2.2528  Validation loss = 3.2267  \n",
      "\n",
      "Fold: 13  Epoch: 745  Training loss = 2.2525  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 13  Epoch: 746  Training loss = 2.2523  Validation loss = 3.2242  \n",
      "\n",
      "Fold: 13  Epoch: 747  Training loss = 2.2522  Validation loss = 3.2235  \n",
      "\n",
      "Fold: 13  Epoch: 748  Training loss = 2.2519  Validation loss = 3.2225  \n",
      "\n",
      "Fold: 13  Epoch: 749  Training loss = 2.2517  Validation loss = 3.2219  \n",
      "\n",
      "Fold: 13  Epoch: 750  Training loss = 2.2516  Validation loss = 3.2220  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 749  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.3660  Validation loss = 7.1400  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.3657  Validation loss = 7.1392  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.3654  Validation loss = 7.1384  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.3652  Validation loss = 7.1372  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.3649  Validation loss = 7.1365  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.3647  Validation loss = 7.1362  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.3644  Validation loss = 7.1354  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.3640  Validation loss = 7.1341  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.3637  Validation loss = 7.1328  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.3632  Validation loss = 7.1310  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.3628  Validation loss = 7.1295  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.3625  Validation loss = 7.1283  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.3619  Validation loss = 7.1264  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.3614  Validation loss = 7.1246  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.3611  Validation loss = 7.1238  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.3610  Validation loss = 7.1231  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.3607  Validation loss = 7.1221  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 2.3604  Validation loss = 7.1210  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.3601  Validation loss = 7.1195  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.3597  Validation loss = 7.1180  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.3593  Validation loss = 7.1169  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 2.3590  Validation loss = 7.1157  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 2.3586  Validation loss = 7.1144  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 2.3582  Validation loss = 7.1125  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 2.3577  Validation loss = 7.1106  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 2.3573  Validation loss = 7.1087  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 2.3567  Validation loss = 7.1061  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 2.3564  Validation loss = 7.1044  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 2.3561  Validation loss = 7.1036  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.3556  Validation loss = 7.1019  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 2.3552  Validation loss = 7.1008  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 2.3551  Validation loss = 7.1004  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 2.3548  Validation loss = 7.0994  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 2.3548  Validation loss = 7.0995  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 2.3546  Validation loss = 7.0991  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 2.3541  Validation loss = 7.0974  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 2.3537  Validation loss = 7.0960  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 2.3535  Validation loss = 7.0953  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 2.3531  Validation loss = 7.0937  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 2.3527  Validation loss = 7.0923  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 2.3525  Validation loss = 7.0915  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 2.3522  Validation loss = 7.0904  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 2.3519  Validation loss = 7.0893  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 2.3515  Validation loss = 7.0882  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 2.3511  Validation loss = 7.0870  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 2.3508  Validation loss = 7.0863  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 2.3505  Validation loss = 7.0848  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 2.3502  Validation loss = 7.0835  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 2.3498  Validation loss = 7.0818  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 2.3492  Validation loss = 7.0797  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 2.3488  Validation loss = 7.0780  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 2.3485  Validation loss = 7.0775  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 2.3481  Validation loss = 7.0763  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 2.3478  Validation loss = 7.0751  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 2.3474  Validation loss = 7.0734  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 2.3471  Validation loss = 7.0727  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 2.3468  Validation loss = 7.0719  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 2.3465  Validation loss = 7.0708  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 2.3463  Validation loss = 7.0705  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 2.3460  Validation loss = 7.0691  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 2.3456  Validation loss = 7.0676  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 2.3453  Validation loss = 7.0669  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 2.3450  Validation loss = 7.0657  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 2.3448  Validation loss = 7.0650  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 2.3441  Validation loss = 7.0628  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 2.3439  Validation loss = 7.0615  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 2.3435  Validation loss = 7.0603  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 2.3431  Validation loss = 7.0587  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 2.3430  Validation loss = 7.0585  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 2.3427  Validation loss = 7.0578  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 2.3424  Validation loss = 7.0569  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 2.3419  Validation loss = 7.0553  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 2.3419  Validation loss = 7.0549  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 2.3417  Validation loss = 7.0539  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 2.3414  Validation loss = 7.0526  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 2.3410  Validation loss = 7.0517  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 2.3405  Validation loss = 7.0502  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 2.3405  Validation loss = 7.0493  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 2.3400  Validation loss = 7.0485  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 2.3398  Validation loss = 7.0474  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 2.3397  Validation loss = 7.0466  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 2.3394  Validation loss = 7.0461  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 2.3392  Validation loss = 7.0456  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 2.3389  Validation loss = 7.0443  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 2.3385  Validation loss = 7.0427  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 2.3381  Validation loss = 7.0413  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 2.3377  Validation loss = 7.0395  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 2.3373  Validation loss = 7.0379  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 2.3371  Validation loss = 7.0371  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 2.3368  Validation loss = 7.0364  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 2.3366  Validation loss = 7.0356  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 2.3363  Validation loss = 7.0345  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 2.3360  Validation loss = 7.0333  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 2.3357  Validation loss = 7.0324  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 2.3354  Validation loss = 7.0307  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 2.3351  Validation loss = 7.0301  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 2.3348  Validation loss = 7.0287  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 2.3345  Validation loss = 7.0278  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 2.3343  Validation loss = 7.0269  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 2.3339  Validation loss = 7.0259  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 2.3335  Validation loss = 7.0243  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 2.3333  Validation loss = 7.0236  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 2.3329  Validation loss = 7.0220  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 2.3325  Validation loss = 7.0206  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 2.3323  Validation loss = 7.0202  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 2.3322  Validation loss = 7.0200  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 2.3318  Validation loss = 7.0182  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 2.3315  Validation loss = 7.0171  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 2.3312  Validation loss = 7.0161  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 2.3310  Validation loss = 7.0156  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 2.3307  Validation loss = 7.0145  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 2.3304  Validation loss = 7.0130  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 2.3300  Validation loss = 7.0124  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 2.3297  Validation loss = 7.0116  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 2.3295  Validation loss = 7.0103  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 2.3291  Validation loss = 7.0090  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 2.3288  Validation loss = 7.0076  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 2.3285  Validation loss = 7.0069  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 2.3283  Validation loss = 7.0063  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 2.3281  Validation loss = 7.0051  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 2.3279  Validation loss = 7.0049  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 2.3275  Validation loss = 7.0033  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 2.3273  Validation loss = 7.0029  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 2.3269  Validation loss = 7.0010  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 2.3267  Validation loss = 7.0001  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 2.3264  Validation loss = 6.9991  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 2.3263  Validation loss = 6.9986  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 2.3261  Validation loss = 6.9984  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 2.3258  Validation loss = 6.9978  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 2.3257  Validation loss = 6.9975  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 2.3255  Validation loss = 6.9971  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 2.3252  Validation loss = 6.9958  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 2.3247  Validation loss = 6.9940  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 2.3245  Validation loss = 6.9934  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 2.3244  Validation loss = 6.9927  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 2.3240  Validation loss = 6.9913  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 2.3237  Validation loss = 6.9909  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 2.3233  Validation loss = 6.9897  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 2.3229  Validation loss = 6.9887  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 2.3227  Validation loss = 6.9876  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 2.3223  Validation loss = 6.9864  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 2.3220  Validation loss = 6.9853  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 2.3219  Validation loss = 6.9849  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 2.3215  Validation loss = 6.9833  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 2.3212  Validation loss = 6.9819  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 2.3209  Validation loss = 6.9815  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 2.3208  Validation loss = 6.9809  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 2.3205  Validation loss = 6.9799  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 2.3200  Validation loss = 6.9780  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 2.3196  Validation loss = 6.9769  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 2.3193  Validation loss = 6.9756  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 2.3189  Validation loss = 6.9740  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 2.3186  Validation loss = 6.9736  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 2.3183  Validation loss = 6.9721  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 2.3180  Validation loss = 6.9711  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 2.3176  Validation loss = 6.9693  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 2.3173  Validation loss = 6.9682  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 2.3170  Validation loss = 6.9673  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 2.3167  Validation loss = 6.9671  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 2.3164  Validation loss = 6.9661  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 2.3161  Validation loss = 6.9651  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 2.3158  Validation loss = 6.9639  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 2.3155  Validation loss = 6.9625  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 2.3152  Validation loss = 6.9607  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 2.3150  Validation loss = 6.9602  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 2.3148  Validation loss = 6.9590  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 2.3145  Validation loss = 6.9584  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 2.3142  Validation loss = 6.9575  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 2.3138  Validation loss = 6.9560  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 2.3135  Validation loss = 6.9553  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 2.3133  Validation loss = 6.9542  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 2.3130  Validation loss = 6.9533  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 2.3128  Validation loss = 6.9522  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 2.3124  Validation loss = 6.9505  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 2.3122  Validation loss = 6.9498  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 2.3120  Validation loss = 6.9495  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 2.3118  Validation loss = 6.9482  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 2.3113  Validation loss = 6.9469  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 2.3108  Validation loss = 6.9450  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 2.3103  Validation loss = 6.9434  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 2.3100  Validation loss = 6.9420  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 2.3097  Validation loss = 6.9414  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 2.3094  Validation loss = 6.9405  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 2.3092  Validation loss = 6.9399  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 2.3090  Validation loss = 6.9389  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 2.3087  Validation loss = 6.9379  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 2.3084  Validation loss = 6.9365  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 2.3080  Validation loss = 6.9350  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 2.3078  Validation loss = 6.9344  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 2.3074  Validation loss = 6.9325  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 2.3071  Validation loss = 6.9315  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 2.3068  Validation loss = 6.9304  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 2.3068  Validation loss = 6.9296  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 2.3067  Validation loss = 6.9297  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 2.3065  Validation loss = 6.9282  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 2.3062  Validation loss = 6.9281  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 2.3060  Validation loss = 6.9272  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 2.3058  Validation loss = 6.9259  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 2.3056  Validation loss = 6.9252  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 2.3054  Validation loss = 6.9246  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 2.3051  Validation loss = 6.9239  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 2.3048  Validation loss = 6.9224  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 2.3045  Validation loss = 6.9213  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 2.3042  Validation loss = 6.9204  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 2.3039  Validation loss = 6.9189  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 2.3037  Validation loss = 6.9186  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 2.3035  Validation loss = 6.9184  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 2.3032  Validation loss = 6.9180  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 2.3029  Validation loss = 6.9170  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 2.3026  Validation loss = 6.9153  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 2.3023  Validation loss = 6.9141  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 2.3019  Validation loss = 6.9126  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 2.3017  Validation loss = 6.9118  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 2.3017  Validation loss = 6.9120  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 2.3015  Validation loss = 6.9113  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 2.3015  Validation loss = 6.9115  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 2.3011  Validation loss = 6.9105  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 2.3008  Validation loss = 6.9091  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 2.3006  Validation loss = 6.9085  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 2.3003  Validation loss = 6.9073  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 2.3001  Validation loss = 6.9067  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 2.2998  Validation loss = 6.9056  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 2.2996  Validation loss = 6.9053  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 2.2993  Validation loss = 6.9044  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 2.2990  Validation loss = 6.9034  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 2.2987  Validation loss = 6.9015  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 2.2983  Validation loss = 6.9002  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 2.2981  Validation loss = 6.8990  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 2.2976  Validation loss = 6.8975  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 2.2973  Validation loss = 6.8964  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 2.2971  Validation loss = 6.8958  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 2.2969  Validation loss = 6.8948  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 2.2968  Validation loss = 6.8944  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 2.2966  Validation loss = 6.8939  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 2.2966  Validation loss = 6.8942  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 2.2963  Validation loss = 6.8935  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 2.2961  Validation loss = 6.8931  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 2.2959  Validation loss = 6.8922  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 2.2956  Validation loss = 6.8905  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 2.2954  Validation loss = 6.8904  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 2.2951  Validation loss = 6.8895  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 2.2947  Validation loss = 6.8879  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 2.2945  Validation loss = 6.8872  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 2.2942  Validation loss = 6.8864  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 2.2940  Validation loss = 6.8854  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 2.2937  Validation loss = 6.8846  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 2.2932  Validation loss = 6.8826  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 2.2930  Validation loss = 6.8822  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 2.2928  Validation loss = 6.8815  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 2.2924  Validation loss = 6.8793  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 2.2922  Validation loss = 6.8785  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 2.2919  Validation loss = 6.8778  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 2.2918  Validation loss = 6.8774  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 2.2916  Validation loss = 6.8768  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 2.2912  Validation loss = 6.8751  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 2.2910  Validation loss = 6.8742  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 2.2907  Validation loss = 6.8733  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 2.2904  Validation loss = 6.8720  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 2.2900  Validation loss = 6.8703  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 2.2897  Validation loss = 6.8694  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 2.2893  Validation loss = 6.8677  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 2.2891  Validation loss = 6.8661  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 2.2888  Validation loss = 6.8657  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 2.2887  Validation loss = 6.8657  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 2.2884  Validation loss = 6.8646  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 2.2882  Validation loss = 6.8637  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 2.2880  Validation loss = 6.8631  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 2.2878  Validation loss = 6.8620  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 2.2875  Validation loss = 6.8610  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 2.2873  Validation loss = 6.8593  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 2.2869  Validation loss = 6.8582  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 2.2868  Validation loss = 6.8575  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 2.2865  Validation loss = 6.8563  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 2.2861  Validation loss = 6.8552  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 2.2860  Validation loss = 6.8542  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 2.2856  Validation loss = 6.8520  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 2.2854  Validation loss = 6.8520  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 2.2852  Validation loss = 6.8518  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 2.2850  Validation loss = 6.8506  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 2.2849  Validation loss = 6.8503  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 2.2847  Validation loss = 6.8498  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 2.2845  Validation loss = 6.8496  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 2.2843  Validation loss = 6.8485  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 2.2840  Validation loss = 6.8474  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 2.2839  Validation loss = 6.8464  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 2.2834  Validation loss = 6.8447  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 2.2832  Validation loss = 6.8444  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 2.2830  Validation loss = 6.8435  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 2.2826  Validation loss = 6.8415  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 2.2824  Validation loss = 6.8413  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 2.2820  Validation loss = 6.8398  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 2.2819  Validation loss = 6.8395  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 2.2815  Validation loss = 6.8379  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 2.2811  Validation loss = 6.8364  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 2.2807  Validation loss = 6.8348  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 2.2805  Validation loss = 6.8343  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 2.2803  Validation loss = 6.8341  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 2.2800  Validation loss = 6.8328  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 2.2798  Validation loss = 6.8314  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 2.2795  Validation loss = 6.8304  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 2.2795  Validation loss = 6.8301  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 2.2793  Validation loss = 6.8284  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 2.2791  Validation loss = 6.8279  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 2.2788  Validation loss = 6.8266  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 2.2786  Validation loss = 6.8248  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 2.2784  Validation loss = 6.8237  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 2.2781  Validation loss = 6.8224  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 2.2778  Validation loss = 6.8217  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 2.2776  Validation loss = 6.8214  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 2.2774  Validation loss = 6.8207  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 2.2771  Validation loss = 6.8203  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 2.2769  Validation loss = 6.8198  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 2.2765  Validation loss = 6.8182  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 2.2762  Validation loss = 6.8174  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 2.2761  Validation loss = 6.8160  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 2.2758  Validation loss = 6.8141  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 2.2753  Validation loss = 6.8117  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 2.2751  Validation loss = 6.8114  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 2.2747  Validation loss = 6.8102  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 2.2743  Validation loss = 6.8089  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 2.2741  Validation loss = 6.8077  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 2.2740  Validation loss = 6.8080  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 2.2736  Validation loss = 6.8062  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 2.2733  Validation loss = 6.8044  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 2.2730  Validation loss = 6.8037  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 2.2726  Validation loss = 6.8022  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 2.2726  Validation loss = 6.8008  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 2.2723  Validation loss = 6.7995  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 2.2722  Validation loss = 6.7994  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 2.2719  Validation loss = 6.7976  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 2.2717  Validation loss = 6.7972  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 2.2715  Validation loss = 6.7962  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 2.2711  Validation loss = 6.7954  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 2.2710  Validation loss = 6.7953  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 2.2709  Validation loss = 6.7945  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 2.2706  Validation loss = 6.7931  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 2.2705  Validation loss = 6.7932  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 2.2704  Validation loss = 6.7927  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 2.2701  Validation loss = 6.7925  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 2.2701  Validation loss = 6.7914  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 2.2699  Validation loss = 6.7904  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 2.2696  Validation loss = 6.7900  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 2.2696  Validation loss = 6.7901  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 2.2695  Validation loss = 6.7892  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 2.2692  Validation loss = 6.7883  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 2.2690  Validation loss = 6.7878  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 2.2688  Validation loss = 6.7873  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 2.2686  Validation loss = 6.7868  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 2.2685  Validation loss = 6.7857  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 2.2682  Validation loss = 6.7845  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 2.2681  Validation loss = 6.7828  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 2.2674  Validation loss = 6.7822  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 2.2673  Validation loss = 6.7820  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 2.2670  Validation loss = 6.7805  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 2.2670  Validation loss = 6.7792  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 2.2665  Validation loss = 6.7790  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 2.2664  Validation loss = 6.7781  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 2.2663  Validation loss = 6.7775  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 2.2661  Validation loss = 6.7762  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 2.2658  Validation loss = 6.7762  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 2.2656  Validation loss = 6.7746  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 2.2653  Validation loss = 6.7739  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 2.2648  Validation loss = 6.7735  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 2.2645  Validation loss = 6.7727  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 2.2643  Validation loss = 6.7720  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 2.2641  Validation loss = 6.7717  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 2.2639  Validation loss = 6.7710  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 2.2636  Validation loss = 6.7698  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 2.2636  Validation loss = 6.7685  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 2.2633  Validation loss = 6.7671  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 2.2633  Validation loss = 6.7659  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 2.2629  Validation loss = 6.7641  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 2.2626  Validation loss = 6.7637  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 2.2623  Validation loss = 6.7622  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 2.2617  Validation loss = 6.7611  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 2.2614  Validation loss = 6.7603  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 2.2614  Validation loss = 6.7595  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 2.2614  Validation loss = 6.7578  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 2.2608  Validation loss = 6.7575  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 2.2609  Validation loss = 6.7572  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 2.2606  Validation loss = 6.7565  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 2.2606  Validation loss = 6.7555  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 2.2604  Validation loss = 6.7546  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 2.2598  Validation loss = 6.7534  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 2.2596  Validation loss = 6.7520  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 2.2593  Validation loss = 6.7510  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 2.2591  Validation loss = 6.7498  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 2.2590  Validation loss = 6.7492  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 2.2587  Validation loss = 6.7483  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 2.2584  Validation loss = 6.7461  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 2.2582  Validation loss = 6.7457  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 2.2581  Validation loss = 6.7444  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 2.2576  Validation loss = 6.7433  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 2.2575  Validation loss = 6.7432  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 2.2573  Validation loss = 6.7425  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 2.2568  Validation loss = 6.7426  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 2.2564  Validation loss = 6.7412  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 2.2562  Validation loss = 6.7410  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 2.2559  Validation loss = 6.7402  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 2.2557  Validation loss = 6.7396  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 2.2556  Validation loss = 6.7396  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 2.2553  Validation loss = 6.7385  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 2.2550  Validation loss = 6.7373  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 2.2550  Validation loss = 6.7355  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 2.2550  Validation loss = 6.7347  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 2.2546  Validation loss = 6.7337  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 2.2541  Validation loss = 6.7319  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 2.2538  Validation loss = 6.7321  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 2.2534  Validation loss = 6.7318  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 2.2532  Validation loss = 6.7308  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 2.2531  Validation loss = 6.7305  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 2.2531  Validation loss = 6.7292  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 2.2528  Validation loss = 6.7288  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 2.2528  Validation loss = 6.7286  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 2.2524  Validation loss = 6.7282  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 2.2522  Validation loss = 6.7274  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 2.2521  Validation loss = 6.7270  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 2.2517  Validation loss = 6.7252  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 2.2516  Validation loss = 6.7248  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 2.2514  Validation loss = 6.7241  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 2.2513  Validation loss = 6.7239  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 2.2511  Validation loss = 6.7226  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 2.2510  Validation loss = 6.7218  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 2.2505  Validation loss = 6.7212  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 2.2506  Validation loss = 6.7214  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 2.2501  Validation loss = 6.7210  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 2.2498  Validation loss = 6.7201  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 2.2498  Validation loss = 6.7186  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 2.2495  Validation loss = 6.7179  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 2.2489  Validation loss = 6.7173  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 2.2485  Validation loss = 6.7158  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 2.2482  Validation loss = 6.7136  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 2.2481  Validation loss = 6.7121  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 2.2482  Validation loss = 6.7109  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 2.2483  Validation loss = 6.7091  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 2.2478  Validation loss = 6.7084  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 2.2474  Validation loss = 6.7079  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 2.2468  Validation loss = 6.7072  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 2.2469  Validation loss = 6.7056  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 2.2469  Validation loss = 6.7042  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 2.2463  Validation loss = 6.7034  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 2.2462  Validation loss = 6.7033  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 2.2457  Validation loss = 6.7028  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 2.2451  Validation loss = 6.7016  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 2.2450  Validation loss = 6.7010  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 2.2445  Validation loss = 6.7003  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 2.2443  Validation loss = 6.6990  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 2.2442  Validation loss = 6.6975  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 2.2438  Validation loss = 6.6963  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 2.2435  Validation loss = 6.6956  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 2.2433  Validation loss = 6.6954  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 2.2432  Validation loss = 6.6946  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 2.2429  Validation loss = 6.6936  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 2.2425  Validation loss = 6.6927  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 2.2422  Validation loss = 6.6924  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 2.2421  Validation loss = 6.6922  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 2.2418  Validation loss = 6.6920  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 2.2415  Validation loss = 6.6910  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 2.2414  Validation loss = 6.6908  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 2.2411  Validation loss = 6.6907  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 2.2409  Validation loss = 6.6892  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 2.2405  Validation loss = 6.6880  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 2.2403  Validation loss = 6.6875  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 2.2403  Validation loss = 6.6875  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 2.2401  Validation loss = 6.6871  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 2.2400  Validation loss = 6.6862  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 2.2396  Validation loss = 6.6855  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 2.2392  Validation loss = 6.6844  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 2.2389  Validation loss = 6.6833  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 2.2388  Validation loss = 6.6825  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 2.2384  Validation loss = 6.6810  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 2.2382  Validation loss = 6.6797  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 2.2380  Validation loss = 6.6798  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 2.2377  Validation loss = 6.6790  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 2.2375  Validation loss = 6.6783  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 2.2371  Validation loss = 6.6768  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 2.2368  Validation loss = 6.6758  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 2.2366  Validation loss = 6.6742  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 2.2363  Validation loss = 6.6735  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 2.2362  Validation loss = 6.6731  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 2.2360  Validation loss = 6.6730  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 2.2356  Validation loss = 6.6725  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 2.2355  Validation loss = 6.6718  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 2.2351  Validation loss = 6.6703  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 2.2348  Validation loss = 6.6687  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 2.2348  Validation loss = 6.6680  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 2.2348  Validation loss = 6.6678  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 2.2342  Validation loss = 6.6669  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 2.2339  Validation loss = 6.6659  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 2.2335  Validation loss = 6.6640  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 2.2333  Validation loss = 6.6634  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 2.2331  Validation loss = 6.6633  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 2.2332  Validation loss = 6.6625  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 2.2331  Validation loss = 6.6611  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 2.2328  Validation loss = 6.6609  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 2.2327  Validation loss = 6.6597  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 2.2324  Validation loss = 6.6584  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 2.2318  Validation loss = 6.6584  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 2.2315  Validation loss = 6.6574  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 2.2313  Validation loss = 6.6570  \n",
      "\n",
      "Fold: 14  Epoch: 501  Training loss = 2.2311  Validation loss = 6.6559  \n",
      "\n",
      "Fold: 14  Epoch: 502  Training loss = 2.2309  Validation loss = 6.6558  \n",
      "\n",
      "Fold: 14  Epoch: 503  Training loss = 2.2306  Validation loss = 6.6538  \n",
      "\n",
      "Fold: 14  Epoch: 504  Training loss = 2.2304  Validation loss = 6.6534  \n",
      "\n",
      "Fold: 14  Epoch: 505  Training loss = 2.2301  Validation loss = 6.6525  \n",
      "\n",
      "Fold: 14  Epoch: 506  Training loss = 2.2300  Validation loss = 6.6529  \n",
      "\n",
      "Fold: 14  Epoch: 507  Training loss = 2.2299  Validation loss = 6.6518  \n",
      "\n",
      "Fold: 14  Epoch: 508  Training loss = 2.2296  Validation loss = 6.6503  \n",
      "\n",
      "Fold: 14  Epoch: 509  Training loss = 2.2295  Validation loss = 6.6497  \n",
      "\n",
      "Fold: 14  Epoch: 510  Training loss = 2.2293  Validation loss = 6.6497  \n",
      "\n",
      "Fold: 14  Epoch: 511  Training loss = 2.2289  Validation loss = 6.6492  \n",
      "\n",
      "Fold: 14  Epoch: 512  Training loss = 2.2286  Validation loss = 6.6486  \n",
      "\n",
      "Fold: 14  Epoch: 513  Training loss = 2.2281  Validation loss = 6.6475  \n",
      "\n",
      "Fold: 14  Epoch: 514  Training loss = 2.2281  Validation loss = 6.6469  \n",
      "\n",
      "Fold: 14  Epoch: 515  Training loss = 2.2277  Validation loss = 6.6461  \n",
      "\n",
      "Fold: 14  Epoch: 516  Training loss = 2.2278  Validation loss = 6.6457  \n",
      "\n",
      "Fold: 14  Epoch: 517  Training loss = 2.2277  Validation loss = 6.6451  \n",
      "\n",
      "Fold: 14  Epoch: 518  Training loss = 2.2270  Validation loss = 6.6437  \n",
      "\n",
      "Fold: 14  Epoch: 519  Training loss = 2.2267  Validation loss = 6.6430  \n",
      "\n",
      "Fold: 14  Epoch: 520  Training loss = 2.2265  Validation loss = 6.6427  \n",
      "\n",
      "Fold: 14  Epoch: 521  Training loss = 2.2263  Validation loss = 6.6419  \n",
      "\n",
      "Fold: 14  Epoch: 522  Training loss = 2.2261  Validation loss = 6.6407  \n",
      "\n",
      "Fold: 14  Epoch: 523  Training loss = 2.2260  Validation loss = 6.6400  \n",
      "\n",
      "Fold: 14  Epoch: 524  Training loss = 2.2257  Validation loss = 6.6387  \n",
      "\n",
      "Fold: 14  Epoch: 525  Training loss = 2.2256  Validation loss = 6.6379  \n",
      "\n",
      "Fold: 14  Epoch: 526  Training loss = 2.2254  Validation loss = 6.6370  \n",
      "\n",
      "Fold: 14  Epoch: 527  Training loss = 2.2252  Validation loss = 6.6371  \n",
      "\n",
      "Fold: 14  Epoch: 528  Training loss = 2.2249  Validation loss = 6.6366  \n",
      "\n",
      "Fold: 14  Epoch: 529  Training loss = 2.2246  Validation loss = 6.6363  \n",
      "\n",
      "Fold: 14  Epoch: 530  Training loss = 2.2244  Validation loss = 6.6357  \n",
      "\n",
      "Fold: 14  Epoch: 531  Training loss = 2.2242  Validation loss = 6.6353  \n",
      "\n",
      "Fold: 14  Epoch: 532  Training loss = 2.2240  Validation loss = 6.6347  \n",
      "\n",
      "Fold: 14  Epoch: 533  Training loss = 2.2237  Validation loss = 6.6334  \n",
      "\n",
      "Fold: 14  Epoch: 534  Training loss = 2.2234  Validation loss = 6.6331  \n",
      "\n",
      "Fold: 14  Epoch: 535  Training loss = 2.2234  Validation loss = 6.6325  \n",
      "\n",
      "Fold: 14  Epoch: 536  Training loss = 2.2231  Validation loss = 6.6311  \n",
      "\n",
      "Fold: 14  Epoch: 537  Training loss = 2.2230  Validation loss = 6.6311  \n",
      "\n",
      "Fold: 14  Epoch: 538  Training loss = 2.2229  Validation loss = 6.6310  \n",
      "\n",
      "Fold: 14  Epoch: 539  Training loss = 2.2223  Validation loss = 6.6293  \n",
      "\n",
      "Fold: 14  Epoch: 540  Training loss = 2.2221  Validation loss = 6.6293  \n",
      "\n",
      "Fold: 14  Epoch: 541  Training loss = 2.2222  Validation loss = 6.6286  \n",
      "\n",
      "Fold: 14  Epoch: 542  Training loss = 2.2218  Validation loss = 6.6283  \n",
      "\n",
      "Fold: 14  Epoch: 543  Training loss = 2.2217  Validation loss = 6.6285  \n",
      "\n",
      "Fold: 14  Epoch: 544  Training loss = 2.2215  Validation loss = 6.6287  \n",
      "\n",
      "Fold: 14  Epoch: 545  Training loss = 2.2214  Validation loss = 6.6285  \n",
      "\n",
      "Fold: 14  Epoch: 546  Training loss = 2.2211  Validation loss = 6.6283  \n",
      "\n",
      "Fold: 14  Epoch: 547  Training loss = 2.2207  Validation loss = 6.6269  \n",
      "\n",
      "Fold: 14  Epoch: 548  Training loss = 2.2204  Validation loss = 6.6257  \n",
      "\n",
      "Fold: 14  Epoch: 549  Training loss = 2.2203  Validation loss = 6.6251  \n",
      "\n",
      "Fold: 14  Epoch: 550  Training loss = 2.2200  Validation loss = 6.6243  \n",
      "\n",
      "Fold: 14  Epoch: 551  Training loss = 2.2196  Validation loss = 6.6233  \n",
      "\n",
      "Fold: 14  Epoch: 552  Training loss = 2.2191  Validation loss = 6.6222  \n",
      "\n",
      "Fold: 14  Epoch: 553  Training loss = 2.2190  Validation loss = 6.6216  \n",
      "\n",
      "Fold: 14  Epoch: 554  Training loss = 2.2186  Validation loss = 6.6205  \n",
      "\n",
      "Fold: 14  Epoch: 555  Training loss = 2.2179  Validation loss = 6.6182  \n",
      "\n",
      "Fold: 14  Epoch: 556  Training loss = 2.2175  Validation loss = 6.6172  \n",
      "\n",
      "Fold: 14  Epoch: 557  Training loss = 2.2173  Validation loss = 6.6160  \n",
      "\n",
      "Fold: 14  Epoch: 558  Training loss = 2.2171  Validation loss = 6.6151  \n",
      "\n",
      "Fold: 14  Epoch: 559  Training loss = 2.2168  Validation loss = 6.6148  \n",
      "\n",
      "Fold: 14  Epoch: 560  Training loss = 2.2166  Validation loss = 6.6130  \n",
      "\n",
      "Fold: 14  Epoch: 561  Training loss = 2.2163  Validation loss = 6.6129  \n",
      "\n",
      "Fold: 14  Epoch: 562  Training loss = 2.2159  Validation loss = 6.6113  \n",
      "\n",
      "Fold: 14  Epoch: 563  Training loss = 2.2158  Validation loss = 6.6105  \n",
      "\n",
      "Fold: 14  Epoch: 564  Training loss = 2.2156  Validation loss = 6.6090  \n",
      "\n",
      "Fold: 14  Epoch: 565  Training loss = 2.2153  Validation loss = 6.6078  \n",
      "\n",
      "Fold: 14  Epoch: 566  Training loss = 2.2151  Validation loss = 6.6079  \n",
      "\n",
      "Fold: 14  Epoch: 567  Training loss = 2.2153  Validation loss = 6.6067  \n",
      "\n",
      "Fold: 14  Epoch: 568  Training loss = 2.2153  Validation loss = 6.6057  \n",
      "\n",
      "Fold: 14  Epoch: 569  Training loss = 2.2150  Validation loss = 6.6052  \n",
      "\n",
      "Fold: 14  Epoch: 570  Training loss = 2.2147  Validation loss = 6.6048  \n",
      "\n",
      "Fold: 14  Epoch: 571  Training loss = 2.2145  Validation loss = 6.6036  \n",
      "\n",
      "Fold: 14  Epoch: 572  Training loss = 2.2143  Validation loss = 6.6034  \n",
      "\n",
      "Fold: 14  Epoch: 573  Training loss = 2.2139  Validation loss = 6.6026  \n",
      "\n",
      "Fold: 14  Epoch: 574  Training loss = 2.2137  Validation loss = 6.6021  \n",
      "\n",
      "Fold: 14  Epoch: 575  Training loss = 2.2132  Validation loss = 6.6014  \n",
      "\n",
      "Fold: 14  Epoch: 576  Training loss = 2.2132  Validation loss = 6.6012  \n",
      "\n",
      "Fold: 14  Epoch: 577  Training loss = 2.2128  Validation loss = 6.6005  \n",
      "\n",
      "Fold: 14  Epoch: 578  Training loss = 2.2129  Validation loss = 6.5992  \n",
      "\n",
      "Fold: 14  Epoch: 579  Training loss = 2.2129  Validation loss = 6.5983  \n",
      "\n",
      "Fold: 14  Epoch: 580  Training loss = 2.2127  Validation loss = 6.5988  \n",
      "\n",
      "Fold: 14  Epoch: 581  Training loss = 2.2120  Validation loss = 6.5983  \n",
      "\n",
      "Fold: 14  Epoch: 582  Training loss = 2.2118  Validation loss = 6.5975  \n",
      "\n",
      "Fold: 14  Epoch: 583  Training loss = 2.2115  Validation loss = 6.5971  \n",
      "\n",
      "Fold: 14  Epoch: 584  Training loss = 2.2117  Validation loss = 6.5971  \n",
      "\n",
      "Fold: 14  Epoch: 585  Training loss = 2.2117  Validation loss = 6.5962  \n",
      "\n",
      "Fold: 14  Epoch: 586  Training loss = 2.2114  Validation loss = 6.5950  \n",
      "\n",
      "Fold: 14  Epoch: 587  Training loss = 2.2107  Validation loss = 6.5941  \n",
      "\n",
      "Fold: 14  Epoch: 588  Training loss = 2.2103  Validation loss = 6.5934  \n",
      "\n",
      "Fold: 14  Epoch: 589  Training loss = 2.2101  Validation loss = 6.5932  \n",
      "\n",
      "Fold: 14  Epoch: 590  Training loss = 2.2099  Validation loss = 6.5933  \n",
      "\n",
      "Fold: 14  Epoch: 591  Training loss = 2.2097  Validation loss = 6.5918  \n",
      "\n",
      "Fold: 14  Epoch: 592  Training loss = 2.2094  Validation loss = 6.5912  \n",
      "\n",
      "Fold: 14  Epoch: 593  Training loss = 2.2091  Validation loss = 6.5900  \n",
      "\n",
      "Fold: 14  Epoch: 594  Training loss = 2.2088  Validation loss = 6.5887  \n",
      "\n",
      "Fold: 14  Epoch: 595  Training loss = 2.2087  Validation loss = 6.5883  \n",
      "\n",
      "Fold: 14  Epoch: 596  Training loss = 2.2085  Validation loss = 6.5870  \n",
      "\n",
      "Fold: 14  Epoch: 597  Training loss = 2.2086  Validation loss = 6.5861  \n",
      "\n",
      "Fold: 14  Epoch: 598  Training loss = 2.2082  Validation loss = 6.5849  \n",
      "\n",
      "Fold: 14  Epoch: 599  Training loss = 2.2077  Validation loss = 6.5836  \n",
      "\n",
      "Fold: 14  Epoch: 600  Training loss = 2.2076  Validation loss = 6.5830  \n",
      "\n",
      "Fold: 14  Epoch: 601  Training loss = 2.2075  Validation loss = 6.5823  \n",
      "\n",
      "Fold: 14  Epoch: 602  Training loss = 2.2070  Validation loss = 6.5822  \n",
      "\n",
      "Fold: 14  Epoch: 603  Training loss = 2.2069  Validation loss = 6.5814  \n",
      "\n",
      "Fold: 14  Epoch: 604  Training loss = 2.2065  Validation loss = 6.5809  \n",
      "\n",
      "Fold: 14  Epoch: 605  Training loss = 2.2064  Validation loss = 6.5789  \n",
      "\n",
      "Fold: 14  Epoch: 606  Training loss = 2.2065  Validation loss = 6.5777  \n",
      "\n",
      "Fold: 14  Epoch: 607  Training loss = 2.2060  Validation loss = 6.5772  \n",
      "\n",
      "Fold: 14  Epoch: 608  Training loss = 2.2059  Validation loss = 6.5761  \n",
      "\n",
      "Fold: 14  Epoch: 609  Training loss = 2.2058  Validation loss = 6.5759  \n",
      "\n",
      "Fold: 14  Epoch: 610  Training loss = 2.2053  Validation loss = 6.5754  \n",
      "\n",
      "Fold: 14  Epoch: 611  Training loss = 2.2051  Validation loss = 6.5738  \n",
      "\n",
      "Fold: 14  Epoch: 612  Training loss = 2.2050  Validation loss = 6.5725  \n",
      "\n",
      "Fold: 14  Epoch: 613  Training loss = 2.2049  Validation loss = 6.5719  \n",
      "\n",
      "Fold: 14  Epoch: 614  Training loss = 2.2044  Validation loss = 6.5709  \n",
      "\n",
      "Fold: 14  Epoch: 615  Training loss = 2.2041  Validation loss = 6.5700  \n",
      "\n",
      "Fold: 14  Epoch: 616  Training loss = 2.2035  Validation loss = 6.5687  \n",
      "\n",
      "Fold: 14  Epoch: 617  Training loss = 2.2032  Validation loss = 6.5679  \n",
      "\n",
      "Fold: 14  Epoch: 618  Training loss = 2.2030  Validation loss = 6.5672  \n",
      "\n",
      "Fold: 14  Epoch: 619  Training loss = 2.2028  Validation loss = 6.5667  \n",
      "\n",
      "Fold: 14  Epoch: 620  Training loss = 2.2024  Validation loss = 6.5654  \n",
      "\n",
      "Fold: 14  Epoch: 621  Training loss = 2.2021  Validation loss = 6.5643  \n",
      "\n",
      "Fold: 14  Epoch: 622  Training loss = 2.2017  Validation loss = 6.5621  \n",
      "\n",
      "Fold: 14  Epoch: 623  Training loss = 2.2014  Validation loss = 6.5609  \n",
      "\n",
      "Fold: 14  Epoch: 624  Training loss = 2.2014  Validation loss = 6.5604  \n",
      "\n",
      "Fold: 14  Epoch: 625  Training loss = 2.2013  Validation loss = 6.5593  \n",
      "\n",
      "Fold: 14  Epoch: 626  Training loss = 2.2008  Validation loss = 6.5589  \n",
      "\n",
      "Fold: 14  Epoch: 627  Training loss = 2.2004  Validation loss = 6.5582  \n",
      "\n",
      "Fold: 14  Epoch: 628  Training loss = 2.2003  Validation loss = 6.5575  \n",
      "\n",
      "Fold: 14  Epoch: 629  Training loss = 2.2001  Validation loss = 6.5564  \n",
      "\n",
      "Fold: 14  Epoch: 630  Training loss = 2.1999  Validation loss = 6.5558  \n",
      "\n",
      "Fold: 14  Epoch: 631  Training loss = 2.1997  Validation loss = 6.5548  \n",
      "\n",
      "Fold: 14  Epoch: 632  Training loss = 2.1994  Validation loss = 6.5534  \n",
      "\n",
      "Fold: 14  Epoch: 633  Training loss = 2.1992  Validation loss = 6.5523  \n",
      "\n",
      "Fold: 14  Epoch: 634  Training loss = 2.1988  Validation loss = 6.5511  \n",
      "\n",
      "Fold: 14  Epoch: 635  Training loss = 2.1984  Validation loss = 6.5500  \n",
      "\n",
      "Fold: 14  Epoch: 636  Training loss = 2.1982  Validation loss = 6.5495  \n",
      "\n",
      "Fold: 14  Epoch: 637  Training loss = 2.1982  Validation loss = 6.5484  \n",
      "\n",
      "Fold: 14  Epoch: 638  Training loss = 2.1979  Validation loss = 6.5477  \n",
      "\n",
      "Fold: 14  Epoch: 639  Training loss = 2.1977  Validation loss = 6.5472  \n",
      "\n",
      "Fold: 14  Epoch: 640  Training loss = 2.1974  Validation loss = 6.5459  \n",
      "\n",
      "Fold: 14  Epoch: 641  Training loss = 2.1970  Validation loss = 6.5465  \n",
      "\n",
      "Fold: 14  Epoch: 642  Training loss = 2.1967  Validation loss = 6.5467  \n",
      "\n",
      "Fold: 14  Epoch: 643  Training loss = 2.1964  Validation loss = 6.5451  \n",
      "\n",
      "Fold: 14  Epoch: 644  Training loss = 2.1962  Validation loss = 6.5434  \n",
      "\n",
      "Fold: 14  Epoch: 645  Training loss = 2.1958  Validation loss = 6.5430  \n",
      "\n",
      "Fold: 14  Epoch: 646  Training loss = 2.1954  Validation loss = 6.5418  \n",
      "\n",
      "Fold: 14  Epoch: 647  Training loss = 2.1949  Validation loss = 6.5403  \n",
      "\n",
      "Fold: 14  Epoch: 648  Training loss = 2.1946  Validation loss = 6.5398  \n",
      "\n",
      "Fold: 14  Epoch: 649  Training loss = 2.1942  Validation loss = 6.5386  \n",
      "\n",
      "Fold: 14  Epoch: 650  Training loss = 2.1940  Validation loss = 6.5383  \n",
      "\n",
      "Fold: 14  Epoch: 651  Training loss = 2.1937  Validation loss = 6.5374  \n",
      "\n",
      "Fold: 14  Epoch: 652  Training loss = 2.1936  Validation loss = 6.5367  \n",
      "\n",
      "Fold: 14  Epoch: 653  Training loss = 2.1933  Validation loss = 6.5356  \n",
      "\n",
      "Fold: 14  Epoch: 654  Training loss = 2.1935  Validation loss = 6.5344  \n",
      "\n",
      "Fold: 14  Epoch: 655  Training loss = 2.1932  Validation loss = 6.5335  \n",
      "\n",
      "Fold: 14  Epoch: 656  Training loss = 2.1927  Validation loss = 6.5322  \n",
      "\n",
      "Fold: 14  Epoch: 657  Training loss = 2.1923  Validation loss = 6.5319  \n",
      "\n",
      "Fold: 14  Epoch: 658  Training loss = 2.1921  Validation loss = 6.5319  \n",
      "\n",
      "Fold: 14  Epoch: 659  Training loss = 2.1917  Validation loss = 6.5312  \n",
      "\n",
      "Fold: 14  Epoch: 660  Training loss = 2.1916  Validation loss = 6.5302  \n",
      "\n",
      "Fold: 14  Epoch: 661  Training loss = 2.1912  Validation loss = 6.5296  \n",
      "\n",
      "Fold: 14  Epoch: 662  Training loss = 2.1911  Validation loss = 6.5297  \n",
      "\n",
      "Fold: 14  Epoch: 663  Training loss = 2.1916  Validation loss = 6.5300  \n",
      "\n",
      "Fold: 14  Epoch: 664  Training loss = 2.1909  Validation loss = 6.5291  \n",
      "\n",
      "Fold: 14  Epoch: 665  Training loss = 2.1904  Validation loss = 6.5278  \n",
      "\n",
      "Fold: 14  Epoch: 666  Training loss = 2.1900  Validation loss = 6.5266  \n",
      "\n",
      "Fold: 14  Epoch: 667  Training loss = 2.1897  Validation loss = 6.5256  \n",
      "\n",
      "Fold: 14  Epoch: 668  Training loss = 2.1895  Validation loss = 6.5247  \n",
      "\n",
      "Fold: 14  Epoch: 669  Training loss = 2.1892  Validation loss = 6.5232  \n",
      "\n",
      "Fold: 14  Epoch: 670  Training loss = 2.1890  Validation loss = 6.5228  \n",
      "\n",
      "Fold: 14  Epoch: 671  Training loss = 2.1890  Validation loss = 6.5214  \n",
      "\n",
      "Fold: 14  Epoch: 672  Training loss = 2.1886  Validation loss = 6.5204  \n",
      "\n",
      "Fold: 14  Epoch: 673  Training loss = 2.1884  Validation loss = 6.5192  \n",
      "\n",
      "Fold: 14  Epoch: 674  Training loss = 2.1882  Validation loss = 6.5177  \n",
      "\n",
      "Fold: 14  Epoch: 675  Training loss = 2.1877  Validation loss = 6.5177  \n",
      "\n",
      "Fold: 14  Epoch: 676  Training loss = 2.1876  Validation loss = 6.5169  \n",
      "\n",
      "Fold: 14  Epoch: 677  Training loss = 2.1872  Validation loss = 6.5172  \n",
      "\n",
      "Fold: 14  Epoch: 678  Training loss = 2.1870  Validation loss = 6.5172  \n",
      "\n",
      "Fold: 14  Epoch: 679  Training loss = 2.1868  Validation loss = 6.5162  \n",
      "\n",
      "Fold: 14  Epoch: 680  Training loss = 2.1866  Validation loss = 6.5157  \n",
      "\n",
      "Fold: 14  Epoch: 681  Training loss = 2.1867  Validation loss = 6.5148  \n",
      "\n",
      "Fold: 14  Epoch: 682  Training loss = 2.1862  Validation loss = 6.5140  \n",
      "\n",
      "Fold: 14  Epoch: 683  Training loss = 2.1861  Validation loss = 6.5140  \n",
      "\n",
      "Fold: 14  Epoch: 684  Training loss = 2.1857  Validation loss = 6.5134  \n",
      "\n",
      "Fold: 14  Epoch: 685  Training loss = 2.1856  Validation loss = 6.5132  \n",
      "\n",
      "Fold: 14  Epoch: 686  Training loss = 2.1853  Validation loss = 6.5128  \n",
      "\n",
      "Fold: 14  Epoch: 687  Training loss = 2.1850  Validation loss = 6.5125  \n",
      "\n",
      "Fold: 14  Epoch: 688  Training loss = 2.1847  Validation loss = 6.5115  \n",
      "\n",
      "Fold: 14  Epoch: 689  Training loss = 2.1846  Validation loss = 6.5112  \n",
      "\n",
      "Fold: 14  Epoch: 690  Training loss = 2.1842  Validation loss = 6.5101  \n",
      "\n",
      "Fold: 14  Epoch: 691  Training loss = 2.1837  Validation loss = 6.5089  \n",
      "\n",
      "Fold: 14  Epoch: 692  Training loss = 2.1835  Validation loss = 6.5070  \n",
      "\n",
      "Fold: 14  Epoch: 693  Training loss = 2.1836  Validation loss = 6.5066  \n",
      "\n",
      "Fold: 14  Epoch: 694  Training loss = 2.1836  Validation loss = 6.5065  \n",
      "\n",
      "Fold: 14  Epoch: 695  Training loss = 2.1833  Validation loss = 6.5047  \n",
      "\n",
      "Fold: 14  Epoch: 696  Training loss = 2.1829  Validation loss = 6.5044  \n",
      "\n",
      "Fold: 14  Epoch: 697  Training loss = 2.1826  Validation loss = 6.5034  \n",
      "\n",
      "Fold: 14  Epoch: 698  Training loss = 2.1824  Validation loss = 6.5029  \n",
      "\n",
      "Fold: 14  Epoch: 699  Training loss = 2.1822  Validation loss = 6.5020  \n",
      "\n",
      "Fold: 14  Epoch: 700  Training loss = 2.1819  Validation loss = 6.5016  \n",
      "\n",
      "Fold: 14  Epoch: 701  Training loss = 2.1815  Validation loss = 6.5006  \n",
      "\n",
      "Fold: 14  Epoch: 702  Training loss = 2.1813  Validation loss = 6.5002  \n",
      "\n",
      "Fold: 14  Epoch: 703  Training loss = 2.1811  Validation loss = 6.4989  \n",
      "\n",
      "Fold: 14  Epoch: 704  Training loss = 2.1808  Validation loss = 6.4981  \n",
      "\n",
      "Fold: 14  Epoch: 705  Training loss = 2.1806  Validation loss = 6.4971  \n",
      "\n",
      "Fold: 14  Epoch: 706  Training loss = 2.1804  Validation loss = 6.4960  \n",
      "\n",
      "Fold: 14  Epoch: 707  Training loss = 2.1800  Validation loss = 6.4948  \n",
      "\n",
      "Fold: 14  Epoch: 708  Training loss = 2.1798  Validation loss = 6.4947  \n",
      "\n",
      "Fold: 14  Epoch: 709  Training loss = 2.1795  Validation loss = 6.4934  \n",
      "\n",
      "Fold: 14  Epoch: 710  Training loss = 2.1794  Validation loss = 6.4933  \n",
      "\n",
      "Fold: 14  Epoch: 711  Training loss = 2.1791  Validation loss = 6.4917  \n",
      "\n",
      "Fold: 14  Epoch: 712  Training loss = 2.1790  Validation loss = 6.4914  \n",
      "\n",
      "Fold: 14  Epoch: 713  Training loss = 2.1789  Validation loss = 6.4915  \n",
      "\n",
      "Fold: 14  Epoch: 714  Training loss = 2.1789  Validation loss = 6.4910  \n",
      "\n",
      "Fold: 14  Epoch: 715  Training loss = 2.1786  Validation loss = 6.4903  \n",
      "\n",
      "Fold: 14  Epoch: 716  Training loss = 2.1782  Validation loss = 6.4896  \n",
      "\n",
      "Fold: 14  Epoch: 717  Training loss = 2.1777  Validation loss = 6.4886  \n",
      "\n",
      "Fold: 14  Epoch: 718  Training loss = 2.1774  Validation loss = 6.4882  \n",
      "\n",
      "Fold: 14  Epoch: 719  Training loss = 2.1772  Validation loss = 6.4870  \n",
      "\n",
      "Fold: 14  Epoch: 720  Training loss = 2.1768  Validation loss = 6.4857  \n",
      "\n",
      "Fold: 14  Epoch: 721  Training loss = 2.1764  Validation loss = 6.4845  \n",
      "\n",
      "Fold: 14  Epoch: 722  Training loss = 2.1761  Validation loss = 6.4841  \n",
      "\n",
      "Fold: 14  Epoch: 723  Training loss = 2.1761  Validation loss = 6.4839  \n",
      "\n",
      "Fold: 14  Epoch: 724  Training loss = 2.1759  Validation loss = 6.4834  \n",
      "\n",
      "Fold: 14  Epoch: 725  Training loss = 2.1755  Validation loss = 6.4828  \n",
      "\n",
      "Fold: 14  Epoch: 726  Training loss = 2.1753  Validation loss = 6.4819  \n",
      "\n",
      "Fold: 14  Epoch: 727  Training loss = 2.1751  Validation loss = 6.4808  \n",
      "\n",
      "Fold: 14  Epoch: 728  Training loss = 2.1749  Validation loss = 6.4807  \n",
      "\n",
      "Fold: 14  Epoch: 729  Training loss = 2.1747  Validation loss = 6.4802  \n",
      "\n",
      "Fold: 14  Epoch: 730  Training loss = 2.1746  Validation loss = 6.4798  \n",
      "\n",
      "Fold: 14  Epoch: 731  Training loss = 2.1743  Validation loss = 6.4788  \n",
      "\n",
      "Fold: 14  Epoch: 732  Training loss = 2.1740  Validation loss = 6.4771  \n",
      "\n",
      "Fold: 14  Epoch: 733  Training loss = 2.1738  Validation loss = 6.4765  \n",
      "\n",
      "Fold: 14  Epoch: 734  Training loss = 2.1735  Validation loss = 6.4758  \n",
      "\n",
      "Fold: 14  Epoch: 735  Training loss = 2.1733  Validation loss = 6.4759  \n",
      "\n",
      "Fold: 14  Epoch: 736  Training loss = 2.1733  Validation loss = 6.4759  \n",
      "\n",
      "Fold: 14  Epoch: 737  Training loss = 2.1729  Validation loss = 6.4747  \n",
      "\n",
      "Fold: 14  Epoch: 738  Training loss = 2.1726  Validation loss = 6.4734  \n",
      "\n",
      "Fold: 14  Epoch: 739  Training loss = 2.1723  Validation loss = 6.4717  \n",
      "\n",
      "Fold: 14  Epoch: 740  Training loss = 2.1720  Validation loss = 6.4708  \n",
      "\n",
      "Fold: 14  Epoch: 741  Training loss = 2.1719  Validation loss = 6.4704  \n",
      "\n",
      "Fold: 14  Epoch: 742  Training loss = 2.1715  Validation loss = 6.4689  \n",
      "\n",
      "Fold: 14  Epoch: 743  Training loss = 2.1713  Validation loss = 6.4670  \n",
      "\n",
      "Fold: 14  Epoch: 744  Training loss = 2.1711  Validation loss = 6.4662  \n",
      "\n",
      "Fold: 14  Epoch: 745  Training loss = 2.1707  Validation loss = 6.4655  \n",
      "\n",
      "Fold: 14  Epoch: 746  Training loss = 2.1706  Validation loss = 6.4644  \n",
      "\n",
      "Fold: 14  Epoch: 747  Training loss = 2.1700  Validation loss = 6.4628  \n",
      "\n",
      "Fold: 14  Epoch: 748  Training loss = 2.1697  Validation loss = 6.4625  \n",
      "\n",
      "Fold: 14  Epoch: 749  Training loss = 2.1695  Validation loss = 6.4612  \n",
      "\n",
      "Fold: 14  Epoch: 750  Training loss = 2.1691  Validation loss = 6.4596  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 750  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.6772  Validation loss = 7.2923  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.6767  Validation loss = 7.2906  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.6761  Validation loss = 7.2893  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.6756  Validation loss = 7.2882  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.6748  Validation loss = 7.2867  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.6741  Validation loss = 7.2853  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.6735  Validation loss = 7.2842  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.6732  Validation loss = 7.2836  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.6728  Validation loss = 7.2829  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.6720  Validation loss = 7.2809  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.6716  Validation loss = 7.2801  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.6711  Validation loss = 7.2789  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.6703  Validation loss = 7.2771  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.6696  Validation loss = 7.2751  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.6691  Validation loss = 7.2731  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.6685  Validation loss = 7.2721  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.6685  Validation loss = 7.2708  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.6676  Validation loss = 7.2699  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.6671  Validation loss = 7.2695  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.6665  Validation loss = 7.2684  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.6662  Validation loss = 7.2671  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.6657  Validation loss = 7.2657  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.6650  Validation loss = 7.2644  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.6643  Validation loss = 7.2632  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.6635  Validation loss = 7.2620  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 2.6631  Validation loss = 7.2606  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.6625  Validation loss = 7.2597  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 2.6623  Validation loss = 7.2588  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 2.6617  Validation loss = 7.2574  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 2.6609  Validation loss = 7.2565  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 2.6598  Validation loss = 7.2538  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.6594  Validation loss = 7.2519  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 2.6586  Validation loss = 7.2507  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 2.6583  Validation loss = 7.2493  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 2.6579  Validation loss = 7.2488  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 2.6576  Validation loss = 7.2469  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 2.6572  Validation loss = 7.2457  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 2.6565  Validation loss = 7.2446  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 2.6561  Validation loss = 7.2435  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 2.6550  Validation loss = 7.2411  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 2.6541  Validation loss = 7.2402  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 2.6533  Validation loss = 7.2382  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 2.6527  Validation loss = 7.2367  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 2.6520  Validation loss = 7.2349  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 2.6514  Validation loss = 7.2324  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 2.6515  Validation loss = 7.2310  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 2.6502  Validation loss = 7.2300  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 2.6497  Validation loss = 7.2290  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 2.6486  Validation loss = 7.2277  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 2.6478  Validation loss = 7.2263  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 2.6473  Validation loss = 7.2255  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 2.6470  Validation loss = 7.2253  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 2.6462  Validation loss = 7.2235  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 2.6452  Validation loss = 7.2216  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 2.6445  Validation loss = 7.2202  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 2.6440  Validation loss = 7.2182  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 2.6434  Validation loss = 7.2169  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 2.6429  Validation loss = 7.2164  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 2.6426  Validation loss = 7.2157  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 2.6419  Validation loss = 7.2141  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 2.6417  Validation loss = 7.2123  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 2.6405  Validation loss = 7.2095  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 2.6397  Validation loss = 7.2085  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 2.6395  Validation loss = 7.2075  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 2.6391  Validation loss = 7.2070  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 2.6384  Validation loss = 7.2054  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 2.6379  Validation loss = 7.2048  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 2.6374  Validation loss = 7.2045  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 2.6369  Validation loss = 7.2037  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 2.6366  Validation loss = 7.2029  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 2.6357  Validation loss = 7.2012  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 2.6351  Validation loss = 7.1998  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 2.6347  Validation loss = 7.1986  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 2.6341  Validation loss = 7.1975  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 2.6336  Validation loss = 7.1969  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 2.6330  Validation loss = 7.1955  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 2.6327  Validation loss = 7.1952  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 2.6323  Validation loss = 7.1941  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 2.6319  Validation loss = 7.1936  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 2.6312  Validation loss = 7.1918  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 2.6307  Validation loss = 7.1904  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 2.6304  Validation loss = 7.1883  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 2.6299  Validation loss = 7.1870  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 2.6290  Validation loss = 7.1860  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 2.6284  Validation loss = 7.1845  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 2.6281  Validation loss = 7.1836  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 2.6274  Validation loss = 7.1819  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 2.6272  Validation loss = 7.1808  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 2.6265  Validation loss = 7.1793  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 2.6260  Validation loss = 7.1786  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 2.6252  Validation loss = 7.1780  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 2.6244  Validation loss = 7.1764  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 2.6238  Validation loss = 7.1746  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 2.6230  Validation loss = 7.1733  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 2.6224  Validation loss = 7.1711  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 2.6222  Validation loss = 7.1690  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 2.6218  Validation loss = 7.1674  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 2.6211  Validation loss = 7.1661  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 2.6201  Validation loss = 7.1650  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 2.6192  Validation loss = 7.1640  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 2.6192  Validation loss = 7.1634  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 2.6188  Validation loss = 7.1613  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 2.6182  Validation loss = 7.1594  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 2.6175  Validation loss = 7.1581  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 2.6171  Validation loss = 7.1577  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 2.6164  Validation loss = 7.1558  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 2.6156  Validation loss = 7.1548  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 2.6152  Validation loss = 7.1523  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 2.6151  Validation loss = 7.1511  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 2.6146  Validation loss = 7.1503  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 2.6150  Validation loss = 7.1486  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 2.6138  Validation loss = 7.1476  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 2.6129  Validation loss = 7.1465  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 2.6120  Validation loss = 7.1440  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 2.6112  Validation loss = 7.1427  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 2.6107  Validation loss = 7.1409  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 2.6100  Validation loss = 7.1390  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 2.6092  Validation loss = 7.1386  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 2.6087  Validation loss = 7.1383  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 2.6081  Validation loss = 7.1376  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 2.6078  Validation loss = 7.1360  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 2.6069  Validation loss = 7.1342  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 2.6063  Validation loss = 7.1330  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 2.6054  Validation loss = 7.1305  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 2.6048  Validation loss = 7.1299  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 2.6041  Validation loss = 7.1290  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 2.6035  Validation loss = 7.1276  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 2.6030  Validation loss = 7.1272  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 2.6026  Validation loss = 7.1264  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 2.6018  Validation loss = 7.1246  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 2.6013  Validation loss = 7.1233  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 2.6011  Validation loss = 7.1238  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 2.6007  Validation loss = 7.1221  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 2.6001  Validation loss = 7.1218  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 2.5995  Validation loss = 7.1211  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 2.5992  Validation loss = 7.1208  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 2.5987  Validation loss = 7.1199  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 2.5978  Validation loss = 7.1174  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 2.5975  Validation loss = 7.1168  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 2.5970  Validation loss = 7.1159  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 2.5961  Validation loss = 7.1133  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 2.5953  Validation loss = 7.1113  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 2.5944  Validation loss = 7.1088  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 2.5940  Validation loss = 7.1078  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 2.5933  Validation loss = 7.1058  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 2.5930  Validation loss = 7.1051  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 2.5923  Validation loss = 7.1040  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 2.5920  Validation loss = 7.1043  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 2.5915  Validation loss = 7.1029  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 2.5911  Validation loss = 7.1022  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 2.5904  Validation loss = 7.1000  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 2.5899  Validation loss = 7.0988  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 2.5895  Validation loss = 7.0979  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 2.5890  Validation loss = 7.0970  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 2.5886  Validation loss = 7.0954  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 2.5878  Validation loss = 7.0932  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 2.5877  Validation loss = 7.0929  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 2.5872  Validation loss = 7.0923  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 2.5868  Validation loss = 7.0926  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 2.5859  Validation loss = 7.0915  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 2.5853  Validation loss = 7.0902  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 2.5846  Validation loss = 7.0886  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 2.5842  Validation loss = 7.0869  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 2.5838  Validation loss = 7.0884  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 2.5834  Validation loss = 7.0876  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 2.5826  Validation loss = 7.0864  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 2.5823  Validation loss = 7.0866  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 2.5818  Validation loss = 7.0854  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 2.5811  Validation loss = 7.0835  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 2.5807  Validation loss = 7.0841  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 2.5802  Validation loss = 7.0828  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 2.5797  Validation loss = 7.0814  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 2.5793  Validation loss = 7.0804  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 2.5788  Validation loss = 7.0789  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 2.5783  Validation loss = 7.0775  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 2.5776  Validation loss = 7.0744  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 2.5771  Validation loss = 7.0735  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 2.5763  Validation loss = 7.0715  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 2.5757  Validation loss = 7.0716  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 2.5754  Validation loss = 7.0718  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 2.5748  Validation loss = 7.0695  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 2.5743  Validation loss = 7.0683  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 2.5739  Validation loss = 7.0687  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 2.5730  Validation loss = 7.0641  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 2.5726  Validation loss = 7.0639  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 2.5723  Validation loss = 7.0639  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 2.5720  Validation loss = 7.0653  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 2.5712  Validation loss = 7.0619  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 2.5707  Validation loss = 7.0612  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 2.5700  Validation loss = 7.0607  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 2.5696  Validation loss = 7.0604  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 2.5690  Validation loss = 7.0581  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 2.5685  Validation loss = 7.0582  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 2.5680  Validation loss = 7.0576  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 2.5674  Validation loss = 7.0563  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 2.5670  Validation loss = 7.0549  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 2.5668  Validation loss = 7.0552  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 2.5663  Validation loss = 7.0534  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 2.5654  Validation loss = 7.0523  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 2.5648  Validation loss = 7.0516  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 2.5643  Validation loss = 7.0497  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 2.5641  Validation loss = 7.0485  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 2.5632  Validation loss = 7.0451  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 2.5626  Validation loss = 7.0446  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 2.5621  Validation loss = 7.0454  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 2.5615  Validation loss = 7.0441  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 2.5614  Validation loss = 7.0421  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 2.5609  Validation loss = 7.0410  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 2.5604  Validation loss = 7.0405  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 2.5597  Validation loss = 7.0420  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 2.5591  Validation loss = 7.0441  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 2.5586  Validation loss = 7.0435  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 2.5581  Validation loss = 7.0436  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 2.5576  Validation loss = 7.0435  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 2.5570  Validation loss = 7.0438  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 2.5565  Validation loss = 7.0440  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 2.5556  Validation loss = 7.0409  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 2.5550  Validation loss = 7.0394  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 2.5545  Validation loss = 7.0396  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 2.5540  Validation loss = 7.0374  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 2.5538  Validation loss = 7.0389  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 2.5531  Validation loss = 7.0352  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 2.5528  Validation loss = 7.0369  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 2.5524  Validation loss = 7.0385  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 2.5521  Validation loss = 7.0391  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 2.5518  Validation loss = 7.0389  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 2.5511  Validation loss = 7.0363  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 2.5507  Validation loss = 7.0354  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 2.5500  Validation loss = 7.0352  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 2.5497  Validation loss = 7.0341  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 2.5493  Validation loss = 7.0353  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 2.5488  Validation loss = 7.0353  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 2.5484  Validation loss = 7.0348  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 2.5479  Validation loss = 7.0327  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 2.5474  Validation loss = 7.0335  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 2.5471  Validation loss = 7.0333  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 2.5466  Validation loss = 7.0319  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 2.5463  Validation loss = 7.0303  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 2.5460  Validation loss = 7.0284  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 2.5454  Validation loss = 7.0292  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 2.5446  Validation loss = 7.0301  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 2.5442  Validation loss = 7.0311  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 2.5438  Validation loss = 7.0298  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 2.5434  Validation loss = 7.0291  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 2.5430  Validation loss = 7.0301  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 2.5423  Validation loss = 7.0282  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 2.5417  Validation loss = 7.0270  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 2.5413  Validation loss = 7.0243  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 2.5411  Validation loss = 7.0231  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 2.5407  Validation loss = 7.0223  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 2.5408  Validation loss = 7.0184  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 2.5398  Validation loss = 7.0180  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 2.5394  Validation loss = 7.0174  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 2.5384  Validation loss = 7.0180  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 2.5380  Validation loss = 7.0169  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 2.5375  Validation loss = 7.0150  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 2.5372  Validation loss = 7.0147  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 2.5369  Validation loss = 7.0151  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 2.5364  Validation loss = 7.0153  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 2.5360  Validation loss = 7.0165  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 2.5355  Validation loss = 7.0157  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 2.5347  Validation loss = 7.0161  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 2.5342  Validation loss = 7.0136  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 2.5337  Validation loss = 7.0149  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 2.5333  Validation loss = 7.0130  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 2.5327  Validation loss = 7.0107  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 2.5320  Validation loss = 7.0095  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 2.5313  Validation loss = 7.0093  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 2.5310  Validation loss = 7.0072  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 2.5307  Validation loss = 7.0063  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 2.5298  Validation loss = 7.0029  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 2.5291  Validation loss = 7.0024  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 2.5288  Validation loss = 7.0044  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 2.5283  Validation loss = 7.0041  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 2.5277  Validation loss = 7.0026  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 2.5274  Validation loss = 7.0043  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 2.5265  Validation loss = 7.0029  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 2.5256  Validation loss = 7.0000  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 2.5255  Validation loss = 7.0019  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 2.5250  Validation loss = 7.0023  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 2.5240  Validation loss = 6.9987  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 2.5237  Validation loss = 6.9984  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 2.5229  Validation loss = 6.9964  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 2.5225  Validation loss = 6.9948  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 2.5221  Validation loss = 6.9933  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 2.5216  Validation loss = 6.9920  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 2.5213  Validation loss = 6.9911  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 2.5211  Validation loss = 6.9904  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 2.5207  Validation loss = 6.9890  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 2.5204  Validation loss = 6.9891  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 2.5198  Validation loss = 6.9868  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 2.5193  Validation loss = 6.9837  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 2.5186  Validation loss = 6.9836  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 2.5184  Validation loss = 6.9847  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 2.5179  Validation loss = 6.9835  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 2.5174  Validation loss = 6.9801  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 2.5167  Validation loss = 6.9821  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 2.5162  Validation loss = 6.9830  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 2.5159  Validation loss = 6.9823  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 2.5154  Validation loss = 6.9812  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 2.5152  Validation loss = 6.9812  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 2.5143  Validation loss = 6.9796  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 2.5141  Validation loss = 6.9800  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 2.5139  Validation loss = 6.9802  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 2.5134  Validation loss = 6.9792  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 2.5127  Validation loss = 6.9767  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 2.5123  Validation loss = 6.9744  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 2.5116  Validation loss = 6.9740  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 2.5109  Validation loss = 6.9725  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 2.5101  Validation loss = 6.9710  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 2.5095  Validation loss = 6.9699  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 2.5092  Validation loss = 6.9684  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 2.5086  Validation loss = 6.9676  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 2.5082  Validation loss = 6.9666  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 2.5079  Validation loss = 6.9675  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 2.5075  Validation loss = 6.9672  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 2.5073  Validation loss = 6.9682  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 2.5068  Validation loss = 6.9664  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 2.5062  Validation loss = 6.9643  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 2.5055  Validation loss = 6.9633  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 2.5048  Validation loss = 6.9633  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 2.5044  Validation loss = 6.9621  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 2.5042  Validation loss = 6.9615  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 2.5033  Validation loss = 6.9591  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 2.5031  Validation loss = 6.9590  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 2.5025  Validation loss = 6.9579  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 2.5018  Validation loss = 6.9546  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 2.5015  Validation loss = 6.9544  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 2.5008  Validation loss = 6.9521  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 2.5002  Validation loss = 6.9512  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 2.4996  Validation loss = 6.9503  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 2.4993  Validation loss = 6.9494  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 2.4987  Validation loss = 6.9470  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 2.4985  Validation loss = 6.9466  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 2.4984  Validation loss = 6.9466  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 2.4982  Validation loss = 6.9464  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 2.4976  Validation loss = 6.9450  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 2.4974  Validation loss = 6.9443  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 2.4964  Validation loss = 6.9428  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 2.4959  Validation loss = 6.9416  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 2.4959  Validation loss = 6.9424  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 2.4949  Validation loss = 6.9398  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 2.4944  Validation loss = 6.9392  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 2.4934  Validation loss = 6.9370  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 2.4928  Validation loss = 6.9364  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 2.4925  Validation loss = 6.9355  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 2.4917  Validation loss = 6.9329  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 2.4913  Validation loss = 6.9318  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 2.4910  Validation loss = 6.9322  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 2.4905  Validation loss = 6.9318  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 2.4900  Validation loss = 6.9302  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 2.4896  Validation loss = 6.9291  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 2.4893  Validation loss = 6.9293  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 2.4886  Validation loss = 6.9275  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 2.4880  Validation loss = 6.9266  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 2.4875  Validation loss = 6.9257  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 2.4869  Validation loss = 6.9252  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 2.4865  Validation loss = 6.9254  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 2.4856  Validation loss = 6.9236  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 2.4850  Validation loss = 6.9223  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 2.4846  Validation loss = 6.9202  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 2.4844  Validation loss = 6.9197  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 2.4838  Validation loss = 6.9191  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 2.4834  Validation loss = 6.9176  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 2.4826  Validation loss = 6.9159  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 2.4822  Validation loss = 6.9157  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 2.4815  Validation loss = 6.9139  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 2.4807  Validation loss = 6.9113  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 2.4801  Validation loss = 6.9091  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 2.4799  Validation loss = 6.9077  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 2.4792  Validation loss = 6.9074  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 2.4786  Validation loss = 6.9061  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 2.4782  Validation loss = 6.9042  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 2.4782  Validation loss = 6.9035  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 2.4778  Validation loss = 6.9027  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 2.4773  Validation loss = 6.9015  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 2.4768  Validation loss = 6.9030  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 2.4760  Validation loss = 6.9023  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 2.4757  Validation loss = 6.9008  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 2.4754  Validation loss = 6.8991  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 2.4747  Validation loss = 6.8980  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 2.4742  Validation loss = 6.8971  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 2.4735  Validation loss = 6.8978  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 2.4734  Validation loss = 6.8968  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 2.4730  Validation loss = 6.8952  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 2.4721  Validation loss = 6.8955  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 2.4715  Validation loss = 6.8934  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 2.4711  Validation loss = 6.8923  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 2.4708  Validation loss = 6.8918  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 2.4704  Validation loss = 6.8906  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 2.4703  Validation loss = 6.8908  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 2.4697  Validation loss = 6.8900  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 2.4694  Validation loss = 6.8901  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 2.4688  Validation loss = 6.8884  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 2.4685  Validation loss = 6.8869  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 2.4686  Validation loss = 6.8869  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 2.4681  Validation loss = 6.8857  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 2.4675  Validation loss = 6.8842  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 2.4667  Validation loss = 6.8839  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 2.4667  Validation loss = 6.8838  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 2.4658  Validation loss = 6.8819  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 2.4653  Validation loss = 6.8813  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 2.4645  Validation loss = 6.8799  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 2.4641  Validation loss = 6.8791  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 2.4634  Validation loss = 6.8770  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 2.4631  Validation loss = 6.8760  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 2.4628  Validation loss = 6.8751  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 2.4622  Validation loss = 6.8732  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 2.4618  Validation loss = 6.8725  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 2.4612  Validation loss = 6.8714  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 2.4607  Validation loss = 6.8710  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 2.4601  Validation loss = 6.8686  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 2.4596  Validation loss = 6.8680  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 2.4590  Validation loss = 6.8666  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 2.4587  Validation loss = 6.8657  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 2.4582  Validation loss = 6.8647  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 2.4578  Validation loss = 6.8639  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 2.4572  Validation loss = 6.8618  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 2.4566  Validation loss = 6.8609  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 2.4563  Validation loss = 6.8600  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 2.4561  Validation loss = 6.8598  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 2.4557  Validation loss = 6.8594  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 2.4555  Validation loss = 6.8590  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 2.4551  Validation loss = 6.8575  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 2.4550  Validation loss = 6.8570  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 2.4543  Validation loss = 6.8549  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 2.4538  Validation loss = 6.8541  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 2.4537  Validation loss = 6.8530  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 2.4534  Validation loss = 6.8532  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 2.4528  Validation loss = 6.8521  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 2.4523  Validation loss = 6.8502  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 2.4520  Validation loss = 6.8498  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 2.4517  Validation loss = 6.8489  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 2.4515  Validation loss = 6.8491  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 2.4512  Validation loss = 6.8480  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 2.4507  Validation loss = 6.8472  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 2.4505  Validation loss = 6.8472  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 2.4501  Validation loss = 6.8461  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 2.4499  Validation loss = 6.8455  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 2.4491  Validation loss = 6.8433  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 2.4486  Validation loss = 6.8420  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 2.4479  Validation loss = 6.8397  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 2.4474  Validation loss = 6.8387  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 2.4469  Validation loss = 6.8379  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 2.4463  Validation loss = 6.8369  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 2.4459  Validation loss = 6.8361  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 2.4457  Validation loss = 6.8356  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 2.4453  Validation loss = 6.8346  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 2.4447  Validation loss = 6.8334  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 2.4443  Validation loss = 6.8324  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 2.4440  Validation loss = 6.8317  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 2.4438  Validation loss = 6.8318  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 2.4432  Validation loss = 6.8298  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 2.4426  Validation loss = 6.8273  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 2.4422  Validation loss = 6.8263  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 2.4416  Validation loss = 6.8240  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 2.4410  Validation loss = 6.8219  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 2.4406  Validation loss = 6.8211  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 2.4401  Validation loss = 6.8205  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 2.4397  Validation loss = 6.8194  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 2.4394  Validation loss = 6.8179  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 2.4389  Validation loss = 6.8157  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 2.4388  Validation loss = 6.8150  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 2.4382  Validation loss = 6.8134  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 2.4378  Validation loss = 6.8120  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 2.4373  Validation loss = 6.8111  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 2.4371  Validation loss = 6.8102  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 2.4366  Validation loss = 6.8083  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 2.4361  Validation loss = 6.8086  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 2.4356  Validation loss = 6.8075  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 2.4349  Validation loss = 6.8073  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 2.4344  Validation loss = 6.8063  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 2.4339  Validation loss = 6.8044  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 2.4335  Validation loss = 6.8033  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 2.4334  Validation loss = 6.8022  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 2.4331  Validation loss = 6.8004  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 2.4330  Validation loss = 6.7992  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 2.4328  Validation loss = 6.7991  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 2.4327  Validation loss = 6.7966  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 2.4319  Validation loss = 6.7964  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 2.4311  Validation loss = 6.7968  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 2.4308  Validation loss = 6.7953  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 2.4308  Validation loss = 6.7947  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 2.4303  Validation loss = 6.7949  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 2.4299  Validation loss = 6.7934  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 2.4293  Validation loss = 6.7933  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 2.4291  Validation loss = 6.7936  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 2.4288  Validation loss = 6.7930  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 2.4284  Validation loss = 6.7907  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 2.4278  Validation loss = 6.7898  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 2.4276  Validation loss = 6.7886  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 2.4273  Validation loss = 6.7879  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 2.4271  Validation loss = 6.7878  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 2.4263  Validation loss = 6.7859  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 2.4259  Validation loss = 6.7842  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 2.4254  Validation loss = 6.7834  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 2.4249  Validation loss = 6.7820  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 2.4245  Validation loss = 6.7805  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 2.4240  Validation loss = 6.7796  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 2.4237  Validation loss = 6.7788  \n",
      "\n",
      "Fold: 15  Epoch: 501  Training loss = 2.4234  Validation loss = 6.7778  \n",
      "\n",
      "Fold: 15  Epoch: 502  Training loss = 2.4230  Validation loss = 6.7775  \n",
      "\n",
      "Fold: 15  Epoch: 503  Training loss = 2.4226  Validation loss = 6.7767  \n",
      "\n",
      "Fold: 15  Epoch: 504  Training loss = 2.4219  Validation loss = 6.7747  \n",
      "\n",
      "Fold: 15  Epoch: 505  Training loss = 2.4215  Validation loss = 6.7737  \n",
      "\n",
      "Fold: 15  Epoch: 506  Training loss = 2.4211  Validation loss = 6.7726  \n",
      "\n",
      "Fold: 15  Epoch: 507  Training loss = 2.4206  Validation loss = 6.7707  \n",
      "\n",
      "Fold: 15  Epoch: 508  Training loss = 2.4201  Validation loss = 6.7693  \n",
      "\n",
      "Fold: 15  Epoch: 509  Training loss = 2.4196  Validation loss = 6.7679  \n",
      "\n",
      "Fold: 15  Epoch: 510  Training loss = 2.4192  Validation loss = 6.7669  \n",
      "\n",
      "Fold: 15  Epoch: 511  Training loss = 2.4193  Validation loss = 6.7675  \n",
      "\n",
      "Fold: 15  Epoch: 512  Training loss = 2.4190  Validation loss = 6.7668  \n",
      "\n",
      "Fold: 15  Epoch: 513  Training loss = 2.4184  Validation loss = 6.7655  \n",
      "\n",
      "Fold: 15  Epoch: 514  Training loss = 2.4178  Validation loss = 6.7633  \n",
      "\n",
      "Fold: 15  Epoch: 515  Training loss = 2.4175  Validation loss = 6.7634  \n",
      "\n",
      "Fold: 15  Epoch: 516  Training loss = 2.4174  Validation loss = 6.7625  \n",
      "\n",
      "Fold: 15  Epoch: 517  Training loss = 2.4172  Validation loss = 6.7617  \n",
      "\n",
      "Fold: 15  Epoch: 518  Training loss = 2.4174  Validation loss = 6.7613  \n",
      "\n",
      "Fold: 15  Epoch: 519  Training loss = 2.4171  Validation loss = 6.7597  \n",
      "\n",
      "Fold: 15  Epoch: 520  Training loss = 2.4171  Validation loss = 6.7598  \n",
      "\n",
      "Fold: 15  Epoch: 521  Training loss = 2.4164  Validation loss = 6.7578  \n",
      "\n",
      "Fold: 15  Epoch: 522  Training loss = 2.4160  Validation loss = 6.7566  \n",
      "\n",
      "Fold: 15  Epoch: 523  Training loss = 2.4160  Validation loss = 6.7561  \n",
      "\n",
      "Fold: 15  Epoch: 524  Training loss = 2.4155  Validation loss = 6.7556  \n",
      "\n",
      "Fold: 15  Epoch: 525  Training loss = 2.4141  Validation loss = 6.7542  \n",
      "\n",
      "Fold: 15  Epoch: 526  Training loss = 2.4139  Validation loss = 6.7533  \n",
      "\n",
      "Fold: 15  Epoch: 527  Training loss = 2.4138  Validation loss = 6.7526  \n",
      "\n",
      "Fold: 15  Epoch: 528  Training loss = 2.4127  Validation loss = 6.7511  \n",
      "\n",
      "Fold: 15  Epoch: 529  Training loss = 2.4129  Validation loss = 6.7511  \n",
      "\n",
      "Fold: 15  Epoch: 530  Training loss = 2.4122  Validation loss = 6.7496  \n",
      "\n",
      "Fold: 15  Epoch: 531  Training loss = 2.4121  Validation loss = 6.7486  \n",
      "\n",
      "Fold: 15  Epoch: 532  Training loss = 2.4121  Validation loss = 6.7487  \n",
      "\n",
      "Fold: 15  Epoch: 533  Training loss = 2.4113  Validation loss = 6.7474  \n",
      "\n",
      "Fold: 15  Epoch: 534  Training loss = 2.4109  Validation loss = 6.7463  \n",
      "\n",
      "Fold: 15  Epoch: 535  Training loss = 2.4104  Validation loss = 6.7433  \n",
      "\n",
      "Fold: 15  Epoch: 536  Training loss = 2.4103  Validation loss = 6.7424  \n",
      "\n",
      "Fold: 15  Epoch: 537  Training loss = 2.4113  Validation loss = 6.7433  \n",
      "\n",
      "Fold: 15  Epoch: 538  Training loss = 2.4106  Validation loss = 6.7429  \n",
      "\n",
      "Fold: 15  Epoch: 539  Training loss = 2.4104  Validation loss = 6.7416  \n",
      "\n",
      "Fold: 15  Epoch: 540  Training loss = 2.4093  Validation loss = 6.7394  \n",
      "\n",
      "Fold: 15  Epoch: 541  Training loss = 2.4086  Validation loss = 6.7375  \n",
      "\n",
      "Fold: 15  Epoch: 542  Training loss = 2.4079  Validation loss = 6.7344  \n",
      "\n",
      "Fold: 15  Epoch: 543  Training loss = 2.4073  Validation loss = 6.7324  \n",
      "\n",
      "Fold: 15  Epoch: 544  Training loss = 2.4064  Validation loss = 6.7301  \n",
      "\n",
      "Fold: 15  Epoch: 545  Training loss = 2.4061  Validation loss = 6.7288  \n",
      "\n",
      "Fold: 15  Epoch: 546  Training loss = 2.4060  Validation loss = 6.7274  \n",
      "\n",
      "Fold: 15  Epoch: 547  Training loss = 2.4058  Validation loss = 6.7270  \n",
      "\n",
      "Fold: 15  Epoch: 548  Training loss = 2.4055  Validation loss = 6.7263  \n",
      "\n",
      "Fold: 15  Epoch: 549  Training loss = 2.4051  Validation loss = 6.7245  \n",
      "\n",
      "Fold: 15  Epoch: 550  Training loss = 2.4048  Validation loss = 6.7240  \n",
      "\n",
      "Fold: 15  Epoch: 551  Training loss = 2.4050  Validation loss = 6.7241  \n",
      "\n",
      "Fold: 15  Epoch: 552  Training loss = 2.4048  Validation loss = 6.7237  \n",
      "\n",
      "Fold: 15  Epoch: 553  Training loss = 2.4039  Validation loss = 6.7230  \n",
      "\n",
      "Fold: 15  Epoch: 554  Training loss = 2.4030  Validation loss = 6.7216  \n",
      "\n",
      "Fold: 15  Epoch: 555  Training loss = 2.4030  Validation loss = 6.7221  \n",
      "\n",
      "Fold: 15  Epoch: 556  Training loss = 2.4034  Validation loss = 6.7218  \n",
      "\n",
      "Fold: 15  Epoch: 557  Training loss = 2.4023  Validation loss = 6.7209  \n",
      "\n",
      "Fold: 15  Epoch: 558  Training loss = 2.4021  Validation loss = 6.7209  \n",
      "\n",
      "Fold: 15  Epoch: 559  Training loss = 2.4015  Validation loss = 6.7203  \n",
      "\n",
      "Fold: 15  Epoch: 560  Training loss = 2.4007  Validation loss = 6.7194  \n",
      "\n",
      "Fold: 15  Epoch: 561  Training loss = 2.4002  Validation loss = 6.7182  \n",
      "\n",
      "Fold: 15  Epoch: 562  Training loss = 2.3997  Validation loss = 6.7175  \n",
      "\n",
      "Fold: 15  Epoch: 563  Training loss = 2.3993  Validation loss = 6.7164  \n",
      "\n",
      "Fold: 15  Epoch: 564  Training loss = 2.3989  Validation loss = 6.7149  \n",
      "\n",
      "Fold: 15  Epoch: 565  Training loss = 2.3986  Validation loss = 6.7153  \n",
      "\n",
      "Fold: 15  Epoch: 566  Training loss = 2.3982  Validation loss = 6.7151  \n",
      "\n",
      "Fold: 15  Epoch: 567  Training loss = 2.3979  Validation loss = 6.7140  \n",
      "\n",
      "Fold: 15  Epoch: 568  Training loss = 2.3976  Validation loss = 6.7134  \n",
      "\n",
      "Fold: 15  Epoch: 569  Training loss = 2.3968  Validation loss = 6.7116  \n",
      "\n",
      "Fold: 15  Epoch: 570  Training loss = 2.3965  Validation loss = 6.7110  \n",
      "\n",
      "Fold: 15  Epoch: 571  Training loss = 2.3960  Validation loss = 6.7102  \n",
      "\n",
      "Fold: 15  Epoch: 572  Training loss = 2.3956  Validation loss = 6.7089  \n",
      "\n",
      "Fold: 15  Epoch: 573  Training loss = 2.3949  Validation loss = 6.7069  \n",
      "\n",
      "Fold: 15  Epoch: 574  Training loss = 2.3945  Validation loss = 6.7049  \n",
      "\n",
      "Fold: 15  Epoch: 575  Training loss = 2.3942  Validation loss = 6.7051  \n",
      "\n",
      "Fold: 15  Epoch: 576  Training loss = 2.3940  Validation loss = 6.7026  \n",
      "\n",
      "Fold: 15  Epoch: 577  Training loss = 2.3933  Validation loss = 6.7020  \n",
      "\n",
      "Fold: 15  Epoch: 578  Training loss = 2.3930  Validation loss = 6.7003  \n",
      "\n",
      "Fold: 15  Epoch: 579  Training loss = 2.3925  Validation loss = 6.6984  \n",
      "\n",
      "Fold: 15  Epoch: 580  Training loss = 2.3924  Validation loss = 6.6980  \n",
      "\n",
      "Fold: 15  Epoch: 581  Training loss = 2.3923  Validation loss = 6.6975  \n",
      "\n",
      "Fold: 15  Epoch: 582  Training loss = 2.3919  Validation loss = 6.6966  \n",
      "\n",
      "Fold: 15  Epoch: 583  Training loss = 2.3915  Validation loss = 6.6955  \n",
      "\n",
      "Fold: 15  Epoch: 584  Training loss = 2.3909  Validation loss = 6.6927  \n",
      "\n",
      "Fold: 15  Epoch: 585  Training loss = 2.3906  Validation loss = 6.6924  \n",
      "\n",
      "Fold: 15  Epoch: 586  Training loss = 2.3903  Validation loss = 6.6918  \n",
      "\n",
      "Fold: 15  Epoch: 587  Training loss = 2.3898  Validation loss = 6.6904  \n",
      "\n",
      "Fold: 15  Epoch: 588  Training loss = 2.3895  Validation loss = 6.6893  \n",
      "\n",
      "Fold: 15  Epoch: 589  Training loss = 2.3892  Validation loss = 6.6880  \n",
      "\n",
      "Fold: 15  Epoch: 590  Training loss = 2.3890  Validation loss = 6.6880  \n",
      "\n",
      "Fold: 15  Epoch: 591  Training loss = 2.3887  Validation loss = 6.6877  \n",
      "\n",
      "Fold: 15  Epoch: 592  Training loss = 2.3883  Validation loss = 6.6862  \n",
      "\n",
      "Fold: 15  Epoch: 593  Training loss = 2.3879  Validation loss = 6.6854  \n",
      "\n",
      "Fold: 15  Epoch: 594  Training loss = 2.3878  Validation loss = 6.6851  \n",
      "\n",
      "Fold: 15  Epoch: 595  Training loss = 2.3875  Validation loss = 6.6833  \n",
      "\n",
      "Fold: 15  Epoch: 596  Training loss = 2.3875  Validation loss = 6.6830  \n",
      "\n",
      "Fold: 15  Epoch: 597  Training loss = 2.3879  Validation loss = 6.6819  \n",
      "\n",
      "Fold: 15  Epoch: 598  Training loss = 2.3882  Validation loss = 6.6815  \n",
      "\n",
      "Fold: 15  Epoch: 599  Training loss = 2.3877  Validation loss = 6.6807  \n",
      "\n",
      "Fold: 15  Epoch: 600  Training loss = 2.3861  Validation loss = 6.6788  \n",
      "\n",
      "Fold: 15  Epoch: 601  Training loss = 2.3856  Validation loss = 6.6785  \n",
      "\n",
      "Fold: 15  Epoch: 602  Training loss = 2.3856  Validation loss = 6.6783  \n",
      "\n",
      "Fold: 15  Epoch: 603  Training loss = 2.3854  Validation loss = 6.6773  \n",
      "\n",
      "Fold: 15  Epoch: 604  Training loss = 2.3848  Validation loss = 6.6757  \n",
      "\n",
      "Fold: 15  Epoch: 605  Training loss = 2.3848  Validation loss = 6.6744  \n",
      "\n",
      "Fold: 15  Epoch: 606  Training loss = 2.3846  Validation loss = 6.6735  \n",
      "\n",
      "Fold: 15  Epoch: 607  Training loss = 2.3848  Validation loss = 6.6733  \n",
      "\n",
      "Fold: 15  Epoch: 608  Training loss = 2.3838  Validation loss = 6.6720  \n",
      "\n",
      "Fold: 15  Epoch: 609  Training loss = 2.3833  Validation loss = 6.6714  \n",
      "\n",
      "Fold: 15  Epoch: 610  Training loss = 2.3827  Validation loss = 6.6696  \n",
      "\n",
      "Fold: 15  Epoch: 611  Training loss = 2.3818  Validation loss = 6.6678  \n",
      "\n",
      "Fold: 15  Epoch: 612  Training loss = 2.3814  Validation loss = 6.6666  \n",
      "\n",
      "Fold: 15  Epoch: 613  Training loss = 2.3810  Validation loss = 6.6660  \n",
      "\n",
      "Fold: 15  Epoch: 614  Training loss = 2.3805  Validation loss = 6.6646  \n",
      "\n",
      "Fold: 15  Epoch: 615  Training loss = 2.3801  Validation loss = 6.6633  \n",
      "\n",
      "Fold: 15  Epoch: 616  Training loss = 2.3799  Validation loss = 6.6618  \n",
      "\n",
      "Fold: 15  Epoch: 617  Training loss = 2.3795  Validation loss = 6.6617  \n",
      "\n",
      "Fold: 15  Epoch: 618  Training loss = 2.3794  Validation loss = 6.6618  \n",
      "\n",
      "Fold: 15  Epoch: 619  Training loss = 2.3790  Validation loss = 6.6610  \n",
      "\n",
      "Fold: 15  Epoch: 620  Training loss = 2.3787  Validation loss = 6.6593  \n",
      "\n",
      "Fold: 15  Epoch: 621  Training loss = 2.3786  Validation loss = 6.6578  \n",
      "\n",
      "Fold: 15  Epoch: 622  Training loss = 2.3778  Validation loss = 6.6588  \n",
      "\n",
      "Fold: 15  Epoch: 623  Training loss = 2.3774  Validation loss = 6.6568  \n",
      "\n",
      "Fold: 15  Epoch: 624  Training loss = 2.3771  Validation loss = 6.6564  \n",
      "\n",
      "Fold: 15  Epoch: 625  Training loss = 2.3768  Validation loss = 6.6563  \n",
      "\n",
      "Fold: 15  Epoch: 626  Training loss = 2.3765  Validation loss = 6.6542  \n",
      "\n",
      "Fold: 15  Epoch: 627  Training loss = 2.3762  Validation loss = 6.6528  \n",
      "\n",
      "Fold: 15  Epoch: 628  Training loss = 2.3758  Validation loss = 6.6521  \n",
      "\n",
      "Fold: 15  Epoch: 629  Training loss = 2.3757  Validation loss = 6.6511  \n",
      "\n",
      "Fold: 15  Epoch: 630  Training loss = 2.3753  Validation loss = 6.6500  \n",
      "\n",
      "Fold: 15  Epoch: 631  Training loss = 2.3747  Validation loss = 6.6497  \n",
      "\n",
      "Fold: 15  Epoch: 632  Training loss = 2.3745  Validation loss = 6.6480  \n",
      "\n",
      "Fold: 15  Epoch: 633  Training loss = 2.3747  Validation loss = 6.6473  \n",
      "\n",
      "Fold: 15  Epoch: 634  Training loss = 2.3744  Validation loss = 6.6474  \n",
      "\n",
      "Fold: 15  Epoch: 635  Training loss = 2.3739  Validation loss = 6.6468  \n",
      "\n",
      "Fold: 15  Epoch: 636  Training loss = 2.3736  Validation loss = 6.6478  \n",
      "\n",
      "Fold: 15  Epoch: 637  Training loss = 2.3733  Validation loss = 6.6469  \n",
      "\n",
      "Fold: 15  Epoch: 638  Training loss = 2.3729  Validation loss = 6.6459  \n",
      "\n",
      "Fold: 15  Epoch: 639  Training loss = 2.3726  Validation loss = 6.6456  \n",
      "\n",
      "Fold: 15  Epoch: 640  Training loss = 2.3723  Validation loss = 6.6447  \n",
      "\n",
      "Fold: 15  Epoch: 641  Training loss = 2.3719  Validation loss = 6.6438  \n",
      "\n",
      "Fold: 15  Epoch: 642  Training loss = 2.3715  Validation loss = 6.6435  \n",
      "\n",
      "Fold: 15  Epoch: 643  Training loss = 2.3713  Validation loss = 6.6432  \n",
      "\n",
      "Fold: 15  Epoch: 644  Training loss = 2.3711  Validation loss = 6.6430  \n",
      "\n",
      "Fold: 15  Epoch: 645  Training loss = 2.3706  Validation loss = 6.6413  \n",
      "\n",
      "Fold: 15  Epoch: 646  Training loss = 2.3703  Validation loss = 6.6398  \n",
      "\n",
      "Fold: 15  Epoch: 647  Training loss = 2.3701  Validation loss = 6.6391  \n",
      "\n",
      "Fold: 15  Epoch: 648  Training loss = 2.3698  Validation loss = 6.6392  \n",
      "\n",
      "Fold: 15  Epoch: 649  Training loss = 2.3698  Validation loss = 6.6387  \n",
      "\n",
      "Fold: 15  Epoch: 650  Training loss = 2.3695  Validation loss = 6.6385  \n",
      "\n",
      "Fold: 15  Epoch: 651  Training loss = 2.3692  Validation loss = 6.6377  \n",
      "\n",
      "Fold: 15  Epoch: 652  Training loss = 2.3689  Validation loss = 6.6360  \n",
      "\n",
      "Fold: 15  Epoch: 653  Training loss = 2.3686  Validation loss = 6.6351  \n",
      "\n",
      "Fold: 15  Epoch: 654  Training loss = 2.3688  Validation loss = 6.6363  \n",
      "\n",
      "Fold: 15  Epoch: 655  Training loss = 2.3683  Validation loss = 6.6347  \n",
      "\n",
      "Fold: 15  Epoch: 656  Training loss = 2.3680  Validation loss = 6.6342  \n",
      "\n",
      "Fold: 15  Epoch: 657  Training loss = 2.3680  Validation loss = 6.6342  \n",
      "\n",
      "Fold: 15  Epoch: 658  Training loss = 2.3676  Validation loss = 6.6324  \n",
      "\n",
      "Fold: 15  Epoch: 659  Training loss = 2.3671  Validation loss = 6.6306  \n",
      "\n",
      "Fold: 15  Epoch: 660  Training loss = 2.3667  Validation loss = 6.6290  \n",
      "\n",
      "Fold: 15  Epoch: 661  Training loss = 2.3665  Validation loss = 6.6281  \n",
      "\n",
      "Fold: 15  Epoch: 662  Training loss = 2.3661  Validation loss = 6.6278  \n",
      "\n",
      "Fold: 15  Epoch: 663  Training loss = 2.3658  Validation loss = 6.6279  \n",
      "\n",
      "Fold: 15  Epoch: 664  Training loss = 2.3656  Validation loss = 6.6273  \n",
      "\n",
      "Fold: 15  Epoch: 665  Training loss = 2.3651  Validation loss = 6.6248  \n",
      "\n",
      "Fold: 15  Epoch: 666  Training loss = 2.3649  Validation loss = 6.6237  \n",
      "\n",
      "Fold: 15  Epoch: 667  Training loss = 2.3645  Validation loss = 6.6217  \n",
      "\n",
      "Fold: 15  Epoch: 668  Training loss = 2.3642  Validation loss = 6.6207  \n",
      "\n",
      "Fold: 15  Epoch: 669  Training loss = 2.3638  Validation loss = 6.6196  \n",
      "\n",
      "Fold: 15  Epoch: 670  Training loss = 2.3635  Validation loss = 6.6191  \n",
      "\n",
      "Fold: 15  Epoch: 671  Training loss = 2.3632  Validation loss = 6.6182  \n",
      "\n",
      "Fold: 15  Epoch: 672  Training loss = 2.3627  Validation loss = 6.6157  \n",
      "\n",
      "Fold: 15  Epoch: 673  Training loss = 2.3626  Validation loss = 6.6157  \n",
      "\n",
      "Fold: 15  Epoch: 674  Training loss = 2.3624  Validation loss = 6.6153  \n",
      "\n",
      "Fold: 15  Epoch: 675  Training loss = 2.3621  Validation loss = 6.6123  \n",
      "\n",
      "Fold: 15  Epoch: 676  Training loss = 2.3616  Validation loss = 6.6103  \n",
      "\n",
      "Fold: 15  Epoch: 677  Training loss = 2.3610  Validation loss = 6.6103  \n",
      "\n",
      "Fold: 15  Epoch: 678  Training loss = 2.3604  Validation loss = 6.6088  \n",
      "\n",
      "Fold: 15  Epoch: 679  Training loss = 2.3602  Validation loss = 6.6076  \n",
      "\n",
      "Fold: 15  Epoch: 680  Training loss = 2.3600  Validation loss = 6.6074  \n",
      "\n",
      "Fold: 15  Epoch: 681  Training loss = 2.3597  Validation loss = 6.6060  \n",
      "\n",
      "Fold: 15  Epoch: 682  Training loss = 2.3594  Validation loss = 6.6046  \n",
      "\n",
      "Fold: 15  Epoch: 683  Training loss = 2.3590  Validation loss = 6.6039  \n",
      "\n",
      "Fold: 15  Epoch: 684  Training loss = 2.3588  Validation loss = 6.6043  \n",
      "\n",
      "Fold: 15  Epoch: 685  Training loss = 2.3587  Validation loss = 6.6044  \n",
      "\n",
      "Fold: 15  Epoch: 686  Training loss = 2.3584  Validation loss = 6.6036  \n",
      "\n",
      "Fold: 15  Epoch: 687  Training loss = 2.3581  Validation loss = 6.6019  \n",
      "\n",
      "Fold: 15  Epoch: 688  Training loss = 2.3577  Validation loss = 6.6003  \n",
      "\n",
      "Fold: 15  Epoch: 689  Training loss = 2.3573  Validation loss = 6.5992  \n",
      "\n",
      "Fold: 15  Epoch: 690  Training loss = 2.3571  Validation loss = 6.5997  \n",
      "\n",
      "Fold: 15  Epoch: 691  Training loss = 2.3566  Validation loss = 6.5985  \n",
      "\n",
      "Fold: 15  Epoch: 692  Training loss = 2.3567  Validation loss = 6.5990  \n",
      "\n",
      "Fold: 15  Epoch: 693  Training loss = 2.3563  Validation loss = 6.5975  \n",
      "\n",
      "Fold: 15  Epoch: 694  Training loss = 2.3560  Validation loss = 6.5980  \n",
      "\n",
      "Fold: 15  Epoch: 695  Training loss = 2.3557  Validation loss = 6.5974  \n",
      "\n",
      "Fold: 15  Epoch: 696  Training loss = 2.3552  Validation loss = 6.5952  \n",
      "\n",
      "Fold: 15  Epoch: 697  Training loss = 2.3551  Validation loss = 6.5944  \n",
      "\n",
      "Fold: 15  Epoch: 698  Training loss = 2.3549  Validation loss = 6.5939  \n",
      "\n",
      "Fold: 15  Epoch: 699  Training loss = 2.3546  Validation loss = 6.5925  \n",
      "\n",
      "Fold: 15  Epoch: 700  Training loss = 2.3541  Validation loss = 6.5919  \n",
      "\n",
      "Fold: 15  Epoch: 701  Training loss = 2.3537  Validation loss = 6.5915  \n",
      "\n",
      "Fold: 15  Epoch: 702  Training loss = 2.3532  Validation loss = 6.5903  \n",
      "\n",
      "Fold: 15  Epoch: 703  Training loss = 2.3529  Validation loss = 6.5894  \n",
      "\n",
      "Fold: 15  Epoch: 704  Training loss = 2.3526  Validation loss = 6.5874  \n",
      "\n",
      "Fold: 15  Epoch: 705  Training loss = 2.3522  Validation loss = 6.5858  \n",
      "\n",
      "Fold: 15  Epoch: 706  Training loss = 2.3520  Validation loss = 6.5856  \n",
      "\n",
      "Fold: 15  Epoch: 707  Training loss = 2.3514  Validation loss = 6.5849  \n",
      "\n",
      "Fold: 15  Epoch: 708  Training loss = 2.3511  Validation loss = 6.5842  \n",
      "\n",
      "Fold: 15  Epoch: 709  Training loss = 2.3511  Validation loss = 6.5842  \n",
      "\n",
      "Fold: 15  Epoch: 710  Training loss = 2.3510  Validation loss = 6.5829  \n",
      "\n",
      "Fold: 15  Epoch: 711  Training loss = 2.3508  Validation loss = 6.5829  \n",
      "\n",
      "Fold: 15  Epoch: 712  Training loss = 2.3503  Validation loss = 6.5836  \n",
      "\n",
      "Fold: 15  Epoch: 713  Training loss = 2.3504  Validation loss = 6.5826  \n",
      "\n",
      "Fold: 15  Epoch: 714  Training loss = 2.3499  Validation loss = 6.5821  \n",
      "\n",
      "Fold: 15  Epoch: 715  Training loss = 2.3503  Validation loss = 6.5811  \n",
      "\n",
      "Fold: 15  Epoch: 716  Training loss = 2.3507  Validation loss = 6.5792  \n",
      "\n",
      "Fold: 15  Epoch: 717  Training loss = 2.3507  Validation loss = 6.5781  \n",
      "\n",
      "Fold: 15  Epoch: 718  Training loss = 2.3502  Validation loss = 6.5760  \n",
      "\n",
      "Fold: 15  Epoch: 719  Training loss = 2.3495  Validation loss = 6.5747  \n",
      "\n",
      "Fold: 15  Epoch: 720  Training loss = 2.3486  Validation loss = 6.5750  \n",
      "\n",
      "Fold: 15  Epoch: 721  Training loss = 2.3476  Validation loss = 6.5759  \n",
      "\n",
      "Fold: 15  Epoch: 722  Training loss = 2.3471  Validation loss = 6.5747  \n",
      "\n",
      "Fold: 15  Epoch: 723  Training loss = 2.3469  Validation loss = 6.5744  \n",
      "\n",
      "Fold: 15  Epoch: 724  Training loss = 2.3465  Validation loss = 6.5729  \n",
      "\n",
      "Fold: 15  Epoch: 725  Training loss = 2.3462  Validation loss = 6.5723  \n",
      "\n",
      "Fold: 15  Epoch: 726  Training loss = 2.3458  Validation loss = 6.5722  \n",
      "\n",
      "Fold: 15  Epoch: 727  Training loss = 2.3456  Validation loss = 6.5718  \n",
      "\n",
      "Fold: 15  Epoch: 728  Training loss = 2.3453  Validation loss = 6.5715  \n",
      "\n",
      "Fold: 15  Epoch: 729  Training loss = 2.3452  Validation loss = 6.5688  \n",
      "\n",
      "Fold: 15  Epoch: 730  Training loss = 2.3448  Validation loss = 6.5694  \n",
      "\n",
      "Fold: 15  Epoch: 731  Training loss = 2.3446  Validation loss = 6.5676  \n",
      "\n",
      "Fold: 15  Epoch: 732  Training loss = 2.3442  Validation loss = 6.5670  \n",
      "\n",
      "Fold: 15  Epoch: 733  Training loss = 2.3439  Validation loss = 6.5669  \n",
      "\n",
      "Fold: 15  Epoch: 734  Training loss = 2.3436  Validation loss = 6.5675  \n",
      "\n",
      "Fold: 15  Epoch: 735  Training loss = 2.3436  Validation loss = 6.5647  \n",
      "\n",
      "Fold: 15  Epoch: 736  Training loss = 2.3435  Validation loss = 6.5647  \n",
      "\n",
      "Fold: 15  Epoch: 737  Training loss = 2.3433  Validation loss = 6.5631  \n",
      "\n",
      "Fold: 15  Epoch: 738  Training loss = 2.3432  Validation loss = 6.5610  \n",
      "\n",
      "Fold: 15  Epoch: 739  Training loss = 2.3422  Validation loss = 6.5613  \n",
      "\n",
      "Fold: 15  Epoch: 740  Training loss = 2.3419  Validation loss = 6.5612  \n",
      "\n",
      "Fold: 15  Epoch: 741  Training loss = 2.3414  Validation loss = 6.5596  \n",
      "\n",
      "Fold: 15  Epoch: 742  Training loss = 2.3408  Validation loss = 6.5574  \n",
      "\n",
      "Fold: 15  Epoch: 743  Training loss = 2.3407  Validation loss = 6.5578  \n",
      "\n",
      "Fold: 15  Epoch: 744  Training loss = 2.3409  Validation loss = 6.5543  \n",
      "\n",
      "Fold: 15  Epoch: 745  Training loss = 2.3407  Validation loss = 6.5508  \n",
      "\n",
      "Fold: 15  Epoch: 746  Training loss = 2.3403  Validation loss = 6.5506  \n",
      "\n",
      "Fold: 15  Epoch: 747  Training loss = 2.3401  Validation loss = 6.5511  \n",
      "\n",
      "Fold: 15  Epoch: 748  Training loss = 2.3393  Validation loss = 6.5520  \n",
      "\n",
      "Fold: 15  Epoch: 749  Training loss = 2.3392  Validation loss = 6.5528  \n",
      "\n",
      "Fold: 15  Epoch: 750  Training loss = 2.3386  Validation loss = 6.5524  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 746  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.8331  Validation loss = 4.5151  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.8326  Validation loss = 4.5089  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.8324  Validation loss = 4.5113  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.8317  Validation loss = 4.5062  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.8312  Validation loss = 4.5028  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.8303  Validation loss = 4.4967  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.8299  Validation loss = 4.4889  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.8287  Validation loss = 4.4932  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.8269  Validation loss = 4.4990  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.8257  Validation loss = 4.4996  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.8250  Validation loss = 4.4905  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.8245  Validation loss = 4.4957  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.8237  Validation loss = 4.4998  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.8226  Validation loss = 4.5018  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.8216  Validation loss = 4.5047  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.8214  Validation loss = 4.4978  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.8203  Validation loss = 4.4955  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 2.8188  Validation loss = 4.4917  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.8169  Validation loss = 4.4934  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.8153  Validation loss = 4.4985  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 2.8126  Validation loss = 4.4912  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 2.8100  Validation loss = 4.4942  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 2.8072  Validation loss = 4.4836  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 2.8064  Validation loss = 4.4794  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 2.8047  Validation loss = 4.4820  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 2.8035  Validation loss = 4.4849  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 2.8030  Validation loss = 4.4875  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 2.8016  Validation loss = 4.4889  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 2.8012  Validation loss = 4.4928  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 2.8002  Validation loss = 4.4936  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 2.7998  Validation loss = 4.4987  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 24  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 3.0116  Validation loss = 3.1147  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 3.0065  Validation loss = 3.1254  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 3.0043  Validation loss = 3.1272  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 3.0000  Validation loss = 3.1323  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.9974  Validation loss = 3.1348  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.9948  Validation loss = 3.1363  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.9940  Validation loss = 3.1351  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.9907  Validation loss = 3.1392  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.9882  Validation loss = 3.1387  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.9853  Validation loss = 3.1396  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.9841  Validation loss = 3.1398  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.9820  Validation loss = 3.1394  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.9799  Validation loss = 3.1390  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.9784  Validation loss = 3.1391  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.9776  Validation loss = 3.1392  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 2.9753  Validation loss = 3.1375  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 2.9722  Validation loss = 3.1341  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 2.9720  Validation loss = 3.1334  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 2.9704  Validation loss = 3.1328  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 2.9682  Validation loss = 3.1293  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 2.9676  Validation loss = 3.1314  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 2.9651  Validation loss = 3.1311  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 2.9642  Validation loss = 3.1334  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 2.9630  Validation loss = 3.1309  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 2.9619  Validation loss = 3.1339  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 2.9598  Validation loss = 3.1335  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 2.9577  Validation loss = 3.1305  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 2.9561  Validation loss = 3.1263  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 2.9553  Validation loss = 3.1252  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 2.9551  Validation loss = 3.1290  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 2.9549  Validation loss = 3.1274  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 2.9532  Validation loss = 3.1281  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 2.9525  Validation loss = 3.1314  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 2.9490  Validation loss = 3.1308  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 2.9475  Validation loss = 3.1293  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 2.9454  Validation loss = 3.1314  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 2.9422  Validation loss = 3.1289  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 2.9394  Validation loss = 3.1225  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 2.9389  Validation loss = 3.1272  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 2.9366  Validation loss = 3.1279  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 2.9358  Validation loss = 3.1264  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 2.9335  Validation loss = 3.1243  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 2.9318  Validation loss = 3.1245  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 2.9286  Validation loss = 3.1187  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 2.9273  Validation loss = 3.1237  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 2.9271  Validation loss = 3.1265  \n",
      "\n",
      "Fold: 17  Epoch: 47  Training loss = 2.9243  Validation loss = 3.1266  \n",
      "\n",
      "Fold: 17  Epoch: 48  Training loss = 2.9218  Validation loss = 3.1245  \n",
      "\n",
      "Fold: 17  Epoch: 49  Training loss = 2.9202  Validation loss = 3.1195  \n",
      "\n",
      "Fold: 17  Epoch: 50  Training loss = 2.9182  Validation loss = 3.1183  \n",
      "\n",
      "Fold: 17  Epoch: 51  Training loss = 2.9167  Validation loss = 3.1172  \n",
      "\n",
      "Fold: 17  Epoch: 52  Training loss = 2.9149  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 17  Epoch: 53  Training loss = 2.9128  Validation loss = 3.1178  \n",
      "\n",
      "Fold: 17  Epoch: 54  Training loss = 2.9110  Validation loss = 3.1216  \n",
      "\n",
      "Fold: 17  Epoch: 55  Training loss = 2.9102  Validation loss = 3.1240  \n",
      "\n",
      "Fold: 17  Epoch: 56  Training loss = 2.9082  Validation loss = 3.1280  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.0069  Validation loss = 1.4184  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.0063  Validation loss = 1.4176  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.0051  Validation loss = 1.4155  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.0036  Validation loss = 1.4155  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.0025  Validation loss = 1.4173  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.0004  Validation loss = 1.4156  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.9986  Validation loss = 1.4135  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.9968  Validation loss = 1.4137  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.9963  Validation loss = 1.4131  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.9949  Validation loss = 1.4123  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.9946  Validation loss = 1.4118  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 2.9929  Validation loss = 1.4118  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 2.9898  Validation loss = 1.4092  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 2.9883  Validation loss = 1.4094  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 2.9861  Validation loss = 1.4093  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 2.9849  Validation loss = 1.4076  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 2.9841  Validation loss = 1.4065  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 2.9837  Validation loss = 1.4081  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 2.9834  Validation loss = 1.4095  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 2.9816  Validation loss = 1.4095  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 2.9810  Validation loss = 1.4084  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 2.9792  Validation loss = 1.4076  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 2.9789  Validation loss = 1.4074  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 2.9775  Validation loss = 1.4072  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 2.9761  Validation loss = 1.4071  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 2.9753  Validation loss = 1.4084  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 2.9747  Validation loss = 1.4086  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 2.9736  Validation loss = 1.4068  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 2.9721  Validation loss = 1.4077  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 2.9711  Validation loss = 1.4061  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 2.9708  Validation loss = 1.4044  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 2.9686  Validation loss = 1.4038  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 2.9685  Validation loss = 1.4027  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 2.9686  Validation loss = 1.4026  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 2.9679  Validation loss = 1.4030  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 2.9664  Validation loss = 1.4035  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 2.9659  Validation loss = 1.4033  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 2.9655  Validation loss = 1.4036  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 2.9671  Validation loss = 1.4039  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 2.9653  Validation loss = 1.4059  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 2.9641  Validation loss = 1.4063  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 2.9634  Validation loss = 1.4052  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 2.9624  Validation loss = 1.4057  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 2.9604  Validation loss = 1.4054  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 2.9591  Validation loss = 1.4046  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 2.9580  Validation loss = 1.4048  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 2.9576  Validation loss = 1.4048  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 2.9573  Validation loss = 1.4034  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 2.9554  Validation loss = 1.4041  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 2.9546  Validation loss = 1.4043  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 2.9534  Validation loss = 1.4045  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 2.9524  Validation loss = 1.4048  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 2.9509  Validation loss = 1.4046  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 2.9494  Validation loss = 1.4059  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 2.9485  Validation loss = 1.4044  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 2.9482  Validation loss = 1.4056  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 2.9472  Validation loss = 1.4041  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 2.9457  Validation loss = 1.4031  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 2.9436  Validation loss = 1.4031  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 2.9421  Validation loss = 1.4036  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 2.9415  Validation loss = 1.4047  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 2.9408  Validation loss = 1.4045  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 2.9400  Validation loss = 1.4046  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 2.9391  Validation loss = 1.4044  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 2.9372  Validation loss = 1.4041  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 2.9363  Validation loss = 1.4041  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 2.9356  Validation loss = 1.4036  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 2.9349  Validation loss = 1.4044  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 2.9341  Validation loss = 1.4057  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 34  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.9053  Validation loss = 2.8484  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.9032  Validation loss = 2.8451  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.9018  Validation loss = 2.8429  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.9002  Validation loss = 2.8399  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.8988  Validation loss = 2.8387  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.8970  Validation loss = 2.8394  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.8946  Validation loss = 2.8387  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.8920  Validation loss = 2.8361  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.8892  Validation loss = 2.8370  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.8877  Validation loss = 2.8357  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.8871  Validation loss = 2.8357  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.8860  Validation loss = 2.8330  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.8851  Validation loss = 2.8319  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.8852  Validation loss = 2.8318  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.8838  Validation loss = 2.8290  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.8826  Validation loss = 2.8293  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 2.8815  Validation loss = 2.8276  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 2.8811  Validation loss = 2.8281  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 2.8803  Validation loss = 2.8273  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 2.8789  Validation loss = 2.8260  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 2.8778  Validation loss = 2.8248  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 2.8767  Validation loss = 2.8247  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 2.8761  Validation loss = 2.8266  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 2.8761  Validation loss = 2.8274  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 2.8762  Validation loss = 2.8276  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 2.8737  Validation loss = 2.8271  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 2.8721  Validation loss = 2.8258  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 2.8713  Validation loss = 2.8227  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 2.8702  Validation loss = 2.8217  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 2.8690  Validation loss = 2.8215  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 2.8685  Validation loss = 2.8203  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 2.8681  Validation loss = 2.8188  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 2.8674  Validation loss = 2.8176  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 2.8665  Validation loss = 2.8185  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 2.8655  Validation loss = 2.8160  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 2.8650  Validation loss = 2.8152  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 2.8640  Validation loss = 2.8156  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 2.8635  Validation loss = 2.8132  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 2.8623  Validation loss = 2.8124  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 2.8609  Validation loss = 2.8100  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 2.8598  Validation loss = 2.8091  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 2.8591  Validation loss = 2.8085  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 2.8584  Validation loss = 2.8089  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 2.8573  Validation loss = 2.8077  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 2.8566  Validation loss = 2.8078  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 2.8561  Validation loss = 2.8075  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 2.8551  Validation loss = 2.8074  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 2.8542  Validation loss = 2.8062  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 2.8533  Validation loss = 2.8067  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 2.8528  Validation loss = 2.8055  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 2.8517  Validation loss = 2.8044  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 2.8517  Validation loss = 2.8050  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 2.8510  Validation loss = 2.8051  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 2.8498  Validation loss = 2.8035  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 2.8499  Validation loss = 2.8038  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 2.8492  Validation loss = 2.8030  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 2.8481  Validation loss = 2.8030  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 2.8472  Validation loss = 2.8020  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 2.8469  Validation loss = 2.8015  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 2.8462  Validation loss = 2.8012  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 2.8455  Validation loss = 2.8003  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 2.8451  Validation loss = 2.8002  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 2.8447  Validation loss = 2.8012  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 2.8442  Validation loss = 2.8008  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 2.8434  Validation loss = 2.7970  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 2.8431  Validation loss = 2.7973  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 2.8422  Validation loss = 2.7982  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 2.8414  Validation loss = 2.7997  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 2.8405  Validation loss = 2.7991  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 2.8401  Validation loss = 2.7969  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 2.8391  Validation loss = 2.7960  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 2.8386  Validation loss = 2.7960  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 2.8380  Validation loss = 2.7952  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 2.8383  Validation loss = 2.7971  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 2.8372  Validation loss = 2.7951  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 2.8365  Validation loss = 2.7948  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 2.8358  Validation loss = 2.7954  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 2.8350  Validation loss = 2.7949  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 2.8341  Validation loss = 2.7955  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 2.8334  Validation loss = 2.7946  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 2.8333  Validation loss = 2.7955  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 2.8329  Validation loss = 2.7951  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 2.8325  Validation loss = 2.7936  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 2.8317  Validation loss = 2.7937  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 2.8314  Validation loss = 2.7936  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 2.8306  Validation loss = 2.7921  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 2.8300  Validation loss = 2.7919  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 2.8293  Validation loss = 2.7917  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 2.8295  Validation loss = 2.7921  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 2.8290  Validation loss = 2.7904  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 2.8289  Validation loss = 2.7903  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 2.8296  Validation loss = 2.7896  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 2.8286  Validation loss = 2.7889  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 2.8274  Validation loss = 2.7888  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 2.8275  Validation loss = 2.7870  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 2.8264  Validation loss = 2.7870  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 2.8262  Validation loss = 2.7858  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 2.8246  Validation loss = 2.7860  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 2.8243  Validation loss = 2.7859  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 2.8234  Validation loss = 2.7842  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 2.8229  Validation loss = 2.7854  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 2.8225  Validation loss = 2.7849  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 2.8224  Validation loss = 2.7854  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 2.8215  Validation loss = 2.7857  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 2.8210  Validation loss = 2.7856  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 2.8209  Validation loss = 2.7859  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 2.8217  Validation loss = 2.7861  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 2.8208  Validation loss = 2.7872  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 2.8201  Validation loss = 2.7852  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 2.8193  Validation loss = 2.7848  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 2.8186  Validation loss = 2.7848  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 2.8177  Validation loss = 2.7829  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 2.8169  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 2.8164  Validation loss = 2.7817  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 2.8162  Validation loss = 2.7828  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 2.8154  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 2.8151  Validation loss = 2.7822  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 2.8148  Validation loss = 2.7811  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 2.8140  Validation loss = 2.7800  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 2.8130  Validation loss = 2.7791  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 2.8120  Validation loss = 2.7762  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 2.8115  Validation loss = 2.7757  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 2.8109  Validation loss = 2.7744  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 2.8102  Validation loss = 2.7749  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 2.8096  Validation loss = 2.7757  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 2.8093  Validation loss = 2.7748  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 2.8089  Validation loss = 2.7741  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 2.8082  Validation loss = 2.7738  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 2.8074  Validation loss = 2.7717  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 2.8069  Validation loss = 2.7699  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 2.8069  Validation loss = 2.7710  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 2.8060  Validation loss = 2.7703  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 2.8052  Validation loss = 2.7698  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 2.8049  Validation loss = 2.7696  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 2.8041  Validation loss = 2.7691  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 2.8034  Validation loss = 2.7683  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 2.8032  Validation loss = 2.7686  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 2.8027  Validation loss = 2.7689  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 2.8022  Validation loss = 2.7682  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 2.8018  Validation loss = 2.7681  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 2.8011  Validation loss = 2.7679  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 2.8007  Validation loss = 2.7671  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 2.8002  Validation loss = 2.7674  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 2.8004  Validation loss = 2.7690  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 2.7993  Validation loss = 2.7680  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 2.7990  Validation loss = 2.7686  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 2.7985  Validation loss = 2.7686  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 2.7983  Validation loss = 2.7687  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 2.7978  Validation loss = 2.7685  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 2.7971  Validation loss = 2.7669  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 2.7967  Validation loss = 2.7665  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 2.7962  Validation loss = 2.7658  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 2.7958  Validation loss = 2.7660  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 2.7951  Validation loss = 2.7655  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 2.7947  Validation loss = 2.7658  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 2.7945  Validation loss = 2.7660  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 2.7945  Validation loss = 2.7656  \n",
      "\n",
      "Fold: 19  Epoch: 158  Training loss = 2.7940  Validation loss = 2.7640  \n",
      "\n",
      "Fold: 19  Epoch: 159  Training loss = 2.7937  Validation loss = 2.7656  \n",
      "\n",
      "Fold: 19  Epoch: 160  Training loss = 2.7930  Validation loss = 2.7657  \n",
      "\n",
      "Fold: 19  Epoch: 161  Training loss = 2.7925  Validation loss = 2.7654  \n",
      "\n",
      "Fold: 19  Epoch: 162  Training loss = 2.7921  Validation loss = 2.7657  \n",
      "\n",
      "Fold: 19  Epoch: 163  Training loss = 2.7916  Validation loss = 2.7656  \n",
      "\n",
      "Fold: 19  Epoch: 164  Training loss = 2.7917  Validation loss = 2.7664  \n",
      "\n",
      "Fold: 19  Epoch: 165  Training loss = 2.7908  Validation loss = 2.7656  \n",
      "\n",
      "Fold: 19  Epoch: 166  Training loss = 2.7902  Validation loss = 2.7644  \n",
      "\n",
      "Fold: 19  Epoch: 167  Training loss = 2.7893  Validation loss = 2.7631  \n",
      "\n",
      "Fold: 19  Epoch: 168  Training loss = 2.7886  Validation loss = 2.7621  \n",
      "\n",
      "Fold: 19  Epoch: 169  Training loss = 2.7880  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 19  Epoch: 170  Training loss = 2.7874  Validation loss = 2.7576  \n",
      "\n",
      "Fold: 19  Epoch: 171  Training loss = 2.7869  Validation loss = 2.7581  \n",
      "\n",
      "Fold: 19  Epoch: 172  Training loss = 2.7862  Validation loss = 2.7577  \n",
      "\n",
      "Fold: 19  Epoch: 173  Training loss = 2.7859  Validation loss = 2.7567  \n",
      "\n",
      "Fold: 19  Epoch: 174  Training loss = 2.7857  Validation loss = 2.7567  \n",
      "\n",
      "Fold: 19  Epoch: 175  Training loss = 2.7851  Validation loss = 2.7565  \n",
      "\n",
      "Fold: 19  Epoch: 176  Training loss = 2.7847  Validation loss = 2.7545  \n",
      "\n",
      "Fold: 19  Epoch: 177  Training loss = 2.7839  Validation loss = 2.7542  \n",
      "\n",
      "Fold: 19  Epoch: 178  Training loss = 2.7843  Validation loss = 2.7546  \n",
      "\n",
      "Fold: 19  Epoch: 179  Training loss = 2.7832  Validation loss = 2.7547  \n",
      "\n",
      "Fold: 19  Epoch: 180  Training loss = 2.7828  Validation loss = 2.7551  \n",
      "\n",
      "Fold: 19  Epoch: 181  Training loss = 2.7823  Validation loss = 2.7545  \n",
      "\n",
      "Fold: 19  Epoch: 182  Training loss = 2.7820  Validation loss = 2.7532  \n",
      "\n",
      "Fold: 19  Epoch: 183  Training loss = 2.7817  Validation loss = 2.7529  \n",
      "\n",
      "Fold: 19  Epoch: 184  Training loss = 2.7809  Validation loss = 2.7525  \n",
      "\n",
      "Fold: 19  Epoch: 185  Training loss = 2.7804  Validation loss = 2.7519  \n",
      "\n",
      "Fold: 19  Epoch: 186  Training loss = 2.7801  Validation loss = 2.7525  \n",
      "\n",
      "Fold: 19  Epoch: 187  Training loss = 2.7795  Validation loss = 2.7521  \n",
      "\n",
      "Fold: 19  Epoch: 188  Training loss = 2.7795  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 19  Epoch: 189  Training loss = 2.7787  Validation loss = 2.7516  \n",
      "\n",
      "Fold: 19  Epoch: 190  Training loss = 2.7784  Validation loss = 2.7512  \n",
      "\n",
      "Fold: 19  Epoch: 191  Training loss = 2.7788  Validation loss = 2.7516  \n",
      "\n",
      "Fold: 19  Epoch: 192  Training loss = 2.7778  Validation loss = 2.7502  \n",
      "\n",
      "Fold: 19  Epoch: 193  Training loss = 2.7774  Validation loss = 2.7500  \n",
      "\n",
      "Fold: 19  Epoch: 194  Training loss = 2.7769  Validation loss = 2.7489  \n",
      "\n",
      "Fold: 19  Epoch: 195  Training loss = 2.7769  Validation loss = 2.7485  \n",
      "\n",
      "Fold: 19  Epoch: 196  Training loss = 2.7763  Validation loss = 2.7489  \n",
      "\n",
      "Fold: 19  Epoch: 197  Training loss = 2.7759  Validation loss = 2.7486  \n",
      "\n",
      "Fold: 19  Epoch: 198  Training loss = 2.7755  Validation loss = 2.7469  \n",
      "\n",
      "Fold: 19  Epoch: 199  Training loss = 2.7752  Validation loss = 2.7478  \n",
      "\n",
      "Fold: 19  Epoch: 200  Training loss = 2.7750  Validation loss = 2.7453  \n",
      "\n",
      "Fold: 19  Epoch: 201  Training loss = 2.7743  Validation loss = 2.7448  \n",
      "\n",
      "Fold: 19  Epoch: 202  Training loss = 2.7739  Validation loss = 2.7445  \n",
      "\n",
      "Fold: 19  Epoch: 203  Training loss = 2.7736  Validation loss = 2.7433  \n",
      "\n",
      "Fold: 19  Epoch: 204  Training loss = 2.7735  Validation loss = 2.7441  \n",
      "\n",
      "Fold: 19  Epoch: 205  Training loss = 2.7731  Validation loss = 2.7439  \n",
      "\n",
      "Fold: 19  Epoch: 206  Training loss = 2.7728  Validation loss = 2.7415  \n",
      "\n",
      "Fold: 19  Epoch: 207  Training loss = 2.7723  Validation loss = 2.7414  \n",
      "\n",
      "Fold: 19  Epoch: 208  Training loss = 2.7723  Validation loss = 2.7411  \n",
      "\n",
      "Fold: 19  Epoch: 209  Training loss = 2.7716  Validation loss = 2.7398  \n",
      "\n",
      "Fold: 19  Epoch: 210  Training loss = 2.7712  Validation loss = 2.7415  \n",
      "\n",
      "Fold: 19  Epoch: 211  Training loss = 2.7715  Validation loss = 2.7422  \n",
      "\n",
      "Fold: 19  Epoch: 212  Training loss = 2.7707  Validation loss = 2.7417  \n",
      "\n",
      "Fold: 19  Epoch: 213  Training loss = 2.7701  Validation loss = 2.7422  \n",
      "\n",
      "Fold: 19  Epoch: 214  Training loss = 2.7693  Validation loss = 2.7420  \n",
      "\n",
      "Fold: 19  Epoch: 215  Training loss = 2.7685  Validation loss = 2.7415  \n",
      "\n",
      "Fold: 19  Epoch: 216  Training loss = 2.7684  Validation loss = 2.7397  \n",
      "\n",
      "Fold: 19  Epoch: 217  Training loss = 2.7678  Validation loss = 2.7388  \n",
      "\n",
      "Fold: 19  Epoch: 218  Training loss = 2.7676  Validation loss = 2.7378  \n",
      "\n",
      "Fold: 19  Epoch: 219  Training loss = 2.7670  Validation loss = 2.7379  \n",
      "\n",
      "Fold: 19  Epoch: 220  Training loss = 2.7662  Validation loss = 2.7387  \n",
      "\n",
      "Fold: 19  Epoch: 221  Training loss = 2.7655  Validation loss = 2.7380  \n",
      "\n",
      "Fold: 19  Epoch: 222  Training loss = 2.7651  Validation loss = 2.7376  \n",
      "\n",
      "Fold: 19  Epoch: 223  Training loss = 2.7648  Validation loss = 2.7381  \n",
      "\n",
      "Fold: 19  Epoch: 224  Training loss = 2.7643  Validation loss = 2.7372  \n",
      "\n",
      "Fold: 19  Epoch: 225  Training loss = 2.7637  Validation loss = 2.7372  \n",
      "\n",
      "Fold: 19  Epoch: 226  Training loss = 2.7632  Validation loss = 2.7370  \n",
      "\n",
      "Fold: 19  Epoch: 227  Training loss = 2.7631  Validation loss = 2.7368  \n",
      "\n",
      "Fold: 19  Epoch: 228  Training loss = 2.7626  Validation loss = 2.7366  \n",
      "\n",
      "Fold: 19  Epoch: 229  Training loss = 2.7624  Validation loss = 2.7366  \n",
      "\n",
      "Fold: 19  Epoch: 230  Training loss = 2.7624  Validation loss = 2.7371  \n",
      "\n",
      "Fold: 19  Epoch: 231  Training loss = 2.7626  Validation loss = 2.7370  \n",
      "\n",
      "Fold: 19  Epoch: 232  Training loss = 2.7614  Validation loss = 2.7373  \n",
      "\n",
      "Fold: 19  Epoch: 233  Training loss = 2.7612  Validation loss = 2.7373  \n",
      "\n",
      "Fold: 19  Epoch: 234  Training loss = 2.7610  Validation loss = 2.7379  \n",
      "\n",
      "Fold: 19  Epoch: 235  Training loss = 2.7607  Validation loss = 2.7364  \n",
      "\n",
      "Fold: 19  Epoch: 236  Training loss = 2.7601  Validation loss = 2.7364  \n",
      "\n",
      "Fold: 19  Epoch: 237  Training loss = 2.7599  Validation loss = 2.7369  \n",
      "\n",
      "Fold: 19  Epoch: 238  Training loss = 2.7594  Validation loss = 2.7378  \n",
      "\n",
      "Fold: 19  Epoch: 239  Training loss = 2.7593  Validation loss = 2.7377  \n",
      "\n",
      "Fold: 19  Epoch: 240  Training loss = 2.7591  Validation loss = 2.7369  \n",
      "\n",
      "Fold: 19  Epoch: 241  Training loss = 2.7590  Validation loss = 2.7367  \n",
      "\n",
      "Fold: 19  Epoch: 242  Training loss = 2.7584  Validation loss = 2.7357  \n",
      "\n",
      "Fold: 19  Epoch: 243  Training loss = 2.7583  Validation loss = 2.7361  \n",
      "\n",
      "Fold: 19  Epoch: 244  Training loss = 2.7577  Validation loss = 2.7348  \n",
      "\n",
      "Fold: 19  Epoch: 245  Training loss = 2.7574  Validation loss = 2.7346  \n",
      "\n",
      "Fold: 19  Epoch: 246  Training loss = 2.7571  Validation loss = 2.7347  \n",
      "\n",
      "Fold: 19  Epoch: 247  Training loss = 2.7564  Validation loss = 2.7344  \n",
      "\n",
      "Fold: 19  Epoch: 248  Training loss = 2.7559  Validation loss = 2.7348  \n",
      "\n",
      "Fold: 19  Epoch: 249  Training loss = 2.7556  Validation loss = 2.7350  \n",
      "\n",
      "Fold: 19  Epoch: 250  Training loss = 2.7554  Validation loss = 2.7336  \n",
      "\n",
      "Fold: 19  Epoch: 251  Training loss = 2.7551  Validation loss = 2.7333  \n",
      "\n",
      "Fold: 19  Epoch: 252  Training loss = 2.7550  Validation loss = 2.7324  \n",
      "\n",
      "Fold: 19  Epoch: 253  Training loss = 2.7544  Validation loss = 2.7305  \n",
      "\n",
      "Fold: 19  Epoch: 254  Training loss = 2.7540  Validation loss = 2.7303  \n",
      "\n",
      "Fold: 19  Epoch: 255  Training loss = 2.7539  Validation loss = 2.7302  \n",
      "\n",
      "Fold: 19  Epoch: 256  Training loss = 2.7536  Validation loss = 2.7311  \n",
      "\n",
      "Fold: 19  Epoch: 257  Training loss = 2.7530  Validation loss = 2.7310  \n",
      "\n",
      "Fold: 19  Epoch: 258  Training loss = 2.7526  Validation loss = 2.7303  \n",
      "\n",
      "Fold: 19  Epoch: 259  Training loss = 2.7524  Validation loss = 2.7302  \n",
      "\n",
      "Fold: 19  Epoch: 260  Training loss = 2.7520  Validation loss = 2.7302  \n",
      "\n",
      "Fold: 19  Epoch: 261  Training loss = 2.7513  Validation loss = 2.7315  \n",
      "\n",
      "Fold: 19  Epoch: 262  Training loss = 2.7513  Validation loss = 2.7309  \n",
      "\n",
      "Fold: 19  Epoch: 263  Training loss = 2.7507  Validation loss = 2.7314  \n",
      "\n",
      "Fold: 19  Epoch: 264  Training loss = 2.7503  Validation loss = 2.7321  \n",
      "\n",
      "Fold: 19  Epoch: 265  Training loss = 2.7497  Validation loss = 2.7330  \n",
      "\n",
      "Fold: 19  Epoch: 266  Training loss = 2.7493  Validation loss = 2.7326  \n",
      "\n",
      "Fold: 19  Epoch: 267  Training loss = 2.7490  Validation loss = 2.7329  \n",
      "\n",
      "Fold: 19  Epoch: 268  Training loss = 2.7488  Validation loss = 2.7334  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 259  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.8211  Validation loss = 1.5285  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.8206  Validation loss = 1.5264  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.8201  Validation loss = 1.5242  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.8196  Validation loss = 1.5242  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.8192  Validation loss = 1.5245  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.8180  Validation loss = 1.5203  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.8175  Validation loss = 1.5205  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.8169  Validation loss = 1.5196  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.8162  Validation loss = 1.5195  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.8167  Validation loss = 1.5161  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.8156  Validation loss = 1.5129  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.8145  Validation loss = 1.5102  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 2.8146  Validation loss = 1.5110  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.8142  Validation loss = 1.5106  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.8133  Validation loss = 1.5066  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.8128  Validation loss = 1.5048  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.8124  Validation loss = 1.5040  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.8121  Validation loss = 1.5034  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 2.8110  Validation loss = 1.5017  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 2.8106  Validation loss = 1.4991  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 2.8103  Validation loss = 1.4997  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 2.8101  Validation loss = 1.4984  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 2.8101  Validation loss = 1.4992  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 2.8090  Validation loss = 1.4958  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 2.8087  Validation loss = 1.4954  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 2.8081  Validation loss = 1.4962  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 2.8073  Validation loss = 1.4936  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 2.8068  Validation loss = 1.4925  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 2.8059  Validation loss = 1.4886  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 2.8057  Validation loss = 1.4895  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 2.8054  Validation loss = 1.4873  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 2.8051  Validation loss = 1.4847  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 2.8053  Validation loss = 1.4843  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 2.8051  Validation loss = 1.4840  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 2.8043  Validation loss = 1.4807  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 2.8037  Validation loss = 1.4809  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 2.8036  Validation loss = 1.4804  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 2.8053  Validation loss = 1.4818  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 2.8033  Validation loss = 1.4775  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 2.8028  Validation loss = 1.4767  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 2.8023  Validation loss = 1.4781  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 2.8019  Validation loss = 1.4773  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 2.8007  Validation loss = 1.4769  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 2.8000  Validation loss = 1.4758  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 2.7998  Validation loss = 1.4746  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 2.7994  Validation loss = 1.4730  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 2.7992  Validation loss = 1.4731  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 2.7999  Validation loss = 1.4738  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 2.7989  Validation loss = 1.4713  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 2.7977  Validation loss = 1.4715  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 2.7976  Validation loss = 1.4697  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 2.7965  Validation loss = 1.4675  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 2.7957  Validation loss = 1.4643  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 2.7949  Validation loss = 1.4618  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 2.7946  Validation loss = 1.4607  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 2.7943  Validation loss = 1.4607  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 2.7939  Validation loss = 1.4579  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 2.7932  Validation loss = 1.4565  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 2.7932  Validation loss = 1.4563  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 2.7928  Validation loss = 1.4582  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 2.7924  Validation loss = 1.4567  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 2.7920  Validation loss = 1.4566  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 2.7915  Validation loss = 1.4556  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 2.7909  Validation loss = 1.4535  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 2.7902  Validation loss = 1.4502  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 2.7897  Validation loss = 1.4494  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 2.7893  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 2.7890  Validation loss = 1.4469  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 2.7883  Validation loss = 1.4446  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 2.7877  Validation loss = 1.4429  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 2.7872  Validation loss = 1.4407  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 2.7869  Validation loss = 1.4404  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 2.7866  Validation loss = 1.4403  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 2.7864  Validation loss = 1.4396  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 2.7861  Validation loss = 1.4381  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 2.7854  Validation loss = 1.4352  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 2.7867  Validation loss = 1.4386  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 2.7862  Validation loss = 1.4378  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 2.7857  Validation loss = 1.4378  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 2.7855  Validation loss = 1.4378  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 2.7845  Validation loss = 1.4344  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 2.7839  Validation loss = 1.4325  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 2.7832  Validation loss = 1.4315  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 2.7826  Validation loss = 1.4316  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 2.7818  Validation loss = 1.4307  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 2.7811  Validation loss = 1.4271  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 2.7806  Validation loss = 1.4237  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 2.7801  Validation loss = 1.4244  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 2.7805  Validation loss = 1.4212  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 2.7802  Validation loss = 1.4215  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 2.7794  Validation loss = 1.4191  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 2.7788  Validation loss = 1.4158  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 2.7789  Validation loss = 1.4163  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 2.7781  Validation loss = 1.4149  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 2.7774  Validation loss = 1.4125  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 2.7769  Validation loss = 1.4137  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 2.7764  Validation loss = 1.4131  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 2.7760  Validation loss = 1.4118  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 2.7754  Validation loss = 1.4107  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 2.7750  Validation loss = 1.4101  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 2.7744  Validation loss = 1.4078  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 2.7737  Validation loss = 1.4082  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 2.7734  Validation loss = 1.4070  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 2.7728  Validation loss = 1.4063  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 2.7724  Validation loss = 1.4064  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 2.7716  Validation loss = 1.4039  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 2.7714  Validation loss = 1.4041  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 2.7713  Validation loss = 1.4037  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 2.7710  Validation loss = 1.4021  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 2.7702  Validation loss = 1.3987  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 2.7695  Validation loss = 1.3957  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 2.7684  Validation loss = 1.3914  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 2.7693  Validation loss = 1.3931  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 2.7685  Validation loss = 1.3920  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 2.7677  Validation loss = 1.3929  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 2.7674  Validation loss = 1.3935  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 2.7665  Validation loss = 1.3902  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 2.7660  Validation loss = 1.3900  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 2.7654  Validation loss = 1.3889  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 2.7647  Validation loss = 1.3861  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 2.7643  Validation loss = 1.3853  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 2.7637  Validation loss = 1.3829  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 2.7646  Validation loss = 1.3833  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 2.7630  Validation loss = 1.3805  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 2.7620  Validation loss = 1.3780  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 2.7614  Validation loss = 1.3769  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 2.7611  Validation loss = 1.3764  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 2.7606  Validation loss = 1.3753  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 2.7602  Validation loss = 1.3750  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 2.7597  Validation loss = 1.3723  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 2.7591  Validation loss = 1.3716  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 2.7593  Validation loss = 1.3693  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 2.7585  Validation loss = 1.3691  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 2.7576  Validation loss = 1.3672  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 2.7571  Validation loss = 1.3672  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 2.7580  Validation loss = 1.3678  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 2.7572  Validation loss = 1.3676  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 2.7565  Validation loss = 1.3659  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 2.7557  Validation loss = 1.3663  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 2.7552  Validation loss = 1.3637  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 2.7554  Validation loss = 1.3630  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 2.7546  Validation loss = 1.3611  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 2.7536  Validation loss = 1.3589  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 2.7532  Validation loss = 1.3563  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 2.7527  Validation loss = 1.3554  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 2.7520  Validation loss = 1.3549  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 2.7517  Validation loss = 1.3540  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 2.7514  Validation loss = 1.3545  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 2.7509  Validation loss = 1.3511  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 2.7508  Validation loss = 1.3508  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 2.7504  Validation loss = 1.3466  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 2.7495  Validation loss = 1.3472  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 2.7488  Validation loss = 1.3441  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 2.7483  Validation loss = 1.3422  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 2.7484  Validation loss = 1.3411  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 2.7488  Validation loss = 1.3404  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 2.7482  Validation loss = 1.3409  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 2.7471  Validation loss = 1.3414  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 2.7463  Validation loss = 1.3409  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 2.7460  Validation loss = 1.3408  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 2.7455  Validation loss = 1.3412  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 2.7442  Validation loss = 1.3396  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 2.7435  Validation loss = 1.3383  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 2.7429  Validation loss = 1.3381  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 2.7423  Validation loss = 1.3370  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 2.7419  Validation loss = 1.3361  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 2.7429  Validation loss = 1.3355  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 2.7418  Validation loss = 1.3304  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 2.7412  Validation loss = 1.3287  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 2.7401  Validation loss = 1.3274  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 2.7393  Validation loss = 1.3253  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 2.7386  Validation loss = 1.3241  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 2.7384  Validation loss = 1.3233  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 2.7377  Validation loss = 1.3208  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 2.7367  Validation loss = 1.3161  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 2.7362  Validation loss = 1.3148  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 2.7359  Validation loss = 1.3128  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 2.7354  Validation loss = 1.3103  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 2.7349  Validation loss = 1.3091  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 2.7348  Validation loss = 1.3090  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 2.7343  Validation loss = 1.3073  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 2.7337  Validation loss = 1.3057  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 2.7332  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 2.7331  Validation loss = 1.3045  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 2.7325  Validation loss = 1.3035  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 2.7322  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 2.7318  Validation loss = 1.3025  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 2.7363  Validation loss = 1.3034  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 2.7327  Validation loss = 1.3055  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 2.7312  Validation loss = 1.3011  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 2.7300  Validation loss = 1.2999  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 2.7290  Validation loss = 1.2972  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 2.7290  Validation loss = 1.2984  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 2.7287  Validation loss = 1.2990  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 2.7282  Validation loss = 1.2964  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 2.7276  Validation loss = 1.2935  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 2.7267  Validation loss = 1.2902  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 2.7260  Validation loss = 1.2879  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 2.7265  Validation loss = 1.2869  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 2.7248  Validation loss = 1.2837  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 2.7244  Validation loss = 1.2824  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 2.7246  Validation loss = 1.2813  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 2.7235  Validation loss = 1.2784  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 2.7229  Validation loss = 1.2782  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 2.7224  Validation loss = 1.2763  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 2.7215  Validation loss = 1.2756  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 2.7206  Validation loss = 1.2713  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 2.7201  Validation loss = 1.2708  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 2.7197  Validation loss = 1.2716  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 2.7261  Validation loss = 1.2716  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 2.7196  Validation loss = 1.2727  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 2.7186  Validation loss = 1.2685  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 2.7180  Validation loss = 1.2651  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 2.7179  Validation loss = 1.2637  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 2.7169  Validation loss = 1.2607  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 2.7160  Validation loss = 1.2599  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 2.7155  Validation loss = 1.2588  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 2.7155  Validation loss = 1.2578  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 2.7146  Validation loss = 1.2588  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 2.7136  Validation loss = 1.2577  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 2.7130  Validation loss = 1.2565  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 2.7121  Validation loss = 1.2553  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 2.7116  Validation loss = 1.2552  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 2.7113  Validation loss = 1.2531  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 2.7112  Validation loss = 1.2539  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 2.7105  Validation loss = 1.2514  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 2.7100  Validation loss = 1.2489  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 2.7095  Validation loss = 1.2456  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 2.7091  Validation loss = 1.2427  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 2.7085  Validation loss = 1.2434  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 2.7083  Validation loss = 1.2442  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 2.7076  Validation loss = 1.2430  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 2.7074  Validation loss = 1.2408  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 2.7071  Validation loss = 1.2350  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 2.7073  Validation loss = 1.2342  \n",
      "\n",
      "Fold: 20  Epoch: 236  Training loss = 2.7067  Validation loss = 1.2326  \n",
      "\n",
      "Fold: 20  Epoch: 237  Training loss = 2.7065  Validation loss = 1.2298  \n",
      "\n",
      "Fold: 20  Epoch: 238  Training loss = 2.7076  Validation loss = 1.2326  \n",
      "\n",
      "Fold: 20  Epoch: 239  Training loss = 2.7068  Validation loss = 1.2307  \n",
      "\n",
      "Fold: 20  Epoch: 240  Training loss = 2.7053  Validation loss = 1.2303  \n",
      "\n",
      "Fold: 20  Epoch: 241  Training loss = 2.7038  Validation loss = 1.2273  \n",
      "\n",
      "Fold: 20  Epoch: 242  Training loss = 2.7035  Validation loss = 1.2240  \n",
      "\n",
      "Fold: 20  Epoch: 243  Training loss = 2.7028  Validation loss = 1.2246  \n",
      "\n",
      "Fold: 20  Epoch: 244  Training loss = 2.7028  Validation loss = 1.2221  \n",
      "\n",
      "Fold: 20  Epoch: 245  Training loss = 2.7024  Validation loss = 1.2188  \n",
      "\n",
      "Fold: 20  Epoch: 246  Training loss = 2.7017  Validation loss = 1.2174  \n",
      "\n",
      "Fold: 20  Epoch: 247  Training loss = 2.7012  Validation loss = 1.2153  \n",
      "\n",
      "Fold: 20  Epoch: 248  Training loss = 2.7005  Validation loss = 1.2136  \n",
      "\n",
      "Fold: 20  Epoch: 249  Training loss = 2.6998  Validation loss = 1.2131  \n",
      "\n",
      "Fold: 20  Epoch: 250  Training loss = 2.7029  Validation loss = 1.2125  \n",
      "\n",
      "Fold: 20  Epoch: 251  Training loss = 2.6989  Validation loss = 1.2133  \n",
      "\n",
      "Fold: 20  Epoch: 252  Training loss = 2.6986  Validation loss = 1.2104  \n",
      "\n",
      "Fold: 20  Epoch: 253  Training loss = 2.6979  Validation loss = 1.2086  \n",
      "\n",
      "Fold: 20  Epoch: 254  Training loss = 2.6976  Validation loss = 1.2089  \n",
      "\n",
      "Fold: 20  Epoch: 255  Training loss = 2.6971  Validation loss = 1.2068  \n",
      "\n",
      "Fold: 20  Epoch: 256  Training loss = 2.6964  Validation loss = 1.2035  \n",
      "\n",
      "Fold: 20  Epoch: 257  Training loss = 2.6961  Validation loss = 1.2015  \n",
      "\n",
      "Fold: 20  Epoch: 258  Training loss = 2.6954  Validation loss = 1.2011  \n",
      "\n",
      "Fold: 20  Epoch: 259  Training loss = 2.6954  Validation loss = 1.1991  \n",
      "\n",
      "Fold: 20  Epoch: 260  Training loss = 2.6952  Validation loss = 1.1982  \n",
      "\n",
      "Fold: 20  Epoch: 261  Training loss = 2.6947  Validation loss = 1.1972  \n",
      "\n",
      "Fold: 20  Epoch: 262  Training loss = 2.6941  Validation loss = 1.1961  \n",
      "\n",
      "Fold: 20  Epoch: 263  Training loss = 2.6935  Validation loss = 1.1973  \n",
      "\n",
      "Fold: 20  Epoch: 264  Training loss = 2.6930  Validation loss = 1.1949  \n",
      "\n",
      "Fold: 20  Epoch: 265  Training loss = 2.6924  Validation loss = 1.1958  \n",
      "\n",
      "Fold: 20  Epoch: 266  Training loss = 2.6921  Validation loss = 1.1926  \n",
      "\n",
      "Fold: 20  Epoch: 267  Training loss = 2.6910  Validation loss = 1.1925  \n",
      "\n",
      "Fold: 20  Epoch: 268  Training loss = 2.6904  Validation loss = 1.1911  \n",
      "\n",
      "Fold: 20  Epoch: 269  Training loss = 2.6897  Validation loss = 1.1890  \n",
      "\n",
      "Fold: 20  Epoch: 270  Training loss = 2.6894  Validation loss = 1.1876  \n",
      "\n",
      "Fold: 20  Epoch: 271  Training loss = 2.6891  Validation loss = 1.1875  \n",
      "\n",
      "Fold: 20  Epoch: 272  Training loss = 2.6903  Validation loss = 1.1892  \n",
      "\n",
      "Fold: 20  Epoch: 273  Training loss = 2.6897  Validation loss = 1.1904  \n",
      "\n",
      "Fold: 20  Epoch: 274  Training loss = 2.6897  Validation loss = 1.1889  \n",
      "\n",
      "Fold: 20  Epoch: 275  Training loss = 2.6887  Validation loss = 1.1865  \n",
      "\n",
      "Fold: 20  Epoch: 276  Training loss = 2.6878  Validation loss = 1.1853  \n",
      "\n",
      "Fold: 20  Epoch: 277  Training loss = 2.6875  Validation loss = 1.1857  \n",
      "\n",
      "Fold: 20  Epoch: 278  Training loss = 2.6869  Validation loss = 1.1842  \n",
      "\n",
      "Fold: 20  Epoch: 279  Training loss = 2.6862  Validation loss = 1.1843  \n",
      "\n",
      "Fold: 20  Epoch: 280  Training loss = 2.6860  Validation loss = 1.1859  \n",
      "\n",
      "Fold: 20  Epoch: 281  Training loss = 2.6859  Validation loss = 1.1850  \n",
      "\n",
      "Fold: 20  Epoch: 282  Training loss = 2.6858  Validation loss = 1.1847  \n",
      "\n",
      "Fold: 20  Epoch: 283  Training loss = 2.6856  Validation loss = 1.1842  \n",
      "\n",
      "Fold: 20  Epoch: 284  Training loss = 2.6857  Validation loss = 1.1851  \n",
      "\n",
      "Fold: 20  Epoch: 285  Training loss = 2.6849  Validation loss = 1.1823  \n",
      "\n",
      "Fold: 20  Epoch: 286  Training loss = 2.6845  Validation loss = 1.1831  \n",
      "\n",
      "Fold: 20  Epoch: 287  Training loss = 2.6838  Validation loss = 1.1815  \n",
      "\n",
      "Fold: 20  Epoch: 288  Training loss = 2.6834  Validation loss = 1.1809  \n",
      "\n",
      "Fold: 20  Epoch: 289  Training loss = 2.6826  Validation loss = 1.1802  \n",
      "\n",
      "Fold: 20  Epoch: 290  Training loss = 2.6820  Validation loss = 1.1774  \n",
      "\n",
      "Fold: 20  Epoch: 291  Training loss = 2.6815  Validation loss = 1.1772  \n",
      "\n",
      "Fold: 20  Epoch: 292  Training loss = 2.6812  Validation loss = 1.1777  \n",
      "\n",
      "Fold: 20  Epoch: 293  Training loss = 2.6804  Validation loss = 1.1758  \n",
      "\n",
      "Fold: 20  Epoch: 294  Training loss = 2.6802  Validation loss = 1.1781  \n",
      "\n",
      "Fold: 20  Epoch: 295  Training loss = 2.6797  Validation loss = 1.1775  \n",
      "\n",
      "Fold: 20  Epoch: 296  Training loss = 2.6788  Validation loss = 1.1755  \n",
      "\n",
      "Fold: 20  Epoch: 297  Training loss = 2.6791  Validation loss = 1.1753  \n",
      "\n",
      "Fold: 20  Epoch: 298  Training loss = 2.6776  Validation loss = 1.1736  \n",
      "\n",
      "Fold: 20  Epoch: 299  Training loss = 2.6770  Validation loss = 1.1727  \n",
      "\n",
      "Fold: 20  Epoch: 300  Training loss = 2.6764  Validation loss = 1.1701  \n",
      "\n",
      "Fold: 20  Epoch: 301  Training loss = 2.6762  Validation loss = 1.1707  \n",
      "\n",
      "Fold: 20  Epoch: 302  Training loss = 2.6757  Validation loss = 1.1696  \n",
      "\n",
      "Fold: 20  Epoch: 303  Training loss = 2.6750  Validation loss = 1.1682  \n",
      "\n",
      "Fold: 20  Epoch: 304  Training loss = 2.6748  Validation loss = 1.1669  \n",
      "\n",
      "Fold: 20  Epoch: 305  Training loss = 2.6743  Validation loss = 1.1667  \n",
      "\n",
      "Fold: 20  Epoch: 306  Training loss = 2.6739  Validation loss = 1.1646  \n",
      "\n",
      "Fold: 20  Epoch: 307  Training loss = 2.6731  Validation loss = 1.1618  \n",
      "\n",
      "Fold: 20  Epoch: 308  Training loss = 2.6726  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 20  Epoch: 309  Training loss = 2.6726  Validation loss = 1.1581  \n",
      "\n",
      "Fold: 20  Epoch: 310  Training loss = 2.6723  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 20  Epoch: 311  Training loss = 2.6714  Validation loss = 1.1555  \n",
      "\n",
      "Fold: 20  Epoch: 312  Training loss = 2.6709  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 20  Epoch: 313  Training loss = 2.6708  Validation loss = 1.1524  \n",
      "\n",
      "Fold: 20  Epoch: 314  Training loss = 2.6705  Validation loss = 1.1517  \n",
      "\n",
      "Fold: 20  Epoch: 315  Training loss = 2.6701  Validation loss = 1.1521  \n",
      "\n",
      "Fold: 20  Epoch: 316  Training loss = 2.6695  Validation loss = 1.1509  \n",
      "\n",
      "Fold: 20  Epoch: 317  Training loss = 2.6689  Validation loss = 1.1499  \n",
      "\n",
      "Fold: 20  Epoch: 318  Training loss = 2.6685  Validation loss = 1.1491  \n",
      "\n",
      "Fold: 20  Epoch: 319  Training loss = 2.6680  Validation loss = 1.1491  \n",
      "\n",
      "Fold: 20  Epoch: 320  Training loss = 2.6677  Validation loss = 1.1498  \n",
      "\n",
      "Fold: 20  Epoch: 321  Training loss = 2.6678  Validation loss = 1.1505  \n",
      "\n",
      "Fold: 20  Epoch: 322  Training loss = 2.6671  Validation loss = 1.1495  \n",
      "\n",
      "Fold: 20  Epoch: 323  Training loss = 2.6666  Validation loss = 1.1492  \n",
      "\n",
      "Fold: 20  Epoch: 324  Training loss = 2.6664  Validation loss = 1.1466  \n",
      "\n",
      "Fold: 20  Epoch: 325  Training loss = 2.6657  Validation loss = 1.1452  \n",
      "\n",
      "Fold: 20  Epoch: 326  Training loss = 2.6668  Validation loss = 1.1423  \n",
      "\n",
      "Fold: 20  Epoch: 327  Training loss = 2.6655  Validation loss = 1.1393  \n",
      "\n",
      "Fold: 20  Epoch: 328  Training loss = 2.6646  Validation loss = 1.1361  \n",
      "\n",
      "Fold: 20  Epoch: 329  Training loss = 2.6650  Validation loss = 1.1344  \n",
      "\n",
      "Fold: 20  Epoch: 330  Training loss = 2.6647  Validation loss = 1.1337  \n",
      "\n",
      "Fold: 20  Epoch: 331  Training loss = 2.6647  Validation loss = 1.1324  \n",
      "\n",
      "Fold: 20  Epoch: 332  Training loss = 2.6652  Validation loss = 1.1311  \n",
      "\n",
      "Fold: 20  Epoch: 333  Training loss = 2.6644  Validation loss = 1.1306  \n",
      "\n",
      "Fold: 20  Epoch: 334  Training loss = 2.6649  Validation loss = 1.1285  \n",
      "\n",
      "Fold: 20  Epoch: 335  Training loss = 2.6661  Validation loss = 1.1274  \n",
      "\n",
      "Fold: 20  Epoch: 336  Training loss = 2.6639  Validation loss = 1.1268  \n",
      "\n",
      "Fold: 20  Epoch: 337  Training loss = 2.6612  Validation loss = 1.1290  \n",
      "\n",
      "Fold: 20  Epoch: 338  Training loss = 2.6608  Validation loss = 1.1273  \n",
      "\n",
      "Fold: 20  Epoch: 339  Training loss = 2.6597  Validation loss = 1.1261  \n",
      "\n",
      "Fold: 20  Epoch: 340  Training loss = 2.6592  Validation loss = 1.1261  \n",
      "\n",
      "Fold: 20  Epoch: 341  Training loss = 2.6591  Validation loss = 1.1233  \n",
      "\n",
      "Fold: 20  Epoch: 342  Training loss = 2.6585  Validation loss = 1.1221  \n",
      "\n",
      "Fold: 20  Epoch: 343  Training loss = 2.6578  Validation loss = 1.1193  \n",
      "\n",
      "Fold: 20  Epoch: 344  Training loss = 2.6576  Validation loss = 1.1176  \n",
      "\n",
      "Fold: 20  Epoch: 345  Training loss = 2.6571  Validation loss = 1.1158  \n",
      "\n",
      "Fold: 20  Epoch: 346  Training loss = 2.6564  Validation loss = 1.1169  \n",
      "\n",
      "Fold: 20  Epoch: 347  Training loss = 2.6563  Validation loss = 1.1170  \n",
      "\n",
      "Fold: 20  Epoch: 348  Training loss = 2.6562  Validation loss = 1.1149  \n",
      "\n",
      "Fold: 20  Epoch: 349  Training loss = 2.6560  Validation loss = 1.1122  \n",
      "\n",
      "Fold: 20  Epoch: 350  Training loss = 2.6554  Validation loss = 1.1127  \n",
      "\n",
      "Fold: 20  Epoch: 351  Training loss = 2.6546  Validation loss = 1.1110  \n",
      "\n",
      "Fold: 20  Epoch: 352  Training loss = 2.6546  Validation loss = 1.1096  \n",
      "\n",
      "Fold: 20  Epoch: 353  Training loss = 2.6538  Validation loss = 1.1079  \n",
      "\n",
      "Fold: 20  Epoch: 354  Training loss = 2.6535  Validation loss = 1.1068  \n",
      "\n",
      "Fold: 20  Epoch: 355  Training loss = 2.6531  Validation loss = 1.1039  \n",
      "\n",
      "Fold: 20  Epoch: 356  Training loss = 2.6531  Validation loss = 1.1039  \n",
      "\n",
      "Fold: 20  Epoch: 357  Training loss = 2.6528  Validation loss = 1.1027  \n",
      "\n",
      "Fold: 20  Epoch: 358  Training loss = 2.6524  Validation loss = 1.1006  \n",
      "\n",
      "Fold: 20  Epoch: 359  Training loss = 2.6520  Validation loss = 1.1000  \n",
      "\n",
      "Fold: 20  Epoch: 360  Training loss = 2.6516  Validation loss = 1.0990  \n",
      "\n",
      "Fold: 20  Epoch: 361  Training loss = 2.6515  Validation loss = 1.0987  \n",
      "\n",
      "Fold: 20  Epoch: 362  Training loss = 2.6519  Validation loss = 1.0981  \n",
      "\n",
      "Fold: 20  Epoch: 363  Training loss = 2.6523  Validation loss = 1.0986  \n",
      "\n",
      "Fold: 20  Epoch: 364  Training loss = 2.6510  Validation loss = 1.0969  \n",
      "\n",
      "Fold: 20  Epoch: 365  Training loss = 2.6509  Validation loss = 1.0974  \n",
      "\n",
      "Fold: 20  Epoch: 366  Training loss = 2.6495  Validation loss = 1.0972  \n",
      "\n",
      "Fold: 20  Epoch: 367  Training loss = 2.6491  Validation loss = 1.0981  \n",
      "\n",
      "Fold: 20  Epoch: 368  Training loss = 2.6488  Validation loss = 1.0978  \n",
      "\n",
      "Fold: 20  Epoch: 369  Training loss = 2.6484  Validation loss = 1.0957  \n",
      "\n",
      "Fold: 20  Epoch: 370  Training loss = 2.6490  Validation loss = 1.0953  \n",
      "\n",
      "Fold: 20  Epoch: 371  Training loss = 2.6482  Validation loss = 1.0950  \n",
      "\n",
      "Fold: 20  Epoch: 372  Training loss = 2.6514  Validation loss = 1.0930  \n",
      "\n",
      "Fold: 20  Epoch: 373  Training loss = 2.6507  Validation loss = 1.0930  \n",
      "\n",
      "Fold: 20  Epoch: 374  Training loss = 2.6485  Validation loss = 1.0909  \n",
      "\n",
      "Fold: 20  Epoch: 375  Training loss = 2.6475  Validation loss = 1.0906  \n",
      "\n",
      "Fold: 20  Epoch: 376  Training loss = 2.6470  Validation loss = 1.0915  \n",
      "\n",
      "Fold: 20  Epoch: 377  Training loss = 2.6460  Validation loss = 1.0901  \n",
      "\n",
      "Fold: 20  Epoch: 378  Training loss = 2.6471  Validation loss = 1.0892  \n",
      "\n",
      "Fold: 20  Epoch: 379  Training loss = 2.6463  Validation loss = 1.0859  \n",
      "\n",
      "Fold: 20  Epoch: 380  Training loss = 2.6453  Validation loss = 1.0858  \n",
      "\n",
      "Fold: 20  Epoch: 381  Training loss = 2.6439  Validation loss = 1.0847  \n",
      "\n",
      "Fold: 20  Epoch: 382  Training loss = 2.6439  Validation loss = 1.0852  \n",
      "\n",
      "Fold: 20  Epoch: 383  Training loss = 2.6431  Validation loss = 1.0871  \n",
      "\n",
      "Fold: 20  Epoch: 384  Training loss = 2.6424  Validation loss = 1.0833  \n",
      "\n",
      "Fold: 20  Epoch: 385  Training loss = 2.6417  Validation loss = 1.0824  \n",
      "\n",
      "Fold: 20  Epoch: 386  Training loss = 2.6419  Validation loss = 1.0830  \n",
      "\n",
      "Fold: 20  Epoch: 387  Training loss = 2.6415  Validation loss = 1.0808  \n",
      "\n",
      "Fold: 20  Epoch: 388  Training loss = 2.6429  Validation loss = 1.0772  \n",
      "\n",
      "Fold: 20  Epoch: 389  Training loss = 2.6432  Validation loss = 1.0774  \n",
      "\n",
      "Fold: 20  Epoch: 390  Training loss = 2.6448  Validation loss = 1.0761  \n",
      "\n",
      "Fold: 20  Epoch: 391  Training loss = 2.6422  Validation loss = 1.0737  \n",
      "\n",
      "Fold: 20  Epoch: 392  Training loss = 2.6421  Validation loss = 1.0714  \n",
      "\n",
      "Fold: 20  Epoch: 393  Training loss = 2.6398  Validation loss = 1.0734  \n",
      "\n",
      "Fold: 20  Epoch: 394  Training loss = 2.6396  Validation loss = 1.0714  \n",
      "\n",
      "Fold: 20  Epoch: 395  Training loss = 2.6407  Validation loss = 1.0691  \n",
      "\n",
      "Fold: 20  Epoch: 396  Training loss = 2.6382  Validation loss = 1.0666  \n",
      "\n",
      "Fold: 20  Epoch: 397  Training loss = 2.6374  Validation loss = 1.0677  \n",
      "\n",
      "Fold: 20  Epoch: 398  Training loss = 2.6386  Validation loss = 1.0676  \n",
      "\n",
      "Fold: 20  Epoch: 399  Training loss = 2.6403  Validation loss = 1.0699  \n",
      "\n",
      "Fold: 20  Epoch: 400  Training loss = 2.6388  Validation loss = 1.0676  \n",
      "\n",
      "Fold: 20  Epoch: 401  Training loss = 2.6361  Validation loss = 1.0637  \n",
      "\n",
      "Fold: 20  Epoch: 402  Training loss = 2.6363  Validation loss = 1.0624  \n",
      "\n",
      "Fold: 20  Epoch: 403  Training loss = 2.6350  Validation loss = 1.0642  \n",
      "\n",
      "Fold: 20  Epoch: 404  Training loss = 2.6354  Validation loss = 1.0632  \n",
      "\n",
      "Fold: 20  Epoch: 405  Training loss = 2.6344  Validation loss = 1.0614  \n",
      "\n",
      "Fold: 20  Epoch: 406  Training loss = 2.6332  Validation loss = 1.0626  \n",
      "\n",
      "Fold: 20  Epoch: 407  Training loss = 2.6329  Validation loss = 1.0613  \n",
      "\n",
      "Fold: 20  Epoch: 408  Training loss = 2.6325  Validation loss = 1.0599  \n",
      "\n",
      "Fold: 20  Epoch: 409  Training loss = 2.6324  Validation loss = 1.0593  \n",
      "\n",
      "Fold: 20  Epoch: 410  Training loss = 2.6344  Validation loss = 1.0575  \n",
      "\n",
      "Fold: 20  Epoch: 411  Training loss = 2.6337  Validation loss = 1.0568  \n",
      "\n",
      "Fold: 20  Epoch: 412  Training loss = 2.6316  Validation loss = 1.0594  \n",
      "\n",
      "Fold: 20  Epoch: 413  Training loss = 2.6303  Validation loss = 1.0599  \n",
      "\n",
      "Fold: 20  Epoch: 414  Training loss = 2.6298  Validation loss = 1.0590  \n",
      "\n",
      "Fold: 20  Epoch: 415  Training loss = 2.6291  Validation loss = 1.0570  \n",
      "\n",
      "Fold: 20  Epoch: 416  Training loss = 2.6283  Validation loss = 1.0576  \n",
      "\n",
      "Fold: 20  Epoch: 417  Training loss = 2.6279  Validation loss = 1.0573  \n",
      "\n",
      "Fold: 20  Epoch: 418  Training loss = 2.6279  Validation loss = 1.0569  \n",
      "\n",
      "Fold: 20  Epoch: 419  Training loss = 2.6270  Validation loss = 1.0567  \n",
      "\n",
      "Fold: 20  Epoch: 420  Training loss = 2.6267  Validation loss = 1.0561  \n",
      "\n",
      "Fold: 20  Epoch: 421  Training loss = 2.6269  Validation loss = 1.0540  \n",
      "\n",
      "Fold: 20  Epoch: 422  Training loss = 2.6266  Validation loss = 1.0528  \n",
      "\n",
      "Fold: 20  Epoch: 423  Training loss = 2.6255  Validation loss = 1.0522  \n",
      "\n",
      "Fold: 20  Epoch: 424  Training loss = 2.6255  Validation loss = 1.0505  \n",
      "\n",
      "Fold: 20  Epoch: 425  Training loss = 2.6256  Validation loss = 1.0478  \n",
      "\n",
      "Fold: 20  Epoch: 426  Training loss = 2.6238  Validation loss = 1.0484  \n",
      "\n",
      "Fold: 20  Epoch: 427  Training loss = 2.6231  Validation loss = 1.0471  \n",
      "\n",
      "Fold: 20  Epoch: 428  Training loss = 2.6236  Validation loss = 1.0464  \n",
      "\n",
      "Fold: 20  Epoch: 429  Training loss = 2.6235  Validation loss = 1.0456  \n",
      "\n",
      "Fold: 20  Epoch: 430  Training loss = 2.6226  Validation loss = 1.0443  \n",
      "\n",
      "Fold: 20  Epoch: 431  Training loss = 2.6220  Validation loss = 1.0447  \n",
      "\n",
      "Fold: 20  Epoch: 432  Training loss = 2.6227  Validation loss = 1.0464  \n",
      "\n",
      "Fold: 20  Epoch: 433  Training loss = 2.6240  Validation loss = 1.0490  \n",
      "\n",
      "Fold: 20  Epoch: 434  Training loss = 2.6215  Validation loss = 1.0460  \n",
      "\n",
      "Fold: 20  Epoch: 435  Training loss = 2.6210  Validation loss = 1.0472  \n",
      "\n",
      "Fold: 20  Epoch: 436  Training loss = 2.6203  Validation loss = 1.0480  \n",
      "\n",
      "Fold: 20  Epoch: 437  Training loss = 2.6200  Validation loss = 1.0461  \n",
      "\n",
      "Fold: 20  Epoch: 438  Training loss = 2.6221  Validation loss = 1.0455  \n",
      "\n",
      "Fold: 20  Epoch: 439  Training loss = 2.6213  Validation loss = 1.0452  \n",
      "\n",
      "Fold: 20  Epoch: 440  Training loss = 2.6202  Validation loss = 1.0440  \n",
      "\n",
      "Fold: 20  Epoch: 441  Training loss = 2.6197  Validation loss = 1.0418  \n",
      "\n",
      "Fold: 20  Epoch: 442  Training loss = 2.6179  Validation loss = 1.0421  \n",
      "\n",
      "Fold: 20  Epoch: 443  Training loss = 2.6171  Validation loss = 1.0435  \n",
      "\n",
      "Fold: 20  Epoch: 444  Training loss = 2.6173  Validation loss = 1.0415  \n",
      "\n",
      "Fold: 20  Epoch: 445  Training loss = 2.6170  Validation loss = 1.0424  \n",
      "\n",
      "Fold: 20  Epoch: 446  Training loss = 2.6165  Validation loss = 1.0406  \n",
      "\n",
      "Fold: 20  Epoch: 447  Training loss = 2.6160  Validation loss = 1.0405  \n",
      "\n",
      "Fold: 20  Epoch: 448  Training loss = 2.6159  Validation loss = 1.0375  \n",
      "\n",
      "Fold: 20  Epoch: 449  Training loss = 2.6158  Validation loss = 1.0388  \n",
      "\n",
      "Fold: 20  Epoch: 450  Training loss = 2.6184  Validation loss = 1.0399  \n",
      "\n",
      "Fold: 20  Epoch: 451  Training loss = 2.6151  Validation loss = 1.0375  \n",
      "\n",
      "Fold: 20  Epoch: 452  Training loss = 2.6156  Validation loss = 1.0362  \n",
      "\n",
      "Fold: 20  Epoch: 453  Training loss = 2.6150  Validation loss = 1.0354  \n",
      "\n",
      "Fold: 20  Epoch: 454  Training loss = 2.6139  Validation loss = 1.0354  \n",
      "\n",
      "Fold: 20  Epoch: 455  Training loss = 2.6135  Validation loss = 1.0372  \n",
      "\n",
      "Fold: 20  Epoch: 456  Training loss = 2.6132  Validation loss = 1.0369  \n",
      "\n",
      "Fold: 20  Epoch: 457  Training loss = 2.6127  Validation loss = 1.0378  \n",
      "\n",
      "Fold: 20  Epoch: 458  Training loss = 2.6120  Validation loss = 1.0383  \n",
      "\n",
      "Fold: 20  Epoch: 459  Training loss = 2.6112  Validation loss = 1.0372  \n",
      "\n",
      "Fold: 20  Epoch: 460  Training loss = 2.6107  Validation loss = 1.0368  \n",
      "\n",
      "Fold: 20  Epoch: 461  Training loss = 2.6112  Validation loss = 1.0345  \n",
      "\n",
      "Fold: 20  Epoch: 462  Training loss = 2.6103  Validation loss = 1.0334  \n",
      "\n",
      "Fold: 20  Epoch: 463  Training loss = 2.6096  Validation loss = 1.0327  \n",
      "\n",
      "Fold: 20  Epoch: 464  Training loss = 2.6093  Validation loss = 1.0311  \n",
      "\n",
      "Fold: 20  Epoch: 465  Training loss = 2.6082  Validation loss = 1.0312  \n",
      "\n",
      "Fold: 20  Epoch: 466  Training loss = 2.6079  Validation loss = 1.0307  \n",
      "\n",
      "Fold: 20  Epoch: 467  Training loss = 2.6076  Validation loss = 1.0287  \n",
      "\n",
      "Fold: 20  Epoch: 468  Training loss = 2.6077  Validation loss = 1.0288  \n",
      "\n",
      "Fold: 20  Epoch: 469  Training loss = 2.6090  Validation loss = 1.0279  \n",
      "\n",
      "Fold: 20  Epoch: 470  Training loss = 2.6085  Validation loss = 1.0277  \n",
      "\n",
      "Fold: 20  Epoch: 471  Training loss = 2.6071  Validation loss = 1.0272  \n",
      "\n",
      "Fold: 20  Epoch: 472  Training loss = 2.6064  Validation loss = 1.0254  \n",
      "\n",
      "Fold: 20  Epoch: 473  Training loss = 2.6062  Validation loss = 1.0258  \n",
      "\n",
      "Fold: 20  Epoch: 474  Training loss = 2.6066  Validation loss = 1.0261  \n",
      "\n",
      "Fold: 20  Epoch: 475  Training loss = 2.6056  Validation loss = 1.0257  \n",
      "\n",
      "Fold: 20  Epoch: 476  Training loss = 2.6057  Validation loss = 1.0260  \n",
      "\n",
      "Fold: 20  Epoch: 477  Training loss = 2.6053  Validation loss = 1.0263  \n",
      "\n",
      "Fold: 20  Epoch: 478  Training loss = 2.6048  Validation loss = 1.0239  \n",
      "\n",
      "Fold: 20  Epoch: 479  Training loss = 2.6036  Validation loss = 1.0233  \n",
      "\n",
      "Fold: 20  Epoch: 480  Training loss = 2.6025  Validation loss = 1.0213  \n",
      "\n",
      "Fold: 20  Epoch: 481  Training loss = 2.6022  Validation loss = 1.0218  \n",
      "\n",
      "Fold: 20  Epoch: 482  Training loss = 2.6010  Validation loss = 1.0211  \n",
      "\n",
      "Fold: 20  Epoch: 483  Training loss = 2.6004  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 20  Epoch: 484  Training loss = 2.5999  Validation loss = 1.0190  \n",
      "\n",
      "Fold: 20  Epoch: 485  Training loss = 2.5996  Validation loss = 1.0197  \n",
      "\n",
      "Fold: 20  Epoch: 486  Training loss = 2.5993  Validation loss = 1.0169  \n",
      "\n",
      "Fold: 20  Epoch: 487  Training loss = 2.5988  Validation loss = 1.0163  \n",
      "\n",
      "Fold: 20  Epoch: 488  Training loss = 2.5987  Validation loss = 1.0176  \n",
      "\n",
      "Fold: 20  Epoch: 489  Training loss = 2.5980  Validation loss = 1.0151  \n",
      "\n",
      "Fold: 20  Epoch: 490  Training loss = 2.5976  Validation loss = 1.0149  \n",
      "\n",
      "Fold: 20  Epoch: 491  Training loss = 2.5974  Validation loss = 1.0154  \n",
      "\n",
      "Fold: 20  Epoch: 492  Training loss = 2.5966  Validation loss = 1.0128  \n",
      "\n",
      "Fold: 20  Epoch: 493  Training loss = 2.5963  Validation loss = 1.0112  \n",
      "\n",
      "Fold: 20  Epoch: 494  Training loss = 2.5961  Validation loss = 1.0109  \n",
      "\n",
      "Fold: 20  Epoch: 495  Training loss = 2.5962  Validation loss = 1.0084  \n",
      "\n",
      "Fold: 20  Epoch: 496  Training loss = 2.5960  Validation loss = 1.0085  \n",
      "\n",
      "Fold: 20  Epoch: 497  Training loss = 2.5953  Validation loss = 1.0087  \n",
      "\n",
      "Fold: 20  Epoch: 498  Training loss = 2.5946  Validation loss = 1.0088  \n",
      "\n",
      "Fold: 20  Epoch: 499  Training loss = 2.5947  Validation loss = 1.0074  \n",
      "\n",
      "Fold: 20  Epoch: 500  Training loss = 2.5943  Validation loss = 1.0080  \n",
      "\n",
      "Fold: 20  Epoch: 501  Training loss = 2.5945  Validation loss = 1.0073  \n",
      "\n",
      "Fold: 20  Epoch: 502  Training loss = 2.5978  Validation loss = 1.0084  \n",
      "\n",
      "Fold: 20  Epoch: 503  Training loss = 2.5970  Validation loss = 1.0092  \n",
      "\n",
      "Fold: 20  Epoch: 504  Training loss = 2.5945  Validation loss = 1.0057  \n",
      "\n",
      "Fold: 20  Epoch: 505  Training loss = 2.5942  Validation loss = 1.0034  \n",
      "\n",
      "Fold: 20  Epoch: 506  Training loss = 2.5941  Validation loss = 1.0041  \n",
      "\n",
      "Fold: 20  Epoch: 507  Training loss = 2.5936  Validation loss = 1.0039  \n",
      "\n",
      "Fold: 20  Epoch: 508  Training loss = 2.5966  Validation loss = 1.0022  \n",
      "\n",
      "Fold: 20  Epoch: 509  Training loss = 2.5938  Validation loss = 1.0010  \n",
      "\n",
      "Fold: 20  Epoch: 510  Training loss = 2.5917  Validation loss = 0.9994  \n",
      "\n",
      "Fold: 20  Epoch: 511  Training loss = 2.5909  Validation loss = 0.9968  \n",
      "\n",
      "Fold: 20  Epoch: 512  Training loss = 2.5905  Validation loss = 0.9953  \n",
      "\n",
      "Fold: 20  Epoch: 513  Training loss = 2.5903  Validation loss = 0.9949  \n",
      "\n",
      "Fold: 20  Epoch: 514  Training loss = 2.5897  Validation loss = 0.9945  \n",
      "\n",
      "Fold: 20  Epoch: 515  Training loss = 2.5888  Validation loss = 0.9941  \n",
      "\n",
      "Fold: 20  Epoch: 516  Training loss = 2.5891  Validation loss = 0.9940  \n",
      "\n",
      "Fold: 20  Epoch: 517  Training loss = 2.5888  Validation loss = 0.9922  \n",
      "\n",
      "Fold: 20  Epoch: 518  Training loss = 2.5881  Validation loss = 0.9910  \n",
      "\n",
      "Fold: 20  Epoch: 519  Training loss = 2.5884  Validation loss = 0.9907  \n",
      "\n",
      "Fold: 20  Epoch: 520  Training loss = 2.5904  Validation loss = 0.9900  \n",
      "\n",
      "Fold: 20  Epoch: 521  Training loss = 2.5884  Validation loss = 0.9890  \n",
      "\n",
      "Fold: 20  Epoch: 522  Training loss = 2.5883  Validation loss = 0.9897  \n",
      "\n",
      "Fold: 20  Epoch: 523  Training loss = 2.5873  Validation loss = 0.9886  \n",
      "\n",
      "Fold: 20  Epoch: 524  Training loss = 2.5876  Validation loss = 0.9870  \n",
      "\n",
      "Fold: 20  Epoch: 525  Training loss = 2.5865  Validation loss = 0.9859  \n",
      "\n",
      "Fold: 20  Epoch: 526  Training loss = 2.5860  Validation loss = 0.9878  \n",
      "\n",
      "Fold: 20  Epoch: 527  Training loss = 2.5853  Validation loss = 0.9886  \n",
      "\n",
      "Fold: 20  Epoch: 528  Training loss = 2.5856  Validation loss = 0.9904  \n",
      "\n",
      "Fold: 20  Epoch: 529  Training loss = 2.5875  Validation loss = 0.9888  \n",
      "\n",
      "Fold: 20  Epoch: 530  Training loss = 2.5858  Validation loss = 0.9889  \n",
      "\n",
      "Fold: 20  Epoch: 531  Training loss = 2.5844  Validation loss = 0.9888  \n",
      "\n",
      "Fold: 20  Epoch: 532  Training loss = 2.5844  Validation loss = 0.9888  \n",
      "\n",
      "Fold: 20  Epoch: 533  Training loss = 2.5839  Validation loss = 0.9891  \n",
      "\n",
      "Fold: 20  Epoch: 534  Training loss = 2.5841  Validation loss = 0.9888  \n",
      "\n",
      "Fold: 20  Epoch: 535  Training loss = 2.5843  Validation loss = 0.9879  \n",
      "\n",
      "Fold: 20  Epoch: 536  Training loss = 2.5838  Validation loss = 0.9877  \n",
      "\n",
      "Fold: 20  Epoch: 537  Training loss = 2.5837  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 20  Epoch: 538  Training loss = 2.5830  Validation loss = 0.9876  \n",
      "\n",
      "Fold: 20  Epoch: 539  Training loss = 2.5824  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 20  Epoch: 540  Training loss = 2.5828  Validation loss = 0.9863  \n",
      "\n",
      "Fold: 20  Epoch: 541  Training loss = 2.5836  Validation loss = 0.9864  \n",
      "\n",
      "Fold: 20  Epoch: 542  Training loss = 2.5833  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 20  Epoch: 543  Training loss = 2.5822  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 20  Epoch: 544  Training loss = 2.5825  Validation loss = 0.9845  \n",
      "\n",
      "Fold: 20  Epoch: 545  Training loss = 2.5835  Validation loss = 0.9831  \n",
      "\n",
      "Fold: 20  Epoch: 546  Training loss = 2.5803  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 20  Epoch: 547  Training loss = 2.5811  Validation loss = 0.9860  \n",
      "\n",
      "Fold: 20  Epoch: 548  Training loss = 2.5806  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 20  Epoch: 549  Training loss = 2.5815  Validation loss = 0.9828  \n",
      "\n",
      "Fold: 20  Epoch: 550  Training loss = 2.5802  Validation loss = 0.9827  \n",
      "\n",
      "Fold: 20  Epoch: 551  Training loss = 2.5776  Validation loss = 0.9824  \n",
      "\n",
      "Fold: 20  Epoch: 552  Training loss = 2.5784  Validation loss = 0.9796  \n",
      "\n",
      "Fold: 20  Epoch: 553  Training loss = 2.5788  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 20  Epoch: 554  Training loss = 2.5767  Validation loss = 0.9796  \n",
      "\n",
      "Fold: 20  Epoch: 555  Training loss = 2.5763  Validation loss = 0.9789  \n",
      "\n",
      "Fold: 20  Epoch: 556  Training loss = 2.5766  Validation loss = 0.9812  \n",
      "\n",
      "Fold: 20  Epoch: 557  Training loss = 2.5754  Validation loss = 0.9815  \n",
      "\n",
      "Fold: 20  Epoch: 558  Training loss = 2.5752  Validation loss = 0.9825  \n",
      "\n",
      "Fold: 20  Epoch: 559  Training loss = 2.5750  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 20  Epoch: 560  Training loss = 2.5763  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 20  Epoch: 561  Training loss = 2.5757  Validation loss = 0.9845  \n",
      "\n",
      "Fold: 20  Epoch: 562  Training loss = 2.5750  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 20  Epoch: 563  Training loss = 2.5743  Validation loss = 0.9873  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 555  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.5560  Validation loss = 3.8513  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.5552  Validation loss = 3.8367  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.5547  Validation loss = 3.8299  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.5544  Validation loss = 3.8541  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.5541  Validation loss = 3.8543  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.5543  Validation loss = 3.8323  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.5542  Validation loss = 3.8373  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.5525  Validation loss = 3.8344  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.5513  Validation loss = 3.8314  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.5523  Validation loss = 3.8741  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.5530  Validation loss = 3.8940  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.5502  Validation loss = 3.8583  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 2.5488  Validation loss = 3.8286  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 2.5476  Validation loss = 3.8454  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 2.5465  Validation loss = 3.8538  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 2.5408  Validation loss = 3.7874  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 2.5408  Validation loss = 3.7320  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 2.5395  Validation loss = 3.7866  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 2.5394  Validation loss = 3.7896  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 2.5388  Validation loss = 3.8025  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 2.5378  Validation loss = 3.7787  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 2.5374  Validation loss = 3.7992  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 2.5370  Validation loss = 3.8068  \n",
      "\n",
      "Fold: 21  Epoch: 24  Training loss = 2.5362  Validation loss = 3.7744  \n",
      "\n",
      "Fold: 21  Epoch: 25  Training loss = 2.5371  Validation loss = 3.7364  \n",
      "\n",
      "Fold: 21  Epoch: 26  Training loss = 2.5347  Validation loss = 3.7915  \n",
      "\n",
      "Fold: 21  Epoch: 27  Training loss = 2.5343  Validation loss = 3.8085  \n",
      "\n",
      "Fold: 21  Epoch: 28  Training loss = 2.5350  Validation loss = 3.8342  \n",
      "\n",
      "Fold: 21  Epoch: 29  Training loss = 2.5330  Validation loss = 3.7760  \n",
      "\n",
      "Fold: 21  Epoch: 30  Training loss = 2.5330  Validation loss = 3.7742  \n",
      "\n",
      "Fold: 21  Epoch: 31  Training loss = 2.5330  Validation loss = 3.7577  \n",
      "\n",
      "Fold: 21  Epoch: 32  Training loss = 2.5322  Validation loss = 3.8177  \n",
      "\n",
      "Fold: 21  Epoch: 33  Training loss = 2.5321  Validation loss = 3.8184  \n",
      "\n",
      "Fold: 21  Epoch: 34  Training loss = 2.5339  Validation loss = 3.8564  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 17  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.6213  Validation loss = 2.9452  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.6158  Validation loss = 2.9057  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.6090  Validation loss = 2.8069  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.6073  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.6031  Validation loss = 2.6386  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.6029  Validation loss = 2.6388  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 2.6026  Validation loss = 2.6573  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.6015  Validation loss = 2.6425  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.6002  Validation loss = 2.6517  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.6003  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.5990  Validation loss = 2.4744  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.5971  Validation loss = 2.5080  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.5968  Validation loss = 2.4407  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 2.5958  Validation loss = 2.3913  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 2.5953  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 2.5949  Validation loss = 2.5319  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 2.5940  Validation loss = 2.4535  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 2.6009  Validation loss = 2.5711  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 2.5981  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 2.5954  Validation loss = 2.4706  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 2.5959  Validation loss = 2.5552  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 2.5932  Validation loss = 2.4892  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 2.5932  Validation loss = 2.5451  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 2.5921  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 2.5896  Validation loss = 2.5074  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 2.5904  Validation loss = 2.6028  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 14  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.6116  Validation loss = 1.8533  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.6027  Validation loss = 1.6491  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.6010  Validation loss = 1.7175  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.6058  Validation loss = 1.8730  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.5927  Validation loss = 1.5261  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.5913  Validation loss = 1.5030  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.5912  Validation loss = 1.6094  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.5886  Validation loss = 1.3170  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.5921  Validation loss = 1.2614  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.5824  Validation loss = 1.4625  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.5801  Validation loss = 1.5045  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.5809  Validation loss = 1.5287  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.5766  Validation loss = 1.5044  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 2.5749  Validation loss = 1.4769  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 2.5741  Validation loss = 1.5135  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 2.5761  Validation loss = 1.6230  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 2.5745  Validation loss = 1.6317  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 2.5746  Validation loss = 1.6539  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 2.5672  Validation loss = 1.4440  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 2.5683  Validation loss = 1.5510  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 2.5656  Validation loss = 1.3765  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 2.5698  Validation loss = 1.2550  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 2.5652  Validation loss = 1.2947  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 2.5677  Validation loss = 1.5871  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 2.5629  Validation loss = 1.3793  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 2.5629  Validation loss = 1.4780  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 2.5647  Validation loss = 1.5298  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 2.5617  Validation loss = 1.4218  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 2.5618  Validation loss = 1.3456  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 2.5615  Validation loss = 1.5093  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 2.5588  Validation loss = 1.4365  \n",
      "\n",
      "Fold: 23  Epoch: 32  Training loss = 2.5603  Validation loss = 1.5226  \n",
      "\n",
      "Fold: 23  Epoch: 33  Training loss = 2.5621  Validation loss = 1.5964  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 22  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.5655  Validation loss = 1.3078  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.5590  Validation loss = 1.3164  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.5588  Validation loss = 1.3385  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.5562  Validation loss = 1.3167  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.5548  Validation loss = 1.3020  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.5538  Validation loss = 1.2937  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.5712  Validation loss = 1.2618  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.5571  Validation loss = 1.2764  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.5524  Validation loss = 1.2772  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.5513  Validation loss = 1.2721  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.5494  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.5514  Validation loss = 1.3318  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.5574  Validation loss = 1.2966  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.5546  Validation loss = 1.3006  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.5552  Validation loss = 1.2910  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.5516  Validation loss = 1.3138  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.5516  Validation loss = 1.2975  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.5556  Validation loss = 1.2542  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.5506  Validation loss = 1.2752  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.5479  Validation loss = 1.2962  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.5481  Validation loss = 1.3036  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.5452  Validation loss = 1.3197  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 2.5447  Validation loss = 1.3227  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 2.5454  Validation loss = 1.3056  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 2.5557  Validation loss = 1.2776  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 2.5511  Validation loss = 1.2730  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 2.5410  Validation loss = 1.2979  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 2.5413  Validation loss = 1.2899  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 2.5425  Validation loss = 1.2718  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 2.5398  Validation loss = 1.2997  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 2.5681  Validation loss = 1.2470  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 2.5590  Validation loss = 1.3204  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 2.5594  Validation loss = 1.2933  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 2.5565  Validation loss = 1.3428  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 31  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.5039  Validation loss = 2.6044  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.5013  Validation loss = 2.6004  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.4980  Validation loss = 2.5846  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.4969  Validation loss = 2.5720  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.4952  Validation loss = 2.5689  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.4977  Validation loss = 2.6264  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.4951  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.4941  Validation loss = 2.5912  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.4925  Validation loss = 2.5842  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.4910  Validation loss = 2.5878  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.4885  Validation loss = 2.5412  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.4879  Validation loss = 2.5318  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.4869  Validation loss = 2.5661  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.4857  Validation loss = 2.5508  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.4831  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.4833  Validation loss = 2.5749  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 2.4834  Validation loss = 2.5311  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 2.4811  Validation loss = 2.5661  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 2.4803  Validation loss = 2.5419  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 2.4794  Validation loss = 2.5572  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 2.4805  Validation loss = 2.5838  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 2.4779  Validation loss = 2.5438  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 2.4762  Validation loss = 2.5379  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 2.4763  Validation loss = 2.5676  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 2.4747  Validation loss = 2.5518  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 2.4801  Validation loss = 2.6076  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 17  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.4634  Validation loss = 3.4384  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.4617  Validation loss = 3.4053  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.4594  Validation loss = 3.3750  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.4575  Validation loss = 3.3812  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.4623  Validation loss = 3.3870  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.4627  Validation loss = 3.3097  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.4643  Validation loss = 3.5383  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.4605  Validation loss = 3.4815  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.4587  Validation loss = 3.4603  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.4574  Validation loss = 3.4936  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.4605  Validation loss = 3.5421  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.4703  Validation loss = 3.6124  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.4623  Validation loss = 3.5692  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.4559  Validation loss = 3.4239  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.4532  Validation loss = 3.3819  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 2.4534  Validation loss = 3.3716  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 2.4523  Validation loss = 3.4216  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 2.4516  Validation loss = 3.4218  \n",
      "\n",
      "Fold: 26  Epoch: 19  Training loss = 2.4523  Validation loss = 3.4276  \n",
      "\n",
      "Fold: 26  Epoch: 20  Training loss = 2.4670  Validation loss = 3.6474  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 6  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.5277  Validation loss = 0.5499  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.5177  Validation loss = 0.5374  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.5024  Validation loss = 0.5151  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.4635  Validation loss = 0.5122  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.4491  Validation loss = 0.5070  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.4823  Validation loss = 0.4820  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.4689  Validation loss = 0.4871  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.4522  Validation loss = 0.4940  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.4407  Validation loss = 0.5074  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.4391  Validation loss = 0.5106  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.4387  Validation loss = 0.5086  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.4370  Validation loss = 0.5144  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.4394  Validation loss = 0.4989  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.4442  Validation loss = 0.4956  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.4390  Validation loss = 0.5038  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.4329  Validation loss = 0.5082  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.4328  Validation loss = 0.5080  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.4331  Validation loss = 0.5020  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.4349  Validation loss = 0.5105  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.4334  Validation loss = 0.5292  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 6  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.4163  Validation loss = 1.3514  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.4192  Validation loss = 1.3308  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.4175  Validation loss = 1.3033  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.4128  Validation loss = 1.3261  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.4101  Validation loss = 1.2984  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.4081  Validation loss = 1.2950  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.4074  Validation loss = 1.2904  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.4083  Validation loss = 1.2985  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.4053  Validation loss = 1.2851  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.4153  Validation loss = 1.2478  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.4101  Validation loss = 1.2535  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.4058  Validation loss = 1.3078  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.4035  Validation loss = 1.3017  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.4019  Validation loss = 1.2858  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.4049  Validation loss = 1.2510  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.3987  Validation loss = 1.2684  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 2.3961  Validation loss = 1.2677  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 2.3950  Validation loss = 1.2630  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 2.3971  Validation loss = 1.2522  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 2.4073  Validation loss = 1.2257  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 2.3946  Validation loss = 1.2558  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 2.3944  Validation loss = 1.2594  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 2.3970  Validation loss = 1.2696  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 2.4008  Validation loss = 1.2679  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 2.4055  Validation loss = 1.2793  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 2.4342  Validation loss = 1.2945  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 2.3907  Validation loss = 1.2481  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 2.3893  Validation loss = 1.2532  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 2.3882  Validation loss = 1.2563  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 2.3889  Validation loss = 1.2521  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 2.3893  Validation loss = 1.2598  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 2.3879  Validation loss = 1.2662  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 2.3886  Validation loss = 1.2392  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 2.3874  Validation loss = 1.2426  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 2.3997  Validation loss = 1.2190  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 2.3843  Validation loss = 1.2514  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 2.3848  Validation loss = 1.2749  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 2.3841  Validation loss = 1.2457  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 2.3867  Validation loss = 1.2475  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 2.3835  Validation loss = 1.2417  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 2.3821  Validation loss = 1.2637  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 2.3816  Validation loss = 1.2589  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 2.3800  Validation loss = 1.2399  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 2.3835  Validation loss = 1.2359  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 2.3793  Validation loss = 1.2462  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 2.3812  Validation loss = 1.2479  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 2.3828  Validation loss = 1.2644  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 2.3816  Validation loss = 1.2321  \n",
      "\n",
      "Fold: 28  Epoch: 49  Training loss = 2.3870  Validation loss = 1.2144  \n",
      "\n",
      "Fold: 28  Epoch: 50  Training loss = 2.3785  Validation loss = 1.2523  \n",
      "\n",
      "Fold: 28  Epoch: 51  Training loss = 2.3800  Validation loss = 1.2366  \n",
      "\n",
      "Fold: 28  Epoch: 52  Training loss = 2.3788  Validation loss = 1.2286  \n",
      "\n",
      "Fold: 28  Epoch: 53  Training loss = 2.3792  Validation loss = 1.2259  \n",
      "\n",
      "Fold: 28  Epoch: 54  Training loss = 2.3773  Validation loss = 1.2202  \n",
      "\n",
      "Fold: 28  Epoch: 55  Training loss = 2.3844  Validation loss = 1.2165  \n",
      "\n",
      "Fold: 28  Epoch: 56  Training loss = 2.3775  Validation loss = 1.2816  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 49  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.3513  Validation loss = 1.2743  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.3500  Validation loss = 1.2748  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.3467  Validation loss = 1.2694  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.3431  Validation loss = 1.2693  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.3418  Validation loss = 1.2657  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.3483  Validation loss = 1.2648  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.3413  Validation loss = 1.2632  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.3410  Validation loss = 1.2623  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.3418  Validation loss = 1.2618  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.3401  Validation loss = 1.2616  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.3371  Validation loss = 1.2644  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.3363  Validation loss = 1.2651  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.3371  Validation loss = 1.2661  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.3449  Validation loss = 1.2635  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.3329  Validation loss = 1.2587  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.3334  Validation loss = 1.2579  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 2.3344  Validation loss = 1.2585  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 2.3325  Validation loss = 1.2540  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 2.3333  Validation loss = 1.2547  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.3299  Validation loss = 1.2541  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 2.3436  Validation loss = 1.2567  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 2.3388  Validation loss = 1.2505  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 2.3290  Validation loss = 1.2438  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 2.3315  Validation loss = 1.2439  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 2.3402  Validation loss = 1.2480  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 2.3278  Validation loss = 1.2528  \n",
      "\n",
      "Fold: 29  Epoch: 27  Training loss = 2.3324  Validation loss = 1.2490  \n",
      "\n",
      "Fold: 29  Epoch: 28  Training loss = 2.3228  Validation loss = 1.2482  \n",
      "\n",
      "Fold: 29  Epoch: 29  Training loss = 2.3218  Validation loss = 1.2500  \n",
      "\n",
      "Fold: 29  Epoch: 30  Training loss = 2.3228  Validation loss = 1.2541  \n",
      "\n",
      "Fold: 29  Epoch: 31  Training loss = 2.3229  Validation loss = 1.2559  \n",
      "\n",
      "Fold: 29  Epoch: 32  Training loss = 2.3207  Validation loss = 1.2534  \n",
      "\n",
      "Fold: 29  Epoch: 33  Training loss = 2.3208  Validation loss = 1.2529  \n",
      "\n",
      "Fold: 29  Epoch: 34  Training loss = 2.3191  Validation loss = 1.2471  \n",
      "\n",
      "Fold: 29  Epoch: 35  Training loss = 2.3198  Validation loss = 1.2505  \n",
      "\n",
      "Fold: 29  Epoch: 36  Training loss = 2.3194  Validation loss = 1.2524  \n",
      "\n",
      "Fold: 29  Epoch: 37  Training loss = 2.3191  Validation loss = 1.2518  \n",
      "\n",
      "Fold: 29  Epoch: 38  Training loss = 2.3181  Validation loss = 1.2507  \n",
      "\n",
      "Fold: 29  Epoch: 39  Training loss = 2.3173  Validation loss = 1.2491  \n",
      "\n",
      "Fold: 29  Epoch: 40  Training loss = 2.3224  Validation loss = 1.2553  \n",
      "\n",
      "Fold: 29  Epoch: 41  Training loss = 2.3200  Validation loss = 1.2561  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 23  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.3251  Validation loss = 1.1258  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.3378  Validation loss = 1.0948  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.3268  Validation loss = 1.0966  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.3235  Validation loss = 1.0949  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.3247  Validation loss = 1.1743  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.3190  Validation loss = 1.1226  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.3218  Validation loss = 1.1094  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.3195  Validation loss = 1.1542  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.3186  Validation loss = 1.1657  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.3160  Validation loss = 1.1565  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.3187  Validation loss = 1.1918  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.3167  Validation loss = 1.1843  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 2.3177  Validation loss = 1.1891  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.3205  Validation loss = 1.1962  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 2.3200  Validation loss = 1.1848  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 2.3136  Validation loss = 1.1699  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 2.3083  Validation loss = 1.1348  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 2.3098  Validation loss = 1.1213  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 2.3095  Validation loss = 1.1228  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 2.3142  Validation loss = 1.1206  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 2.3075  Validation loss = 1.1152  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 2.3084  Validation loss = 1.0932  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 2.3037  Validation loss = 1.1057  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 2.3021  Validation loss = 1.0912  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 2.3032  Validation loss = 1.1315  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 2.3011  Validation loss = 1.1005  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 2.2993  Validation loss = 1.0890  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 2.2979  Validation loss = 1.0942  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 2.2998  Validation loss = 1.0630  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 2.3023  Validation loss = 1.0505  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 2.3106  Validation loss = 1.0401  \n",
      "\n",
      "Fold: 30  Epoch: 32  Training loss = 2.3007  Validation loss = 1.0565  \n",
      "\n",
      "Fold: 30  Epoch: 33  Training loss = 2.2981  Validation loss = 1.0569  \n",
      "\n",
      "Fold: 30  Epoch: 34  Training loss = 2.2967  Validation loss = 1.0757  \n",
      "\n",
      "Fold: 30  Epoch: 35  Training loss = 2.2977  Validation loss = 1.0271  \n",
      "\n",
      "Fold: 30  Epoch: 36  Training loss = 2.3055  Validation loss = 1.0093  \n",
      "\n",
      "Fold: 30  Epoch: 37  Training loss = 2.2989  Validation loss = 1.0292  \n",
      "\n",
      "Fold: 30  Epoch: 38  Training loss = 2.2913  Validation loss = 1.0532  \n",
      "\n",
      "Fold: 30  Epoch: 39  Training loss = 2.2908  Validation loss = 1.0955  \n",
      "\n",
      "Fold: 30  Epoch: 40  Training loss = 2.2890  Validation loss = 1.0952  \n",
      "\n",
      "Fold: 30  Epoch: 41  Training loss = 2.2864  Validation loss = 1.0834  \n",
      "\n",
      "Fold: 30  Epoch: 42  Training loss = 2.2858  Validation loss = 1.0796  \n",
      "\n",
      "Fold: 30  Epoch: 43  Training loss = 2.2845  Validation loss = 1.0810  \n",
      "\n",
      "Fold: 30  Epoch: 44  Training loss = 2.2862  Validation loss = 1.1026  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 36  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.1602  Validation loss = 0.3922  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.1609  Validation loss = 0.3453  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.1584  Validation loss = 0.3652  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.1609  Validation loss = 0.3614  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.1628  Validation loss = 0.3575  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.1595  Validation loss = 0.3592  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.1570  Validation loss = 0.3506  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.1559  Validation loss = 0.3610  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.1533  Validation loss = 0.3567  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.1523  Validation loss = 0.3893  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.1553  Validation loss = 0.4470  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.1591  Validation loss = 0.4676  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.1592  Validation loss = 0.4730  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.1508  Validation loss = 0.3746  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.1491  Validation loss = 0.4331  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.1489  Validation loss = 0.4298  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 2.1445  Validation loss = 0.4062  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 2.1432  Validation loss = 0.3824  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 2.1416  Validation loss = 0.4020  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 2.1415  Validation loss = 0.4194  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 2.1431  Validation loss = 0.4477  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 2.1440  Validation loss = 0.4116  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 2.1396  Validation loss = 0.4169  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 2.1377  Validation loss = 0.3964  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 2.1365  Validation loss = 0.3871  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 2.1356  Validation loss = 0.3950  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 2.1343  Validation loss = 0.4021  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 2.1344  Validation loss = 0.3768  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 2.1347  Validation loss = 0.4108  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 2.1347  Validation loss = 0.4043  \n",
      "\n",
      "Fold: 31  Epoch: 31  Training loss = 2.1360  Validation loss = 0.3755  \n",
      "\n",
      "Fold: 31  Epoch: 32  Training loss = 2.1322  Validation loss = 0.3837  \n",
      "\n",
      "Fold: 31  Epoch: 33  Training loss = 2.1408  Validation loss = 0.4773  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 2  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.7751  Validation loss = 1.4948  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.7588  Validation loss = 1.6176  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.7531  Validation loss = 1.7108  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.7506  Validation loss = 1.7319  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.7490  Validation loss = 1.7471  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.7475  Validation loss = 1.7269  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.7466  Validation loss = 1.7157  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.7456  Validation loss = 1.7369  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.7467  Validation loss = 1.9024  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.7433  Validation loss = 1.8068  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.7430  Validation loss = 1.8616  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.7399  Validation loss = 1.7398  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.7381  Validation loss = 1.7913  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.7375  Validation loss = 1.7551  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.7364  Validation loss = 1.7786  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.7351  Validation loss = 1.7983  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.7353  Validation loss = 1.8865  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.7349  Validation loss = 1.8923  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.7318  Validation loss = 1.7512  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.7305  Validation loss = 1.7411  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.7304  Validation loss = 1.7379  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 1.7293  Validation loss = 1.7785  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 1.7312  Validation loss = 1.6152  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 1.7274  Validation loss = 1.6803  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 1.7306  Validation loss = 1.6007  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 1.7258  Validation loss = 1.6914  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 1.7242  Validation loss = 1.6694  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 1.7218  Validation loss = 1.7489  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 1.7219  Validation loss = 1.8607  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 1.7211  Validation loss = 1.8451  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 1.7204  Validation loss = 1.7152  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 1.7202  Validation loss = 1.7290  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 1.7190  Validation loss = 1.7914  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 1.7232  Validation loss = 1.5911  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 1.7178  Validation loss = 1.7482  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 1.7184  Validation loss = 1.7009  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 1.7156  Validation loss = 1.7906  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 1.7162  Validation loss = 1.6634  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 1.7159  Validation loss = 1.6474  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 1.7129  Validation loss = 1.7324  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 1.7131  Validation loss = 1.7283  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 1.7117  Validation loss = 1.7149  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 1.7107  Validation loss = 1.7973  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 1.7120  Validation loss = 1.9062  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 1  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 327\n",
      "Average validation error: 2.80337\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.6523  Test loss = 2.5109  \n",
      "\n",
      "Epoch: 2  Training loss = 1.6503  Test loss = 2.5070  \n",
      "\n",
      "Epoch: 3  Training loss = 1.6485  Test loss = 2.5033  \n",
      "\n",
      "Epoch: 4  Training loss = 1.6469  Test loss = 2.4998  \n",
      "\n",
      "Epoch: 5  Training loss = 1.6454  Test loss = 2.4965  \n",
      "\n",
      "Epoch: 6  Training loss = 1.6441  Test loss = 2.4933  \n",
      "\n",
      "Epoch: 7  Training loss = 1.6429  Test loss = 2.4903  \n",
      "\n",
      "Epoch: 8  Training loss = 1.6418  Test loss = 2.4875  \n",
      "\n",
      "Epoch: 9  Training loss = 1.6409  Test loss = 2.4848  \n",
      "\n",
      "Epoch: 10  Training loss = 1.6400  Test loss = 2.4823  \n",
      "\n",
      "Epoch: 11  Training loss = 1.6392  Test loss = 2.4799  \n",
      "\n",
      "Epoch: 12  Training loss = 1.6385  Test loss = 2.4777  \n",
      "\n",
      "Epoch: 13  Training loss = 1.6379  Test loss = 2.4755  \n",
      "\n",
      "Epoch: 14  Training loss = 1.6373  Test loss = 2.4735  \n",
      "\n",
      "Epoch: 15  Training loss = 1.6367  Test loss = 2.4716  \n",
      "\n",
      "Epoch: 16  Training loss = 1.6363  Test loss = 2.4699  \n",
      "\n",
      "Epoch: 17  Training loss = 1.6358  Test loss = 2.4682  \n",
      "\n",
      "Epoch: 18  Training loss = 1.6354  Test loss = 2.4666  \n",
      "\n",
      "Epoch: 19  Training loss = 1.6350  Test loss = 2.4651  \n",
      "\n",
      "Epoch: 20  Training loss = 1.6347  Test loss = 2.4637  \n",
      "\n",
      "Epoch: 21  Training loss = 1.6344  Test loss = 2.4624  \n",
      "\n",
      "Epoch: 22  Training loss = 1.6341  Test loss = 2.4612  \n",
      "\n",
      "Epoch: 23  Training loss = 1.6338  Test loss = 2.4600  \n",
      "\n",
      "Epoch: 24  Training loss = 1.6336  Test loss = 2.4589  \n",
      "\n",
      "Epoch: 25  Training loss = 1.6333  Test loss = 2.4579  \n",
      "\n",
      "Epoch: 26  Training loss = 1.6331  Test loss = 2.4569  \n",
      "\n",
      "Epoch: 27  Training loss = 1.6329  Test loss = 2.4560  \n",
      "\n",
      "Epoch: 28  Training loss = 1.6327  Test loss = 2.4551  \n",
      "\n",
      "Epoch: 29  Training loss = 1.6325  Test loss = 2.4543  \n",
      "\n",
      "Epoch: 30  Training loss = 1.6323  Test loss = 2.4536  \n",
      "\n",
      "Epoch: 31  Training loss = 1.6322  Test loss = 2.4529  \n",
      "\n",
      "Epoch: 32  Training loss = 1.6320  Test loss = 2.4522  \n",
      "\n",
      "Epoch: 33  Training loss = 1.6318  Test loss = 2.4516  \n",
      "\n",
      "Epoch: 34  Training loss = 1.6317  Test loss = 2.4510  \n",
      "\n",
      "Epoch: 35  Training loss = 1.6315  Test loss = 2.4505  \n",
      "\n",
      "Epoch: 36  Training loss = 1.6314  Test loss = 2.4500  \n",
      "\n",
      "Epoch: 37  Training loss = 1.6313  Test loss = 2.4495  \n",
      "\n",
      "Epoch: 38  Training loss = 1.6311  Test loss = 2.4490  \n",
      "\n",
      "Epoch: 39  Training loss = 1.6310  Test loss = 2.4486  \n",
      "\n",
      "Epoch: 40  Training loss = 1.6309  Test loss = 2.4482  \n",
      "\n",
      "Epoch: 41  Training loss = 1.6307  Test loss = 2.4479  \n",
      "\n",
      "Epoch: 42  Training loss = 1.6306  Test loss = 2.4475  \n",
      "\n",
      "Epoch: 43  Training loss = 1.6305  Test loss = 2.4472  \n",
      "\n",
      "Epoch: 44  Training loss = 1.6304  Test loss = 2.4469  \n",
      "\n",
      "Epoch: 45  Training loss = 1.6303  Test loss = 2.4466  \n",
      "\n",
      "Epoch: 46  Training loss = 1.6301  Test loss = 2.4463  \n",
      "\n",
      "Epoch: 47  Training loss = 1.6300  Test loss = 2.4461  \n",
      "\n",
      "Epoch: 48  Training loss = 1.6299  Test loss = 2.4458  \n",
      "\n",
      "Epoch: 49  Training loss = 1.6298  Test loss = 2.4456  \n",
      "\n",
      "Epoch: 50  Training loss = 1.6297  Test loss = 2.4454  \n",
      "\n",
      "Epoch: 51  Training loss = 1.6296  Test loss = 2.4452  \n",
      "\n",
      "Epoch: 52  Training loss = 1.6295  Test loss = 2.4450  \n",
      "\n",
      "Epoch: 53  Training loss = 1.6294  Test loss = 2.4449  \n",
      "\n",
      "Epoch: 54  Training loss = 1.6293  Test loss = 2.4447  \n",
      "\n",
      "Epoch: 55  Training loss = 1.6292  Test loss = 2.4446  \n",
      "\n",
      "Epoch: 56  Training loss = 1.6290  Test loss = 2.4444  \n",
      "\n",
      "Epoch: 57  Training loss = 1.6289  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 58  Training loss = 1.6288  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 59  Training loss = 1.6287  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 60  Training loss = 1.6286  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 61  Training loss = 1.6285  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 62  Training loss = 1.6284  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 63  Training loss = 1.6283  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 64  Training loss = 1.6282  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 65  Training loss = 1.6281  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 66  Training loss = 1.6280  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 67  Training loss = 1.6279  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 68  Training loss = 1.6278  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 69  Training loss = 1.6277  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 70  Training loss = 1.6276  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 71  Training loss = 1.6275  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 72  Training loss = 1.6275  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 73  Training loss = 1.6274  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 74  Training loss = 1.6273  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 75  Training loss = 1.6272  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 76  Training loss = 1.6271  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 77  Training loss = 1.6270  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 78  Training loss = 1.6269  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 79  Training loss = 1.6268  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 80  Training loss = 1.6267  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 81  Training loss = 1.6266  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 82  Training loss = 1.6265  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 83  Training loss = 1.6264  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 84  Training loss = 1.6263  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 85  Training loss = 1.6262  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 86  Training loss = 1.6261  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 87  Training loss = 1.6261  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 88  Training loss = 1.6260  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 89  Training loss = 1.6259  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 90  Training loss = 1.6258  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 91  Training loss = 1.6257  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 92  Training loss = 1.6256  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 93  Training loss = 1.6255  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 94  Training loss = 1.6254  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 95  Training loss = 1.6253  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 96  Training loss = 1.6253  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 97  Training loss = 1.6252  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 98  Training loss = 1.6251  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 99  Training loss = 1.6250  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 100  Training loss = 1.6249  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 101  Training loss = 1.6248  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 102  Training loss = 1.6247  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 103  Training loss = 1.6247  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 104  Training loss = 1.6246  Test loss = 2.4428  \n",
      "\n",
      "Epoch: 105  Training loss = 1.6245  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 106  Training loss = 1.6244  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 107  Training loss = 1.6243  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 108  Training loss = 1.6242  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 109  Training loss = 1.6241  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 110  Training loss = 1.6241  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 111  Training loss = 1.6240  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 112  Training loss = 1.6239  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 113  Training loss = 1.6238  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 114  Training loss = 1.6237  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 115  Training loss = 1.6237  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 116  Training loss = 1.6236  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 117  Training loss = 1.6235  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 118  Training loss = 1.6234  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 119  Training loss = 1.6233  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 120  Training loss = 1.6232  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 121  Training loss = 1.6232  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 122  Training loss = 1.6231  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 123  Training loss = 1.6230  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 124  Training loss = 1.6229  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 125  Training loss = 1.6228  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 126  Training loss = 1.6228  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 127  Training loss = 1.6227  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 128  Training loss = 1.6226  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 129  Training loss = 1.6225  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 130  Training loss = 1.6224  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 131  Training loss = 1.6224  Test loss = 2.4430  \n",
      "\n",
      "Epoch: 132  Training loss = 1.6223  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 133  Training loss = 1.6222  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 134  Training loss = 1.6221  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 135  Training loss = 1.6220  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 136  Training loss = 1.6220  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 137  Training loss = 1.6219  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 138  Training loss = 1.6218  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 139  Training loss = 1.6217  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 140  Training loss = 1.6217  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 141  Training loss = 1.6216  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 142  Training loss = 1.6215  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 143  Training loss = 1.6214  Test loss = 2.4431  \n",
      "\n",
      "Epoch: 144  Training loss = 1.6213  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 145  Training loss = 1.6213  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 146  Training loss = 1.6212  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 147  Training loss = 1.6211  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 148  Training loss = 1.6210  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 149  Training loss = 1.6210  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 150  Training loss = 1.6209  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 151  Training loss = 1.6208  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 152  Training loss = 1.6207  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 153  Training loss = 1.6207  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 154  Training loss = 1.6206  Test loss = 2.4432  \n",
      "\n",
      "Epoch: 155  Training loss = 1.6205  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 156  Training loss = 1.6204  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 157  Training loss = 1.6204  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 158  Training loss = 1.6203  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 159  Training loss = 1.6202  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 160  Training loss = 1.6201  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 161  Training loss = 1.6201  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 162  Training loss = 1.6200  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 163  Training loss = 1.6199  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 164  Training loss = 1.6198  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 165  Training loss = 1.6198  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 166  Training loss = 1.6197  Test loss = 2.4433  \n",
      "\n",
      "Epoch: 167  Training loss = 1.6196  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 168  Training loss = 1.6196  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 169  Training loss = 1.6195  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 170  Training loss = 1.6194  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 171  Training loss = 1.6193  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 172  Training loss = 1.6193  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 173  Training loss = 1.6192  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 174  Training loss = 1.6191  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 175  Training loss = 1.6190  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 176  Training loss = 1.6190  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 177  Training loss = 1.6189  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 178  Training loss = 1.6188  Test loss = 2.4434  \n",
      "\n",
      "Epoch: 179  Training loss = 1.6188  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 180  Training loss = 1.6187  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 181  Training loss = 1.6186  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 182  Training loss = 1.6185  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 183  Training loss = 1.6185  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 184  Training loss = 1.6184  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 185  Training loss = 1.6183  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 186  Training loss = 1.6183  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 187  Training loss = 1.6182  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 188  Training loss = 1.6181  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 189  Training loss = 1.6180  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 190  Training loss = 1.6180  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 191  Training loss = 1.6179  Test loss = 2.4435  \n",
      "\n",
      "Epoch: 192  Training loss = 1.6178  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 193  Training loss = 1.6178  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 194  Training loss = 1.6177  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 195  Training loss = 1.6176  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 196  Training loss = 1.6176  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 197  Training loss = 1.6175  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 198  Training loss = 1.6174  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 199  Training loss = 1.6173  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 200  Training loss = 1.6173  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 201  Training loss = 1.6172  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 202  Training loss = 1.6171  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 203  Training loss = 1.6171  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 204  Training loss = 1.6170  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 205  Training loss = 1.6169  Test loss = 2.4436  \n",
      "\n",
      "Epoch: 206  Training loss = 1.6169  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 207  Training loss = 1.6168  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 208  Training loss = 1.6167  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 209  Training loss = 1.6166  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 210  Training loss = 1.6166  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 211  Training loss = 1.6165  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 212  Training loss = 1.6164  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 213  Training loss = 1.6164  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 214  Training loss = 1.6163  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 215  Training loss = 1.6162  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 216  Training loss = 1.6162  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 217  Training loss = 1.6161  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 218  Training loss = 1.6160  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 219  Training loss = 1.6160  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 220  Training loss = 1.6159  Test loss = 2.4437  \n",
      "\n",
      "Epoch: 221  Training loss = 1.6158  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 222  Training loss = 1.6158  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 223  Training loss = 1.6157  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 224  Training loss = 1.6156  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 225  Training loss = 1.6156  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 226  Training loss = 1.6155  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 227  Training loss = 1.6154  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 228  Training loss = 1.6154  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 229  Training loss = 1.6153  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 230  Training loss = 1.6152  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 231  Training loss = 1.6152  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 232  Training loss = 1.6151  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 233  Training loss = 1.6150  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 234  Training loss = 1.6150  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 235  Training loss = 1.6149  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 236  Training loss = 1.6148  Test loss = 2.4438  \n",
      "\n",
      "Epoch: 237  Training loss = 1.6148  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 238  Training loss = 1.6147  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 239  Training loss = 1.6146  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 240  Training loss = 1.6146  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 241  Training loss = 1.6145  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 242  Training loss = 1.6144  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 243  Training loss = 1.6144  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 244  Training loss = 1.6143  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 245  Training loss = 1.6142  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 246  Training loss = 1.6142  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 247  Training loss = 1.6141  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 248  Training loss = 1.6140  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 249  Training loss = 1.6140  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 250  Training loss = 1.6139  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 251  Training loss = 1.6138  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 252  Training loss = 1.6138  Test loss = 2.4439  \n",
      "\n",
      "Epoch: 253  Training loss = 1.6137  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 254  Training loss = 1.6136  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 255  Training loss = 1.6136  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 256  Training loss = 1.6135  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 257  Training loss = 1.6134  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 258  Training loss = 1.6134  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 259  Training loss = 1.6133  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 260  Training loss = 1.6132  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 261  Training loss = 1.6132  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 262  Training loss = 1.6131  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 263  Training loss = 1.6131  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 264  Training loss = 1.6130  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 265  Training loss = 1.6129  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 266  Training loss = 1.6129  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 267  Training loss = 1.6128  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 268  Training loss = 1.6127  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 269  Training loss = 1.6127  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 270  Training loss = 1.6126  Test loss = 2.4440  \n",
      "\n",
      "Epoch: 271  Training loss = 1.6125  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 272  Training loss = 1.6125  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 273  Training loss = 1.6124  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 274  Training loss = 1.6123  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 275  Training loss = 1.6123  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 276  Training loss = 1.6122  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 277  Training loss = 1.6122  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 278  Training loss = 1.6121  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 279  Training loss = 1.6120  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 280  Training loss = 1.6120  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 281  Training loss = 1.6119  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 282  Training loss = 1.6118  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 283  Training loss = 1.6118  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 284  Training loss = 1.6117  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 285  Training loss = 1.6116  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 286  Training loss = 1.6116  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 287  Training loss = 1.6115  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 288  Training loss = 1.6115  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 289  Training loss = 1.6114  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 290  Training loss = 1.6113  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 291  Training loss = 1.6113  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 292  Training loss = 1.6112  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 293  Training loss = 1.6111  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 294  Training loss = 1.6111  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 295  Training loss = 1.6110  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 296  Training loss = 1.6109  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 297  Training loss = 1.6109  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 298  Training loss = 1.6108  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 299  Training loss = 1.6108  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 300  Training loss = 1.6107  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 301  Training loss = 1.6106  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 302  Training loss = 1.6106  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 303  Training loss = 1.6105  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 304  Training loss = 1.6104  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 305  Training loss = 1.6104  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 306  Training loss = 1.6103  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 307  Training loss = 1.6103  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 308  Training loss = 1.6102  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 309  Training loss = 1.6101  Test loss = 2.4442  \n",
      "\n",
      "Epoch: 310  Training loss = 1.6101  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 311  Training loss = 1.6100  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 312  Training loss = 1.6099  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 313  Training loss = 1.6099  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 314  Training loss = 1.6098  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 315  Training loss = 1.6098  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 316  Training loss = 1.6097  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 317  Training loss = 1.6096  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 318  Training loss = 1.6096  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 319  Training loss = 1.6095  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 320  Training loss = 1.6095  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 321  Training loss = 1.6094  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 322  Training loss = 1.6093  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 323  Training loss = 1.6093  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 324  Training loss = 1.6092  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 325  Training loss = 1.6091  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 326  Training loss = 1.6091  Test loss = 2.4443  \n",
      "\n",
      "Epoch: 327  Training loss = 1.6090  Test loss = 2.4443  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nloxK7EVRFEvGP+jODmrp+sA3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc2017b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2BuNRmPM+BvdTRdeYIkf0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd4a9e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.444331606 \n",
      "Fixed scheme MAE:  1.52117377485\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.6090  Test loss = 1.6785  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.6152  Test loss = 1.2017  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.4985  Test loss = 1.2556  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.5045  Test loss = 1.8179  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.4105  Test loss = 0.4814  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.3734  Test loss = 0.5850  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.3337  Test loss = 0.3890  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.3206  Test loss = 0.1705  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.2229  Test loss = 0.4092  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.2139  Test loss = 1.1037  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.1759  Test loss = 1.2412  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.1778  Test loss = 1.4475  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.1392  Test loss = 0.4628  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.1406  Test loss = 2.3541  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.1773  Test loss = 4.0634  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.2802  Test loss = 5.0531  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.3516  Test loss = 1.0181  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.3497  Test loss = 0.9287  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.3544  Test loss = 0.2667  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.2482  Test loss = 0.5613  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.1950  Test loss = 1.8496  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.2168  Test loss = 2.8409  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.2453  Test loss = 0.9103  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.2322  Test loss = 1.3044  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.1678  Test loss = 0.9500  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.1737  Test loss = 0.4532  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.1725  Test loss = 0.1015  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1667  Test loss = 2.0242  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.1469  Test loss = 0.7932  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.1481  Test loss = 0.0559  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.1468  Test loss = 3.6672  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.2133  Test loss = 1.2017  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.1568  Test loss = 0.9834  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.1630  Test loss = 0.2792  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.1267  Test loss = 0.7307  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.1071  Test loss = 5.7408  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.2675  Test loss = 1.3881  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2448  Test loss = 1.8481  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2598  Test loss = 0.9341  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2646  Test loss = 2.2752  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.1772  Test loss = 1.0898  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.1821  Test loss = 1.6531  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.1994  Test loss = 2.3661  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.2326  Test loss = 12.5025  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9715  Test loss = 5.9220  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1004  Test loss = 0.6194  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1009  Test loss = 1.4511  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1061  Test loss = 0.7383  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.9157  Test loss = 1.9178  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.9245  Test loss = 1.8127  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.9376  Test loss = 0.7689  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.9398  Test loss = 1.3336  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.9177  Test loss = 2.0648  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.9346  Test loss = 2.2137  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.9526  Test loss = 0.0485  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.9462  Test loss = 0.4778  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.9172  Test loss = 0.3540  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.9177  Test loss = 1.9600  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.9307  Test loss = 0.3471  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.9295  Test loss = 0.3316  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.9055  Test loss = 0.1700  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.9054  Test loss = 2.6065  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.9255  Test loss = 0.5969  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.9205  Test loss = 0.8301  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.8989  Test loss = 0.4763  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.8997  Test loss = 0.2348  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.8982  Test loss = 1.1138  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.9032  Test loss = 2.4506  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.9114  Test loss = 4.4773  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.9903  Test loss = 0.3429  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.9904  Test loss = 0.6153  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.9844  Test loss = 2.4822  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.9641  Test loss = 2.6440  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.9864  Test loss = 1.0139  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.9904  Test loss = 0.5978  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.9913  Test loss = 0.8158  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.9604  Test loss = 1.5786  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2IMgCErGb1beTDTVJQ/DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd4e3550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.35264194264 \n",
      "Updating scheme MAE:  1.55637078634\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
