{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/16_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-3\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 16 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 16 \n",
      "Learning rate = 0.001 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.001\n",
      "Fold: 1  Epoch: 1  Training loss = 3.1702  Validation loss = 3.2963  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.0836  Validation loss = 3.1019  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.0184  Validation loss = 2.9470  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.9598  Validation loss = 2.7980  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.8988  Validation loss = 2.6374  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.8564  Validation loss = 2.5183  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.8084  Validation loss = 2.3722  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.7766  Validation loss = 2.2547  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.7689  Validation loss = 2.2262  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.7591  Validation loss = 2.1836  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.7520  Validation loss = 2.1563  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.7417  Validation loss = 2.1049  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.7324  Validation loss = 2.0556  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 2.7173  Validation loss = 1.9744  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 2.7059  Validation loss = 1.9011  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 2.7052  Validation loss = 1.9020  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 2.6942  Validation loss = 1.8203  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 2.6937  Validation loss = 1.8217  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 2.6869  Validation loss = 1.7524  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 2.6829  Validation loss = 1.7186  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 2.6826  Validation loss = 1.7489  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 2.6810  Validation loss = 1.7465  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 2.6792  Validation loss = 1.7343  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 2.6723  Validation loss = 1.6440  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 2.6731  Validation loss = 1.6929  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 2.6692  Validation loss = 1.6140  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 2.6680  Validation loss = 1.6312  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 2.6671  Validation loss = 1.6198  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 2.6687  Validation loss = 1.6773  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 2.6640  Validation loss = 1.6364  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 2.6600  Validation loss = 1.5915  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 2.6582  Validation loss = 1.5843  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 2.6572  Validation loss = 1.5205  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 2.6562  Validation loss = 1.5361  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 2.6517  Validation loss = 1.5278  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 2.6509  Validation loss = 1.5566  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 2.6510  Validation loss = 1.6398  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 2.6471  Validation loss = 1.5976  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 2.6452  Validation loss = 1.6084  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 2.6410  Validation loss = 1.5408  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 2.6368  Validation loss = 1.4919  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 2.6344  Validation loss = 1.4613  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 2.6289  Validation loss = 1.5432  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 2.6257  Validation loss = 1.6250  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 2.6240  Validation loss = 1.6737  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 42  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.5090  Validation loss = 1.7283  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.4963  Validation loss = 1.6834  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.5101  Validation loss = 1.7307  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.4917  Validation loss = 1.7009  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.4851  Validation loss = 1.6814  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.4842  Validation loss = 1.6197  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.4788  Validation loss = 1.5825  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.4640  Validation loss = 1.5670  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.4592  Validation loss = 1.5467  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.4552  Validation loss = 1.5279  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.4407  Validation loss = 1.5126  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.4208  Validation loss = 1.5559  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.4168  Validation loss = 1.5177  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.4045  Validation loss = 1.5266  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.4014  Validation loss = 1.5352  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.4040  Validation loss = 1.5377  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.3938  Validation loss = 1.5221  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.3823  Validation loss = 1.5171  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.3732  Validation loss = 1.4990  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.3809  Validation loss = 1.4887  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.3582  Validation loss = 1.5114  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.3464  Validation loss = 1.5077  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.3386  Validation loss = 1.5125  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.3323  Validation loss = 1.4985  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.3284  Validation loss = 1.4969  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.3217  Validation loss = 1.5057  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.3200  Validation loss = 1.5083  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.3164  Validation loss = 1.5028  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.3184  Validation loss = 1.5032  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.3011  Validation loss = 1.4974  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.2961  Validation loss = 1.5044  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.2945  Validation loss = 1.5198  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 20  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.3148  Validation loss = 1.6847  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.3130  Validation loss = 1.6733  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.3129  Validation loss = 1.6506  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.3111  Validation loss = 1.6814  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.3155  Validation loss = 1.6837  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.3134  Validation loss = 1.6877  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.3057  Validation loss = 1.6466  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.3104  Validation loss = 1.6631  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.3003  Validation loss = 1.5816  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.3015  Validation loss = 1.5801  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.2991  Validation loss = 1.5653  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.3015  Validation loss = 1.5059  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.2984  Validation loss = 1.5081  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.2979  Validation loss = 1.5013  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.2970  Validation loss = 1.4989  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.3226  Validation loss = 1.4388  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.2995  Validation loss = 1.4998  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.2959  Validation loss = 1.4887  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.2919  Validation loss = 1.4758  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.2906  Validation loss = 1.4907  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.2954  Validation loss = 1.4621  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.3026  Validation loss = 1.4305  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.2966  Validation loss = 1.4315  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.2897  Validation loss = 1.4188  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.2891  Validation loss = 1.4124  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.2877  Validation loss = 1.4060  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.2969  Validation loss = 1.3666  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.2841  Validation loss = 1.3954  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.2829  Validation loss = 1.3952  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.2829  Validation loss = 1.3970  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.2826  Validation loss = 1.4130  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.2805  Validation loss = 1.4087  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.2799  Validation loss = 1.4250  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 27  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.2373  Validation loss = 2.9857  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.2327  Validation loss = 2.9636  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.2366  Validation loss = 2.9035  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.2411  Validation loss = 2.9101  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.2260  Validation loss = 2.9405  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.2246  Validation loss = 2.9322  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.2239  Validation loss = 2.9068  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.2212  Validation loss = 2.8626  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.2174  Validation loss = 2.8701  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.2154  Validation loss = 2.8509  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.2141  Validation loss = 2.8441  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.2143  Validation loss = 2.8592  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.2108  Validation loss = 2.8344  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.2113  Validation loss = 2.8487  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.2114  Validation loss = 2.8344  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.2095  Validation loss = 2.7855  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.2127  Validation loss = 2.7557  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.2126  Validation loss = 2.8082  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.2039  Validation loss = 2.7686  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.2084  Validation loss = 2.7877  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.1992  Validation loss = 2.7531  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.1991  Validation loss = 2.7684  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.2093  Validation loss = 2.7325  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.2029  Validation loss = 2.7126  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.2017  Validation loss = 2.7569  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.2033  Validation loss = 2.6827  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.1951  Validation loss = 2.7003  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.1942  Validation loss = 2.6699  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.1997  Validation loss = 2.6959  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.1934  Validation loss = 2.6401  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.1878  Validation loss = 2.6342  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.1920  Validation loss = 2.6692  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.1846  Validation loss = 2.6418  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.1859  Validation loss = 2.6298  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.1838  Validation loss = 2.6676  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.1818  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.1849  Validation loss = 2.6866  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.1772  Validation loss = 2.6459  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.1764  Validation loss = 2.6106  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.1731  Validation loss = 2.6335  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.1732  Validation loss = 2.6121  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.1775  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.1731  Validation loss = 2.6071  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.1713  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.1712  Validation loss = 2.6197  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.1739  Validation loss = 2.5634  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.1707  Validation loss = 2.5814  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.1690  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.1636  Validation loss = 2.5893  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.1628  Validation loss = 2.5737  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.1626  Validation loss = 2.5612  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.1615  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.1689  Validation loss = 2.6361  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 42  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.2271  Validation loss = 2.3800  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.2171  Validation loss = 2.3521  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.2109  Validation loss = 2.3227  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.2077  Validation loss = 2.2919  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.2027  Validation loss = 2.2313  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.1917  Validation loss = 2.2071  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.1850  Validation loss = 2.1647  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.1774  Validation loss = 2.1511  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.1762  Validation loss = 2.1362  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.1683  Validation loss = 2.1258  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.1706  Validation loss = 2.1440  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.1550  Validation loss = 1.9657  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.1646  Validation loss = 1.9745  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.1469  Validation loss = 1.9715  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.1509  Validation loss = 1.8867  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.1427  Validation loss = 1.9394  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.1456  Validation loss = 1.8668  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.1414  Validation loss = 1.9143  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.1377  Validation loss = 1.9196  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.1389  Validation loss = 1.8703  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.1468  Validation loss = 1.7811  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.1407  Validation loss = 1.7724  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.1395  Validation loss = 1.7708  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.1424  Validation loss = 1.7026  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.1409  Validation loss = 1.7493  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.1198  Validation loss = 1.7665  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.1183  Validation loss = 1.7764  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.1196  Validation loss = 1.7881  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.1173  Validation loss = 1.8001  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.1171  Validation loss = 1.7733  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.1176  Validation loss = 1.6740  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.1090  Validation loss = 1.7456  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.1072  Validation loss = 1.7295  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.1057  Validation loss = 1.6801  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.1201  Validation loss = 1.7532  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.1056  Validation loss = 1.6881  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.1036  Validation loss = 1.6731  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.1003  Validation loss = 1.6835  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.1170  Validation loss = 1.5815  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.0970  Validation loss = 1.5848  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.1020  Validation loss = 1.5481  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.0921  Validation loss = 1.5081  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.0866  Validation loss = 1.5198  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.0915  Validation loss = 1.5384  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.1130  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.0911  Validation loss = 1.4818  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.0964  Validation loss = 1.4479  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.0822  Validation loss = 1.4795  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.0743  Validation loss = 1.4447  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.0760  Validation loss = 1.4409  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.0873  Validation loss = 1.3909  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.0722  Validation loss = 1.4177  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.0764  Validation loss = 1.4484  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.0699  Validation loss = 1.3957  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.0759  Validation loss = 1.3780  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.1061  Validation loss = 1.3538  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.0654  Validation loss = 1.4125  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.0674  Validation loss = 1.3963  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.0810  Validation loss = 1.4007  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.0743  Validation loss = 1.3793  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.0832  Validation loss = 1.3898  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.0892  Validation loss = 1.4820  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 56  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.1039  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.1165  Validation loss = 0.9914  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.0989  Validation loss = 1.0065  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.0974  Validation loss = 0.9766  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.0975  Validation loss = 0.9483  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.1141  Validation loss = 1.0644  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.1146  Validation loss = 1.0826  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.0892  Validation loss = 0.9372  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.0834  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.0830  Validation loss = 0.9703  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.0876  Validation loss = 1.0336  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.0776  Validation loss = 1.0171  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.0745  Validation loss = 1.0288  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.0751  Validation loss = 1.1103  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 8  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.0710  Validation loss = 0.8984  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.0530  Validation loss = 1.0011  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.0593  Validation loss = 1.0415  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.0625  Validation loss = 0.8351  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.0498  Validation loss = 1.0703  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.0459  Validation loss = 0.8478  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.0482  Validation loss = 1.0783  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.0414  Validation loss = 0.9398  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.0390  Validation loss = 0.7542  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.0392  Validation loss = 0.7573  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.0404  Validation loss = 0.9439  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.0427  Validation loss = 1.0333  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.0406  Validation loss = 1.0421  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.0300  Validation loss = 0.9439  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.0355  Validation loss = 0.7084  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.0292  Validation loss = 1.0169  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.0331  Validation loss = 0.7144  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.0349  Validation loss = 0.7016  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.0203  Validation loss = 0.8538  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.0282  Validation loss = 0.9951  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.0207  Validation loss = 0.7867  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.0446  Validation loss = 1.2589  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 18  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.9700  Validation loss = 4.2524  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.9376  Validation loss = 4.3509  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.9439  Validation loss = 4.3727  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.9468  Validation loss = 4.3658  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.0039  Validation loss = 4.1614  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.9442  Validation loss = 4.3849  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.9477  Validation loss = 4.3733  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.9373  Validation loss = 4.2816  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.9450  Validation loss = 4.1825  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.9324  Validation loss = 4.2830  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.9559  Validation loss = 4.4109  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 5  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.3881  Validation loss = 7.5743  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.3666  Validation loss = 7.4419  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.3606  Validation loss = 7.5188  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.3832  Validation loss = 7.4200  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.3606  Validation loss = 7.2872  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.3570  Validation loss = 7.1900  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.3495  Validation loss = 7.0371  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.3676  Validation loss = 7.3716  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.3506  Validation loss = 7.3808  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.3583  Validation loss = 6.9530  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.3167  Validation loss = 6.8685  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.3209  Validation loss = 6.7951  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.3126  Validation loss = 6.8076  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.3014  Validation loss = 6.9038  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.3414  Validation loss = 6.8428  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.3063  Validation loss = 6.8686  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.3356  Validation loss = 6.9585  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.2935  Validation loss = 6.8274  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.2846  Validation loss = 6.7813  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.2901  Validation loss = 6.6938  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.2827  Validation loss = 6.6830  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.3655  Validation loss = 6.6625  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.3103  Validation loss = 7.0739  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 22  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.0911  Validation loss = 2.8076  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.0328  Validation loss = 2.8859  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.9804  Validation loss = 3.1237  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.9347  Validation loss = 2.8611  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.8843  Validation loss = 2.6136  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.8823  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.8578  Validation loss = 2.6434  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.8817  Validation loss = 2.7915  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.8491  Validation loss = 2.5934  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.8275  Validation loss = 2.6154  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.8288  Validation loss = 2.6353  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.8092  Validation loss = 2.6810  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 1.7986  Validation loss = 2.6588  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.7813  Validation loss = 2.6732  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.7897  Validation loss = 2.5306  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 1.7771  Validation loss = 2.6164  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 1.7473  Validation loss = 2.7318  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 1.7605  Validation loss = 2.7935  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 15  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.8339  Validation loss = 1.3303  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.8191  Validation loss = 1.3730  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.8191  Validation loss = 1.3197  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.8103  Validation loss = 1.4359  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.8175  Validation loss = 1.5270  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.7881  Validation loss = 1.3056  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.7863  Validation loss = 1.4498  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.8086  Validation loss = 1.2843  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.7713  Validation loss = 1.3105  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.7858  Validation loss = 1.5802  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.7807  Validation loss = 1.6634  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 8  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.7605  Validation loss = 1.8566  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.7486  Validation loss = 1.8462  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.7438  Validation loss = 1.7949  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.7397  Validation loss = 1.6767  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.7245  Validation loss = 1.6484  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.7089  Validation loss = 1.6204  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.7143  Validation loss = 1.6049  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.7563  Validation loss = 1.5684  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.7006  Validation loss = 1.5342  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.7021  Validation loss = 1.5218  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.6973  Validation loss = 1.5432  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.7005  Validation loss = 1.5672  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.6882  Validation loss = 1.5390  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.6830  Validation loss = 1.5379  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.6784  Validation loss = 1.5341  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.6768  Validation loss = 1.5284  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 1.6975  Validation loss = 1.6060  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 10  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.6901  Validation loss = 3.6699  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.7556  Validation loss = 3.7641  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.6874  Validation loss = 3.4285  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.6682  Validation loss = 3.3970  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.6593  Validation loss = 3.5848  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.6801  Validation loss = 3.4576  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.6772  Validation loss = 3.3646  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.6438  Validation loss = 3.4725  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.6349  Validation loss = 3.3966  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.6326  Validation loss = 3.4582  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.6732  Validation loss = 3.2730  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.6752  Validation loss = 3.3078  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 1.6408  Validation loss = 3.4077  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 1.6212  Validation loss = 3.4859  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 1.6525  Validation loss = 3.6945  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 11  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.8419  Validation loss = 5.5708  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.8587  Validation loss = 5.7246  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.8139  Validation loss = 5.5386  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.7982  Validation loss = 5.3174  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.7955  Validation loss = 5.5294  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.8183  Validation loss = 5.5138  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.8359  Validation loss = 5.0870  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.7760  Validation loss = 5.4739  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.7934  Validation loss = 5.2725  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.7428  Validation loss = 5.1749  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.6924  Validation loss = 5.2912  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.6785  Validation loss = 5.2349  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.7761  Validation loss = 4.7035  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.6762  Validation loss = 5.0685  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.6888  Validation loss = 5.1388  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.6516  Validation loss = 5.1658  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.6216  Validation loss = 5.1731  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.6761  Validation loss = 5.0349  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.6355  Validation loss = 4.8982  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 1.6223  Validation loss = 4.8153  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 1.6974  Validation loss = 5.6323  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 13  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.0765  Validation loss = 4.3291  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.9713  Validation loss = 4.2662  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 1.9333  Validation loss = 4.1899  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.9124  Validation loss = 4.1632  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.0049  Validation loss = 4.1114  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.8681  Validation loss = 4.0701  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.9657  Validation loss = 4.0758  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.9996  Validation loss = 4.0232  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.9946  Validation loss = 4.0427  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.8579  Validation loss = 4.0246  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.0529  Validation loss = 4.0141  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.0167  Validation loss = 4.0166  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.0160  Validation loss = 4.0223  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.4435  Validation loss = 5.6367  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 11  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.4622  Validation loss = 5.4637  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.4082  Validation loss = 5.5995  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.3582  Validation loss = 5.5996  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.3462  Validation loss = 5.6196  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.3286  Validation loss = 5.4274  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.1767  Validation loss = 5.5400  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.1621  Validation loss = 5.8393  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.1625  Validation loss = 5.7519  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.1942  Validation loss = 5.1709  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.6328  Validation loss = 6.0766  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.5142  Validation loss = 5.8001  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.3571  Validation loss = 5.9205  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.1832  Validation loss = 5.9673  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.1810  Validation loss = 5.6645  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.1331  Validation loss = 5.6246  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.4927  Validation loss = 6.2339  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 9  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.7671  Validation loss = 3.1009  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.6461  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.7551  Validation loss = 2.7298  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.5396  Validation loss = 2.3458  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.5398  Validation loss = 2.4257  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.5075  Validation loss = 2.3379  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.4942  Validation loss = 2.3063  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.4869  Validation loss = 2.4971  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.4765  Validation loss = 2.2481  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.3589  Validation loss = 2.2770  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.5129  Validation loss = 2.2680  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.4828  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.2775  Validation loss = 2.4439  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.3401  Validation loss = 2.3707  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.2471  Validation loss = 2.3799  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 2.3486  Validation loss = 2.7048  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 9  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.3495  Validation loss = 0.7100  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.4328  Validation loss = 0.7039  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.3490  Validation loss = 0.8554  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.3281  Validation loss = 1.0185  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.2632  Validation loss = 0.9819  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.3000  Validation loss = 0.9456  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.3135  Validation loss = 0.8997  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.1942  Validation loss = 0.9218  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.1776  Validation loss = 0.9500  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.1279  Validation loss = 1.0358  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.9027  Validation loss = 1.3302  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 2  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.7773  Validation loss = 2.0979  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.7658  Validation loss = 2.2312  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.7233  Validation loss = 2.3532  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.6382  Validation loss = 2.3098  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.6944  Validation loss = 2.3234  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.5703  Validation loss = 2.6306  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.4994  Validation loss = 2.6972  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.5710  Validation loss = 2.7741  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.7441  Validation loss = 2.8114  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.3062  Validation loss = 3.3300  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.1078  Validation loss = 2.8111  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.1071  Validation loss = 2.7263  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 1.9431  Validation loss = 3.0210  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.0014  Validation loss = 3.2733  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 1.9612  Validation loss = 3.0902  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 1.9184  Validation loss = 3.1146  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 1.9695  Validation loss = 3.1790  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 1.9607  Validation loss = 2.8920  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 1.9291  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 1.8430  Validation loss = 2.9060  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 1.9433  Validation loss = 2.8658  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 1.8532  Validation loss = 3.1335  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 1.8665  Validation loss = 3.0249  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 1.8294  Validation loss = 2.8579  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 1.8520  Validation loss = 2.8462  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 1.7975  Validation loss = 2.8747  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 1.7637  Validation loss = 2.7704  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 1.7270  Validation loss = 2.8072  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 1.7118  Validation loss = 2.7961  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 1.7232  Validation loss = 2.7988  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 1.8237  Validation loss = 2.7799  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 1.7020  Validation loss = 2.7667  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 1.8008  Validation loss = 2.7509  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 1.6769  Validation loss = 2.7211  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 1.6689  Validation loss = 2.8224  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 1.6791  Validation loss = 2.7222  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 1.6420  Validation loss = 2.6850  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 1.6930  Validation loss = 2.6544  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 1.6631  Validation loss = 2.6257  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 1.7415  Validation loss = 2.6093  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 1.6413  Validation loss = 2.5802  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 1.7404  Validation loss = 2.7534  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 1.6727  Validation loss = 2.7270  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 1.6602  Validation loss = 2.7300  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 1.6484  Validation loss = 2.7522  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 1.7036  Validation loss = 2.8827  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 1  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 1.7523  Validation loss = 1.0160  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 1.7374  Validation loss = 1.0027  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 1.8875  Validation loss = 1.0425  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 1.7843  Validation loss = 0.9394  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 1.9642  Validation loss = 0.9087  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 1.7366  Validation loss = 1.0370  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 1.7284  Validation loss = 0.7735  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 1.7169  Validation loss = 0.8838  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 1.7092  Validation loss = 0.8400  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 1.6698  Validation loss = 0.8394  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 1.7237  Validation loss = 0.8411  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 1.6948  Validation loss = 0.8670  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 1.6916  Validation loss = 0.7970  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 1.6788  Validation loss = 0.8730  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 1.6432  Validation loss = 0.9981  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 1.6331  Validation loss = 0.8637  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 1.6758  Validation loss = 0.8703  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 1.8459  Validation loss = 0.9511  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 1.6538  Validation loss = 0.9153  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 1.6669  Validation loss = 1.0464  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 7  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 1.6080  Validation loss = 2.6858  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.6032  Validation loss = 3.1560  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 1.7185  Validation loss = 3.6723  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.6793  Validation loss = 3.1711  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 1.6469  Validation loss = 3.4644  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 1.6308  Validation loss = 3.3121  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 1.6914  Validation loss = 2.9669  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 1.6214  Validation loss = 3.2581  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.6123  Validation loss = 3.4758  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 1.5725  Validation loss = 3.2474  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 1.6140  Validation loss = 3.1939  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 1.5488  Validation loss = 3.2697  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 1.5246  Validation loss = 3.3838  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 1.5463  Validation loss = 3.0157  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 1.6045  Validation loss = 3.5064  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.6664  Validation loss = 4.0427  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 1.7495  Validation loss = 4.6540  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.6173  Validation loss = 4.1574  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 1.6002  Validation loss = 4.0675  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 1.5358  Validation loss = 4.2839  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 1.5190  Validation loss = 3.7662  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.5189  Validation loss = 3.0339  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 1.5351  Validation loss = 3.8589  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.4908  Validation loss = 4.2014  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.5312  Validation loss = 4.2437  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 1.5352  Validation loss = 4.3729  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 1.6503  Validation loss = 4.0482  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 1.5629  Validation loss = 4.5243  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 7  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.0183  Validation loss = 3.8682  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 1.9242  Validation loss = 3.0528  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 1.8690  Validation loss = 2.6736  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 1.7718  Validation loss = 1.9325  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 1.7155  Validation loss = 1.4250  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 1.7278  Validation loss = 1.8714  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 1.6289  Validation loss = 1.8229  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 1.9585  Validation loss = 3.7660  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.1861  Validation loss = 3.3370  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.0334  Validation loss = 3.2116  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.8138  Validation loss = 4.1130  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 5  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.7011  Validation loss = 1.4952  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.5598  Validation loss = 1.8911  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.6563  Validation loss = 1.9986  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.6369  Validation loss = 2.0503  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.6842  Validation loss = 2.0921  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.5405  Validation loss = 2.0605  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.5230  Validation loss = 2.1805  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 1.4722  Validation loss = 2.0921  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 1.6074  Validation loss = 1.9804  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.5547  Validation loss = 1.7483  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.2550  Validation loss = 1.4383  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.3908  Validation loss = 1.1311  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.2519  Validation loss = 2.0789  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.1306  Validation loss = 1.4472  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.1986  Validation loss = 1.2715  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.2644  Validation loss = 1.9959  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.1522  Validation loss = 1.7176  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.0574  Validation loss = 1.5324  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.0335  Validation loss = 1.2027  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 1.9238  Validation loss = 2.3858  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 12  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 1.9419  Validation loss = 1.6777  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 1.9261  Validation loss = 1.7214  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 1.8403  Validation loss = 1.8983  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 1.8351  Validation loss = 1.9024  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 1.8021  Validation loss = 2.0521  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 1.7888  Validation loss = 1.8543  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 1.7722  Validation loss = 2.0623  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 1.7932  Validation loss = 1.8610  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 1.7269  Validation loss = 1.9496  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 1.7594  Validation loss = 2.3215  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 1.7244  Validation loss = 2.1429  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 1.7469  Validation loss = 2.1251  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 1.7357  Validation loss = 2.4149  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 1  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.0332  Validation loss = 2.6861  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.0262  Validation loss = 0.7041  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 1.8891  Validation loss = 0.7522  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 1.7334  Validation loss = 1.1283  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 1.7803  Validation loss = 1.0767  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 1.7538  Validation loss = 1.0104  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 1.7655  Validation loss = 1.0415  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 1.6798  Validation loss = 1.5220  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 1.9127  Validation loss = 2.2531  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 1.7290  Validation loss = 1.2167  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 1.7689  Validation loss = 1.1933  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 1.8119  Validation loss = 1.6770  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 1.6884  Validation loss = 1.1490  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 1.8503  Validation loss = 1.9427  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 1.7207  Validation loss = 1.0850  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 1.7103  Validation loss = 1.0845  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 1.8258  Validation loss = 0.9283  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 1.7468  Validation loss = 0.9814  \n",
      "\n",
      "Fold: 26  Epoch: 19  Training loss = 1.6628  Validation loss = 1.1864  \n",
      "\n",
      "Fold: 26  Epoch: 20  Training loss = 1.6498  Validation loss = 1.1126  \n",
      "\n",
      "Fold: 26  Epoch: 21  Training loss = 1.6658  Validation loss = 1.1286  \n",
      "\n",
      "Fold: 26  Epoch: 22  Training loss = 1.7132  Validation loss = 1.2883  \n",
      "\n",
      "Fold: 26  Epoch: 23  Training loss = 1.6588  Validation loss = 1.1980  \n",
      "\n",
      "Fold: 26  Epoch: 24  Training loss = 1.7214  Validation loss = 1.0416  \n",
      "\n",
      "Fold: 26  Epoch: 25  Training loss = 1.6591  Validation loss = 1.1389  \n",
      "\n",
      "Fold: 26  Epoch: 26  Training loss = 1.6842  Validation loss = 1.2104  \n",
      "\n",
      "Fold: 26  Epoch: 27  Training loss = 1.6429  Validation loss = 1.1167  \n",
      "\n",
      "Fold: 26  Epoch: 28  Training loss = 1.6443  Validation loss = 1.1017  \n",
      "\n",
      "Fold: 26  Epoch: 29  Training loss = 1.6814  Validation loss = 1.2897  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 2  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 1.4888  Validation loss = 1.7261  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 1.5726  Validation loss = 1.3654  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.5589  Validation loss = 2.0445  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 1.4558  Validation loss = 1.7890  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 1.4845  Validation loss = 1.9653  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 1.4386  Validation loss = 1.8774  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 1.4786  Validation loss = 1.9253  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 1.4683  Validation loss = 1.7119  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 1.4275  Validation loss = 1.9337  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.4321  Validation loss = 1.8613  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 1.4313  Validation loss = 1.7721  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 1.4077  Validation loss = 1.8334  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 1.4208  Validation loss = 1.7769  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 1.4427  Validation loss = 1.9338  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 1.4661  Validation loss = 2.2074  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 2  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 1.5376  Validation loss = 0.3827  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 1.4828  Validation loss = 0.4126  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 1.4494  Validation loss = 0.3865  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 1.4190  Validation loss = 0.3663  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 1.4553  Validation loss = 0.3385  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 1.3997  Validation loss = 0.6776  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 1.4422  Validation loss = 0.6293  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 1.4024  Validation loss = 0.3699  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 1.4407  Validation loss = 0.5841  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 1.5676  Validation loss = 0.5180  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 1.4770  Validation loss = 0.6565  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 1.4133  Validation loss = 0.5997  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 1.4017  Validation loss = 0.3175  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 1.3740  Validation loss = 0.3476  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 1.5212  Validation loss = 0.6316  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 1.4080  Validation loss = 0.2900  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 1.4289  Validation loss = 0.4835  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 1.4210  Validation loss = 0.4170  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 1.5536  Validation loss = 0.8141  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 16  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 1.3515  Validation loss = 1.7016  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 1.3555  Validation loss = 1.7071  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 1.3380  Validation loss = 1.5326  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 1.4039  Validation loss = 1.4423  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 1.2896  Validation loss = 1.6470  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 1.3654  Validation loss = 1.8441  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 1.3332  Validation loss = 1.6159  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 1.3284  Validation loss = 2.0102  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 1.3130  Validation loss = 1.8851  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.3039  Validation loss = 1.7637  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 1.2906  Validation loss = 1.9503  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 1.2587  Validation loss = 2.0642  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 4  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.3487  Validation loss = 1.4779  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 1.4388  Validation loss = 1.8404  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 1.3463  Validation loss = 2.0195  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 1.3843  Validation loss = 2.2957  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 1.3439  Validation loss = 1.6189  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.3262  Validation loss = 1.4614  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 1.3453  Validation loss = 1.6989  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.3180  Validation loss = 1.9690  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.3157  Validation loss = 2.1541  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.3318  Validation loss = 2.3254  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.3281  Validation loss = 2.5373  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 6  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 1.3895  Validation loss = 2.2040  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.3972  Validation loss = 2.2840  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.3977  Validation loss = 2.2385  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.4130  Validation loss = 2.3768  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 1.6338  Validation loss = 2.4125  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 1.6588  Validation loss = 2.6076  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.6547  Validation loss = 2.4513  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.5110  Validation loss = 2.5001  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.5283  Validation loss = 2.5979  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 1.4380  Validation loss = 2.3930  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.4045  Validation loss = 2.3003  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.4618  Validation loss = 2.4136  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.5315  Validation loss = 2.6509  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 1  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.3357  Validation loss = 3.4161  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.3707  Validation loss = 3.5301  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.2940  Validation loss = 3.4526  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.3134  Validation loss = 3.3011  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.3111  Validation loss = 3.3250  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.3185  Validation loss = 3.0958  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.3073  Validation loss = 3.4115  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.2819  Validation loss = 2.8958  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.2809  Validation loss = 2.8930  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.3250  Validation loss = 3.6487  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.3106  Validation loss = 3.4990  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.2559  Validation loss = 3.4114  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.2504  Validation loss = 2.9806  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.2762  Validation loss = 2.9329  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.2898  Validation loss = 3.2753  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.2351  Validation loss = 3.2006  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.2546  Validation loss = 3.4204  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.2559  Validation loss = 3.0280  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.2364  Validation loss = 3.3248  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.3797  Validation loss = 3.5485  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 9  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 12\n",
      "Average validation error: 2.80848\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.4416  Test loss = 3.4507  \n",
      "\n",
      "Epoch: 2  Training loss = 1.3848  Test loss = 3.3001  \n",
      "\n",
      "Epoch: 3  Training loss = 1.3586  Test loss = 3.1997  \n",
      "\n",
      "Epoch: 4  Training loss = 1.3437  Test loss = 3.1311  \n",
      "\n",
      "Epoch: 5  Training loss = 1.3322  Test loss = 3.0789  \n",
      "\n",
      "Epoch: 6  Training loss = 1.3196  Test loss = 3.0273  \n",
      "\n",
      "Epoch: 7  Training loss = 1.3101  Test loss = 2.9814  \n",
      "\n",
      "Epoch: 8  Training loss = 1.3052  Test loss = 3.0056  \n",
      "\n",
      "Epoch: 9  Training loss = 1.3016  Test loss = 3.0062  \n",
      "\n",
      "Epoch: 10  Training loss = 1.2987  Test loss = 3.0111  \n",
      "\n",
      "Epoch: 11  Training loss = 1.2961  Test loss = 3.0128  \n",
      "\n",
      "Epoch: 12  Training loss = 1.2938  Test loss = 3.0142  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6233c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd1ff710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.01421786315 \n",
      "Fixed scheme MAE:  2.14967504226\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.2938  Test loss = 2.2537  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.3218  Test loss = 2.6226  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.3520  Test loss = 0.7245  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.3548  Test loss = 0.4299  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.1797  Test loss = 0.1026  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.1762  Test loss = 0.3095  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.1754  Test loss = 0.0479  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.1745  Test loss = 0.0869  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.0191  Test loss = 1.4319  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.0308  Test loss = 2.2734  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.0597  Test loss = 2.9327  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.1158  Test loss = 1.5810  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.9118  Test loss = 1.4600  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.9294  Test loss = 1.0482  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 0.9344  Test loss = 2.0428  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 0.9671  Test loss = 4.0219  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.0376  Test loss = 0.3223  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.0289  Test loss = 0.7737  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.0309  Test loss = 1.8501  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.0095  Test loss = 1.2642  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.8449  Test loss = 0.6968  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.8451  Test loss = 4.5773  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.0141  Test loss = 1.4869  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.0299  Test loss = 2.6605  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.9515  Test loss = 0.4448  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.9527  Test loss = 0.6023  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.9551  Test loss = 0.5314  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 0.9572  Test loss = 0.6128  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.8910  Test loss = 0.5543  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.8920  Test loss = 0.5201  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.8925  Test loss = 3.3341  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.9767  Test loss = 0.1914  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.9112  Test loss = 2.1719  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.9487  Test loss = 0.0776  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.9215  Test loss = 0.2600  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.9151  Test loss = 5.4066  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.0729  Test loss = 1.3594  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.0653  Test loss = 0.0924  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.0559  Test loss = 1.5499  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.0729  Test loss = 1.5940  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.9190  Test loss = 2.2526  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.9568  Test loss = 1.5642  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.9760  Test loss = 3.3659  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.0488  Test loss = 12.6282  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.8392  Test loss = 6.2117  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 1.9930  Test loss = 0.3553  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 1.9933  Test loss = 0.4195  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 1.9922  Test loss = 0.9568  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.5557  Test loss = 3.2979  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.6044  Test loss = 2.4087  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.6320  Test loss = 0.4504  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.6317  Test loss = 3.0859  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.5993  Test loss = 3.3670  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.6528  Test loss = 0.1235  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.6529  Test loss = 1.8149  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.6668  Test loss = 0.4775  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.5745  Test loss = 0.6339  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.5759  Test loss = 1.6902  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.5860  Test loss = 0.9586  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.5896  Test loss = 1.9708  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.5328  Test loss = 0.2047  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.5320  Test loss = 2.8030  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.5642  Test loss = 0.1769  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.5577  Test loss = 1.1467  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.5262  Test loss = 1.0294  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.5262  Test loss = 1.6062  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.5387  Test loss = 1.5297  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.5503  Test loss = 2.2908  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.5484  Test loss = 4.1929  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.6329  Test loss = 0.1159  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.6323  Test loss = 1.9755  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.6483  Test loss = 3.3867  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.6212  Test loss = 3.5137  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.6752  Test loss = 1.1006  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.6800  Test loss = 0.8814  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.6684  Test loss = 0.1159  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.5489  Test loss = 1.9338  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdbc61d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.5068432247 \n",
      "Updating scheme MAE:  1.71871347742\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
