{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/2_cells/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 750\n",
    "learning_rate = 1e-6\n",
    "batch_size = 5\n",
    "early_stop_iters = 15\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 12 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell]*2, state_is_tuple = True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 12 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 750 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 15 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.1087  Validation loss = 3.1264  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.1087  Validation loss = 3.1263  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.1086  Validation loss = 3.1262  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.1086  Validation loss = 3.1261  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.1085  Validation loss = 3.1260  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.1085  Validation loss = 3.1258  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.1084  Validation loss = 3.1257  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.1084  Validation loss = 3.1256  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.1083  Validation loss = 3.1255  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.1082  Validation loss = 3.1254  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.1082  Validation loss = 3.1252  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.1081  Validation loss = 3.1251  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.1081  Validation loss = 3.1250  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.1080  Validation loss = 3.1248  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.1079  Validation loss = 3.1247  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.1079  Validation loss = 3.1246  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.1078  Validation loss = 3.1244  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.1077  Validation loss = 3.1243  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.1077  Validation loss = 3.1241  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.1076  Validation loss = 3.1240  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.1076  Validation loss = 3.1239  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.1075  Validation loss = 3.1238  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.1075  Validation loss = 3.1237  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.1074  Validation loss = 3.1235  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.1073  Validation loss = 3.1234  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.1073  Validation loss = 3.1233  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.1072  Validation loss = 3.1231  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.1071  Validation loss = 3.1230  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.1071  Validation loss = 3.1229  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.1070  Validation loss = 3.1228  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.1070  Validation loss = 3.1226  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.1069  Validation loss = 3.1225  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.1068  Validation loss = 3.1224  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.1067  Validation loss = 3.1222  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.1067  Validation loss = 3.1221  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.1066  Validation loss = 3.1219  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.1065  Validation loss = 3.1218  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.1065  Validation loss = 3.1216  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.1064  Validation loss = 3.1215  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.1063  Validation loss = 3.1214  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.1063  Validation loss = 3.1212  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.1062  Validation loss = 3.1211  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.1061  Validation loss = 3.1210  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.1061  Validation loss = 3.1208  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.1060  Validation loss = 3.1207  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.1059  Validation loss = 3.1205  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.1059  Validation loss = 3.1204  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.1058  Validation loss = 3.1203  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.1058  Validation loss = 3.1202  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.1057  Validation loss = 3.1201  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.1056  Validation loss = 3.1199  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.1056  Validation loss = 3.1198  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.1055  Validation loss = 3.1196  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.1055  Validation loss = 3.1195  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.1054  Validation loss = 3.1194  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.1053  Validation loss = 3.1192  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.1052  Validation loss = 3.1191  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.1052  Validation loss = 3.1189  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.1051  Validation loss = 3.1188  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.1050  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.1050  Validation loss = 3.1185  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.1049  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.1048  Validation loss = 3.1182  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.1048  Validation loss = 3.1181  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.1047  Validation loss = 3.1180  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.1046  Validation loss = 3.1178  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.1046  Validation loss = 3.1177  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.1045  Validation loss = 3.1176  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.1044  Validation loss = 3.1174  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.1044  Validation loss = 3.1173  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.1043  Validation loss = 3.1172  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.1043  Validation loss = 3.1170  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.1042  Validation loss = 3.1169  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.1041  Validation loss = 3.1167  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.1040  Validation loss = 3.1166  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.1040  Validation loss = 3.1164  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.1039  Validation loss = 3.1163  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.1039  Validation loss = 3.1162  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.1038  Validation loss = 3.1161  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.1038  Validation loss = 3.1160  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.1037  Validation loss = 3.1158  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.1036  Validation loss = 3.1157  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.1036  Validation loss = 3.1156  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.1035  Validation loss = 3.1155  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.1035  Validation loss = 3.1154  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.1034  Validation loss = 3.1152  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.1033  Validation loss = 3.1151  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.1033  Validation loss = 3.1150  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.1032  Validation loss = 3.1148  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.1031  Validation loss = 3.1147  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.1031  Validation loss = 3.1146  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.1030  Validation loss = 3.1145  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.1030  Validation loss = 3.1144  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.1030  Validation loss = 3.1143  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.1029  Validation loss = 3.1141  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.1028  Validation loss = 3.1139  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.1027  Validation loss = 3.1138  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.1027  Validation loss = 3.1137  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.1026  Validation loss = 3.1135  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.1025  Validation loss = 3.1134  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.1024  Validation loss = 3.1132  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.1024  Validation loss = 3.1131  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.1023  Validation loss = 3.1130  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.1023  Validation loss = 3.1129  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.1022  Validation loss = 3.1127  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.1021  Validation loss = 3.1126  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.1021  Validation loss = 3.1124  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.1020  Validation loss = 3.1123  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.1020  Validation loss = 3.1122  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.1019  Validation loss = 3.1120  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.1018  Validation loss = 3.1119  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.1018  Validation loss = 3.1118  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.1017  Validation loss = 3.1116  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.1016  Validation loss = 3.1115  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.1016  Validation loss = 3.1114  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.1015  Validation loss = 3.1113  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.1015  Validation loss = 3.1112  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.1014  Validation loss = 3.1110  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.1014  Validation loss = 3.1109  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.1013  Validation loss = 3.1108  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.1012  Validation loss = 3.1107  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.1012  Validation loss = 3.1106  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.1011  Validation loss = 3.1105  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.1011  Validation loss = 3.1103  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.1010  Validation loss = 3.1102  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.1010  Validation loss = 3.1101  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.1009  Validation loss = 3.1100  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.1009  Validation loss = 3.1099  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.1008  Validation loss = 3.1097  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.1008  Validation loss = 3.1097  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.1007  Validation loss = 3.1094  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.1006  Validation loss = 3.1093  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.1005  Validation loss = 3.1092  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.1005  Validation loss = 3.1091  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.1004  Validation loss = 3.1089  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.1003  Validation loss = 3.1088  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.1003  Validation loss = 3.1086  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.1002  Validation loss = 3.1085  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.1002  Validation loss = 3.1084  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.1001  Validation loss = 3.1083  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.1000  Validation loss = 3.1081  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.1000  Validation loss = 3.1080  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.0999  Validation loss = 3.1079  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.0998  Validation loss = 3.1077  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.0998  Validation loss = 3.1076  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.0997  Validation loss = 3.1075  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.0997  Validation loss = 3.1074  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.0996  Validation loss = 3.1073  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.0995  Validation loss = 3.1071  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.0995  Validation loss = 3.1070  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.0994  Validation loss = 3.1068  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.0994  Validation loss = 3.1067  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.0993  Validation loss = 3.1066  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.0992  Validation loss = 3.1065  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.0992  Validation loss = 3.1063  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.0991  Validation loss = 3.1062  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.0990  Validation loss = 3.1061  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.0990  Validation loss = 3.1059  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.0990  Validation loss = 3.1059  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.0989  Validation loss = 3.1057  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.0988  Validation loss = 3.1056  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.0988  Validation loss = 3.1055  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.0987  Validation loss = 3.1054  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.0987  Validation loss = 3.1052  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.0986  Validation loss = 3.1050  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.0985  Validation loss = 3.1049  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.0984  Validation loss = 3.1047  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.0984  Validation loss = 3.1046  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.0983  Validation loss = 3.1045  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.0982  Validation loss = 3.1044  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.0982  Validation loss = 3.1042  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.0981  Validation loss = 3.1041  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.0980  Validation loss = 3.1039  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.0980  Validation loss = 3.1038  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.0979  Validation loss = 3.1036  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.0978  Validation loss = 3.1035  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.0978  Validation loss = 3.1034  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.0977  Validation loss = 3.1033  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.0977  Validation loss = 3.1032  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.0976  Validation loss = 3.1030  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.0975  Validation loss = 3.1029  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.0975  Validation loss = 3.1027  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.0974  Validation loss = 3.1025  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.0973  Validation loss = 3.1024  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.0972  Validation loss = 3.1022  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.0972  Validation loss = 3.1021  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.0971  Validation loss = 3.1019  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.0970  Validation loss = 3.1018  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.0970  Validation loss = 3.1016  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.0969  Validation loss = 3.1016  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.0969  Validation loss = 3.1015  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.0968  Validation loss = 3.1013  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.0968  Validation loss = 3.1012  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.0967  Validation loss = 3.1011  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.0966  Validation loss = 3.1009  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.0966  Validation loss = 3.1008  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.0965  Validation loss = 3.1007  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.0965  Validation loss = 3.1006  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.0964  Validation loss = 3.1004  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.0963  Validation loss = 3.1003  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.0962  Validation loss = 3.1001  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.0962  Validation loss = 3.1000  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.0961  Validation loss = 3.0999  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.0960  Validation loss = 3.0997  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.0960  Validation loss = 3.0996  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.0959  Validation loss = 3.0994  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.0959  Validation loss = 3.0993  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.0958  Validation loss = 3.0992  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.0957  Validation loss = 3.0991  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.0957  Validation loss = 3.0989  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.0956  Validation loss = 3.0988  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.0955  Validation loss = 3.0986  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.0955  Validation loss = 3.0985  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.0954  Validation loss = 3.0983  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.0954  Validation loss = 3.0982  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.0953  Validation loss = 3.0981  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.0952  Validation loss = 3.0980  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.0952  Validation loss = 3.0978  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.0951  Validation loss = 3.0977  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.0951  Validation loss = 3.0976  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.0950  Validation loss = 3.0975  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.0949  Validation loss = 3.0974  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.0949  Validation loss = 3.0972  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.0948  Validation loss = 3.0971  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.0947  Validation loss = 3.0969  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.0947  Validation loss = 3.0968  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.0946  Validation loss = 3.0967  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.0946  Validation loss = 3.0966  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.0945  Validation loss = 3.0964  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.0944  Validation loss = 3.0963  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.0944  Validation loss = 3.0962  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.0943  Validation loss = 3.0961  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.0943  Validation loss = 3.0959  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.0942  Validation loss = 3.0958  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.0941  Validation loss = 3.0956  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.0941  Validation loss = 3.0955  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.0940  Validation loss = 3.0954  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.0940  Validation loss = 3.0953  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.0939  Validation loss = 3.0951  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.0938  Validation loss = 3.0950  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.0938  Validation loss = 3.0949  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.0937  Validation loss = 3.0948  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.0937  Validation loss = 3.0947  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.0936  Validation loss = 3.0946  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.0936  Validation loss = 3.0944  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.0935  Validation loss = 3.0943  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.0934  Validation loss = 3.0941  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.0934  Validation loss = 3.0940  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.0933  Validation loss = 3.0939  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.0933  Validation loss = 3.0938  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.0932  Validation loss = 3.0936  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.0931  Validation loss = 3.0935  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.0931  Validation loss = 3.0934  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.0930  Validation loss = 3.0933  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.0930  Validation loss = 3.0932  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.0929  Validation loss = 3.0930  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.0929  Validation loss = 3.0929  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.0928  Validation loss = 3.0928  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.0927  Validation loss = 3.0927  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.0927  Validation loss = 3.0926  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.0927  Validation loss = 3.0925  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.0926  Validation loss = 3.0923  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.0925  Validation loss = 3.0922  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.0925  Validation loss = 3.0921  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.0924  Validation loss = 3.0920  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.0924  Validation loss = 3.0919  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.0923  Validation loss = 3.0918  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.0923  Validation loss = 3.0917  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.0922  Validation loss = 3.0916  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.0922  Validation loss = 3.0915  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.0921  Validation loss = 3.0913  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.0921  Validation loss = 3.0912  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.0920  Validation loss = 3.0911  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.0919  Validation loss = 3.0909  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.0919  Validation loss = 3.0909  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.0918  Validation loss = 3.0907  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.0918  Validation loss = 3.0906  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.0917  Validation loss = 3.0905  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.0916  Validation loss = 3.0903  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.0916  Validation loss = 3.0902  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.0915  Validation loss = 3.0900  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.0914  Validation loss = 3.0899  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.0914  Validation loss = 3.0898  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.0913  Validation loss = 3.0896  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.0912  Validation loss = 3.0895  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.0912  Validation loss = 3.0894  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.0911  Validation loss = 3.0892  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.0911  Validation loss = 3.0891  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.0910  Validation loss = 3.0889  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.0909  Validation loss = 3.0888  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.0909  Validation loss = 3.0887  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.0908  Validation loss = 3.0886  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.0908  Validation loss = 3.0885  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.0907  Validation loss = 3.0883  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.0906  Validation loss = 3.0881  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.0906  Validation loss = 3.0881  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.0905  Validation loss = 3.0880  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.0904  Validation loss = 3.0878  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.0904  Validation loss = 3.0877  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.0903  Validation loss = 3.0875  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.0903  Validation loss = 3.0874  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.0902  Validation loss = 3.0873  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.0902  Validation loss = 3.0872  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.0901  Validation loss = 3.0871  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.0900  Validation loss = 3.0869  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.0900  Validation loss = 3.0868  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.0899  Validation loss = 3.0867  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.0899  Validation loss = 3.0866  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.0898  Validation loss = 3.0864  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.0897  Validation loss = 3.0863  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.0897  Validation loss = 3.0862  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.0896  Validation loss = 3.0860  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.0895  Validation loss = 3.0858  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.0895  Validation loss = 3.0858  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.0894  Validation loss = 3.0856  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.0893  Validation loss = 3.0855  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.0893  Validation loss = 3.0853  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.0892  Validation loss = 3.0851  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.0891  Validation loss = 3.0850  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.0891  Validation loss = 3.0849  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.0890  Validation loss = 3.0848  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.0890  Validation loss = 3.0846  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.0889  Validation loss = 3.0845  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.0889  Validation loss = 3.0844  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.0888  Validation loss = 3.0843  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.0888  Validation loss = 3.0842  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.0887  Validation loss = 3.0841  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.0887  Validation loss = 3.0840  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.0886  Validation loss = 3.0839  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.0886  Validation loss = 3.0838  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.0885  Validation loss = 3.0837  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.0885  Validation loss = 3.0836  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.0884  Validation loss = 3.0835  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.0883  Validation loss = 3.0833  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.0883  Validation loss = 3.0832  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.0882  Validation loss = 3.0831  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.0882  Validation loss = 3.0829  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.0881  Validation loss = 3.0828  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.0880  Validation loss = 3.0827  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.0880  Validation loss = 3.0825  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.0879  Validation loss = 3.0825  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.0879  Validation loss = 3.0823  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.0878  Validation loss = 3.0822  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.0878  Validation loss = 3.0821  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.0877  Validation loss = 3.0820  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.0877  Validation loss = 3.0818  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.0876  Validation loss = 3.0817  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.0875  Validation loss = 3.0816  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.0875  Validation loss = 3.0815  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.0874  Validation loss = 3.0813  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.0873  Validation loss = 3.0812  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.0873  Validation loss = 3.0811  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.0873  Validation loss = 3.0810  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.0872  Validation loss = 3.0809  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.0871  Validation loss = 3.0807  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.0871  Validation loss = 3.0806  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.0870  Validation loss = 3.0804  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.0869  Validation loss = 3.0803  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.0869  Validation loss = 3.0802  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.0868  Validation loss = 3.0801  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.0868  Validation loss = 3.0800  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.0867  Validation loss = 3.0798  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.0866  Validation loss = 3.0796  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.0866  Validation loss = 3.0795  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.0865  Validation loss = 3.0794  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.0864  Validation loss = 3.0792  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.0864  Validation loss = 3.0791  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.0863  Validation loss = 3.0790  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.0863  Validation loss = 3.0789  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.0862  Validation loss = 3.0787  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.0861  Validation loss = 3.0785  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.0860  Validation loss = 3.0784  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.0860  Validation loss = 3.0783  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.0859  Validation loss = 3.0782  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.0859  Validation loss = 3.0781  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.0858  Validation loss = 3.0779  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.0858  Validation loss = 3.0778  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.0857  Validation loss = 3.0777  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.0856  Validation loss = 3.0775  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.0856  Validation loss = 3.0774  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.0855  Validation loss = 3.0773  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.0855  Validation loss = 3.0772  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.0854  Validation loss = 3.0770  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.0853  Validation loss = 3.0769  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.0853  Validation loss = 3.0768  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.0852  Validation loss = 3.0767  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.0852  Validation loss = 3.0766  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.0851  Validation loss = 3.0765  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.0851  Validation loss = 3.0763  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.0850  Validation loss = 3.0762  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.0849  Validation loss = 3.0761  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.0849  Validation loss = 3.0759  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.0848  Validation loss = 3.0758  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.0848  Validation loss = 3.0757  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.0847  Validation loss = 3.0755  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.0846  Validation loss = 3.0754  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.0845  Validation loss = 3.0752  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.0845  Validation loss = 3.0750  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.0844  Validation loss = 3.0749  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.0844  Validation loss = 3.0748  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.0843  Validation loss = 3.0747  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.0842  Validation loss = 3.0745  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.0842  Validation loss = 3.0744  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.0841  Validation loss = 3.0743  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.0841  Validation loss = 3.0742  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.0840  Validation loss = 3.0741  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.0839  Validation loss = 3.0739  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.0839  Validation loss = 3.0738  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.0838  Validation loss = 3.0737  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.0838  Validation loss = 3.0736  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.0837  Validation loss = 3.0734  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.0837  Validation loss = 3.0733  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.0836  Validation loss = 3.0732  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.0836  Validation loss = 3.0731  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.0835  Validation loss = 3.0730  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.0835  Validation loss = 3.0729  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.0834  Validation loss = 3.0728  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.0834  Validation loss = 3.0727  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.0833  Validation loss = 3.0726  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.0833  Validation loss = 3.0725  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.0832  Validation loss = 3.0724  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.0832  Validation loss = 3.0723  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.0831  Validation loss = 3.0722  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.0831  Validation loss = 3.0720  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.0830  Validation loss = 3.0719  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.0829  Validation loss = 3.0718  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.0829  Validation loss = 3.0716  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.0828  Validation loss = 3.0715  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.0827  Validation loss = 3.0714  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.0827  Validation loss = 3.0713  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.0826  Validation loss = 3.0711  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.0826  Validation loss = 3.0710  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.0825  Validation loss = 3.0709  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.0825  Validation loss = 3.0708  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.0824  Validation loss = 3.0707  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.0824  Validation loss = 3.0705  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.0823  Validation loss = 3.0705  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.0823  Validation loss = 3.0703  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.0822  Validation loss = 3.0702  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.0821  Validation loss = 3.0700  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.0821  Validation loss = 3.0699  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.0820  Validation loss = 3.0698  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.0820  Validation loss = 3.0697  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.0819  Validation loss = 3.0696  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.0818  Validation loss = 3.0694  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.0818  Validation loss = 3.0693  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.0817  Validation loss = 3.0692  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.0817  Validation loss = 3.0691  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.0816  Validation loss = 3.0689  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.0816  Validation loss = 3.0688  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.0815  Validation loss = 3.0687  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.0815  Validation loss = 3.0686  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.0814  Validation loss = 3.0685  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.0813  Validation loss = 3.0683  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.0813  Validation loss = 3.0682  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.0812  Validation loss = 3.0680  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.0811  Validation loss = 3.0679  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.0811  Validation loss = 3.0678  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.0810  Validation loss = 3.0676  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.0809  Validation loss = 3.0674  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.0808  Validation loss = 3.0673  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.0808  Validation loss = 3.0672  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.0807  Validation loss = 3.0671  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.0807  Validation loss = 3.0669  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.0806  Validation loss = 3.0667  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.0805  Validation loss = 3.0666  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.0805  Validation loss = 3.0664  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.0804  Validation loss = 3.0663  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.0804  Validation loss = 3.0662  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.0803  Validation loss = 3.0661  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.0803  Validation loss = 3.0660  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.0802  Validation loss = 3.0659  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.0801  Validation loss = 3.0657  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.0801  Validation loss = 3.0656  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.0800  Validation loss = 3.0655  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.0800  Validation loss = 3.0653  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.0799  Validation loss = 3.0653  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.0798  Validation loss = 3.0651  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.0798  Validation loss = 3.0650  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.0797  Validation loss = 3.0649  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.0796  Validation loss = 3.0647  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.0796  Validation loss = 3.0646  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.0795  Validation loss = 3.0644  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.0795  Validation loss = 3.0643  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.0794  Validation loss = 3.0642  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.0794  Validation loss = 3.0641  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.0793  Validation loss = 3.0640  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.0793  Validation loss = 3.0639  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.0792  Validation loss = 3.0638  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.0792  Validation loss = 3.0637  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.0791  Validation loss = 3.0636  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.0791  Validation loss = 3.0635  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.0790  Validation loss = 3.0634  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.0790  Validation loss = 3.0632  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.0789  Validation loss = 3.0631  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.0789  Validation loss = 3.0630  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.0788  Validation loss = 3.0629  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.0788  Validation loss = 3.0628  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.0787  Validation loss = 3.0627  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.0787  Validation loss = 3.0626  \n",
      "\n",
      "Fold: 1  Epoch: 501  Training loss = 3.0786  Validation loss = 3.0625  \n",
      "\n",
      "Fold: 1  Epoch: 502  Training loss = 3.0785  Validation loss = 3.0623  \n",
      "\n",
      "Fold: 1  Epoch: 503  Training loss = 3.0785  Validation loss = 3.0621  \n",
      "\n",
      "Fold: 1  Epoch: 504  Training loss = 3.0784  Validation loss = 3.0620  \n",
      "\n",
      "Fold: 1  Epoch: 505  Training loss = 3.0783  Validation loss = 3.0619  \n",
      "\n",
      "Fold: 1  Epoch: 506  Training loss = 3.0783  Validation loss = 3.0617  \n",
      "\n",
      "Fold: 1  Epoch: 507  Training loss = 3.0782  Validation loss = 3.0616  \n",
      "\n",
      "Fold: 1  Epoch: 508  Training loss = 3.0782  Validation loss = 3.0615  \n",
      "\n",
      "Fold: 1  Epoch: 509  Training loss = 3.0781  Validation loss = 3.0614  \n",
      "\n",
      "Fold: 1  Epoch: 510  Training loss = 3.0781  Validation loss = 3.0613  \n",
      "\n",
      "Fold: 1  Epoch: 511  Training loss = 3.0780  Validation loss = 3.0611  \n",
      "\n",
      "Fold: 1  Epoch: 512  Training loss = 3.0779  Validation loss = 3.0610  \n",
      "\n",
      "Fold: 1  Epoch: 513  Training loss = 3.0779  Validation loss = 3.0609  \n",
      "\n",
      "Fold: 1  Epoch: 514  Training loss = 3.0778  Validation loss = 3.0608  \n",
      "\n",
      "Fold: 1  Epoch: 515  Training loss = 3.0778  Validation loss = 3.0606  \n",
      "\n",
      "Fold: 1  Epoch: 516  Training loss = 3.0777  Validation loss = 3.0605  \n",
      "\n",
      "Fold: 1  Epoch: 517  Training loss = 3.0776  Validation loss = 3.0604  \n",
      "\n",
      "Fold: 1  Epoch: 518  Training loss = 3.0776  Validation loss = 3.0602  \n",
      "\n",
      "Fold: 1  Epoch: 519  Training loss = 3.0775  Validation loss = 3.0601  \n",
      "\n",
      "Fold: 1  Epoch: 520  Training loss = 3.0775  Validation loss = 3.0600  \n",
      "\n",
      "Fold: 1  Epoch: 521  Training loss = 3.0774  Validation loss = 3.0598  \n",
      "\n",
      "Fold: 1  Epoch: 522  Training loss = 3.0773  Validation loss = 3.0597  \n",
      "\n",
      "Fold: 1  Epoch: 523  Training loss = 3.0773  Validation loss = 3.0596  \n",
      "\n",
      "Fold: 1  Epoch: 524  Training loss = 3.0772  Validation loss = 3.0595  \n",
      "\n",
      "Fold: 1  Epoch: 525  Training loss = 3.0772  Validation loss = 3.0594  \n",
      "\n",
      "Fold: 1  Epoch: 526  Training loss = 3.0771  Validation loss = 3.0593  \n",
      "\n",
      "Fold: 1  Epoch: 527  Training loss = 3.0771  Validation loss = 3.0591  \n",
      "\n",
      "Fold: 1  Epoch: 528  Training loss = 3.0770  Validation loss = 3.0590  \n",
      "\n",
      "Fold: 1  Epoch: 529  Training loss = 3.0770  Validation loss = 3.0589  \n",
      "\n",
      "Fold: 1  Epoch: 530  Training loss = 3.0769  Validation loss = 3.0588  \n",
      "\n",
      "Fold: 1  Epoch: 531  Training loss = 3.0768  Validation loss = 3.0586  \n",
      "\n",
      "Fold: 1  Epoch: 532  Training loss = 3.0768  Validation loss = 3.0585  \n",
      "\n",
      "Fold: 1  Epoch: 533  Training loss = 3.0767  Validation loss = 3.0583  \n",
      "\n",
      "Fold: 1  Epoch: 534  Training loss = 3.0766  Validation loss = 3.0582  \n",
      "\n",
      "Fold: 1  Epoch: 535  Training loss = 3.0766  Validation loss = 3.0581  \n",
      "\n",
      "Fold: 1  Epoch: 536  Training loss = 3.0765  Validation loss = 3.0579  \n",
      "\n",
      "Fold: 1  Epoch: 537  Training loss = 3.0765  Validation loss = 3.0578  \n",
      "\n",
      "Fold: 1  Epoch: 538  Training loss = 3.0764  Validation loss = 3.0577  \n",
      "\n",
      "Fold: 1  Epoch: 539  Training loss = 3.0763  Validation loss = 3.0575  \n",
      "\n",
      "Fold: 1  Epoch: 540  Training loss = 3.0763  Validation loss = 3.0574  \n",
      "\n",
      "Fold: 1  Epoch: 541  Training loss = 3.0762  Validation loss = 3.0573  \n",
      "\n",
      "Fold: 1  Epoch: 542  Training loss = 3.0761  Validation loss = 3.0571  \n",
      "\n",
      "Fold: 1  Epoch: 543  Training loss = 3.0761  Validation loss = 3.0570  \n",
      "\n",
      "Fold: 1  Epoch: 544  Training loss = 3.0760  Validation loss = 3.0569  \n",
      "\n",
      "Fold: 1  Epoch: 545  Training loss = 3.0760  Validation loss = 3.0568  \n",
      "\n",
      "Fold: 1  Epoch: 546  Training loss = 3.0760  Validation loss = 3.0567  \n",
      "\n",
      "Fold: 1  Epoch: 547  Training loss = 3.0759  Validation loss = 3.0566  \n",
      "\n",
      "Fold: 1  Epoch: 548  Training loss = 3.0759  Validation loss = 3.0565  \n",
      "\n",
      "Fold: 1  Epoch: 549  Training loss = 3.0758  Validation loss = 3.0563  \n",
      "\n",
      "Fold: 1  Epoch: 550  Training loss = 3.0757  Validation loss = 3.0562  \n",
      "\n",
      "Fold: 1  Epoch: 551  Training loss = 3.0757  Validation loss = 3.0561  \n",
      "\n",
      "Fold: 1  Epoch: 552  Training loss = 3.0756  Validation loss = 3.0560  \n",
      "\n",
      "Fold: 1  Epoch: 553  Training loss = 3.0756  Validation loss = 3.0559  \n",
      "\n",
      "Fold: 1  Epoch: 554  Training loss = 3.0755  Validation loss = 3.0558  \n",
      "\n",
      "Fold: 1  Epoch: 555  Training loss = 3.0754  Validation loss = 3.0556  \n",
      "\n",
      "Fold: 1  Epoch: 556  Training loss = 3.0754  Validation loss = 3.0555  \n",
      "\n",
      "Fold: 1  Epoch: 557  Training loss = 3.0753  Validation loss = 3.0554  \n",
      "\n",
      "Fold: 1  Epoch: 558  Training loss = 3.0753  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 1  Epoch: 559  Training loss = 3.0752  Validation loss = 3.0551  \n",
      "\n",
      "Fold: 1  Epoch: 560  Training loss = 3.0752  Validation loss = 3.0550  \n",
      "\n",
      "Fold: 1  Epoch: 561  Training loss = 3.0751  Validation loss = 3.0549  \n",
      "\n",
      "Fold: 1  Epoch: 562  Training loss = 3.0750  Validation loss = 3.0547  \n",
      "\n",
      "Fold: 1  Epoch: 563  Training loss = 3.0750  Validation loss = 3.0546  \n",
      "\n",
      "Fold: 1  Epoch: 564  Training loss = 3.0749  Validation loss = 3.0545  \n",
      "\n",
      "Fold: 1  Epoch: 565  Training loss = 3.0749  Validation loss = 3.0544  \n",
      "\n",
      "Fold: 1  Epoch: 566  Training loss = 3.0748  Validation loss = 3.0542  \n",
      "\n",
      "Fold: 1  Epoch: 567  Training loss = 3.0748  Validation loss = 3.0542  \n",
      "\n",
      "Fold: 1  Epoch: 568  Training loss = 3.0747  Validation loss = 3.0540  \n",
      "\n",
      "Fold: 1  Epoch: 569  Training loss = 3.0746  Validation loss = 3.0539  \n",
      "\n",
      "Fold: 1  Epoch: 570  Training loss = 3.0746  Validation loss = 3.0538  \n",
      "\n",
      "Fold: 1  Epoch: 571  Training loss = 3.0745  Validation loss = 3.0537  \n",
      "\n",
      "Fold: 1  Epoch: 572  Training loss = 3.0745  Validation loss = 3.0535  \n",
      "\n",
      "Fold: 1  Epoch: 573  Training loss = 3.0744  Validation loss = 3.0534  \n",
      "\n",
      "Fold: 1  Epoch: 574  Training loss = 3.0744  Validation loss = 3.0533  \n",
      "\n",
      "Fold: 1  Epoch: 575  Training loss = 3.0743  Validation loss = 3.0531  \n",
      "\n",
      "Fold: 1  Epoch: 576  Training loss = 3.0742  Validation loss = 3.0530  \n",
      "\n",
      "Fold: 1  Epoch: 577  Training loss = 3.0742  Validation loss = 3.0528  \n",
      "\n",
      "Fold: 1  Epoch: 578  Training loss = 3.0741  Validation loss = 3.0527  \n",
      "\n",
      "Fold: 1  Epoch: 579  Training loss = 3.0740  Validation loss = 3.0526  \n",
      "\n",
      "Fold: 1  Epoch: 580  Training loss = 3.0740  Validation loss = 3.0525  \n",
      "\n",
      "Fold: 1  Epoch: 581  Training loss = 3.0739  Validation loss = 3.0524  \n",
      "\n",
      "Fold: 1  Epoch: 582  Training loss = 3.0739  Validation loss = 3.0523  \n",
      "\n",
      "Fold: 1  Epoch: 583  Training loss = 3.0738  Validation loss = 3.0521  \n",
      "\n",
      "Fold: 1  Epoch: 584  Training loss = 3.0738  Validation loss = 3.0520  \n",
      "\n",
      "Fold: 1  Epoch: 585  Training loss = 3.0737  Validation loss = 3.0518  \n",
      "\n",
      "Fold: 1  Epoch: 586  Training loss = 3.0736  Validation loss = 3.0517  \n",
      "\n",
      "Fold: 1  Epoch: 587  Training loss = 3.0736  Validation loss = 3.0516  \n",
      "\n",
      "Fold: 1  Epoch: 588  Training loss = 3.0736  Validation loss = 3.0515  \n",
      "\n",
      "Fold: 1  Epoch: 589  Training loss = 3.0735  Validation loss = 3.0514  \n",
      "\n",
      "Fold: 1  Epoch: 590  Training loss = 3.0734  Validation loss = 3.0513  \n",
      "\n",
      "Fold: 1  Epoch: 591  Training loss = 3.0734  Validation loss = 3.0512  \n",
      "\n",
      "Fold: 1  Epoch: 592  Training loss = 3.0733  Validation loss = 3.0511  \n",
      "\n",
      "Fold: 1  Epoch: 593  Training loss = 3.0733  Validation loss = 3.0509  \n",
      "\n",
      "Fold: 1  Epoch: 594  Training loss = 3.0732  Validation loss = 3.0508  \n",
      "\n",
      "Fold: 1  Epoch: 595  Training loss = 3.0732  Validation loss = 3.0507  \n",
      "\n",
      "Fold: 1  Epoch: 596  Training loss = 3.0731  Validation loss = 3.0506  \n",
      "\n",
      "Fold: 1  Epoch: 597  Training loss = 3.0731  Validation loss = 3.0504  \n",
      "\n",
      "Fold: 1  Epoch: 598  Training loss = 3.0730  Validation loss = 3.0503  \n",
      "\n",
      "Fold: 1  Epoch: 599  Training loss = 3.0729  Validation loss = 3.0502  \n",
      "\n",
      "Fold: 1  Epoch: 600  Training loss = 3.0729  Validation loss = 3.0500  \n",
      "\n",
      "Fold: 1  Epoch: 601  Training loss = 3.0728  Validation loss = 3.0498  \n",
      "\n",
      "Fold: 1  Epoch: 602  Training loss = 3.0727  Validation loss = 3.0497  \n",
      "\n",
      "Fold: 1  Epoch: 603  Training loss = 3.0726  Validation loss = 3.0496  \n",
      "\n",
      "Fold: 1  Epoch: 604  Training loss = 3.0726  Validation loss = 3.0495  \n",
      "\n",
      "Fold: 1  Epoch: 605  Training loss = 3.0726  Validation loss = 3.0494  \n",
      "\n",
      "Fold: 1  Epoch: 606  Training loss = 3.0725  Validation loss = 3.0493  \n",
      "\n",
      "Fold: 1  Epoch: 607  Training loss = 3.0725  Validation loss = 3.0492  \n",
      "\n",
      "Fold: 1  Epoch: 608  Training loss = 3.0724  Validation loss = 3.0490  \n",
      "\n",
      "Fold: 1  Epoch: 609  Training loss = 3.0724  Validation loss = 3.0490  \n",
      "\n",
      "Fold: 1  Epoch: 610  Training loss = 3.0723  Validation loss = 3.0488  \n",
      "\n",
      "Fold: 1  Epoch: 611  Training loss = 3.0723  Validation loss = 3.0487  \n",
      "\n",
      "Fold: 1  Epoch: 612  Training loss = 3.0722  Validation loss = 3.0486  \n",
      "\n",
      "Fold: 1  Epoch: 613  Training loss = 3.0721  Validation loss = 3.0485  \n",
      "\n",
      "Fold: 1  Epoch: 614  Training loss = 3.0721  Validation loss = 3.0484  \n",
      "\n",
      "Fold: 1  Epoch: 615  Training loss = 3.0720  Validation loss = 3.0482  \n",
      "\n",
      "Fold: 1  Epoch: 616  Training loss = 3.0720  Validation loss = 3.0481  \n",
      "\n",
      "Fold: 1  Epoch: 617  Training loss = 3.0719  Validation loss = 3.0480  \n",
      "\n",
      "Fold: 1  Epoch: 618  Training loss = 3.0719  Validation loss = 3.0479  \n",
      "\n",
      "Fold: 1  Epoch: 619  Training loss = 3.0718  Validation loss = 3.0478  \n",
      "\n",
      "Fold: 1  Epoch: 620  Training loss = 3.0718  Validation loss = 3.0477  \n",
      "\n",
      "Fold: 1  Epoch: 621  Training loss = 3.0717  Validation loss = 3.0475  \n",
      "\n",
      "Fold: 1  Epoch: 622  Training loss = 3.0716  Validation loss = 3.0474  \n",
      "\n",
      "Fold: 1  Epoch: 623  Training loss = 3.0716  Validation loss = 3.0473  \n",
      "\n",
      "Fold: 1  Epoch: 624  Training loss = 3.0715  Validation loss = 3.0471  \n",
      "\n",
      "Fold: 1  Epoch: 625  Training loss = 3.0715  Validation loss = 3.0470  \n",
      "\n",
      "Fold: 1  Epoch: 626  Training loss = 3.0714  Validation loss = 3.0469  \n",
      "\n",
      "Fold: 1  Epoch: 627  Training loss = 3.0714  Validation loss = 3.0468  \n",
      "\n",
      "Fold: 1  Epoch: 628  Training loss = 3.0713  Validation loss = 3.0467  \n",
      "\n",
      "Fold: 1  Epoch: 629  Training loss = 3.0713  Validation loss = 3.0466  \n",
      "\n",
      "Fold: 1  Epoch: 630  Training loss = 3.0712  Validation loss = 3.0464  \n",
      "\n",
      "Fold: 1  Epoch: 631  Training loss = 3.0711  Validation loss = 3.0463  \n",
      "\n",
      "Fold: 1  Epoch: 632  Training loss = 3.0711  Validation loss = 3.0462  \n",
      "\n",
      "Fold: 1  Epoch: 633  Training loss = 3.0710  Validation loss = 3.0461  \n",
      "\n",
      "Fold: 1  Epoch: 634  Training loss = 3.0710  Validation loss = 3.0460  \n",
      "\n",
      "Fold: 1  Epoch: 635  Training loss = 3.0709  Validation loss = 3.0458  \n",
      "\n",
      "Fold: 1  Epoch: 636  Training loss = 3.0709  Validation loss = 3.0457  \n",
      "\n",
      "Fold: 1  Epoch: 637  Training loss = 3.0708  Validation loss = 3.0456  \n",
      "\n",
      "Fold: 1  Epoch: 638  Training loss = 3.0708  Validation loss = 3.0455  \n",
      "\n",
      "Fold: 1  Epoch: 639  Training loss = 3.0707  Validation loss = 3.0454  \n",
      "\n",
      "Fold: 1  Epoch: 640  Training loss = 3.0706  Validation loss = 3.0452  \n",
      "\n",
      "Fold: 1  Epoch: 641  Training loss = 3.0706  Validation loss = 3.0451  \n",
      "\n",
      "Fold: 1  Epoch: 642  Training loss = 3.0705  Validation loss = 3.0449  \n",
      "\n",
      "Fold: 1  Epoch: 643  Training loss = 3.0704  Validation loss = 3.0448  \n",
      "\n",
      "Fold: 1  Epoch: 644  Training loss = 3.0704  Validation loss = 3.0446  \n",
      "\n",
      "Fold: 1  Epoch: 645  Training loss = 3.0703  Validation loss = 3.0445  \n",
      "\n",
      "Fold: 1  Epoch: 646  Training loss = 3.0702  Validation loss = 3.0444  \n",
      "\n",
      "Fold: 1  Epoch: 647  Training loss = 3.0702  Validation loss = 3.0442  \n",
      "\n",
      "Fold: 1  Epoch: 648  Training loss = 3.0701  Validation loss = 3.0441  \n",
      "\n",
      "Fold: 1  Epoch: 649  Training loss = 3.0701  Validation loss = 3.0439  \n",
      "\n",
      "Fold: 1  Epoch: 650  Training loss = 3.0700  Validation loss = 3.0438  \n",
      "\n",
      "Fold: 1  Epoch: 651  Training loss = 3.0699  Validation loss = 3.0437  \n",
      "\n",
      "Fold: 1  Epoch: 652  Training loss = 3.0699  Validation loss = 3.0435  \n",
      "\n",
      "Fold: 1  Epoch: 653  Training loss = 3.0698  Validation loss = 3.0434  \n",
      "\n",
      "Fold: 1  Epoch: 654  Training loss = 3.0698  Validation loss = 3.0433  \n",
      "\n",
      "Fold: 1  Epoch: 655  Training loss = 3.0697  Validation loss = 3.0431  \n",
      "\n",
      "Fold: 1  Epoch: 656  Training loss = 3.0697  Validation loss = 3.0431  \n",
      "\n",
      "Fold: 1  Epoch: 657  Training loss = 3.0696  Validation loss = 3.0430  \n",
      "\n",
      "Fold: 1  Epoch: 658  Training loss = 3.0696  Validation loss = 3.0429  \n",
      "\n",
      "Fold: 1  Epoch: 659  Training loss = 3.0695  Validation loss = 3.0428  \n",
      "\n",
      "Fold: 1  Epoch: 660  Training loss = 3.0695  Validation loss = 3.0426  \n",
      "\n",
      "Fold: 1  Epoch: 661  Training loss = 3.0694  Validation loss = 3.0425  \n",
      "\n",
      "Fold: 1  Epoch: 662  Training loss = 3.0693  Validation loss = 3.0424  \n",
      "\n",
      "Fold: 1  Epoch: 663  Training loss = 3.0693  Validation loss = 3.0423  \n",
      "\n",
      "Fold: 1  Epoch: 664  Training loss = 3.0692  Validation loss = 3.0422  \n",
      "\n",
      "Fold: 1  Epoch: 665  Training loss = 3.0692  Validation loss = 3.0420  \n",
      "\n",
      "Fold: 1  Epoch: 666  Training loss = 3.0691  Validation loss = 3.0419  \n",
      "\n",
      "Fold: 1  Epoch: 667  Training loss = 3.0691  Validation loss = 3.0418  \n",
      "\n",
      "Fold: 1  Epoch: 668  Training loss = 3.0690  Validation loss = 3.0416  \n",
      "\n",
      "Fold: 1  Epoch: 669  Training loss = 3.0690  Validation loss = 3.0415  \n",
      "\n",
      "Fold: 1  Epoch: 670  Training loss = 3.0689  Validation loss = 3.0414  \n",
      "\n",
      "Fold: 1  Epoch: 671  Training loss = 3.0688  Validation loss = 3.0413  \n",
      "\n",
      "Fold: 1  Epoch: 672  Training loss = 3.0688  Validation loss = 3.0412  \n",
      "\n",
      "Fold: 1  Epoch: 673  Training loss = 3.0687  Validation loss = 3.0411  \n",
      "\n",
      "Fold: 1  Epoch: 674  Training loss = 3.0687  Validation loss = 3.0409  \n",
      "\n",
      "Fold: 1  Epoch: 675  Training loss = 3.0686  Validation loss = 3.0408  \n",
      "\n",
      "Fold: 1  Epoch: 676  Training loss = 3.0686  Validation loss = 3.0407  \n",
      "\n",
      "Fold: 1  Epoch: 677  Training loss = 3.0685  Validation loss = 3.0406  \n",
      "\n",
      "Fold: 1  Epoch: 678  Training loss = 3.0685  Validation loss = 3.0404  \n",
      "\n",
      "Fold: 1  Epoch: 679  Training loss = 3.0684  Validation loss = 3.0404  \n",
      "\n",
      "Fold: 1  Epoch: 680  Training loss = 3.0683  Validation loss = 3.0402  \n",
      "\n",
      "Fold: 1  Epoch: 681  Training loss = 3.0683  Validation loss = 3.0401  \n",
      "\n",
      "Fold: 1  Epoch: 682  Training loss = 3.0682  Validation loss = 3.0400  \n",
      "\n",
      "Fold: 1  Epoch: 683  Training loss = 3.0682  Validation loss = 3.0399  \n",
      "\n",
      "Fold: 1  Epoch: 684  Training loss = 3.0682  Validation loss = 3.0398  \n",
      "\n",
      "Fold: 1  Epoch: 685  Training loss = 3.0681  Validation loss = 3.0397  \n",
      "\n",
      "Fold: 1  Epoch: 686  Training loss = 3.0681  Validation loss = 3.0396  \n",
      "\n",
      "Fold: 1  Epoch: 687  Training loss = 3.0680  Validation loss = 3.0395  \n",
      "\n",
      "Fold: 1  Epoch: 688  Training loss = 3.0680  Validation loss = 3.0394  \n",
      "\n",
      "Fold: 1  Epoch: 689  Training loss = 3.0679  Validation loss = 3.0393  \n",
      "\n",
      "Fold: 1  Epoch: 690  Training loss = 3.0679  Validation loss = 3.0392  \n",
      "\n",
      "Fold: 1  Epoch: 691  Training loss = 3.0678  Validation loss = 3.0391  \n",
      "\n",
      "Fold: 1  Epoch: 692  Training loss = 3.0678  Validation loss = 3.0390  \n",
      "\n",
      "Fold: 1  Epoch: 693  Training loss = 3.0677  Validation loss = 3.0388  \n",
      "\n",
      "Fold: 1  Epoch: 694  Training loss = 3.0677  Validation loss = 3.0387  \n",
      "\n",
      "Fold: 1  Epoch: 695  Training loss = 3.0676  Validation loss = 3.0386  \n",
      "\n",
      "Fold: 1  Epoch: 696  Training loss = 3.0675  Validation loss = 3.0384  \n",
      "\n",
      "Fold: 1  Epoch: 697  Training loss = 3.0675  Validation loss = 3.0383  \n",
      "\n",
      "Fold: 1  Epoch: 698  Training loss = 3.0674  Validation loss = 3.0381  \n",
      "\n",
      "Fold: 1  Epoch: 699  Training loss = 3.0673  Validation loss = 3.0380  \n",
      "\n",
      "Fold: 1  Epoch: 700  Training loss = 3.0673  Validation loss = 3.0379  \n",
      "\n",
      "Fold: 1  Epoch: 701  Training loss = 3.0672  Validation loss = 3.0377  \n",
      "\n",
      "Fold: 1  Epoch: 702  Training loss = 3.0672  Validation loss = 3.0376  \n",
      "\n",
      "Fold: 1  Epoch: 703  Training loss = 3.0671  Validation loss = 3.0375  \n",
      "\n",
      "Fold: 1  Epoch: 704  Training loss = 3.0671  Validation loss = 3.0374  \n",
      "\n",
      "Fold: 1  Epoch: 705  Training loss = 3.0670  Validation loss = 3.0373  \n",
      "\n",
      "Fold: 1  Epoch: 706  Training loss = 3.0670  Validation loss = 3.0372  \n",
      "\n",
      "Fold: 1  Epoch: 707  Training loss = 3.0669  Validation loss = 3.0371  \n",
      "\n",
      "Fold: 1  Epoch: 708  Training loss = 3.0669  Validation loss = 3.0370  \n",
      "\n",
      "Fold: 1  Epoch: 709  Training loss = 3.0668  Validation loss = 3.0368  \n",
      "\n",
      "Fold: 1  Epoch: 710  Training loss = 3.0668  Validation loss = 3.0367  \n",
      "\n",
      "Fold: 1  Epoch: 711  Training loss = 3.0667  Validation loss = 3.0366  \n",
      "\n",
      "Fold: 1  Epoch: 712  Training loss = 3.0666  Validation loss = 3.0365  \n",
      "\n",
      "Fold: 1  Epoch: 713  Training loss = 3.0666  Validation loss = 3.0363  \n",
      "\n",
      "Fold: 1  Epoch: 714  Training loss = 3.0665  Validation loss = 3.0362  \n",
      "\n",
      "Fold: 1  Epoch: 715  Training loss = 3.0665  Validation loss = 3.0361  \n",
      "\n",
      "Fold: 1  Epoch: 716  Training loss = 3.0664  Validation loss = 3.0360  \n",
      "\n",
      "Fold: 1  Epoch: 717  Training loss = 3.0663  Validation loss = 3.0358  \n",
      "\n",
      "Fold: 1  Epoch: 718  Training loss = 3.0663  Validation loss = 3.0357  \n",
      "\n",
      "Fold: 1  Epoch: 719  Training loss = 3.0663  Validation loss = 3.0356  \n",
      "\n",
      "Fold: 1  Epoch: 720  Training loss = 3.0662  Validation loss = 3.0355  \n",
      "\n",
      "Fold: 1  Epoch: 721  Training loss = 3.0661  Validation loss = 3.0354  \n",
      "\n",
      "Fold: 1  Epoch: 722  Training loss = 3.0661  Validation loss = 3.0353  \n",
      "\n",
      "Fold: 1  Epoch: 723  Training loss = 3.0660  Validation loss = 3.0351  \n",
      "\n",
      "Fold: 1  Epoch: 724  Training loss = 3.0659  Validation loss = 3.0350  \n",
      "\n",
      "Fold: 1  Epoch: 725  Training loss = 3.0659  Validation loss = 3.0349  \n",
      "\n",
      "Fold: 1  Epoch: 726  Training loss = 3.0658  Validation loss = 3.0347  \n",
      "\n",
      "Fold: 1  Epoch: 727  Training loss = 3.0658  Validation loss = 3.0346  \n",
      "\n",
      "Fold: 1  Epoch: 728  Training loss = 3.0657  Validation loss = 3.0345  \n",
      "\n",
      "Fold: 1  Epoch: 729  Training loss = 3.0657  Validation loss = 3.0343  \n",
      "\n",
      "Fold: 1  Epoch: 730  Training loss = 3.0656  Validation loss = 3.0342  \n",
      "\n",
      "Fold: 1  Epoch: 731  Training loss = 3.0655  Validation loss = 3.0341  \n",
      "\n",
      "Fold: 1  Epoch: 732  Training loss = 3.0655  Validation loss = 3.0340  \n",
      "\n",
      "Fold: 1  Epoch: 733  Training loss = 3.0654  Validation loss = 3.0339  \n",
      "\n",
      "Fold: 1  Epoch: 734  Training loss = 3.0654  Validation loss = 3.0337  \n",
      "\n",
      "Fold: 1  Epoch: 735  Training loss = 3.0653  Validation loss = 3.0336  \n",
      "\n",
      "Fold: 1  Epoch: 736  Training loss = 3.0652  Validation loss = 3.0334  \n",
      "\n",
      "Fold: 1  Epoch: 737  Training loss = 3.0652  Validation loss = 3.0333  \n",
      "\n",
      "Fold: 1  Epoch: 738  Training loss = 3.0651  Validation loss = 3.0332  \n",
      "\n",
      "Fold: 1  Epoch: 739  Training loss = 3.0651  Validation loss = 3.0331  \n",
      "\n",
      "Fold: 1  Epoch: 740  Training loss = 3.0650  Validation loss = 3.0330  \n",
      "\n",
      "Fold: 1  Epoch: 741  Training loss = 3.0650  Validation loss = 3.0328  \n",
      "\n",
      "Fold: 1  Epoch: 742  Training loss = 3.0649  Validation loss = 3.0327  \n",
      "\n",
      "Fold: 1  Epoch: 743  Training loss = 3.0649  Validation loss = 3.0326  \n",
      "\n",
      "Fold: 1  Epoch: 744  Training loss = 3.0648  Validation loss = 3.0325  \n",
      "\n",
      "Fold: 1  Epoch: 745  Training loss = 3.0648  Validation loss = 3.0324  \n",
      "\n",
      "Fold: 1  Epoch: 746  Training loss = 3.0647  Validation loss = 3.0323  \n",
      "\n",
      "Fold: 1  Epoch: 747  Training loss = 3.0647  Validation loss = 3.0322  \n",
      "\n",
      "Fold: 1  Epoch: 748  Training loss = 3.0646  Validation loss = 3.0321  \n",
      "\n",
      "Fold: 1  Epoch: 749  Training loss = 3.0646  Validation loss = 3.0320  \n",
      "\n",
      "Fold: 1  Epoch: 750  Training loss = 3.0645  Validation loss = 3.0318  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 750  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.9997  Validation loss = 3.2092  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.9996  Validation loss = 3.2091  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.9995  Validation loss = 3.2090  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.9995  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.9994  Validation loss = 3.2088  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.9994  Validation loss = 3.2087  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.9993  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.9992  Validation loss = 3.2085  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.9992  Validation loss = 3.2084  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.9991  Validation loss = 3.2083  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.9991  Validation loss = 3.2083  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.9990  Validation loss = 3.2082  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.9989  Validation loss = 3.2081  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.9989  Validation loss = 3.2080  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.9988  Validation loss = 3.2079  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.9988  Validation loss = 3.2079  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.9987  Validation loss = 3.2078  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.9987  Validation loss = 3.2076  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.9986  Validation loss = 3.2075  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.9985  Validation loss = 3.2074  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.9985  Validation loss = 3.2073  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.9984  Validation loss = 3.2073  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.9984  Validation loss = 3.2072  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.9983  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.9982  Validation loss = 3.2069  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.9981  Validation loss = 3.2068  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.9981  Validation loss = 3.2067  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.9980  Validation loss = 3.2066  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.9979  Validation loss = 3.2065  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.9979  Validation loss = 3.2064  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.9978  Validation loss = 3.2063  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.9977  Validation loss = 3.2062  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.9976  Validation loss = 3.2061  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.9976  Validation loss = 3.2060  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.9975  Validation loss = 3.2059  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.9975  Validation loss = 3.2059  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.9974  Validation loss = 3.2057  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.9974  Validation loss = 3.2056  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.9973  Validation loss = 3.2055  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.9973  Validation loss = 3.2055  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.9972  Validation loss = 3.2053  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.9971  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.9971  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.9970  Validation loss = 3.2051  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.9970  Validation loss = 3.2050  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.9969  Validation loss = 3.2049  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.9968  Validation loss = 3.2048  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.9967  Validation loss = 3.2047  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.9967  Validation loss = 3.2046  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.9966  Validation loss = 3.2045  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.9966  Validation loss = 3.2044  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.9965  Validation loss = 3.2043  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.9964  Validation loss = 3.2042  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.9964  Validation loss = 3.2041  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.9963  Validation loss = 3.2040  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.9963  Validation loss = 3.2039  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.9962  Validation loss = 3.2038  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.9962  Validation loss = 3.2037  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.9961  Validation loss = 3.2036  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.9960  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.9960  Validation loss = 3.2034  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.9959  Validation loss = 3.2034  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.9958  Validation loss = 3.2032  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.9958  Validation loss = 3.2032  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.9957  Validation loss = 3.2030  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.9956  Validation loss = 3.2029  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.9956  Validation loss = 3.2028  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.9955  Validation loss = 3.2028  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.9955  Validation loss = 3.2027  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.9954  Validation loss = 3.2026  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.9954  Validation loss = 3.2025  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.9953  Validation loss = 3.2024  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.9952  Validation loss = 3.2023  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.9952  Validation loss = 3.2022  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.9951  Validation loss = 3.2021  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.9950  Validation loss = 3.2020  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.9950  Validation loss = 3.2019  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.9949  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.9949  Validation loss = 3.2017  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.9948  Validation loss = 3.2016  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.9948  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.9947  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.9946  Validation loss = 3.2014  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.9946  Validation loss = 3.2013  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.9945  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.9945  Validation loss = 3.2011  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.9944  Validation loss = 3.2010  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.9944  Validation loss = 3.2009  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.9943  Validation loss = 3.2008  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.9942  Validation loss = 3.2007  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.9942  Validation loss = 3.2006  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.9941  Validation loss = 3.2005  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.9940  Validation loss = 3.2004  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.9940  Validation loss = 3.2003  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.9939  Validation loss = 3.2002  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.9938  Validation loss = 3.2001  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.9938  Validation loss = 3.2000  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.9937  Validation loss = 3.1999  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.9937  Validation loss = 3.1998  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.9936  Validation loss = 3.1997  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.9935  Validation loss = 3.1996  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.9934  Validation loss = 3.1995  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.9933  Validation loss = 3.1994  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.9933  Validation loss = 3.1993  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.9932  Validation loss = 3.1992  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.9932  Validation loss = 3.1991  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.9931  Validation loss = 3.1990  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.9931  Validation loss = 3.1989  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.9930  Validation loss = 3.1988  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.9929  Validation loss = 3.1987  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.9929  Validation loss = 3.1986  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.9928  Validation loss = 3.1986  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.9928  Validation loss = 3.1985  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.9927  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.9927  Validation loss = 3.1983  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.9926  Validation loss = 3.1982  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.9926  Validation loss = 3.1981  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.9925  Validation loss = 3.1980  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.9924  Validation loss = 3.1979  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.9924  Validation loss = 3.1979  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.9923  Validation loss = 3.1978  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.9923  Validation loss = 3.1977  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.9922  Validation loss = 3.1976  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.9921  Validation loss = 3.1974  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.9920  Validation loss = 3.1973  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.9920  Validation loss = 3.1972  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.9919  Validation loss = 3.1971  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.9918  Validation loss = 3.1970  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.9918  Validation loss = 3.1969  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.9917  Validation loss = 3.1968  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.9917  Validation loss = 3.1968  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.9916  Validation loss = 3.1967  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.9915  Validation loss = 3.1966  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.9915  Validation loss = 3.1965  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.9915  Validation loss = 3.1965  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.9914  Validation loss = 3.1964  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.9914  Validation loss = 3.1963  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.9913  Validation loss = 3.1961  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.9912  Validation loss = 3.1960  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.9911  Validation loss = 3.1960  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.9911  Validation loss = 3.1959  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.9910  Validation loss = 3.1958  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.9910  Validation loss = 3.1957  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.9909  Validation loss = 3.1956  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.9908  Validation loss = 3.1955  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.9908  Validation loss = 3.1954  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.9907  Validation loss = 3.1953  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.9907  Validation loss = 3.1952  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.9906  Validation loss = 3.1951  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.9906  Validation loss = 3.1950  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.9905  Validation loss = 3.1949  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.9904  Validation loss = 3.1949  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.9904  Validation loss = 3.1948  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.9903  Validation loss = 3.1947  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.9903  Validation loss = 3.1946  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.9902  Validation loss = 3.1945  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.9901  Validation loss = 3.1944  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.9901  Validation loss = 3.1943  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.9900  Validation loss = 3.1942  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.9900  Validation loss = 3.1941  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.9899  Validation loss = 3.1940  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.9898  Validation loss = 3.1939  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.9898  Validation loss = 3.1939  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.9897  Validation loss = 3.1937  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.9897  Validation loss = 3.1937  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.9896  Validation loss = 3.1935  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.9895  Validation loss = 3.1934  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.9894  Validation loss = 3.1933  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.9894  Validation loss = 3.1933  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.9893  Validation loss = 3.1931  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.9893  Validation loss = 3.1931  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.9892  Validation loss = 3.1929  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.9891  Validation loss = 3.1928  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.9891  Validation loss = 3.1927  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.9890  Validation loss = 3.1926  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.9889  Validation loss = 3.1925  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.9889  Validation loss = 3.1924  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.9889  Validation loss = 3.1924  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.9888  Validation loss = 3.1923  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.9887  Validation loss = 3.1922  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.9886  Validation loss = 3.1921  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.9886  Validation loss = 3.1920  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.9885  Validation loss = 3.1919  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.9885  Validation loss = 3.1918  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.9884  Validation loss = 3.1917  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.9884  Validation loss = 3.1916  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.9883  Validation loss = 3.1915  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.9883  Validation loss = 3.1915  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.9882  Validation loss = 3.1914  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.9881  Validation loss = 3.1913  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.9880  Validation loss = 3.1911  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.9880  Validation loss = 3.1910  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.9879  Validation loss = 3.1909  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.9878  Validation loss = 3.1908  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.9878  Validation loss = 3.1907  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.9877  Validation loss = 3.1907  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.9877  Validation loss = 3.1906  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.9876  Validation loss = 3.1905  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.9876  Validation loss = 3.1904  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.9875  Validation loss = 3.1903  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.9875  Validation loss = 3.1902  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.9874  Validation loss = 3.1901  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.9873  Validation loss = 3.1900  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.9872  Validation loss = 3.1899  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.9872  Validation loss = 3.1898  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.9871  Validation loss = 3.1897  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.9871  Validation loss = 3.1896  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.9870  Validation loss = 3.1895  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.9870  Validation loss = 3.1895  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.9869  Validation loss = 3.1894  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.9869  Validation loss = 3.1893  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.9868  Validation loss = 3.1892  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.9868  Validation loss = 3.1891  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.9867  Validation loss = 3.1890  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.9867  Validation loss = 3.1890  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.9866  Validation loss = 3.1889  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.9865  Validation loss = 3.1888  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.9865  Validation loss = 3.1887  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.9864  Validation loss = 3.1886  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.9864  Validation loss = 3.1885  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.9863  Validation loss = 3.1884  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.9862  Validation loss = 3.1883  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.9862  Validation loss = 3.1882  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.9861  Validation loss = 3.1881  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.9861  Validation loss = 3.1880  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.9860  Validation loss = 3.1879  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.9859  Validation loss = 3.1878  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.9858  Validation loss = 3.1877  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.9858  Validation loss = 3.1876  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.9857  Validation loss = 3.1874  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.9856  Validation loss = 3.1873  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.9855  Validation loss = 3.1872  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.9855  Validation loss = 3.1871  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.9854  Validation loss = 3.1870  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.9854  Validation loss = 3.1869  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.9853  Validation loss = 3.1868  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.9852  Validation loss = 3.1867  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.9852  Validation loss = 3.1866  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.9851  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.9850  Validation loss = 3.1864  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.9850  Validation loss = 3.1864  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.9849  Validation loss = 3.1863  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.9849  Validation loss = 3.1862  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.9848  Validation loss = 3.1861  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.9847  Validation loss = 3.1860  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.9847  Validation loss = 3.1859  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.9846  Validation loss = 3.1858  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.9845  Validation loss = 3.1857  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.9845  Validation loss = 3.1856  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.9844  Validation loss = 3.1855  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.9844  Validation loss = 3.1854  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.9843  Validation loss = 3.1853  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.9842  Validation loss = 3.1852  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.9842  Validation loss = 3.1851  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.9841  Validation loss = 3.1851  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.9841  Validation loss = 3.1850  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.9840  Validation loss = 3.1849  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.9840  Validation loss = 3.1848  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.9839  Validation loss = 3.1847  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.9839  Validation loss = 3.1846  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.9838  Validation loss = 3.1845  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.9837  Validation loss = 3.1844  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.9837  Validation loss = 3.1843  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.9836  Validation loss = 3.1842  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.9836  Validation loss = 3.1841  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.9835  Validation loss = 3.1840  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.9835  Validation loss = 3.1839  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.9834  Validation loss = 3.1838  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.9833  Validation loss = 3.1837  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.9832  Validation loss = 3.1836  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.9832  Validation loss = 3.1835  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.9831  Validation loss = 3.1834  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.9831  Validation loss = 3.1833  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.9830  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.9830  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.9829  Validation loss = 3.1831  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.9829  Validation loss = 3.1830  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.9828  Validation loss = 3.1829  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.9827  Validation loss = 3.1828  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.9827  Validation loss = 3.1827  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.9826  Validation loss = 3.1826  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.9826  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.9825  Validation loss = 3.1824  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.9824  Validation loss = 3.1823  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.9824  Validation loss = 3.1822  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.9823  Validation loss = 3.1821  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.9822  Validation loss = 3.1820  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.9822  Validation loss = 3.1819  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.9821  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.9820  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.9820  Validation loss = 3.1816  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.9819  Validation loss = 3.1815  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.9818  Validation loss = 3.1814  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.9818  Validation loss = 3.1813  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.9817  Validation loss = 3.1812  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.9816  Validation loss = 3.1811  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.9816  Validation loss = 3.1810  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.9815  Validation loss = 3.1809  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.9815  Validation loss = 3.1808  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.9814  Validation loss = 3.1807  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.9814  Validation loss = 3.1806  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.9813  Validation loss = 3.1805  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.9813  Validation loss = 3.1804  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.9812  Validation loss = 3.1804  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.9811  Validation loss = 3.1803  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.9811  Validation loss = 3.1802  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.9810  Validation loss = 3.1801  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.9810  Validation loss = 3.1800  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.9809  Validation loss = 3.1799  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.9808  Validation loss = 3.1798  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.9808  Validation loss = 3.1797  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.9807  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.9807  Validation loss = 3.1795  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.9806  Validation loss = 3.1794  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.9805  Validation loss = 3.1793  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.9805  Validation loss = 3.1792  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.9804  Validation loss = 3.1792  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.9804  Validation loss = 3.1790  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.9803  Validation loss = 3.1790  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.9803  Validation loss = 3.1789  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.9802  Validation loss = 3.1788  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.9801  Validation loss = 3.1787  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.9801  Validation loss = 3.1786  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.9800  Validation loss = 3.1785  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.9800  Validation loss = 3.1784  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.9799  Validation loss = 3.1783  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.9798  Validation loss = 3.1782  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.9798  Validation loss = 3.1781  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.9797  Validation loss = 3.1780  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.9797  Validation loss = 3.1779  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.9796  Validation loss = 3.1778  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.9795  Validation loss = 3.1777  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.9795  Validation loss = 3.1776  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.9794  Validation loss = 3.1775  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.9793  Validation loss = 3.1774  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.9793  Validation loss = 3.1773  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.9792  Validation loss = 3.1772  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.9792  Validation loss = 3.1771  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.9791  Validation loss = 3.1770  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.9790  Validation loss = 3.1769  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.9790  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.9789  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.9789  Validation loss = 3.1767  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.9788  Validation loss = 3.1766  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.9788  Validation loss = 3.1765  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.9787  Validation loss = 3.1765  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.9787  Validation loss = 3.1764  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.9787  Validation loss = 3.1763  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.9786  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.9786  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.9785  Validation loss = 3.1761  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.9785  Validation loss = 3.1760  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.9784  Validation loss = 3.1760  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.9784  Validation loss = 3.1759  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.9783  Validation loss = 3.1758  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.9782  Validation loss = 3.1757  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.9782  Validation loss = 3.1756  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.9782  Validation loss = 3.1755  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.9781  Validation loss = 3.1754  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.9780  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.9780  Validation loss = 3.1752  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.9779  Validation loss = 3.1751  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.9779  Validation loss = 3.1751  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.9778  Validation loss = 3.1749  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.9777  Validation loss = 3.1748  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.9777  Validation loss = 3.1747  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.9776  Validation loss = 3.1746  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.9776  Validation loss = 3.1746  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.9775  Validation loss = 3.1745  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.9774  Validation loss = 3.1744  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.9774  Validation loss = 3.1743  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.9773  Validation loss = 3.1742  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.9773  Validation loss = 3.1741  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.9772  Validation loss = 3.1740  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.9772  Validation loss = 3.1739  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.9771  Validation loss = 3.1738  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.9770  Validation loss = 3.1737  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.9770  Validation loss = 3.1736  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.9769  Validation loss = 3.1736  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.9769  Validation loss = 3.1735  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.9768  Validation loss = 3.1734  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.9767  Validation loss = 3.1733  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.9767  Validation loss = 3.1732  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.9766  Validation loss = 3.1731  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.9765  Validation loss = 3.1729  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.9765  Validation loss = 3.1728  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.9764  Validation loss = 3.1727  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.9763  Validation loss = 3.1727  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.9763  Validation loss = 3.1726  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.9763  Validation loss = 3.1725  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.9762  Validation loss = 3.1724  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.9761  Validation loss = 3.1723  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.9761  Validation loss = 3.1722  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.9760  Validation loss = 3.1721  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.9760  Validation loss = 3.1721  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.9759  Validation loss = 3.1720  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.9759  Validation loss = 3.1719  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.9758  Validation loss = 3.1718  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.9757  Validation loss = 3.1717  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.9757  Validation loss = 3.1716  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.9756  Validation loss = 3.1715  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.9756  Validation loss = 3.1714  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.9755  Validation loss = 3.1713  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.9755  Validation loss = 3.1713  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.9754  Validation loss = 3.1712  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.9754  Validation loss = 3.1711  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.9753  Validation loss = 3.1710  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.9753  Validation loss = 3.1709  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.9752  Validation loss = 3.1708  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.9751  Validation loss = 3.1707  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.9751  Validation loss = 3.1706  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.9750  Validation loss = 3.1705  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.9749  Validation loss = 3.1704  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.9749  Validation loss = 3.1703  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.9748  Validation loss = 3.1702  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.9747  Validation loss = 3.1701  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.9746  Validation loss = 3.1699  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.9746  Validation loss = 3.1698  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.9746  Validation loss = 3.1698  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.9745  Validation loss = 3.1697  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.9745  Validation loss = 3.1696  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.9744  Validation loss = 3.1695  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.9744  Validation loss = 3.1694  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.9743  Validation loss = 3.1694  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.9743  Validation loss = 3.1693  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.9742  Validation loss = 3.1692  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.9742  Validation loss = 3.1691  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.9741  Validation loss = 3.1690  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.9741  Validation loss = 3.1689  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.9740  Validation loss = 3.1689  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.9740  Validation loss = 3.1688  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.9739  Validation loss = 3.1687  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.9738  Validation loss = 3.1686  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.9738  Validation loss = 3.1685  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.9737  Validation loss = 3.1684  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.9737  Validation loss = 3.1683  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.9736  Validation loss = 3.1682  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.9736  Validation loss = 3.1681  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.9735  Validation loss = 3.1680  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.9734  Validation loss = 3.1679  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.9734  Validation loss = 3.1678  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.9733  Validation loss = 3.1677  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.9733  Validation loss = 3.1677  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.9732  Validation loss = 3.1676  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.9732  Validation loss = 3.1675  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.9731  Validation loss = 3.1674  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.9731  Validation loss = 3.1673  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.9730  Validation loss = 3.1672  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.9730  Validation loss = 3.1671  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.9729  Validation loss = 3.1670  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.9728  Validation loss = 3.1670  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.9728  Validation loss = 3.1669  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.9727  Validation loss = 3.1668  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.9727  Validation loss = 3.1667  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.9726  Validation loss = 3.1666  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.9726  Validation loss = 3.1665  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.9725  Validation loss = 3.1664  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.9724  Validation loss = 3.1663  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.9724  Validation loss = 3.1663  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.9724  Validation loss = 3.1662  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.9723  Validation loss = 3.1661  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.9722  Validation loss = 3.1660  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.9722  Validation loss = 3.1659  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.9721  Validation loss = 3.1658  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.9721  Validation loss = 3.1658  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.9720  Validation loss = 3.1656  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.9719  Validation loss = 3.1655  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.9719  Validation loss = 3.1655  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.9718  Validation loss = 3.1654  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.9718  Validation loss = 3.1653  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.9717  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.9716  Validation loss = 3.1651  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.9716  Validation loss = 3.1650  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.9716  Validation loss = 3.1649  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.9715  Validation loss = 3.1649  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.9715  Validation loss = 3.1648  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.9714  Validation loss = 3.1647  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.9714  Validation loss = 3.1646  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.9713  Validation loss = 3.1645  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.9713  Validation loss = 3.1645  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.9712  Validation loss = 3.1644  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.9712  Validation loss = 3.1643  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.9711  Validation loss = 3.1642  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.9711  Validation loss = 3.1641  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.9710  Validation loss = 3.1640  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.9710  Validation loss = 3.1639  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.9709  Validation loss = 3.1638  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.9708  Validation loss = 3.1637  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.9707  Validation loss = 3.1636  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.9707  Validation loss = 3.1635  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.9706  Validation loss = 3.1634  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.9706  Validation loss = 3.1633  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.9705  Validation loss = 3.1632  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.9704  Validation loss = 3.1631  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.9704  Validation loss = 3.1630  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.9703  Validation loss = 3.1630  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.9703  Validation loss = 3.1629  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.9702  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.9701  Validation loss = 3.1626  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.9701  Validation loss = 3.1626  \n",
      "\n",
      "Fold: 2  Epoch: 501  Training loss = 2.9700  Validation loss = 3.1625  \n",
      "\n",
      "Fold: 2  Epoch: 502  Training loss = 2.9700  Validation loss = 3.1624  \n",
      "\n",
      "Fold: 2  Epoch: 503  Training loss = 2.9699  Validation loss = 3.1623  \n",
      "\n",
      "Fold: 2  Epoch: 504  Training loss = 2.9699  Validation loss = 3.1622  \n",
      "\n",
      "Fold: 2  Epoch: 505  Training loss = 2.9698  Validation loss = 3.1621  \n",
      "\n",
      "Fold: 2  Epoch: 506  Training loss = 2.9698  Validation loss = 3.1620  \n",
      "\n",
      "Fold: 2  Epoch: 507  Training loss = 2.9697  Validation loss = 3.1620  \n",
      "\n",
      "Fold: 2  Epoch: 508  Training loss = 2.9697  Validation loss = 3.1618  \n",
      "\n",
      "Fold: 2  Epoch: 509  Training loss = 2.9696  Validation loss = 3.1618  \n",
      "\n",
      "Fold: 2  Epoch: 510  Training loss = 2.9696  Validation loss = 3.1617  \n",
      "\n",
      "Fold: 2  Epoch: 511  Training loss = 2.9695  Validation loss = 3.1616  \n",
      "\n",
      "Fold: 2  Epoch: 512  Training loss = 2.9694  Validation loss = 3.1615  \n",
      "\n",
      "Fold: 2  Epoch: 513  Training loss = 2.9693  Validation loss = 3.1614  \n",
      "\n",
      "Fold: 2  Epoch: 514  Training loss = 2.9693  Validation loss = 3.1613  \n",
      "\n",
      "Fold: 2  Epoch: 515  Training loss = 2.9692  Validation loss = 3.1612  \n",
      "\n",
      "Fold: 2  Epoch: 516  Training loss = 2.9692  Validation loss = 3.1611  \n",
      "\n",
      "Fold: 2  Epoch: 517  Training loss = 2.9691  Validation loss = 3.1609  \n",
      "\n",
      "Fold: 2  Epoch: 518  Training loss = 2.9690  Validation loss = 3.1609  \n",
      "\n",
      "Fold: 2  Epoch: 519  Training loss = 2.9690  Validation loss = 3.1608  \n",
      "\n",
      "Fold: 2  Epoch: 520  Training loss = 2.9689  Validation loss = 3.1607  \n",
      "\n",
      "Fold: 2  Epoch: 521  Training loss = 2.9689  Validation loss = 3.1606  \n",
      "\n",
      "Fold: 2  Epoch: 522  Training loss = 2.9688  Validation loss = 3.1605  \n",
      "\n",
      "Fold: 2  Epoch: 523  Training loss = 2.9687  Validation loss = 3.1604  \n",
      "\n",
      "Fold: 2  Epoch: 524  Training loss = 2.9687  Validation loss = 3.1603  \n",
      "\n",
      "Fold: 2  Epoch: 525  Training loss = 2.9687  Validation loss = 3.1602  \n",
      "\n",
      "Fold: 2  Epoch: 526  Training loss = 2.9686  Validation loss = 3.1601  \n",
      "\n",
      "Fold: 2  Epoch: 527  Training loss = 2.9685  Validation loss = 3.1600  \n",
      "\n",
      "Fold: 2  Epoch: 528  Training loss = 2.9685  Validation loss = 3.1600  \n",
      "\n",
      "Fold: 2  Epoch: 529  Training loss = 2.9684  Validation loss = 3.1599  \n",
      "\n",
      "Fold: 2  Epoch: 530  Training loss = 2.9684  Validation loss = 3.1598  \n",
      "\n",
      "Fold: 2  Epoch: 531  Training loss = 2.9683  Validation loss = 3.1597  \n",
      "\n",
      "Fold: 2  Epoch: 532  Training loss = 2.9682  Validation loss = 3.1596  \n",
      "\n",
      "Fold: 2  Epoch: 533  Training loss = 2.9682  Validation loss = 3.1595  \n",
      "\n",
      "Fold: 2  Epoch: 534  Training loss = 2.9681  Validation loss = 3.1594  \n",
      "\n",
      "Fold: 2  Epoch: 535  Training loss = 2.9681  Validation loss = 3.1593  \n",
      "\n",
      "Fold: 2  Epoch: 536  Training loss = 2.9680  Validation loss = 3.1592  \n",
      "\n",
      "Fold: 2  Epoch: 537  Training loss = 2.9679  Validation loss = 3.1591  \n",
      "\n",
      "Fold: 2  Epoch: 538  Training loss = 2.9679  Validation loss = 3.1590  \n",
      "\n",
      "Fold: 2  Epoch: 539  Training loss = 2.9678  Validation loss = 3.1589  \n",
      "\n",
      "Fold: 2  Epoch: 540  Training loss = 2.9678  Validation loss = 3.1588  \n",
      "\n",
      "Fold: 2  Epoch: 541  Training loss = 2.9677  Validation loss = 3.1588  \n",
      "\n",
      "Fold: 2  Epoch: 542  Training loss = 2.9677  Validation loss = 3.1587  \n",
      "\n",
      "Fold: 2  Epoch: 543  Training loss = 2.9676  Validation loss = 3.1586  \n",
      "\n",
      "Fold: 2  Epoch: 544  Training loss = 2.9676  Validation loss = 3.1585  \n",
      "\n",
      "Fold: 2  Epoch: 545  Training loss = 2.9675  Validation loss = 3.1584  \n",
      "\n",
      "Fold: 2  Epoch: 546  Training loss = 2.9675  Validation loss = 3.1583  \n",
      "\n",
      "Fold: 2  Epoch: 547  Training loss = 2.9674  Validation loss = 3.1582  \n",
      "\n",
      "Fold: 2  Epoch: 548  Training loss = 2.9673  Validation loss = 3.1581  \n",
      "\n",
      "Fold: 2  Epoch: 549  Training loss = 2.9673  Validation loss = 3.1580  \n",
      "\n",
      "Fold: 2  Epoch: 550  Training loss = 2.9672  Validation loss = 3.1580  \n",
      "\n",
      "Fold: 2  Epoch: 551  Training loss = 2.9672  Validation loss = 3.1579  \n",
      "\n",
      "Fold: 2  Epoch: 552  Training loss = 2.9671  Validation loss = 3.1578  \n",
      "\n",
      "Fold: 2  Epoch: 553  Training loss = 2.9671  Validation loss = 3.1577  \n",
      "\n",
      "Fold: 2  Epoch: 554  Training loss = 2.9670  Validation loss = 3.1576  \n",
      "\n",
      "Fold: 2  Epoch: 555  Training loss = 2.9669  Validation loss = 3.1575  \n",
      "\n",
      "Fold: 2  Epoch: 556  Training loss = 2.9669  Validation loss = 3.1574  \n",
      "\n",
      "Fold: 2  Epoch: 557  Training loss = 2.9668  Validation loss = 3.1573  \n",
      "\n",
      "Fold: 2  Epoch: 558  Training loss = 2.9668  Validation loss = 3.1572  \n",
      "\n",
      "Fold: 2  Epoch: 559  Training loss = 2.9667  Validation loss = 3.1571  \n",
      "\n",
      "Fold: 2  Epoch: 560  Training loss = 2.9666  Validation loss = 3.1570  \n",
      "\n",
      "Fold: 2  Epoch: 561  Training loss = 2.9666  Validation loss = 3.1569  \n",
      "\n",
      "Fold: 2  Epoch: 562  Training loss = 2.9665  Validation loss = 3.1568  \n",
      "\n",
      "Fold: 2  Epoch: 563  Training loss = 2.9665  Validation loss = 3.1568  \n",
      "\n",
      "Fold: 2  Epoch: 564  Training loss = 2.9664  Validation loss = 3.1567  \n",
      "\n",
      "Fold: 2  Epoch: 565  Training loss = 2.9664  Validation loss = 3.1566  \n",
      "\n",
      "Fold: 2  Epoch: 566  Training loss = 2.9663  Validation loss = 3.1565  \n",
      "\n",
      "Fold: 2  Epoch: 567  Training loss = 2.9663  Validation loss = 3.1564  \n",
      "\n",
      "Fold: 2  Epoch: 568  Training loss = 2.9662  Validation loss = 3.1563  \n",
      "\n",
      "Fold: 2  Epoch: 569  Training loss = 2.9661  Validation loss = 3.1562  \n",
      "\n",
      "Fold: 2  Epoch: 570  Training loss = 2.9661  Validation loss = 3.1561  \n",
      "\n",
      "Fold: 2  Epoch: 571  Training loss = 2.9660  Validation loss = 3.1560  \n",
      "\n",
      "Fold: 2  Epoch: 572  Training loss = 2.9659  Validation loss = 3.1559  \n",
      "\n",
      "Fold: 2  Epoch: 573  Training loss = 2.9659  Validation loss = 3.1558  \n",
      "\n",
      "Fold: 2  Epoch: 574  Training loss = 2.9659  Validation loss = 3.1557  \n",
      "\n",
      "Fold: 2  Epoch: 575  Training loss = 2.9658  Validation loss = 3.1556  \n",
      "\n",
      "Fold: 2  Epoch: 576  Training loss = 2.9658  Validation loss = 3.1556  \n",
      "\n",
      "Fold: 2  Epoch: 577  Training loss = 2.9657  Validation loss = 3.1555  \n",
      "\n",
      "Fold: 2  Epoch: 578  Training loss = 2.9656  Validation loss = 3.1554  \n",
      "\n",
      "Fold: 2  Epoch: 579  Training loss = 2.9656  Validation loss = 3.1553  \n",
      "\n",
      "Fold: 2  Epoch: 580  Training loss = 2.9655  Validation loss = 3.1552  \n",
      "\n",
      "Fold: 2  Epoch: 581  Training loss = 2.9655  Validation loss = 3.1551  \n",
      "\n",
      "Fold: 2  Epoch: 582  Training loss = 2.9654  Validation loss = 3.1550  \n",
      "\n",
      "Fold: 2  Epoch: 583  Training loss = 2.9654  Validation loss = 3.1549  \n",
      "\n",
      "Fold: 2  Epoch: 584  Training loss = 2.9653  Validation loss = 3.1548  \n",
      "\n",
      "Fold: 2  Epoch: 585  Training loss = 2.9653  Validation loss = 3.1547  \n",
      "\n",
      "Fold: 2  Epoch: 586  Training loss = 2.9652  Validation loss = 3.1546  \n",
      "\n",
      "Fold: 2  Epoch: 587  Training loss = 2.9651  Validation loss = 3.1545  \n",
      "\n",
      "Fold: 2  Epoch: 588  Training loss = 2.9651  Validation loss = 3.1545  \n",
      "\n",
      "Fold: 2  Epoch: 589  Training loss = 2.9650  Validation loss = 3.1544  \n",
      "\n",
      "Fold: 2  Epoch: 590  Training loss = 2.9650  Validation loss = 3.1543  \n",
      "\n",
      "Fold: 2  Epoch: 591  Training loss = 2.9649  Validation loss = 3.1542  \n",
      "\n",
      "Fold: 2  Epoch: 592  Training loss = 2.9649  Validation loss = 3.1541  \n",
      "\n",
      "Fold: 2  Epoch: 593  Training loss = 2.9648  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 2  Epoch: 594  Training loss = 2.9648  Validation loss = 3.1539  \n",
      "\n",
      "Fold: 2  Epoch: 595  Training loss = 2.9647  Validation loss = 3.1538  \n",
      "\n",
      "Fold: 2  Epoch: 596  Training loss = 2.9646  Validation loss = 3.1537  \n",
      "\n",
      "Fold: 2  Epoch: 597  Training loss = 2.9646  Validation loss = 3.1536  \n",
      "\n",
      "Fold: 2  Epoch: 598  Training loss = 2.9645  Validation loss = 3.1535  \n",
      "\n",
      "Fold: 2  Epoch: 599  Training loss = 2.9644  Validation loss = 3.1534  \n",
      "\n",
      "Fold: 2  Epoch: 600  Training loss = 2.9644  Validation loss = 3.1533  \n",
      "\n",
      "Fold: 2  Epoch: 601  Training loss = 2.9644  Validation loss = 3.1533  \n",
      "\n",
      "Fold: 2  Epoch: 602  Training loss = 2.9643  Validation loss = 3.1532  \n",
      "\n",
      "Fold: 2  Epoch: 603  Training loss = 2.9643  Validation loss = 3.1531  \n",
      "\n",
      "Fold: 2  Epoch: 604  Training loss = 2.9642  Validation loss = 3.1530  \n",
      "\n",
      "Fold: 2  Epoch: 605  Training loss = 2.9641  Validation loss = 3.1529  \n",
      "\n",
      "Fold: 2  Epoch: 606  Training loss = 2.9641  Validation loss = 3.1528  \n",
      "\n",
      "Fold: 2  Epoch: 607  Training loss = 2.9640  Validation loss = 3.1527  \n",
      "\n",
      "Fold: 2  Epoch: 608  Training loss = 2.9640  Validation loss = 3.1526  \n",
      "\n",
      "Fold: 2  Epoch: 609  Training loss = 2.9639  Validation loss = 3.1525  \n",
      "\n",
      "Fold: 2  Epoch: 610  Training loss = 2.9639  Validation loss = 3.1525  \n",
      "\n",
      "Fold: 2  Epoch: 611  Training loss = 2.9638  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 2  Epoch: 612  Training loss = 2.9637  Validation loss = 3.1523  \n",
      "\n",
      "Fold: 2  Epoch: 613  Training loss = 2.9637  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 2  Epoch: 614  Training loss = 2.9636  Validation loss = 3.1521  \n",
      "\n",
      "Fold: 2  Epoch: 615  Training loss = 2.9636  Validation loss = 3.1520  \n",
      "\n",
      "Fold: 2  Epoch: 616  Training loss = 2.9635  Validation loss = 3.1519  \n",
      "\n",
      "Fold: 2  Epoch: 617  Training loss = 2.9635  Validation loss = 3.1518  \n",
      "\n",
      "Fold: 2  Epoch: 618  Training loss = 2.9634  Validation loss = 3.1517  \n",
      "\n",
      "Fold: 2  Epoch: 619  Training loss = 2.9633  Validation loss = 3.1516  \n",
      "\n",
      "Fold: 2  Epoch: 620  Training loss = 2.9633  Validation loss = 3.1515  \n",
      "\n",
      "Fold: 2  Epoch: 621  Training loss = 2.9632  Validation loss = 3.1514  \n",
      "\n",
      "Fold: 2  Epoch: 622  Training loss = 2.9632  Validation loss = 3.1513  \n",
      "\n",
      "Fold: 2  Epoch: 623  Training loss = 2.9631  Validation loss = 3.1512  \n",
      "\n",
      "Fold: 2  Epoch: 624  Training loss = 2.9630  Validation loss = 3.1511  \n",
      "\n",
      "Fold: 2  Epoch: 625  Training loss = 2.9630  Validation loss = 3.1510  \n",
      "\n",
      "Fold: 2  Epoch: 626  Training loss = 2.9629  Validation loss = 3.1509  \n",
      "\n",
      "Fold: 2  Epoch: 627  Training loss = 2.9629  Validation loss = 3.1508  \n",
      "\n",
      "Fold: 2  Epoch: 628  Training loss = 2.9628  Validation loss = 3.1507  \n",
      "\n",
      "Fold: 2  Epoch: 629  Training loss = 2.9627  Validation loss = 3.1506  \n",
      "\n",
      "Fold: 2  Epoch: 630  Training loss = 2.9627  Validation loss = 3.1505  \n",
      "\n",
      "Fold: 2  Epoch: 631  Training loss = 2.9626  Validation loss = 3.1504  \n",
      "\n",
      "Fold: 2  Epoch: 632  Training loss = 2.9626  Validation loss = 3.1503  \n",
      "\n",
      "Fold: 2  Epoch: 633  Training loss = 2.9625  Validation loss = 3.1502  \n",
      "\n",
      "Fold: 2  Epoch: 634  Training loss = 2.9625  Validation loss = 3.1501  \n",
      "\n",
      "Fold: 2  Epoch: 635  Training loss = 2.9624  Validation loss = 3.1500  \n",
      "\n",
      "Fold: 2  Epoch: 636  Training loss = 2.9623  Validation loss = 3.1500  \n",
      "\n",
      "Fold: 2  Epoch: 637  Training loss = 2.9623  Validation loss = 3.1499  \n",
      "\n",
      "Fold: 2  Epoch: 638  Training loss = 2.9622  Validation loss = 3.1498  \n",
      "\n",
      "Fold: 2  Epoch: 639  Training loss = 2.9622  Validation loss = 3.1497  \n",
      "\n",
      "Fold: 2  Epoch: 640  Training loss = 2.9622  Validation loss = 3.1497  \n",
      "\n",
      "Fold: 2  Epoch: 641  Training loss = 2.9621  Validation loss = 3.1496  \n",
      "\n",
      "Fold: 2  Epoch: 642  Training loss = 2.9621  Validation loss = 3.1495  \n",
      "\n",
      "Fold: 2  Epoch: 643  Training loss = 2.9620  Validation loss = 3.1494  \n",
      "\n",
      "Fold: 2  Epoch: 644  Training loss = 2.9619  Validation loss = 3.1493  \n",
      "\n",
      "Fold: 2  Epoch: 645  Training loss = 2.9619  Validation loss = 3.1492  \n",
      "\n",
      "Fold: 2  Epoch: 646  Training loss = 2.9618  Validation loss = 3.1491  \n",
      "\n",
      "Fold: 2  Epoch: 647  Training loss = 2.9618  Validation loss = 3.1491  \n",
      "\n",
      "Fold: 2  Epoch: 648  Training loss = 2.9617  Validation loss = 3.1490  \n",
      "\n",
      "Fold: 2  Epoch: 649  Training loss = 2.9617  Validation loss = 3.1489  \n",
      "\n",
      "Fold: 2  Epoch: 650  Training loss = 2.9616  Validation loss = 3.1488  \n",
      "\n",
      "Fold: 2  Epoch: 651  Training loss = 2.9616  Validation loss = 3.1487  \n",
      "\n",
      "Fold: 2  Epoch: 652  Training loss = 2.9615  Validation loss = 3.1486  \n",
      "\n",
      "Fold: 2  Epoch: 653  Training loss = 2.9615  Validation loss = 3.1485  \n",
      "\n",
      "Fold: 2  Epoch: 654  Training loss = 2.9614  Validation loss = 3.1484  \n",
      "\n",
      "Fold: 2  Epoch: 655  Training loss = 2.9613  Validation loss = 3.1483  \n",
      "\n",
      "Fold: 2  Epoch: 656  Training loss = 2.9613  Validation loss = 3.1482  \n",
      "\n",
      "Fold: 2  Epoch: 657  Training loss = 2.9612  Validation loss = 3.1481  \n",
      "\n",
      "Fold: 2  Epoch: 658  Training loss = 2.9612  Validation loss = 3.1480  \n",
      "\n",
      "Fold: 2  Epoch: 659  Training loss = 2.9611  Validation loss = 3.1479  \n",
      "\n",
      "Fold: 2  Epoch: 660  Training loss = 2.9610  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 2  Epoch: 661  Training loss = 2.9610  Validation loss = 3.1477  \n",
      "\n",
      "Fold: 2  Epoch: 662  Training loss = 2.9609  Validation loss = 3.1476  \n",
      "\n",
      "Fold: 2  Epoch: 663  Training loss = 2.9609  Validation loss = 3.1476  \n",
      "\n",
      "Fold: 2  Epoch: 664  Training loss = 2.9608  Validation loss = 3.1475  \n",
      "\n",
      "Fold: 2  Epoch: 665  Training loss = 2.9608  Validation loss = 3.1474  \n",
      "\n",
      "Fold: 2  Epoch: 666  Training loss = 2.9607  Validation loss = 3.1473  \n",
      "\n",
      "Fold: 2  Epoch: 667  Training loss = 2.9606  Validation loss = 3.1472  \n",
      "\n",
      "Fold: 2  Epoch: 668  Training loss = 2.9606  Validation loss = 3.1471  \n",
      "\n",
      "Fold: 2  Epoch: 669  Training loss = 2.9605  Validation loss = 3.1470  \n",
      "\n",
      "Fold: 2  Epoch: 670  Training loss = 2.9604  Validation loss = 3.1469  \n",
      "\n",
      "Fold: 2  Epoch: 671  Training loss = 2.9604  Validation loss = 3.1468  \n",
      "\n",
      "Fold: 2  Epoch: 672  Training loss = 2.9603  Validation loss = 3.1467  \n",
      "\n",
      "Fold: 2  Epoch: 673  Training loss = 2.9603  Validation loss = 3.1466  \n",
      "\n",
      "Fold: 2  Epoch: 674  Training loss = 2.9602  Validation loss = 3.1465  \n",
      "\n",
      "Fold: 2  Epoch: 675  Training loss = 2.9602  Validation loss = 3.1464  \n",
      "\n",
      "Fold: 2  Epoch: 676  Training loss = 2.9601  Validation loss = 3.1463  \n",
      "\n",
      "Fold: 2  Epoch: 677  Training loss = 2.9601  Validation loss = 3.1462  \n",
      "\n",
      "Fold: 2  Epoch: 678  Training loss = 2.9600  Validation loss = 3.1461  \n",
      "\n",
      "Fold: 2  Epoch: 679  Training loss = 2.9600  Validation loss = 3.1461  \n",
      "\n",
      "Fold: 2  Epoch: 680  Training loss = 2.9599  Validation loss = 3.1460  \n",
      "\n",
      "Fold: 2  Epoch: 681  Training loss = 2.9599  Validation loss = 3.1459  \n",
      "\n",
      "Fold: 2  Epoch: 682  Training loss = 2.9598  Validation loss = 3.1458  \n",
      "\n",
      "Fold: 2  Epoch: 683  Training loss = 2.9597  Validation loss = 3.1457  \n",
      "\n",
      "Fold: 2  Epoch: 684  Training loss = 2.9597  Validation loss = 3.1456  \n",
      "\n",
      "Fold: 2  Epoch: 685  Training loss = 2.9596  Validation loss = 3.1454  \n",
      "\n",
      "Fold: 2  Epoch: 686  Training loss = 2.9595  Validation loss = 3.1454  \n",
      "\n",
      "Fold: 2  Epoch: 687  Training loss = 2.9595  Validation loss = 3.1453  \n",
      "\n",
      "Fold: 2  Epoch: 688  Training loss = 2.9594  Validation loss = 3.1452  \n",
      "\n",
      "Fold: 2  Epoch: 689  Training loss = 2.9594  Validation loss = 3.1451  \n",
      "\n",
      "Fold: 2  Epoch: 690  Training loss = 2.9593  Validation loss = 3.1450  \n",
      "\n",
      "Fold: 2  Epoch: 691  Training loss = 2.9593  Validation loss = 3.1450  \n",
      "\n",
      "Fold: 2  Epoch: 692  Training loss = 2.9592  Validation loss = 3.1448  \n",
      "\n",
      "Fold: 2  Epoch: 693  Training loss = 2.9592  Validation loss = 3.1447  \n",
      "\n",
      "Fold: 2  Epoch: 694  Training loss = 2.9591  Validation loss = 3.1446  \n",
      "\n",
      "Fold: 2  Epoch: 695  Training loss = 2.9590  Validation loss = 3.1445  \n",
      "\n",
      "Fold: 2  Epoch: 696  Training loss = 2.9590  Validation loss = 3.1444  \n",
      "\n",
      "Fold: 2  Epoch: 697  Training loss = 2.9589  Validation loss = 3.1443  \n",
      "\n",
      "Fold: 2  Epoch: 698  Training loss = 2.9589  Validation loss = 3.1443  \n",
      "\n",
      "Fold: 2  Epoch: 699  Training loss = 2.9588  Validation loss = 3.1442  \n",
      "\n",
      "Fold: 2  Epoch: 700  Training loss = 2.9587  Validation loss = 3.1441  \n",
      "\n",
      "Fold: 2  Epoch: 701  Training loss = 2.9587  Validation loss = 3.1439  \n",
      "\n",
      "Fold: 2  Epoch: 702  Training loss = 2.9586  Validation loss = 3.1438  \n",
      "\n",
      "Fold: 2  Epoch: 703  Training loss = 2.9586  Validation loss = 3.1438  \n",
      "\n",
      "Fold: 2  Epoch: 704  Training loss = 2.9585  Validation loss = 3.1437  \n",
      "\n",
      "Fold: 2  Epoch: 705  Training loss = 2.9585  Validation loss = 3.1436  \n",
      "\n",
      "Fold: 2  Epoch: 706  Training loss = 2.9584  Validation loss = 3.1435  \n",
      "\n",
      "Fold: 2  Epoch: 707  Training loss = 2.9584  Validation loss = 3.1434  \n",
      "\n",
      "Fold: 2  Epoch: 708  Training loss = 2.9583  Validation loss = 3.1434  \n",
      "\n",
      "Fold: 2  Epoch: 709  Training loss = 2.9583  Validation loss = 3.1433  \n",
      "\n",
      "Fold: 2  Epoch: 710  Training loss = 2.9582  Validation loss = 3.1432  \n",
      "\n",
      "Fold: 2  Epoch: 711  Training loss = 2.9582  Validation loss = 3.1431  \n",
      "\n",
      "Fold: 2  Epoch: 712  Training loss = 2.9581  Validation loss = 3.1430  \n",
      "\n",
      "Fold: 2  Epoch: 713  Training loss = 2.9580  Validation loss = 3.1429  \n",
      "\n",
      "Fold: 2  Epoch: 714  Training loss = 2.9580  Validation loss = 3.1428  \n",
      "\n",
      "Fold: 2  Epoch: 715  Training loss = 2.9579  Validation loss = 3.1427  \n",
      "\n",
      "Fold: 2  Epoch: 716  Training loss = 2.9579  Validation loss = 3.1426  \n",
      "\n",
      "Fold: 2  Epoch: 717  Training loss = 2.9578  Validation loss = 3.1425  \n",
      "\n",
      "Fold: 2  Epoch: 718  Training loss = 2.9578  Validation loss = 3.1425  \n",
      "\n",
      "Fold: 2  Epoch: 719  Training loss = 2.9577  Validation loss = 3.1424  \n",
      "\n",
      "Fold: 2  Epoch: 720  Training loss = 2.9577  Validation loss = 3.1423  \n",
      "\n",
      "Fold: 2  Epoch: 721  Training loss = 2.9576  Validation loss = 3.1422  \n",
      "\n",
      "Fold: 2  Epoch: 722  Training loss = 2.9576  Validation loss = 3.1421  \n",
      "\n",
      "Fold: 2  Epoch: 723  Training loss = 2.9575  Validation loss = 3.1420  \n",
      "\n",
      "Fold: 2  Epoch: 724  Training loss = 2.9575  Validation loss = 3.1419  \n",
      "\n",
      "Fold: 2  Epoch: 725  Training loss = 2.9574  Validation loss = 3.1419  \n",
      "\n",
      "Fold: 2  Epoch: 726  Training loss = 2.9574  Validation loss = 3.1418  \n",
      "\n",
      "Fold: 2  Epoch: 727  Training loss = 2.9573  Validation loss = 3.1417  \n",
      "\n",
      "Fold: 2  Epoch: 728  Training loss = 2.9573  Validation loss = 3.1416  \n",
      "\n",
      "Fold: 2  Epoch: 729  Training loss = 2.9572  Validation loss = 3.1415  \n",
      "\n",
      "Fold: 2  Epoch: 730  Training loss = 2.9572  Validation loss = 3.1414  \n",
      "\n",
      "Fold: 2  Epoch: 731  Training loss = 2.9571  Validation loss = 3.1413  \n",
      "\n",
      "Fold: 2  Epoch: 732  Training loss = 2.9571  Validation loss = 3.1413  \n",
      "\n",
      "Fold: 2  Epoch: 733  Training loss = 2.9570  Validation loss = 3.1412  \n",
      "\n",
      "Fold: 2  Epoch: 734  Training loss = 2.9570  Validation loss = 3.1411  \n",
      "\n",
      "Fold: 2  Epoch: 735  Training loss = 2.9569  Validation loss = 3.1410  \n",
      "\n",
      "Fold: 2  Epoch: 736  Training loss = 2.9569  Validation loss = 3.1409  \n",
      "\n",
      "Fold: 2  Epoch: 737  Training loss = 2.9568  Validation loss = 3.1408  \n",
      "\n",
      "Fold: 2  Epoch: 738  Training loss = 2.9568  Validation loss = 3.1407  \n",
      "\n",
      "Fold: 2  Epoch: 739  Training loss = 2.9567  Validation loss = 3.1407  \n",
      "\n",
      "Fold: 2  Epoch: 740  Training loss = 2.9567  Validation loss = 3.1406  \n",
      "\n",
      "Fold: 2  Epoch: 741  Training loss = 2.9566  Validation loss = 3.1405  \n",
      "\n",
      "Fold: 2  Epoch: 742  Training loss = 2.9566  Validation loss = 3.1404  \n",
      "\n",
      "Fold: 2  Epoch: 743  Training loss = 2.9565  Validation loss = 3.1403  \n",
      "\n",
      "Fold: 2  Epoch: 744  Training loss = 2.9565  Validation loss = 3.1402  \n",
      "\n",
      "Fold: 2  Epoch: 745  Training loss = 2.9564  Validation loss = 3.1401  \n",
      "\n",
      "Fold: 2  Epoch: 746  Training loss = 2.9563  Validation loss = 3.1400  \n",
      "\n",
      "Fold: 2  Epoch: 747  Training loss = 2.9563  Validation loss = 3.1399  \n",
      "\n",
      "Fold: 2  Epoch: 748  Training loss = 2.9562  Validation loss = 3.1399  \n",
      "\n",
      "Fold: 2  Epoch: 749  Training loss = 2.9562  Validation loss = 3.1398  \n",
      "\n",
      "Fold: 2  Epoch: 750  Training loss = 2.9561  Validation loss = 3.1397  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 750  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.9691  Validation loss = 4.3390  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.9690  Validation loss = 4.3388  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.9690  Validation loss = 4.3387  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.9689  Validation loss = 4.3386  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.9689  Validation loss = 4.3384  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.9688  Validation loss = 4.3383  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.9688  Validation loss = 4.3382  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.9687  Validation loss = 4.3381  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.9686  Validation loss = 4.3379  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.9686  Validation loss = 4.3379  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.9685  Validation loss = 4.3377  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.9684  Validation loss = 4.3376  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.9684  Validation loss = 4.3374  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.9683  Validation loss = 4.3373  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.9683  Validation loss = 4.3372  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.9682  Validation loss = 4.3370  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.9681  Validation loss = 4.3369  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.9681  Validation loss = 4.3368  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.9680  Validation loss = 4.3366  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.9679  Validation loss = 4.3365  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.9678  Validation loss = 4.3363  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.9678  Validation loss = 4.3361  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.9677  Validation loss = 4.3359  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.9676  Validation loss = 4.3358  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.9676  Validation loss = 4.3357  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.9675  Validation loss = 4.3356  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.9675  Validation loss = 4.3355  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.9674  Validation loss = 4.3354  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.9674  Validation loss = 4.3353  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.9673  Validation loss = 4.3352  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.9673  Validation loss = 4.3351  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.9672  Validation loss = 4.3350  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.9672  Validation loss = 4.3349  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.9671  Validation loss = 4.3347  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.9671  Validation loss = 4.3346  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.9670  Validation loss = 4.3345  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.9670  Validation loss = 4.3344  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.9669  Validation loss = 4.3343  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.9668  Validation loss = 4.3341  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.9668  Validation loss = 4.3340  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.9667  Validation loss = 4.3339  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.9667  Validation loss = 4.3338  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.9666  Validation loss = 4.3336  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.9665  Validation loss = 4.3334  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.9665  Validation loss = 4.3333  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.9664  Validation loss = 4.3332  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.9664  Validation loss = 4.3331  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.9663  Validation loss = 4.3329  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.9662  Validation loss = 4.3328  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.9662  Validation loss = 4.3327  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.9661  Validation loss = 4.3325  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.9660  Validation loss = 4.3324  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.9660  Validation loss = 4.3323  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.9659  Validation loss = 4.3321  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.9659  Validation loss = 4.3320  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.9658  Validation loss = 4.3319  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.9657  Validation loss = 4.3317  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.9657  Validation loss = 4.3316  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.9656  Validation loss = 4.3315  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.9656  Validation loss = 4.3313  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.9655  Validation loss = 4.3312  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.9654  Validation loss = 4.3311  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.9654  Validation loss = 4.3309  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.9653  Validation loss = 4.3308  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.9652  Validation loss = 4.3306  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.9652  Validation loss = 4.3305  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.9651  Validation loss = 4.3305  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.9651  Validation loss = 4.3303  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.9650  Validation loss = 4.3302  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.9650  Validation loss = 4.3301  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.9649  Validation loss = 4.3300  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.9649  Validation loss = 4.3298  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.9648  Validation loss = 4.3297  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.9647  Validation loss = 4.3296  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.9647  Validation loss = 4.3294  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.9646  Validation loss = 4.3292  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.9645  Validation loss = 4.3291  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.9645  Validation loss = 4.3290  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.9644  Validation loss = 4.3288  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.9644  Validation loss = 4.3287  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.9643  Validation loss = 4.3286  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.9642  Validation loss = 4.3284  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.9641  Validation loss = 4.3283  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.9641  Validation loss = 4.3281  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.9640  Validation loss = 4.3279  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.9640  Validation loss = 4.3278  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.9639  Validation loss = 4.3277  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.9638  Validation loss = 4.3275  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.9638  Validation loss = 4.3274  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.9637  Validation loss = 4.3272  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.9636  Validation loss = 4.3271  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.9636  Validation loss = 4.3269  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.9635  Validation loss = 4.3268  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.9634  Validation loss = 4.3267  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.9634  Validation loss = 4.3266  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.9633  Validation loss = 4.3265  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.9633  Validation loss = 4.3263  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.9632  Validation loss = 4.3262  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.9632  Validation loss = 4.3261  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.9631  Validation loss = 4.3259  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.9630  Validation loss = 4.3258  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.9630  Validation loss = 4.3257  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.9629  Validation loss = 4.3255  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.9629  Validation loss = 4.3254  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.9628  Validation loss = 4.3253  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.9627  Validation loss = 4.3251  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.9627  Validation loss = 4.3250  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.9626  Validation loss = 4.3248  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.9625  Validation loss = 4.3247  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.9625  Validation loss = 4.3246  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.9624  Validation loss = 4.3244  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.9623  Validation loss = 4.3243  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.9623  Validation loss = 4.3242  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.9622  Validation loss = 4.3240  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.9622  Validation loss = 4.3239  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.9621  Validation loss = 4.3238  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.9620  Validation loss = 4.3236  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.9620  Validation loss = 4.3235  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.9619  Validation loss = 4.3234  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.9619  Validation loss = 4.3233  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.9618  Validation loss = 4.3232  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.9618  Validation loss = 4.3230  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.9617  Validation loss = 4.3229  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.9617  Validation loss = 4.3228  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.9616  Validation loss = 4.3226  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.9615  Validation loss = 4.3225  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.9615  Validation loss = 4.3223  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.9614  Validation loss = 4.3222  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.9613  Validation loss = 4.3221  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.9613  Validation loss = 4.3219  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.9612  Validation loss = 4.3218  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.9612  Validation loss = 4.3217  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.9611  Validation loss = 4.3215  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.9610  Validation loss = 4.3214  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.9610  Validation loss = 4.3213  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.9609  Validation loss = 4.3211  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.9609  Validation loss = 4.3210  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.9608  Validation loss = 4.3208  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.9607  Validation loss = 4.3207  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.9607  Validation loss = 4.3206  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.9606  Validation loss = 4.3204  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.9606  Validation loss = 4.3203  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.9605  Validation loss = 4.3201  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.9604  Validation loss = 4.3200  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.9604  Validation loss = 4.3199  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.9603  Validation loss = 4.3197  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.9602  Validation loss = 4.3195  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.9602  Validation loss = 4.3194  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.9601  Validation loss = 4.3193  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.9600  Validation loss = 4.3191  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.9600  Validation loss = 4.3190  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.9599  Validation loss = 4.3189  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.9599  Validation loss = 4.3188  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.9598  Validation loss = 4.3187  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.9598  Validation loss = 4.3185  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.9597  Validation loss = 4.3184  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.9596  Validation loss = 4.3183  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.9596  Validation loss = 4.3182  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.9595  Validation loss = 4.3181  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.9595  Validation loss = 4.3180  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.9594  Validation loss = 4.3178  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.9594  Validation loss = 4.3177  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.9593  Validation loss = 4.3176  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.9593  Validation loss = 4.3175  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.9592  Validation loss = 4.3173  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.9591  Validation loss = 4.3172  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.9591  Validation loss = 4.3171  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.9591  Validation loss = 4.3170  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.9590  Validation loss = 4.3169  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.9590  Validation loss = 4.3168  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.9589  Validation loss = 4.3166  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.9588  Validation loss = 4.3165  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.9588  Validation loss = 4.3164  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.9587  Validation loss = 4.3162  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.9586  Validation loss = 4.3161  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.9586  Validation loss = 4.3160  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.9586  Validation loss = 4.3159  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.9585  Validation loss = 4.3158  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.9584  Validation loss = 4.3156  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.9584  Validation loss = 4.3155  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.9583  Validation loss = 4.3154  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.9583  Validation loss = 4.3153  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.9582  Validation loss = 4.3151  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.9581  Validation loss = 4.3150  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.9581  Validation loss = 4.3149  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.9580  Validation loss = 4.3147  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.9580  Validation loss = 4.3146  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.9579  Validation loss = 4.3145  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.9579  Validation loss = 4.3144  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.9578  Validation loss = 4.3142  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.9577  Validation loss = 4.3141  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.9577  Validation loss = 4.3139  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.9576  Validation loss = 4.3138  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.9576  Validation loss = 4.3137  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.9575  Validation loss = 4.3136  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.9575  Validation loss = 4.3135  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.9574  Validation loss = 4.3133  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.9573  Validation loss = 4.3132  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.9573  Validation loss = 4.3130  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.9572  Validation loss = 4.3128  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.9571  Validation loss = 4.3127  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.9570  Validation loss = 4.3125  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.9570  Validation loss = 4.3123  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.9569  Validation loss = 4.3122  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.9568  Validation loss = 4.3120  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.9568  Validation loss = 4.3119  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.9567  Validation loss = 4.3118  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.9567  Validation loss = 4.3117  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.9566  Validation loss = 4.3115  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.9566  Validation loss = 4.3115  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.9565  Validation loss = 4.3113  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.9564  Validation loss = 4.3111  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.9563  Validation loss = 4.3109  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.9563  Validation loss = 4.3108  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.9562  Validation loss = 4.3106  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.9562  Validation loss = 4.3105  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.9561  Validation loss = 4.3104  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.9560  Validation loss = 4.3102  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.9560  Validation loss = 4.3101  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.9559  Validation loss = 4.3099  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.9559  Validation loss = 4.3098  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.9558  Validation loss = 4.3097  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.9557  Validation loss = 4.3096  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.9557  Validation loss = 4.3094  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.9556  Validation loss = 4.3093  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.9555  Validation loss = 4.3091  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.9555  Validation loss = 4.3090  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.9554  Validation loss = 4.3089  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.9553  Validation loss = 4.3086  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.9553  Validation loss = 4.3085  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.9552  Validation loss = 4.3084  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.9552  Validation loss = 4.3082  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.9551  Validation loss = 4.3081  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.9551  Validation loss = 4.3080  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.9550  Validation loss = 4.3078  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.9549  Validation loss = 4.3077  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.9549  Validation loss = 4.3076  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.9548  Validation loss = 4.3074  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.9547  Validation loss = 4.3073  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.9547  Validation loss = 4.3071  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.9546  Validation loss = 4.3070  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.9546  Validation loss = 4.3069  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.9545  Validation loss = 4.3067  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.9544  Validation loss = 4.3066  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.9544  Validation loss = 4.3065  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.9543  Validation loss = 4.3064  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.9543  Validation loss = 4.3062  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.9542  Validation loss = 4.3061  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.9542  Validation loss = 4.3060  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.9541  Validation loss = 4.3058  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.9540  Validation loss = 4.3057  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.9540  Validation loss = 4.3056  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.9539  Validation loss = 4.3054  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.9539  Validation loss = 4.3053  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.9538  Validation loss = 4.3051  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.9537  Validation loss = 4.3050  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.9537  Validation loss = 4.3048  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.9536  Validation loss = 4.3046  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.9535  Validation loss = 4.3045  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.9535  Validation loss = 4.3044  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.9534  Validation loss = 4.3043  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.9534  Validation loss = 4.3042  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.9533  Validation loss = 4.3041  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.9532  Validation loss = 4.3039  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.9532  Validation loss = 4.3037  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.9531  Validation loss = 4.3035  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.9530  Validation loss = 4.3034  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.9530  Validation loss = 4.3032  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.9529  Validation loss = 4.3031  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.9528  Validation loss = 4.3030  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.9528  Validation loss = 4.3028  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.9527  Validation loss = 4.3027  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.9527  Validation loss = 4.3025  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.9526  Validation loss = 4.3024  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.9526  Validation loss = 4.3023  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.9525  Validation loss = 4.3022  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.9525  Validation loss = 4.3021  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.9524  Validation loss = 4.3020  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.9524  Validation loss = 4.3019  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.9523  Validation loss = 4.3017  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.9522  Validation loss = 4.3016  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.9522  Validation loss = 4.3015  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.9521  Validation loss = 4.3014  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.9521  Validation loss = 4.3012  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.9520  Validation loss = 4.3011  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.9519  Validation loss = 4.3009  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.9519  Validation loss = 4.3008  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.9518  Validation loss = 4.3007  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.9518  Validation loss = 4.3006  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.9517  Validation loss = 4.3004  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.9516  Validation loss = 4.3003  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.9516  Validation loss = 4.3002  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.9515  Validation loss = 4.3001  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.9515  Validation loss = 4.2999  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.9514  Validation loss = 4.2998  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.9513  Validation loss = 4.2996  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.9513  Validation loss = 4.2995  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.9512  Validation loss = 4.2993  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.9511  Validation loss = 4.2992  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.9511  Validation loss = 4.2991  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.9510  Validation loss = 4.2990  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.9510  Validation loss = 4.2989  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.9509  Validation loss = 4.2988  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.9509  Validation loss = 4.2987  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.9508  Validation loss = 4.2985  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.9508  Validation loss = 4.2984  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.9507  Validation loss = 4.2983  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.9507  Validation loss = 4.2982  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.9506  Validation loss = 4.2980  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.9505  Validation loss = 4.2979  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.9505  Validation loss = 4.2977  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.9504  Validation loss = 4.2976  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.9503  Validation loss = 4.2974  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.9503  Validation loss = 4.2973  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.9502  Validation loss = 4.2972  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.9502  Validation loss = 4.2971  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.9501  Validation loss = 4.2969  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.9500  Validation loss = 4.2967  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.9500  Validation loss = 4.2966  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.9499  Validation loss = 4.2965  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.9498  Validation loss = 4.2963  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.9498  Validation loss = 4.2962  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.9497  Validation loss = 4.2960  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.9497  Validation loss = 4.2959  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.9496  Validation loss = 4.2958  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.9495  Validation loss = 4.2956  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.9495  Validation loss = 4.2955  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.9494  Validation loss = 4.2953  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.9493  Validation loss = 4.2952  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.9493  Validation loss = 4.2950  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.9492  Validation loss = 4.2949  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.9491  Validation loss = 4.2947  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.9491  Validation loss = 4.2946  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.9491  Validation loss = 4.2946  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.9490  Validation loss = 4.2944  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.9489  Validation loss = 4.2942  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.9489  Validation loss = 4.2941  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.9488  Validation loss = 4.2940  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.9488  Validation loss = 4.2939  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.9487  Validation loss = 4.2937  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.9486  Validation loss = 4.2935  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.9485  Validation loss = 4.2934  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.9485  Validation loss = 4.2932  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.9484  Validation loss = 4.2931  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.9484  Validation loss = 4.2930  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.9483  Validation loss = 4.2928  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.9482  Validation loss = 4.2926  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.9482  Validation loss = 4.2925  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.9481  Validation loss = 4.2924  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.9481  Validation loss = 4.2923  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.9480  Validation loss = 4.2921  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.9480  Validation loss = 4.2920  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.9479  Validation loss = 4.2919  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.9479  Validation loss = 4.2918  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.9478  Validation loss = 4.2916  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.9478  Validation loss = 4.2915  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.9477  Validation loss = 4.2914  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.9476  Validation loss = 4.2913  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.9476  Validation loss = 4.2912  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.9475  Validation loss = 4.2910  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.9474  Validation loss = 4.2908  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.9474  Validation loss = 4.2906  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.9473  Validation loss = 4.2905  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.9473  Validation loss = 4.2904  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.9472  Validation loss = 4.2903  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.9472  Validation loss = 4.2902  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.9471  Validation loss = 4.2901  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.9471  Validation loss = 4.2900  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.9470  Validation loss = 4.2898  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.9469  Validation loss = 4.2897  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.9469  Validation loss = 4.2896  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.9468  Validation loss = 4.2894  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.9468  Validation loss = 4.2893  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.9467  Validation loss = 4.2891  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.9467  Validation loss = 4.2890  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.9466  Validation loss = 4.2889  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.9465  Validation loss = 4.2888  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.9465  Validation loss = 4.2885  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.9464  Validation loss = 4.2884  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.9463  Validation loss = 4.2883  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.9463  Validation loss = 4.2882  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.9462  Validation loss = 4.2880  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.9461  Validation loss = 4.2878  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.9461  Validation loss = 4.2877  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.9460  Validation loss = 4.2875  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.9459  Validation loss = 4.2873  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.9459  Validation loss = 4.2872  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.9458  Validation loss = 4.2870  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.9458  Validation loss = 4.2869  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.9457  Validation loss = 4.2868  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.9457  Validation loss = 4.2867  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.9456  Validation loss = 4.2865  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.9455  Validation loss = 4.2864  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.9455  Validation loss = 4.2862  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.9454  Validation loss = 4.2861  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.9453  Validation loss = 4.2860  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.9453  Validation loss = 4.2858  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.9452  Validation loss = 4.2857  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.9452  Validation loss = 4.2856  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.9451  Validation loss = 4.2855  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.9451  Validation loss = 4.2853  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.9450  Validation loss = 4.2852  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.9450  Validation loss = 4.2850  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.9449  Validation loss = 4.2849  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.9448  Validation loss = 4.2848  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.9448  Validation loss = 4.2847  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.9447  Validation loss = 4.2846  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.9447  Validation loss = 4.2844  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.9446  Validation loss = 4.2843  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.9446  Validation loss = 4.2841  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.9445  Validation loss = 4.2840  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.9444  Validation loss = 4.2838  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.9444  Validation loss = 4.2837  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.9443  Validation loss = 4.2835  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.9443  Validation loss = 4.2835  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.9442  Validation loss = 4.2833  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.9442  Validation loss = 4.2832  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.9441  Validation loss = 4.2831  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.9440  Validation loss = 4.2829  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.9440  Validation loss = 4.2828  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.9439  Validation loss = 4.2827  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.9439  Validation loss = 4.2826  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.9438  Validation loss = 4.2825  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.9438  Validation loss = 4.2823  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.9437  Validation loss = 4.2822  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.9437  Validation loss = 4.2821  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.9436  Validation loss = 4.2819  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.9435  Validation loss = 4.2818  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.9435  Validation loss = 4.2817  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.9434  Validation loss = 4.2815  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.9434  Validation loss = 4.2814  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.9433  Validation loss = 4.2813  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.9433  Validation loss = 4.2812  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.9432  Validation loss = 4.2811  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.9431  Validation loss = 4.2809  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.9431  Validation loss = 4.2807  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.9430  Validation loss = 4.2806  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.9429  Validation loss = 4.2804  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.9429  Validation loss = 4.2803  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.9428  Validation loss = 4.2801  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.9428  Validation loss = 4.2800  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.9427  Validation loss = 4.2799  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.9426  Validation loss = 4.2797  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.9426  Validation loss = 4.2796  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.9425  Validation loss = 4.2795  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.9425  Validation loss = 4.2794  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.9424  Validation loss = 4.2792  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.9424  Validation loss = 4.2791  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.9423  Validation loss = 4.2790  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.9422  Validation loss = 4.2789  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.9422  Validation loss = 4.2787  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.9421  Validation loss = 4.2786  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.9421  Validation loss = 4.2785  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.9420  Validation loss = 4.2783  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.9419  Validation loss = 4.2782  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.9419  Validation loss = 4.2781  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.9418  Validation loss = 4.2780  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.9418  Validation loss = 4.2778  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.9417  Validation loss = 4.2777  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.9417  Validation loss = 4.2776  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.9416  Validation loss = 4.2775  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.9416  Validation loss = 4.2773  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.9415  Validation loss = 4.2772  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.9415  Validation loss = 4.2771  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.9414  Validation loss = 4.2769  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.9413  Validation loss = 4.2768  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.9413  Validation loss = 4.2767  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.9412  Validation loss = 4.2765  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.9412  Validation loss = 4.2764  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.9411  Validation loss = 4.2763  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.9410  Validation loss = 4.2762  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.9410  Validation loss = 4.2760  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.9409  Validation loss = 4.2759  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.9409  Validation loss = 4.2758  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.9408  Validation loss = 4.2757  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.9408  Validation loss = 4.2756  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.9407  Validation loss = 4.2755  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.9407  Validation loss = 4.2753  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.9406  Validation loss = 4.2752  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.9405  Validation loss = 4.2750  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.9405  Validation loss = 4.2749  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.9404  Validation loss = 4.2747  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.9404  Validation loss = 4.2746  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.9403  Validation loss = 4.2745  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.9402  Validation loss = 4.2744  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.9402  Validation loss = 4.2743  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.9401  Validation loss = 4.2741  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.9401  Validation loss = 4.2740  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.9400  Validation loss = 4.2739  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.9400  Validation loss = 4.2737  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.9399  Validation loss = 4.2736  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.9399  Validation loss = 4.2735  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.9398  Validation loss = 4.2734  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.9398  Validation loss = 4.2733  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.9397  Validation loss = 4.2732  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.9396  Validation loss = 4.2730  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.9396  Validation loss = 4.2729  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.9395  Validation loss = 4.2728  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.9395  Validation loss = 4.2727  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.9394  Validation loss = 4.2726  \n",
      "\n",
      "Fold: 3  Epoch: 501  Training loss = 1.9394  Validation loss = 4.2725  \n",
      "\n",
      "Fold: 3  Epoch: 502  Training loss = 1.9393  Validation loss = 4.2724  \n",
      "\n",
      "Fold: 3  Epoch: 503  Training loss = 1.9393  Validation loss = 4.2722  \n",
      "\n",
      "Fold: 3  Epoch: 504  Training loss = 1.9392  Validation loss = 4.2721  \n",
      "\n",
      "Fold: 3  Epoch: 505  Training loss = 1.9392  Validation loss = 4.2720  \n",
      "\n",
      "Fold: 3  Epoch: 506  Training loss = 1.9391  Validation loss = 4.2719  \n",
      "\n",
      "Fold: 3  Epoch: 507  Training loss = 1.9391  Validation loss = 4.2717  \n",
      "\n",
      "Fold: 3  Epoch: 508  Training loss = 1.9390  Validation loss = 4.2716  \n",
      "\n",
      "Fold: 3  Epoch: 509  Training loss = 1.9389  Validation loss = 4.2715  \n",
      "\n",
      "Fold: 3  Epoch: 510  Training loss = 1.9389  Validation loss = 4.2713  \n",
      "\n",
      "Fold: 3  Epoch: 511  Training loss = 1.9388  Validation loss = 4.2712  \n",
      "\n",
      "Fold: 3  Epoch: 512  Training loss = 1.9388  Validation loss = 4.2711  \n",
      "\n",
      "Fold: 3  Epoch: 513  Training loss = 1.9387  Validation loss = 4.2710  \n",
      "\n",
      "Fold: 3  Epoch: 514  Training loss = 1.9387  Validation loss = 4.2708  \n",
      "\n",
      "Fold: 3  Epoch: 515  Training loss = 1.9386  Validation loss = 4.2707  \n",
      "\n",
      "Fold: 3  Epoch: 516  Training loss = 1.9385  Validation loss = 4.2705  \n",
      "\n",
      "Fold: 3  Epoch: 517  Training loss = 1.9385  Validation loss = 4.2704  \n",
      "\n",
      "Fold: 3  Epoch: 518  Training loss = 1.9384  Validation loss = 4.2702  \n",
      "\n",
      "Fold: 3  Epoch: 519  Training loss = 1.9383  Validation loss = 4.2701  \n",
      "\n",
      "Fold: 3  Epoch: 520  Training loss = 1.9383  Validation loss = 4.2699  \n",
      "\n",
      "Fold: 3  Epoch: 521  Training loss = 1.9382  Validation loss = 4.2697  \n",
      "\n",
      "Fold: 3  Epoch: 522  Training loss = 1.9381  Validation loss = 4.2696  \n",
      "\n",
      "Fold: 3  Epoch: 523  Training loss = 1.9381  Validation loss = 4.2694  \n",
      "\n",
      "Fold: 3  Epoch: 524  Training loss = 1.9380  Validation loss = 4.2693  \n",
      "\n",
      "Fold: 3  Epoch: 525  Training loss = 1.9379  Validation loss = 4.2692  \n",
      "\n",
      "Fold: 3  Epoch: 526  Training loss = 1.9379  Validation loss = 4.2690  \n",
      "\n",
      "Fold: 3  Epoch: 527  Training loss = 1.9378  Validation loss = 4.2689  \n",
      "\n",
      "Fold: 3  Epoch: 528  Training loss = 1.9378  Validation loss = 4.2687  \n",
      "\n",
      "Fold: 3  Epoch: 529  Training loss = 1.9377  Validation loss = 4.2685  \n",
      "\n",
      "Fold: 3  Epoch: 530  Training loss = 1.9376  Validation loss = 4.2684  \n",
      "\n",
      "Fold: 3  Epoch: 531  Training loss = 1.9376  Validation loss = 4.2683  \n",
      "\n",
      "Fold: 3  Epoch: 532  Training loss = 1.9375  Validation loss = 4.2681  \n",
      "\n",
      "Fold: 3  Epoch: 533  Training loss = 1.9374  Validation loss = 4.2680  \n",
      "\n",
      "Fold: 3  Epoch: 534  Training loss = 1.9374  Validation loss = 4.2678  \n",
      "\n",
      "Fold: 3  Epoch: 535  Training loss = 1.9373  Validation loss = 4.2677  \n",
      "\n",
      "Fold: 3  Epoch: 536  Training loss = 1.9373  Validation loss = 4.2675  \n",
      "\n",
      "Fold: 3  Epoch: 537  Training loss = 1.9372  Validation loss = 4.2674  \n",
      "\n",
      "Fold: 3  Epoch: 538  Training loss = 1.9371  Validation loss = 4.2672  \n",
      "\n",
      "Fold: 3  Epoch: 539  Training loss = 1.9371  Validation loss = 4.2671  \n",
      "\n",
      "Fold: 3  Epoch: 540  Training loss = 1.9370  Validation loss = 4.2670  \n",
      "\n",
      "Fold: 3  Epoch: 541  Training loss = 1.9370  Validation loss = 4.2669  \n",
      "\n",
      "Fold: 3  Epoch: 542  Training loss = 1.9369  Validation loss = 4.2667  \n",
      "\n",
      "Fold: 3  Epoch: 543  Training loss = 1.9369  Validation loss = 4.2666  \n",
      "\n",
      "Fold: 3  Epoch: 544  Training loss = 1.9368  Validation loss = 4.2664  \n",
      "\n",
      "Fold: 3  Epoch: 545  Training loss = 1.9367  Validation loss = 4.2663  \n",
      "\n",
      "Fold: 3  Epoch: 546  Training loss = 1.9367  Validation loss = 4.2662  \n",
      "\n",
      "Fold: 3  Epoch: 547  Training loss = 1.9366  Validation loss = 4.2660  \n",
      "\n",
      "Fold: 3  Epoch: 548  Training loss = 1.9365  Validation loss = 4.2658  \n",
      "\n",
      "Fold: 3  Epoch: 549  Training loss = 1.9365  Validation loss = 4.2657  \n",
      "\n",
      "Fold: 3  Epoch: 550  Training loss = 1.9364  Validation loss = 4.2656  \n",
      "\n",
      "Fold: 3  Epoch: 551  Training loss = 1.9364  Validation loss = 4.2655  \n",
      "\n",
      "Fold: 3  Epoch: 552  Training loss = 1.9363  Validation loss = 4.2653  \n",
      "\n",
      "Fold: 3  Epoch: 553  Training loss = 1.9362  Validation loss = 4.2652  \n",
      "\n",
      "Fold: 3  Epoch: 554  Training loss = 1.9362  Validation loss = 4.2650  \n",
      "\n",
      "Fold: 3  Epoch: 555  Training loss = 1.9361  Validation loss = 4.2649  \n",
      "\n",
      "Fold: 3  Epoch: 556  Training loss = 1.9361  Validation loss = 4.2648  \n",
      "\n",
      "Fold: 3  Epoch: 557  Training loss = 1.9360  Validation loss = 4.2646  \n",
      "\n",
      "Fold: 3  Epoch: 558  Training loss = 1.9360  Validation loss = 4.2645  \n",
      "\n",
      "Fold: 3  Epoch: 559  Training loss = 1.9359  Validation loss = 4.2644  \n",
      "\n",
      "Fold: 3  Epoch: 560  Training loss = 1.9358  Validation loss = 4.2642  \n",
      "\n",
      "Fold: 3  Epoch: 561  Training loss = 1.9358  Validation loss = 4.2641  \n",
      "\n",
      "Fold: 3  Epoch: 562  Training loss = 1.9357  Validation loss = 4.2639  \n",
      "\n",
      "Fold: 3  Epoch: 563  Training loss = 1.9357  Validation loss = 4.2638  \n",
      "\n",
      "Fold: 3  Epoch: 564  Training loss = 1.9356  Validation loss = 4.2637  \n",
      "\n",
      "Fold: 3  Epoch: 565  Training loss = 1.9355  Validation loss = 4.2636  \n",
      "\n",
      "Fold: 3  Epoch: 566  Training loss = 1.9355  Validation loss = 4.2634  \n",
      "\n",
      "Fold: 3  Epoch: 567  Training loss = 1.9354  Validation loss = 4.2633  \n",
      "\n",
      "Fold: 3  Epoch: 568  Training loss = 1.9354  Validation loss = 4.2631  \n",
      "\n",
      "Fold: 3  Epoch: 569  Training loss = 1.9353  Validation loss = 4.2630  \n",
      "\n",
      "Fold: 3  Epoch: 570  Training loss = 1.9352  Validation loss = 4.2629  \n",
      "\n",
      "Fold: 3  Epoch: 571  Training loss = 1.9352  Validation loss = 4.2628  \n",
      "\n",
      "Fold: 3  Epoch: 572  Training loss = 1.9351  Validation loss = 4.2626  \n",
      "\n",
      "Fold: 3  Epoch: 573  Training loss = 1.9351  Validation loss = 4.2625  \n",
      "\n",
      "Fold: 3  Epoch: 574  Training loss = 1.9350  Validation loss = 4.2624  \n",
      "\n",
      "Fold: 3  Epoch: 575  Training loss = 1.9350  Validation loss = 4.2623  \n",
      "\n",
      "Fold: 3  Epoch: 576  Training loss = 1.9349  Validation loss = 4.2622  \n",
      "\n",
      "Fold: 3  Epoch: 577  Training loss = 1.9349  Validation loss = 4.2621  \n",
      "\n",
      "Fold: 3  Epoch: 578  Training loss = 1.9348  Validation loss = 4.2620  \n",
      "\n",
      "Fold: 3  Epoch: 579  Training loss = 1.9348  Validation loss = 4.2618  \n",
      "\n",
      "Fold: 3  Epoch: 580  Training loss = 1.9347  Validation loss = 4.2617  \n",
      "\n",
      "Fold: 3  Epoch: 581  Training loss = 1.9347  Validation loss = 4.2616  \n",
      "\n",
      "Fold: 3  Epoch: 582  Training loss = 1.9346  Validation loss = 4.2614  \n",
      "\n",
      "Fold: 3  Epoch: 583  Training loss = 1.9345  Validation loss = 4.2613  \n",
      "\n",
      "Fold: 3  Epoch: 584  Training loss = 1.9345  Validation loss = 4.2612  \n",
      "\n",
      "Fold: 3  Epoch: 585  Training loss = 1.9344  Validation loss = 4.2611  \n",
      "\n",
      "Fold: 3  Epoch: 586  Training loss = 1.9344  Validation loss = 4.2610  \n",
      "\n",
      "Fold: 3  Epoch: 587  Training loss = 1.9343  Validation loss = 4.2609  \n",
      "\n",
      "Fold: 3  Epoch: 588  Training loss = 1.9343  Validation loss = 4.2608  \n",
      "\n",
      "Fold: 3  Epoch: 589  Training loss = 1.9342  Validation loss = 4.2607  \n",
      "\n",
      "Fold: 3  Epoch: 590  Training loss = 1.9342  Validation loss = 4.2605  \n",
      "\n",
      "Fold: 3  Epoch: 591  Training loss = 1.9341  Validation loss = 4.2604  \n",
      "\n",
      "Fold: 3  Epoch: 592  Training loss = 1.9341  Validation loss = 4.2603  \n",
      "\n",
      "Fold: 3  Epoch: 593  Training loss = 1.9340  Validation loss = 4.2602  \n",
      "\n",
      "Fold: 3  Epoch: 594  Training loss = 1.9340  Validation loss = 4.2601  \n",
      "\n",
      "Fold: 3  Epoch: 595  Training loss = 1.9339  Validation loss = 4.2600  \n",
      "\n",
      "Fold: 3  Epoch: 596  Training loss = 1.9339  Validation loss = 4.2599  \n",
      "\n",
      "Fold: 3  Epoch: 597  Training loss = 1.9338  Validation loss = 4.2598  \n",
      "\n",
      "Fold: 3  Epoch: 598  Training loss = 1.9338  Validation loss = 4.2597  \n",
      "\n",
      "Fold: 3  Epoch: 599  Training loss = 1.9337  Validation loss = 4.2594  \n",
      "\n",
      "Fold: 3  Epoch: 600  Training loss = 1.9336  Validation loss = 4.2593  \n",
      "\n",
      "Fold: 3  Epoch: 601  Training loss = 1.9336  Validation loss = 4.2592  \n",
      "\n",
      "Fold: 3  Epoch: 602  Training loss = 1.9336  Validation loss = 4.2591  \n",
      "\n",
      "Fold: 3  Epoch: 603  Training loss = 1.9335  Validation loss = 4.2590  \n",
      "\n",
      "Fold: 3  Epoch: 604  Training loss = 1.9334  Validation loss = 4.2589  \n",
      "\n",
      "Fold: 3  Epoch: 605  Training loss = 1.9334  Validation loss = 4.2587  \n",
      "\n",
      "Fold: 3  Epoch: 606  Training loss = 1.9333  Validation loss = 4.2586  \n",
      "\n",
      "Fold: 3  Epoch: 607  Training loss = 1.9333  Validation loss = 4.2585  \n",
      "\n",
      "Fold: 3  Epoch: 608  Training loss = 1.9332  Validation loss = 4.2583  \n",
      "\n",
      "Fold: 3  Epoch: 609  Training loss = 1.9332  Validation loss = 4.2582  \n",
      "\n",
      "Fold: 3  Epoch: 610  Training loss = 1.9331  Validation loss = 4.2581  \n",
      "\n",
      "Fold: 3  Epoch: 611  Training loss = 1.9330  Validation loss = 4.2579  \n",
      "\n",
      "Fold: 3  Epoch: 612  Training loss = 1.9330  Validation loss = 4.2578  \n",
      "\n",
      "Fold: 3  Epoch: 613  Training loss = 1.9329  Validation loss = 4.2577  \n",
      "\n",
      "Fold: 3  Epoch: 614  Training loss = 1.9329  Validation loss = 4.2576  \n",
      "\n",
      "Fold: 3  Epoch: 615  Training loss = 1.9328  Validation loss = 4.2575  \n",
      "\n",
      "Fold: 3  Epoch: 616  Training loss = 1.9328  Validation loss = 4.2574  \n",
      "\n",
      "Fold: 3  Epoch: 617  Training loss = 1.9327  Validation loss = 4.2573  \n",
      "\n",
      "Fold: 3  Epoch: 618  Training loss = 1.9327  Validation loss = 4.2571  \n",
      "\n",
      "Fold: 3  Epoch: 619  Training loss = 1.9326  Validation loss = 4.2570  \n",
      "\n",
      "Fold: 3  Epoch: 620  Training loss = 1.9326  Validation loss = 4.2569  \n",
      "\n",
      "Fold: 3  Epoch: 621  Training loss = 1.9325  Validation loss = 4.2567  \n",
      "\n",
      "Fold: 3  Epoch: 622  Training loss = 1.9324  Validation loss = 4.2565  \n",
      "\n",
      "Fold: 3  Epoch: 623  Training loss = 1.9324  Validation loss = 4.2564  \n",
      "\n",
      "Fold: 3  Epoch: 624  Training loss = 1.9323  Validation loss = 4.2563  \n",
      "\n",
      "Fold: 3  Epoch: 625  Training loss = 1.9323  Validation loss = 4.2562  \n",
      "\n",
      "Fold: 3  Epoch: 626  Training loss = 1.9322  Validation loss = 4.2561  \n",
      "\n",
      "Fold: 3  Epoch: 627  Training loss = 1.9322  Validation loss = 4.2560  \n",
      "\n",
      "Fold: 3  Epoch: 628  Training loss = 1.9321  Validation loss = 4.2559  \n",
      "\n",
      "Fold: 3  Epoch: 629  Training loss = 1.9321  Validation loss = 4.2557  \n",
      "\n",
      "Fold: 3  Epoch: 630  Training loss = 1.9320  Validation loss = 4.2556  \n",
      "\n",
      "Fold: 3  Epoch: 631  Training loss = 1.9319  Validation loss = 4.2554  \n",
      "\n",
      "Fold: 3  Epoch: 632  Training loss = 1.9319  Validation loss = 4.2553  \n",
      "\n",
      "Fold: 3  Epoch: 633  Training loss = 1.9318  Validation loss = 4.2552  \n",
      "\n",
      "Fold: 3  Epoch: 634  Training loss = 1.9318  Validation loss = 4.2551  \n",
      "\n",
      "Fold: 3  Epoch: 635  Training loss = 1.9317  Validation loss = 4.2550  \n",
      "\n",
      "Fold: 3  Epoch: 636  Training loss = 1.9317  Validation loss = 4.2549  \n",
      "\n",
      "Fold: 3  Epoch: 637  Training loss = 1.9316  Validation loss = 4.2548  \n",
      "\n",
      "Fold: 3  Epoch: 638  Training loss = 1.9316  Validation loss = 4.2547  \n",
      "\n",
      "Fold: 3  Epoch: 639  Training loss = 1.9315  Validation loss = 4.2545  \n",
      "\n",
      "Fold: 3  Epoch: 640  Training loss = 1.9315  Validation loss = 4.2544  \n",
      "\n",
      "Fold: 3  Epoch: 641  Training loss = 1.9314  Validation loss = 4.2543  \n",
      "\n",
      "Fold: 3  Epoch: 642  Training loss = 1.9314  Validation loss = 4.2542  \n",
      "\n",
      "Fold: 3  Epoch: 643  Training loss = 1.9313  Validation loss = 4.2541  \n",
      "\n",
      "Fold: 3  Epoch: 644  Training loss = 1.9313  Validation loss = 4.2539  \n",
      "\n",
      "Fold: 3  Epoch: 645  Training loss = 1.9312  Validation loss = 4.2538  \n",
      "\n",
      "Fold: 3  Epoch: 646  Training loss = 1.9311  Validation loss = 4.2536  \n",
      "\n",
      "Fold: 3  Epoch: 647  Training loss = 1.9311  Validation loss = 4.2535  \n",
      "\n",
      "Fold: 3  Epoch: 648  Training loss = 1.9310  Validation loss = 4.2533  \n",
      "\n",
      "Fold: 3  Epoch: 649  Training loss = 1.9310  Validation loss = 4.2532  \n",
      "\n",
      "Fold: 3  Epoch: 650  Training loss = 1.9309  Validation loss = 4.2531  \n",
      "\n",
      "Fold: 3  Epoch: 651  Training loss = 1.9309  Validation loss = 4.2530  \n",
      "\n",
      "Fold: 3  Epoch: 652  Training loss = 1.9308  Validation loss = 4.2529  \n",
      "\n",
      "Fold: 3  Epoch: 653  Training loss = 1.9307  Validation loss = 4.2528  \n",
      "\n",
      "Fold: 3  Epoch: 654  Training loss = 1.9307  Validation loss = 4.2526  \n",
      "\n",
      "Fold: 3  Epoch: 655  Training loss = 1.9306  Validation loss = 4.2525  \n",
      "\n",
      "Fold: 3  Epoch: 656  Training loss = 1.9306  Validation loss = 4.2524  \n",
      "\n",
      "Fold: 3  Epoch: 657  Training loss = 1.9305  Validation loss = 4.2522  \n",
      "\n",
      "Fold: 3  Epoch: 658  Training loss = 1.9304  Validation loss = 4.2521  \n",
      "\n",
      "Fold: 3  Epoch: 659  Training loss = 1.9304  Validation loss = 4.2520  \n",
      "\n",
      "Fold: 3  Epoch: 660  Training loss = 1.9303  Validation loss = 4.2518  \n",
      "\n",
      "Fold: 3  Epoch: 661  Training loss = 1.9303  Validation loss = 4.2517  \n",
      "\n",
      "Fold: 3  Epoch: 662  Training loss = 1.9302  Validation loss = 4.2516  \n",
      "\n",
      "Fold: 3  Epoch: 663  Training loss = 1.9302  Validation loss = 4.2515  \n",
      "\n",
      "Fold: 3  Epoch: 664  Training loss = 1.9301  Validation loss = 4.2513  \n",
      "\n",
      "Fold: 3  Epoch: 665  Training loss = 1.9300  Validation loss = 4.2512  \n",
      "\n",
      "Fold: 3  Epoch: 666  Training loss = 1.9300  Validation loss = 4.2511  \n",
      "\n",
      "Fold: 3  Epoch: 667  Training loss = 1.9299  Validation loss = 4.2509  \n",
      "\n",
      "Fold: 3  Epoch: 668  Training loss = 1.9299  Validation loss = 4.2508  \n",
      "\n",
      "Fold: 3  Epoch: 669  Training loss = 1.9298  Validation loss = 4.2507  \n",
      "\n",
      "Fold: 3  Epoch: 670  Training loss = 1.9298  Validation loss = 4.2506  \n",
      "\n",
      "Fold: 3  Epoch: 671  Training loss = 1.9297  Validation loss = 4.2505  \n",
      "\n",
      "Fold: 3  Epoch: 672  Training loss = 1.9297  Validation loss = 4.2503  \n",
      "\n",
      "Fold: 3  Epoch: 673  Training loss = 1.9296  Validation loss = 4.2501  \n",
      "\n",
      "Fold: 3  Epoch: 674  Training loss = 1.9296  Validation loss = 4.2500  \n",
      "\n",
      "Fold: 3  Epoch: 675  Training loss = 1.9295  Validation loss = 4.2499  \n",
      "\n",
      "Fold: 3  Epoch: 676  Training loss = 1.9295  Validation loss = 4.2498  \n",
      "\n",
      "Fold: 3  Epoch: 677  Training loss = 1.9294  Validation loss = 4.2497  \n",
      "\n",
      "Fold: 3  Epoch: 678  Training loss = 1.9293  Validation loss = 4.2495  \n",
      "\n",
      "Fold: 3  Epoch: 679  Training loss = 1.9293  Validation loss = 4.2494  \n",
      "\n",
      "Fold: 3  Epoch: 680  Training loss = 1.9292  Validation loss = 4.2492  \n",
      "\n",
      "Fold: 3  Epoch: 681  Training loss = 1.9292  Validation loss = 4.2492  \n",
      "\n",
      "Fold: 3  Epoch: 682  Training loss = 1.9291  Validation loss = 4.2491  \n",
      "\n",
      "Fold: 3  Epoch: 683  Training loss = 1.9291  Validation loss = 4.2489  \n",
      "\n",
      "Fold: 3  Epoch: 684  Training loss = 1.9290  Validation loss = 4.2488  \n",
      "\n",
      "Fold: 3  Epoch: 685  Training loss = 1.9289  Validation loss = 4.2487  \n",
      "\n",
      "Fold: 3  Epoch: 686  Training loss = 1.9289  Validation loss = 4.2486  \n",
      "\n",
      "Fold: 3  Epoch: 687  Training loss = 1.9288  Validation loss = 4.2484  \n",
      "\n",
      "Fold: 3  Epoch: 688  Training loss = 1.9288  Validation loss = 4.2483  \n",
      "\n",
      "Fold: 3  Epoch: 689  Training loss = 1.9287  Validation loss = 4.2482  \n",
      "\n",
      "Fold: 3  Epoch: 690  Training loss = 1.9287  Validation loss = 4.2481  \n",
      "\n",
      "Fold: 3  Epoch: 691  Training loss = 1.9286  Validation loss = 4.2480  \n",
      "\n",
      "Fold: 3  Epoch: 692  Training loss = 1.9286  Validation loss = 4.2479  \n",
      "\n",
      "Fold: 3  Epoch: 693  Training loss = 1.9285  Validation loss = 4.2477  \n",
      "\n",
      "Fold: 3  Epoch: 694  Training loss = 1.9285  Validation loss = 4.2476  \n",
      "\n",
      "Fold: 3  Epoch: 695  Training loss = 1.9284  Validation loss = 4.2475  \n",
      "\n",
      "Fold: 3  Epoch: 696  Training loss = 1.9284  Validation loss = 4.2473  \n",
      "\n",
      "Fold: 3  Epoch: 697  Training loss = 1.9283  Validation loss = 4.2472  \n",
      "\n",
      "Fold: 3  Epoch: 698  Training loss = 1.9282  Validation loss = 4.2470  \n",
      "\n",
      "Fold: 3  Epoch: 699  Training loss = 1.9282  Validation loss = 4.2469  \n",
      "\n",
      "Fold: 3  Epoch: 700  Training loss = 1.9281  Validation loss = 4.2467  \n",
      "\n",
      "Fold: 3  Epoch: 701  Training loss = 1.9280  Validation loss = 4.2466  \n",
      "\n",
      "Fold: 3  Epoch: 702  Training loss = 1.9280  Validation loss = 4.2464  \n",
      "\n",
      "Fold: 3  Epoch: 703  Training loss = 1.9279  Validation loss = 4.2463  \n",
      "\n",
      "Fold: 3  Epoch: 704  Training loss = 1.9279  Validation loss = 4.2462  \n",
      "\n",
      "Fold: 3  Epoch: 705  Training loss = 1.9278  Validation loss = 4.2461  \n",
      "\n",
      "Fold: 3  Epoch: 706  Training loss = 1.9278  Validation loss = 4.2460  \n",
      "\n",
      "Fold: 3  Epoch: 707  Training loss = 1.9277  Validation loss = 4.2459  \n",
      "\n",
      "Fold: 3  Epoch: 708  Training loss = 1.9277  Validation loss = 4.2457  \n",
      "\n",
      "Fold: 3  Epoch: 709  Training loss = 1.9276  Validation loss = 4.2456  \n",
      "\n",
      "Fold: 3  Epoch: 710  Training loss = 1.9276  Validation loss = 4.2455  \n",
      "\n",
      "Fold: 3  Epoch: 711  Training loss = 1.9275  Validation loss = 4.2454  \n",
      "\n",
      "Fold: 3  Epoch: 712  Training loss = 1.9275  Validation loss = 4.2453  \n",
      "\n",
      "Fold: 3  Epoch: 713  Training loss = 1.9274  Validation loss = 4.2451  \n",
      "\n",
      "Fold: 3  Epoch: 714  Training loss = 1.9274  Validation loss = 4.2450  \n",
      "\n",
      "Fold: 3  Epoch: 715  Training loss = 1.9273  Validation loss = 4.2449  \n",
      "\n",
      "Fold: 3  Epoch: 716  Training loss = 1.9272  Validation loss = 4.2448  \n",
      "\n",
      "Fold: 3  Epoch: 717  Training loss = 1.9272  Validation loss = 4.2446  \n",
      "\n",
      "Fold: 3  Epoch: 718  Training loss = 1.9271  Validation loss = 4.2445  \n",
      "\n",
      "Fold: 3  Epoch: 719  Training loss = 1.9271  Validation loss = 4.2444  \n",
      "\n",
      "Fold: 3  Epoch: 720  Training loss = 1.9270  Validation loss = 4.2443  \n",
      "\n",
      "Fold: 3  Epoch: 721  Training loss = 1.9270  Validation loss = 4.2441  \n",
      "\n",
      "Fold: 3  Epoch: 722  Training loss = 1.9269  Validation loss = 4.2440  \n",
      "\n",
      "Fold: 3  Epoch: 723  Training loss = 1.9269  Validation loss = 4.2439  \n",
      "\n",
      "Fold: 3  Epoch: 724  Training loss = 1.9268  Validation loss = 4.2437  \n",
      "\n",
      "Fold: 3  Epoch: 725  Training loss = 1.9268  Validation loss = 4.2437  \n",
      "\n",
      "Fold: 3  Epoch: 726  Training loss = 1.9267  Validation loss = 4.2435  \n",
      "\n",
      "Fold: 3  Epoch: 727  Training loss = 1.9267  Validation loss = 4.2434  \n",
      "\n",
      "Fold: 3  Epoch: 728  Training loss = 1.9266  Validation loss = 4.2433  \n",
      "\n",
      "Fold: 3  Epoch: 729  Training loss = 1.9265  Validation loss = 4.2431  \n",
      "\n",
      "Fold: 3  Epoch: 730  Training loss = 1.9265  Validation loss = 4.2430  \n",
      "\n",
      "Fold: 3  Epoch: 731  Training loss = 1.9264  Validation loss = 4.2429  \n",
      "\n",
      "Fold: 3  Epoch: 732  Training loss = 1.9264  Validation loss = 4.2428  \n",
      "\n",
      "Fold: 3  Epoch: 733  Training loss = 1.9263  Validation loss = 4.2426  \n",
      "\n",
      "Fold: 3  Epoch: 734  Training loss = 1.9263  Validation loss = 4.2424  \n",
      "\n",
      "Fold: 3  Epoch: 735  Training loss = 1.9262  Validation loss = 4.2423  \n",
      "\n",
      "Fold: 3  Epoch: 736  Training loss = 1.9261  Validation loss = 4.2422  \n",
      "\n",
      "Fold: 3  Epoch: 737  Training loss = 1.9261  Validation loss = 4.2420  \n",
      "\n",
      "Fold: 3  Epoch: 738  Training loss = 1.9260  Validation loss = 4.2419  \n",
      "\n",
      "Fold: 3  Epoch: 739  Training loss = 1.9260  Validation loss = 4.2418  \n",
      "\n",
      "Fold: 3  Epoch: 740  Training loss = 1.9259  Validation loss = 4.2417  \n",
      "\n",
      "Fold: 3  Epoch: 741  Training loss = 1.9259  Validation loss = 4.2416  \n",
      "\n",
      "Fold: 3  Epoch: 742  Training loss = 1.9258  Validation loss = 4.2415  \n",
      "\n",
      "Fold: 3  Epoch: 743  Training loss = 1.9258  Validation loss = 4.2413  \n",
      "\n",
      "Fold: 3  Epoch: 744  Training loss = 1.9257  Validation loss = 4.2412  \n",
      "\n",
      "Fold: 3  Epoch: 745  Training loss = 1.9256  Validation loss = 4.2410  \n",
      "\n",
      "Fold: 3  Epoch: 746  Training loss = 1.9256  Validation loss = 4.2409  \n",
      "\n",
      "Fold: 3  Epoch: 747  Training loss = 1.9255  Validation loss = 4.2408  \n",
      "\n",
      "Fold: 3  Epoch: 748  Training loss = 1.9255  Validation loss = 4.2407  \n",
      "\n",
      "Fold: 3  Epoch: 749  Training loss = 1.9254  Validation loss = 4.2405  \n",
      "\n",
      "Fold: 3  Epoch: 750  Training loss = 1.9254  Validation loss = 4.2404  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 750  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 2.0661  Validation loss = 5.3870  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 2.0660  Validation loss = 5.3869  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 2.0659  Validation loss = 5.3868  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 2.0658  Validation loss = 5.3867  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 2.0658  Validation loss = 5.3866  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 2.0657  Validation loss = 5.3865  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 2.0657  Validation loss = 5.3864  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 2.0656  Validation loss = 5.3863  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 2.0655  Validation loss = 5.3861  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 2.0654  Validation loss = 5.3861  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 2.0654  Validation loss = 5.3859  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 2.0653  Validation loss = 5.3858  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 2.0652  Validation loss = 5.3857  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 2.0651  Validation loss = 5.3856  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 2.0650  Validation loss = 5.3854  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 2.0649  Validation loss = 5.3853  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 2.0648  Validation loss = 5.3852  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 2.0648  Validation loss = 5.3850  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 2.0647  Validation loss = 5.3849  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 2.0646  Validation loss = 5.3848  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 2.0645  Validation loss = 5.3847  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 2.0644  Validation loss = 5.3845  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 2.0644  Validation loss = 5.3844  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 2.0643  Validation loss = 5.3843  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 2.0642  Validation loss = 5.3842  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 2.0642  Validation loss = 5.3841  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 2.0641  Validation loss = 5.3840  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 2.0640  Validation loss = 5.3839  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 2.0639  Validation loss = 5.3838  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 2.0639  Validation loss = 5.3836  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 2.0637  Validation loss = 5.3834  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 2.0636  Validation loss = 5.3833  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 2.0635  Validation loss = 5.3832  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 2.0635  Validation loss = 5.3830  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 2.0634  Validation loss = 5.3830  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 2.0633  Validation loss = 5.3828  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 2.0632  Validation loss = 5.3827  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 2.0632  Validation loss = 5.3826  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 2.0631  Validation loss = 5.3825  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 2.0630  Validation loss = 5.3824  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 2.0629  Validation loss = 5.3822  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 2.0629  Validation loss = 5.3821  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 2.0628  Validation loss = 5.3820  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 2.0627  Validation loss = 5.3818  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 2.0626  Validation loss = 5.3817  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 2.0625  Validation loss = 5.3816  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 2.0625  Validation loss = 5.3815  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 2.0624  Validation loss = 5.3814  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 2.0623  Validation loss = 5.3813  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 2.0622  Validation loss = 5.3812  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 2.0621  Validation loss = 5.3810  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 2.0621  Validation loss = 5.3809  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 2.0620  Validation loss = 5.3808  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 2.0619  Validation loss = 5.3807  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 2.0619  Validation loss = 5.3806  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 2.0618  Validation loss = 5.3805  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 2.0617  Validation loss = 5.3803  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 2.0616  Validation loss = 5.3802  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 2.0616  Validation loss = 5.3802  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 2.0615  Validation loss = 5.3801  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 2.0615  Validation loss = 5.3800  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 2.0614  Validation loss = 5.3799  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 2.0613  Validation loss = 5.3798  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 2.0613  Validation loss = 5.3796  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 2.0612  Validation loss = 5.3795  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 2.0611  Validation loss = 5.3794  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 2.0611  Validation loss = 5.3793  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 2.0610  Validation loss = 5.3792  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 2.0609  Validation loss = 5.3791  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 2.0608  Validation loss = 5.3790  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 2.0608  Validation loss = 5.3789  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 2.0607  Validation loss = 5.3788  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 2.0606  Validation loss = 5.3786  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 2.0605  Validation loss = 5.3785  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 2.0605  Validation loss = 5.3784  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 2.0604  Validation loss = 5.3783  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 2.0603  Validation loss = 5.3782  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 2.0602  Validation loss = 5.3780  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 2.0601  Validation loss = 5.3779  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 2.0601  Validation loss = 5.3778  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 2.0600  Validation loss = 5.3777  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 2.0599  Validation loss = 5.3776  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 2.0598  Validation loss = 5.3774  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 2.0597  Validation loss = 5.3773  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 2.0597  Validation loss = 5.3772  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 2.0596  Validation loss = 5.3771  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 2.0595  Validation loss = 5.3769  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 2.0594  Validation loss = 5.3769  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 2.0594  Validation loss = 5.3767  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 2.0593  Validation loss = 5.3766  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 2.0592  Validation loss = 5.3765  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 2.0591  Validation loss = 5.3764  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 2.0590  Validation loss = 5.3762  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 2.0590  Validation loss = 5.3761  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 2.0589  Validation loss = 5.3760  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 2.0588  Validation loss = 5.3759  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 2.0587  Validation loss = 5.3758  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 2.0587  Validation loss = 5.3757  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 2.0586  Validation loss = 5.3756  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 2.0585  Validation loss = 5.3754  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 2.0584  Validation loss = 5.3753  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 2.0584  Validation loss = 5.3752  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 2.0583  Validation loss = 5.3751  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 2.0582  Validation loss = 5.3750  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 2.0582  Validation loss = 5.3749  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 2.0581  Validation loss = 5.3748  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 2.0580  Validation loss = 5.3746  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 2.0579  Validation loss = 5.3745  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 2.0579  Validation loss = 5.3744  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 2.0578  Validation loss = 5.3743  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 2.0577  Validation loss = 5.3742  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 2.0577  Validation loss = 5.3741  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 2.0576  Validation loss = 5.3740  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 2.0575  Validation loss = 5.3739  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 2.0575  Validation loss = 5.3738  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 2.0574  Validation loss = 5.3737  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 2.0573  Validation loss = 5.3736  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 2.0572  Validation loss = 5.3735  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 2.0572  Validation loss = 5.3733  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 2.0571  Validation loss = 5.3732  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 2.0571  Validation loss = 5.3732  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 2.0570  Validation loss = 5.3730  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 2.0569  Validation loss = 5.3729  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 2.0568  Validation loss = 5.3728  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 2.0568  Validation loss = 5.3727  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 2.0567  Validation loss = 5.3726  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 2.0566  Validation loss = 5.3725  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 2.0565  Validation loss = 5.3724  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 2.0565  Validation loss = 5.3722  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 2.0564  Validation loss = 5.3721  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 2.0563  Validation loss = 5.3720  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 2.0562  Validation loss = 5.3719  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 2.0562  Validation loss = 5.3718  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 2.0561  Validation loss = 5.3717  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 2.0560  Validation loss = 5.3716  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 2.0560  Validation loss = 5.3715  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 2.0559  Validation loss = 5.3714  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 2.0558  Validation loss = 5.3713  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 2.0557  Validation loss = 5.3711  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 2.0557  Validation loss = 5.3710  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 2.0556  Validation loss = 5.3710  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 2.0556  Validation loss = 5.3709  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 2.0555  Validation loss = 5.3708  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 2.0554  Validation loss = 5.3707  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 2.0554  Validation loss = 5.3706  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 2.0553  Validation loss = 5.3704  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 2.0552  Validation loss = 5.3703  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 2.0552  Validation loss = 5.3702  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 2.0551  Validation loss = 5.3702  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 2.0550  Validation loss = 5.3700  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 2.0549  Validation loss = 5.3699  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 2.0549  Validation loss = 5.3698  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 2.0548  Validation loss = 5.3696  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 2.0547  Validation loss = 5.3695  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 2.0546  Validation loss = 5.3694  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 2.0546  Validation loss = 5.3693  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 2.0545  Validation loss = 5.3692  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 2.0544  Validation loss = 5.3691  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 2.0543  Validation loss = 5.3690  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 2.0543  Validation loss = 5.3689  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 2.0542  Validation loss = 5.3688  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 2.0542  Validation loss = 5.3687  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 2.0541  Validation loss = 5.3685  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 2.0540  Validation loss = 5.3684  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 2.0539  Validation loss = 5.3683  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 2.0538  Validation loss = 5.3682  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 2.0537  Validation loss = 5.3680  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 2.0536  Validation loss = 5.3679  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 2.0536  Validation loss = 5.3677  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 2.0535  Validation loss = 5.3676  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 2.0534  Validation loss = 5.3675  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 2.0533  Validation loss = 5.3673  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 2.0532  Validation loss = 5.3672  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 2.0532  Validation loss = 5.3671  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 2.0531  Validation loss = 5.3670  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 2.0530  Validation loss = 5.3669  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 2.0529  Validation loss = 5.3668  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 2.0528  Validation loss = 5.3666  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 2.0528  Validation loss = 5.3665  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 2.0527  Validation loss = 5.3664  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 2.0526  Validation loss = 5.3663  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 2.0526  Validation loss = 5.3662  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 2.0525  Validation loss = 5.3661  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 2.0524  Validation loss = 5.3660  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 2.0523  Validation loss = 5.3658  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 2.0522  Validation loss = 5.3657  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 2.0522  Validation loss = 5.3656  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 2.0521  Validation loss = 5.3655  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 2.0520  Validation loss = 5.3654  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 2.0520  Validation loss = 5.3653  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 2.0519  Validation loss = 5.3652  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 2.0518  Validation loss = 5.3651  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 2.0518  Validation loss = 5.3650  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 2.0517  Validation loss = 5.3649  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 2.0516  Validation loss = 5.3648  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 2.0516  Validation loss = 5.3646  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 2.0515  Validation loss = 5.3646  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 2.0514  Validation loss = 5.3645  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 2.0514  Validation loss = 5.3644  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 2.0513  Validation loss = 5.3643  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 2.0512  Validation loss = 5.3641  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 2.0512  Validation loss = 5.3640  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 2.0511  Validation loss = 5.3639  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 2.0510  Validation loss = 5.3638  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 2.0509  Validation loss = 5.3636  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 2.0508  Validation loss = 5.3635  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 2.0508  Validation loss = 5.3634  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 2.0507  Validation loss = 5.3633  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 2.0506  Validation loss = 5.3632  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 2.0506  Validation loss = 5.3631  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 2.0505  Validation loss = 5.3630  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 2.0504  Validation loss = 5.3629  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 2.0504  Validation loss = 5.3628  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 2.0503  Validation loss = 5.3627  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 2.0502  Validation loss = 5.3626  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 2.0502  Validation loss = 5.3625  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 2.0501  Validation loss = 5.3624  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 2.0500  Validation loss = 5.3623  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 2.0499  Validation loss = 5.3621  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 2.0498  Validation loss = 5.3620  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 2.0498  Validation loss = 5.3619  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 2.0497  Validation loss = 5.3618  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 2.0496  Validation loss = 5.3616  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 2.0496  Validation loss = 5.3615  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 2.0495  Validation loss = 5.3614  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 2.0494  Validation loss = 5.3613  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 2.0493  Validation loss = 5.3612  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 2.0492  Validation loss = 5.3610  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 2.0492  Validation loss = 5.3609  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 2.0491  Validation loss = 5.3608  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 2.0490  Validation loss = 5.3607  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 2.0490  Validation loss = 5.3606  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 2.0489  Validation loss = 5.3606  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 2.0489  Validation loss = 5.3605  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 2.0488  Validation loss = 5.3604  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 2.0487  Validation loss = 5.3603  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 2.0487  Validation loss = 5.3602  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 2.0486  Validation loss = 5.3601  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 2.0485  Validation loss = 5.3599  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 2.0485  Validation loss = 5.3599  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 2.0484  Validation loss = 5.3598  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 2.0484  Validation loss = 5.3597  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 2.0483  Validation loss = 5.3596  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 2.0482  Validation loss = 5.3594  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 2.0481  Validation loss = 5.3593  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 2.0481  Validation loss = 5.3592  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 2.0480  Validation loss = 5.3591  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 2.0479  Validation loss = 5.3589  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 2.0478  Validation loss = 5.3588  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 2.0478  Validation loss = 5.3587  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 2.0477  Validation loss = 5.3586  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 2.0476  Validation loss = 5.3585  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 2.0475  Validation loss = 5.3584  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 2.0475  Validation loss = 5.3583  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 2.0474  Validation loss = 5.3582  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 2.0473  Validation loss = 5.3581  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 2.0473  Validation loss = 5.3580  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 2.0472  Validation loss = 5.3579  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 2.0471  Validation loss = 5.3577  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 2.0470  Validation loss = 5.3576  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 2.0470  Validation loss = 5.3575  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 2.0469  Validation loss = 5.3574  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 2.0468  Validation loss = 5.3573  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 2.0468  Validation loss = 5.3572  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 2.0467  Validation loss = 5.3571  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 2.0466  Validation loss = 5.3570  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 2.0466  Validation loss = 5.3569  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 2.0465  Validation loss = 5.3567  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 2.0464  Validation loss = 5.3566  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 2.0463  Validation loss = 5.3565  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 2.0462  Validation loss = 5.3564  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 2.0462  Validation loss = 5.3562  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 2.0461  Validation loss = 5.3561  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 2.0460  Validation loss = 5.3560  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 2.0459  Validation loss = 5.3559  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 2.0459  Validation loss = 5.3558  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 2.0458  Validation loss = 5.3557  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 2.0457  Validation loss = 5.3556  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 2.0457  Validation loss = 5.3555  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 2.0456  Validation loss = 5.3553  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 2.0455  Validation loss = 5.3552  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 2.0454  Validation loss = 5.3551  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 2.0453  Validation loss = 5.3550  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 2.0453  Validation loss = 5.3548  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 2.0452  Validation loss = 5.3547  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 2.0451  Validation loss = 5.3546  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 2.0450  Validation loss = 5.3545  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 2.0450  Validation loss = 5.3544  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 2.0449  Validation loss = 5.3543  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 2.0448  Validation loss = 5.3541  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 2.0447  Validation loss = 5.3540  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 2.0446  Validation loss = 5.3539  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 2.0446  Validation loss = 5.3537  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 2.0445  Validation loss = 5.3536  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 2.0444  Validation loss = 5.3535  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 2.0443  Validation loss = 5.3534  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 2.0443  Validation loss = 5.3533  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 2.0442  Validation loss = 5.3532  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 2.0441  Validation loss = 5.3530  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 2.0440  Validation loss = 5.3529  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 2.0440  Validation loss = 5.3528  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 2.0439  Validation loss = 5.3527  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 2.0438  Validation loss = 5.3525  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 2.0438  Validation loss = 5.3525  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 2.0437  Validation loss = 5.3524  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 2.0436  Validation loss = 5.3523  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 2.0435  Validation loss = 5.3521  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 2.0435  Validation loss = 5.3520  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 2.0434  Validation loss = 5.3519  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 2.0434  Validation loss = 5.3518  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 2.0433  Validation loss = 5.3517  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 2.0432  Validation loss = 5.3516  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 2.0432  Validation loss = 5.3515  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 2.0431  Validation loss = 5.3514  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 2.0430  Validation loss = 5.3512  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 2.0429  Validation loss = 5.3512  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 2.0429  Validation loss = 5.3510  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 2.0428  Validation loss = 5.3509  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 2.0427  Validation loss = 5.3508  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 2.0426  Validation loss = 5.3507  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 2.0426  Validation loss = 5.3506  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 2.0425  Validation loss = 5.3505  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 2.0424  Validation loss = 5.3504  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 2.0424  Validation loss = 5.3503  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 2.0423  Validation loss = 5.3502  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 2.0422  Validation loss = 5.3501  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 2.0422  Validation loss = 5.3500  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 2.0421  Validation loss = 5.3499  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 2.0420  Validation loss = 5.3498  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 2.0420  Validation loss = 5.3497  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 2.0419  Validation loss = 5.3496  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 2.0418  Validation loss = 5.3495  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 2.0418  Validation loss = 5.3493  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 2.0417  Validation loss = 5.3493  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 2.0417  Validation loss = 5.3492  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 2.0416  Validation loss = 5.3490  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 2.0415  Validation loss = 5.3489  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 2.0414  Validation loss = 5.3488  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 2.0414  Validation loss = 5.3487  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 2.0413  Validation loss = 5.3486  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 2.0412  Validation loss = 5.3485  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 2.0412  Validation loss = 5.3484  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 2.0411  Validation loss = 5.3483  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 2.0410  Validation loss = 5.3482  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 2.0410  Validation loss = 5.3481  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 2.0409  Validation loss = 5.3479  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 2.0408  Validation loss = 5.3478  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 2.0408  Validation loss = 5.3478  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 2.0407  Validation loss = 5.3476  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 2.0406  Validation loss = 5.3475  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 2.0405  Validation loss = 5.3474  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 2.0405  Validation loss = 5.3473  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 2.0404  Validation loss = 5.3472  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 2.0403  Validation loss = 5.3471  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 2.0403  Validation loss = 5.3470  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 2.0402  Validation loss = 5.3469  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 2.0401  Validation loss = 5.3468  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 2.0400  Validation loss = 5.3466  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 2.0400  Validation loss = 5.3465  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 2.0399  Validation loss = 5.3464  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 2.0398  Validation loss = 5.3463  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 2.0397  Validation loss = 5.3462  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 2.0397  Validation loss = 5.3461  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 2.0396  Validation loss = 5.3460  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 2.0395  Validation loss = 5.3459  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 2.0395  Validation loss = 5.3457  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 2.0394  Validation loss = 5.3456  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 2.0393  Validation loss = 5.3455  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 2.0392  Validation loss = 5.3454  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 2.0392  Validation loss = 5.3452  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 2.0391  Validation loss = 5.3451  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 2.0390  Validation loss = 5.3450  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 2.0390  Validation loss = 5.3449  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 2.0389  Validation loss = 5.3448  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 2.0388  Validation loss = 5.3447  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 2.0387  Validation loss = 5.3446  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 2.0387  Validation loss = 5.3444  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 2.0386  Validation loss = 5.3444  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 2.0385  Validation loss = 5.3443  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 2.0385  Validation loss = 5.3442  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 2.0384  Validation loss = 5.3441  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 2.0383  Validation loss = 5.3439  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 2.0383  Validation loss = 5.3438  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 2.0382  Validation loss = 5.3437  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 2.0381  Validation loss = 5.3436  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 2.0380  Validation loss = 5.3435  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 2.0380  Validation loss = 5.3434  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 2.0379  Validation loss = 5.3433  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 2.0378  Validation loss = 5.3432  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 2.0378  Validation loss = 5.3430  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 2.0377  Validation loss = 5.3429  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 2.0376  Validation loss = 5.3428  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 2.0375  Validation loss = 5.3427  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 2.0375  Validation loss = 5.3426  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 2.0374  Validation loss = 5.3425  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 2.0374  Validation loss = 5.3424  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 2.0373  Validation loss = 5.3423  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 2.0372  Validation loss = 5.3422  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 2.0371  Validation loss = 5.3421  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 2.0371  Validation loss = 5.3420  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 2.0370  Validation loss = 5.3418  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 2.0369  Validation loss = 5.3417  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 2.0368  Validation loss = 5.3416  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 2.0368  Validation loss = 5.3415  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 2.0367  Validation loss = 5.3414  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 2.0367  Validation loss = 5.3413  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 2.0366  Validation loss = 5.3412  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 2.0365  Validation loss = 5.3411  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 2.0364  Validation loss = 5.3410  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 2.0364  Validation loss = 5.3408  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 2.0363  Validation loss = 5.3407  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 2.0362  Validation loss = 5.3406  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 2.0362  Validation loss = 5.3405  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 2.0361  Validation loss = 5.3404  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 2.0360  Validation loss = 5.3403  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 2.0359  Validation loss = 5.3401  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 2.0359  Validation loss = 5.3401  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 2.0358  Validation loss = 5.3399  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 2.0357  Validation loss = 5.3398  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 2.0356  Validation loss = 5.3397  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 2.0356  Validation loss = 5.3396  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 2.0355  Validation loss = 5.3395  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 2.0354  Validation loss = 5.3394  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 2.0354  Validation loss = 5.3393  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 2.0353  Validation loss = 5.3392  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 2.0353  Validation loss = 5.3391  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 2.0352  Validation loss = 5.3390  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 2.0352  Validation loss = 5.3389  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 2.0351  Validation loss = 5.3388  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 2.0350  Validation loss = 5.3387  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 2.0349  Validation loss = 5.3386  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 2.0349  Validation loss = 5.3385  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 2.0348  Validation loss = 5.3384  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 2.0347  Validation loss = 5.3383  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 2.0347  Validation loss = 5.3382  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 2.0346  Validation loss = 5.3380  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 2.0345  Validation loss = 5.3379  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 2.0345  Validation loss = 5.3378  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 2.0344  Validation loss = 5.3377  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 2.0343  Validation loss = 5.3377  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 2.0343  Validation loss = 5.3375  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 2.0342  Validation loss = 5.3374  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 2.0341  Validation loss = 5.3373  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 2.0341  Validation loss = 5.3372  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 2.0340  Validation loss = 5.3371  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 2.0339  Validation loss = 5.3370  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 2.0338  Validation loss = 5.3369  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 2.0338  Validation loss = 5.3367  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 2.0337  Validation loss = 5.3366  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 2.0336  Validation loss = 5.3365  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 2.0336  Validation loss = 5.3365  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 2.0335  Validation loss = 5.3363  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 2.0335  Validation loss = 5.3362  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 2.0334  Validation loss = 5.3361  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 2.0333  Validation loss = 5.3360  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 2.0332  Validation loss = 5.3359  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 2.0332  Validation loss = 5.3358  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 2.0331  Validation loss = 5.3357  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 2.0330  Validation loss = 5.3355  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 2.0329  Validation loss = 5.3354  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 2.0328  Validation loss = 5.3353  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 2.0328  Validation loss = 5.3351  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 2.0327  Validation loss = 5.3350  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 2.0326  Validation loss = 5.3349  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 2.0325  Validation loss = 5.3348  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 2.0325  Validation loss = 5.3347  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 2.0324  Validation loss = 5.3346  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 2.0324  Validation loss = 5.3345  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 2.0323  Validation loss = 5.3344  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 2.0322  Validation loss = 5.3343  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 2.0322  Validation loss = 5.3342  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 2.0321  Validation loss = 5.3341  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 2.0320  Validation loss = 5.3340  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 2.0320  Validation loss = 5.3339  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 2.0319  Validation loss = 5.3338  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 2.0318  Validation loss = 5.3336  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 2.0317  Validation loss = 5.3335  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 2.0317  Validation loss = 5.3334  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 2.0316  Validation loss = 5.3333  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 2.0315  Validation loss = 5.3332  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 2.0314  Validation loss = 5.3331  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 2.0314  Validation loss = 5.3330  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 2.0313  Validation loss = 5.3329  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 2.0313  Validation loss = 5.3328  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 2.0312  Validation loss = 5.3327  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 2.0311  Validation loss = 5.3325  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 2.0311  Validation loss = 5.3325  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 2.0310  Validation loss = 5.3324  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 2.0309  Validation loss = 5.3323  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 2.0308  Validation loss = 5.3321  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 2.0308  Validation loss = 5.3320  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 2.0307  Validation loss = 5.3319  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 2.0306  Validation loss = 5.3318  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 2.0306  Validation loss = 5.3317  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 2.0305  Validation loss = 5.3316  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 2.0304  Validation loss = 5.3315  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 2.0304  Validation loss = 5.3314  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 2.0303  Validation loss = 5.3313  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 2.0302  Validation loss = 5.3312  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 2.0302  Validation loss = 5.3311  \n",
      "\n",
      "Fold: 4  Epoch: 501  Training loss = 2.0301  Validation loss = 5.3309  \n",
      "\n",
      "Fold: 4  Epoch: 502  Training loss = 2.0300  Validation loss = 5.3308  \n",
      "\n",
      "Fold: 4  Epoch: 503  Training loss = 2.0300  Validation loss = 5.3308  \n",
      "\n",
      "Fold: 4  Epoch: 504  Training loss = 2.0299  Validation loss = 5.3307  \n",
      "\n",
      "Fold: 4  Epoch: 505  Training loss = 2.0298  Validation loss = 5.3306  \n",
      "\n",
      "Fold: 4  Epoch: 506  Training loss = 2.0298  Validation loss = 5.3305  \n",
      "\n",
      "Fold: 4  Epoch: 507  Training loss = 2.0297  Validation loss = 5.3304  \n",
      "\n",
      "Fold: 4  Epoch: 508  Training loss = 2.0297  Validation loss = 5.3303  \n",
      "\n",
      "Fold: 4  Epoch: 509  Training loss = 2.0296  Validation loss = 5.3302  \n",
      "\n",
      "Fold: 4  Epoch: 510  Training loss = 2.0295  Validation loss = 5.3300  \n",
      "\n",
      "Fold: 4  Epoch: 511  Training loss = 2.0294  Validation loss = 5.3299  \n",
      "\n",
      "Fold: 4  Epoch: 512  Training loss = 2.0294  Validation loss = 5.3298  \n",
      "\n",
      "Fold: 4  Epoch: 513  Training loss = 2.0293  Validation loss = 5.3297  \n",
      "\n",
      "Fold: 4  Epoch: 514  Training loss = 2.0292  Validation loss = 5.3296  \n",
      "\n",
      "Fold: 4  Epoch: 515  Training loss = 2.0292  Validation loss = 5.3294  \n",
      "\n",
      "Fold: 4  Epoch: 516  Training loss = 2.0291  Validation loss = 5.3294  \n",
      "\n",
      "Fold: 4  Epoch: 517  Training loss = 2.0290  Validation loss = 5.3293  \n",
      "\n",
      "Fold: 4  Epoch: 518  Training loss = 2.0290  Validation loss = 5.3292  \n",
      "\n",
      "Fold: 4  Epoch: 519  Training loss = 2.0289  Validation loss = 5.3291  \n",
      "\n",
      "Fold: 4  Epoch: 520  Training loss = 2.0288  Validation loss = 5.3290  \n",
      "\n",
      "Fold: 4  Epoch: 521  Training loss = 2.0288  Validation loss = 5.3289  \n",
      "\n",
      "Fold: 4  Epoch: 522  Training loss = 2.0287  Validation loss = 5.3287  \n",
      "\n",
      "Fold: 4  Epoch: 523  Training loss = 2.0286  Validation loss = 5.3286  \n",
      "\n",
      "Fold: 4  Epoch: 524  Training loss = 2.0286  Validation loss = 5.3285  \n",
      "\n",
      "Fold: 4  Epoch: 525  Training loss = 2.0285  Validation loss = 5.3284  \n",
      "\n",
      "Fold: 4  Epoch: 526  Training loss = 2.0284  Validation loss = 5.3283  \n",
      "\n",
      "Fold: 4  Epoch: 527  Training loss = 2.0284  Validation loss = 5.3282  \n",
      "\n",
      "Fold: 4  Epoch: 528  Training loss = 2.0283  Validation loss = 5.3281  \n",
      "\n",
      "Fold: 4  Epoch: 529  Training loss = 2.0283  Validation loss = 5.3280  \n",
      "\n",
      "Fold: 4  Epoch: 530  Training loss = 2.0282  Validation loss = 5.3279  \n",
      "\n",
      "Fold: 4  Epoch: 531  Training loss = 2.0281  Validation loss = 5.3278  \n",
      "\n",
      "Fold: 4  Epoch: 532  Training loss = 2.0280  Validation loss = 5.3276  \n",
      "\n",
      "Fold: 4  Epoch: 533  Training loss = 2.0280  Validation loss = 5.3275  \n",
      "\n",
      "Fold: 4  Epoch: 534  Training loss = 2.0279  Validation loss = 5.3274  \n",
      "\n",
      "Fold: 4  Epoch: 535  Training loss = 2.0278  Validation loss = 5.3273  \n",
      "\n",
      "Fold: 4  Epoch: 536  Training loss = 2.0277  Validation loss = 5.3272  \n",
      "\n",
      "Fold: 4  Epoch: 537  Training loss = 2.0276  Validation loss = 5.3270  \n",
      "\n",
      "Fold: 4  Epoch: 538  Training loss = 2.0276  Validation loss = 5.3269  \n",
      "\n",
      "Fold: 4  Epoch: 539  Training loss = 2.0275  Validation loss = 5.3268  \n",
      "\n",
      "Fold: 4  Epoch: 540  Training loss = 2.0275  Validation loss = 5.3267  \n",
      "\n",
      "Fold: 4  Epoch: 541  Training loss = 2.0274  Validation loss = 5.3266  \n",
      "\n",
      "Fold: 4  Epoch: 542  Training loss = 2.0273  Validation loss = 5.3266  \n",
      "\n",
      "Fold: 4  Epoch: 543  Training loss = 2.0273  Validation loss = 5.3265  \n",
      "\n",
      "Fold: 4  Epoch: 544  Training loss = 2.0272  Validation loss = 5.3264  \n",
      "\n",
      "Fold: 4  Epoch: 545  Training loss = 2.0272  Validation loss = 5.3263  \n",
      "\n",
      "Fold: 4  Epoch: 546  Training loss = 2.0271  Validation loss = 5.3262  \n",
      "\n",
      "Fold: 4  Epoch: 547  Training loss = 2.0270  Validation loss = 5.3261  \n",
      "\n",
      "Fold: 4  Epoch: 548  Training loss = 2.0270  Validation loss = 5.3260  \n",
      "\n",
      "Fold: 4  Epoch: 549  Training loss = 2.0269  Validation loss = 5.3259  \n",
      "\n",
      "Fold: 4  Epoch: 550  Training loss = 2.0268  Validation loss = 5.3258  \n",
      "\n",
      "Fold: 4  Epoch: 551  Training loss = 2.0268  Validation loss = 5.3257  \n",
      "\n",
      "Fold: 4  Epoch: 552  Training loss = 2.0267  Validation loss = 5.3255  \n",
      "\n",
      "Fold: 4  Epoch: 553  Training loss = 2.0266  Validation loss = 5.3254  \n",
      "\n",
      "Fold: 4  Epoch: 554  Training loss = 2.0265  Validation loss = 5.3253  \n",
      "\n",
      "Fold: 4  Epoch: 555  Training loss = 2.0265  Validation loss = 5.3252  \n",
      "\n",
      "Fold: 4  Epoch: 556  Training loss = 2.0264  Validation loss = 5.3251  \n",
      "\n",
      "Fold: 4  Epoch: 557  Training loss = 2.0264  Validation loss = 5.3250  \n",
      "\n",
      "Fold: 4  Epoch: 558  Training loss = 2.0263  Validation loss = 5.3249  \n",
      "\n",
      "Fold: 4  Epoch: 559  Training loss = 2.0262  Validation loss = 5.3248  \n",
      "\n",
      "Fold: 4  Epoch: 560  Training loss = 2.0262  Validation loss = 5.3247  \n",
      "\n",
      "Fold: 4  Epoch: 561  Training loss = 2.0261  Validation loss = 5.3246  \n",
      "\n",
      "Fold: 4  Epoch: 562  Training loss = 2.0261  Validation loss = 5.3245  \n",
      "\n",
      "Fold: 4  Epoch: 563  Training loss = 2.0260  Validation loss = 5.3244  \n",
      "\n",
      "Fold: 4  Epoch: 564  Training loss = 2.0259  Validation loss = 5.3243  \n",
      "\n",
      "Fold: 4  Epoch: 565  Training loss = 2.0259  Validation loss = 5.3242  \n",
      "\n",
      "Fold: 4  Epoch: 566  Training loss = 2.0258  Validation loss = 5.3241  \n",
      "\n",
      "Fold: 4  Epoch: 567  Training loss = 2.0257  Validation loss = 5.3240  \n",
      "\n",
      "Fold: 4  Epoch: 568  Training loss = 2.0256  Validation loss = 5.3238  \n",
      "\n",
      "Fold: 4  Epoch: 569  Training loss = 2.0256  Validation loss = 5.3237  \n",
      "\n",
      "Fold: 4  Epoch: 570  Training loss = 2.0255  Validation loss = 5.3236  \n",
      "\n",
      "Fold: 4  Epoch: 571  Training loss = 2.0254  Validation loss = 5.3235  \n",
      "\n",
      "Fold: 4  Epoch: 572  Training loss = 2.0254  Validation loss = 5.3234  \n",
      "\n",
      "Fold: 4  Epoch: 573  Training loss = 2.0253  Validation loss = 5.3233  \n",
      "\n",
      "Fold: 4  Epoch: 574  Training loss = 2.0252  Validation loss = 5.3232  \n",
      "\n",
      "Fold: 4  Epoch: 575  Training loss = 2.0252  Validation loss = 5.3231  \n",
      "\n",
      "Fold: 4  Epoch: 576  Training loss = 2.0251  Validation loss = 5.3230  \n",
      "\n",
      "Fold: 4  Epoch: 577  Training loss = 2.0250  Validation loss = 5.3228  \n",
      "\n",
      "Fold: 4  Epoch: 578  Training loss = 2.0249  Validation loss = 5.3227  \n",
      "\n",
      "Fold: 4  Epoch: 579  Training loss = 2.0249  Validation loss = 5.3226  \n",
      "\n",
      "Fold: 4  Epoch: 580  Training loss = 2.0248  Validation loss = 5.3225  \n",
      "\n",
      "Fold: 4  Epoch: 581  Training loss = 2.0247  Validation loss = 5.3224  \n",
      "\n",
      "Fold: 4  Epoch: 582  Training loss = 2.0247  Validation loss = 5.3223  \n",
      "\n",
      "Fold: 4  Epoch: 583  Training loss = 2.0246  Validation loss = 5.3222  \n",
      "\n",
      "Fold: 4  Epoch: 584  Training loss = 2.0245  Validation loss = 5.3221  \n",
      "\n",
      "Fold: 4  Epoch: 585  Training loss = 2.0245  Validation loss = 5.3219  \n",
      "\n",
      "Fold: 4  Epoch: 586  Training loss = 2.0244  Validation loss = 5.3218  \n",
      "\n",
      "Fold: 4  Epoch: 587  Training loss = 2.0243  Validation loss = 5.3218  \n",
      "\n",
      "Fold: 4  Epoch: 588  Training loss = 2.0243  Validation loss = 5.3217  \n",
      "\n",
      "Fold: 4  Epoch: 589  Training loss = 2.0242  Validation loss = 5.3216  \n",
      "\n",
      "Fold: 4  Epoch: 590  Training loss = 2.0241  Validation loss = 5.3215  \n",
      "\n",
      "Fold: 4  Epoch: 591  Training loss = 2.0241  Validation loss = 5.3213  \n",
      "\n",
      "Fold: 4  Epoch: 592  Training loss = 2.0240  Validation loss = 5.3212  \n",
      "\n",
      "Fold: 4  Epoch: 593  Training loss = 2.0239  Validation loss = 5.3211  \n",
      "\n",
      "Fold: 4  Epoch: 594  Training loss = 2.0239  Validation loss = 5.3210  \n",
      "\n",
      "Fold: 4  Epoch: 595  Training loss = 2.0238  Validation loss = 5.3209  \n",
      "\n",
      "Fold: 4  Epoch: 596  Training loss = 2.0237  Validation loss = 5.3208  \n",
      "\n",
      "Fold: 4  Epoch: 597  Training loss = 2.0237  Validation loss = 5.3207  \n",
      "\n",
      "Fold: 4  Epoch: 598  Training loss = 2.0236  Validation loss = 5.3206  \n",
      "\n",
      "Fold: 4  Epoch: 599  Training loss = 2.0235  Validation loss = 5.3205  \n",
      "\n",
      "Fold: 4  Epoch: 600  Training loss = 2.0235  Validation loss = 5.3204  \n",
      "\n",
      "Fold: 4  Epoch: 601  Training loss = 2.0234  Validation loss = 5.3202  \n",
      "\n",
      "Fold: 4  Epoch: 602  Training loss = 2.0233  Validation loss = 5.3201  \n",
      "\n",
      "Fold: 4  Epoch: 603  Training loss = 2.0233  Validation loss = 5.3200  \n",
      "\n",
      "Fold: 4  Epoch: 604  Training loss = 2.0232  Validation loss = 5.3199  \n",
      "\n",
      "Fold: 4  Epoch: 605  Training loss = 2.0231  Validation loss = 5.3198  \n",
      "\n",
      "Fold: 4  Epoch: 606  Training loss = 2.0230  Validation loss = 5.3197  \n",
      "\n",
      "Fold: 4  Epoch: 607  Training loss = 2.0230  Validation loss = 5.3196  \n",
      "\n",
      "Fold: 4  Epoch: 608  Training loss = 2.0229  Validation loss = 5.3194  \n",
      "\n",
      "Fold: 4  Epoch: 609  Training loss = 2.0228  Validation loss = 5.3193  \n",
      "\n",
      "Fold: 4  Epoch: 610  Training loss = 2.0227  Validation loss = 5.3192  \n",
      "\n",
      "Fold: 4  Epoch: 611  Training loss = 2.0227  Validation loss = 5.3191  \n",
      "\n",
      "Fold: 4  Epoch: 612  Training loss = 2.0226  Validation loss = 5.3190  \n",
      "\n",
      "Fold: 4  Epoch: 613  Training loss = 2.0225  Validation loss = 5.3189  \n",
      "\n",
      "Fold: 4  Epoch: 614  Training loss = 2.0225  Validation loss = 5.3188  \n",
      "\n",
      "Fold: 4  Epoch: 615  Training loss = 2.0224  Validation loss = 5.3187  \n",
      "\n",
      "Fold: 4  Epoch: 616  Training loss = 2.0224  Validation loss = 5.3186  \n",
      "\n",
      "Fold: 4  Epoch: 617  Training loss = 2.0223  Validation loss = 5.3185  \n",
      "\n",
      "Fold: 4  Epoch: 618  Training loss = 2.0222  Validation loss = 5.3184  \n",
      "\n",
      "Fold: 4  Epoch: 619  Training loss = 2.0221  Validation loss = 5.3183  \n",
      "\n",
      "Fold: 4  Epoch: 620  Training loss = 2.0221  Validation loss = 5.3181  \n",
      "\n",
      "Fold: 4  Epoch: 621  Training loss = 2.0220  Validation loss = 5.3180  \n",
      "\n",
      "Fold: 4  Epoch: 622  Training loss = 2.0219  Validation loss = 5.3179  \n",
      "\n",
      "Fold: 4  Epoch: 623  Training loss = 2.0219  Validation loss = 5.3178  \n",
      "\n",
      "Fold: 4  Epoch: 624  Training loss = 2.0218  Validation loss = 5.3177  \n",
      "\n",
      "Fold: 4  Epoch: 625  Training loss = 2.0217  Validation loss = 5.3176  \n",
      "\n",
      "Fold: 4  Epoch: 626  Training loss = 2.0217  Validation loss = 5.3175  \n",
      "\n",
      "Fold: 4  Epoch: 627  Training loss = 2.0216  Validation loss = 5.3174  \n",
      "\n",
      "Fold: 4  Epoch: 628  Training loss = 2.0215  Validation loss = 5.3173  \n",
      "\n",
      "Fold: 4  Epoch: 629  Training loss = 2.0215  Validation loss = 5.3171  \n",
      "\n",
      "Fold: 4  Epoch: 630  Training loss = 2.0214  Validation loss = 5.3170  \n",
      "\n",
      "Fold: 4  Epoch: 631  Training loss = 2.0213  Validation loss = 5.3169  \n",
      "\n",
      "Fold: 4  Epoch: 632  Training loss = 2.0212  Validation loss = 5.3168  \n",
      "\n",
      "Fold: 4  Epoch: 633  Training loss = 2.0212  Validation loss = 5.3167  \n",
      "\n",
      "Fold: 4  Epoch: 634  Training loss = 2.0211  Validation loss = 5.3166  \n",
      "\n",
      "Fold: 4  Epoch: 635  Training loss = 2.0211  Validation loss = 5.3165  \n",
      "\n",
      "Fold: 4  Epoch: 636  Training loss = 2.0210  Validation loss = 5.3164  \n",
      "\n",
      "Fold: 4  Epoch: 637  Training loss = 2.0209  Validation loss = 5.3163  \n",
      "\n",
      "Fold: 4  Epoch: 638  Training loss = 2.0209  Validation loss = 5.3162  \n",
      "\n",
      "Fold: 4  Epoch: 639  Training loss = 2.0208  Validation loss = 5.3161  \n",
      "\n",
      "Fold: 4  Epoch: 640  Training loss = 2.0207  Validation loss = 5.3160  \n",
      "\n",
      "Fold: 4  Epoch: 641  Training loss = 2.0206  Validation loss = 5.3158  \n",
      "\n",
      "Fold: 4  Epoch: 642  Training loss = 2.0206  Validation loss = 5.3157  \n",
      "\n",
      "Fold: 4  Epoch: 643  Training loss = 2.0205  Validation loss = 5.3156  \n",
      "\n",
      "Fold: 4  Epoch: 644  Training loss = 2.0204  Validation loss = 5.3155  \n",
      "\n",
      "Fold: 4  Epoch: 645  Training loss = 2.0203  Validation loss = 5.3154  \n",
      "\n",
      "Fold: 4  Epoch: 646  Training loss = 2.0203  Validation loss = 5.3153  \n",
      "\n",
      "Fold: 4  Epoch: 647  Training loss = 2.0202  Validation loss = 5.3152  \n",
      "\n",
      "Fold: 4  Epoch: 648  Training loss = 2.0202  Validation loss = 5.3151  \n",
      "\n",
      "Fold: 4  Epoch: 649  Training loss = 2.0201  Validation loss = 5.3149  \n",
      "\n",
      "Fold: 4  Epoch: 650  Training loss = 2.0200  Validation loss = 5.3148  \n",
      "\n",
      "Fold: 4  Epoch: 651  Training loss = 2.0199  Validation loss = 5.3147  \n",
      "\n",
      "Fold: 4  Epoch: 652  Training loss = 2.0199  Validation loss = 5.3146  \n",
      "\n",
      "Fold: 4  Epoch: 653  Training loss = 2.0198  Validation loss = 5.3145  \n",
      "\n",
      "Fold: 4  Epoch: 654  Training loss = 2.0198  Validation loss = 5.3144  \n",
      "\n",
      "Fold: 4  Epoch: 655  Training loss = 2.0197  Validation loss = 5.3143  \n",
      "\n",
      "Fold: 4  Epoch: 656  Training loss = 2.0196  Validation loss = 5.3142  \n",
      "\n",
      "Fold: 4  Epoch: 657  Training loss = 2.0195  Validation loss = 5.3140  \n",
      "\n",
      "Fold: 4  Epoch: 658  Training loss = 2.0195  Validation loss = 5.3140  \n",
      "\n",
      "Fold: 4  Epoch: 659  Training loss = 2.0194  Validation loss = 5.3139  \n",
      "\n",
      "Fold: 4  Epoch: 660  Training loss = 2.0194  Validation loss = 5.3138  \n",
      "\n",
      "Fold: 4  Epoch: 661  Training loss = 2.0193  Validation loss = 5.3136  \n",
      "\n",
      "Fold: 4  Epoch: 662  Training loss = 2.0192  Validation loss = 5.3135  \n",
      "\n",
      "Fold: 4  Epoch: 663  Training loss = 2.0191  Validation loss = 5.3134  \n",
      "\n",
      "Fold: 4  Epoch: 664  Training loss = 2.0191  Validation loss = 5.3133  \n",
      "\n",
      "Fold: 4  Epoch: 665  Training loss = 2.0190  Validation loss = 5.3132  \n",
      "\n",
      "Fold: 4  Epoch: 666  Training loss = 2.0189  Validation loss = 5.3131  \n",
      "\n",
      "Fold: 4  Epoch: 667  Training loss = 2.0189  Validation loss = 5.3130  \n",
      "\n",
      "Fold: 4  Epoch: 668  Training loss = 2.0188  Validation loss = 5.3129  \n",
      "\n",
      "Fold: 4  Epoch: 669  Training loss = 2.0187  Validation loss = 5.3127  \n",
      "\n",
      "Fold: 4  Epoch: 670  Training loss = 2.0187  Validation loss = 5.3127  \n",
      "\n",
      "Fold: 4  Epoch: 671  Training loss = 2.0186  Validation loss = 5.3125  \n",
      "\n",
      "Fold: 4  Epoch: 672  Training loss = 2.0185  Validation loss = 5.3124  \n",
      "\n",
      "Fold: 4  Epoch: 673  Training loss = 2.0184  Validation loss = 5.3123  \n",
      "\n",
      "Fold: 4  Epoch: 674  Training loss = 2.0184  Validation loss = 5.3122  \n",
      "\n",
      "Fold: 4  Epoch: 675  Training loss = 2.0183  Validation loss = 5.3121  \n",
      "\n",
      "Fold: 4  Epoch: 676  Training loss = 2.0182  Validation loss = 5.3119  \n",
      "\n",
      "Fold: 4  Epoch: 677  Training loss = 2.0181  Validation loss = 5.3118  \n",
      "\n",
      "Fold: 4  Epoch: 678  Training loss = 2.0181  Validation loss = 5.3117  \n",
      "\n",
      "Fold: 4  Epoch: 679  Training loss = 2.0180  Validation loss = 5.3116  \n",
      "\n",
      "Fold: 4  Epoch: 680  Training loss = 2.0179  Validation loss = 5.3115  \n",
      "\n",
      "Fold: 4  Epoch: 681  Training loss = 2.0179  Validation loss = 5.3114  \n",
      "\n",
      "Fold: 4  Epoch: 682  Training loss = 2.0178  Validation loss = 5.3113  \n",
      "\n",
      "Fold: 4  Epoch: 683  Training loss = 2.0178  Validation loss = 5.3112  \n",
      "\n",
      "Fold: 4  Epoch: 684  Training loss = 2.0177  Validation loss = 5.3111  \n",
      "\n",
      "Fold: 4  Epoch: 685  Training loss = 2.0176  Validation loss = 5.3110  \n",
      "\n",
      "Fold: 4  Epoch: 686  Training loss = 2.0176  Validation loss = 5.3109  \n",
      "\n",
      "Fold: 4  Epoch: 687  Training loss = 2.0175  Validation loss = 5.3108  \n",
      "\n",
      "Fold: 4  Epoch: 688  Training loss = 2.0174  Validation loss = 5.3107  \n",
      "\n",
      "Fold: 4  Epoch: 689  Training loss = 2.0174  Validation loss = 5.3106  \n",
      "\n",
      "Fold: 4  Epoch: 690  Training loss = 2.0173  Validation loss = 5.3105  \n",
      "\n",
      "Fold: 4  Epoch: 691  Training loss = 2.0172  Validation loss = 5.3104  \n",
      "\n",
      "Fold: 4  Epoch: 692  Training loss = 2.0171  Validation loss = 5.3102  \n",
      "\n",
      "Fold: 4  Epoch: 693  Training loss = 2.0171  Validation loss = 5.3101  \n",
      "\n",
      "Fold: 4  Epoch: 694  Training loss = 2.0170  Validation loss = 5.3100  \n",
      "\n",
      "Fold: 4  Epoch: 695  Training loss = 2.0170  Validation loss = 5.3099  \n",
      "\n",
      "Fold: 4  Epoch: 696  Training loss = 2.0169  Validation loss = 5.3099  \n",
      "\n",
      "Fold: 4  Epoch: 697  Training loss = 2.0168  Validation loss = 5.3098  \n",
      "\n",
      "Fold: 4  Epoch: 698  Training loss = 2.0168  Validation loss = 5.3096  \n",
      "\n",
      "Fold: 4  Epoch: 699  Training loss = 2.0167  Validation loss = 5.3095  \n",
      "\n",
      "Fold: 4  Epoch: 700  Training loss = 2.0166  Validation loss = 5.3094  \n",
      "\n",
      "Fold: 4  Epoch: 701  Training loss = 2.0166  Validation loss = 5.3093  \n",
      "\n",
      "Fold: 4  Epoch: 702  Training loss = 2.0165  Validation loss = 5.3092  \n",
      "\n",
      "Fold: 4  Epoch: 703  Training loss = 2.0165  Validation loss = 5.3092  \n",
      "\n",
      "Fold: 4  Epoch: 704  Training loss = 2.0164  Validation loss = 5.3090  \n",
      "\n",
      "Fold: 4  Epoch: 705  Training loss = 2.0163  Validation loss = 5.3089  \n",
      "\n",
      "Fold: 4  Epoch: 706  Training loss = 2.0162  Validation loss = 5.3088  \n",
      "\n",
      "Fold: 4  Epoch: 707  Training loss = 2.0162  Validation loss = 5.3087  \n",
      "\n",
      "Fold: 4  Epoch: 708  Training loss = 2.0161  Validation loss = 5.3086  \n",
      "\n",
      "Fold: 4  Epoch: 709  Training loss = 2.0160  Validation loss = 5.3085  \n",
      "\n",
      "Fold: 4  Epoch: 710  Training loss = 2.0160  Validation loss = 5.3084  \n",
      "\n",
      "Fold: 4  Epoch: 711  Training loss = 2.0159  Validation loss = 5.3083  \n",
      "\n",
      "Fold: 4  Epoch: 712  Training loss = 2.0158  Validation loss = 5.3081  \n",
      "\n",
      "Fold: 4  Epoch: 713  Training loss = 2.0158  Validation loss = 5.3080  \n",
      "\n",
      "Fold: 4  Epoch: 714  Training loss = 2.0157  Validation loss = 5.3079  \n",
      "\n",
      "Fold: 4  Epoch: 715  Training loss = 2.0156  Validation loss = 5.3078  \n",
      "\n",
      "Fold: 4  Epoch: 716  Training loss = 2.0156  Validation loss = 5.3077  \n",
      "\n",
      "Fold: 4  Epoch: 717  Training loss = 2.0155  Validation loss = 5.3076  \n",
      "\n",
      "Fold: 4  Epoch: 718  Training loss = 2.0155  Validation loss = 5.3075  \n",
      "\n",
      "Fold: 4  Epoch: 719  Training loss = 2.0154  Validation loss = 5.3074  \n",
      "\n",
      "Fold: 4  Epoch: 720  Training loss = 2.0153  Validation loss = 5.3073  \n",
      "\n",
      "Fold: 4  Epoch: 721  Training loss = 2.0153  Validation loss = 5.3072  \n",
      "\n",
      "Fold: 4  Epoch: 722  Training loss = 2.0152  Validation loss = 5.3071  \n",
      "\n",
      "Fold: 4  Epoch: 723  Training loss = 2.0152  Validation loss = 5.3070  \n",
      "\n",
      "Fold: 4  Epoch: 724  Training loss = 2.0151  Validation loss = 5.3069  \n",
      "\n",
      "Fold: 4  Epoch: 725  Training loss = 2.0150  Validation loss = 5.3069  \n",
      "\n",
      "Fold: 4  Epoch: 726  Training loss = 2.0150  Validation loss = 5.3068  \n",
      "\n",
      "Fold: 4  Epoch: 727  Training loss = 2.0149  Validation loss = 5.3066  \n",
      "\n",
      "Fold: 4  Epoch: 728  Training loss = 2.0148  Validation loss = 5.3065  \n",
      "\n",
      "Fold: 4  Epoch: 729  Training loss = 2.0148  Validation loss = 5.3065  \n",
      "\n",
      "Fold: 4  Epoch: 730  Training loss = 2.0147  Validation loss = 5.3063  \n",
      "\n",
      "Fold: 4  Epoch: 731  Training loss = 2.0147  Validation loss = 5.3062  \n",
      "\n",
      "Fold: 4  Epoch: 732  Training loss = 2.0146  Validation loss = 5.3061  \n",
      "\n",
      "Fold: 4  Epoch: 733  Training loss = 2.0145  Validation loss = 5.3060  \n",
      "\n",
      "Fold: 4  Epoch: 734  Training loss = 2.0145  Validation loss = 5.3060  \n",
      "\n",
      "Fold: 4  Epoch: 735  Training loss = 2.0144  Validation loss = 5.3059  \n",
      "\n",
      "Fold: 4  Epoch: 736  Training loss = 2.0144  Validation loss = 5.3058  \n",
      "\n",
      "Fold: 4  Epoch: 737  Training loss = 2.0143  Validation loss = 5.3057  \n",
      "\n",
      "Fold: 4  Epoch: 738  Training loss = 2.0143  Validation loss = 5.3056  \n",
      "\n",
      "Fold: 4  Epoch: 739  Training loss = 2.0142  Validation loss = 5.3055  \n",
      "\n",
      "Fold: 4  Epoch: 740  Training loss = 2.0141  Validation loss = 5.3053  \n",
      "\n",
      "Fold: 4  Epoch: 741  Training loss = 2.0140  Validation loss = 5.3052  \n",
      "\n",
      "Fold: 4  Epoch: 742  Training loss = 2.0140  Validation loss = 5.3051  \n",
      "\n",
      "Fold: 4  Epoch: 743  Training loss = 2.0139  Validation loss = 5.3050  \n",
      "\n",
      "Fold: 4  Epoch: 744  Training loss = 2.0138  Validation loss = 5.3049  \n",
      "\n",
      "Fold: 4  Epoch: 745  Training loss = 2.0137  Validation loss = 5.3048  \n",
      "\n",
      "Fold: 4  Epoch: 746  Training loss = 2.0136  Validation loss = 5.3046  \n",
      "\n",
      "Fold: 4  Epoch: 747  Training loss = 2.0136  Validation loss = 5.3045  \n",
      "\n",
      "Fold: 4  Epoch: 748  Training loss = 2.0135  Validation loss = 5.3044  \n",
      "\n",
      "Fold: 4  Epoch: 749  Training loss = 2.0134  Validation loss = 5.3043  \n",
      "\n",
      "Fold: 4  Epoch: 750  Training loss = 2.0134  Validation loss = 5.3042  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 750  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.3763  Validation loss = 5.0326  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.3762  Validation loss = 5.0325  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.3761  Validation loss = 5.0324  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.3760  Validation loss = 5.0322  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.3759  Validation loss = 5.0321  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.3758  Validation loss = 5.0319  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.3757  Validation loss = 5.0318  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.3756  Validation loss = 5.0316  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.3755  Validation loss = 5.0315  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.3754  Validation loss = 5.0314  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.3754  Validation loss = 5.0313  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.3753  Validation loss = 5.0312  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.3752  Validation loss = 5.0310  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.3751  Validation loss = 5.0309  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.3750  Validation loss = 5.0307  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.3749  Validation loss = 5.0306  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.3748  Validation loss = 5.0305  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.3747  Validation loss = 5.0304  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.3746  Validation loss = 5.0302  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.3745  Validation loss = 5.0301  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.3744  Validation loss = 5.0299  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.3743  Validation loss = 5.0298  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.3742  Validation loss = 5.0297  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.3741  Validation loss = 5.0295  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.3741  Validation loss = 5.0294  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.3739  Validation loss = 5.0292  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.3739  Validation loss = 5.0291  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.3738  Validation loss = 5.0290  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.3737  Validation loss = 5.0288  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.3736  Validation loss = 5.0287  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.3735  Validation loss = 5.0285  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.3734  Validation loss = 5.0284  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.3733  Validation loss = 5.0283  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.3732  Validation loss = 5.0282  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.3732  Validation loss = 5.0281  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.3731  Validation loss = 5.0280  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.3730  Validation loss = 5.0279  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.3729  Validation loss = 5.0278  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.3729  Validation loss = 5.0277  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.3728  Validation loss = 5.0275  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.3727  Validation loss = 5.0274  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.3726  Validation loss = 5.0273  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.3725  Validation loss = 5.0272  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.3724  Validation loss = 5.0270  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.3723  Validation loss = 5.0269  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.3722  Validation loss = 5.0267  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.3721  Validation loss = 5.0266  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.3720  Validation loss = 5.0264  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.3719  Validation loss = 5.0263  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.3719  Validation loss = 5.0262  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.3718  Validation loss = 5.0262  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.3717  Validation loss = 5.0260  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.3716  Validation loss = 5.0258  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.3715  Validation loss = 5.0257  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.3714  Validation loss = 5.0256  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.3713  Validation loss = 5.0254  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.3713  Validation loss = 5.0253  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.3712  Validation loss = 5.0252  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.3711  Validation loss = 5.0251  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.3710  Validation loss = 5.0250  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.3709  Validation loss = 5.0248  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.3708  Validation loss = 5.0247  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.3708  Validation loss = 5.0246  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.3707  Validation loss = 5.0245  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.3706  Validation loss = 5.0243  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.3705  Validation loss = 5.0242  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.3704  Validation loss = 5.0240  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.3703  Validation loss = 5.0239  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.3702  Validation loss = 5.0237  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.3701  Validation loss = 5.0236  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.3700  Validation loss = 5.0234  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.3699  Validation loss = 5.0233  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.3698  Validation loss = 5.0232  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.3698  Validation loss = 5.0231  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.3697  Validation loss = 5.0230  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.3696  Validation loss = 5.0228  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.3695  Validation loss = 5.0227  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.3694  Validation loss = 5.0226  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.3693  Validation loss = 5.0225  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.3692  Validation loss = 5.0223  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.3691  Validation loss = 5.0222  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.3691  Validation loss = 5.0221  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.3690  Validation loss = 5.0219  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.3689  Validation loss = 5.0218  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.3688  Validation loss = 5.0217  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.3687  Validation loss = 5.0216  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.3686  Validation loss = 5.0214  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.3686  Validation loss = 5.0213  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.3685  Validation loss = 5.0212  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.3684  Validation loss = 5.0211  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.3683  Validation loss = 5.0209  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.3682  Validation loss = 5.0208  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.3681  Validation loss = 5.0207  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.3680  Validation loss = 5.0205  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.3679  Validation loss = 5.0204  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.3679  Validation loss = 5.0203  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.3678  Validation loss = 5.0202  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.3677  Validation loss = 5.0200  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.3676  Validation loss = 5.0199  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.3675  Validation loss = 5.0197  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.3674  Validation loss = 5.0196  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.3673  Validation loss = 5.0194  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.3672  Validation loss = 5.0193  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.3671  Validation loss = 5.0192  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.3670  Validation loss = 5.0190  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.3669  Validation loss = 5.0189  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.3669  Validation loss = 5.0188  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.3668  Validation loss = 5.0187  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.3667  Validation loss = 5.0185  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.3666  Validation loss = 5.0184  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.3665  Validation loss = 5.0183  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.3664  Validation loss = 5.0182  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.3663  Validation loss = 5.0180  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.3663  Validation loss = 5.0179  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.3662  Validation loss = 5.0178  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.3661  Validation loss = 5.0177  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.3660  Validation loss = 5.0176  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.3660  Validation loss = 5.0175  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.3659  Validation loss = 5.0173  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.3658  Validation loss = 5.0172  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.3657  Validation loss = 5.0171  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.3656  Validation loss = 5.0170  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.3655  Validation loss = 5.0168  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.3654  Validation loss = 5.0167  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.3653  Validation loss = 5.0166  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.3652  Validation loss = 5.0164  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.3652  Validation loss = 5.0163  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.3651  Validation loss = 5.0162  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.3650  Validation loss = 5.0161  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.3649  Validation loss = 5.0159  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.3648  Validation loss = 5.0158  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.3647  Validation loss = 5.0156  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.3646  Validation loss = 5.0155  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.3645  Validation loss = 5.0154  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.3644  Validation loss = 5.0152  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.3643  Validation loss = 5.0151  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.3642  Validation loss = 5.0150  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.3642  Validation loss = 5.0149  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.3641  Validation loss = 5.0147  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.3640  Validation loss = 5.0146  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.3639  Validation loss = 5.0145  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.3638  Validation loss = 5.0143  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.3637  Validation loss = 5.0142  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.3637  Validation loss = 5.0141  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.3636  Validation loss = 5.0139  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.3635  Validation loss = 5.0138  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.3634  Validation loss = 5.0137  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.3633  Validation loss = 5.0136  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.3632  Validation loss = 5.0134  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.3631  Validation loss = 5.0133  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.3630  Validation loss = 5.0132  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.3630  Validation loss = 5.0131  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.3629  Validation loss = 5.0129  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.3627  Validation loss = 5.0127  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.3627  Validation loss = 5.0126  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.3626  Validation loss = 5.0125  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.3625  Validation loss = 5.0124  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.3624  Validation loss = 5.0123  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.3623  Validation loss = 5.0122  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.3623  Validation loss = 5.0120  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.3621  Validation loss = 5.0119  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.3621  Validation loss = 5.0117  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.3620  Validation loss = 5.0116  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.3619  Validation loss = 5.0115  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.3618  Validation loss = 5.0113  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.3617  Validation loss = 5.0112  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.3616  Validation loss = 5.0111  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.3616  Validation loss = 5.0110  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.3615  Validation loss = 5.0109  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.3614  Validation loss = 5.0108  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.3613  Validation loss = 5.0107  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.3612  Validation loss = 5.0105  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.3612  Validation loss = 5.0104  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.3611  Validation loss = 5.0103  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.3610  Validation loss = 5.0102  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.3610  Validation loss = 5.0101  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.3609  Validation loss = 5.0100  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.3608  Validation loss = 5.0099  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.3607  Validation loss = 5.0097  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.3606  Validation loss = 5.0096  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.3605  Validation loss = 5.0094  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.3604  Validation loss = 5.0093  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.3603  Validation loss = 5.0091  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.3602  Validation loss = 5.0090  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.3601  Validation loss = 5.0089  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.3600  Validation loss = 5.0088  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.3600  Validation loss = 5.0087  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.3599  Validation loss = 5.0086  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.3598  Validation loss = 5.0084  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.3597  Validation loss = 5.0083  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.3596  Validation loss = 5.0082  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.3595  Validation loss = 5.0080  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.3594  Validation loss = 5.0079  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.3593  Validation loss = 5.0077  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.3592  Validation loss = 5.0076  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.3591  Validation loss = 5.0075  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.3591  Validation loss = 5.0073  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.3590  Validation loss = 5.0072  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.3588  Validation loss = 5.0070  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.3588  Validation loss = 5.0069  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.3587  Validation loss = 5.0068  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.3586  Validation loss = 5.0066  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.3585  Validation loss = 5.0065  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.3584  Validation loss = 5.0064  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.3583  Validation loss = 5.0063  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.3582  Validation loss = 5.0061  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.3581  Validation loss = 5.0060  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.3581  Validation loss = 5.0059  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.3580  Validation loss = 5.0058  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.3579  Validation loss = 5.0057  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.3578  Validation loss = 5.0055  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.3578  Validation loss = 5.0054  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.3576  Validation loss = 5.0053  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.3576  Validation loss = 5.0052  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.3575  Validation loss = 5.0050  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.3574  Validation loss = 5.0049  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.3573  Validation loss = 5.0048  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.3572  Validation loss = 5.0047  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.3572  Validation loss = 5.0045  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.3571  Validation loss = 5.0044  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.3570  Validation loss = 5.0043  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.3569  Validation loss = 5.0042  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.3568  Validation loss = 5.0040  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.3567  Validation loss = 5.0039  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.3566  Validation loss = 5.0037  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.3565  Validation loss = 5.0036  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.3564  Validation loss = 5.0035  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.3563  Validation loss = 5.0033  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.3562  Validation loss = 5.0032  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.3561  Validation loss = 5.0030  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.3561  Validation loss = 5.0029  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.3560  Validation loss = 5.0028  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.3559  Validation loss = 5.0027  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.3558  Validation loss = 5.0025  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.3557  Validation loss = 5.0024  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.3556  Validation loss = 5.0023  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.3555  Validation loss = 5.0022  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.3555  Validation loss = 5.0021  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.3554  Validation loss = 5.0020  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.3553  Validation loss = 5.0018  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.3552  Validation loss = 5.0017  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.3551  Validation loss = 5.0015  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.3550  Validation loss = 5.0014  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.3549  Validation loss = 5.0013  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.3549  Validation loss = 5.0011  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.3548  Validation loss = 5.0010  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.3547  Validation loss = 5.0009  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.3546  Validation loss = 5.0008  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.3545  Validation loss = 5.0006  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.3544  Validation loss = 5.0005  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.3543  Validation loss = 5.0004  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.3543  Validation loss = 5.0003  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.3542  Validation loss = 5.0001  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.3541  Validation loss = 5.0000  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.3540  Validation loss = 4.9999  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.3539  Validation loss = 4.9997  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.3538  Validation loss = 4.9996  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.3537  Validation loss = 4.9995  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.3537  Validation loss = 4.9994  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.3536  Validation loss = 4.9993  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.3535  Validation loss = 4.9991  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.3534  Validation loss = 4.9990  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.3533  Validation loss = 4.9989  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.3532  Validation loss = 4.9988  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.3532  Validation loss = 4.9986  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.3531  Validation loss = 4.9985  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.3530  Validation loss = 4.9984  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.3529  Validation loss = 4.9983  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.3528  Validation loss = 4.9981  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.3527  Validation loss = 4.9980  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.3526  Validation loss = 4.9979  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.3525  Validation loss = 4.9977  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.3524  Validation loss = 4.9976  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.3523  Validation loss = 4.9974  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.3523  Validation loss = 4.9973  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.3522  Validation loss = 4.9972  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.3521  Validation loss = 4.9970  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.3520  Validation loss = 4.9969  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.3519  Validation loss = 4.9968  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.3518  Validation loss = 4.9966  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.3517  Validation loss = 4.9965  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.3516  Validation loss = 4.9963  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.3515  Validation loss = 4.9962  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.3514  Validation loss = 4.9961  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.3514  Validation loss = 4.9959  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.3513  Validation loss = 4.9958  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.3512  Validation loss = 4.9957  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.3511  Validation loss = 4.9956  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.3511  Validation loss = 4.9955  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.3510  Validation loss = 4.9954  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.3509  Validation loss = 4.9952  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.3508  Validation loss = 4.9951  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.3507  Validation loss = 4.9950  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.3506  Validation loss = 4.9948  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.3505  Validation loss = 4.9946  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.3504  Validation loss = 4.9945  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.3503  Validation loss = 4.9944  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.3502  Validation loss = 4.9942  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.3501  Validation loss = 4.9941  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.3501  Validation loss = 4.9940  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.3500  Validation loss = 4.9939  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.3499  Validation loss = 4.9937  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.3498  Validation loss = 4.9936  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.3497  Validation loss = 4.9934  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.3496  Validation loss = 4.9933  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.3495  Validation loss = 4.9931  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.3494  Validation loss = 4.9930  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.3493  Validation loss = 4.9928  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.3492  Validation loss = 4.9927  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.3491  Validation loss = 4.9926  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.3490  Validation loss = 4.9924  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.3489  Validation loss = 4.9923  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.3488  Validation loss = 4.9921  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.3487  Validation loss = 4.9920  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.3486  Validation loss = 4.9919  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.3485  Validation loss = 4.9918  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.3485  Validation loss = 4.9916  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.3484  Validation loss = 4.9915  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.3483  Validation loss = 4.9914  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.3482  Validation loss = 4.9913  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.3481  Validation loss = 4.9912  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.3480  Validation loss = 4.9910  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.3480  Validation loss = 4.9909  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.3479  Validation loss = 4.9908  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.3478  Validation loss = 4.9907  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.3477  Validation loss = 4.9905  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.3476  Validation loss = 4.9904  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.3475  Validation loss = 4.9903  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.3474  Validation loss = 4.9901  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.3474  Validation loss = 4.9900  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.3473  Validation loss = 4.9899  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.3472  Validation loss = 4.9898  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.3472  Validation loss = 4.9897  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.3471  Validation loss = 4.9896  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.3470  Validation loss = 4.9894  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.3469  Validation loss = 4.9892  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.3468  Validation loss = 4.9891  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.3467  Validation loss = 4.9889  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.3466  Validation loss = 4.9888  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.3465  Validation loss = 4.9886  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.3464  Validation loss = 4.9885  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.3463  Validation loss = 4.9884  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.3462  Validation loss = 4.9882  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.3461  Validation loss = 4.9881  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.3460  Validation loss = 4.9880  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.3459  Validation loss = 4.9878  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.3459  Validation loss = 4.9877  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.3458  Validation loss = 4.9876  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.3457  Validation loss = 4.9875  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.3456  Validation loss = 4.9874  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.3455  Validation loss = 4.9872  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.3455  Validation loss = 4.9871  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.3454  Validation loss = 4.9870  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.3453  Validation loss = 4.9869  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.3452  Validation loss = 4.9868  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.3451  Validation loss = 4.9866  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.3450  Validation loss = 4.9865  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.3449  Validation loss = 4.9863  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.3448  Validation loss = 4.9862  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.3448  Validation loss = 4.9861  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.3447  Validation loss = 4.9859  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.3446  Validation loss = 4.9858  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.3445  Validation loss = 4.9857  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.3444  Validation loss = 4.9856  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.3443  Validation loss = 4.9854  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.3443  Validation loss = 4.9853  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.3442  Validation loss = 4.9852  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.3441  Validation loss = 4.9851  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.3440  Validation loss = 4.9849  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.3439  Validation loss = 4.9848  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.3438  Validation loss = 4.9847  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.3438  Validation loss = 4.9846  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.3437  Validation loss = 4.9845  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.3436  Validation loss = 4.9843  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.3435  Validation loss = 4.9842  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.3434  Validation loss = 4.9841  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.3433  Validation loss = 4.9839  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.3432  Validation loss = 4.9838  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.3432  Validation loss = 4.9837  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.3431  Validation loss = 4.9836  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.3430  Validation loss = 4.9834  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.3429  Validation loss = 4.9833  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.3428  Validation loss = 4.9832  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.3428  Validation loss = 4.9831  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.3427  Validation loss = 4.9830  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.3426  Validation loss = 4.9829  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.3425  Validation loss = 4.9827  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.3425  Validation loss = 4.9826  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.3424  Validation loss = 4.9825  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.3423  Validation loss = 4.9824  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.3422  Validation loss = 4.9822  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.3421  Validation loss = 4.9821  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.3421  Validation loss = 4.9820  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.3420  Validation loss = 4.9819  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.3419  Validation loss = 4.9817  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.3418  Validation loss = 4.9816  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.3417  Validation loss = 4.9814  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.3416  Validation loss = 4.9813  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.3415  Validation loss = 4.9812  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.3414  Validation loss = 4.9810  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.3413  Validation loss = 4.9809  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.3412  Validation loss = 4.9808  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.3412  Validation loss = 4.9807  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.3411  Validation loss = 4.9805  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.3410  Validation loss = 4.9804  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.3409  Validation loss = 4.9803  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.3409  Validation loss = 4.9802  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.3408  Validation loss = 4.9801  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.3407  Validation loss = 4.9799  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.3406  Validation loss = 4.9798  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.3405  Validation loss = 4.9797  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.3404  Validation loss = 4.9796  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.3403  Validation loss = 4.9794  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.3403  Validation loss = 4.9793  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.3402  Validation loss = 4.9792  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.3401  Validation loss = 4.9791  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.3400  Validation loss = 4.9789  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.3399  Validation loss = 4.9788  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.3398  Validation loss = 4.9786  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.3397  Validation loss = 4.9785  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.3397  Validation loss = 4.9784  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.3396  Validation loss = 4.9782  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.3395  Validation loss = 4.9781  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.3394  Validation loss = 4.9780  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.3393  Validation loss = 4.9779  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.3392  Validation loss = 4.9777  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.3392  Validation loss = 4.9776  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.3391  Validation loss = 4.9775  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.3390  Validation loss = 4.9774  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.3389  Validation loss = 4.9772  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.3388  Validation loss = 4.9771  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.3387  Validation loss = 4.9769  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.3386  Validation loss = 4.9768  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.3385  Validation loss = 4.9767  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.3384  Validation loss = 4.9766  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.3384  Validation loss = 4.9764  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.3383  Validation loss = 4.9763  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.3382  Validation loss = 4.9762  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.3381  Validation loss = 4.9761  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.3381  Validation loss = 4.9760  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.3380  Validation loss = 4.9759  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.3379  Validation loss = 4.9758  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.3379  Validation loss = 4.9757  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.3378  Validation loss = 4.9755  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.3377  Validation loss = 4.9754  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.3376  Validation loss = 4.9753  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.3375  Validation loss = 4.9751  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.3374  Validation loss = 4.9750  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.3373  Validation loss = 4.9749  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.3372  Validation loss = 4.9747  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.3372  Validation loss = 4.9746  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.3371  Validation loss = 4.9745  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.3370  Validation loss = 4.9743  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.3369  Validation loss = 4.9742  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.3368  Validation loss = 4.9741  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.3367  Validation loss = 4.9739  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.3366  Validation loss = 4.9738  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.3365  Validation loss = 4.9737  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.3365  Validation loss = 4.9735  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.3364  Validation loss = 4.9734  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.3363  Validation loss = 4.9733  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.3362  Validation loss = 4.9732  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.3361  Validation loss = 4.9731  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.3361  Validation loss = 4.9730  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.3360  Validation loss = 4.9729  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.3359  Validation loss = 4.9727  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.3358  Validation loss = 4.9726  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.3357  Validation loss = 4.9724  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.3356  Validation loss = 4.9723  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.3356  Validation loss = 4.9722  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.3355  Validation loss = 4.9720  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.3354  Validation loss = 4.9719  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.3353  Validation loss = 4.9717  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.3352  Validation loss = 4.9716  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.3351  Validation loss = 4.9715  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.3350  Validation loss = 4.9713  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.3349  Validation loss = 4.9712  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.3348  Validation loss = 4.9710  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.3347  Validation loss = 4.9709  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.3346  Validation loss = 4.9708  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.3346  Validation loss = 4.9706  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.3345  Validation loss = 4.9705  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.3344  Validation loss = 4.9704  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.3343  Validation loss = 4.9703  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.3343  Validation loss = 4.9702  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.3342  Validation loss = 4.9700  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.3341  Validation loss = 4.9699  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.3340  Validation loss = 4.9698  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.3339  Validation loss = 4.9697  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.3338  Validation loss = 4.9695  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.3337  Validation loss = 4.9694  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.3337  Validation loss = 4.9693  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.3336  Validation loss = 4.9692  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.3335  Validation loss = 4.9690  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.3334  Validation loss = 4.9688  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.3333  Validation loss = 4.9687  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.3332  Validation loss = 4.9686  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.3331  Validation loss = 4.9685  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.3330  Validation loss = 4.9683  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.3329  Validation loss = 4.9682  \n",
      "\n",
      "Fold: 5  Epoch: 501  Training loss = 2.3329  Validation loss = 4.9681  \n",
      "\n",
      "Fold: 5  Epoch: 502  Training loss = 2.3328  Validation loss = 4.9680  \n",
      "\n",
      "Fold: 5  Epoch: 503  Training loss = 2.3327  Validation loss = 4.9678  \n",
      "\n",
      "Fold: 5  Epoch: 504  Training loss = 2.3326  Validation loss = 4.9676  \n",
      "\n",
      "Fold: 5  Epoch: 505  Training loss = 2.3325  Validation loss = 4.9675  \n",
      "\n",
      "Fold: 5  Epoch: 506  Training loss = 2.3324  Validation loss = 4.9674  \n",
      "\n",
      "Fold: 5  Epoch: 507  Training loss = 2.3323  Validation loss = 4.9673  \n",
      "\n",
      "Fold: 5  Epoch: 508  Training loss = 2.3322  Validation loss = 4.9671  \n",
      "\n",
      "Fold: 5  Epoch: 509  Training loss = 2.3322  Validation loss = 4.9670  \n",
      "\n",
      "Fold: 5  Epoch: 510  Training loss = 2.3321  Validation loss = 4.9669  \n",
      "\n",
      "Fold: 5  Epoch: 511  Training loss = 2.3320  Validation loss = 4.9667  \n",
      "\n",
      "Fold: 5  Epoch: 512  Training loss = 2.3319  Validation loss = 4.9666  \n",
      "\n",
      "Fold: 5  Epoch: 513  Training loss = 2.3318  Validation loss = 4.9665  \n",
      "\n",
      "Fold: 5  Epoch: 514  Training loss = 2.3317  Validation loss = 4.9664  \n",
      "\n",
      "Fold: 5  Epoch: 515  Training loss = 2.3317  Validation loss = 4.9662  \n",
      "\n",
      "Fold: 5  Epoch: 516  Training loss = 2.3316  Validation loss = 4.9661  \n",
      "\n",
      "Fold: 5  Epoch: 517  Training loss = 2.3315  Validation loss = 4.9660  \n",
      "\n",
      "Fold: 5  Epoch: 518  Training loss = 2.3314  Validation loss = 4.9659  \n",
      "\n",
      "Fold: 5  Epoch: 519  Training loss = 2.3313  Validation loss = 4.9657  \n",
      "\n",
      "Fold: 5  Epoch: 520  Training loss = 2.3312  Validation loss = 4.9656  \n",
      "\n",
      "Fold: 5  Epoch: 521  Training loss = 2.3311  Validation loss = 4.9655  \n",
      "\n",
      "Fold: 5  Epoch: 522  Training loss = 2.3311  Validation loss = 4.9654  \n",
      "\n",
      "Fold: 5  Epoch: 523  Training loss = 2.3310  Validation loss = 4.9652  \n",
      "\n",
      "Fold: 5  Epoch: 524  Training loss = 2.3309  Validation loss = 4.9651  \n",
      "\n",
      "Fold: 5  Epoch: 525  Training loss = 2.3308  Validation loss = 4.9650  \n",
      "\n",
      "Fold: 5  Epoch: 526  Training loss = 2.3308  Validation loss = 4.9649  \n",
      "\n",
      "Fold: 5  Epoch: 527  Training loss = 2.3307  Validation loss = 4.9647  \n",
      "\n",
      "Fold: 5  Epoch: 528  Training loss = 2.3306  Validation loss = 4.9646  \n",
      "\n",
      "Fold: 5  Epoch: 529  Training loss = 2.3305  Validation loss = 4.9645  \n",
      "\n",
      "Fold: 5  Epoch: 530  Training loss = 2.3304  Validation loss = 4.9643  \n",
      "\n",
      "Fold: 5  Epoch: 531  Training loss = 2.3303  Validation loss = 4.9642  \n",
      "\n",
      "Fold: 5  Epoch: 532  Training loss = 2.3302  Validation loss = 4.9641  \n",
      "\n",
      "Fold: 5  Epoch: 533  Training loss = 2.3301  Validation loss = 4.9639  \n",
      "\n",
      "Fold: 5  Epoch: 534  Training loss = 2.3301  Validation loss = 4.9638  \n",
      "\n",
      "Fold: 5  Epoch: 535  Training loss = 2.3300  Validation loss = 4.9637  \n",
      "\n",
      "Fold: 5  Epoch: 536  Training loss = 2.3299  Validation loss = 4.9636  \n",
      "\n",
      "Fold: 5  Epoch: 537  Training loss = 2.3298  Validation loss = 4.9635  \n",
      "\n",
      "Fold: 5  Epoch: 538  Training loss = 2.3297  Validation loss = 4.9633  \n",
      "\n",
      "Fold: 5  Epoch: 539  Training loss = 2.3297  Validation loss = 4.9632  \n",
      "\n",
      "Fold: 5  Epoch: 540  Training loss = 2.3296  Validation loss = 4.9631  \n",
      "\n",
      "Fold: 5  Epoch: 541  Training loss = 2.3295  Validation loss = 4.9630  \n",
      "\n",
      "Fold: 5  Epoch: 542  Training loss = 2.3294  Validation loss = 4.9629  \n",
      "\n",
      "Fold: 5  Epoch: 543  Training loss = 2.3294  Validation loss = 4.9627  \n",
      "\n",
      "Fold: 5  Epoch: 544  Training loss = 2.3293  Validation loss = 4.9626  \n",
      "\n",
      "Fold: 5  Epoch: 545  Training loss = 2.3292  Validation loss = 4.9625  \n",
      "\n",
      "Fold: 5  Epoch: 546  Training loss = 2.3291  Validation loss = 4.9624  \n",
      "\n",
      "Fold: 5  Epoch: 547  Training loss = 2.3290  Validation loss = 4.9623  \n",
      "\n",
      "Fold: 5  Epoch: 548  Training loss = 2.3290  Validation loss = 4.9621  \n",
      "\n",
      "Fold: 5  Epoch: 549  Training loss = 2.3289  Validation loss = 4.9620  \n",
      "\n",
      "Fold: 5  Epoch: 550  Training loss = 2.3288  Validation loss = 4.9619  \n",
      "\n",
      "Fold: 5  Epoch: 551  Training loss = 2.3287  Validation loss = 4.9618  \n",
      "\n",
      "Fold: 5  Epoch: 552  Training loss = 2.3286  Validation loss = 4.9617  \n",
      "\n",
      "Fold: 5  Epoch: 553  Training loss = 2.3286  Validation loss = 4.9615  \n",
      "\n",
      "Fold: 5  Epoch: 554  Training loss = 2.3285  Validation loss = 4.9614  \n",
      "\n",
      "Fold: 5  Epoch: 555  Training loss = 2.3284  Validation loss = 4.9613  \n",
      "\n",
      "Fold: 5  Epoch: 556  Training loss = 2.3283  Validation loss = 4.9612  \n",
      "\n",
      "Fold: 5  Epoch: 557  Training loss = 2.3282  Validation loss = 4.9610  \n",
      "\n",
      "Fold: 5  Epoch: 558  Training loss = 2.3281  Validation loss = 4.9609  \n",
      "\n",
      "Fold: 5  Epoch: 559  Training loss = 2.3281  Validation loss = 4.9608  \n",
      "\n",
      "Fold: 5  Epoch: 560  Training loss = 2.3280  Validation loss = 4.9607  \n",
      "\n",
      "Fold: 5  Epoch: 561  Training loss = 2.3279  Validation loss = 4.9605  \n",
      "\n",
      "Fold: 5  Epoch: 562  Training loss = 2.3278  Validation loss = 4.9604  \n",
      "\n",
      "Fold: 5  Epoch: 563  Training loss = 2.3278  Validation loss = 4.9603  \n",
      "\n",
      "Fold: 5  Epoch: 564  Training loss = 2.3277  Validation loss = 4.9602  \n",
      "\n",
      "Fold: 5  Epoch: 565  Training loss = 2.3276  Validation loss = 4.9600  \n",
      "\n",
      "Fold: 5  Epoch: 566  Training loss = 2.3275  Validation loss = 4.9599  \n",
      "\n",
      "Fold: 5  Epoch: 567  Training loss = 2.3274  Validation loss = 4.9597  \n",
      "\n",
      "Fold: 5  Epoch: 568  Training loss = 2.3273  Validation loss = 4.9596  \n",
      "\n",
      "Fold: 5  Epoch: 569  Training loss = 2.3272  Validation loss = 4.9595  \n",
      "\n",
      "Fold: 5  Epoch: 570  Training loss = 2.3271  Validation loss = 4.9594  \n",
      "\n",
      "Fold: 5  Epoch: 571  Training loss = 2.3271  Validation loss = 4.9592  \n",
      "\n",
      "Fold: 5  Epoch: 572  Training loss = 2.3270  Validation loss = 4.9591  \n",
      "\n",
      "Fold: 5  Epoch: 573  Training loss = 2.3269  Validation loss = 4.9589  \n",
      "\n",
      "Fold: 5  Epoch: 574  Training loss = 2.3268  Validation loss = 4.9588  \n",
      "\n",
      "Fold: 5  Epoch: 575  Training loss = 2.3267  Validation loss = 4.9587  \n",
      "\n",
      "Fold: 5  Epoch: 576  Training loss = 2.3266  Validation loss = 4.9586  \n",
      "\n",
      "Fold: 5  Epoch: 577  Training loss = 2.3265  Validation loss = 4.9585  \n",
      "\n",
      "Fold: 5  Epoch: 578  Training loss = 2.3265  Validation loss = 4.9584  \n",
      "\n",
      "Fold: 5  Epoch: 579  Training loss = 2.3264  Validation loss = 4.9583  \n",
      "\n",
      "Fold: 5  Epoch: 580  Training loss = 2.3264  Validation loss = 4.9582  \n",
      "\n",
      "Fold: 5  Epoch: 581  Training loss = 2.3263  Validation loss = 4.9581  \n",
      "\n",
      "Fold: 5  Epoch: 582  Training loss = 2.3262  Validation loss = 4.9580  \n",
      "\n",
      "Fold: 5  Epoch: 583  Training loss = 2.3262  Validation loss = 4.9579  \n",
      "\n",
      "Fold: 5  Epoch: 584  Training loss = 2.3261  Validation loss = 4.9578  \n",
      "\n",
      "Fold: 5  Epoch: 585  Training loss = 2.3260  Validation loss = 4.9577  \n",
      "\n",
      "Fold: 5  Epoch: 586  Training loss = 2.3259  Validation loss = 4.9575  \n",
      "\n",
      "Fold: 5  Epoch: 587  Training loss = 2.3259  Validation loss = 4.9574  \n",
      "\n",
      "Fold: 5  Epoch: 588  Training loss = 2.3258  Validation loss = 4.9573  \n",
      "\n",
      "Fold: 5  Epoch: 589  Training loss = 2.3257  Validation loss = 4.9572  \n",
      "\n",
      "Fold: 5  Epoch: 590  Training loss = 2.3256  Validation loss = 4.9570  \n",
      "\n",
      "Fold: 5  Epoch: 591  Training loss = 2.3255  Validation loss = 4.9569  \n",
      "\n",
      "Fold: 5  Epoch: 592  Training loss = 2.3254  Validation loss = 4.9568  \n",
      "\n",
      "Fold: 5  Epoch: 593  Training loss = 2.3253  Validation loss = 4.9566  \n",
      "\n",
      "Fold: 5  Epoch: 594  Training loss = 2.3252  Validation loss = 4.9565  \n",
      "\n",
      "Fold: 5  Epoch: 595  Training loss = 2.3251  Validation loss = 4.9563  \n",
      "\n",
      "Fold: 5  Epoch: 596  Training loss = 2.3251  Validation loss = 4.9562  \n",
      "\n",
      "Fold: 5  Epoch: 597  Training loss = 2.3250  Validation loss = 4.9561  \n",
      "\n",
      "Fold: 5  Epoch: 598  Training loss = 2.3249  Validation loss = 4.9559  \n",
      "\n",
      "Fold: 5  Epoch: 599  Training loss = 2.3248  Validation loss = 4.9558  \n",
      "\n",
      "Fold: 5  Epoch: 600  Training loss = 2.3247  Validation loss = 4.9557  \n",
      "\n",
      "Fold: 5  Epoch: 601  Training loss = 2.3246  Validation loss = 4.9556  \n",
      "\n",
      "Fold: 5  Epoch: 602  Training loss = 2.3246  Validation loss = 4.9555  \n",
      "\n",
      "Fold: 5  Epoch: 603  Training loss = 2.3245  Validation loss = 4.9553  \n",
      "\n",
      "Fold: 5  Epoch: 604  Training loss = 2.3244  Validation loss = 4.9552  \n",
      "\n",
      "Fold: 5  Epoch: 605  Training loss = 2.3243  Validation loss = 4.9551  \n",
      "\n",
      "Fold: 5  Epoch: 606  Training loss = 2.3243  Validation loss = 4.9550  \n",
      "\n",
      "Fold: 5  Epoch: 607  Training loss = 2.3241  Validation loss = 4.9548  \n",
      "\n",
      "Fold: 5  Epoch: 608  Training loss = 2.3241  Validation loss = 4.9547  \n",
      "\n",
      "Fold: 5  Epoch: 609  Training loss = 2.3240  Validation loss = 4.9546  \n",
      "\n",
      "Fold: 5  Epoch: 610  Training loss = 2.3239  Validation loss = 4.9544  \n",
      "\n",
      "Fold: 5  Epoch: 611  Training loss = 2.3238  Validation loss = 4.9543  \n",
      "\n",
      "Fold: 5  Epoch: 612  Training loss = 2.3237  Validation loss = 4.9542  \n",
      "\n",
      "Fold: 5  Epoch: 613  Training loss = 2.3236  Validation loss = 4.9540  \n",
      "\n",
      "Fold: 5  Epoch: 614  Training loss = 2.3236  Validation loss = 4.9539  \n",
      "\n",
      "Fold: 5  Epoch: 615  Training loss = 2.3234  Validation loss = 4.9537  \n",
      "\n",
      "Fold: 5  Epoch: 616  Training loss = 2.3233  Validation loss = 4.9536  \n",
      "\n",
      "Fold: 5  Epoch: 617  Training loss = 2.3233  Validation loss = 4.9534  \n",
      "\n",
      "Fold: 5  Epoch: 618  Training loss = 2.3232  Validation loss = 4.9533  \n",
      "\n",
      "Fold: 5  Epoch: 619  Training loss = 2.3231  Validation loss = 4.9532  \n",
      "\n",
      "Fold: 5  Epoch: 620  Training loss = 2.3230  Validation loss = 4.9531  \n",
      "\n",
      "Fold: 5  Epoch: 621  Training loss = 2.3229  Validation loss = 4.9529  \n",
      "\n",
      "Fold: 5  Epoch: 622  Training loss = 2.3228  Validation loss = 4.9528  \n",
      "\n",
      "Fold: 5  Epoch: 623  Training loss = 2.3227  Validation loss = 4.9526  \n",
      "\n",
      "Fold: 5  Epoch: 624  Training loss = 2.3226  Validation loss = 4.9525  \n",
      "\n",
      "Fold: 5  Epoch: 625  Training loss = 2.3226  Validation loss = 4.9524  \n",
      "\n",
      "Fold: 5  Epoch: 626  Training loss = 2.3225  Validation loss = 4.9523  \n",
      "\n",
      "Fold: 5  Epoch: 627  Training loss = 2.3224  Validation loss = 4.9521  \n",
      "\n",
      "Fold: 5  Epoch: 628  Training loss = 2.3223  Validation loss = 4.9520  \n",
      "\n",
      "Fold: 5  Epoch: 629  Training loss = 2.3222  Validation loss = 4.9519  \n",
      "\n",
      "Fold: 5  Epoch: 630  Training loss = 2.3222  Validation loss = 4.9518  \n",
      "\n",
      "Fold: 5  Epoch: 631  Training loss = 2.3221  Validation loss = 4.9517  \n",
      "\n",
      "Fold: 5  Epoch: 632  Training loss = 2.3220  Validation loss = 4.9515  \n",
      "\n",
      "Fold: 5  Epoch: 633  Training loss = 2.3219  Validation loss = 4.9514  \n",
      "\n",
      "Fold: 5  Epoch: 634  Training loss = 2.3218  Validation loss = 4.9513  \n",
      "\n",
      "Fold: 5  Epoch: 635  Training loss = 2.3218  Validation loss = 4.9512  \n",
      "\n",
      "Fold: 5  Epoch: 636  Training loss = 2.3217  Validation loss = 4.9511  \n",
      "\n",
      "Fold: 5  Epoch: 637  Training loss = 2.3217  Validation loss = 4.9510  \n",
      "\n",
      "Fold: 5  Epoch: 638  Training loss = 2.3216  Validation loss = 4.9509  \n",
      "\n",
      "Fold: 5  Epoch: 639  Training loss = 2.3215  Validation loss = 4.9508  \n",
      "\n",
      "Fold: 5  Epoch: 640  Training loss = 2.3214  Validation loss = 4.9506  \n",
      "\n",
      "Fold: 5  Epoch: 641  Training loss = 2.3213  Validation loss = 4.9505  \n",
      "\n",
      "Fold: 5  Epoch: 642  Training loss = 2.3212  Validation loss = 4.9503  \n",
      "\n",
      "Fold: 5  Epoch: 643  Training loss = 2.3211  Validation loss = 4.9502  \n",
      "\n",
      "Fold: 5  Epoch: 644  Training loss = 2.3210  Validation loss = 4.9500  \n",
      "\n",
      "Fold: 5  Epoch: 645  Training loss = 2.3210  Validation loss = 4.9499  \n",
      "\n",
      "Fold: 5  Epoch: 646  Training loss = 2.3209  Validation loss = 4.9498  \n",
      "\n",
      "Fold: 5  Epoch: 647  Training loss = 2.3208  Validation loss = 4.9497  \n",
      "\n",
      "Fold: 5  Epoch: 648  Training loss = 2.3207  Validation loss = 4.9496  \n",
      "\n",
      "Fold: 5  Epoch: 649  Training loss = 2.3207  Validation loss = 4.9495  \n",
      "\n",
      "Fold: 5  Epoch: 650  Training loss = 2.3206  Validation loss = 4.9494  \n",
      "\n",
      "Fold: 5  Epoch: 651  Training loss = 2.3205  Validation loss = 4.9492  \n",
      "\n",
      "Fold: 5  Epoch: 652  Training loss = 2.3204  Validation loss = 4.9491  \n",
      "\n",
      "Fold: 5  Epoch: 653  Training loss = 2.3203  Validation loss = 4.9490  \n",
      "\n",
      "Fold: 5  Epoch: 654  Training loss = 2.3203  Validation loss = 4.9489  \n",
      "\n",
      "Fold: 5  Epoch: 655  Training loss = 2.3202  Validation loss = 4.9488  \n",
      "\n",
      "Fold: 5  Epoch: 656  Training loss = 2.3201  Validation loss = 4.9486  \n",
      "\n",
      "Fold: 5  Epoch: 657  Training loss = 2.3200  Validation loss = 4.9485  \n",
      "\n",
      "Fold: 5  Epoch: 658  Training loss = 2.3199  Validation loss = 4.9484  \n",
      "\n",
      "Fold: 5  Epoch: 659  Training loss = 2.3199  Validation loss = 4.9483  \n",
      "\n",
      "Fold: 5  Epoch: 660  Training loss = 2.3198  Validation loss = 4.9482  \n",
      "\n",
      "Fold: 5  Epoch: 661  Training loss = 2.3197  Validation loss = 4.9480  \n",
      "\n",
      "Fold: 5  Epoch: 662  Training loss = 2.3196  Validation loss = 4.9479  \n",
      "\n",
      "Fold: 5  Epoch: 663  Training loss = 2.3196  Validation loss = 4.9478  \n",
      "\n",
      "Fold: 5  Epoch: 664  Training loss = 2.3195  Validation loss = 4.9477  \n",
      "\n",
      "Fold: 5  Epoch: 665  Training loss = 2.3194  Validation loss = 4.9476  \n",
      "\n",
      "Fold: 5  Epoch: 666  Training loss = 2.3193  Validation loss = 4.9474  \n",
      "\n",
      "Fold: 5  Epoch: 667  Training loss = 2.3192  Validation loss = 4.9473  \n",
      "\n",
      "Fold: 5  Epoch: 668  Training loss = 2.3191  Validation loss = 4.9472  \n",
      "\n",
      "Fold: 5  Epoch: 669  Training loss = 2.3190  Validation loss = 4.9470  \n",
      "\n",
      "Fold: 5  Epoch: 670  Training loss = 2.3189  Validation loss = 4.9469  \n",
      "\n",
      "Fold: 5  Epoch: 671  Training loss = 2.3189  Validation loss = 4.9468  \n",
      "\n",
      "Fold: 5  Epoch: 672  Training loss = 2.3188  Validation loss = 4.9467  \n",
      "\n",
      "Fold: 5  Epoch: 673  Training loss = 2.3187  Validation loss = 4.9465  \n",
      "\n",
      "Fold: 5  Epoch: 674  Training loss = 2.3187  Validation loss = 4.9465  \n",
      "\n",
      "Fold: 5  Epoch: 675  Training loss = 2.3186  Validation loss = 4.9463  \n",
      "\n",
      "Fold: 5  Epoch: 676  Training loss = 2.3185  Validation loss = 4.9462  \n",
      "\n",
      "Fold: 5  Epoch: 677  Training loss = 2.3184  Validation loss = 4.9461  \n",
      "\n",
      "Fold: 5  Epoch: 678  Training loss = 2.3184  Validation loss = 4.9460  \n",
      "\n",
      "Fold: 5  Epoch: 679  Training loss = 2.3183  Validation loss = 4.9459  \n",
      "\n",
      "Fold: 5  Epoch: 680  Training loss = 2.3182  Validation loss = 4.9457  \n",
      "\n",
      "Fold: 5  Epoch: 681  Training loss = 2.3181  Validation loss = 4.9456  \n",
      "\n",
      "Fold: 5  Epoch: 682  Training loss = 2.3180  Validation loss = 4.9455  \n",
      "\n",
      "Fold: 5  Epoch: 683  Training loss = 2.3180  Validation loss = 4.9454  \n",
      "\n",
      "Fold: 5  Epoch: 684  Training loss = 2.3179  Validation loss = 4.9453  \n",
      "\n",
      "Fold: 5  Epoch: 685  Training loss = 2.3178  Validation loss = 4.9452  \n",
      "\n",
      "Fold: 5  Epoch: 686  Training loss = 2.3178  Validation loss = 4.9451  \n",
      "\n",
      "Fold: 5  Epoch: 687  Training loss = 2.3177  Validation loss = 4.9450  \n",
      "\n",
      "Fold: 5  Epoch: 688  Training loss = 2.3176  Validation loss = 4.9448  \n",
      "\n",
      "Fold: 5  Epoch: 689  Training loss = 2.3175  Validation loss = 4.9447  \n",
      "\n",
      "Fold: 5  Epoch: 690  Training loss = 2.3174  Validation loss = 4.9446  \n",
      "\n",
      "Fold: 5  Epoch: 691  Training loss = 2.3173  Validation loss = 4.9444  \n",
      "\n",
      "Fold: 5  Epoch: 692  Training loss = 2.3173  Validation loss = 4.9443  \n",
      "\n",
      "Fold: 5  Epoch: 693  Training loss = 2.3172  Validation loss = 4.9442  \n",
      "\n",
      "Fold: 5  Epoch: 694  Training loss = 2.3171  Validation loss = 4.9441  \n",
      "\n",
      "Fold: 5  Epoch: 695  Training loss = 2.3170  Validation loss = 4.9440  \n",
      "\n",
      "Fold: 5  Epoch: 696  Training loss = 2.3170  Validation loss = 4.9439  \n",
      "\n",
      "Fold: 5  Epoch: 697  Training loss = 2.3169  Validation loss = 4.9438  \n",
      "\n",
      "Fold: 5  Epoch: 698  Training loss = 2.3169  Validation loss = 4.9437  \n",
      "\n",
      "Fold: 5  Epoch: 699  Training loss = 2.3168  Validation loss = 4.9436  \n",
      "\n",
      "Fold: 5  Epoch: 700  Training loss = 2.3167  Validation loss = 4.9434  \n",
      "\n",
      "Fold: 5  Epoch: 701  Training loss = 2.3166  Validation loss = 4.9433  \n",
      "\n",
      "Fold: 5  Epoch: 702  Training loss = 2.3166  Validation loss = 4.9432  \n",
      "\n",
      "Fold: 5  Epoch: 703  Training loss = 2.3165  Validation loss = 4.9431  \n",
      "\n",
      "Fold: 5  Epoch: 704  Training loss = 2.3164  Validation loss = 4.9430  \n",
      "\n",
      "Fold: 5  Epoch: 705  Training loss = 2.3163  Validation loss = 4.9428  \n",
      "\n",
      "Fold: 5  Epoch: 706  Training loss = 2.3162  Validation loss = 4.9427  \n",
      "\n",
      "Fold: 5  Epoch: 707  Training loss = 2.3161  Validation loss = 4.9425  \n",
      "\n",
      "Fold: 5  Epoch: 708  Training loss = 2.3160  Validation loss = 4.9424  \n",
      "\n",
      "Fold: 5  Epoch: 709  Training loss = 2.3159  Validation loss = 4.9423  \n",
      "\n",
      "Fold: 5  Epoch: 710  Training loss = 2.3159  Validation loss = 4.9421  \n",
      "\n",
      "Fold: 5  Epoch: 711  Training loss = 2.3158  Validation loss = 4.9420  \n",
      "\n",
      "Fold: 5  Epoch: 712  Training loss = 2.3157  Validation loss = 4.9419  \n",
      "\n",
      "Fold: 5  Epoch: 713  Training loss = 2.3156  Validation loss = 4.9418  \n",
      "\n",
      "Fold: 5  Epoch: 714  Training loss = 2.3155  Validation loss = 4.9416  \n",
      "\n",
      "Fold: 5  Epoch: 715  Training loss = 2.3154  Validation loss = 4.9414  \n",
      "\n",
      "Fold: 5  Epoch: 716  Training loss = 2.3153  Validation loss = 4.9413  \n",
      "\n",
      "Fold: 5  Epoch: 717  Training loss = 2.3152  Validation loss = 4.9411  \n",
      "\n",
      "Fold: 5  Epoch: 718  Training loss = 2.3151  Validation loss = 4.9410  \n",
      "\n",
      "Fold: 5  Epoch: 719  Training loss = 2.3150  Validation loss = 4.9408  \n",
      "\n",
      "Fold: 5  Epoch: 720  Training loss = 2.3149  Validation loss = 4.9406  \n",
      "\n",
      "Fold: 5  Epoch: 721  Training loss = 2.3148  Validation loss = 4.9405  \n",
      "\n",
      "Fold: 5  Epoch: 722  Training loss = 2.3148  Validation loss = 4.9404  \n",
      "\n",
      "Fold: 5  Epoch: 723  Training loss = 2.3147  Validation loss = 4.9403  \n",
      "\n",
      "Fold: 5  Epoch: 724  Training loss = 2.3146  Validation loss = 4.9401  \n",
      "\n",
      "Fold: 5  Epoch: 725  Training loss = 2.3145  Validation loss = 4.9400  \n",
      "\n",
      "Fold: 5  Epoch: 726  Training loss = 2.3144  Validation loss = 4.9399  \n",
      "\n",
      "Fold: 5  Epoch: 727  Training loss = 2.3144  Validation loss = 4.9398  \n",
      "\n",
      "Fold: 5  Epoch: 728  Training loss = 2.3143  Validation loss = 4.9397  \n",
      "\n",
      "Fold: 5  Epoch: 729  Training loss = 2.3142  Validation loss = 4.9395  \n",
      "\n",
      "Fold: 5  Epoch: 730  Training loss = 2.3141  Validation loss = 4.9394  \n",
      "\n",
      "Fold: 5  Epoch: 731  Training loss = 2.3140  Validation loss = 4.9392  \n",
      "\n",
      "Fold: 5  Epoch: 732  Training loss = 2.3139  Validation loss = 4.9391  \n",
      "\n",
      "Fold: 5  Epoch: 733  Training loss = 2.3138  Validation loss = 4.9390  \n",
      "\n",
      "Fold: 5  Epoch: 734  Training loss = 2.3137  Validation loss = 4.9388  \n",
      "\n",
      "Fold: 5  Epoch: 735  Training loss = 2.3137  Validation loss = 4.9388  \n",
      "\n",
      "Fold: 5  Epoch: 736  Training loss = 2.3136  Validation loss = 4.9386  \n",
      "\n",
      "Fold: 5  Epoch: 737  Training loss = 2.3135  Validation loss = 4.9385  \n",
      "\n",
      "Fold: 5  Epoch: 738  Training loss = 2.3135  Validation loss = 4.9384  \n",
      "\n",
      "Fold: 5  Epoch: 739  Training loss = 2.3134  Validation loss = 4.9383  \n",
      "\n",
      "Fold: 5  Epoch: 740  Training loss = 2.3133  Validation loss = 4.9382  \n",
      "\n",
      "Fold: 5  Epoch: 741  Training loss = 2.3133  Validation loss = 4.9381  \n",
      "\n",
      "Fold: 5  Epoch: 742  Training loss = 2.3132  Validation loss = 4.9380  \n",
      "\n",
      "Fold: 5  Epoch: 743  Training loss = 2.3131  Validation loss = 4.9378  \n",
      "\n",
      "Fold: 5  Epoch: 744  Training loss = 2.3130  Validation loss = 4.9378  \n",
      "\n",
      "Fold: 5  Epoch: 745  Training loss = 2.3130  Validation loss = 4.9376  \n",
      "\n",
      "Fold: 5  Epoch: 746  Training loss = 2.3129  Validation loss = 4.9375  \n",
      "\n",
      "Fold: 5  Epoch: 747  Training loss = 2.3128  Validation loss = 4.9374  \n",
      "\n",
      "Fold: 5  Epoch: 748  Training loss = 2.3127  Validation loss = 4.9373  \n",
      "\n",
      "Fold: 5  Epoch: 749  Training loss = 2.3127  Validation loss = 4.9372  \n",
      "\n",
      "Fold: 5  Epoch: 750  Training loss = 2.3126  Validation loss = 4.9370  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 750  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.6101  Validation loss = 2.8803  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.6100  Validation loss = 2.8801  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.6098  Validation loss = 2.8799  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.6097  Validation loss = 2.8797  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.6096  Validation loss = 2.8795  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.6095  Validation loss = 2.8794  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.6094  Validation loss = 2.8791  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.6093  Validation loss = 2.8789  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.6092  Validation loss = 2.8787  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.6091  Validation loss = 2.8786  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.6090  Validation loss = 2.8784  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.6089  Validation loss = 2.8782  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.6087  Validation loss = 2.8780  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.6086  Validation loss = 2.8778  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.6085  Validation loss = 2.8776  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.6084  Validation loss = 2.8774  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.6083  Validation loss = 2.8773  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.6082  Validation loss = 2.8771  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.6081  Validation loss = 2.8769  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.6080  Validation loss = 2.8768  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.6079  Validation loss = 2.8766  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.6078  Validation loss = 2.8763  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.6077  Validation loss = 2.8762  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.6076  Validation loss = 2.8760  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.6075  Validation loss = 2.8758  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.6074  Validation loss = 2.8756  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.6073  Validation loss = 2.8755  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.6072  Validation loss = 2.8753  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.6071  Validation loss = 2.8752  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.6070  Validation loss = 2.8750  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.6069  Validation loss = 2.8748  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.6068  Validation loss = 2.8746  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.6066  Validation loss = 2.8744  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.6065  Validation loss = 2.8742  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.6064  Validation loss = 2.8740  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.6063  Validation loss = 2.8739  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.6062  Validation loss = 2.8737  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.6061  Validation loss = 2.8735  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.6060  Validation loss = 2.8733  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.6059  Validation loss = 2.8731  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.6058  Validation loss = 2.8729  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.6057  Validation loss = 2.8727  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.6056  Validation loss = 2.8725  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.6055  Validation loss = 2.8724  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.6054  Validation loss = 2.8721  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.6053  Validation loss = 2.8720  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.6052  Validation loss = 2.8718  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.6050  Validation loss = 2.8716  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.6049  Validation loss = 2.8714  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.6048  Validation loss = 2.8712  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.6047  Validation loss = 2.8710  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.6046  Validation loss = 2.8708  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.6045  Validation loss = 2.8706  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.6044  Validation loss = 2.8704  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.6043  Validation loss = 2.8702  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.6042  Validation loss = 2.8700  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.6041  Validation loss = 2.8699  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.6039  Validation loss = 2.8697  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.6038  Validation loss = 2.8695  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.6037  Validation loss = 2.8693  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.6036  Validation loss = 2.8691  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.6035  Validation loss = 2.8689  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.6034  Validation loss = 2.8688  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.6033  Validation loss = 2.8686  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.6032  Validation loss = 2.8684  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.6031  Validation loss = 2.8682  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.6030  Validation loss = 2.8680  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.6029  Validation loss = 2.8678  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.6028  Validation loss = 2.8676  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.6027  Validation loss = 2.8674  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.6026  Validation loss = 2.8673  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.6025  Validation loss = 2.8671  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.6024  Validation loss = 2.8669  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.6023  Validation loss = 2.8667  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.6022  Validation loss = 2.8665  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.6021  Validation loss = 2.8664  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.6020  Validation loss = 2.8662  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.6019  Validation loss = 2.8660  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.6018  Validation loss = 2.8659  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.6017  Validation loss = 2.8656  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.6016  Validation loss = 2.8655  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.6015  Validation loss = 2.8653  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.6014  Validation loss = 2.8651  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.6012  Validation loss = 2.8649  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.6011  Validation loss = 2.8647  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.6010  Validation loss = 2.8645  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.6009  Validation loss = 2.8643  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.6008  Validation loss = 2.8641  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.6007  Validation loss = 2.8640  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.6006  Validation loss = 2.8637  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.6005  Validation loss = 2.8635  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.6003  Validation loss = 2.8633  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.6002  Validation loss = 2.8631  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.6001  Validation loss = 2.8629  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.6000  Validation loss = 2.8627  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.5999  Validation loss = 2.8626  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.5998  Validation loss = 2.8624  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.5997  Validation loss = 2.8622  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.5996  Validation loss = 2.8620  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.5995  Validation loss = 2.8618  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.5994  Validation loss = 2.8617  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.5993  Validation loss = 2.8615  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.5992  Validation loss = 2.8613  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.5991  Validation loss = 2.8611  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.5990  Validation loss = 2.8610  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.5989  Validation loss = 2.8608  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.5988  Validation loss = 2.8606  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.5986  Validation loss = 2.8604  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.5985  Validation loss = 2.8602  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.5984  Validation loss = 2.8600  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.5984  Validation loss = 2.8599  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.5983  Validation loss = 2.8597  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.5982  Validation loss = 2.8596  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.5981  Validation loss = 2.8594  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.5980  Validation loss = 2.8593  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.5979  Validation loss = 2.8591  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.5978  Validation loss = 2.8589  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.5976  Validation loss = 2.8587  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.5975  Validation loss = 2.8584  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.5974  Validation loss = 2.8583  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.5973  Validation loss = 2.8581  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.5972  Validation loss = 2.8579  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.5971  Validation loss = 2.8577  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.5970  Validation loss = 2.8575  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.5969  Validation loss = 2.8573  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.5968  Validation loss = 2.8572  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.5967  Validation loss = 2.8570  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.5966  Validation loss = 2.8568  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.5965  Validation loss = 2.8566  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.5964  Validation loss = 2.8564  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.5963  Validation loss = 2.8563  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.5962  Validation loss = 2.8561  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.5961  Validation loss = 2.8559  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.5960  Validation loss = 2.8557  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.5959  Validation loss = 2.8555  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.5958  Validation loss = 2.8553  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.5957  Validation loss = 2.8551  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.5956  Validation loss = 2.8550  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.5955  Validation loss = 2.8548  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.5954  Validation loss = 2.8546  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.5952  Validation loss = 2.8544  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.5952  Validation loss = 2.8543  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.5950  Validation loss = 2.8540  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.5949  Validation loss = 2.8538  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.5948  Validation loss = 2.8536  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.5947  Validation loss = 2.8535  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.5946  Validation loss = 2.8532  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.5945  Validation loss = 2.8530  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.5944  Validation loss = 2.8529  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.5943  Validation loss = 2.8527  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.5942  Validation loss = 2.8525  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.5941  Validation loss = 2.8523  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.5940  Validation loss = 2.8522  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.5939  Validation loss = 2.8520  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.5938  Validation loss = 2.8519  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.5937  Validation loss = 2.8516  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.5936  Validation loss = 2.8515  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.5935  Validation loss = 2.8512  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.5934  Validation loss = 2.8511  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.5933  Validation loss = 2.8509  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.5932  Validation loss = 2.8507  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.5931  Validation loss = 2.8505  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.5930  Validation loss = 2.8503  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.5929  Validation loss = 2.8501  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.5927  Validation loss = 2.8499  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.5926  Validation loss = 2.8497  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.5925  Validation loss = 2.8495  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.5924  Validation loss = 2.8494  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.5924  Validation loss = 2.8492  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.5923  Validation loss = 2.8491  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.5921  Validation loss = 2.8488  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.5920  Validation loss = 2.8486  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.5919  Validation loss = 2.8484  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.5918  Validation loss = 2.8483  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.5917  Validation loss = 2.8481  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.5917  Validation loss = 2.8480  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.5915  Validation loss = 2.8478  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.5914  Validation loss = 2.8476  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.5913  Validation loss = 2.8474  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.5912  Validation loss = 2.8472  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.5911  Validation loss = 2.8471  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.5911  Validation loss = 2.8470  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.5910  Validation loss = 2.8468  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.5909  Validation loss = 2.8466  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.5908  Validation loss = 2.8464  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.5907  Validation loss = 2.8462  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.5905  Validation loss = 2.8460  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.5904  Validation loss = 2.8458  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.5903  Validation loss = 2.8456  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.5902  Validation loss = 2.8454  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.5901  Validation loss = 2.8451  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.5900  Validation loss = 2.8449  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.5899  Validation loss = 2.8448  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.5898  Validation loss = 2.8446  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.5897  Validation loss = 2.8444  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.5896  Validation loss = 2.8442  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.5895  Validation loss = 2.8440  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.5894  Validation loss = 2.8438  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.5893  Validation loss = 2.8437  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.5892  Validation loss = 2.8435  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.5891  Validation loss = 2.8433  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.5890  Validation loss = 2.8431  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.5889  Validation loss = 2.8430  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.5888  Validation loss = 2.8428  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.5887  Validation loss = 2.8427  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.5886  Validation loss = 2.8424  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.5885  Validation loss = 2.8422  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.5884  Validation loss = 2.8421  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.5883  Validation loss = 2.8419  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.5882  Validation loss = 2.8417  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.5881  Validation loss = 2.8416  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.5880  Validation loss = 2.8415  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.5879  Validation loss = 2.8413  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.5879  Validation loss = 2.8411  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.5877  Validation loss = 2.8409  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.5876  Validation loss = 2.8408  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.5875  Validation loss = 2.8406  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.5874  Validation loss = 2.8404  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.5873  Validation loss = 2.8402  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.5872  Validation loss = 2.8400  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.5871  Validation loss = 2.8398  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.5870  Validation loss = 2.8396  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.5869  Validation loss = 2.8394  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.5868  Validation loss = 2.8392  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.5867  Validation loss = 2.8390  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.5866  Validation loss = 2.8388  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.5865  Validation loss = 2.8386  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.5864  Validation loss = 2.8384  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.5863  Validation loss = 2.8382  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.5862  Validation loss = 2.8381  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.5861  Validation loss = 2.8379  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.5860  Validation loss = 2.8378  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.5859  Validation loss = 2.8376  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.5858  Validation loss = 2.8374  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.5857  Validation loss = 2.8372  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.5856  Validation loss = 2.8370  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.5855  Validation loss = 2.8368  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.5854  Validation loss = 2.8366  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.5852  Validation loss = 2.8364  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.5851  Validation loss = 2.8363  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.5850  Validation loss = 2.8361  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.5849  Validation loss = 2.8359  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.5848  Validation loss = 2.8357  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.5848  Validation loss = 2.8356  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.5847  Validation loss = 2.8355  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.5846  Validation loss = 2.8353  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.5845  Validation loss = 2.8351  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.5844  Validation loss = 2.8350  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.5843  Validation loss = 2.8348  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.5843  Validation loss = 2.8347  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.5842  Validation loss = 2.8345  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.5840  Validation loss = 2.8343  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.5840  Validation loss = 2.8341  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.5838  Validation loss = 2.8339  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.5838  Validation loss = 2.8338  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.5837  Validation loss = 2.8336  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.5835  Validation loss = 2.8334  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.5835  Validation loss = 2.8332  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.5834  Validation loss = 2.8331  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.5833  Validation loss = 2.8330  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.5832  Validation loss = 2.8327  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.5831  Validation loss = 2.8325  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.5830  Validation loss = 2.8324  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.5829  Validation loss = 2.8322  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.5828  Validation loss = 2.8320  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.5827  Validation loss = 2.8318  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.5826  Validation loss = 2.8316  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.5824  Validation loss = 2.8314  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.5823  Validation loss = 2.8312  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.5822  Validation loss = 2.8310  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.5821  Validation loss = 2.8308  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.5820  Validation loss = 2.8306  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.5819  Validation loss = 2.8304  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.5818  Validation loss = 2.8302  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.5817  Validation loss = 2.8300  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.5816  Validation loss = 2.8299  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.5815  Validation loss = 2.8297  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.5814  Validation loss = 2.8296  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.5813  Validation loss = 2.8293  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.5812  Validation loss = 2.8291  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.5811  Validation loss = 2.8290  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.5810  Validation loss = 2.8288  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.5809  Validation loss = 2.8286  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.5808  Validation loss = 2.8284  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.5807  Validation loss = 2.8282  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.5806  Validation loss = 2.8281  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.5805  Validation loss = 2.8279  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.5804  Validation loss = 2.8277  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.5803  Validation loss = 2.8276  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.5802  Validation loss = 2.8274  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.5801  Validation loss = 2.8272  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.5800  Validation loss = 2.8270  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.5799  Validation loss = 2.8269  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.5798  Validation loss = 2.8267  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.5797  Validation loss = 2.8265  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.5796  Validation loss = 2.8263  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.5795  Validation loss = 2.8261  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.5794  Validation loss = 2.8259  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.5793  Validation loss = 2.8258  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.5792  Validation loss = 2.8256  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.5791  Validation loss = 2.8254  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.5790  Validation loss = 2.8251  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.5789  Validation loss = 2.8249  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.5788  Validation loss = 2.8247  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.5786  Validation loss = 2.8245  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.5785  Validation loss = 2.8243  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.5785  Validation loss = 2.8242  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.5784  Validation loss = 2.8240  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.5783  Validation loss = 2.8238  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.5782  Validation loss = 2.8236  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.5780  Validation loss = 2.8234  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.5780  Validation loss = 2.8232  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.5778  Validation loss = 2.8230  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.5777  Validation loss = 2.8228  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.5776  Validation loss = 2.8226  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.5775  Validation loss = 2.8224  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.5774  Validation loss = 2.8222  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.5773  Validation loss = 2.8220  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.5773  Validation loss = 2.8219  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.5772  Validation loss = 2.8217  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.5771  Validation loss = 2.8215  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.5770  Validation loss = 2.8214  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.5769  Validation loss = 2.8212  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.5768  Validation loss = 2.8210  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.5767  Validation loss = 2.8208  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.5766  Validation loss = 2.8206  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.5764  Validation loss = 2.8204  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.5763  Validation loss = 2.8202  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.5762  Validation loss = 2.8200  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.5761  Validation loss = 2.8198  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.5761  Validation loss = 2.8197  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.5760  Validation loss = 2.8196  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.5759  Validation loss = 2.8193  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.5757  Validation loss = 2.8191  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.5757  Validation loss = 2.8190  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.5756  Validation loss = 2.8188  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.5755  Validation loss = 2.8186  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.5754  Validation loss = 2.8185  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.5753  Validation loss = 2.8183  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.5752  Validation loss = 2.8181  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.5751  Validation loss = 2.8179  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.5750  Validation loss = 2.8177  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.5749  Validation loss = 2.8175  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.5748  Validation loss = 2.8173  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.5747  Validation loss = 2.8172  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.5746  Validation loss = 2.8170  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.5745  Validation loss = 2.8168  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.5744  Validation loss = 2.8166  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.5743  Validation loss = 2.8165  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.5742  Validation loss = 2.8163  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.5741  Validation loss = 2.8161  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.5740  Validation loss = 2.8159  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.5739  Validation loss = 2.8158  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.5738  Validation loss = 2.8155  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.5737  Validation loss = 2.8153  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.5736  Validation loss = 2.8151  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.5735  Validation loss = 2.8150  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.5734  Validation loss = 2.8148  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.5733  Validation loss = 2.8146  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.5732  Validation loss = 2.8144  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.5731  Validation loss = 2.8142  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.5730  Validation loss = 2.8141  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.5729  Validation loss = 2.8139  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.5728  Validation loss = 2.8137  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.5727  Validation loss = 2.8135  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.5726  Validation loss = 2.8133  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.5725  Validation loss = 2.8130  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.5723  Validation loss = 2.8128  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.5722  Validation loss = 2.8125  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.5721  Validation loss = 2.8124  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.5720  Validation loss = 2.8122  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.5719  Validation loss = 2.8121  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.5718  Validation loss = 2.8119  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.5717  Validation loss = 2.8117  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.5716  Validation loss = 2.8115  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.5715  Validation loss = 2.8113  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.5714  Validation loss = 2.8111  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.5713  Validation loss = 2.8109  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.5712  Validation loss = 2.8107  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.5711  Validation loss = 2.8106  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.5710  Validation loss = 2.8104  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.5709  Validation loss = 2.8102  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.5708  Validation loss = 2.8100  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.5707  Validation loss = 2.8098  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.5707  Validation loss = 2.8096  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.5706  Validation loss = 2.8095  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.5705  Validation loss = 2.8093  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.5704  Validation loss = 2.8091  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.5703  Validation loss = 2.8089  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.5702  Validation loss = 2.8088  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.5701  Validation loss = 2.8086  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.5700  Validation loss = 2.8084  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.5699  Validation loss = 2.8082  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.5698  Validation loss = 2.8080  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.5697  Validation loss = 2.8078  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.5696  Validation loss = 2.8077  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.5695  Validation loss = 2.8075  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.5694  Validation loss = 2.8073  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.5693  Validation loss = 2.8071  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.5692  Validation loss = 2.8069  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.5691  Validation loss = 2.8068  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.5690  Validation loss = 2.8066  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.5690  Validation loss = 2.8064  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.5689  Validation loss = 2.8063  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.5688  Validation loss = 2.8062  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.5687  Validation loss = 2.8060  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.5686  Validation loss = 2.8058  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.5685  Validation loss = 2.8056  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.5684  Validation loss = 2.8054  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.5683  Validation loss = 2.8052  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.5682  Validation loss = 2.8050  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.5681  Validation loss = 2.8048  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.5680  Validation loss = 2.8046  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.5679  Validation loss = 2.8044  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.5678  Validation loss = 2.8043  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.5677  Validation loss = 2.8040  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.5676  Validation loss = 2.8039  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.5675  Validation loss = 2.8037  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.5674  Validation loss = 2.8035  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.5673  Validation loss = 2.8033  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.5672  Validation loss = 2.8031  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.5671  Validation loss = 2.8030  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.5670  Validation loss = 2.8028  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.5669  Validation loss = 2.8026  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.5668  Validation loss = 2.8025  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.5667  Validation loss = 2.8023  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.5666  Validation loss = 2.8021  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.5665  Validation loss = 2.8019  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.5664  Validation loss = 2.8018  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.5663  Validation loss = 2.8015  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.5662  Validation loss = 2.8013  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.5661  Validation loss = 2.8011  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.5660  Validation loss = 2.8009  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.5659  Validation loss = 2.8008  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.5658  Validation loss = 2.8006  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.5657  Validation loss = 2.8004  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.5656  Validation loss = 2.8002  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.5655  Validation loss = 2.8000  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.5654  Validation loss = 2.7999  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.5653  Validation loss = 2.7997  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.5652  Validation loss = 2.7995  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.5651  Validation loss = 2.7993  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.5650  Validation loss = 2.7991  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.5649  Validation loss = 2.7990  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.5649  Validation loss = 2.7988  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.5648  Validation loss = 2.7987  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.5647  Validation loss = 2.7985  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.5646  Validation loss = 2.7983  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.5645  Validation loss = 2.7981  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.5644  Validation loss = 2.7979  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.5643  Validation loss = 2.7977  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.5642  Validation loss = 2.7975  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.5640  Validation loss = 2.7973  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.5639  Validation loss = 2.7971  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.5638  Validation loss = 2.7968  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.5637  Validation loss = 2.7967  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.5636  Validation loss = 2.7965  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.5635  Validation loss = 2.7963  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.5634  Validation loss = 2.7961  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.5633  Validation loss = 2.7959  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.5632  Validation loss = 2.7958  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.5631  Validation loss = 2.7956  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.5630  Validation loss = 2.7954  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.5629  Validation loss = 2.7952  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.5628  Validation loss = 2.7950  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.5628  Validation loss = 2.7948  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.5627  Validation loss = 2.7947  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.5626  Validation loss = 2.7945  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.5625  Validation loss = 2.7943  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.5624  Validation loss = 2.7941  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.5622  Validation loss = 2.7939  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.5622  Validation loss = 2.7937  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.5621  Validation loss = 2.7935  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.5620  Validation loss = 2.7933  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.5619  Validation loss = 2.7932  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.5618  Validation loss = 2.7930  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.5617  Validation loss = 2.7928  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.5616  Validation loss = 2.7926  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.5615  Validation loss = 2.7924  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.5614  Validation loss = 2.7922  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.5613  Validation loss = 2.7920  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.5612  Validation loss = 2.7919  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.5611  Validation loss = 2.7917  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.5610  Validation loss = 2.7915  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.5609  Validation loss = 2.7914  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.5608  Validation loss = 2.7911  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.5607  Validation loss = 2.7909  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.5606  Validation loss = 2.7907  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.5605  Validation loss = 2.7906  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.5604  Validation loss = 2.7903  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.5603  Validation loss = 2.7902  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.5602  Validation loss = 2.7900  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.5601  Validation loss = 2.7899  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.5600  Validation loss = 2.7897  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.5599  Validation loss = 2.7894  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.5598  Validation loss = 2.7892  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.5597  Validation loss = 2.7891  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.5596  Validation loss = 2.7889  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.5595  Validation loss = 2.7887  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.5594  Validation loss = 2.7886  \n",
      "\n",
      "Fold: 6  Epoch: 501  Training loss = 2.5593  Validation loss = 2.7884  \n",
      "\n",
      "Fold: 6  Epoch: 502  Training loss = 2.5592  Validation loss = 2.7882  \n",
      "\n",
      "Fold: 6  Epoch: 503  Training loss = 2.5591  Validation loss = 2.7880  \n",
      "\n",
      "Fold: 6  Epoch: 504  Training loss = 2.5590  Validation loss = 2.7878  \n",
      "\n",
      "Fold: 6  Epoch: 505  Training loss = 2.5589  Validation loss = 2.7876  \n",
      "\n",
      "Fold: 6  Epoch: 506  Training loss = 2.5588  Validation loss = 2.7874  \n",
      "\n",
      "Fold: 6  Epoch: 507  Training loss = 2.5587  Validation loss = 2.7873  \n",
      "\n",
      "Fold: 6  Epoch: 508  Training loss = 2.5585  Validation loss = 2.7870  \n",
      "\n",
      "Fold: 6  Epoch: 509  Training loss = 2.5585  Validation loss = 2.7869  \n",
      "\n",
      "Fold: 6  Epoch: 510  Training loss = 2.5584  Validation loss = 2.7867  \n",
      "\n",
      "Fold: 6  Epoch: 511  Training loss = 2.5583  Validation loss = 2.7865  \n",
      "\n",
      "Fold: 6  Epoch: 512  Training loss = 2.5581  Validation loss = 2.7863  \n",
      "\n",
      "Fold: 6  Epoch: 513  Training loss = 2.5581  Validation loss = 2.7861  \n",
      "\n",
      "Fold: 6  Epoch: 514  Training loss = 2.5580  Validation loss = 2.7859  \n",
      "\n",
      "Fold: 6  Epoch: 515  Training loss = 2.5579  Validation loss = 2.7858  \n",
      "\n",
      "Fold: 6  Epoch: 516  Training loss = 2.5578  Validation loss = 2.7855  \n",
      "\n",
      "Fold: 6  Epoch: 517  Training loss = 2.5577  Validation loss = 2.7853  \n",
      "\n",
      "Fold: 6  Epoch: 518  Training loss = 2.5576  Validation loss = 2.7851  \n",
      "\n",
      "Fold: 6  Epoch: 519  Training loss = 2.5575  Validation loss = 2.7849  \n",
      "\n",
      "Fold: 6  Epoch: 520  Training loss = 2.5573  Validation loss = 2.7847  \n",
      "\n",
      "Fold: 6  Epoch: 521  Training loss = 2.5573  Validation loss = 2.7846  \n",
      "\n",
      "Fold: 6  Epoch: 522  Training loss = 2.5572  Validation loss = 2.7844  \n",
      "\n",
      "Fold: 6  Epoch: 523  Training loss = 2.5571  Validation loss = 2.7843  \n",
      "\n",
      "Fold: 6  Epoch: 524  Training loss = 2.5570  Validation loss = 2.7841  \n",
      "\n",
      "Fold: 6  Epoch: 525  Training loss = 2.5569  Validation loss = 2.7839  \n",
      "\n",
      "Fold: 6  Epoch: 526  Training loss = 2.5568  Validation loss = 2.7838  \n",
      "\n",
      "Fold: 6  Epoch: 527  Training loss = 2.5567  Validation loss = 2.7836  \n",
      "\n",
      "Fold: 6  Epoch: 528  Training loss = 2.5566  Validation loss = 2.7834  \n",
      "\n",
      "Fold: 6  Epoch: 529  Training loss = 2.5565  Validation loss = 2.7832  \n",
      "\n",
      "Fold: 6  Epoch: 530  Training loss = 2.5564  Validation loss = 2.7830  \n",
      "\n",
      "Fold: 6  Epoch: 531  Training loss = 2.5564  Validation loss = 2.7829  \n",
      "\n",
      "Fold: 6  Epoch: 532  Training loss = 2.5563  Validation loss = 2.7827  \n",
      "\n",
      "Fold: 6  Epoch: 533  Training loss = 2.5561  Validation loss = 2.7824  \n",
      "\n",
      "Fold: 6  Epoch: 534  Training loss = 2.5561  Validation loss = 2.7823  \n",
      "\n",
      "Fold: 6  Epoch: 535  Training loss = 2.5560  Validation loss = 2.7821  \n",
      "\n",
      "Fold: 6  Epoch: 536  Training loss = 2.5559  Validation loss = 2.7819  \n",
      "\n",
      "Fold: 6  Epoch: 537  Training loss = 2.5558  Validation loss = 2.7817  \n",
      "\n",
      "Fold: 6  Epoch: 538  Training loss = 2.5557  Validation loss = 2.7815  \n",
      "\n",
      "Fold: 6  Epoch: 539  Training loss = 2.5556  Validation loss = 2.7814  \n",
      "\n",
      "Fold: 6  Epoch: 540  Training loss = 2.5555  Validation loss = 2.7812  \n",
      "\n",
      "Fold: 6  Epoch: 541  Training loss = 2.5554  Validation loss = 2.7810  \n",
      "\n",
      "Fold: 6  Epoch: 542  Training loss = 2.5553  Validation loss = 2.7808  \n",
      "\n",
      "Fold: 6  Epoch: 543  Training loss = 2.5552  Validation loss = 2.7806  \n",
      "\n",
      "Fold: 6  Epoch: 544  Training loss = 2.5551  Validation loss = 2.7804  \n",
      "\n",
      "Fold: 6  Epoch: 545  Training loss = 2.5550  Validation loss = 2.7802  \n",
      "\n",
      "Fold: 6  Epoch: 546  Training loss = 2.5549  Validation loss = 2.7800  \n",
      "\n",
      "Fold: 6  Epoch: 547  Training loss = 2.5548  Validation loss = 2.7798  \n",
      "\n",
      "Fold: 6  Epoch: 548  Training loss = 2.5547  Validation loss = 2.7796  \n",
      "\n",
      "Fold: 6  Epoch: 549  Training loss = 2.5546  Validation loss = 2.7795  \n",
      "\n",
      "Fold: 6  Epoch: 550  Training loss = 2.5545  Validation loss = 2.7793  \n",
      "\n",
      "Fold: 6  Epoch: 551  Training loss = 2.5544  Validation loss = 2.7791  \n",
      "\n",
      "Fold: 6  Epoch: 552  Training loss = 2.5543  Validation loss = 2.7789  \n",
      "\n",
      "Fold: 6  Epoch: 553  Training loss = 2.5542  Validation loss = 2.7787  \n",
      "\n",
      "Fold: 6  Epoch: 554  Training loss = 2.5541  Validation loss = 2.7785  \n",
      "\n",
      "Fold: 6  Epoch: 555  Training loss = 2.5540  Validation loss = 2.7784  \n",
      "\n",
      "Fold: 6  Epoch: 556  Training loss = 2.5540  Validation loss = 2.7782  \n",
      "\n",
      "Fold: 6  Epoch: 557  Training loss = 2.5539  Validation loss = 2.7781  \n",
      "\n",
      "Fold: 6  Epoch: 558  Training loss = 2.5538  Validation loss = 2.7779  \n",
      "\n",
      "Fold: 6  Epoch: 559  Training loss = 2.5537  Validation loss = 2.7777  \n",
      "\n",
      "Fold: 6  Epoch: 560  Training loss = 2.5536  Validation loss = 2.7775  \n",
      "\n",
      "Fold: 6  Epoch: 561  Training loss = 2.5535  Validation loss = 2.7773  \n",
      "\n",
      "Fold: 6  Epoch: 562  Training loss = 2.5534  Validation loss = 2.7771  \n",
      "\n",
      "Fold: 6  Epoch: 563  Training loss = 2.5533  Validation loss = 2.7770  \n",
      "\n",
      "Fold: 6  Epoch: 564  Training loss = 2.5531  Validation loss = 2.7767  \n",
      "\n",
      "Fold: 6  Epoch: 565  Training loss = 2.5531  Validation loss = 2.7765  \n",
      "\n",
      "Fold: 6  Epoch: 566  Training loss = 2.5530  Validation loss = 2.7764  \n",
      "\n",
      "Fold: 6  Epoch: 567  Training loss = 2.5529  Validation loss = 2.7762  \n",
      "\n",
      "Fold: 6  Epoch: 568  Training loss = 2.5528  Validation loss = 2.7759  \n",
      "\n",
      "Fold: 6  Epoch: 569  Training loss = 2.5527  Validation loss = 2.7758  \n",
      "\n",
      "Fold: 6  Epoch: 570  Training loss = 2.5526  Validation loss = 2.7756  \n",
      "\n",
      "Fold: 6  Epoch: 571  Training loss = 2.5525  Validation loss = 2.7754  \n",
      "\n",
      "Fold: 6  Epoch: 572  Training loss = 2.5523  Validation loss = 2.7751  \n",
      "\n",
      "Fold: 6  Epoch: 573  Training loss = 2.5522  Validation loss = 2.7750  \n",
      "\n",
      "Fold: 6  Epoch: 574  Training loss = 2.5521  Validation loss = 2.7748  \n",
      "\n",
      "Fold: 6  Epoch: 575  Training loss = 2.5520  Validation loss = 2.7746  \n",
      "\n",
      "Fold: 6  Epoch: 576  Training loss = 2.5520  Validation loss = 2.7744  \n",
      "\n",
      "Fold: 6  Epoch: 577  Training loss = 2.5519  Validation loss = 2.7743  \n",
      "\n",
      "Fold: 6  Epoch: 578  Training loss = 2.5518  Validation loss = 2.7741  \n",
      "\n",
      "Fold: 6  Epoch: 579  Training loss = 2.5517  Validation loss = 2.7740  \n",
      "\n",
      "Fold: 6  Epoch: 580  Training loss = 2.5516  Validation loss = 2.7738  \n",
      "\n",
      "Fold: 6  Epoch: 581  Training loss = 2.5515  Validation loss = 2.7736  \n",
      "\n",
      "Fold: 6  Epoch: 582  Training loss = 2.5514  Validation loss = 2.7734  \n",
      "\n",
      "Fold: 6  Epoch: 583  Training loss = 2.5513  Validation loss = 2.7732  \n",
      "\n",
      "Fold: 6  Epoch: 584  Training loss = 2.5512  Validation loss = 2.7730  \n",
      "\n",
      "Fold: 6  Epoch: 585  Training loss = 2.5511  Validation loss = 2.7729  \n",
      "\n",
      "Fold: 6  Epoch: 586  Training loss = 2.5510  Validation loss = 2.7727  \n",
      "\n",
      "Fold: 6  Epoch: 587  Training loss = 2.5509  Validation loss = 2.7724  \n",
      "\n",
      "Fold: 6  Epoch: 588  Training loss = 2.5508  Validation loss = 2.7723  \n",
      "\n",
      "Fold: 6  Epoch: 589  Training loss = 2.5507  Validation loss = 2.7721  \n",
      "\n",
      "Fold: 6  Epoch: 590  Training loss = 2.5506  Validation loss = 2.7719  \n",
      "\n",
      "Fold: 6  Epoch: 591  Training loss = 2.5505  Validation loss = 2.7717  \n",
      "\n",
      "Fold: 6  Epoch: 592  Training loss = 2.5504  Validation loss = 2.7715  \n",
      "\n",
      "Fold: 6  Epoch: 593  Training loss = 2.5503  Validation loss = 2.7713  \n",
      "\n",
      "Fold: 6  Epoch: 594  Training loss = 2.5502  Validation loss = 2.7711  \n",
      "\n",
      "Fold: 6  Epoch: 595  Training loss = 2.5501  Validation loss = 2.7709  \n",
      "\n",
      "Fold: 6  Epoch: 596  Training loss = 2.5500  Validation loss = 2.7707  \n",
      "\n",
      "Fold: 6  Epoch: 597  Training loss = 2.5499  Validation loss = 2.7705  \n",
      "\n",
      "Fold: 6  Epoch: 598  Training loss = 2.5498  Validation loss = 2.7704  \n",
      "\n",
      "Fold: 6  Epoch: 599  Training loss = 2.5497  Validation loss = 2.7702  \n",
      "\n",
      "Fold: 6  Epoch: 600  Training loss = 2.5496  Validation loss = 2.7699  \n",
      "\n",
      "Fold: 6  Epoch: 601  Training loss = 2.5495  Validation loss = 2.7698  \n",
      "\n",
      "Fold: 6  Epoch: 602  Training loss = 2.5494  Validation loss = 2.7696  \n",
      "\n",
      "Fold: 6  Epoch: 603  Training loss = 2.5493  Validation loss = 2.7693  \n",
      "\n",
      "Fold: 6  Epoch: 604  Training loss = 2.5492  Validation loss = 2.7691  \n",
      "\n",
      "Fold: 6  Epoch: 605  Training loss = 2.5491  Validation loss = 2.7690  \n",
      "\n",
      "Fold: 6  Epoch: 606  Training loss = 2.5490  Validation loss = 2.7688  \n",
      "\n",
      "Fold: 6  Epoch: 607  Training loss = 2.5489  Validation loss = 2.7686  \n",
      "\n",
      "Fold: 6  Epoch: 608  Training loss = 2.5488  Validation loss = 2.7684  \n",
      "\n",
      "Fold: 6  Epoch: 609  Training loss = 2.5487  Validation loss = 2.7682  \n",
      "\n",
      "Fold: 6  Epoch: 610  Training loss = 2.5486  Validation loss = 2.7680  \n",
      "\n",
      "Fold: 6  Epoch: 611  Training loss = 2.5485  Validation loss = 2.7678  \n",
      "\n",
      "Fold: 6  Epoch: 612  Training loss = 2.5484  Validation loss = 2.7676  \n",
      "\n",
      "Fold: 6  Epoch: 613  Training loss = 2.5483  Validation loss = 2.7674  \n",
      "\n",
      "Fold: 6  Epoch: 614  Training loss = 2.5482  Validation loss = 2.7672  \n",
      "\n",
      "Fold: 6  Epoch: 615  Training loss = 2.5480  Validation loss = 2.7670  \n",
      "\n",
      "Fold: 6  Epoch: 616  Training loss = 2.5479  Validation loss = 2.7668  \n",
      "\n",
      "Fold: 6  Epoch: 617  Training loss = 2.5479  Validation loss = 2.7666  \n",
      "\n",
      "Fold: 6  Epoch: 618  Training loss = 2.5477  Validation loss = 2.7664  \n",
      "\n",
      "Fold: 6  Epoch: 619  Training loss = 2.5476  Validation loss = 2.7662  \n",
      "\n",
      "Fold: 6  Epoch: 620  Training loss = 2.5475  Validation loss = 2.7660  \n",
      "\n",
      "Fold: 6  Epoch: 621  Training loss = 2.5474  Validation loss = 2.7658  \n",
      "\n",
      "Fold: 6  Epoch: 622  Training loss = 2.5473  Validation loss = 2.7656  \n",
      "\n",
      "Fold: 6  Epoch: 623  Training loss = 2.5472  Validation loss = 2.7654  \n",
      "\n",
      "Fold: 6  Epoch: 624  Training loss = 2.5472  Validation loss = 2.7652  \n",
      "\n",
      "Fold: 6  Epoch: 625  Training loss = 2.5470  Validation loss = 2.7650  \n",
      "\n",
      "Fold: 6  Epoch: 626  Training loss = 2.5469  Validation loss = 2.7648  \n",
      "\n",
      "Fold: 6  Epoch: 627  Training loss = 2.5468  Validation loss = 2.7645  \n",
      "\n",
      "Fold: 6  Epoch: 628  Training loss = 2.5467  Validation loss = 2.7644  \n",
      "\n",
      "Fold: 6  Epoch: 629  Training loss = 2.5467  Validation loss = 2.7643  \n",
      "\n",
      "Fold: 6  Epoch: 630  Training loss = 2.5466  Validation loss = 2.7641  \n",
      "\n",
      "Fold: 6  Epoch: 631  Training loss = 2.5465  Validation loss = 2.7639  \n",
      "\n",
      "Fold: 6  Epoch: 632  Training loss = 2.5464  Validation loss = 2.7637  \n",
      "\n",
      "Fold: 6  Epoch: 633  Training loss = 2.5463  Validation loss = 2.7635  \n",
      "\n",
      "Fold: 6  Epoch: 634  Training loss = 2.5462  Validation loss = 2.7633  \n",
      "\n",
      "Fold: 6  Epoch: 635  Training loss = 2.5461  Validation loss = 2.7632  \n",
      "\n",
      "Fold: 6  Epoch: 636  Training loss = 2.5460  Validation loss = 2.7630  \n",
      "\n",
      "Fold: 6  Epoch: 637  Training loss = 2.5459  Validation loss = 2.7628  \n",
      "\n",
      "Fold: 6  Epoch: 638  Training loss = 2.5458  Validation loss = 2.7626  \n",
      "\n",
      "Fold: 6  Epoch: 639  Training loss = 2.5457  Validation loss = 2.7624  \n",
      "\n",
      "Fold: 6  Epoch: 640  Training loss = 2.5456  Validation loss = 2.7622  \n",
      "\n",
      "Fold: 6  Epoch: 641  Training loss = 2.5455  Validation loss = 2.7620  \n",
      "\n",
      "Fold: 6  Epoch: 642  Training loss = 2.5454  Validation loss = 2.7618  \n",
      "\n",
      "Fold: 6  Epoch: 643  Training loss = 2.5453  Validation loss = 2.7617  \n",
      "\n",
      "Fold: 6  Epoch: 644  Training loss = 2.5452  Validation loss = 2.7615  \n",
      "\n",
      "Fold: 6  Epoch: 645  Training loss = 2.5451  Validation loss = 2.7613  \n",
      "\n",
      "Fold: 6  Epoch: 646  Training loss = 2.5450  Validation loss = 2.7611  \n",
      "\n",
      "Fold: 6  Epoch: 647  Training loss = 2.5449  Validation loss = 2.7608  \n",
      "\n",
      "Fold: 6  Epoch: 648  Training loss = 2.5448  Validation loss = 2.7607  \n",
      "\n",
      "Fold: 6  Epoch: 649  Training loss = 2.5447  Validation loss = 2.7604  \n",
      "\n",
      "Fold: 6  Epoch: 650  Training loss = 2.5446  Validation loss = 2.7602  \n",
      "\n",
      "Fold: 6  Epoch: 651  Training loss = 2.5445  Validation loss = 2.7601  \n",
      "\n",
      "Fold: 6  Epoch: 652  Training loss = 2.5444  Validation loss = 2.7599  \n",
      "\n",
      "Fold: 6  Epoch: 653  Training loss = 2.5443  Validation loss = 2.7597  \n",
      "\n",
      "Fold: 6  Epoch: 654  Training loss = 2.5442  Validation loss = 2.7596  \n",
      "\n",
      "Fold: 6  Epoch: 655  Training loss = 2.5441  Validation loss = 2.7593  \n",
      "\n",
      "Fold: 6  Epoch: 656  Training loss = 2.5440  Validation loss = 2.7591  \n",
      "\n",
      "Fold: 6  Epoch: 657  Training loss = 2.5439  Validation loss = 2.7590  \n",
      "\n",
      "Fold: 6  Epoch: 658  Training loss = 2.5438  Validation loss = 2.7588  \n",
      "\n",
      "Fold: 6  Epoch: 659  Training loss = 2.5437  Validation loss = 2.7585  \n",
      "\n",
      "Fold: 6  Epoch: 660  Training loss = 2.5436  Validation loss = 2.7583  \n",
      "\n",
      "Fold: 6  Epoch: 661  Training loss = 2.5435  Validation loss = 2.7581  \n",
      "\n",
      "Fold: 6  Epoch: 662  Training loss = 2.5434  Validation loss = 2.7579  \n",
      "\n",
      "Fold: 6  Epoch: 663  Training loss = 2.5433  Validation loss = 2.7578  \n",
      "\n",
      "Fold: 6  Epoch: 664  Training loss = 2.5432  Validation loss = 2.7576  \n",
      "\n",
      "Fold: 6  Epoch: 665  Training loss = 2.5431  Validation loss = 2.7574  \n",
      "\n",
      "Fold: 6  Epoch: 666  Training loss = 2.5430  Validation loss = 2.7572  \n",
      "\n",
      "Fold: 6  Epoch: 667  Training loss = 2.5430  Validation loss = 2.7571  \n",
      "\n",
      "Fold: 6  Epoch: 668  Training loss = 2.5429  Validation loss = 2.7569  \n",
      "\n",
      "Fold: 6  Epoch: 669  Training loss = 2.5428  Validation loss = 2.7568  \n",
      "\n",
      "Fold: 6  Epoch: 670  Training loss = 2.5427  Validation loss = 2.7566  \n",
      "\n",
      "Fold: 6  Epoch: 671  Training loss = 2.5426  Validation loss = 2.7564  \n",
      "\n",
      "Fold: 6  Epoch: 672  Training loss = 2.5425  Validation loss = 2.7562  \n",
      "\n",
      "Fold: 6  Epoch: 673  Training loss = 2.5424  Validation loss = 2.7560  \n",
      "\n",
      "Fold: 6  Epoch: 674  Training loss = 2.5423  Validation loss = 2.7558  \n",
      "\n",
      "Fold: 6  Epoch: 675  Training loss = 2.5422  Validation loss = 2.7556  \n",
      "\n",
      "Fold: 6  Epoch: 676  Training loss = 2.5421  Validation loss = 2.7554  \n",
      "\n",
      "Fold: 6  Epoch: 677  Training loss = 2.5420  Validation loss = 2.7552  \n",
      "\n",
      "Fold: 6  Epoch: 678  Training loss = 2.5419  Validation loss = 2.7550  \n",
      "\n",
      "Fold: 6  Epoch: 679  Training loss = 2.5418  Validation loss = 2.7548  \n",
      "\n",
      "Fold: 6  Epoch: 680  Training loss = 2.5417  Validation loss = 2.7546  \n",
      "\n",
      "Fold: 6  Epoch: 681  Training loss = 2.5416  Validation loss = 2.7544  \n",
      "\n",
      "Fold: 6  Epoch: 682  Training loss = 2.5415  Validation loss = 2.7542  \n",
      "\n",
      "Fold: 6  Epoch: 683  Training loss = 2.5414  Validation loss = 2.7541  \n",
      "\n",
      "Fold: 6  Epoch: 684  Training loss = 2.5414  Validation loss = 2.7539  \n",
      "\n",
      "Fold: 6  Epoch: 685  Training loss = 2.5413  Validation loss = 2.7537  \n",
      "\n",
      "Fold: 6  Epoch: 686  Training loss = 2.5412  Validation loss = 2.7535  \n",
      "\n",
      "Fold: 6  Epoch: 687  Training loss = 2.5411  Validation loss = 2.7534  \n",
      "\n",
      "Fold: 6  Epoch: 688  Training loss = 2.5410  Validation loss = 2.7532  \n",
      "\n",
      "Fold: 6  Epoch: 689  Training loss = 2.5409  Validation loss = 2.7531  \n",
      "\n",
      "Fold: 6  Epoch: 690  Training loss = 2.5408  Validation loss = 2.7529  \n",
      "\n",
      "Fold: 6  Epoch: 691  Training loss = 2.5407  Validation loss = 2.7527  \n",
      "\n",
      "Fold: 6  Epoch: 692  Training loss = 2.5406  Validation loss = 2.7525  \n",
      "\n",
      "Fold: 6  Epoch: 693  Training loss = 2.5405  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 6  Epoch: 694  Training loss = 2.5404  Validation loss = 2.7521  \n",
      "\n",
      "Fold: 6  Epoch: 695  Training loss = 2.5403  Validation loss = 2.7520  \n",
      "\n",
      "Fold: 6  Epoch: 696  Training loss = 2.5402  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 6  Epoch: 697  Training loss = 2.5401  Validation loss = 2.7516  \n",
      "\n",
      "Fold: 6  Epoch: 698  Training loss = 2.5400  Validation loss = 2.7514  \n",
      "\n",
      "Fold: 6  Epoch: 699  Training loss = 2.5399  Validation loss = 2.7512  \n",
      "\n",
      "Fold: 6  Epoch: 700  Training loss = 2.5398  Validation loss = 2.7510  \n",
      "\n",
      "Fold: 6  Epoch: 701  Training loss = 2.5397  Validation loss = 2.7508  \n",
      "\n",
      "Fold: 6  Epoch: 702  Training loss = 2.5396  Validation loss = 2.7505  \n",
      "\n",
      "Fold: 6  Epoch: 703  Training loss = 2.5395  Validation loss = 2.7504  \n",
      "\n",
      "Fold: 6  Epoch: 704  Training loss = 2.5394  Validation loss = 2.7501  \n",
      "\n",
      "Fold: 6  Epoch: 705  Training loss = 2.5393  Validation loss = 2.7500  \n",
      "\n",
      "Fold: 6  Epoch: 706  Training loss = 2.5392  Validation loss = 2.7498  \n",
      "\n",
      "Fold: 6  Epoch: 707  Training loss = 2.5392  Validation loss = 2.7496  \n",
      "\n",
      "Fold: 6  Epoch: 708  Training loss = 2.5391  Validation loss = 2.7495  \n",
      "\n",
      "Fold: 6  Epoch: 709  Training loss = 2.5390  Validation loss = 2.7493  \n",
      "\n",
      "Fold: 6  Epoch: 710  Training loss = 2.5389  Validation loss = 2.7491  \n",
      "\n",
      "Fold: 6  Epoch: 711  Training loss = 2.5388  Validation loss = 2.7489  \n",
      "\n",
      "Fold: 6  Epoch: 712  Training loss = 2.5387  Validation loss = 2.7488  \n",
      "\n",
      "Fold: 6  Epoch: 713  Training loss = 2.5386  Validation loss = 2.7486  \n",
      "\n",
      "Fold: 6  Epoch: 714  Training loss = 2.5385  Validation loss = 2.7484  \n",
      "\n",
      "Fold: 6  Epoch: 715  Training loss = 2.5384  Validation loss = 2.7482  \n",
      "\n",
      "Fold: 6  Epoch: 716  Training loss = 2.5383  Validation loss = 2.7480  \n",
      "\n",
      "Fold: 6  Epoch: 717  Training loss = 2.5382  Validation loss = 2.7478  \n",
      "\n",
      "Fold: 6  Epoch: 718  Training loss = 2.5381  Validation loss = 2.7476  \n",
      "\n",
      "Fold: 6  Epoch: 719  Training loss = 2.5381  Validation loss = 2.7475  \n",
      "\n",
      "Fold: 6  Epoch: 720  Training loss = 2.5380  Validation loss = 2.7473  \n",
      "\n",
      "Fold: 6  Epoch: 721  Training loss = 2.5379  Validation loss = 2.7471  \n",
      "\n",
      "Fold: 6  Epoch: 722  Training loss = 2.5378  Validation loss = 2.7469  \n",
      "\n",
      "Fold: 6  Epoch: 723  Training loss = 2.5377  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 6  Epoch: 724  Training loss = 2.5376  Validation loss = 2.7466  \n",
      "\n",
      "Fold: 6  Epoch: 725  Training loss = 2.5375  Validation loss = 2.7463  \n",
      "\n",
      "Fold: 6  Epoch: 726  Training loss = 2.5374  Validation loss = 2.7462  \n",
      "\n",
      "Fold: 6  Epoch: 727  Training loss = 2.5373  Validation loss = 2.7459  \n",
      "\n",
      "Fold: 6  Epoch: 728  Training loss = 2.5372  Validation loss = 2.7458  \n",
      "\n",
      "Fold: 6  Epoch: 729  Training loss = 2.5371  Validation loss = 2.7455  \n",
      "\n",
      "Fold: 6  Epoch: 730  Training loss = 2.5369  Validation loss = 2.7453  \n",
      "\n",
      "Fold: 6  Epoch: 731  Training loss = 2.5368  Validation loss = 2.7451  \n",
      "\n",
      "Fold: 6  Epoch: 732  Training loss = 2.5367  Validation loss = 2.7449  \n",
      "\n",
      "Fold: 6  Epoch: 733  Training loss = 2.5366  Validation loss = 2.7447  \n",
      "\n",
      "Fold: 6  Epoch: 734  Training loss = 2.5365  Validation loss = 2.7445  \n",
      "\n",
      "Fold: 6  Epoch: 735  Training loss = 2.5365  Validation loss = 2.7443  \n",
      "\n",
      "Fold: 6  Epoch: 736  Training loss = 2.5364  Validation loss = 2.7441  \n",
      "\n",
      "Fold: 6  Epoch: 737  Training loss = 2.5362  Validation loss = 2.7439  \n",
      "\n",
      "Fold: 6  Epoch: 738  Training loss = 2.5361  Validation loss = 2.7437  \n",
      "\n",
      "Fold: 6  Epoch: 739  Training loss = 2.5361  Validation loss = 2.7436  \n",
      "\n",
      "Fold: 6  Epoch: 740  Training loss = 2.5360  Validation loss = 2.7434  \n",
      "\n",
      "Fold: 6  Epoch: 741  Training loss = 2.5359  Validation loss = 2.7432  \n",
      "\n",
      "Fold: 6  Epoch: 742  Training loss = 2.5358  Validation loss = 2.7430  \n",
      "\n",
      "Fold: 6  Epoch: 743  Training loss = 2.5357  Validation loss = 2.7429  \n",
      "\n",
      "Fold: 6  Epoch: 744  Training loss = 2.5356  Validation loss = 2.7427  \n",
      "\n",
      "Fold: 6  Epoch: 745  Training loss = 2.5355  Validation loss = 2.7425  \n",
      "\n",
      "Fold: 6  Epoch: 746  Training loss = 2.5354  Validation loss = 2.7424  \n",
      "\n",
      "Fold: 6  Epoch: 747  Training loss = 2.5354  Validation loss = 2.7422  \n",
      "\n",
      "Fold: 6  Epoch: 748  Training loss = 2.5352  Validation loss = 2.7419  \n",
      "\n",
      "Fold: 6  Epoch: 749  Training loss = 2.5351  Validation loss = 2.7417  \n",
      "\n",
      "Fold: 6  Epoch: 750  Training loss = 2.5350  Validation loss = 2.7415  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 750  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.6051  Validation loss = 2.4279  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.6049  Validation loss = 2.4277  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.6048  Validation loss = 2.4275  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.6046  Validation loss = 2.4274  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.6045  Validation loss = 2.4272  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.6044  Validation loss = 2.4271  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.6042  Validation loss = 2.4269  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.6041  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.6039  Validation loss = 2.4265  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.6038  Validation loss = 2.4264  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.6037  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.6036  Validation loss = 2.4261  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.6034  Validation loss = 2.4259  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.6033  Validation loss = 2.4258  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.6032  Validation loss = 2.4256  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.6030  Validation loss = 2.4254  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.6029  Validation loss = 2.4253  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.6028  Validation loss = 2.4251  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.6027  Validation loss = 2.4250  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.6025  Validation loss = 2.4248  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.6024  Validation loss = 2.4247  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.6023  Validation loss = 2.4245  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.6021  Validation loss = 2.4243  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.6020  Validation loss = 2.4241  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.6018  Validation loss = 2.4240  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.6017  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.6016  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.6015  Validation loss = 2.4236  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.6013  Validation loss = 2.4234  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.6012  Validation loss = 2.4232  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.6011  Validation loss = 2.4231  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.6009  Validation loss = 2.4229  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.6008  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.6007  Validation loss = 2.4226  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.6006  Validation loss = 2.4225  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.6004  Validation loss = 2.4223  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.6003  Validation loss = 2.4221  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.6001  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.6000  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.5999  Validation loss = 2.4216  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.5997  Validation loss = 2.4215  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.5996  Validation loss = 2.4213  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.5995  Validation loss = 2.4212  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.5993  Validation loss = 2.4210  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.5992  Validation loss = 2.4208  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.5991  Validation loss = 2.4207  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.5989  Validation loss = 2.4206  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.5988  Validation loss = 2.4204  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.5987  Validation loss = 2.4202  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.5986  Validation loss = 2.4201  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.5984  Validation loss = 2.4200  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.5983  Validation loss = 2.4198  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.5982  Validation loss = 2.4197  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.5981  Validation loss = 2.4195  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.5980  Validation loss = 2.4194  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.5978  Validation loss = 2.4193  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.5977  Validation loss = 2.4191  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.5976  Validation loss = 2.4190  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.5975  Validation loss = 2.4188  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.5974  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.5973  Validation loss = 2.4186  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.5972  Validation loss = 2.4184  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.5970  Validation loss = 2.4183  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.5969  Validation loss = 2.4181  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.5968  Validation loss = 2.4180  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.5967  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.5966  Validation loss = 2.4177  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.5965  Validation loss = 2.4176  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.5963  Validation loss = 2.4174  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.5962  Validation loss = 2.4173  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.5961  Validation loss = 2.4171  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.5960  Validation loss = 2.4170  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.5958  Validation loss = 2.4168  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.5957  Validation loss = 2.4167  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.5956  Validation loss = 2.4166  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.5955  Validation loss = 2.4164  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.5954  Validation loss = 2.4163  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.5953  Validation loss = 2.4161  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.5952  Validation loss = 2.4160  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.5951  Validation loss = 2.4159  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.5949  Validation loss = 2.4157  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.5948  Validation loss = 2.4156  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.5947  Validation loss = 2.4154  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.5946  Validation loss = 2.4153  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.5944  Validation loss = 2.4151  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.5943  Validation loss = 2.4150  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.5942  Validation loss = 2.4148  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.5941  Validation loss = 2.4147  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.5940  Validation loss = 2.4145  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.5938  Validation loss = 2.4144  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.5937  Validation loss = 2.4142  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.5936  Validation loss = 2.4140  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.5934  Validation loss = 2.4138  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.5932  Validation loss = 2.4137  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.5931  Validation loss = 2.4135  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.5930  Validation loss = 2.4133  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.5928  Validation loss = 2.4132  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.5927  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.5926  Validation loss = 2.4128  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.5924  Validation loss = 2.4127  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.5923  Validation loss = 2.4126  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.5922  Validation loss = 2.4124  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.5921  Validation loss = 2.4123  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.5920  Validation loss = 2.4121  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.5918  Validation loss = 2.4120  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.5917  Validation loss = 2.4118  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.5916  Validation loss = 2.4117  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.5915  Validation loss = 2.4115  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.5913  Validation loss = 2.4114  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.5912  Validation loss = 2.4112  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.5911  Validation loss = 2.4111  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.5910  Validation loss = 2.4110  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.5909  Validation loss = 2.4108  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.5907  Validation loss = 2.4107  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.5906  Validation loss = 2.4105  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.5905  Validation loss = 2.4104  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.5904  Validation loss = 2.4102  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.5903  Validation loss = 2.4101  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.5902  Validation loss = 2.4100  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.5901  Validation loss = 2.4099  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.5899  Validation loss = 2.4097  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.5898  Validation loss = 2.4095  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.5897  Validation loss = 2.4094  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.5896  Validation loss = 2.4093  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.5894  Validation loss = 2.4091  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.5893  Validation loss = 2.4090  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.5892  Validation loss = 2.4088  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.5891  Validation loss = 2.4087  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.5890  Validation loss = 2.4085  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.5889  Validation loss = 2.4084  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.5887  Validation loss = 2.4082  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.5886  Validation loss = 2.4081  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.5884  Validation loss = 2.4079  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.5883  Validation loss = 2.4077  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.5882  Validation loss = 2.4076  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.5881  Validation loss = 2.4074  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.5880  Validation loss = 2.4073  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.5879  Validation loss = 2.4072  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.5877  Validation loss = 2.4070  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.5876  Validation loss = 2.4068  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.5875  Validation loss = 2.4067  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.5874  Validation loss = 2.4065  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.5872  Validation loss = 2.4064  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.5871  Validation loss = 2.4062  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.5869  Validation loss = 2.4060  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.5868  Validation loss = 2.4059  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.5867  Validation loss = 2.4057  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.5865  Validation loss = 2.4055  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.5864  Validation loss = 2.4054  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.5863  Validation loss = 2.4052  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.5861  Validation loss = 2.4051  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.5860  Validation loss = 2.4049  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.5859  Validation loss = 2.4048  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.5858  Validation loss = 2.4046  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.5856  Validation loss = 2.4044  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.5855  Validation loss = 2.4043  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.5853  Validation loss = 2.4041  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.5852  Validation loss = 2.4039  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.5851  Validation loss = 2.4038  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.5850  Validation loss = 2.4036  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.5848  Validation loss = 2.4035  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.5847  Validation loss = 2.4033  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.5846  Validation loss = 2.4032  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.5844  Validation loss = 2.4030  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.5843  Validation loss = 2.4029  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.5842  Validation loss = 2.4027  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.5840  Validation loss = 2.4026  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.5839  Validation loss = 2.4024  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.5838  Validation loss = 2.4023  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.5837  Validation loss = 2.4022  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.5836  Validation loss = 2.4020  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.5835  Validation loss = 2.4019  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.5833  Validation loss = 2.4017  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.5832  Validation loss = 2.4015  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.5830  Validation loss = 2.4013  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.5829  Validation loss = 2.4012  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.5828  Validation loss = 2.4010  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.5826  Validation loss = 2.4009  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.5825  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.5824  Validation loss = 2.4005  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.5822  Validation loss = 2.4004  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.5821  Validation loss = 2.4002  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.5820  Validation loss = 2.4001  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.5818  Validation loss = 2.3999  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.5817  Validation loss = 2.3997  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.5816  Validation loss = 2.3996  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.5815  Validation loss = 2.3994  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.5813  Validation loss = 2.3993  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.5812  Validation loss = 2.3991  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.5811  Validation loss = 2.3990  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.5809  Validation loss = 2.3988  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.5808  Validation loss = 2.3987  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.5807  Validation loss = 2.3985  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.5806  Validation loss = 2.3984  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.5804  Validation loss = 2.3982  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.5804  Validation loss = 2.3981  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.5802  Validation loss = 2.3980  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.5801  Validation loss = 2.3978  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.5800  Validation loss = 2.3977  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.5799  Validation loss = 2.3975  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.5797  Validation loss = 2.3974  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.5796  Validation loss = 2.3972  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.5794  Validation loss = 2.3970  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.5792  Validation loss = 2.3968  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.5791  Validation loss = 2.3966  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.5790  Validation loss = 2.3965  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.5789  Validation loss = 2.3963  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.5788  Validation loss = 2.3962  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.5786  Validation loss = 2.3961  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.5785  Validation loss = 2.3959  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.5784  Validation loss = 2.3957  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.5782  Validation loss = 2.3956  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.5781  Validation loss = 2.3954  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.5780  Validation loss = 2.3953  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.5778  Validation loss = 2.3951  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.5777  Validation loss = 2.3950  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.5776  Validation loss = 2.3948  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.5774  Validation loss = 2.3946  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.5773  Validation loss = 2.3945  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.5772  Validation loss = 2.3943  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.5771  Validation loss = 2.3942  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.5770  Validation loss = 2.3940  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.5768  Validation loss = 2.3938  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.5767  Validation loss = 2.3937  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.5766  Validation loss = 2.3936  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.5765  Validation loss = 2.3934  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.5764  Validation loss = 2.3933  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.5762  Validation loss = 2.3932  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.5761  Validation loss = 2.3930  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.5760  Validation loss = 2.3929  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.5758  Validation loss = 2.3927  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.5757  Validation loss = 2.3925  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.5756  Validation loss = 2.3924  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.5755  Validation loss = 2.3923  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.5753  Validation loss = 2.3921  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.5752  Validation loss = 2.3919  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.5751  Validation loss = 2.3918  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.5750  Validation loss = 2.3917  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.5749  Validation loss = 2.3915  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.5748  Validation loss = 2.3914  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.5746  Validation loss = 2.3912  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.5745  Validation loss = 2.3911  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.5744  Validation loss = 2.3909  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.5742  Validation loss = 2.3907  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.5741  Validation loss = 2.3906  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.5740  Validation loss = 2.3904  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.5738  Validation loss = 2.3902  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.5737  Validation loss = 2.3901  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.5736  Validation loss = 2.3899  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.5735  Validation loss = 2.3898  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.5733  Validation loss = 2.3897  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.5732  Validation loss = 2.3895  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.5731  Validation loss = 2.3893  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.5729  Validation loss = 2.3892  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.5728  Validation loss = 2.3890  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.5727  Validation loss = 2.3889  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.5726  Validation loss = 2.3887  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.5724  Validation loss = 2.3885  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.5723  Validation loss = 2.3884  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.5721  Validation loss = 2.3882  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.5720  Validation loss = 2.3881  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.5719  Validation loss = 2.3879  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.5717  Validation loss = 2.3877  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.5716  Validation loss = 2.3875  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.5714  Validation loss = 2.3874  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.5713  Validation loss = 2.3872  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.5712  Validation loss = 2.3871  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.5711  Validation loss = 2.3869  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.5709  Validation loss = 2.3868  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.5708  Validation loss = 2.3866  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.5707  Validation loss = 2.3865  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.5706  Validation loss = 2.3863  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.5704  Validation loss = 2.3862  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.5703  Validation loss = 2.3860  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.5702  Validation loss = 2.3859  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.5700  Validation loss = 2.3857  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.5699  Validation loss = 2.3855  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.5697  Validation loss = 2.3854  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.5696  Validation loss = 2.3852  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.5695  Validation loss = 2.3851  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.5694  Validation loss = 2.3849  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.5693  Validation loss = 2.3848  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.5691  Validation loss = 2.3846  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.5690  Validation loss = 2.3844  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.5689  Validation loss = 2.3843  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.5688  Validation loss = 2.3842  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.5686  Validation loss = 2.3840  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.5685  Validation loss = 2.3838  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.5684  Validation loss = 2.3837  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.5682  Validation loss = 2.3835  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.5681  Validation loss = 2.3833  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.5680  Validation loss = 2.3832  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.5678  Validation loss = 2.3830  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.5677  Validation loss = 2.3829  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.5676  Validation loss = 2.3827  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.5675  Validation loss = 2.3826  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.5673  Validation loss = 2.3824  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.5672  Validation loss = 2.3823  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.5671  Validation loss = 2.3821  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.5670  Validation loss = 2.3820  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.5669  Validation loss = 2.3819  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.5667  Validation loss = 2.3817  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.5666  Validation loss = 2.3816  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.5665  Validation loss = 2.3815  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.5664  Validation loss = 2.3813  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.5663  Validation loss = 2.3812  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.5661  Validation loss = 2.3810  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.5661  Validation loss = 2.3809  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.5659  Validation loss = 2.3807  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.5658  Validation loss = 2.3806  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.5657  Validation loss = 2.3804  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.5655  Validation loss = 2.3803  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.5654  Validation loss = 2.3801  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.5653  Validation loss = 2.3800  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.5652  Validation loss = 2.3799  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.5650  Validation loss = 2.3797  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.5649  Validation loss = 2.3795  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.5648  Validation loss = 2.3794  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.5647  Validation loss = 2.3792  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.5645  Validation loss = 2.3791  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.5644  Validation loss = 2.3789  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.5643  Validation loss = 2.3788  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.5642  Validation loss = 2.3787  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.5641  Validation loss = 2.3785  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.5639  Validation loss = 2.3784  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.5638  Validation loss = 2.3782  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.5637  Validation loss = 2.3781  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.5636  Validation loss = 2.3779  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.5635  Validation loss = 2.3778  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.5633  Validation loss = 2.3777  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.5632  Validation loss = 2.3775  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.5631  Validation loss = 2.3774  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.5630  Validation loss = 2.3773  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.5629  Validation loss = 2.3771  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.5627  Validation loss = 2.3770  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.5626  Validation loss = 2.3768  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.5624  Validation loss = 2.3766  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.5623  Validation loss = 2.3765  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.5622  Validation loss = 2.3763  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.5620  Validation loss = 2.3762  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.5619  Validation loss = 2.3760  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.5618  Validation loss = 2.3759  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.5617  Validation loss = 2.3757  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.5616  Validation loss = 2.3756  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.5614  Validation loss = 2.3754  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.5613  Validation loss = 2.3753  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.5612  Validation loss = 2.3751  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.5611  Validation loss = 2.3750  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.5609  Validation loss = 2.3748  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.5608  Validation loss = 2.3747  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.5607  Validation loss = 2.3745  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.5605  Validation loss = 2.3743  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.5604  Validation loss = 2.3742  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.5603  Validation loss = 2.3740  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.5602  Validation loss = 2.3739  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.5600  Validation loss = 2.3737  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.5599  Validation loss = 2.3736  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.5598  Validation loss = 2.3734  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.5597  Validation loss = 2.3733  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.5595  Validation loss = 2.3731  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.5594  Validation loss = 2.3729  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.5593  Validation loss = 2.3728  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.5591  Validation loss = 2.3726  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.5590  Validation loss = 2.3725  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.5588  Validation loss = 2.3723  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.5587  Validation loss = 2.3722  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.5586  Validation loss = 2.3720  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.5585  Validation loss = 2.3719  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.5584  Validation loss = 2.3717  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.5582  Validation loss = 2.3715  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.5581  Validation loss = 2.3714  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.5580  Validation loss = 2.3712  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.5578  Validation loss = 2.3711  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.5577  Validation loss = 2.3709  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.5576  Validation loss = 2.3708  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.5574  Validation loss = 2.3706  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.5573  Validation loss = 2.3704  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.5572  Validation loss = 2.3703  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.5570  Validation loss = 2.3701  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.5569  Validation loss = 2.3700  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.5568  Validation loss = 2.3698  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.5567  Validation loss = 2.3697  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.5565  Validation loss = 2.3695  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.5564  Validation loss = 2.3694  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.5563  Validation loss = 2.3692  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.5561  Validation loss = 2.3690  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.5560  Validation loss = 2.3689  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.5559  Validation loss = 2.3688  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.5558  Validation loss = 2.3686  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.5557  Validation loss = 2.3685  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.5555  Validation loss = 2.3683  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.5554  Validation loss = 2.3681  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.5553  Validation loss = 2.3680  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.5551  Validation loss = 2.3678  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.5550  Validation loss = 2.3677  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.5549  Validation loss = 2.3675  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.5548  Validation loss = 2.3673  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.5546  Validation loss = 2.3672  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.5545  Validation loss = 2.3670  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.5544  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.5542  Validation loss = 2.3667  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.5541  Validation loss = 2.3666  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.5540  Validation loss = 2.3664  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.5539  Validation loss = 2.3663  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.5538  Validation loss = 2.3662  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.5537  Validation loss = 2.3661  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.5536  Validation loss = 2.3659  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.5534  Validation loss = 2.3657  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.5533  Validation loss = 2.3656  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.5532  Validation loss = 2.3655  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.5531  Validation loss = 2.3653  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.5529  Validation loss = 2.3651  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.5528  Validation loss = 2.3649  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.5526  Validation loss = 2.3648  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.5525  Validation loss = 2.3646  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.5524  Validation loss = 2.3645  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.5523  Validation loss = 2.3644  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.5522  Validation loss = 2.3642  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.5521  Validation loss = 2.3641  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.5520  Validation loss = 2.3639  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.5518  Validation loss = 2.3638  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.5517  Validation loss = 2.3636  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.5516  Validation loss = 2.3635  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.5515  Validation loss = 2.3633  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.5514  Validation loss = 2.3632  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.5512  Validation loss = 2.3631  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.5511  Validation loss = 2.3629  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.5510  Validation loss = 2.3628  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.5509  Validation loss = 2.3626  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.5508  Validation loss = 2.3625  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.5507  Validation loss = 2.3624  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.5505  Validation loss = 2.3622  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.5504  Validation loss = 2.3620  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.5502  Validation loss = 2.3619  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.5501  Validation loss = 2.3617  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.5500  Validation loss = 2.3616  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.5499  Validation loss = 2.3614  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.5498  Validation loss = 2.3613  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.5496  Validation loss = 2.3611  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.5495  Validation loss = 2.3609  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.5494  Validation loss = 2.3608  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.5492  Validation loss = 2.3606  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.5491  Validation loss = 2.3604  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.5489  Validation loss = 2.3603  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.5488  Validation loss = 2.3601  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.5487  Validation loss = 2.3600  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.5486  Validation loss = 2.3599  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.5485  Validation loss = 2.3597  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.5484  Validation loss = 2.3596  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.5483  Validation loss = 2.3594  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.5482  Validation loss = 2.3593  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.5481  Validation loss = 2.3592  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.5479  Validation loss = 2.3590  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.5478  Validation loss = 2.3589  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.5477  Validation loss = 2.3587  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.5476  Validation loss = 2.3585  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.5474  Validation loss = 2.3584  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.5473  Validation loss = 2.3582  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.5472  Validation loss = 2.3581  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.5471  Validation loss = 2.3579  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.5470  Validation loss = 2.3578  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.5469  Validation loss = 2.3577  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.5467  Validation loss = 2.3575  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.5466  Validation loss = 2.3574  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.5465  Validation loss = 2.3572  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.5464  Validation loss = 2.3571  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.5463  Validation loss = 2.3570  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.5462  Validation loss = 2.3568  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.5460  Validation loss = 2.3567  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.5459  Validation loss = 2.3565  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.5458  Validation loss = 2.3564  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.5457  Validation loss = 2.3563  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.5455  Validation loss = 2.3561  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.5454  Validation loss = 2.3559  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.5453  Validation loss = 2.3557  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.5452  Validation loss = 2.3556  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.5450  Validation loss = 2.3555  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.5449  Validation loss = 2.3553  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.5448  Validation loss = 2.3552  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.5447  Validation loss = 2.3550  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.5445  Validation loss = 2.3549  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.5444  Validation loss = 2.3547  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.5443  Validation loss = 2.3545  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.5441  Validation loss = 2.3544  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.5440  Validation loss = 2.3542  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.5439  Validation loss = 2.3541  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.5438  Validation loss = 2.3539  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.5436  Validation loss = 2.3538  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.5435  Validation loss = 2.3536  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.5434  Validation loss = 2.3535  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.5433  Validation loss = 2.3534  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.5432  Validation loss = 2.3532  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.5431  Validation loss = 2.3531  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.5429  Validation loss = 2.3529  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.5428  Validation loss = 2.3527  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.5427  Validation loss = 2.3526  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.5425  Validation loss = 2.3525  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.5424  Validation loss = 2.3523  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.5423  Validation loss = 2.3522  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.5422  Validation loss = 2.3520  \n",
      "\n",
      "Fold: 7  Epoch: 501  Training loss = 2.5421  Validation loss = 2.3519  \n",
      "\n",
      "Fold: 7  Epoch: 502  Training loss = 2.5419  Validation loss = 2.3517  \n",
      "\n",
      "Fold: 7  Epoch: 503  Training loss = 2.5418  Validation loss = 2.3516  \n",
      "\n",
      "Fold: 7  Epoch: 504  Training loss = 2.5417  Validation loss = 2.3514  \n",
      "\n",
      "Fold: 7  Epoch: 505  Training loss = 2.5416  Validation loss = 2.3513  \n",
      "\n",
      "Fold: 7  Epoch: 506  Training loss = 2.5415  Validation loss = 2.3512  \n",
      "\n",
      "Fold: 7  Epoch: 507  Training loss = 2.5413  Validation loss = 2.3510  \n",
      "\n",
      "Fold: 7  Epoch: 508  Training loss = 2.5412  Validation loss = 2.3509  \n",
      "\n",
      "Fold: 7  Epoch: 509  Training loss = 2.5411  Validation loss = 2.3507  \n",
      "\n",
      "Fold: 7  Epoch: 510  Training loss = 2.5409  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 7  Epoch: 511  Training loss = 2.5408  Validation loss = 2.3504  \n",
      "\n",
      "Fold: 7  Epoch: 512  Training loss = 2.5407  Validation loss = 2.3502  \n",
      "\n",
      "Fold: 7  Epoch: 513  Training loss = 2.5406  Validation loss = 2.3501  \n",
      "\n",
      "Fold: 7  Epoch: 514  Training loss = 2.5405  Validation loss = 2.3500  \n",
      "\n",
      "Fold: 7  Epoch: 515  Training loss = 2.5403  Validation loss = 2.3498  \n",
      "\n",
      "Fold: 7  Epoch: 516  Training loss = 2.5402  Validation loss = 2.3497  \n",
      "\n",
      "Fold: 7  Epoch: 517  Training loss = 2.5401  Validation loss = 2.3495  \n",
      "\n",
      "Fold: 7  Epoch: 518  Training loss = 2.5400  Validation loss = 2.3494  \n",
      "\n",
      "Fold: 7  Epoch: 519  Training loss = 2.5398  Validation loss = 2.3492  \n",
      "\n",
      "Fold: 7  Epoch: 520  Training loss = 2.5397  Validation loss = 2.3491  \n",
      "\n",
      "Fold: 7  Epoch: 521  Training loss = 2.5396  Validation loss = 2.3490  \n",
      "\n",
      "Fold: 7  Epoch: 522  Training loss = 2.5395  Validation loss = 2.3488  \n",
      "\n",
      "Fold: 7  Epoch: 523  Training loss = 2.5394  Validation loss = 2.3486  \n",
      "\n",
      "Fold: 7  Epoch: 524  Training loss = 2.5393  Validation loss = 2.3485  \n",
      "\n",
      "Fold: 7  Epoch: 525  Training loss = 2.5391  Validation loss = 2.3484  \n",
      "\n",
      "Fold: 7  Epoch: 526  Training loss = 2.5390  Validation loss = 2.3482  \n",
      "\n",
      "Fold: 7  Epoch: 527  Training loss = 2.5389  Validation loss = 2.3481  \n",
      "\n",
      "Fold: 7  Epoch: 528  Training loss = 2.5388  Validation loss = 2.3479  \n",
      "\n",
      "Fold: 7  Epoch: 529  Training loss = 2.5386  Validation loss = 2.3477  \n",
      "\n",
      "Fold: 7  Epoch: 530  Training loss = 2.5385  Validation loss = 2.3476  \n",
      "\n",
      "Fold: 7  Epoch: 531  Training loss = 2.5384  Validation loss = 2.3474  \n",
      "\n",
      "Fold: 7  Epoch: 532  Training loss = 2.5382  Validation loss = 2.3473  \n",
      "\n",
      "Fold: 7  Epoch: 533  Training loss = 2.5381  Validation loss = 2.3471  \n",
      "\n",
      "Fold: 7  Epoch: 534  Training loss = 2.5380  Validation loss = 2.3470  \n",
      "\n",
      "Fold: 7  Epoch: 535  Training loss = 2.5378  Validation loss = 2.3468  \n",
      "\n",
      "Fold: 7  Epoch: 536  Training loss = 2.5378  Validation loss = 2.3467  \n",
      "\n",
      "Fold: 7  Epoch: 537  Training loss = 2.5376  Validation loss = 2.3465  \n",
      "\n",
      "Fold: 7  Epoch: 538  Training loss = 2.5375  Validation loss = 2.3464  \n",
      "\n",
      "Fold: 7  Epoch: 539  Training loss = 2.5374  Validation loss = 2.3463  \n",
      "\n",
      "Fold: 7  Epoch: 540  Training loss = 2.5373  Validation loss = 2.3461  \n",
      "\n",
      "Fold: 7  Epoch: 541  Training loss = 2.5372  Validation loss = 2.3460  \n",
      "\n",
      "Fold: 7  Epoch: 542  Training loss = 2.5371  Validation loss = 2.3458  \n",
      "\n",
      "Fold: 7  Epoch: 543  Training loss = 2.5370  Validation loss = 2.3457  \n",
      "\n",
      "Fold: 7  Epoch: 544  Training loss = 2.5368  Validation loss = 2.3455  \n",
      "\n",
      "Fold: 7  Epoch: 545  Training loss = 2.5367  Validation loss = 2.3454  \n",
      "\n",
      "Fold: 7  Epoch: 546  Training loss = 2.5366  Validation loss = 2.3452  \n",
      "\n",
      "Fold: 7  Epoch: 547  Training loss = 2.5364  Validation loss = 2.3451  \n",
      "\n",
      "Fold: 7  Epoch: 548  Training loss = 2.5363  Validation loss = 2.3449  \n",
      "\n",
      "Fold: 7  Epoch: 549  Training loss = 2.5362  Validation loss = 2.3448  \n",
      "\n",
      "Fold: 7  Epoch: 550  Training loss = 2.5361  Validation loss = 2.3446  \n",
      "\n",
      "Fold: 7  Epoch: 551  Training loss = 2.5359  Validation loss = 2.3444  \n",
      "\n",
      "Fold: 7  Epoch: 552  Training loss = 2.5358  Validation loss = 2.3443  \n",
      "\n",
      "Fold: 7  Epoch: 553  Training loss = 2.5357  Validation loss = 2.3441  \n",
      "\n",
      "Fold: 7  Epoch: 554  Training loss = 2.5356  Validation loss = 2.3440  \n",
      "\n",
      "Fold: 7  Epoch: 555  Training loss = 2.5355  Validation loss = 2.3439  \n",
      "\n",
      "Fold: 7  Epoch: 556  Training loss = 2.5354  Validation loss = 2.3437  \n",
      "\n",
      "Fold: 7  Epoch: 557  Training loss = 2.5353  Validation loss = 2.3436  \n",
      "\n",
      "Fold: 7  Epoch: 558  Training loss = 2.5351  Validation loss = 2.3434  \n",
      "\n",
      "Fold: 7  Epoch: 559  Training loss = 2.5350  Validation loss = 2.3433  \n",
      "\n",
      "Fold: 7  Epoch: 560  Training loss = 2.5349  Validation loss = 2.3432  \n",
      "\n",
      "Fold: 7  Epoch: 561  Training loss = 2.5348  Validation loss = 2.3430  \n",
      "\n",
      "Fold: 7  Epoch: 562  Training loss = 2.5347  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 7  Epoch: 563  Training loss = 2.5345  Validation loss = 2.3427  \n",
      "\n",
      "Fold: 7  Epoch: 564  Training loss = 2.5344  Validation loss = 2.3425  \n",
      "\n",
      "Fold: 7  Epoch: 565  Training loss = 2.5342  Validation loss = 2.3423  \n",
      "\n",
      "Fold: 7  Epoch: 566  Training loss = 2.5341  Validation loss = 2.3422  \n",
      "\n",
      "Fold: 7  Epoch: 567  Training loss = 2.5340  Validation loss = 2.3421  \n",
      "\n",
      "Fold: 7  Epoch: 568  Training loss = 2.5339  Validation loss = 2.3420  \n",
      "\n",
      "Fold: 7  Epoch: 569  Training loss = 2.5338  Validation loss = 2.3419  \n",
      "\n",
      "Fold: 7  Epoch: 570  Training loss = 2.5337  Validation loss = 2.3417  \n",
      "\n",
      "Fold: 7  Epoch: 571  Training loss = 2.5336  Validation loss = 2.3416  \n",
      "\n",
      "Fold: 7  Epoch: 572  Training loss = 2.5335  Validation loss = 2.3414  \n",
      "\n",
      "Fold: 7  Epoch: 573  Training loss = 2.5333  Validation loss = 2.3413  \n",
      "\n",
      "Fold: 7  Epoch: 574  Training loss = 2.5332  Validation loss = 2.3412  \n",
      "\n",
      "Fold: 7  Epoch: 575  Training loss = 2.5331  Validation loss = 2.3410  \n",
      "\n",
      "Fold: 7  Epoch: 576  Training loss = 2.5330  Validation loss = 2.3409  \n",
      "\n",
      "Fold: 7  Epoch: 577  Training loss = 2.5329  Validation loss = 2.3407  \n",
      "\n",
      "Fold: 7  Epoch: 578  Training loss = 2.5328  Validation loss = 2.3406  \n",
      "\n",
      "Fold: 7  Epoch: 579  Training loss = 2.5326  Validation loss = 2.3404  \n",
      "\n",
      "Fold: 7  Epoch: 580  Training loss = 2.5325  Validation loss = 2.3403  \n",
      "\n",
      "Fold: 7  Epoch: 581  Training loss = 2.5323  Validation loss = 2.3401  \n",
      "\n",
      "Fold: 7  Epoch: 582  Training loss = 2.5322  Validation loss = 2.3399  \n",
      "\n",
      "Fold: 7  Epoch: 583  Training loss = 2.5321  Validation loss = 2.3398  \n",
      "\n",
      "Fold: 7  Epoch: 584  Training loss = 2.5319  Validation loss = 2.3396  \n",
      "\n",
      "Fold: 7  Epoch: 585  Training loss = 2.5318  Validation loss = 2.3395  \n",
      "\n",
      "Fold: 7  Epoch: 586  Training loss = 2.5317  Validation loss = 2.3393  \n",
      "\n",
      "Fold: 7  Epoch: 587  Training loss = 2.5315  Validation loss = 2.3392  \n",
      "\n",
      "Fold: 7  Epoch: 588  Training loss = 2.5314  Validation loss = 2.3390  \n",
      "\n",
      "Fold: 7  Epoch: 589  Training loss = 2.5313  Validation loss = 2.3388  \n",
      "\n",
      "Fold: 7  Epoch: 590  Training loss = 2.5312  Validation loss = 2.3387  \n",
      "\n",
      "Fold: 7  Epoch: 591  Training loss = 2.5310  Validation loss = 2.3385  \n",
      "\n",
      "Fold: 7  Epoch: 592  Training loss = 2.5309  Validation loss = 2.3384  \n",
      "\n",
      "Fold: 7  Epoch: 593  Training loss = 2.5308  Validation loss = 2.3382  \n",
      "\n",
      "Fold: 7  Epoch: 594  Training loss = 2.5307  Validation loss = 2.3380  \n",
      "\n",
      "Fold: 7  Epoch: 595  Training loss = 2.5306  Validation loss = 2.3379  \n",
      "\n",
      "Fold: 7  Epoch: 596  Training loss = 2.5304  Validation loss = 2.3378  \n",
      "\n",
      "Fold: 7  Epoch: 597  Training loss = 2.5303  Validation loss = 2.3376  \n",
      "\n",
      "Fold: 7  Epoch: 598  Training loss = 2.5302  Validation loss = 2.3375  \n",
      "\n",
      "Fold: 7  Epoch: 599  Training loss = 2.5301  Validation loss = 2.3374  \n",
      "\n",
      "Fold: 7  Epoch: 600  Training loss = 2.5300  Validation loss = 2.3372  \n",
      "\n",
      "Fold: 7  Epoch: 601  Training loss = 2.5298  Validation loss = 2.3370  \n",
      "\n",
      "Fold: 7  Epoch: 602  Training loss = 2.5297  Validation loss = 2.3369  \n",
      "\n",
      "Fold: 7  Epoch: 603  Training loss = 2.5296  Validation loss = 2.3368  \n",
      "\n",
      "Fold: 7  Epoch: 604  Training loss = 2.5295  Validation loss = 2.3366  \n",
      "\n",
      "Fold: 7  Epoch: 605  Training loss = 2.5294  Validation loss = 2.3365  \n",
      "\n",
      "Fold: 7  Epoch: 606  Training loss = 2.5292  Validation loss = 2.3363  \n",
      "\n",
      "Fold: 7  Epoch: 607  Training loss = 2.5291  Validation loss = 2.3362  \n",
      "\n",
      "Fold: 7  Epoch: 608  Training loss = 2.5290  Validation loss = 2.3360  \n",
      "\n",
      "Fold: 7  Epoch: 609  Training loss = 2.5288  Validation loss = 2.3359  \n",
      "\n",
      "Fold: 7  Epoch: 610  Training loss = 2.5287  Validation loss = 2.3357  \n",
      "\n",
      "Fold: 7  Epoch: 611  Training loss = 2.5286  Validation loss = 2.3356  \n",
      "\n",
      "Fold: 7  Epoch: 612  Training loss = 2.5285  Validation loss = 2.3355  \n",
      "\n",
      "Fold: 7  Epoch: 613  Training loss = 2.5284  Validation loss = 2.3353  \n",
      "\n",
      "Fold: 7  Epoch: 614  Training loss = 2.5282  Validation loss = 2.3351  \n",
      "\n",
      "Fold: 7  Epoch: 615  Training loss = 2.5281  Validation loss = 2.3350  \n",
      "\n",
      "Fold: 7  Epoch: 616  Training loss = 2.5280  Validation loss = 2.3348  \n",
      "\n",
      "Fold: 7  Epoch: 617  Training loss = 2.5279  Validation loss = 2.3347  \n",
      "\n",
      "Fold: 7  Epoch: 618  Training loss = 2.5278  Validation loss = 2.3345  \n",
      "\n",
      "Fold: 7  Epoch: 619  Training loss = 2.5277  Validation loss = 2.3344  \n",
      "\n",
      "Fold: 7  Epoch: 620  Training loss = 2.5275  Validation loss = 2.3342  \n",
      "\n",
      "Fold: 7  Epoch: 621  Training loss = 2.5274  Validation loss = 2.3341  \n",
      "\n",
      "Fold: 7  Epoch: 622  Training loss = 2.5273  Validation loss = 2.3339  \n",
      "\n",
      "Fold: 7  Epoch: 623  Training loss = 2.5271  Validation loss = 2.3338  \n",
      "\n",
      "Fold: 7  Epoch: 624  Training loss = 2.5270  Validation loss = 2.3336  \n",
      "\n",
      "Fold: 7  Epoch: 625  Training loss = 2.5269  Validation loss = 2.3335  \n",
      "\n",
      "Fold: 7  Epoch: 626  Training loss = 2.5268  Validation loss = 2.3333  \n",
      "\n",
      "Fold: 7  Epoch: 627  Training loss = 2.5267  Validation loss = 2.3332  \n",
      "\n",
      "Fold: 7  Epoch: 628  Training loss = 2.5265  Validation loss = 2.3330  \n",
      "\n",
      "Fold: 7  Epoch: 629  Training loss = 2.5264  Validation loss = 2.3329  \n",
      "\n",
      "Fold: 7  Epoch: 630  Training loss = 2.5263  Validation loss = 2.3327  \n",
      "\n",
      "Fold: 7  Epoch: 631  Training loss = 2.5262  Validation loss = 2.3326  \n",
      "\n",
      "Fold: 7  Epoch: 632  Training loss = 2.5260  Validation loss = 2.3324  \n",
      "\n",
      "Fold: 7  Epoch: 633  Training loss = 2.5259  Validation loss = 2.3323  \n",
      "\n",
      "Fold: 7  Epoch: 634  Training loss = 2.5258  Validation loss = 2.3321  \n",
      "\n",
      "Fold: 7  Epoch: 635  Training loss = 2.5256  Validation loss = 2.3320  \n",
      "\n",
      "Fold: 7  Epoch: 636  Training loss = 2.5255  Validation loss = 2.3318  \n",
      "\n",
      "Fold: 7  Epoch: 637  Training loss = 2.5254  Validation loss = 2.3317  \n",
      "\n",
      "Fold: 7  Epoch: 638  Training loss = 2.5252  Validation loss = 2.3315  \n",
      "\n",
      "Fold: 7  Epoch: 639  Training loss = 2.5251  Validation loss = 2.3313  \n",
      "\n",
      "Fold: 7  Epoch: 640  Training loss = 2.5250  Validation loss = 2.3312  \n",
      "\n",
      "Fold: 7  Epoch: 641  Training loss = 2.5248  Validation loss = 2.3310  \n",
      "\n",
      "Fold: 7  Epoch: 642  Training loss = 2.5247  Validation loss = 2.3309  \n",
      "\n",
      "Fold: 7  Epoch: 643  Training loss = 2.5246  Validation loss = 2.3307  \n",
      "\n",
      "Fold: 7  Epoch: 644  Training loss = 2.5244  Validation loss = 2.3305  \n",
      "\n",
      "Fold: 7  Epoch: 645  Training loss = 2.5243  Validation loss = 2.3304  \n",
      "\n",
      "Fold: 7  Epoch: 646  Training loss = 2.5242  Validation loss = 2.3303  \n",
      "\n",
      "Fold: 7  Epoch: 647  Training loss = 2.5241  Validation loss = 2.3301  \n",
      "\n",
      "Fold: 7  Epoch: 648  Training loss = 2.5240  Validation loss = 2.3300  \n",
      "\n",
      "Fold: 7  Epoch: 649  Training loss = 2.5238  Validation loss = 2.3298  \n",
      "\n",
      "Fold: 7  Epoch: 650  Training loss = 2.5237  Validation loss = 2.3297  \n",
      "\n",
      "Fold: 7  Epoch: 651  Training loss = 2.5236  Validation loss = 2.3296  \n",
      "\n",
      "Fold: 7  Epoch: 652  Training loss = 2.5235  Validation loss = 2.3294  \n",
      "\n",
      "Fold: 7  Epoch: 653  Training loss = 2.5234  Validation loss = 2.3293  \n",
      "\n",
      "Fold: 7  Epoch: 654  Training loss = 2.5233  Validation loss = 2.3291  \n",
      "\n",
      "Fold: 7  Epoch: 655  Training loss = 2.5231  Validation loss = 2.3289  \n",
      "\n",
      "Fold: 7  Epoch: 656  Training loss = 2.5230  Validation loss = 2.3288  \n",
      "\n",
      "Fold: 7  Epoch: 657  Training loss = 2.5229  Validation loss = 2.3287  \n",
      "\n",
      "Fold: 7  Epoch: 658  Training loss = 2.5227  Validation loss = 2.3285  \n",
      "\n",
      "Fold: 7  Epoch: 659  Training loss = 2.5226  Validation loss = 2.3283  \n",
      "\n",
      "Fold: 7  Epoch: 660  Training loss = 2.5225  Validation loss = 2.3282  \n",
      "\n",
      "Fold: 7  Epoch: 661  Training loss = 2.5224  Validation loss = 2.3280  \n",
      "\n",
      "Fold: 7  Epoch: 662  Training loss = 2.5222  Validation loss = 2.3279  \n",
      "\n",
      "Fold: 7  Epoch: 663  Training loss = 2.5221  Validation loss = 2.3278  \n",
      "\n",
      "Fold: 7  Epoch: 664  Training loss = 2.5219  Validation loss = 2.3275  \n",
      "\n",
      "Fold: 7  Epoch: 665  Training loss = 2.5218  Validation loss = 2.3274  \n",
      "\n",
      "Fold: 7  Epoch: 666  Training loss = 2.5217  Validation loss = 2.3273  \n",
      "\n",
      "Fold: 7  Epoch: 667  Training loss = 2.5216  Validation loss = 2.3271  \n",
      "\n",
      "Fold: 7  Epoch: 668  Training loss = 2.5215  Validation loss = 2.3269  \n",
      "\n",
      "Fold: 7  Epoch: 669  Training loss = 2.5213  Validation loss = 2.3268  \n",
      "\n",
      "Fold: 7  Epoch: 670  Training loss = 2.5212  Validation loss = 2.3266  \n",
      "\n",
      "Fold: 7  Epoch: 671  Training loss = 2.5211  Validation loss = 2.3265  \n",
      "\n",
      "Fold: 7  Epoch: 672  Training loss = 2.5210  Validation loss = 2.3263  \n",
      "\n",
      "Fold: 7  Epoch: 673  Training loss = 2.5209  Validation loss = 2.3262  \n",
      "\n",
      "Fold: 7  Epoch: 674  Training loss = 2.5207  Validation loss = 2.3260  \n",
      "\n",
      "Fold: 7  Epoch: 675  Training loss = 2.5206  Validation loss = 2.3259  \n",
      "\n",
      "Fold: 7  Epoch: 676  Training loss = 2.5205  Validation loss = 2.3258  \n",
      "\n",
      "Fold: 7  Epoch: 677  Training loss = 2.5203  Validation loss = 2.3256  \n",
      "\n",
      "Fold: 7  Epoch: 678  Training loss = 2.5202  Validation loss = 2.3254  \n",
      "\n",
      "Fold: 7  Epoch: 679  Training loss = 2.5201  Validation loss = 2.3253  \n",
      "\n",
      "Fold: 7  Epoch: 680  Training loss = 2.5200  Validation loss = 2.3251  \n",
      "\n",
      "Fold: 7  Epoch: 681  Training loss = 2.5199  Validation loss = 2.3250  \n",
      "\n",
      "Fold: 7  Epoch: 682  Training loss = 2.5197  Validation loss = 2.3248  \n",
      "\n",
      "Fold: 7  Epoch: 683  Training loss = 2.5196  Validation loss = 2.3247  \n",
      "\n",
      "Fold: 7  Epoch: 684  Training loss = 2.5195  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 7  Epoch: 685  Training loss = 2.5193  Validation loss = 2.3244  \n",
      "\n",
      "Fold: 7  Epoch: 686  Training loss = 2.5192  Validation loss = 2.3242  \n",
      "\n",
      "Fold: 7  Epoch: 687  Training loss = 2.5191  Validation loss = 2.3241  \n",
      "\n",
      "Fold: 7  Epoch: 688  Training loss = 2.5190  Validation loss = 2.3239  \n",
      "\n",
      "Fold: 7  Epoch: 689  Training loss = 2.5189  Validation loss = 2.3238  \n",
      "\n",
      "Fold: 7  Epoch: 690  Training loss = 2.5188  Validation loss = 2.3236  \n",
      "\n",
      "Fold: 7  Epoch: 691  Training loss = 2.5187  Validation loss = 2.3235  \n",
      "\n",
      "Fold: 7  Epoch: 692  Training loss = 2.5186  Validation loss = 2.3234  \n",
      "\n",
      "Fold: 7  Epoch: 693  Training loss = 2.5185  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 7  Epoch: 694  Training loss = 2.5184  Validation loss = 2.3231  \n",
      "\n",
      "Fold: 7  Epoch: 695  Training loss = 2.5182  Validation loss = 2.3230  \n",
      "\n",
      "Fold: 7  Epoch: 696  Training loss = 2.5181  Validation loss = 2.3228  \n",
      "\n",
      "Fold: 7  Epoch: 697  Training loss = 2.5180  Validation loss = 2.3227  \n",
      "\n",
      "Fold: 7  Epoch: 698  Training loss = 2.5179  Validation loss = 2.3225  \n",
      "\n",
      "Fold: 7  Epoch: 699  Training loss = 2.5178  Validation loss = 2.3224  \n",
      "\n",
      "Fold: 7  Epoch: 700  Training loss = 2.5176  Validation loss = 2.3223  \n",
      "\n",
      "Fold: 7  Epoch: 701  Training loss = 2.5175  Validation loss = 2.3221  \n",
      "\n",
      "Fold: 7  Epoch: 702  Training loss = 2.5174  Validation loss = 2.3220  \n",
      "\n",
      "Fold: 7  Epoch: 703  Training loss = 2.5173  Validation loss = 2.3218  \n",
      "\n",
      "Fold: 7  Epoch: 704  Training loss = 2.5172  Validation loss = 2.3217  \n",
      "\n",
      "Fold: 7  Epoch: 705  Training loss = 2.5171  Validation loss = 2.3215  \n",
      "\n",
      "Fold: 7  Epoch: 706  Training loss = 2.5169  Validation loss = 2.3214  \n",
      "\n",
      "Fold: 7  Epoch: 707  Training loss = 2.5168  Validation loss = 2.3212  \n",
      "\n",
      "Fold: 7  Epoch: 708  Training loss = 2.5167  Validation loss = 2.3211  \n",
      "\n",
      "Fold: 7  Epoch: 709  Training loss = 2.5166  Validation loss = 2.3210  \n",
      "\n",
      "Fold: 7  Epoch: 710  Training loss = 2.5165  Validation loss = 2.3208  \n",
      "\n",
      "Fold: 7  Epoch: 711  Training loss = 2.5164  Validation loss = 2.3207  \n",
      "\n",
      "Fold: 7  Epoch: 712  Training loss = 2.5162  Validation loss = 2.3205  \n",
      "\n",
      "Fold: 7  Epoch: 713  Training loss = 2.5161  Validation loss = 2.3204  \n",
      "\n",
      "Fold: 7  Epoch: 714  Training loss = 2.5160  Validation loss = 2.3202  \n",
      "\n",
      "Fold: 7  Epoch: 715  Training loss = 2.5158  Validation loss = 2.3201  \n",
      "\n",
      "Fold: 7  Epoch: 716  Training loss = 2.5157  Validation loss = 2.3199  \n",
      "\n",
      "Fold: 7  Epoch: 717  Training loss = 2.5156  Validation loss = 2.3198  \n",
      "\n",
      "Fold: 7  Epoch: 718  Training loss = 2.5155  Validation loss = 2.3196  \n",
      "\n",
      "Fold: 7  Epoch: 719  Training loss = 2.5154  Validation loss = 2.3195  \n",
      "\n",
      "Fold: 7  Epoch: 720  Training loss = 2.5153  Validation loss = 2.3193  \n",
      "\n",
      "Fold: 7  Epoch: 721  Training loss = 2.5152  Validation loss = 2.3192  \n",
      "\n",
      "Fold: 7  Epoch: 722  Training loss = 2.5150  Validation loss = 2.3190  \n",
      "\n",
      "Fold: 7  Epoch: 723  Training loss = 2.5149  Validation loss = 2.3189  \n",
      "\n",
      "Fold: 7  Epoch: 724  Training loss = 2.5148  Validation loss = 2.3187  \n",
      "\n",
      "Fold: 7  Epoch: 725  Training loss = 2.5147  Validation loss = 2.3186  \n",
      "\n",
      "Fold: 7  Epoch: 726  Training loss = 2.5145  Validation loss = 2.3184  \n",
      "\n",
      "Fold: 7  Epoch: 727  Training loss = 2.5144  Validation loss = 2.3183  \n",
      "\n",
      "Fold: 7  Epoch: 728  Training loss = 2.5143  Validation loss = 2.3181  \n",
      "\n",
      "Fold: 7  Epoch: 729  Training loss = 2.5142  Validation loss = 2.3180  \n",
      "\n",
      "Fold: 7  Epoch: 730  Training loss = 2.5141  Validation loss = 2.3179  \n",
      "\n",
      "Fold: 7  Epoch: 731  Training loss = 2.5139  Validation loss = 2.3177  \n",
      "\n",
      "Fold: 7  Epoch: 732  Training loss = 2.5138  Validation loss = 2.3176  \n",
      "\n",
      "Fold: 7  Epoch: 733  Training loss = 2.5137  Validation loss = 2.3174  \n",
      "\n",
      "Fold: 7  Epoch: 734  Training loss = 2.5136  Validation loss = 2.3173  \n",
      "\n",
      "Fold: 7  Epoch: 735  Training loss = 2.5135  Validation loss = 2.3172  \n",
      "\n",
      "Fold: 7  Epoch: 736  Training loss = 2.5134  Validation loss = 2.3170  \n",
      "\n",
      "Fold: 7  Epoch: 737  Training loss = 2.5132  Validation loss = 2.3168  \n",
      "\n",
      "Fold: 7  Epoch: 738  Training loss = 2.5131  Validation loss = 2.3167  \n",
      "\n",
      "Fold: 7  Epoch: 739  Training loss = 2.5130  Validation loss = 2.3166  \n",
      "\n",
      "Fold: 7  Epoch: 740  Training loss = 2.5129  Validation loss = 2.3164  \n",
      "\n",
      "Fold: 7  Epoch: 741  Training loss = 2.5128  Validation loss = 2.3163  \n",
      "\n",
      "Fold: 7  Epoch: 742  Training loss = 2.5126  Validation loss = 2.3161  \n",
      "\n",
      "Fold: 7  Epoch: 743  Training loss = 2.5125  Validation loss = 2.3160  \n",
      "\n",
      "Fold: 7  Epoch: 744  Training loss = 2.5124  Validation loss = 2.3158  \n",
      "\n",
      "Fold: 7  Epoch: 745  Training loss = 2.5123  Validation loss = 2.3157  \n",
      "\n",
      "Fold: 7  Epoch: 746  Training loss = 2.5122  Validation loss = 2.3156  \n",
      "\n",
      "Fold: 7  Epoch: 747  Training loss = 2.5120  Validation loss = 2.3154  \n",
      "\n",
      "Fold: 7  Epoch: 748  Training loss = 2.5119  Validation loss = 2.3153  \n",
      "\n",
      "Fold: 7  Epoch: 749  Training loss = 2.5118  Validation loss = 2.3151  \n",
      "\n",
      "Fold: 7  Epoch: 750  Training loss = 2.5117  Validation loss = 2.3150  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 750  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.5247  Validation loss = 7.4753  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.5245  Validation loss = 7.4751  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.5244  Validation loss = 7.4750  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.5243  Validation loss = 7.4749  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.5242  Validation loss = 7.4747  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.5241  Validation loss = 7.4746  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.5239  Validation loss = 7.4744  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.5238  Validation loss = 7.4743  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.5236  Validation loss = 7.4741  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.5235  Validation loss = 7.4739  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.5234  Validation loss = 7.4738  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.5232  Validation loss = 7.4736  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.5231  Validation loss = 7.4735  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.5230  Validation loss = 7.4733  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.5229  Validation loss = 7.4732  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.5228  Validation loss = 7.4731  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.5226  Validation loss = 7.4729  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.5225  Validation loss = 7.4728  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.5224  Validation loss = 7.4726  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.5222  Validation loss = 7.4725  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.5221  Validation loss = 7.4723  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.5220  Validation loss = 7.4722  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.5218  Validation loss = 7.4720  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.5217  Validation loss = 7.4719  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.5216  Validation loss = 7.4717  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.5214  Validation loss = 7.4715  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.5212  Validation loss = 7.4713  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.5211  Validation loss = 7.4712  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.5210  Validation loss = 7.4710  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.5208  Validation loss = 7.4709  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.5207  Validation loss = 7.4707  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.5205  Validation loss = 7.4706  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.5204  Validation loss = 7.4704  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.5203  Validation loss = 7.4703  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.5202  Validation loss = 7.4701  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.5200  Validation loss = 7.4700  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.5199  Validation loss = 7.4698  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.5198  Validation loss = 7.4697  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.5197  Validation loss = 7.4696  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.5195  Validation loss = 7.4694  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.5194  Validation loss = 7.4693  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.5193  Validation loss = 7.4691  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.5192  Validation loss = 7.4690  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.5191  Validation loss = 7.4688  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.5189  Validation loss = 7.4687  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.5188  Validation loss = 7.4685  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.5187  Validation loss = 7.4684  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.5186  Validation loss = 7.4683  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.5184  Validation loss = 7.4681  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.5183  Validation loss = 7.4679  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.5181  Validation loss = 7.4678  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.5180  Validation loss = 7.4676  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.5179  Validation loss = 7.4675  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.5178  Validation loss = 7.4673  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.5176  Validation loss = 7.4672  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.5174  Validation loss = 7.4670  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.5173  Validation loss = 7.4668  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.5171  Validation loss = 7.4666  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.5170  Validation loss = 7.4664  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.5169  Validation loss = 7.4663  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.5168  Validation loss = 7.4662  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.5166  Validation loss = 7.4660  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.5165  Validation loss = 7.4658  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.5164  Validation loss = 7.4657  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.5162  Validation loss = 7.4655  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.5161  Validation loss = 7.4654  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.5160  Validation loss = 7.4652  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.5159  Validation loss = 7.4651  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.5157  Validation loss = 7.4649  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.5156  Validation loss = 7.4648  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.5155  Validation loss = 7.4646  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.5153  Validation loss = 7.4645  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.5152  Validation loss = 7.4643  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.5151  Validation loss = 7.4642  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.5149  Validation loss = 7.4640  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.5148  Validation loss = 7.4639  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.5147  Validation loss = 7.4637  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.5145  Validation loss = 7.4636  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.5144  Validation loss = 7.4634  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.5143  Validation loss = 7.4633  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.5142  Validation loss = 7.4631  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.5141  Validation loss = 7.4630  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.5139  Validation loss = 7.4628  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.5138  Validation loss = 7.4627  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.5136  Validation loss = 7.4625  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.5135  Validation loss = 7.4624  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.5134  Validation loss = 7.4622  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.5133  Validation loss = 7.4621  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.5132  Validation loss = 7.4619  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.5131  Validation loss = 7.4618  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.5130  Validation loss = 7.4617  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.5128  Validation loss = 7.4615  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.5127  Validation loss = 7.4614  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.5125  Validation loss = 7.4612  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.5124  Validation loss = 7.4610  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.5123  Validation loss = 7.4609  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.5121  Validation loss = 7.4607  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.5120  Validation loss = 7.4606  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.5119  Validation loss = 7.4605  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.5118  Validation loss = 7.4603  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.5116  Validation loss = 7.4602  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.5115  Validation loss = 7.4600  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.5114  Validation loss = 7.4599  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.5112  Validation loss = 7.4597  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.5111  Validation loss = 7.4595  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.5110  Validation loss = 7.4594  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.5108  Validation loss = 7.4592  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.5107  Validation loss = 7.4591  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.5106  Validation loss = 7.4589  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.5104  Validation loss = 7.4588  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.5103  Validation loss = 7.4586  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.5102  Validation loss = 7.4585  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.5100  Validation loss = 7.4583  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.5099  Validation loss = 7.4581  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.5098  Validation loss = 7.4580  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.5096  Validation loss = 7.4578  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.5095  Validation loss = 7.4577  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.5093  Validation loss = 7.4575  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.5092  Validation loss = 7.4574  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.5091  Validation loss = 7.4572  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.5090  Validation loss = 7.4571  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.5089  Validation loss = 7.4570  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.5088  Validation loss = 7.4568  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.5086  Validation loss = 7.4567  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.5085  Validation loss = 7.4565  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.5084  Validation loss = 7.4564  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.5083  Validation loss = 7.4562  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.5081  Validation loss = 7.4561  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.5080  Validation loss = 7.4559  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.5079  Validation loss = 7.4558  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.5077  Validation loss = 7.4556  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.5076  Validation loss = 7.4555  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.5075  Validation loss = 7.4553  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.5074  Validation loss = 7.4552  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.5073  Validation loss = 7.4551  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.5071  Validation loss = 7.4549  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.5070  Validation loss = 7.4548  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.5069  Validation loss = 7.4546  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.5068  Validation loss = 7.4545  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.5066  Validation loss = 7.4543  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.5065  Validation loss = 7.4541  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.5064  Validation loss = 7.4540  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.5062  Validation loss = 7.4539  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.5061  Validation loss = 7.4537  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.5060  Validation loss = 7.4536  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.5059  Validation loss = 7.4535  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.5058  Validation loss = 7.4533  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.5057  Validation loss = 7.4532  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.5055  Validation loss = 7.4530  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.5054  Validation loss = 7.4529  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.5053  Validation loss = 7.4527  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.5052  Validation loss = 7.4526  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.5050  Validation loss = 7.4524  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.5049  Validation loss = 7.4523  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.5048  Validation loss = 7.4521  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.5046  Validation loss = 7.4520  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.5045  Validation loss = 7.4518  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.5044  Validation loss = 7.4517  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.5043  Validation loss = 7.4515  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.5042  Validation loss = 7.4514  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.5041  Validation loss = 7.4513  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.5039  Validation loss = 7.4511  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.5038  Validation loss = 7.4510  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.5037  Validation loss = 7.4508  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.5035  Validation loss = 7.4506  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.5034  Validation loss = 7.4505  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.5033  Validation loss = 7.4503  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.5031  Validation loss = 7.4502  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.5030  Validation loss = 7.4500  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.5028  Validation loss = 7.4499  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.5027  Validation loss = 7.4497  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.5026  Validation loss = 7.4495  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.5024  Validation loss = 7.4494  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.5023  Validation loss = 7.4492  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.5022  Validation loss = 7.4491  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.5021  Validation loss = 7.4490  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.5019  Validation loss = 7.4488  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.5018  Validation loss = 7.4487  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.5017  Validation loss = 7.4485  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.5015  Validation loss = 7.4484  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.5014  Validation loss = 7.4482  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.5013  Validation loss = 7.4481  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.5012  Validation loss = 7.4479  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.5010  Validation loss = 7.4477  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.5008  Validation loss = 7.4476  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.5007  Validation loss = 7.4474  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.5006  Validation loss = 7.4473  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.5004  Validation loss = 7.4471  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.5003  Validation loss = 7.4470  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.5002  Validation loss = 7.4469  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.5001  Validation loss = 7.4467  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.5000  Validation loss = 7.4466  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.4999  Validation loss = 7.4465  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.4998  Validation loss = 7.4463  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.4996  Validation loss = 7.4462  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.4995  Validation loss = 7.4460  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.4994  Validation loss = 7.4458  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.4992  Validation loss = 7.4457  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.4991  Validation loss = 7.4455  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.4990  Validation loss = 7.4454  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.4989  Validation loss = 7.4453  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.4987  Validation loss = 7.4451  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.4986  Validation loss = 7.4450  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.4985  Validation loss = 7.4448  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.4983  Validation loss = 7.4446  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.4982  Validation loss = 7.4445  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.4981  Validation loss = 7.4444  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.4980  Validation loss = 7.4442  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.4978  Validation loss = 7.4441  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.4977  Validation loss = 7.4439  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.4976  Validation loss = 7.4438  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.4974  Validation loss = 7.4436  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.4973  Validation loss = 7.4435  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.4972  Validation loss = 7.4433  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.4970  Validation loss = 7.4432  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.4969  Validation loss = 7.4430  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.4968  Validation loss = 7.4429  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.4967  Validation loss = 7.4427  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.4965  Validation loss = 7.4426  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.4964  Validation loss = 7.4424  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.4962  Validation loss = 7.4422  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.4961  Validation loss = 7.4421  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.4960  Validation loss = 7.4419  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.4958  Validation loss = 7.4417  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.4957  Validation loss = 7.4416  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.4956  Validation loss = 7.4414  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.4954  Validation loss = 7.4413  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.4953  Validation loss = 7.4411  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.4952  Validation loss = 7.4409  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.4950  Validation loss = 7.4408  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.4949  Validation loss = 7.4406  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.4948  Validation loss = 7.4405  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.4946  Validation loss = 7.4403  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.4945  Validation loss = 7.4401  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.4944  Validation loss = 7.4400  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.4942  Validation loss = 7.4398  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.4941  Validation loss = 7.4397  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.4940  Validation loss = 7.4395  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.4939  Validation loss = 7.4394  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.4938  Validation loss = 7.4393  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.4936  Validation loss = 7.4391  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.4935  Validation loss = 7.4390  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.4934  Validation loss = 7.4388  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.4933  Validation loss = 7.4387  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.4931  Validation loss = 7.4385  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.4930  Validation loss = 7.4384  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.4929  Validation loss = 7.4382  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.4928  Validation loss = 7.4381  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.4926  Validation loss = 7.4380  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.4925  Validation loss = 7.4378  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.4924  Validation loss = 7.4377  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.4923  Validation loss = 7.4375  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.4921  Validation loss = 7.4374  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.4920  Validation loss = 7.4372  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.4918  Validation loss = 7.4371  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.4917  Validation loss = 7.4369  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.4916  Validation loss = 7.4368  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.4915  Validation loss = 7.4366  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.4913  Validation loss = 7.4365  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.4912  Validation loss = 7.4363  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.4910  Validation loss = 7.4361  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.4909  Validation loss = 7.4360  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.4907  Validation loss = 7.4358  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.4906  Validation loss = 7.4357  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.4905  Validation loss = 7.4355  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.4904  Validation loss = 7.4354  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.4902  Validation loss = 7.4352  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.4901  Validation loss = 7.4350  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.4900  Validation loss = 7.4349  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.4899  Validation loss = 7.4347  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.4897  Validation loss = 7.4346  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.4896  Validation loss = 7.4345  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.4895  Validation loss = 7.4343  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.4894  Validation loss = 7.4342  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.4893  Validation loss = 7.4340  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.4892  Validation loss = 7.4339  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.4890  Validation loss = 7.4337  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.4889  Validation loss = 7.4336  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.4887  Validation loss = 7.4334  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.4887  Validation loss = 7.4333  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.4885  Validation loss = 7.4332  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.4884  Validation loss = 7.4330  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.4883  Validation loss = 7.4329  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.4881  Validation loss = 7.4327  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.4880  Validation loss = 7.4326  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.4878  Validation loss = 7.4324  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.4877  Validation loss = 7.4322  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.4876  Validation loss = 7.4321  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.4875  Validation loss = 7.4319  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.4874  Validation loss = 7.4318  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.4873  Validation loss = 7.4317  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.4872  Validation loss = 7.4315  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.4870  Validation loss = 7.4314  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.4869  Validation loss = 7.4313  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.4868  Validation loss = 7.4311  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.4867  Validation loss = 7.4310  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.4865  Validation loss = 7.4308  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.4864  Validation loss = 7.4307  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.4863  Validation loss = 7.4305  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.4862  Validation loss = 7.4304  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.4861  Validation loss = 7.4303  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.4860  Validation loss = 7.4301  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.4858  Validation loss = 7.4300  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.4857  Validation loss = 7.4298  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.4855  Validation loss = 7.4297  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.4854  Validation loss = 7.4295  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.4852  Validation loss = 7.4293  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.4851  Validation loss = 7.4292  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.4850  Validation loss = 7.4290  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.4848  Validation loss = 7.4288  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.4847  Validation loss = 7.4287  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.4846  Validation loss = 7.4285  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.4844  Validation loss = 7.4284  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.4843  Validation loss = 7.4282  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.4842  Validation loss = 7.4281  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.4840  Validation loss = 7.4279  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.4839  Validation loss = 7.4278  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.4837  Validation loss = 7.4276  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.4836  Validation loss = 7.4274  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.4834  Validation loss = 7.4272  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.4833  Validation loss = 7.4271  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.4832  Validation loss = 7.4269  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.4831  Validation loss = 7.4268  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.4829  Validation loss = 7.4267  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.4828  Validation loss = 7.4265  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.4827  Validation loss = 7.4264  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.4826  Validation loss = 7.4262  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.4824  Validation loss = 7.4261  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.4823  Validation loss = 7.4259  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.4821  Validation loss = 7.4257  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.4820  Validation loss = 7.4256  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.4819  Validation loss = 7.4254  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.4817  Validation loss = 7.4252  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.4816  Validation loss = 7.4251  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.4815  Validation loss = 7.4249  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.4813  Validation loss = 7.4248  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.4812  Validation loss = 7.4246  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.4811  Validation loss = 7.4245  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.4810  Validation loss = 7.4243  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.4809  Validation loss = 7.4242  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.4807  Validation loss = 7.4240  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.4806  Validation loss = 7.4239  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.4804  Validation loss = 7.4237  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.4803  Validation loss = 7.4236  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.4802  Validation loss = 7.4234  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.4801  Validation loss = 7.4233  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.4799  Validation loss = 7.4231  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.4798  Validation loss = 7.4230  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.4797  Validation loss = 7.4228  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.4795  Validation loss = 7.4227  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.4794  Validation loss = 7.4226  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.4793  Validation loss = 7.4224  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.4792  Validation loss = 7.4223  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.4791  Validation loss = 7.4221  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.4790  Validation loss = 7.4220  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.4788  Validation loss = 7.4218  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.4787  Validation loss = 7.4217  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.4786  Validation loss = 7.4216  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.4785  Validation loss = 7.4214  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.4783  Validation loss = 7.4213  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.4782  Validation loss = 7.4211  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.4781  Validation loss = 7.4209  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.4779  Validation loss = 7.4208  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.4778  Validation loss = 7.4206  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.4777  Validation loss = 7.4205  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.4776  Validation loss = 7.4204  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.4775  Validation loss = 7.4202  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.4773  Validation loss = 7.4201  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.4772  Validation loss = 7.4199  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.4770  Validation loss = 7.4197  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.4769  Validation loss = 7.4196  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.4768  Validation loss = 7.4194  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.4766  Validation loss = 7.4192  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.4765  Validation loss = 7.4191  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.4764  Validation loss = 7.4189  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.4763  Validation loss = 7.4188  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.4761  Validation loss = 7.4186  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.4760  Validation loss = 7.4185  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.4759  Validation loss = 7.4183  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.4757  Validation loss = 7.4182  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.4756  Validation loss = 7.4180  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.4755  Validation loss = 7.4179  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.4753  Validation loss = 7.4177  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.4752  Validation loss = 7.4176  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.4751  Validation loss = 7.4174  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.4750  Validation loss = 7.4173  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.4748  Validation loss = 7.4171  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.4747  Validation loss = 7.4169  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 2.4746  Validation loss = 7.4168  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 2.4744  Validation loss = 7.4166  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 2.4743  Validation loss = 7.4164  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 2.4742  Validation loss = 7.4163  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 2.4741  Validation loss = 7.4162  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 2.4739  Validation loss = 7.4160  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 2.4738  Validation loss = 7.4158  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 2.4736  Validation loss = 7.4157  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 2.4735  Validation loss = 7.4155  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 2.4734  Validation loss = 7.4154  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 2.4733  Validation loss = 7.4153  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 2.4731  Validation loss = 7.4151  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 2.4730  Validation loss = 7.4150  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 2.4729  Validation loss = 7.4148  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 2.4727  Validation loss = 7.4146  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 2.4726  Validation loss = 7.4145  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 2.4725  Validation loss = 7.4144  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 2.4724  Validation loss = 7.4142  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 2.4722  Validation loss = 7.4141  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 2.4721  Validation loss = 7.4139  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 2.4720  Validation loss = 7.4137  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 2.4718  Validation loss = 7.4135  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 2.4717  Validation loss = 7.4134  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 2.4716  Validation loss = 7.4133  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 2.4715  Validation loss = 7.4131  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 2.4714  Validation loss = 7.4130  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 2.4712  Validation loss = 7.4128  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 2.4711  Validation loss = 7.4127  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 2.4710  Validation loss = 7.4126  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 2.4709  Validation loss = 7.4124  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 2.4707  Validation loss = 7.4123  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 2.4706  Validation loss = 7.4121  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 2.4705  Validation loss = 7.4120  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 2.4704  Validation loss = 7.4118  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 2.4702  Validation loss = 7.4117  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 2.4701  Validation loss = 7.4115  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 2.4700  Validation loss = 7.4114  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 2.4699  Validation loss = 7.4113  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 2.4698  Validation loss = 7.4111  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 2.4696  Validation loss = 7.4110  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 2.4695  Validation loss = 7.4108  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 2.4693  Validation loss = 7.4107  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 2.4692  Validation loss = 7.4105  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 2.4691  Validation loss = 7.4104  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 2.4690  Validation loss = 7.4103  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 2.4689  Validation loss = 7.4102  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 2.4688  Validation loss = 7.4100  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 2.4686  Validation loss = 7.4099  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 2.4685  Validation loss = 7.4097  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 2.4684  Validation loss = 7.4096  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 2.4682  Validation loss = 7.4094  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 2.4681  Validation loss = 7.4092  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 2.4679  Validation loss = 7.4090  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 2.4678  Validation loss = 7.4089  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 2.4677  Validation loss = 7.4088  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 2.4675  Validation loss = 7.4086  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 2.4674  Validation loss = 7.4084  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 2.4673  Validation loss = 7.4083  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 2.4672  Validation loss = 7.4081  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 2.4671  Validation loss = 7.4080  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 2.4669  Validation loss = 7.4079  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 2.4668  Validation loss = 7.4077  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 2.4666  Validation loss = 7.4075  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 2.4665  Validation loss = 7.4074  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 2.4663  Validation loss = 7.4072  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 2.4662  Validation loss = 7.4071  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 2.4661  Validation loss = 7.4069  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 2.4660  Validation loss = 7.4068  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 2.4658  Validation loss = 7.4066  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 2.4657  Validation loss = 7.4065  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 2.4656  Validation loss = 7.4063  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 2.4654  Validation loss = 7.4062  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 2.4653  Validation loss = 7.4060  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 2.4652  Validation loss = 7.4059  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 2.4651  Validation loss = 7.4058  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 2.4649  Validation loss = 7.4056  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 2.4648  Validation loss = 7.4054  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 2.4646  Validation loss = 7.4052  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 2.4645  Validation loss = 7.4051  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 2.4644  Validation loss = 7.4050  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 2.4643  Validation loss = 7.4048  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 2.4642  Validation loss = 7.4047  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 2.4641  Validation loss = 7.4045  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 2.4639  Validation loss = 7.4044  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 2.4638  Validation loss = 7.4042  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 2.4637  Validation loss = 7.4041  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 2.4636  Validation loss = 7.4039  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 2.4635  Validation loss = 7.4038  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 2.4633  Validation loss = 7.4037  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 2.4632  Validation loss = 7.4035  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 2.4631  Validation loss = 7.4034  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 2.4630  Validation loss = 7.4032  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 2.4628  Validation loss = 7.4031  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 2.4627  Validation loss = 7.4029  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 2.4626  Validation loss = 7.4028  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 2.4625  Validation loss = 7.4027  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 2.4624  Validation loss = 7.4025  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 2.4622  Validation loss = 7.4023  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 2.4621  Validation loss = 7.4022  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 2.4620  Validation loss = 7.4021  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 2.4619  Validation loss = 7.4020  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 2.4618  Validation loss = 7.4018  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 2.4617  Validation loss = 7.4017  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 2.4615  Validation loss = 7.4015  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 2.4614  Validation loss = 7.4014  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 2.4613  Validation loss = 7.4012  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 2.4611  Validation loss = 7.4010  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 2.4610  Validation loss = 7.4009  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 2.4609  Validation loss = 7.4007  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 2.4608  Validation loss = 7.4006  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 2.4606  Validation loss = 7.4005  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 2.4605  Validation loss = 7.4003  \n",
      "\n",
      "Fold: 8  Epoch: 501  Training loss = 2.4604  Validation loss = 7.4002  \n",
      "\n",
      "Fold: 8  Epoch: 502  Training loss = 2.4603  Validation loss = 7.4000  \n",
      "\n",
      "Fold: 8  Epoch: 503  Training loss = 2.4601  Validation loss = 7.3998  \n",
      "\n",
      "Fold: 8  Epoch: 504  Training loss = 2.4600  Validation loss = 7.3997  \n",
      "\n",
      "Fold: 8  Epoch: 505  Training loss = 2.4599  Validation loss = 7.3995  \n",
      "\n",
      "Fold: 8  Epoch: 506  Training loss = 2.4597  Validation loss = 7.3994  \n",
      "\n",
      "Fold: 8  Epoch: 507  Training loss = 2.4596  Validation loss = 7.3992  \n",
      "\n",
      "Fold: 8  Epoch: 508  Training loss = 2.4595  Validation loss = 7.3991  \n",
      "\n",
      "Fold: 8  Epoch: 509  Training loss = 2.4593  Validation loss = 7.3989  \n",
      "\n",
      "Fold: 8  Epoch: 510  Training loss = 2.4592  Validation loss = 7.3987  \n",
      "\n",
      "Fold: 8  Epoch: 511  Training loss = 2.4590  Validation loss = 7.3985  \n",
      "\n",
      "Fold: 8  Epoch: 512  Training loss = 2.4589  Validation loss = 7.3984  \n",
      "\n",
      "Fold: 8  Epoch: 513  Training loss = 2.4588  Validation loss = 7.3983  \n",
      "\n",
      "Fold: 8  Epoch: 514  Training loss = 2.4587  Validation loss = 7.3981  \n",
      "\n",
      "Fold: 8  Epoch: 515  Training loss = 2.4585  Validation loss = 7.3980  \n",
      "\n",
      "Fold: 8  Epoch: 516  Training loss = 2.4584  Validation loss = 7.3978  \n",
      "\n",
      "Fold: 8  Epoch: 517  Training loss = 2.4583  Validation loss = 7.3977  \n",
      "\n",
      "Fold: 8  Epoch: 518  Training loss = 2.4582  Validation loss = 7.3976  \n",
      "\n",
      "Fold: 8  Epoch: 519  Training loss = 2.4581  Validation loss = 7.3974  \n",
      "\n",
      "Fold: 8  Epoch: 520  Training loss = 2.4579  Validation loss = 7.3973  \n",
      "\n",
      "Fold: 8  Epoch: 521  Training loss = 2.4578  Validation loss = 7.3971  \n",
      "\n",
      "Fold: 8  Epoch: 522  Training loss = 2.4577  Validation loss = 7.3970  \n",
      "\n",
      "Fold: 8  Epoch: 523  Training loss = 2.4575  Validation loss = 7.3968  \n",
      "\n",
      "Fold: 8  Epoch: 524  Training loss = 2.4574  Validation loss = 7.3966  \n",
      "\n",
      "Fold: 8  Epoch: 525  Training loss = 2.4572  Validation loss = 7.3965  \n",
      "\n",
      "Fold: 8  Epoch: 526  Training loss = 2.4571  Validation loss = 7.3963  \n",
      "\n",
      "Fold: 8  Epoch: 527  Training loss = 2.4570  Validation loss = 7.3962  \n",
      "\n",
      "Fold: 8  Epoch: 528  Training loss = 2.4568  Validation loss = 7.3960  \n",
      "\n",
      "Fold: 8  Epoch: 529  Training loss = 2.4567  Validation loss = 7.3959  \n",
      "\n",
      "Fold: 8  Epoch: 530  Training loss = 2.4566  Validation loss = 7.3957  \n",
      "\n",
      "Fold: 8  Epoch: 531  Training loss = 2.4565  Validation loss = 7.3956  \n",
      "\n",
      "Fold: 8  Epoch: 532  Training loss = 2.4563  Validation loss = 7.3955  \n",
      "\n",
      "Fold: 8  Epoch: 533  Training loss = 2.4562  Validation loss = 7.3953  \n",
      "\n",
      "Fold: 8  Epoch: 534  Training loss = 2.4561  Validation loss = 7.3951  \n",
      "\n",
      "Fold: 8  Epoch: 535  Training loss = 2.4560  Validation loss = 7.3950  \n",
      "\n",
      "Fold: 8  Epoch: 536  Training loss = 2.4558  Validation loss = 7.3949  \n",
      "\n",
      "Fold: 8  Epoch: 537  Training loss = 2.4557  Validation loss = 7.3947  \n",
      "\n",
      "Fold: 8  Epoch: 538  Training loss = 2.4556  Validation loss = 7.3946  \n",
      "\n",
      "Fold: 8  Epoch: 539  Training loss = 2.4555  Validation loss = 7.3945  \n",
      "\n",
      "Fold: 8  Epoch: 540  Training loss = 2.4554  Validation loss = 7.3943  \n",
      "\n",
      "Fold: 8  Epoch: 541  Training loss = 2.4553  Validation loss = 7.3942  \n",
      "\n",
      "Fold: 8  Epoch: 542  Training loss = 2.4551  Validation loss = 7.3940  \n",
      "\n",
      "Fold: 8  Epoch: 543  Training loss = 2.4550  Validation loss = 7.3939  \n",
      "\n",
      "Fold: 8  Epoch: 544  Training loss = 2.4549  Validation loss = 7.3937  \n",
      "\n",
      "Fold: 8  Epoch: 545  Training loss = 2.4547  Validation loss = 7.3936  \n",
      "\n",
      "Fold: 8  Epoch: 546  Training loss = 2.4546  Validation loss = 7.3934  \n",
      "\n",
      "Fold: 8  Epoch: 547  Training loss = 2.4545  Validation loss = 7.3933  \n",
      "\n",
      "Fold: 8  Epoch: 548  Training loss = 2.4544  Validation loss = 7.3931  \n",
      "\n",
      "Fold: 8  Epoch: 549  Training loss = 2.4542  Validation loss = 7.3929  \n",
      "\n",
      "Fold: 8  Epoch: 550  Training loss = 2.4541  Validation loss = 7.3928  \n",
      "\n",
      "Fold: 8  Epoch: 551  Training loss = 2.4540  Validation loss = 7.3927  \n",
      "\n",
      "Fold: 8  Epoch: 552  Training loss = 2.4539  Validation loss = 7.3925  \n",
      "\n",
      "Fold: 8  Epoch: 553  Training loss = 2.4538  Validation loss = 7.3924  \n",
      "\n",
      "Fold: 8  Epoch: 554  Training loss = 2.4536  Validation loss = 7.3922  \n",
      "\n",
      "Fold: 8  Epoch: 555  Training loss = 2.4535  Validation loss = 7.3921  \n",
      "\n",
      "Fold: 8  Epoch: 556  Training loss = 2.4534  Validation loss = 7.3920  \n",
      "\n",
      "Fold: 8  Epoch: 557  Training loss = 2.4533  Validation loss = 7.3918  \n",
      "\n",
      "Fold: 8  Epoch: 558  Training loss = 2.4531  Validation loss = 7.3916  \n",
      "\n",
      "Fold: 8  Epoch: 559  Training loss = 2.4530  Validation loss = 7.3915  \n",
      "\n",
      "Fold: 8  Epoch: 560  Training loss = 2.4529  Validation loss = 7.3913  \n",
      "\n",
      "Fold: 8  Epoch: 561  Training loss = 2.4528  Validation loss = 7.3912  \n",
      "\n",
      "Fold: 8  Epoch: 562  Training loss = 2.4527  Validation loss = 7.3911  \n",
      "\n",
      "Fold: 8  Epoch: 563  Training loss = 2.4526  Validation loss = 7.3909  \n",
      "\n",
      "Fold: 8  Epoch: 564  Training loss = 2.4524  Validation loss = 7.3908  \n",
      "\n",
      "Fold: 8  Epoch: 565  Training loss = 2.4523  Validation loss = 7.3906  \n",
      "\n",
      "Fold: 8  Epoch: 566  Training loss = 2.4522  Validation loss = 7.3905  \n",
      "\n",
      "Fold: 8  Epoch: 567  Training loss = 2.4521  Validation loss = 7.3903  \n",
      "\n",
      "Fold: 8  Epoch: 568  Training loss = 2.4520  Validation loss = 7.3902  \n",
      "\n",
      "Fold: 8  Epoch: 569  Training loss = 2.4518  Validation loss = 7.3900  \n",
      "\n",
      "Fold: 8  Epoch: 570  Training loss = 2.4517  Validation loss = 7.3899  \n",
      "\n",
      "Fold: 8  Epoch: 571  Training loss = 2.4515  Validation loss = 7.3897  \n",
      "\n",
      "Fold: 8  Epoch: 572  Training loss = 2.4514  Validation loss = 7.3895  \n",
      "\n",
      "Fold: 8  Epoch: 573  Training loss = 2.4513  Validation loss = 7.3894  \n",
      "\n",
      "Fold: 8  Epoch: 574  Training loss = 2.4511  Validation loss = 7.3892  \n",
      "\n",
      "Fold: 8  Epoch: 575  Training loss = 2.4510  Validation loss = 7.3890  \n",
      "\n",
      "Fold: 8  Epoch: 576  Training loss = 2.4509  Validation loss = 7.3888  \n",
      "\n",
      "Fold: 8  Epoch: 577  Training loss = 2.4508  Validation loss = 7.3887  \n",
      "\n",
      "Fold: 8  Epoch: 578  Training loss = 2.4506  Validation loss = 7.3885  \n",
      "\n",
      "Fold: 8  Epoch: 579  Training loss = 2.4505  Validation loss = 7.3884  \n",
      "\n",
      "Fold: 8  Epoch: 580  Training loss = 2.4504  Validation loss = 7.3882  \n",
      "\n",
      "Fold: 8  Epoch: 581  Training loss = 2.4502  Validation loss = 7.3881  \n",
      "\n",
      "Fold: 8  Epoch: 582  Training loss = 2.4501  Validation loss = 7.3879  \n",
      "\n",
      "Fold: 8  Epoch: 583  Training loss = 2.4500  Validation loss = 7.3878  \n",
      "\n",
      "Fold: 8  Epoch: 584  Training loss = 2.4498  Validation loss = 7.3876  \n",
      "\n",
      "Fold: 8  Epoch: 585  Training loss = 2.4496  Validation loss = 7.3874  \n",
      "\n",
      "Fold: 8  Epoch: 586  Training loss = 2.4495  Validation loss = 7.3872  \n",
      "\n",
      "Fold: 8  Epoch: 587  Training loss = 2.4493  Validation loss = 7.3871  \n",
      "\n",
      "Fold: 8  Epoch: 588  Training loss = 2.4492  Validation loss = 7.3869  \n",
      "\n",
      "Fold: 8  Epoch: 589  Training loss = 2.4491  Validation loss = 7.3868  \n",
      "\n",
      "Fold: 8  Epoch: 590  Training loss = 2.4490  Validation loss = 7.3866  \n",
      "\n",
      "Fold: 8  Epoch: 591  Training loss = 2.4488  Validation loss = 7.3864  \n",
      "\n",
      "Fold: 8  Epoch: 592  Training loss = 2.4487  Validation loss = 7.3863  \n",
      "\n",
      "Fold: 8  Epoch: 593  Training loss = 2.4485  Validation loss = 7.3861  \n",
      "\n",
      "Fold: 8  Epoch: 594  Training loss = 2.4484  Validation loss = 7.3859  \n",
      "\n",
      "Fold: 8  Epoch: 595  Training loss = 2.4483  Validation loss = 7.3858  \n",
      "\n",
      "Fold: 8  Epoch: 596  Training loss = 2.4481  Validation loss = 7.3856  \n",
      "\n",
      "Fold: 8  Epoch: 597  Training loss = 2.4480  Validation loss = 7.3855  \n",
      "\n",
      "Fold: 8  Epoch: 598  Training loss = 2.4479  Validation loss = 7.3853  \n",
      "\n",
      "Fold: 8  Epoch: 599  Training loss = 2.4477  Validation loss = 7.3851  \n",
      "\n",
      "Fold: 8  Epoch: 600  Training loss = 2.4476  Validation loss = 7.3850  \n",
      "\n",
      "Fold: 8  Epoch: 601  Training loss = 2.4475  Validation loss = 7.3849  \n",
      "\n",
      "Fold: 8  Epoch: 602  Training loss = 2.4473  Validation loss = 7.3847  \n",
      "\n",
      "Fold: 8  Epoch: 603  Training loss = 2.4472  Validation loss = 7.3846  \n",
      "\n",
      "Fold: 8  Epoch: 604  Training loss = 2.4471  Validation loss = 7.3845  \n",
      "\n",
      "Fold: 8  Epoch: 605  Training loss = 2.4470  Validation loss = 7.3843  \n",
      "\n",
      "Fold: 8  Epoch: 606  Training loss = 2.4469  Validation loss = 7.3842  \n",
      "\n",
      "Fold: 8  Epoch: 607  Training loss = 2.4467  Validation loss = 7.3840  \n",
      "\n",
      "Fold: 8  Epoch: 608  Training loss = 2.4466  Validation loss = 7.3839  \n",
      "\n",
      "Fold: 8  Epoch: 609  Training loss = 2.4466  Validation loss = 7.3838  \n",
      "\n",
      "Fold: 8  Epoch: 610  Training loss = 2.4464  Validation loss = 7.3837  \n",
      "\n",
      "Fold: 8  Epoch: 611  Training loss = 2.4463  Validation loss = 7.3835  \n",
      "\n",
      "Fold: 8  Epoch: 612  Training loss = 2.4462  Validation loss = 7.3834  \n",
      "\n",
      "Fold: 8  Epoch: 613  Training loss = 2.4460  Validation loss = 7.3832  \n",
      "\n",
      "Fold: 8  Epoch: 614  Training loss = 2.4459  Validation loss = 7.3831  \n",
      "\n",
      "Fold: 8  Epoch: 615  Training loss = 2.4457  Validation loss = 7.3829  \n",
      "\n",
      "Fold: 8  Epoch: 616  Training loss = 2.4456  Validation loss = 7.3827  \n",
      "\n",
      "Fold: 8  Epoch: 617  Training loss = 2.4455  Validation loss = 7.3825  \n",
      "\n",
      "Fold: 8  Epoch: 618  Training loss = 2.4453  Validation loss = 7.3824  \n",
      "\n",
      "Fold: 8  Epoch: 619  Training loss = 2.4452  Validation loss = 7.3823  \n",
      "\n",
      "Fold: 8  Epoch: 620  Training loss = 2.4451  Validation loss = 7.3821  \n",
      "\n",
      "Fold: 8  Epoch: 621  Training loss = 2.4450  Validation loss = 7.3820  \n",
      "\n",
      "Fold: 8  Epoch: 622  Training loss = 2.4449  Validation loss = 7.3818  \n",
      "\n",
      "Fold: 8  Epoch: 623  Training loss = 2.4448  Validation loss = 7.3816  \n",
      "\n",
      "Fold: 8  Epoch: 624  Training loss = 2.4446  Validation loss = 7.3815  \n",
      "\n",
      "Fold: 8  Epoch: 625  Training loss = 2.4445  Validation loss = 7.3814  \n",
      "\n",
      "Fold: 8  Epoch: 626  Training loss = 2.4444  Validation loss = 7.3812  \n",
      "\n",
      "Fold: 8  Epoch: 627  Training loss = 2.4442  Validation loss = 7.3810  \n",
      "\n",
      "Fold: 8  Epoch: 628  Training loss = 2.4441  Validation loss = 7.3809  \n",
      "\n",
      "Fold: 8  Epoch: 629  Training loss = 2.4440  Validation loss = 7.3807  \n",
      "\n",
      "Fold: 8  Epoch: 630  Training loss = 2.4439  Validation loss = 7.3806  \n",
      "\n",
      "Fold: 8  Epoch: 631  Training loss = 2.4438  Validation loss = 7.3804  \n",
      "\n",
      "Fold: 8  Epoch: 632  Training loss = 2.4436  Validation loss = 7.3803  \n",
      "\n",
      "Fold: 8  Epoch: 633  Training loss = 2.4435  Validation loss = 7.3801  \n",
      "\n",
      "Fold: 8  Epoch: 634  Training loss = 2.4434  Validation loss = 7.3800  \n",
      "\n",
      "Fold: 8  Epoch: 635  Training loss = 2.4433  Validation loss = 7.3799  \n",
      "\n",
      "Fold: 8  Epoch: 636  Training loss = 2.4432  Validation loss = 7.3797  \n",
      "\n",
      "Fold: 8  Epoch: 637  Training loss = 2.4430  Validation loss = 7.3795  \n",
      "\n",
      "Fold: 8  Epoch: 638  Training loss = 2.4429  Validation loss = 7.3794  \n",
      "\n",
      "Fold: 8  Epoch: 639  Training loss = 2.4428  Validation loss = 7.3793  \n",
      "\n",
      "Fold: 8  Epoch: 640  Training loss = 2.4427  Validation loss = 7.3791  \n",
      "\n",
      "Fold: 8  Epoch: 641  Training loss = 2.4426  Validation loss = 7.3790  \n",
      "\n",
      "Fold: 8  Epoch: 642  Training loss = 2.4424  Validation loss = 7.3788  \n",
      "\n",
      "Fold: 8  Epoch: 643  Training loss = 2.4423  Validation loss = 7.3787  \n",
      "\n",
      "Fold: 8  Epoch: 644  Training loss = 2.4422  Validation loss = 7.3786  \n",
      "\n",
      "Fold: 8  Epoch: 645  Training loss = 2.4421  Validation loss = 7.3784  \n",
      "\n",
      "Fold: 8  Epoch: 646  Training loss = 2.4420  Validation loss = 7.3782  \n",
      "\n",
      "Fold: 8  Epoch: 647  Training loss = 2.4418  Validation loss = 7.3781  \n",
      "\n",
      "Fold: 8  Epoch: 648  Training loss = 2.4417  Validation loss = 7.3779  \n",
      "\n",
      "Fold: 8  Epoch: 649  Training loss = 2.4416  Validation loss = 7.3778  \n",
      "\n",
      "Fold: 8  Epoch: 650  Training loss = 2.4414  Validation loss = 7.3777  \n",
      "\n",
      "Fold: 8  Epoch: 651  Training loss = 2.4413  Validation loss = 7.3775  \n",
      "\n",
      "Fold: 8  Epoch: 652  Training loss = 2.4412  Validation loss = 7.3773  \n",
      "\n",
      "Fold: 8  Epoch: 653  Training loss = 2.4410  Validation loss = 7.3772  \n",
      "\n",
      "Fold: 8  Epoch: 654  Training loss = 2.4409  Validation loss = 7.3770  \n",
      "\n",
      "Fold: 8  Epoch: 655  Training loss = 2.4408  Validation loss = 7.3768  \n",
      "\n",
      "Fold: 8  Epoch: 656  Training loss = 2.4406  Validation loss = 7.3767  \n",
      "\n",
      "Fold: 8  Epoch: 657  Training loss = 2.4405  Validation loss = 7.3765  \n",
      "\n",
      "Fold: 8  Epoch: 658  Training loss = 2.4404  Validation loss = 7.3764  \n",
      "\n",
      "Fold: 8  Epoch: 659  Training loss = 2.4402  Validation loss = 7.3762  \n",
      "\n",
      "Fold: 8  Epoch: 660  Training loss = 2.4401  Validation loss = 7.3761  \n",
      "\n",
      "Fold: 8  Epoch: 661  Training loss = 2.4400  Validation loss = 7.3759  \n",
      "\n",
      "Fold: 8  Epoch: 662  Training loss = 2.4399  Validation loss = 7.3758  \n",
      "\n",
      "Fold: 8  Epoch: 663  Training loss = 2.4398  Validation loss = 7.3756  \n",
      "\n",
      "Fold: 8  Epoch: 664  Training loss = 2.4397  Validation loss = 7.3755  \n",
      "\n",
      "Fold: 8  Epoch: 665  Training loss = 2.4396  Validation loss = 7.3754  \n",
      "\n",
      "Fold: 8  Epoch: 666  Training loss = 2.4394  Validation loss = 7.3752  \n",
      "\n",
      "Fold: 8  Epoch: 667  Training loss = 2.4393  Validation loss = 7.3750  \n",
      "\n",
      "Fold: 8  Epoch: 668  Training loss = 2.4392  Validation loss = 7.3749  \n",
      "\n",
      "Fold: 8  Epoch: 669  Training loss = 2.4390  Validation loss = 7.3748  \n",
      "\n",
      "Fold: 8  Epoch: 670  Training loss = 2.4389  Validation loss = 7.3746  \n",
      "\n",
      "Fold: 8  Epoch: 671  Training loss = 2.4388  Validation loss = 7.3744  \n",
      "\n",
      "Fold: 8  Epoch: 672  Training loss = 2.4386  Validation loss = 7.3743  \n",
      "\n",
      "Fold: 8  Epoch: 673  Training loss = 2.4385  Validation loss = 7.3742  \n",
      "\n",
      "Fold: 8  Epoch: 674  Training loss = 2.4384  Validation loss = 7.3740  \n",
      "\n",
      "Fold: 8  Epoch: 675  Training loss = 2.4383  Validation loss = 7.3739  \n",
      "\n",
      "Fold: 8  Epoch: 676  Training loss = 2.4381  Validation loss = 7.3737  \n",
      "\n",
      "Fold: 8  Epoch: 677  Training loss = 2.4380  Validation loss = 7.3735  \n",
      "\n",
      "Fold: 8  Epoch: 678  Training loss = 2.4378  Validation loss = 7.3733  \n",
      "\n",
      "Fold: 8  Epoch: 679  Training loss = 2.4377  Validation loss = 7.3732  \n",
      "\n",
      "Fold: 8  Epoch: 680  Training loss = 2.4376  Validation loss = 7.3730  \n",
      "\n",
      "Fold: 8  Epoch: 681  Training loss = 2.4374  Validation loss = 7.3729  \n",
      "\n",
      "Fold: 8  Epoch: 682  Training loss = 2.4373  Validation loss = 7.3728  \n",
      "\n",
      "Fold: 8  Epoch: 683  Training loss = 2.4372  Validation loss = 7.3726  \n",
      "\n",
      "Fold: 8  Epoch: 684  Training loss = 2.4370  Validation loss = 7.3724  \n",
      "\n",
      "Fold: 8  Epoch: 685  Training loss = 2.4369  Validation loss = 7.3723  \n",
      "\n",
      "Fold: 8  Epoch: 686  Training loss = 2.4368  Validation loss = 7.3721  \n",
      "\n",
      "Fold: 8  Epoch: 687  Training loss = 2.4367  Validation loss = 7.3720  \n",
      "\n",
      "Fold: 8  Epoch: 688  Training loss = 2.4366  Validation loss = 7.3718  \n",
      "\n",
      "Fold: 8  Epoch: 689  Training loss = 2.4364  Validation loss = 7.3717  \n",
      "\n",
      "Fold: 8  Epoch: 690  Training loss = 2.4363  Validation loss = 7.3715  \n",
      "\n",
      "Fold: 8  Epoch: 691  Training loss = 2.4362  Validation loss = 7.3713  \n",
      "\n",
      "Fold: 8  Epoch: 692  Training loss = 2.4360  Validation loss = 7.3712  \n",
      "\n",
      "Fold: 8  Epoch: 693  Training loss = 2.4359  Validation loss = 7.3710  \n",
      "\n",
      "Fold: 8  Epoch: 694  Training loss = 2.4358  Validation loss = 7.3709  \n",
      "\n",
      "Fold: 8  Epoch: 695  Training loss = 2.4356  Validation loss = 7.3707  \n",
      "\n",
      "Fold: 8  Epoch: 696  Training loss = 2.4355  Validation loss = 7.3706  \n",
      "\n",
      "Fold: 8  Epoch: 697  Training loss = 2.4354  Validation loss = 7.3704  \n",
      "\n",
      "Fold: 8  Epoch: 698  Training loss = 2.4353  Validation loss = 7.3703  \n",
      "\n",
      "Fold: 8  Epoch: 699  Training loss = 2.4351  Validation loss = 7.3701  \n",
      "\n",
      "Fold: 8  Epoch: 700  Training loss = 2.4350  Validation loss = 7.3700  \n",
      "\n",
      "Fold: 8  Epoch: 701  Training loss = 2.4349  Validation loss = 7.3698  \n",
      "\n",
      "Fold: 8  Epoch: 702  Training loss = 2.4348  Validation loss = 7.3697  \n",
      "\n",
      "Fold: 8  Epoch: 703  Training loss = 2.4347  Validation loss = 7.3696  \n",
      "\n",
      "Fold: 8  Epoch: 704  Training loss = 2.4346  Validation loss = 7.3694  \n",
      "\n",
      "Fold: 8  Epoch: 705  Training loss = 2.4345  Validation loss = 7.3693  \n",
      "\n",
      "Fold: 8  Epoch: 706  Training loss = 2.4343  Validation loss = 7.3691  \n",
      "\n",
      "Fold: 8  Epoch: 707  Training loss = 2.4342  Validation loss = 7.3690  \n",
      "\n",
      "Fold: 8  Epoch: 708  Training loss = 2.4341  Validation loss = 7.3689  \n",
      "\n",
      "Fold: 8  Epoch: 709  Training loss = 2.4340  Validation loss = 7.3688  \n",
      "\n",
      "Fold: 8  Epoch: 710  Training loss = 2.4339  Validation loss = 7.3686  \n",
      "\n",
      "Fold: 8  Epoch: 711  Training loss = 2.4338  Validation loss = 7.3685  \n",
      "\n",
      "Fold: 8  Epoch: 712  Training loss = 2.4337  Validation loss = 7.3683  \n",
      "\n",
      "Fold: 8  Epoch: 713  Training loss = 2.4336  Validation loss = 7.3682  \n",
      "\n",
      "Fold: 8  Epoch: 714  Training loss = 2.4335  Validation loss = 7.3681  \n",
      "\n",
      "Fold: 8  Epoch: 715  Training loss = 2.4333  Validation loss = 7.3679  \n",
      "\n",
      "Fold: 8  Epoch: 716  Training loss = 2.4332  Validation loss = 7.3678  \n",
      "\n",
      "Fold: 8  Epoch: 717  Training loss = 2.4331  Validation loss = 7.3677  \n",
      "\n",
      "Fold: 8  Epoch: 718  Training loss = 2.4330  Validation loss = 7.3675  \n",
      "\n",
      "Fold: 8  Epoch: 719  Training loss = 2.4329  Validation loss = 7.3674  \n",
      "\n",
      "Fold: 8  Epoch: 720  Training loss = 2.4328  Validation loss = 7.3673  \n",
      "\n",
      "Fold: 8  Epoch: 721  Training loss = 2.4327  Validation loss = 7.3672  \n",
      "\n",
      "Fold: 8  Epoch: 722  Training loss = 2.4325  Validation loss = 7.3670  \n",
      "\n",
      "Fold: 8  Epoch: 723  Training loss = 2.4324  Validation loss = 7.3669  \n",
      "\n",
      "Fold: 8  Epoch: 724  Training loss = 2.4323  Validation loss = 7.3667  \n",
      "\n",
      "Fold: 8  Epoch: 725  Training loss = 2.4322  Validation loss = 7.3666  \n",
      "\n",
      "Fold: 8  Epoch: 726  Training loss = 2.4320  Validation loss = 7.3664  \n",
      "\n",
      "Fold: 8  Epoch: 727  Training loss = 2.4319  Validation loss = 7.3663  \n",
      "\n",
      "Fold: 8  Epoch: 728  Training loss = 2.4318  Validation loss = 7.3661  \n",
      "\n",
      "Fold: 8  Epoch: 729  Training loss = 2.4317  Validation loss = 7.3660  \n",
      "\n",
      "Fold: 8  Epoch: 730  Training loss = 2.4316  Validation loss = 7.3659  \n",
      "\n",
      "Fold: 8  Epoch: 731  Training loss = 2.4315  Validation loss = 7.3657  \n",
      "\n",
      "Fold: 8  Epoch: 732  Training loss = 2.4313  Validation loss = 7.3656  \n",
      "\n",
      "Fold: 8  Epoch: 733  Training loss = 2.4312  Validation loss = 7.3654  \n",
      "\n",
      "Fold: 8  Epoch: 734  Training loss = 2.4311  Validation loss = 7.3653  \n",
      "\n",
      "Fold: 8  Epoch: 735  Training loss = 2.4309  Validation loss = 7.3651  \n",
      "\n",
      "Fold: 8  Epoch: 736  Training loss = 2.4308  Validation loss = 7.3650  \n",
      "\n",
      "Fold: 8  Epoch: 737  Training loss = 2.4307  Validation loss = 7.3649  \n",
      "\n",
      "Fold: 8  Epoch: 738  Training loss = 2.4306  Validation loss = 7.3647  \n",
      "\n",
      "Fold: 8  Epoch: 739  Training loss = 2.4305  Validation loss = 7.3646  \n",
      "\n",
      "Fold: 8  Epoch: 740  Training loss = 2.4304  Validation loss = 7.3645  \n",
      "\n",
      "Fold: 8  Epoch: 741  Training loss = 2.4302  Validation loss = 7.3643  \n",
      "\n",
      "Fold: 8  Epoch: 742  Training loss = 2.4300  Validation loss = 7.3641  \n",
      "\n",
      "Fold: 8  Epoch: 743  Training loss = 2.4299  Validation loss = 7.3639  \n",
      "\n",
      "Fold: 8  Epoch: 744  Training loss = 2.4298  Validation loss = 7.3637  \n",
      "\n",
      "Fold: 8  Epoch: 745  Training loss = 2.4296  Validation loss = 7.3636  \n",
      "\n",
      "Fold: 8  Epoch: 746  Training loss = 2.4295  Validation loss = 7.3635  \n",
      "\n",
      "Fold: 8  Epoch: 747  Training loss = 2.4294  Validation loss = 7.3633  \n",
      "\n",
      "Fold: 8  Epoch: 748  Training loss = 2.4293  Validation loss = 7.3632  \n",
      "\n",
      "Fold: 8  Epoch: 749  Training loss = 2.4292  Validation loss = 7.3630  \n",
      "\n",
      "Fold: 8  Epoch: 750  Training loss = 2.4290  Validation loss = 7.3628  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 750  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.9757  Validation loss = 11.6370  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.9756  Validation loss = 11.6369  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.9755  Validation loss = 11.6368  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.9754  Validation loss = 11.6367  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.9753  Validation loss = 11.6366  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.9751  Validation loss = 11.6364  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.9750  Validation loss = 11.6364  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.9748  Validation loss = 11.6362  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.9747  Validation loss = 11.6361  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.9746  Validation loss = 11.6360  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.9744  Validation loss = 11.6359  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.9743  Validation loss = 11.6358  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.9742  Validation loss = 11.6357  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.9741  Validation loss = 11.6356  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.9739  Validation loss = 11.6355  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.9738  Validation loss = 11.6354  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.9736  Validation loss = 11.6353  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.9735  Validation loss = 11.6352  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.9734  Validation loss = 11.6351  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.9732  Validation loss = 11.6350  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.9731  Validation loss = 11.6349  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.9730  Validation loss = 11.6348  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.9729  Validation loss = 11.6347  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.9728  Validation loss = 11.6346  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.9726  Validation loss = 11.6345  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.9725  Validation loss = 11.6344  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.9724  Validation loss = 11.6343  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.9722  Validation loss = 11.6342  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.9721  Validation loss = 11.6341  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.9720  Validation loss = 11.6340  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.9718  Validation loss = 11.6338  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.9717  Validation loss = 11.6337  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.9716  Validation loss = 11.6336  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.9714  Validation loss = 11.6335  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.9713  Validation loss = 11.6334  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.9712  Validation loss = 11.6333  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.9710  Validation loss = 11.6332  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.9709  Validation loss = 11.6331  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.9708  Validation loss = 11.6330  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.9707  Validation loss = 11.6329  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.9705  Validation loss = 11.6328  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.9704  Validation loss = 11.6327  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.9702  Validation loss = 11.6325  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.9701  Validation loss = 11.6324  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.9700  Validation loss = 11.6323  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.9698  Validation loss = 11.6322  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.9697  Validation loss = 11.6321  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.9696  Validation loss = 11.6320  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.9694  Validation loss = 11.6319  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.9693  Validation loss = 11.6318  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.9692  Validation loss = 11.6317  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.9690  Validation loss = 11.6316  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.9689  Validation loss = 11.6315  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.9687  Validation loss = 11.6313  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.9686  Validation loss = 11.6312  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.9685  Validation loss = 11.6311  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.9684  Validation loss = 11.6311  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.9682  Validation loss = 11.6309  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.9681  Validation loss = 11.6308  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.9680  Validation loss = 11.6307  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.9679  Validation loss = 11.6306  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.9677  Validation loss = 11.6305  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.9676  Validation loss = 11.6304  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.9675  Validation loss = 11.6303  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.9673  Validation loss = 11.6302  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.9672  Validation loss = 11.6301  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.9671  Validation loss = 11.6300  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.9670  Validation loss = 11.6299  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.9668  Validation loss = 11.6298  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.9667  Validation loss = 11.6297  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.9666  Validation loss = 11.6296  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.9664  Validation loss = 11.6295  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.9663  Validation loss = 11.6294  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.9662  Validation loss = 11.6293  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.9661  Validation loss = 11.6292  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.9659  Validation loss = 11.6291  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.9658  Validation loss = 11.6290  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.9656  Validation loss = 11.6288  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.9655  Validation loss = 11.6287  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.9653  Validation loss = 11.6286  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.9652  Validation loss = 11.6284  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.9650  Validation loss = 11.6283  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.9649  Validation loss = 11.6282  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.9648  Validation loss = 11.6282  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.9647  Validation loss = 11.6280  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.9645  Validation loss = 11.6279  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.9644  Validation loss = 11.6278  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.9642  Validation loss = 11.6277  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.9641  Validation loss = 11.6276  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.9639  Validation loss = 11.6274  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.9638  Validation loss = 11.6273  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.9637  Validation loss = 11.6272  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.9635  Validation loss = 11.6271  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.9634  Validation loss = 11.6270  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.9633  Validation loss = 11.6270  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.9632  Validation loss = 11.6268  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.9631  Validation loss = 11.6267  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.9629  Validation loss = 11.6266  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.9628  Validation loss = 11.6265  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.9627  Validation loss = 11.6264  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.9626  Validation loss = 11.6263  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.9624  Validation loss = 11.6262  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.9623  Validation loss = 11.6261  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.9622  Validation loss = 11.6260  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.9620  Validation loss = 11.6259  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.9619  Validation loss = 11.6258  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.9617  Validation loss = 11.6256  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.9616  Validation loss = 11.6255  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.9615  Validation loss = 11.6254  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.9613  Validation loss = 11.6253  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.9612  Validation loss = 11.6252  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.9611  Validation loss = 11.6251  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.9609  Validation loss = 11.6250  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.9608  Validation loss = 11.6249  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.9606  Validation loss = 11.6248  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.9605  Validation loss = 11.6247  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.9604  Validation loss = 11.6245  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.9603  Validation loss = 11.6244  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.9602  Validation loss = 11.6244  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.9600  Validation loss = 11.6242  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.9599  Validation loss = 11.6241  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.9597  Validation loss = 11.6240  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.9596  Validation loss = 11.6239  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.9595  Validation loss = 11.6238  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.9594  Validation loss = 11.6237  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.9592  Validation loss = 11.6237  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.9591  Validation loss = 11.6236  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.9590  Validation loss = 11.6234  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.9589  Validation loss = 11.6233  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.9587  Validation loss = 11.6232  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.9586  Validation loss = 11.6231  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.9584  Validation loss = 11.6230  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.9583  Validation loss = 11.6229  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.9582  Validation loss = 11.6228  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.9581  Validation loss = 11.6227  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.9579  Validation loss = 11.6226  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.9578  Validation loss = 11.6225  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.9577  Validation loss = 11.6224  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.9576  Validation loss = 11.6223  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.9575  Validation loss = 11.6222  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.9573  Validation loss = 11.6221  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.9572  Validation loss = 11.6219  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.9570  Validation loss = 11.6218  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.9569  Validation loss = 11.6217  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.9568  Validation loss = 11.6216  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.9567  Validation loss = 11.6215  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.9565  Validation loss = 11.6214  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.9564  Validation loss = 11.6213  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.9562  Validation loss = 11.6212  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.9561  Validation loss = 11.6211  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.9560  Validation loss = 11.6210  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.9559  Validation loss = 11.6209  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.9557  Validation loss = 11.6208  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.9556  Validation loss = 11.6207  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.9555  Validation loss = 11.6206  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.9554  Validation loss = 11.6205  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.9552  Validation loss = 11.6204  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.9551  Validation loss = 11.6203  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.9549  Validation loss = 11.6202  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.9548  Validation loss = 11.6201  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.9547  Validation loss = 11.6199  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.9545  Validation loss = 11.6198  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.9544  Validation loss = 11.6197  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.9542  Validation loss = 11.6196  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.9541  Validation loss = 11.6195  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.9540  Validation loss = 11.6194  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.9538  Validation loss = 11.6193  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.9537  Validation loss = 11.6191  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.9535  Validation loss = 11.6190  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.9534  Validation loss = 11.6189  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.9532  Validation loss = 11.6188  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.9531  Validation loss = 11.6187  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.9530  Validation loss = 11.6186  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.9529  Validation loss = 11.6185  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.9527  Validation loss = 11.6183  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.9526  Validation loss = 11.6182  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.9525  Validation loss = 11.6181  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.9523  Validation loss = 11.6180  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.9522  Validation loss = 11.6179  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.9521  Validation loss = 11.6178  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.9519  Validation loss = 11.6177  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.9518  Validation loss = 11.6176  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.9517  Validation loss = 11.6175  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.9516  Validation loss = 11.6174  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.9514  Validation loss = 11.6172  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.9513  Validation loss = 11.6171  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.9511  Validation loss = 11.6170  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.9509  Validation loss = 11.6169  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.9508  Validation loss = 11.6167  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.9506  Validation loss = 11.6166  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.9505  Validation loss = 11.6165  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.9504  Validation loss = 11.6164  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.9503  Validation loss = 11.6163  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.9502  Validation loss = 11.6162  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.9501  Validation loss = 11.6161  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.9499  Validation loss = 11.6160  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.9498  Validation loss = 11.6159  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.9497  Validation loss = 11.6158  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.9495  Validation loss = 11.6157  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.9494  Validation loss = 11.6156  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.9493  Validation loss = 11.6155  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.9492  Validation loss = 11.6154  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.9490  Validation loss = 11.6153  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.9489  Validation loss = 11.6152  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.9488  Validation loss = 11.6151  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.9486  Validation loss = 11.6150  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.9485  Validation loss = 11.6149  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.9484  Validation loss = 11.6148  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.9482  Validation loss = 11.6146  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.9481  Validation loss = 11.6145  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.9480  Validation loss = 11.6144  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.9479  Validation loss = 11.6143  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.9477  Validation loss = 11.6142  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.9476  Validation loss = 11.6141  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.9474  Validation loss = 11.6140  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.9473  Validation loss = 11.6138  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.9472  Validation loss = 11.6137  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.9470  Validation loss = 11.6136  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.9469  Validation loss = 11.6135  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.9468  Validation loss = 11.6134  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.9467  Validation loss = 11.6133  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.9466  Validation loss = 11.6132  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.9465  Validation loss = 11.6132  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.9463  Validation loss = 11.6131  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.9462  Validation loss = 11.6130  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.9461  Validation loss = 11.6128  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.9459  Validation loss = 11.6127  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.9458  Validation loss = 11.6126  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.9456  Validation loss = 11.6125  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.9455  Validation loss = 11.6124  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.9454  Validation loss = 11.6123  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.9453  Validation loss = 11.6122  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.9451  Validation loss = 11.6121  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.9450  Validation loss = 11.6119  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.9448  Validation loss = 11.6118  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.9447  Validation loss = 11.6117  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.9446  Validation loss = 11.6116  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.9445  Validation loss = 11.6115  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.9443  Validation loss = 11.6114  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.9441  Validation loss = 11.6112  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.9440  Validation loss = 11.6111  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.9439  Validation loss = 11.6111  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.9438  Validation loss = 11.6109  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.9436  Validation loss = 11.6108  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.9435  Validation loss = 11.6107  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.9434  Validation loss = 11.6107  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.9433  Validation loss = 11.6105  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.9432  Validation loss = 11.6104  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.9430  Validation loss = 11.6103  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.9429  Validation loss = 11.6102  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.9428  Validation loss = 11.6101  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.9426  Validation loss = 11.6100  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.9425  Validation loss = 11.6099  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.9424  Validation loss = 11.6098  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.9423  Validation loss = 11.6097  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.9421  Validation loss = 11.6096  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.9420  Validation loss = 11.6095  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 2.9419  Validation loss = 11.6094  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 2.9418  Validation loss = 11.6093  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 2.9416  Validation loss = 11.6092  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 2.9415  Validation loss = 11.6090  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 2.9413  Validation loss = 11.6089  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 2.9412  Validation loss = 11.6088  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 2.9411  Validation loss = 11.6087  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 2.9410  Validation loss = 11.6086  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 2.9408  Validation loss = 11.6085  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 2.9407  Validation loss = 11.6084  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 2.9406  Validation loss = 11.6083  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 2.9404  Validation loss = 11.6082  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 2.9403  Validation loss = 11.6080  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 2.9401  Validation loss = 11.6079  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 2.9400  Validation loss = 11.6078  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 2.9398  Validation loss = 11.6077  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 2.9397  Validation loss = 11.6075  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 2.9395  Validation loss = 11.6074  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 2.9394  Validation loss = 11.6073  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 2.9393  Validation loss = 11.6072  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 2.9391  Validation loss = 11.6071  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 2.9390  Validation loss = 11.6070  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 2.9389  Validation loss = 11.6069  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 2.9388  Validation loss = 11.6068  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 2.9386  Validation loss = 11.6066  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 2.9385  Validation loss = 11.6065  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 2.9383  Validation loss = 11.6064  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 2.9382  Validation loss = 11.6063  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 2.9381  Validation loss = 11.6062  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 2.9380  Validation loss = 11.6061  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 2.9379  Validation loss = 11.6060  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 2.9378  Validation loss = 11.6059  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 2.9376  Validation loss = 11.6058  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 2.9375  Validation loss = 11.6057  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 2.9374  Validation loss = 11.6056  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 2.9372  Validation loss = 11.6055  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 2.9371  Validation loss = 11.6054  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 2.9370  Validation loss = 11.6053  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 2.9369  Validation loss = 11.6052  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 2.9367  Validation loss = 11.6051  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 2.9366  Validation loss = 11.6050  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 2.9365  Validation loss = 11.6049  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 2.9364  Validation loss = 11.6048  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 2.9363  Validation loss = 11.6047  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 2.9361  Validation loss = 11.6045  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 2.9360  Validation loss = 11.6045  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 2.9359  Validation loss = 11.6043  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 2.9358  Validation loss = 11.6042  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 2.9356  Validation loss = 11.6041  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 2.9355  Validation loss = 11.6040  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 2.9354  Validation loss = 11.6039  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 2.9352  Validation loss = 11.6038  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 2.9350  Validation loss = 11.6036  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 2.9349  Validation loss = 11.6035  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 2.9348  Validation loss = 11.6034  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 2.9347  Validation loss = 11.6033  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 2.9346  Validation loss = 11.6032  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 2.9344  Validation loss = 11.6031  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 2.9343  Validation loss = 11.6030  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 2.9341  Validation loss = 11.6029  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 2.9340  Validation loss = 11.6027  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 2.9339  Validation loss = 11.6026  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 2.9337  Validation loss = 11.6025  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 2.9336  Validation loss = 11.6025  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 2.9335  Validation loss = 11.6023  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 2.9334  Validation loss = 11.6022  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 2.9333  Validation loss = 11.6022  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 2.9332  Validation loss = 11.6021  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 2.9330  Validation loss = 11.6020  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 2.9329  Validation loss = 11.6019  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 2.9328  Validation loss = 11.6018  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 2.9327  Validation loss = 11.6017  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 2.9325  Validation loss = 11.6015  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 2.9324  Validation loss = 11.6014  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 2.9322  Validation loss = 11.6013  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 2.9321  Validation loss = 11.6012  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 2.9320  Validation loss = 11.6011  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 2.9318  Validation loss = 11.6010  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 2.9317  Validation loss = 11.6008  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 2.9315  Validation loss = 11.6007  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 2.9314  Validation loss = 11.6006  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 2.9313  Validation loss = 11.6005  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 2.9312  Validation loss = 11.6004  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 2.9310  Validation loss = 11.6003  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 2.9309  Validation loss = 11.6002  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 2.9308  Validation loss = 11.6001  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 2.9306  Validation loss = 11.6000  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 2.9305  Validation loss = 11.5999  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 2.9304  Validation loss = 11.5998  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 2.9302  Validation loss = 11.5997  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 2.9301  Validation loss = 11.5995  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 2.9300  Validation loss = 11.5994  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 2.9298  Validation loss = 11.5993  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 2.9297  Validation loss = 11.5992  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 2.9295  Validation loss = 11.5991  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 2.9294  Validation loss = 11.5990  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 2.9293  Validation loss = 11.5988  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 2.9291  Validation loss = 11.5987  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 2.9290  Validation loss = 11.5986  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 2.9288  Validation loss = 11.5985  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 2.9287  Validation loss = 11.5983  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 2.9286  Validation loss = 11.5982  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 2.9284  Validation loss = 11.5981  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 2.9283  Validation loss = 11.5980  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 2.9282  Validation loss = 11.5979  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 2.9281  Validation loss = 11.5978  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 2.9280  Validation loss = 11.5977  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 2.9278  Validation loss = 11.5976  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 2.9277  Validation loss = 11.5975  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 2.9276  Validation loss = 11.5974  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 2.9274  Validation loss = 11.5973  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 2.9273  Validation loss = 11.5971  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 2.9272  Validation loss = 11.5971  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 2.9271  Validation loss = 11.5970  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 2.9270  Validation loss = 11.5969  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 2.9268  Validation loss = 11.5968  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 2.9267  Validation loss = 11.5967  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 2.9266  Validation loss = 11.5966  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 2.9265  Validation loss = 11.5965  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 2.9264  Validation loss = 11.5963  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 2.9262  Validation loss = 11.5962  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 2.9261  Validation loss = 11.5961  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 2.9260  Validation loss = 11.5960  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 2.9259  Validation loss = 11.5959  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 2.9258  Validation loss = 11.5958  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 2.9256  Validation loss = 11.5957  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 2.9255  Validation loss = 11.5956  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 2.9253  Validation loss = 11.5955  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 2.9252  Validation loss = 11.5954  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 2.9251  Validation loss = 11.5953  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 2.9249  Validation loss = 11.5951  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 2.9248  Validation loss = 11.5950  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 2.9246  Validation loss = 11.5949  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 2.9245  Validation loss = 11.5947  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 2.9244  Validation loss = 11.5946  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 2.9243  Validation loss = 11.5946  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 2.9241  Validation loss = 11.5944  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 2.9240  Validation loss = 11.5943  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 2.9239  Validation loss = 11.5942  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 2.9238  Validation loss = 11.5941  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 2.9236  Validation loss = 11.5940  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 2.9235  Validation loss = 11.5939  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 2.9233  Validation loss = 11.5937  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 2.9232  Validation loss = 11.5936  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 2.9231  Validation loss = 11.5935  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 2.9230  Validation loss = 11.5934  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 2.9229  Validation loss = 11.5934  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 2.9228  Validation loss = 11.5933  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 2.9227  Validation loss = 11.5932  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 2.9226  Validation loss = 11.5931  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 2.9225  Validation loss = 11.5930  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 2.9224  Validation loss = 11.5929  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 2.9222  Validation loss = 11.5928  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 2.9221  Validation loss = 11.5927  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 2.9220  Validation loss = 11.5926  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 2.9218  Validation loss = 11.5925  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 2.9217  Validation loss = 11.5924  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 2.9216  Validation loss = 11.5923  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 2.9215  Validation loss = 11.5921  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 2.9213  Validation loss = 11.5920  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 2.9212  Validation loss = 11.5919  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 2.9211  Validation loss = 11.5918  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 2.9210  Validation loss = 11.5917  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 2.9208  Validation loss = 11.5916  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 2.9207  Validation loss = 11.5915  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 2.9206  Validation loss = 11.5914  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 2.9204  Validation loss = 11.5913  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 2.9203  Validation loss = 11.5912  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 2.9202  Validation loss = 11.5910  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 2.9200  Validation loss = 11.5909  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 2.9199  Validation loss = 11.5908  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 2.9198  Validation loss = 11.5907  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 2.9197  Validation loss = 11.5906  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 2.9195  Validation loss = 11.5905  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 2.9194  Validation loss = 11.5904  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 2.9193  Validation loss = 11.5903  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 2.9192  Validation loss = 11.5902  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 2.9191  Validation loss = 11.5901  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 2.9189  Validation loss = 11.5899  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 2.9188  Validation loss = 11.5898  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 2.9187  Validation loss = 11.5897  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 2.9185  Validation loss = 11.5896  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 2.9184  Validation loss = 11.5895  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 2.9183  Validation loss = 11.5894  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 2.9182  Validation loss = 11.5893  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 2.9180  Validation loss = 11.5892  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 2.9179  Validation loss = 11.5891  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 2.9178  Validation loss = 11.5890  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 2.9176  Validation loss = 11.5889  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 2.9175  Validation loss = 11.5888  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 2.9174  Validation loss = 11.5886  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 2.9172  Validation loss = 11.5885  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 2.9171  Validation loss = 11.5884  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 2.9169  Validation loss = 11.5882  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 2.9168  Validation loss = 11.5881  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 2.9167  Validation loss = 11.5880  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 2.9165  Validation loss = 11.5879  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 2.9164  Validation loss = 11.5878  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 2.9163  Validation loss = 11.5877  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 2.9162  Validation loss = 11.5876  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 2.9160  Validation loss = 11.5875  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 2.9159  Validation loss = 11.5874  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 2.9158  Validation loss = 11.5872  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 2.9156  Validation loss = 11.5871  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 2.9155  Validation loss = 11.5870  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 2.9154  Validation loss = 11.5869  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 2.9153  Validation loss = 11.5868  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 2.9152  Validation loss = 11.5867  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 2.9150  Validation loss = 11.5866  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 2.9149  Validation loss = 11.5864  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 2.9147  Validation loss = 11.5863  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 2.9146  Validation loss = 11.5862  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 2.9144  Validation loss = 11.5861  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 2.9143  Validation loss = 11.5860  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 2.9142  Validation loss = 11.5859  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 2.9141  Validation loss = 11.5858  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 2.9140  Validation loss = 11.5857  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 2.9139  Validation loss = 11.5856  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 2.9138  Validation loss = 11.5855  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 2.9136  Validation loss = 11.5854  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 2.9135  Validation loss = 11.5852  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 2.9134  Validation loss = 11.5852  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 2.9132  Validation loss = 11.5850  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 2.9131  Validation loss = 11.5849  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 2.9130  Validation loss = 11.5848  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 2.9129  Validation loss = 11.5847  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 2.9128  Validation loss = 11.5846  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 2.9126  Validation loss = 11.5845  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 2.9125  Validation loss = 11.5844  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 2.9124  Validation loss = 11.5843  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 2.9122  Validation loss = 11.5842  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 2.9121  Validation loss = 11.5841  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 2.9120  Validation loss = 11.5840  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 2.9119  Validation loss = 11.5839  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 2.9118  Validation loss = 11.5838  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 2.9117  Validation loss = 11.5837  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 2.9115  Validation loss = 11.5835  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 2.9114  Validation loss = 11.5834  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 2.9112  Validation loss = 11.5833  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 2.9111  Validation loss = 11.5832  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 2.9110  Validation loss = 11.5831  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 2.9109  Validation loss = 11.5830  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 2.9107  Validation loss = 11.5829  \n",
      "\n",
      "Fold: 9  Epoch: 501  Training loss = 2.9106  Validation loss = 11.5828  \n",
      "\n",
      "Fold: 9  Epoch: 502  Training loss = 2.9105  Validation loss = 11.5827  \n",
      "\n",
      "Fold: 9  Epoch: 503  Training loss = 2.9104  Validation loss = 11.5825  \n",
      "\n",
      "Fold: 9  Epoch: 504  Training loss = 2.9102  Validation loss = 11.5824  \n",
      "\n",
      "Fold: 9  Epoch: 505  Training loss = 2.9101  Validation loss = 11.5823  \n",
      "\n",
      "Fold: 9  Epoch: 506  Training loss = 2.9100  Validation loss = 11.5822  \n",
      "\n",
      "Fold: 9  Epoch: 507  Training loss = 2.9099  Validation loss = 11.5821  \n",
      "\n",
      "Fold: 9  Epoch: 508  Training loss = 2.9098  Validation loss = 11.5820  \n",
      "\n",
      "Fold: 9  Epoch: 509  Training loss = 2.9096  Validation loss = 11.5819  \n",
      "\n",
      "Fold: 9  Epoch: 510  Training loss = 2.9095  Validation loss = 11.5818  \n",
      "\n",
      "Fold: 9  Epoch: 511  Training loss = 2.9094  Validation loss = 11.5817  \n",
      "\n",
      "Fold: 9  Epoch: 512  Training loss = 2.9093  Validation loss = 11.5816  \n",
      "\n",
      "Fold: 9  Epoch: 513  Training loss = 2.9091  Validation loss = 11.5814  \n",
      "\n",
      "Fold: 9  Epoch: 514  Training loss = 2.9090  Validation loss = 11.5813  \n",
      "\n",
      "Fold: 9  Epoch: 515  Training loss = 2.9089  Validation loss = 11.5812  \n",
      "\n",
      "Fold: 9  Epoch: 516  Training loss = 2.9087  Validation loss = 11.5811  \n",
      "\n",
      "Fold: 9  Epoch: 517  Training loss = 2.9086  Validation loss = 11.5810  \n",
      "\n",
      "Fold: 9  Epoch: 518  Training loss = 2.9085  Validation loss = 11.5809  \n",
      "\n",
      "Fold: 9  Epoch: 519  Training loss = 2.9084  Validation loss = 11.5807  \n",
      "\n",
      "Fold: 9  Epoch: 520  Training loss = 2.9082  Validation loss = 11.5806  \n",
      "\n",
      "Fold: 9  Epoch: 521  Training loss = 2.9081  Validation loss = 11.5805  \n",
      "\n",
      "Fold: 9  Epoch: 522  Training loss = 2.9080  Validation loss = 11.5804  \n",
      "\n",
      "Fold: 9  Epoch: 523  Training loss = 2.9078  Validation loss = 11.5803  \n",
      "\n",
      "Fold: 9  Epoch: 524  Training loss = 2.9077  Validation loss = 11.5801  \n",
      "\n",
      "Fold: 9  Epoch: 525  Training loss = 2.9076  Validation loss = 11.5800  \n",
      "\n",
      "Fold: 9  Epoch: 526  Training loss = 2.9074  Validation loss = 11.5799  \n",
      "\n",
      "Fold: 9  Epoch: 527  Training loss = 2.9073  Validation loss = 11.5798  \n",
      "\n",
      "Fold: 9  Epoch: 528  Training loss = 2.9072  Validation loss = 11.5797  \n",
      "\n",
      "Fold: 9  Epoch: 529  Training loss = 2.9071  Validation loss = 11.5795  \n",
      "\n",
      "Fold: 9  Epoch: 530  Training loss = 2.9069  Validation loss = 11.5794  \n",
      "\n",
      "Fold: 9  Epoch: 531  Training loss = 2.9068  Validation loss = 11.5793  \n",
      "\n",
      "Fold: 9  Epoch: 532  Training loss = 2.9067  Validation loss = 11.5792  \n",
      "\n",
      "Fold: 9  Epoch: 533  Training loss = 2.9066  Validation loss = 11.5791  \n",
      "\n",
      "Fold: 9  Epoch: 534  Training loss = 2.9064  Validation loss = 11.5790  \n",
      "\n",
      "Fold: 9  Epoch: 535  Training loss = 2.9063  Validation loss = 11.5788  \n",
      "\n",
      "Fold: 9  Epoch: 536  Training loss = 2.9062  Validation loss = 11.5787  \n",
      "\n",
      "Fold: 9  Epoch: 537  Training loss = 2.9060  Validation loss = 11.5785  \n",
      "\n",
      "Fold: 9  Epoch: 538  Training loss = 2.9059  Validation loss = 11.5784  \n",
      "\n",
      "Fold: 9  Epoch: 539  Training loss = 2.9058  Validation loss = 11.5783  \n",
      "\n",
      "Fold: 9  Epoch: 540  Training loss = 2.9057  Validation loss = 11.5782  \n",
      "\n",
      "Fold: 9  Epoch: 541  Training loss = 2.9055  Validation loss = 11.5781  \n",
      "\n",
      "Fold: 9  Epoch: 542  Training loss = 2.9054  Validation loss = 11.5780  \n",
      "\n",
      "Fold: 9  Epoch: 543  Training loss = 2.9052  Validation loss = 11.5778  \n",
      "\n",
      "Fold: 9  Epoch: 544  Training loss = 2.9051  Validation loss = 11.5777  \n",
      "\n",
      "Fold: 9  Epoch: 545  Training loss = 2.9050  Validation loss = 11.5776  \n",
      "\n",
      "Fold: 9  Epoch: 546  Training loss = 2.9049  Validation loss = 11.5775  \n",
      "\n",
      "Fold: 9  Epoch: 547  Training loss = 2.9047  Validation loss = 11.5773  \n",
      "\n",
      "Fold: 9  Epoch: 548  Training loss = 2.9046  Validation loss = 11.5772  \n",
      "\n",
      "Fold: 9  Epoch: 549  Training loss = 2.9044  Validation loss = 11.5770  \n",
      "\n",
      "Fold: 9  Epoch: 550  Training loss = 2.9043  Validation loss = 11.5769  \n",
      "\n",
      "Fold: 9  Epoch: 551  Training loss = 2.9041  Validation loss = 11.5768  \n",
      "\n",
      "Fold: 9  Epoch: 552  Training loss = 2.9040  Validation loss = 11.5767  \n",
      "\n",
      "Fold: 9  Epoch: 553  Training loss = 2.9039  Validation loss = 11.5765  \n",
      "\n",
      "Fold: 9  Epoch: 554  Training loss = 2.9038  Validation loss = 11.5764  \n",
      "\n",
      "Fold: 9  Epoch: 555  Training loss = 2.9037  Validation loss = 11.5763  \n",
      "\n",
      "Fold: 9  Epoch: 556  Training loss = 2.9035  Validation loss = 11.5762  \n",
      "\n",
      "Fold: 9  Epoch: 557  Training loss = 2.9034  Validation loss = 11.5761  \n",
      "\n",
      "Fold: 9  Epoch: 558  Training loss = 2.9032  Validation loss = 11.5760  \n",
      "\n",
      "Fold: 9  Epoch: 559  Training loss = 2.9031  Validation loss = 11.5758  \n",
      "\n",
      "Fold: 9  Epoch: 560  Training loss = 2.9030  Validation loss = 11.5757  \n",
      "\n",
      "Fold: 9  Epoch: 561  Training loss = 2.9028  Validation loss = 11.5756  \n",
      "\n",
      "Fold: 9  Epoch: 562  Training loss = 2.9027  Validation loss = 11.5755  \n",
      "\n",
      "Fold: 9  Epoch: 563  Training loss = 2.9026  Validation loss = 11.5753  \n",
      "\n",
      "Fold: 9  Epoch: 564  Training loss = 2.9025  Validation loss = 11.5752  \n",
      "\n",
      "Fold: 9  Epoch: 565  Training loss = 2.9023  Validation loss = 11.5751  \n",
      "\n",
      "Fold: 9  Epoch: 566  Training loss = 2.9022  Validation loss = 11.5750  \n",
      "\n",
      "Fold: 9  Epoch: 567  Training loss = 2.9021  Validation loss = 11.5749  \n",
      "\n",
      "Fold: 9  Epoch: 568  Training loss = 2.9020  Validation loss = 11.5748  \n",
      "\n",
      "Fold: 9  Epoch: 569  Training loss = 2.9019  Validation loss = 11.5747  \n",
      "\n",
      "Fold: 9  Epoch: 570  Training loss = 2.9018  Validation loss = 11.5746  \n",
      "\n",
      "Fold: 9  Epoch: 571  Training loss = 2.9016  Validation loss = 11.5745  \n",
      "\n",
      "Fold: 9  Epoch: 572  Training loss = 2.9015  Validation loss = 11.5744  \n",
      "\n",
      "Fold: 9  Epoch: 573  Training loss = 2.9014  Validation loss = 11.5743  \n",
      "\n",
      "Fold: 9  Epoch: 574  Training loss = 2.9013  Validation loss = 11.5741  \n",
      "\n",
      "Fold: 9  Epoch: 575  Training loss = 2.9012  Validation loss = 11.5740  \n",
      "\n",
      "Fold: 9  Epoch: 576  Training loss = 2.9011  Validation loss = 11.5739  \n",
      "\n",
      "Fold: 9  Epoch: 577  Training loss = 2.9010  Validation loss = 11.5738  \n",
      "\n",
      "Fold: 9  Epoch: 578  Training loss = 2.9009  Validation loss = 11.5738  \n",
      "\n",
      "Fold: 9  Epoch: 579  Training loss = 2.9007  Validation loss = 11.5736  \n",
      "\n",
      "Fold: 9  Epoch: 580  Training loss = 2.9006  Validation loss = 11.5735  \n",
      "\n",
      "Fold: 9  Epoch: 581  Training loss = 2.9005  Validation loss = 11.5734  \n",
      "\n",
      "Fold: 9  Epoch: 582  Training loss = 2.9003  Validation loss = 11.5733  \n",
      "\n",
      "Fold: 9  Epoch: 583  Training loss = 2.9002  Validation loss = 11.5731  \n",
      "\n",
      "Fold: 9  Epoch: 584  Training loss = 2.9000  Validation loss = 11.5730  \n",
      "\n",
      "Fold: 9  Epoch: 585  Training loss = 2.8999  Validation loss = 11.5729  \n",
      "\n",
      "Fold: 9  Epoch: 586  Training loss = 2.8998  Validation loss = 11.5727  \n",
      "\n",
      "Fold: 9  Epoch: 587  Training loss = 2.8997  Validation loss = 11.5726  \n",
      "\n",
      "Fold: 9  Epoch: 588  Training loss = 2.8996  Validation loss = 11.5725  \n",
      "\n",
      "Fold: 9  Epoch: 589  Training loss = 2.8994  Validation loss = 11.5724  \n",
      "\n",
      "Fold: 9  Epoch: 590  Training loss = 2.8993  Validation loss = 11.5723  \n",
      "\n",
      "Fold: 9  Epoch: 591  Training loss = 2.8991  Validation loss = 11.5721  \n",
      "\n",
      "Fold: 9  Epoch: 592  Training loss = 2.8990  Validation loss = 11.5720  \n",
      "\n",
      "Fold: 9  Epoch: 593  Training loss = 2.8989  Validation loss = 11.5719  \n",
      "\n",
      "Fold: 9  Epoch: 594  Training loss = 2.8988  Validation loss = 11.5718  \n",
      "\n",
      "Fold: 9  Epoch: 595  Training loss = 2.8987  Validation loss = 11.5717  \n",
      "\n",
      "Fold: 9  Epoch: 596  Training loss = 2.8985  Validation loss = 11.5715  \n",
      "\n",
      "Fold: 9  Epoch: 597  Training loss = 2.8984  Validation loss = 11.5714  \n",
      "\n",
      "Fold: 9  Epoch: 598  Training loss = 2.8983  Validation loss = 11.5713  \n",
      "\n",
      "Fold: 9  Epoch: 599  Training loss = 2.8982  Validation loss = 11.5712  \n",
      "\n",
      "Fold: 9  Epoch: 600  Training loss = 2.8980  Validation loss = 11.5710  \n",
      "\n",
      "Fold: 9  Epoch: 601  Training loss = 2.8979  Validation loss = 11.5709  \n",
      "\n",
      "Fold: 9  Epoch: 602  Training loss = 2.8978  Validation loss = 11.5708  \n",
      "\n",
      "Fold: 9  Epoch: 603  Training loss = 2.8976  Validation loss = 11.5706  \n",
      "\n",
      "Fold: 9  Epoch: 604  Training loss = 2.8975  Validation loss = 11.5705  \n",
      "\n",
      "Fold: 9  Epoch: 605  Training loss = 2.8974  Validation loss = 11.5704  \n",
      "\n",
      "Fold: 9  Epoch: 606  Training loss = 2.8973  Validation loss = 11.5703  \n",
      "\n",
      "Fold: 9  Epoch: 607  Training loss = 2.8971  Validation loss = 11.5702  \n",
      "\n",
      "Fold: 9  Epoch: 608  Training loss = 2.8970  Validation loss = 11.5700  \n",
      "\n",
      "Fold: 9  Epoch: 609  Training loss = 2.8969  Validation loss = 11.5699  \n",
      "\n",
      "Fold: 9  Epoch: 610  Training loss = 2.8967  Validation loss = 11.5698  \n",
      "\n",
      "Fold: 9  Epoch: 611  Training loss = 2.8966  Validation loss = 11.5697  \n",
      "\n",
      "Fold: 9  Epoch: 612  Training loss = 2.8965  Validation loss = 11.5695  \n",
      "\n",
      "Fold: 9  Epoch: 613  Training loss = 2.8964  Validation loss = 11.5694  \n",
      "\n",
      "Fold: 9  Epoch: 614  Training loss = 2.8962  Validation loss = 11.5693  \n",
      "\n",
      "Fold: 9  Epoch: 615  Training loss = 2.8961  Validation loss = 11.5691  \n",
      "\n",
      "Fold: 9  Epoch: 616  Training loss = 2.8960  Validation loss = 11.5690  \n",
      "\n",
      "Fold: 9  Epoch: 617  Training loss = 2.8959  Validation loss = 11.5689  \n",
      "\n",
      "Fold: 9  Epoch: 618  Training loss = 2.8957  Validation loss = 11.5688  \n",
      "\n",
      "Fold: 9  Epoch: 619  Training loss = 2.8956  Validation loss = 11.5686  \n",
      "\n",
      "Fold: 9  Epoch: 620  Training loss = 2.8955  Validation loss = 11.5685  \n",
      "\n",
      "Fold: 9  Epoch: 621  Training loss = 2.8954  Validation loss = 11.5684  \n",
      "\n",
      "Fold: 9  Epoch: 622  Training loss = 2.8952  Validation loss = 11.5683  \n",
      "\n",
      "Fold: 9  Epoch: 623  Training loss = 2.8951  Validation loss = 11.5682  \n",
      "\n",
      "Fold: 9  Epoch: 624  Training loss = 2.8950  Validation loss = 11.5680  \n",
      "\n",
      "Fold: 9  Epoch: 625  Training loss = 2.8949  Validation loss = 11.5679  \n",
      "\n",
      "Fold: 9  Epoch: 626  Training loss = 2.8948  Validation loss = 11.5678  \n",
      "\n",
      "Fold: 9  Epoch: 627  Training loss = 2.8947  Validation loss = 11.5677  \n",
      "\n",
      "Fold: 9  Epoch: 628  Training loss = 2.8945  Validation loss = 11.5676  \n",
      "\n",
      "Fold: 9  Epoch: 629  Training loss = 2.8944  Validation loss = 11.5674  \n",
      "\n",
      "Fold: 9  Epoch: 630  Training loss = 2.8942  Validation loss = 11.5672  \n",
      "\n",
      "Fold: 9  Epoch: 631  Training loss = 2.8941  Validation loss = 11.5671  \n",
      "\n",
      "Fold: 9  Epoch: 632  Training loss = 2.8939  Validation loss = 11.5669  \n",
      "\n",
      "Fold: 9  Epoch: 633  Training loss = 2.8938  Validation loss = 11.5668  \n",
      "\n",
      "Fold: 9  Epoch: 634  Training loss = 2.8937  Validation loss = 11.5667  \n",
      "\n",
      "Fold: 9  Epoch: 635  Training loss = 2.8935  Validation loss = 11.5666  \n",
      "\n",
      "Fold: 9  Epoch: 636  Training loss = 2.8934  Validation loss = 11.5664  \n",
      "\n",
      "Fold: 9  Epoch: 637  Training loss = 2.8933  Validation loss = 11.5663  \n",
      "\n",
      "Fold: 9  Epoch: 638  Training loss = 2.8931  Validation loss = 11.5661  \n",
      "\n",
      "Fold: 9  Epoch: 639  Training loss = 2.8930  Validation loss = 11.5660  \n",
      "\n",
      "Fold: 9  Epoch: 640  Training loss = 2.8929  Validation loss = 11.5659  \n",
      "\n",
      "Fold: 9  Epoch: 641  Training loss = 2.8928  Validation loss = 11.5658  \n",
      "\n",
      "Fold: 9  Epoch: 642  Training loss = 2.8926  Validation loss = 11.5656  \n",
      "\n",
      "Fold: 9  Epoch: 643  Training loss = 2.8925  Validation loss = 11.5654  \n",
      "\n",
      "Fold: 9  Epoch: 644  Training loss = 2.8924  Validation loss = 11.5653  \n",
      "\n",
      "Fold: 9  Epoch: 645  Training loss = 2.8922  Validation loss = 11.5652  \n",
      "\n",
      "Fold: 9  Epoch: 646  Training loss = 2.8921  Validation loss = 11.5650  \n",
      "\n",
      "Fold: 9  Epoch: 647  Training loss = 2.8920  Validation loss = 11.5649  \n",
      "\n",
      "Fold: 9  Epoch: 648  Training loss = 2.8919  Validation loss = 11.5648  \n",
      "\n",
      "Fold: 9  Epoch: 649  Training loss = 2.8918  Validation loss = 11.5647  \n",
      "\n",
      "Fold: 9  Epoch: 650  Training loss = 2.8916  Validation loss = 11.5645  \n",
      "\n",
      "Fold: 9  Epoch: 651  Training loss = 2.8915  Validation loss = 11.5644  \n",
      "\n",
      "Fold: 9  Epoch: 652  Training loss = 2.8914  Validation loss = 11.5643  \n",
      "\n",
      "Fold: 9  Epoch: 653  Training loss = 2.8912  Validation loss = 11.5641  \n",
      "\n",
      "Fold: 9  Epoch: 654  Training loss = 2.8911  Validation loss = 11.5640  \n",
      "\n",
      "Fold: 9  Epoch: 655  Training loss = 2.8910  Validation loss = 11.5638  \n",
      "\n",
      "Fold: 9  Epoch: 656  Training loss = 2.8908  Validation loss = 11.5637  \n",
      "\n",
      "Fold: 9  Epoch: 657  Training loss = 2.8907  Validation loss = 11.5635  \n",
      "\n",
      "Fold: 9  Epoch: 658  Training loss = 2.8906  Validation loss = 11.5634  \n",
      "\n",
      "Fold: 9  Epoch: 659  Training loss = 2.8905  Validation loss = 11.5633  \n",
      "\n",
      "Fold: 9  Epoch: 660  Training loss = 2.8904  Validation loss = 11.5632  \n",
      "\n",
      "Fold: 9  Epoch: 661  Training loss = 2.8903  Validation loss = 11.5631  \n",
      "\n",
      "Fold: 9  Epoch: 662  Training loss = 2.8901  Validation loss = 11.5629  \n",
      "\n",
      "Fold: 9  Epoch: 663  Training loss = 2.8900  Validation loss = 11.5628  \n",
      "\n",
      "Fold: 9  Epoch: 664  Training loss = 2.8899  Validation loss = 11.5627  \n",
      "\n",
      "Fold: 9  Epoch: 665  Training loss = 2.8897  Validation loss = 11.5625  \n",
      "\n",
      "Fold: 9  Epoch: 666  Training loss = 2.8896  Validation loss = 11.5624  \n",
      "\n",
      "Fold: 9  Epoch: 667  Training loss = 2.8895  Validation loss = 11.5622  \n",
      "\n",
      "Fold: 9  Epoch: 668  Training loss = 2.8894  Validation loss = 11.5621  \n",
      "\n",
      "Fold: 9  Epoch: 669  Training loss = 2.8892  Validation loss = 11.5619  \n",
      "\n",
      "Fold: 9  Epoch: 670  Training loss = 2.8890  Validation loss = 11.5617  \n",
      "\n",
      "Fold: 9  Epoch: 671  Training loss = 2.8889  Validation loss = 11.5616  \n",
      "\n",
      "Fold: 9  Epoch: 672  Training loss = 2.8888  Validation loss = 11.5614  \n",
      "\n",
      "Fold: 9  Epoch: 673  Training loss = 2.8887  Validation loss = 11.5613  \n",
      "\n",
      "Fold: 9  Epoch: 674  Training loss = 2.8886  Validation loss = 11.5612  \n",
      "\n",
      "Fold: 9  Epoch: 675  Training loss = 2.8884  Validation loss = 11.5610  \n",
      "\n",
      "Fold: 9  Epoch: 676  Training loss = 2.8883  Validation loss = 11.5609  \n",
      "\n",
      "Fold: 9  Epoch: 677  Training loss = 2.8882  Validation loss = 11.5607  \n",
      "\n",
      "Fold: 9  Epoch: 678  Training loss = 2.8880  Validation loss = 11.5606  \n",
      "\n",
      "Fold: 9  Epoch: 679  Training loss = 2.8879  Validation loss = 11.5605  \n",
      "\n",
      "Fold: 9  Epoch: 680  Training loss = 2.8878  Validation loss = 11.5603  \n",
      "\n",
      "Fold: 9  Epoch: 681  Training loss = 2.8876  Validation loss = 11.5602  \n",
      "\n",
      "Fold: 9  Epoch: 682  Training loss = 2.8875  Validation loss = 11.5600  \n",
      "\n",
      "Fold: 9  Epoch: 683  Training loss = 2.8873  Validation loss = 11.5598  \n",
      "\n",
      "Fold: 9  Epoch: 684  Training loss = 2.8872  Validation loss = 11.5597  \n",
      "\n",
      "Fold: 9  Epoch: 685  Training loss = 2.8871  Validation loss = 11.5595  \n",
      "\n",
      "Fold: 9  Epoch: 686  Training loss = 2.8869  Validation loss = 11.5594  \n",
      "\n",
      "Fold: 9  Epoch: 687  Training loss = 2.8868  Validation loss = 11.5593  \n",
      "\n",
      "Fold: 9  Epoch: 688  Training loss = 2.8867  Validation loss = 11.5591  \n",
      "\n",
      "Fold: 9  Epoch: 689  Training loss = 2.8866  Validation loss = 11.5590  \n",
      "\n",
      "Fold: 9  Epoch: 690  Training loss = 2.8864  Validation loss = 11.5588  \n",
      "\n",
      "Fold: 9  Epoch: 691  Training loss = 2.8863  Validation loss = 11.5587  \n",
      "\n",
      "Fold: 9  Epoch: 692  Training loss = 2.8862  Validation loss = 11.5585  \n",
      "\n",
      "Fold: 9  Epoch: 693  Training loss = 2.8860  Validation loss = 11.5583  \n",
      "\n",
      "Fold: 9  Epoch: 694  Training loss = 2.8859  Validation loss = 11.5582  \n",
      "\n",
      "Fold: 9  Epoch: 695  Training loss = 2.8858  Validation loss = 11.5581  \n",
      "\n",
      "Fold: 9  Epoch: 696  Training loss = 2.8856  Validation loss = 11.5579  \n",
      "\n",
      "Fold: 9  Epoch: 697  Training loss = 2.8855  Validation loss = 11.5578  \n",
      "\n",
      "Fold: 9  Epoch: 698  Training loss = 2.8854  Validation loss = 11.5576  \n",
      "\n",
      "Fold: 9  Epoch: 699  Training loss = 2.8853  Validation loss = 11.5575  \n",
      "\n",
      "Fold: 9  Epoch: 700  Training loss = 2.8851  Validation loss = 11.5573  \n",
      "\n",
      "Fold: 9  Epoch: 701  Training loss = 2.8850  Validation loss = 11.5571  \n",
      "\n",
      "Fold: 9  Epoch: 702  Training loss = 2.8849  Validation loss = 11.5570  \n",
      "\n",
      "Fold: 9  Epoch: 703  Training loss = 2.8848  Validation loss = 11.5569  \n",
      "\n",
      "Fold: 9  Epoch: 704  Training loss = 2.8846  Validation loss = 11.5567  \n",
      "\n",
      "Fold: 9  Epoch: 705  Training loss = 2.8845  Validation loss = 11.5566  \n",
      "\n",
      "Fold: 9  Epoch: 706  Training loss = 2.8844  Validation loss = 11.5564  \n",
      "\n",
      "Fold: 9  Epoch: 707  Training loss = 2.8842  Validation loss = 11.5563  \n",
      "\n",
      "Fold: 9  Epoch: 708  Training loss = 2.8841  Validation loss = 11.5561  \n",
      "\n",
      "Fold: 9  Epoch: 709  Training loss = 2.8839  Validation loss = 11.5559  \n",
      "\n",
      "Fold: 9  Epoch: 710  Training loss = 2.8838  Validation loss = 11.5557  \n",
      "\n",
      "Fold: 9  Epoch: 711  Training loss = 2.8837  Validation loss = 11.5556  \n",
      "\n",
      "Fold: 9  Epoch: 712  Training loss = 2.8836  Validation loss = 11.5554  \n",
      "\n",
      "Fold: 9  Epoch: 713  Training loss = 2.8835  Validation loss = 11.5553  \n",
      "\n",
      "Fold: 9  Epoch: 714  Training loss = 2.8833  Validation loss = 11.5551  \n",
      "\n",
      "Fold: 9  Epoch: 715  Training loss = 2.8832  Validation loss = 11.5550  \n",
      "\n",
      "Fold: 9  Epoch: 716  Training loss = 2.8831  Validation loss = 11.5548  \n",
      "\n",
      "Fold: 9  Epoch: 717  Training loss = 2.8830  Validation loss = 11.5546  \n",
      "\n",
      "Fold: 9  Epoch: 718  Training loss = 2.8828  Validation loss = 11.5544  \n",
      "\n",
      "Fold: 9  Epoch: 719  Training loss = 2.8827  Validation loss = 11.5543  \n",
      "\n",
      "Fold: 9  Epoch: 720  Training loss = 2.8826  Validation loss = 11.5541  \n",
      "\n",
      "Fold: 9  Epoch: 721  Training loss = 2.8825  Validation loss = 11.5540  \n",
      "\n",
      "Fold: 9  Epoch: 722  Training loss = 2.8823  Validation loss = 11.5538  \n",
      "\n",
      "Fold: 9  Epoch: 723  Training loss = 2.8822  Validation loss = 11.5536  \n",
      "\n",
      "Fold: 9  Epoch: 724  Training loss = 2.8821  Validation loss = 11.5535  \n",
      "\n",
      "Fold: 9  Epoch: 725  Training loss = 2.8820  Validation loss = 11.5534  \n",
      "\n",
      "Fold: 9  Epoch: 726  Training loss = 2.8819  Validation loss = 11.5532  \n",
      "\n",
      "Fold: 9  Epoch: 727  Training loss = 2.8817  Validation loss = 11.5529  \n",
      "\n",
      "Fold: 9  Epoch: 728  Training loss = 2.8816  Validation loss = 11.5528  \n",
      "\n",
      "Fold: 9  Epoch: 729  Training loss = 2.8814  Validation loss = 11.5526  \n",
      "\n",
      "Fold: 9  Epoch: 730  Training loss = 2.8813  Validation loss = 11.5524  \n",
      "\n",
      "Fold: 9  Epoch: 731  Training loss = 2.8812  Validation loss = 11.5523  \n",
      "\n",
      "Fold: 9  Epoch: 732  Training loss = 2.8811  Validation loss = 11.5521  \n",
      "\n",
      "Fold: 9  Epoch: 733  Training loss = 2.8810  Validation loss = 11.5519  \n",
      "\n",
      "Fold: 9  Epoch: 734  Training loss = 2.8808  Validation loss = 11.5518  \n",
      "\n",
      "Fold: 9  Epoch: 735  Training loss = 2.8807  Validation loss = 11.5516  \n",
      "\n",
      "Fold: 9  Epoch: 736  Training loss = 2.8806  Validation loss = 11.5514  \n",
      "\n",
      "Fold: 9  Epoch: 737  Training loss = 2.8805  Validation loss = 11.5513  \n",
      "\n",
      "Fold: 9  Epoch: 738  Training loss = 2.8804  Validation loss = 11.5512  \n",
      "\n",
      "Fold: 9  Epoch: 739  Training loss = 2.8803  Validation loss = 11.5510  \n",
      "\n",
      "Fold: 9  Epoch: 740  Training loss = 2.8801  Validation loss = 11.5509  \n",
      "\n",
      "Fold: 9  Epoch: 741  Training loss = 2.8800  Validation loss = 11.5507  \n",
      "\n",
      "Fold: 9  Epoch: 742  Training loss = 2.8799  Validation loss = 11.5505  \n",
      "\n",
      "Fold: 9  Epoch: 743  Training loss = 2.8797  Validation loss = 11.5503  \n",
      "\n",
      "Fold: 9  Epoch: 744  Training loss = 2.8796  Validation loss = 11.5502  \n",
      "\n",
      "Fold: 9  Epoch: 745  Training loss = 2.8795  Validation loss = 11.5500  \n",
      "\n",
      "Fold: 9  Epoch: 746  Training loss = 2.8793  Validation loss = 11.5498  \n",
      "\n",
      "Fold: 9  Epoch: 747  Training loss = 2.8792  Validation loss = 11.5497  \n",
      "\n",
      "Fold: 9  Epoch: 748  Training loss = 2.8791  Validation loss = 11.5495  \n",
      "\n",
      "Fold: 9  Epoch: 749  Training loss = 2.8790  Validation loss = 11.5493  \n",
      "\n",
      "Fold: 9  Epoch: 750  Training loss = 2.8789  Validation loss = 11.5491  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 750  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 4.0046  Validation loss = 6.4304  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 4.0044  Validation loss = 6.4294  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 4.0042  Validation loss = 6.4288  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 4.0040  Validation loss = 6.4284  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 4.0039  Validation loss = 6.4281  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 4.0037  Validation loss = 6.4278  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 4.0036  Validation loss = 6.4276  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 4.0035  Validation loss = 6.4274  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 4.0034  Validation loss = 6.4272  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 4.0032  Validation loss = 6.4270  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 4.0031  Validation loss = 6.4268  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 4.0030  Validation loss = 6.4266  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 4.0028  Validation loss = 6.4264  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 4.0027  Validation loss = 6.4262  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 4.0025  Validation loss = 6.4259  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 4.0024  Validation loss = 6.4256  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 4.0022  Validation loss = 6.4254  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 4.0020  Validation loss = 6.4251  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 4.0019  Validation loss = 6.4249  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 4.0017  Validation loss = 6.4247  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 4.0016  Validation loss = 6.4244  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 4.0014  Validation loss = 6.4242  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 4.0013  Validation loss = 6.4240  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 4.0012  Validation loss = 6.4238  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 4.0010  Validation loss = 6.4235  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 4.0009  Validation loss = 6.4233  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 4.0007  Validation loss = 6.4231  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 4.0006  Validation loss = 6.4229  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 4.0004  Validation loss = 6.4226  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 4.0003  Validation loss = 6.4225  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 4.0002  Validation loss = 6.4223  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 4.0000  Validation loss = 6.4221  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 3.9999  Validation loss = 6.4218  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 3.9997  Validation loss = 6.4216  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 3.9996  Validation loss = 6.4215  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 3.9995  Validation loss = 6.4213  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 3.9994  Validation loss = 6.4211  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 3.9992  Validation loss = 6.4209  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 3.9991  Validation loss = 6.4206  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 3.9990  Validation loss = 6.4205  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 3.9988  Validation loss = 6.4202  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 3.9987  Validation loss = 6.4201  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 3.9986  Validation loss = 6.4198  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 3.9984  Validation loss = 6.4196  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 3.9983  Validation loss = 6.4194  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 3.9982  Validation loss = 6.4193  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 3.9980  Validation loss = 6.4191  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 3.9979  Validation loss = 6.4189  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 3.9978  Validation loss = 6.4187  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 3.9977  Validation loss = 6.4185  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 3.9975  Validation loss = 6.4183  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 3.9974  Validation loss = 6.4180  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 3.9972  Validation loss = 6.4178  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 3.9971  Validation loss = 6.4176  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 3.9970  Validation loss = 6.4174  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 3.9968  Validation loss = 6.4172  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 3.9967  Validation loss = 6.4170  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 3.9965  Validation loss = 6.4168  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 3.9964  Validation loss = 6.4166  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 3.9963  Validation loss = 6.4163  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 3.9961  Validation loss = 6.4161  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 3.9960  Validation loss = 6.4159  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 3.9959  Validation loss = 6.4158  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 3.9958  Validation loss = 6.4156  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 3.9956  Validation loss = 6.4154  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 3.9955  Validation loss = 6.4152  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 3.9954  Validation loss = 6.4150  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 3.9952  Validation loss = 6.4148  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 3.9951  Validation loss = 6.4146  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 3.9950  Validation loss = 6.4145  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 3.9949  Validation loss = 6.4143  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 3.9947  Validation loss = 6.4141  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 3.9946  Validation loss = 6.4138  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 3.9944  Validation loss = 6.4136  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 3.9943  Validation loss = 6.4134  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 3.9942  Validation loss = 6.4132  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 3.9940  Validation loss = 6.4130  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 3.9939  Validation loss = 6.4128  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 3.9937  Validation loss = 6.4126  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 3.9936  Validation loss = 6.4124  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 3.9935  Validation loss = 6.4122  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 3.9933  Validation loss = 6.4120  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 3.9932  Validation loss = 6.4118  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 3.9930  Validation loss = 6.4115  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 3.9929  Validation loss = 6.4113  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 3.9928  Validation loss = 6.4111  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 3.9926  Validation loss = 6.4109  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 3.9925  Validation loss = 6.4107  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 3.9924  Validation loss = 6.4106  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 3.9923  Validation loss = 6.4104  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 3.9921  Validation loss = 6.4102  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 3.9920  Validation loss = 6.4100  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 3.9919  Validation loss = 6.4098  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 3.9917  Validation loss = 6.4096  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 3.9916  Validation loss = 6.4094  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 3.9915  Validation loss = 6.4093  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 3.9914  Validation loss = 6.4091  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 3.9913  Validation loss = 6.4089  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 3.9911  Validation loss = 6.4087  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 3.9910  Validation loss = 6.4085  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 3.9909  Validation loss = 6.4083  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 3.9908  Validation loss = 6.4081  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 3.9906  Validation loss = 6.4080  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 3.9905  Validation loss = 6.4078  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 3.9904  Validation loss = 6.4076  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 3.9903  Validation loss = 6.4074  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 3.9901  Validation loss = 6.4072  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 3.9900  Validation loss = 6.4070  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 3.9899  Validation loss = 6.4068  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 3.9898  Validation loss = 6.4066  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 3.9896  Validation loss = 6.4064  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 3.9895  Validation loss = 6.4063  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 3.9894  Validation loss = 6.4061  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 3.9893  Validation loss = 6.4059  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 3.9891  Validation loss = 6.4056  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 3.9889  Validation loss = 6.4054  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 3.9888  Validation loss = 6.4053  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 3.9887  Validation loss = 6.4050  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 3.9886  Validation loss = 6.4049  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 3.9885  Validation loss = 6.4047  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 3.9883  Validation loss = 6.4045  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 3.9882  Validation loss = 6.4043  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 3.9881  Validation loss = 6.4040  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 3.9879  Validation loss = 6.4038  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 3.9878  Validation loss = 6.4036  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 3.9876  Validation loss = 6.4034  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 3.9874  Validation loss = 6.4031  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 3.9873  Validation loss = 6.4029  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 3.9872  Validation loss = 6.4027  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 3.9870  Validation loss = 6.4025  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 3.9869  Validation loss = 6.4023  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 3.9867  Validation loss = 6.4021  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 3.9866  Validation loss = 6.4019  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 3.9865  Validation loss = 6.4018  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 3.9864  Validation loss = 6.4015  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 3.9863  Validation loss = 6.4014  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 3.9861  Validation loss = 6.4012  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 3.9860  Validation loss = 6.4010  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 3.9859  Validation loss = 6.4008  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 3.9857  Validation loss = 6.4006  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 3.9856  Validation loss = 6.4005  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 3.9855  Validation loss = 6.4003  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 3.9854  Validation loss = 6.4001  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 3.9852  Validation loss = 6.3999  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 3.9851  Validation loss = 6.3997  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 3.9850  Validation loss = 6.3995  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 3.9848  Validation loss = 6.3993  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 3.9847  Validation loss = 6.3990  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 3.9846  Validation loss = 6.3988  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 3.9844  Validation loss = 6.3987  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 3.9843  Validation loss = 6.3984  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 3.9842  Validation loss = 6.3982  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 3.9841  Validation loss = 6.3981  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 3.9839  Validation loss = 6.3979  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 3.9838  Validation loss = 6.3977  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 3.9836  Validation loss = 6.3974  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 3.9835  Validation loss = 6.3973  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 3.9834  Validation loss = 6.3971  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 3.9833  Validation loss = 6.3969  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 3.9831  Validation loss = 6.3966  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 3.9830  Validation loss = 6.3965  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 3.9829  Validation loss = 6.3963  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 3.9828  Validation loss = 6.3962  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 3.9826  Validation loss = 6.3960  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 3.9825  Validation loss = 6.3958  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 3.9824  Validation loss = 6.3956  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 3.9822  Validation loss = 6.3953  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 3.9821  Validation loss = 6.3951  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 3.9820  Validation loss = 6.3950  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 3.9819  Validation loss = 6.3948  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 3.9817  Validation loss = 6.3945  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 3.9816  Validation loss = 6.3944  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 3.9815  Validation loss = 6.3942  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 3.9814  Validation loss = 6.3940  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 3.9812  Validation loss = 6.3938  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 3.9811  Validation loss = 6.3936  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 3.9810  Validation loss = 6.3934  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 3.9808  Validation loss = 6.3932  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 3.9807  Validation loss = 6.3930  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 3.9805  Validation loss = 6.3927  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 3.9804  Validation loss = 6.3925  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 3.9802  Validation loss = 6.3923  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 3.9801  Validation loss = 6.3921  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 3.9800  Validation loss = 6.3919  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 3.9798  Validation loss = 6.3916  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 3.9797  Validation loss = 6.3915  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 3.9796  Validation loss = 6.3913  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 3.9794  Validation loss = 6.3911  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 3.9793  Validation loss = 6.3909  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 3.9792  Validation loss = 6.3907  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 3.9790  Validation loss = 6.3905  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 3.9789  Validation loss = 6.3902  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 3.9788  Validation loss = 6.3901  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 3.9786  Validation loss = 6.3899  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 3.9785  Validation loss = 6.3897  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 3.9784  Validation loss = 6.3895  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 3.9783  Validation loss = 6.3893  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 3.9781  Validation loss = 6.3890  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 3.9780  Validation loss = 6.3889  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 3.9779  Validation loss = 6.3887  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 3.9777  Validation loss = 6.3885  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 3.9776  Validation loss = 6.3882  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 3.9774  Validation loss = 6.3880  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 3.9773  Validation loss = 6.3878  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 3.9772  Validation loss = 6.3876  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 3.9770  Validation loss = 6.3874  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 3.9769  Validation loss = 6.3872  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 3.9767  Validation loss = 6.3870  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 3.9766  Validation loss = 6.3868  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 3.9765  Validation loss = 6.3866  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 3.9763  Validation loss = 6.3864  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 3.9763  Validation loss = 6.3863  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 3.9761  Validation loss = 6.3861  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 3.9760  Validation loss = 6.3859  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 3.9759  Validation loss = 6.3858  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 3.9758  Validation loss = 6.3856  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 3.9756  Validation loss = 6.3853  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 3.9755  Validation loss = 6.3851  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 3.9753  Validation loss = 6.3849  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 3.9752  Validation loss = 6.3847  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 3.9750  Validation loss = 6.3844  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 3.9749  Validation loss = 6.3843  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 3.9748  Validation loss = 6.3841  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 3.9747  Validation loss = 6.3839  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 3.9746  Validation loss = 6.3837  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 3.9744  Validation loss = 6.3835  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 3.9743  Validation loss = 6.3833  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 3.9741  Validation loss = 6.3830  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 3.9740  Validation loss = 6.3828  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 3.9739  Validation loss = 6.3826  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 3.9737  Validation loss = 6.3825  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 3.9735  Validation loss = 6.3821  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 3.9734  Validation loss = 6.3820  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 3.9733  Validation loss = 6.3818  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 3.9732  Validation loss = 6.3816  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 3.9730  Validation loss = 6.3814  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 3.9729  Validation loss = 6.3811  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 3.9728  Validation loss = 6.3810  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 3.9727  Validation loss = 6.3808  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 3.9725  Validation loss = 6.3806  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 3.9724  Validation loss = 6.3804  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 3.9722  Validation loss = 6.3802  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 3.9721  Validation loss = 6.3800  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 3.9720  Validation loss = 6.3798  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 3.9718  Validation loss = 6.3796  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 3.9717  Validation loss = 6.3794  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 3.9716  Validation loss = 6.3792  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 3.9714  Validation loss = 6.3789  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 3.9713  Validation loss = 6.3787  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 3.9712  Validation loss = 6.3785  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 3.9711  Validation loss = 6.3784  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 3.9709  Validation loss = 6.3782  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 3.9708  Validation loss = 6.3780  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 3.9707  Validation loss = 6.3778  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 3.9706  Validation loss = 6.3776  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 3.9704  Validation loss = 6.3774  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 3.9703  Validation loss = 6.3773  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 3.9702  Validation loss = 6.3770  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 3.9701  Validation loss = 6.3769  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 3.9699  Validation loss = 6.3767  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 3.9698  Validation loss = 6.3765  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 3.9697  Validation loss = 6.3763  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 3.9695  Validation loss = 6.3760  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 3.9694  Validation loss = 6.3759  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 3.9693  Validation loss = 6.3757  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 3.9692  Validation loss = 6.3755  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 3.9690  Validation loss = 6.3753  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 3.9689  Validation loss = 6.3750  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 3.9688  Validation loss = 6.3749  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 3.9686  Validation loss = 6.3747  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 3.9685  Validation loss = 6.3745  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 3.9684  Validation loss = 6.3743  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 3.9682  Validation loss = 6.3741  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 3.9681  Validation loss = 6.3739  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 3.9680  Validation loss = 6.3737  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 3.9679  Validation loss = 6.3735  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 3.9677  Validation loss = 6.3733  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 3.9676  Validation loss = 6.3731  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 3.9675  Validation loss = 6.3729  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 3.9673  Validation loss = 6.3727  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 3.9672  Validation loss = 6.3725  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 3.9671  Validation loss = 6.3723  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 3.9669  Validation loss = 6.3721  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 3.9668  Validation loss = 6.3719  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 3.9667  Validation loss = 6.3717  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 3.9665  Validation loss = 6.3715  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 3.9664  Validation loss = 6.3713  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 3.9663  Validation loss = 6.3711  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 3.9661  Validation loss = 6.3709  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 3.9660  Validation loss = 6.3707  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 3.9659  Validation loss = 6.3705  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 3.9657  Validation loss = 6.3703  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 3.9656  Validation loss = 6.3701  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 3.9655  Validation loss = 6.3699  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 3.9653  Validation loss = 6.3697  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 3.9652  Validation loss = 6.3695  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 3.9651  Validation loss = 6.3692  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 3.9649  Validation loss = 6.3690  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 3.9648  Validation loss = 6.3689  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 3.9647  Validation loss = 6.3687  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 3.9645  Validation loss = 6.3684  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 3.9644  Validation loss = 6.3683  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 3.9643  Validation loss = 6.3681  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 3.9642  Validation loss = 6.3679  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 3.9640  Validation loss = 6.3677  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 3.9639  Validation loss = 6.3675  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 3.9638  Validation loss = 6.3673  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 3.9636  Validation loss = 6.3671  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 3.9635  Validation loss = 6.3669  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 3.9634  Validation loss = 6.3667  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 3.9633  Validation loss = 6.3665  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 3.9631  Validation loss = 6.3663  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 3.9630  Validation loss = 6.3662  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 3.9629  Validation loss = 6.3660  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 3.9627  Validation loss = 6.3658  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 3.9626  Validation loss = 6.3655  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 3.9624  Validation loss = 6.3653  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 3.9623  Validation loss = 6.3651  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 3.9622  Validation loss = 6.3649  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 3.9621  Validation loss = 6.3647  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 3.9619  Validation loss = 6.3645  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 3.9618  Validation loss = 6.3643  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 3.9616  Validation loss = 6.3640  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 3.9615  Validation loss = 6.3638  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 3.9614  Validation loss = 6.3637  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 3.9613  Validation loss = 6.3635  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 3.9611  Validation loss = 6.3633  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 3.9610  Validation loss = 6.3631  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 3.9609  Validation loss = 6.3629  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 3.9608  Validation loss = 6.3627  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 3.9606  Validation loss = 6.3625  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 3.9605  Validation loss = 6.3623  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 3.9604  Validation loss = 6.3622  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 3.9603  Validation loss = 6.3620  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 3.9602  Validation loss = 6.3618  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 3.9601  Validation loss = 6.3617  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 3.9599  Validation loss = 6.3614  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 3.9598  Validation loss = 6.3612  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 3.9597  Validation loss = 6.3611  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 3.9595  Validation loss = 6.3609  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 3.9594  Validation loss = 6.3607  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 3.9593  Validation loss = 6.3605  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 3.9591  Validation loss = 6.3603  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 3.9590  Validation loss = 6.3600  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 3.9588  Validation loss = 6.3598  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 3.9586  Validation loss = 6.3595  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 3.9585  Validation loss = 6.3593  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 3.9583  Validation loss = 6.3591  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 3.9582  Validation loss = 6.3588  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 3.9581  Validation loss = 6.3587  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 3.9579  Validation loss = 6.3585  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 3.9578  Validation loss = 6.3582  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 3.9576  Validation loss = 6.3580  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 3.9575  Validation loss = 6.3578  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 3.9574  Validation loss = 6.3577  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 3.9573  Validation loss = 6.3575  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 3.9572  Validation loss = 6.3574  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 3.9571  Validation loss = 6.3572  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 3.9570  Validation loss = 6.3571  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 3.9569  Validation loss = 6.3568  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 3.9567  Validation loss = 6.3566  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 3.9566  Validation loss = 6.3564  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 3.9564  Validation loss = 6.3562  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 3.9563  Validation loss = 6.3560  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 3.9562  Validation loss = 6.3558  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 3.9561  Validation loss = 6.3556  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 3.9559  Validation loss = 6.3554  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 3.9558  Validation loss = 6.3552  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 3.9557  Validation loss = 6.3550  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 3.9556  Validation loss = 6.3549  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 3.9554  Validation loss = 6.3547  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 3.9553  Validation loss = 6.3544  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 3.9551  Validation loss = 6.3542  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 3.9550  Validation loss = 6.3540  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 3.9549  Validation loss = 6.3538  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 3.9547  Validation loss = 6.3536  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 3.9546  Validation loss = 6.3535  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 3.9544  Validation loss = 6.3532  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 3.9543  Validation loss = 6.3530  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 3.9542  Validation loss = 6.3528  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 3.9541  Validation loss = 6.3526  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 3.9540  Validation loss = 6.3525  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 3.9538  Validation loss = 6.3523  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 3.9537  Validation loss = 6.3520  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 3.9536  Validation loss = 6.3518  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 3.9534  Validation loss = 6.3516  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 3.9533  Validation loss = 6.3514  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 3.9531  Validation loss = 6.3512  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 3.9530  Validation loss = 6.3510  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 3.9529  Validation loss = 6.3509  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 3.9528  Validation loss = 6.3507  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 3.9527  Validation loss = 6.3505  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 3.9526  Validation loss = 6.3503  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 3.9524  Validation loss = 6.3501  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 3.9523  Validation loss = 6.3499  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 3.9522  Validation loss = 6.3497  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 3.9520  Validation loss = 6.3495  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 3.9519  Validation loss = 6.3493  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 3.9518  Validation loss = 6.3492  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 3.9517  Validation loss = 6.3490  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 3.9515  Validation loss = 6.3488  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 3.9514  Validation loss = 6.3486  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 3.9513  Validation loss = 6.3484  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 3.9511  Validation loss = 6.3482  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 3.9510  Validation loss = 6.3480  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 3.9508  Validation loss = 6.3476  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 3.9507  Validation loss = 6.3475  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 3.9506  Validation loss = 6.3473  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 3.9504  Validation loss = 6.3471  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 3.9503  Validation loss = 6.3468  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 3.9501  Validation loss = 6.3466  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 3.9500  Validation loss = 6.3465  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 3.9499  Validation loss = 6.3463  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 3.9498  Validation loss = 6.3461  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 3.9497  Validation loss = 6.3459  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 3.9496  Validation loss = 6.3458  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 3.9494  Validation loss = 6.3456  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 3.9493  Validation loss = 6.3454  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 3.9492  Validation loss = 6.3452  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 3.9490  Validation loss = 6.3450  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 3.9489  Validation loss = 6.3447  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 3.9487  Validation loss = 6.3445  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 3.9486  Validation loss = 6.3442  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 3.9484  Validation loss = 6.3440  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 3.9483  Validation loss = 6.3438  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 3.9481  Validation loss = 6.3435  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 3.9480  Validation loss = 6.3433  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 3.9479  Validation loss = 6.3431  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 3.9477  Validation loss = 6.3430  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 3.9476  Validation loss = 6.3428  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 3.9475  Validation loss = 6.3425  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 3.9473  Validation loss = 6.3423  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 3.9472  Validation loss = 6.3421  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 3.9471  Validation loss = 6.3420  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 3.9469  Validation loss = 6.3417  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 3.9468  Validation loss = 6.3416  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 3.9467  Validation loss = 6.3414  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 3.9466  Validation loss = 6.3412  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 3.9464  Validation loss = 6.3410  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 3.9463  Validation loss = 6.3407  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 3.9461  Validation loss = 6.3405  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 3.9460  Validation loss = 6.3403  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 3.9459  Validation loss = 6.3401  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 3.9458  Validation loss = 6.3399  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 3.9456  Validation loss = 6.3398  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 3.9455  Validation loss = 6.3396  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 3.9454  Validation loss = 6.3394  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 3.9452  Validation loss = 6.3392  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 3.9451  Validation loss = 6.3389  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 3.9449  Validation loss = 6.3387  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 3.9448  Validation loss = 6.3385  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 3.9447  Validation loss = 6.3383  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 3.9445  Validation loss = 6.3381  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 3.9444  Validation loss = 6.3379  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 3.9443  Validation loss = 6.3377  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 3.9441  Validation loss = 6.3375  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 3.9440  Validation loss = 6.3373  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 3.9438  Validation loss = 6.3370  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 3.9437  Validation loss = 6.3368  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 3.9436  Validation loss = 6.3366  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 3.9434  Validation loss = 6.3364  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 3.9433  Validation loss = 6.3362  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 3.9432  Validation loss = 6.3360  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 3.9430  Validation loss = 6.3357  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 3.9429  Validation loss = 6.3355  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 3.9427  Validation loss = 6.3353  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 3.9426  Validation loss = 6.3351  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 3.9425  Validation loss = 6.3349  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 3.9424  Validation loss = 6.3348  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 3.9423  Validation loss = 6.3346  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 3.9421  Validation loss = 6.3344  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 3.9419  Validation loss = 6.3341  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 3.9418  Validation loss = 6.3339  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 3.9417  Validation loss = 6.3337  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 3.9415  Validation loss = 6.3335  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 3.9414  Validation loss = 6.3332  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 3.9412  Validation loss = 6.3330  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 3.9412  Validation loss = 6.3329  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 3.9410  Validation loss = 6.3327  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 3.9409  Validation loss = 6.3325  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 3.9408  Validation loss = 6.3323  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 3.9406  Validation loss = 6.3320  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 3.9404  Validation loss = 6.3318  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 3.9403  Validation loss = 6.3316  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 3.9401  Validation loss = 6.3313  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 3.9400  Validation loss = 6.3311  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 3.9399  Validation loss = 6.3310  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 3.9398  Validation loss = 6.3308  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 3.9397  Validation loss = 6.3306  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 3.9396  Validation loss = 6.3304  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 3.9394  Validation loss = 6.3302  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 3.9393  Validation loss = 6.3300  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 3.9391  Validation loss = 6.3298  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 3.9390  Validation loss = 6.3296  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 3.9389  Validation loss = 6.3294  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 3.9387  Validation loss = 6.3292  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 3.9386  Validation loss = 6.3290  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 3.9384  Validation loss = 6.3288  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 3.9383  Validation loss = 6.3286  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 3.9382  Validation loss = 6.3284  \n",
      "\n",
      "Fold: 10  Epoch: 501  Training loss = 3.9380  Validation loss = 6.3281  \n",
      "\n",
      "Fold: 10  Epoch: 502  Training loss = 3.9379  Validation loss = 6.3279  \n",
      "\n",
      "Fold: 10  Epoch: 503  Training loss = 3.9378  Validation loss = 6.3278  \n",
      "\n",
      "Fold: 10  Epoch: 504  Training loss = 3.9376  Validation loss = 6.3275  \n",
      "\n",
      "Fold: 10  Epoch: 505  Training loss = 3.9375  Validation loss = 6.3273  \n",
      "\n",
      "Fold: 10  Epoch: 506  Training loss = 3.9374  Validation loss = 6.3272  \n",
      "\n",
      "Fold: 10  Epoch: 507  Training loss = 3.9372  Validation loss = 6.3269  \n",
      "\n",
      "Fold: 10  Epoch: 508  Training loss = 3.9371  Validation loss = 6.3267  \n",
      "\n",
      "Fold: 10  Epoch: 509  Training loss = 3.9370  Validation loss = 6.3265  \n",
      "\n",
      "Fold: 10  Epoch: 510  Training loss = 3.9368  Validation loss = 6.3263  \n",
      "\n",
      "Fold: 10  Epoch: 511  Training loss = 3.9367  Validation loss = 6.3260  \n",
      "\n",
      "Fold: 10  Epoch: 512  Training loss = 3.9366  Validation loss = 6.3259  \n",
      "\n",
      "Fold: 10  Epoch: 513  Training loss = 3.9365  Validation loss = 6.3257  \n",
      "\n",
      "Fold: 10  Epoch: 514  Training loss = 3.9363  Validation loss = 6.3255  \n",
      "\n",
      "Fold: 10  Epoch: 515  Training loss = 3.9362  Validation loss = 6.3254  \n",
      "\n",
      "Fold: 10  Epoch: 516  Training loss = 3.9361  Validation loss = 6.3252  \n",
      "\n",
      "Fold: 10  Epoch: 517  Training loss = 3.9360  Validation loss = 6.3250  \n",
      "\n",
      "Fold: 10  Epoch: 518  Training loss = 3.9358  Validation loss = 6.3248  \n",
      "\n",
      "Fold: 10  Epoch: 519  Training loss = 3.9357  Validation loss = 6.3246  \n",
      "\n",
      "Fold: 10  Epoch: 520  Training loss = 3.9356  Validation loss = 6.3244  \n",
      "\n",
      "Fold: 10  Epoch: 521  Training loss = 3.9354  Validation loss = 6.3242  \n",
      "\n",
      "Fold: 10  Epoch: 522  Training loss = 3.9353  Validation loss = 6.3240  \n",
      "\n",
      "Fold: 10  Epoch: 523  Training loss = 3.9352  Validation loss = 6.3238  \n",
      "\n",
      "Fold: 10  Epoch: 524  Training loss = 3.9351  Validation loss = 6.3236  \n",
      "\n",
      "Fold: 10  Epoch: 525  Training loss = 3.9349  Validation loss = 6.3234  \n",
      "\n",
      "Fold: 10  Epoch: 526  Training loss = 3.9348  Validation loss = 6.3232  \n",
      "\n",
      "Fold: 10  Epoch: 527  Training loss = 3.9346  Validation loss = 6.3229  \n",
      "\n",
      "Fold: 10  Epoch: 528  Training loss = 3.9344  Validation loss = 6.3227  \n",
      "\n",
      "Fold: 10  Epoch: 529  Training loss = 3.9343  Validation loss = 6.3224  \n",
      "\n",
      "Fold: 10  Epoch: 530  Training loss = 3.9342  Validation loss = 6.3222  \n",
      "\n",
      "Fold: 10  Epoch: 531  Training loss = 3.9340  Validation loss = 6.3220  \n",
      "\n",
      "Fold: 10  Epoch: 532  Training loss = 3.9338  Validation loss = 6.3217  \n",
      "\n",
      "Fold: 10  Epoch: 533  Training loss = 3.9337  Validation loss = 6.3215  \n",
      "\n",
      "Fold: 10  Epoch: 534  Training loss = 3.9336  Validation loss = 6.3213  \n",
      "\n",
      "Fold: 10  Epoch: 535  Training loss = 3.9335  Validation loss = 6.3212  \n",
      "\n",
      "Fold: 10  Epoch: 536  Training loss = 3.9333  Validation loss = 6.3209  \n",
      "\n",
      "Fold: 10  Epoch: 537  Training loss = 3.9331  Validation loss = 6.3206  \n",
      "\n",
      "Fold: 10  Epoch: 538  Training loss = 3.9329  Validation loss = 6.3203  \n",
      "\n",
      "Fold: 10  Epoch: 539  Training loss = 3.9328  Validation loss = 6.3202  \n",
      "\n",
      "Fold: 10  Epoch: 540  Training loss = 3.9327  Validation loss = 6.3200  \n",
      "\n",
      "Fold: 10  Epoch: 541  Training loss = 3.9325  Validation loss = 6.3197  \n",
      "\n",
      "Fold: 10  Epoch: 542  Training loss = 3.9324  Validation loss = 6.3196  \n",
      "\n",
      "Fold: 10  Epoch: 543  Training loss = 3.9323  Validation loss = 6.3194  \n",
      "\n",
      "Fold: 10  Epoch: 544  Training loss = 3.9321  Validation loss = 6.3191  \n",
      "\n",
      "Fold: 10  Epoch: 545  Training loss = 3.9320  Validation loss = 6.3189  \n",
      "\n",
      "Fold: 10  Epoch: 546  Training loss = 3.9318  Validation loss = 6.3187  \n",
      "\n",
      "Fold: 10  Epoch: 547  Training loss = 3.9317  Validation loss = 6.3185  \n",
      "\n",
      "Fold: 10  Epoch: 548  Training loss = 3.9316  Validation loss = 6.3182  \n",
      "\n",
      "Fold: 10  Epoch: 549  Training loss = 3.9314  Validation loss = 6.3180  \n",
      "\n",
      "Fold: 10  Epoch: 550  Training loss = 3.9313  Validation loss = 6.3178  \n",
      "\n",
      "Fold: 10  Epoch: 551  Training loss = 3.9311  Validation loss = 6.3175  \n",
      "\n",
      "Fold: 10  Epoch: 552  Training loss = 3.9310  Validation loss = 6.3174  \n",
      "\n",
      "Fold: 10  Epoch: 553  Training loss = 3.9309  Validation loss = 6.3172  \n",
      "\n",
      "Fold: 10  Epoch: 554  Training loss = 3.9307  Validation loss = 6.3170  \n",
      "\n",
      "Fold: 10  Epoch: 555  Training loss = 3.9306  Validation loss = 6.3168  \n",
      "\n",
      "Fold: 10  Epoch: 556  Training loss = 3.9305  Validation loss = 6.3166  \n",
      "\n",
      "Fold: 10  Epoch: 557  Training loss = 3.9304  Validation loss = 6.3165  \n",
      "\n",
      "Fold: 10  Epoch: 558  Training loss = 3.9303  Validation loss = 6.3163  \n",
      "\n",
      "Fold: 10  Epoch: 559  Training loss = 3.9301  Validation loss = 6.3161  \n",
      "\n",
      "Fold: 10  Epoch: 560  Training loss = 3.9300  Validation loss = 6.3159  \n",
      "\n",
      "Fold: 10  Epoch: 561  Training loss = 3.9299  Validation loss = 6.3157  \n",
      "\n",
      "Fold: 10  Epoch: 562  Training loss = 3.9297  Validation loss = 6.3155  \n",
      "\n",
      "Fold: 10  Epoch: 563  Training loss = 3.9296  Validation loss = 6.3153  \n",
      "\n",
      "Fold: 10  Epoch: 564  Training loss = 3.9295  Validation loss = 6.3151  \n",
      "\n",
      "Fold: 10  Epoch: 565  Training loss = 3.9293  Validation loss = 6.3149  \n",
      "\n",
      "Fold: 10  Epoch: 566  Training loss = 3.9292  Validation loss = 6.3147  \n",
      "\n",
      "Fold: 10  Epoch: 567  Training loss = 3.9291  Validation loss = 6.3145  \n",
      "\n",
      "Fold: 10  Epoch: 568  Training loss = 3.9289  Validation loss = 6.3143  \n",
      "\n",
      "Fold: 10  Epoch: 569  Training loss = 3.9288  Validation loss = 6.3141  \n",
      "\n",
      "Fold: 10  Epoch: 570  Training loss = 3.9287  Validation loss = 6.3139  \n",
      "\n",
      "Fold: 10  Epoch: 571  Training loss = 3.9286  Validation loss = 6.3138  \n",
      "\n",
      "Fold: 10  Epoch: 572  Training loss = 3.9285  Validation loss = 6.3136  \n",
      "\n",
      "Fold: 10  Epoch: 573  Training loss = 3.9284  Validation loss = 6.3134  \n",
      "\n",
      "Fold: 10  Epoch: 574  Training loss = 3.9282  Validation loss = 6.3132  \n",
      "\n",
      "Fold: 10  Epoch: 575  Training loss = 3.9281  Validation loss = 6.3130  \n",
      "\n",
      "Fold: 10  Epoch: 576  Training loss = 3.9280  Validation loss = 6.3129  \n",
      "\n",
      "Fold: 10  Epoch: 577  Training loss = 3.9279  Validation loss = 6.3126  \n",
      "\n",
      "Fold: 10  Epoch: 578  Training loss = 3.9278  Validation loss = 6.3125  \n",
      "\n",
      "Fold: 10  Epoch: 579  Training loss = 3.9276  Validation loss = 6.3123  \n",
      "\n",
      "Fold: 10  Epoch: 580  Training loss = 3.9275  Validation loss = 6.3121  \n",
      "\n",
      "Fold: 10  Epoch: 581  Training loss = 3.9273  Validation loss = 6.3119  \n",
      "\n",
      "Fold: 10  Epoch: 582  Training loss = 3.9272  Validation loss = 6.3116  \n",
      "\n",
      "Fold: 10  Epoch: 583  Training loss = 3.9271  Validation loss = 6.3114  \n",
      "\n",
      "Fold: 10  Epoch: 584  Training loss = 3.9269  Validation loss = 6.3112  \n",
      "\n",
      "Fold: 10  Epoch: 585  Training loss = 3.9268  Validation loss = 6.3110  \n",
      "\n",
      "Fold: 10  Epoch: 586  Training loss = 3.9266  Validation loss = 6.3107  \n",
      "\n",
      "Fold: 10  Epoch: 587  Training loss = 3.9265  Validation loss = 6.3105  \n",
      "\n",
      "Fold: 10  Epoch: 588  Training loss = 3.9264  Validation loss = 6.3103  \n",
      "\n",
      "Fold: 10  Epoch: 589  Training loss = 3.9263  Validation loss = 6.3102  \n",
      "\n",
      "Fold: 10  Epoch: 590  Training loss = 3.9261  Validation loss = 6.3100  \n",
      "\n",
      "Fold: 10  Epoch: 591  Training loss = 3.9260  Validation loss = 6.3098  \n",
      "\n",
      "Fold: 10  Epoch: 592  Training loss = 3.9259  Validation loss = 6.3096  \n",
      "\n",
      "Fold: 10  Epoch: 593  Training loss = 3.9258  Validation loss = 6.3094  \n",
      "\n",
      "Fold: 10  Epoch: 594  Training loss = 3.9257  Validation loss = 6.3093  \n",
      "\n",
      "Fold: 10  Epoch: 595  Training loss = 3.9255  Validation loss = 6.3091  \n",
      "\n",
      "Fold: 10  Epoch: 596  Training loss = 3.9254  Validation loss = 6.3089  \n",
      "\n",
      "Fold: 10  Epoch: 597  Training loss = 3.9253  Validation loss = 6.3087  \n",
      "\n",
      "Fold: 10  Epoch: 598  Training loss = 3.9251  Validation loss = 6.3085  \n",
      "\n",
      "Fold: 10  Epoch: 599  Training loss = 3.9250  Validation loss = 6.3083  \n",
      "\n",
      "Fold: 10  Epoch: 600  Training loss = 3.9249  Validation loss = 6.3081  \n",
      "\n",
      "Fold: 10  Epoch: 601  Training loss = 3.9248  Validation loss = 6.3079  \n",
      "\n",
      "Fold: 10  Epoch: 602  Training loss = 3.9246  Validation loss = 6.3077  \n",
      "\n",
      "Fold: 10  Epoch: 603  Training loss = 3.9245  Validation loss = 6.3075  \n",
      "\n",
      "Fold: 10  Epoch: 604  Training loss = 3.9244  Validation loss = 6.3073  \n",
      "\n",
      "Fold: 10  Epoch: 605  Training loss = 3.9242  Validation loss = 6.3071  \n",
      "\n",
      "Fold: 10  Epoch: 606  Training loss = 3.9241  Validation loss = 6.3069  \n",
      "\n",
      "Fold: 10  Epoch: 607  Training loss = 3.9240  Validation loss = 6.3068  \n",
      "\n",
      "Fold: 10  Epoch: 608  Training loss = 3.9239  Validation loss = 6.3066  \n",
      "\n",
      "Fold: 10  Epoch: 609  Training loss = 3.9237  Validation loss = 6.3064  \n",
      "\n",
      "Fold: 10  Epoch: 610  Training loss = 3.9236  Validation loss = 6.3062  \n",
      "\n",
      "Fold: 10  Epoch: 611  Training loss = 3.9235  Validation loss = 6.3060  \n",
      "\n",
      "Fold: 10  Epoch: 612  Training loss = 3.9233  Validation loss = 6.3058  \n",
      "\n",
      "Fold: 10  Epoch: 613  Training loss = 3.9232  Validation loss = 6.3055  \n",
      "\n",
      "Fold: 10  Epoch: 614  Training loss = 3.9230  Validation loss = 6.3053  \n",
      "\n",
      "Fold: 10  Epoch: 615  Training loss = 3.9229  Validation loss = 6.3051  \n",
      "\n",
      "Fold: 10  Epoch: 616  Training loss = 3.9228  Validation loss = 6.3050  \n",
      "\n",
      "Fold: 10  Epoch: 617  Training loss = 3.9226  Validation loss = 6.3047  \n",
      "\n",
      "Fold: 10  Epoch: 618  Training loss = 3.9225  Validation loss = 6.3045  \n",
      "\n",
      "Fold: 10  Epoch: 619  Training loss = 3.9224  Validation loss = 6.3043  \n",
      "\n",
      "Fold: 10  Epoch: 620  Training loss = 3.9222  Validation loss = 6.3041  \n",
      "\n",
      "Fold: 10  Epoch: 621  Training loss = 3.9221  Validation loss = 6.3039  \n",
      "\n",
      "Fold: 10  Epoch: 622  Training loss = 3.9220  Validation loss = 6.3037  \n",
      "\n",
      "Fold: 10  Epoch: 623  Training loss = 3.9218  Validation loss = 6.3035  \n",
      "\n",
      "Fold: 10  Epoch: 624  Training loss = 3.9217  Validation loss = 6.3033  \n",
      "\n",
      "Fold: 10  Epoch: 625  Training loss = 3.9215  Validation loss = 6.3031  \n",
      "\n",
      "Fold: 10  Epoch: 626  Training loss = 3.9214  Validation loss = 6.3028  \n",
      "\n",
      "Fold: 10  Epoch: 627  Training loss = 3.9212  Validation loss = 6.3026  \n",
      "\n",
      "Fold: 10  Epoch: 628  Training loss = 3.9211  Validation loss = 6.3025  \n",
      "\n",
      "Fold: 10  Epoch: 629  Training loss = 3.9210  Validation loss = 6.3022  \n",
      "\n",
      "Fold: 10  Epoch: 630  Training loss = 3.9209  Validation loss = 6.3021  \n",
      "\n",
      "Fold: 10  Epoch: 631  Training loss = 3.9207  Validation loss = 6.3019  \n",
      "\n",
      "Fold: 10  Epoch: 632  Training loss = 3.9206  Validation loss = 6.3017  \n",
      "\n",
      "Fold: 10  Epoch: 633  Training loss = 3.9205  Validation loss = 6.3015  \n",
      "\n",
      "Fold: 10  Epoch: 634  Training loss = 3.9204  Validation loss = 6.3013  \n",
      "\n",
      "Fold: 10  Epoch: 635  Training loss = 3.9202  Validation loss = 6.3011  \n",
      "\n",
      "Fold: 10  Epoch: 636  Training loss = 3.9201  Validation loss = 6.3009  \n",
      "\n",
      "Fold: 10  Epoch: 637  Training loss = 3.9200  Validation loss = 6.3007  \n",
      "\n",
      "Fold: 10  Epoch: 638  Training loss = 3.9198  Validation loss = 6.3005  \n",
      "\n",
      "Fold: 10  Epoch: 639  Training loss = 3.9197  Validation loss = 6.3003  \n",
      "\n",
      "Fold: 10  Epoch: 640  Training loss = 3.9196  Validation loss = 6.3001  \n",
      "\n",
      "Fold: 10  Epoch: 641  Training loss = 3.9194  Validation loss = 6.2999  \n",
      "\n",
      "Fold: 10  Epoch: 642  Training loss = 3.9193  Validation loss = 6.2997  \n",
      "\n",
      "Fold: 10  Epoch: 643  Training loss = 3.9192  Validation loss = 6.2995  \n",
      "\n",
      "Fold: 10  Epoch: 644  Training loss = 3.9191  Validation loss = 6.2993  \n",
      "\n",
      "Fold: 10  Epoch: 645  Training loss = 3.9189  Validation loss = 6.2991  \n",
      "\n",
      "Fold: 10  Epoch: 646  Training loss = 3.9188  Validation loss = 6.2990  \n",
      "\n",
      "Fold: 10  Epoch: 647  Training loss = 3.9187  Validation loss = 6.2988  \n",
      "\n",
      "Fold: 10  Epoch: 648  Training loss = 3.9186  Validation loss = 6.2986  \n",
      "\n",
      "Fold: 10  Epoch: 649  Training loss = 3.9184  Validation loss = 6.2984  \n",
      "\n",
      "Fold: 10  Epoch: 650  Training loss = 3.9183  Validation loss = 6.2982  \n",
      "\n",
      "Fold: 10  Epoch: 651  Training loss = 3.9182  Validation loss = 6.2980  \n",
      "\n",
      "Fold: 10  Epoch: 652  Training loss = 3.9180  Validation loss = 6.2978  \n",
      "\n",
      "Fold: 10  Epoch: 653  Training loss = 3.9179  Validation loss = 6.2976  \n",
      "\n",
      "Fold: 10  Epoch: 654  Training loss = 3.9178  Validation loss = 6.2975  \n",
      "\n",
      "Fold: 10  Epoch: 655  Training loss = 3.9177  Validation loss = 6.2973  \n",
      "\n",
      "Fold: 10  Epoch: 656  Training loss = 3.9175  Validation loss = 6.2970  \n",
      "\n",
      "Fold: 10  Epoch: 657  Training loss = 3.9173  Validation loss = 6.2967  \n",
      "\n",
      "Fold: 10  Epoch: 658  Training loss = 3.9172  Validation loss = 6.2966  \n",
      "\n",
      "Fold: 10  Epoch: 659  Training loss = 3.9171  Validation loss = 6.2964  \n",
      "\n",
      "Fold: 10  Epoch: 660  Training loss = 3.9170  Validation loss = 6.2963  \n",
      "\n",
      "Fold: 10  Epoch: 661  Training loss = 3.9168  Validation loss = 6.2960  \n",
      "\n",
      "Fold: 10  Epoch: 662  Training loss = 3.9167  Validation loss = 6.2958  \n",
      "\n",
      "Fold: 10  Epoch: 663  Training loss = 3.9166  Validation loss = 6.2956  \n",
      "\n",
      "Fold: 10  Epoch: 664  Training loss = 3.9165  Validation loss = 6.2954  \n",
      "\n",
      "Fold: 10  Epoch: 665  Training loss = 3.9163  Validation loss = 6.2952  \n",
      "\n",
      "Fold: 10  Epoch: 666  Training loss = 3.9162  Validation loss = 6.2950  \n",
      "\n",
      "Fold: 10  Epoch: 667  Training loss = 3.9160  Validation loss = 6.2948  \n",
      "\n",
      "Fold: 10  Epoch: 668  Training loss = 3.9158  Validation loss = 6.2945  \n",
      "\n",
      "Fold: 10  Epoch: 669  Training loss = 3.9157  Validation loss = 6.2943  \n",
      "\n",
      "Fold: 10  Epoch: 670  Training loss = 3.9156  Validation loss = 6.2941  \n",
      "\n",
      "Fold: 10  Epoch: 671  Training loss = 3.9154  Validation loss = 6.2939  \n",
      "\n",
      "Fold: 10  Epoch: 672  Training loss = 3.9153  Validation loss = 6.2937  \n",
      "\n",
      "Fold: 10  Epoch: 673  Training loss = 3.9151  Validation loss = 6.2935  \n",
      "\n",
      "Fold: 10  Epoch: 674  Training loss = 3.9150  Validation loss = 6.2932  \n",
      "\n",
      "Fold: 10  Epoch: 675  Training loss = 3.9149  Validation loss = 6.2931  \n",
      "\n",
      "Fold: 10  Epoch: 676  Training loss = 3.9148  Validation loss = 6.2929  \n",
      "\n",
      "Fold: 10  Epoch: 677  Training loss = 3.9147  Validation loss = 6.2928  \n",
      "\n",
      "Fold: 10  Epoch: 678  Training loss = 3.9145  Validation loss = 6.2925  \n",
      "\n",
      "Fold: 10  Epoch: 679  Training loss = 3.9144  Validation loss = 6.2923  \n",
      "\n",
      "Fold: 10  Epoch: 680  Training loss = 3.9142  Validation loss = 6.2921  \n",
      "\n",
      "Fold: 10  Epoch: 681  Training loss = 3.9140  Validation loss = 6.2918  \n",
      "\n",
      "Fold: 10  Epoch: 682  Training loss = 3.9139  Validation loss = 6.2916  \n",
      "\n",
      "Fold: 10  Epoch: 683  Training loss = 3.9137  Validation loss = 6.2913  \n",
      "\n",
      "Fold: 10  Epoch: 684  Training loss = 3.9136  Validation loss = 6.2912  \n",
      "\n",
      "Fold: 10  Epoch: 685  Training loss = 3.9135  Validation loss = 6.2910  \n",
      "\n",
      "Fold: 10  Epoch: 686  Training loss = 3.9134  Validation loss = 6.2908  \n",
      "\n",
      "Fold: 10  Epoch: 687  Training loss = 3.9132  Validation loss = 6.2905  \n",
      "\n",
      "Fold: 10  Epoch: 688  Training loss = 3.9130  Validation loss = 6.2902  \n",
      "\n",
      "Fold: 10  Epoch: 689  Training loss = 3.9129  Validation loss = 6.2901  \n",
      "\n",
      "Fold: 10  Epoch: 690  Training loss = 3.9128  Validation loss = 6.2899  \n",
      "\n",
      "Fold: 10  Epoch: 691  Training loss = 3.9126  Validation loss = 6.2897  \n",
      "\n",
      "Fold: 10  Epoch: 692  Training loss = 3.9125  Validation loss = 6.2895  \n",
      "\n",
      "Fold: 10  Epoch: 693  Training loss = 3.9124  Validation loss = 6.2893  \n",
      "\n",
      "Fold: 10  Epoch: 694  Training loss = 3.9122  Validation loss = 6.2891  \n",
      "\n",
      "Fold: 10  Epoch: 695  Training loss = 3.9121  Validation loss = 6.2889  \n",
      "\n",
      "Fold: 10  Epoch: 696  Training loss = 3.9119  Validation loss = 6.2886  \n",
      "\n",
      "Fold: 10  Epoch: 697  Training loss = 3.9118  Validation loss = 6.2885  \n",
      "\n",
      "Fold: 10  Epoch: 698  Training loss = 3.9117  Validation loss = 6.2883  \n",
      "\n",
      "Fold: 10  Epoch: 699  Training loss = 3.9116  Validation loss = 6.2881  \n",
      "\n",
      "Fold: 10  Epoch: 700  Training loss = 3.9114  Validation loss = 6.2879  \n",
      "\n",
      "Fold: 10  Epoch: 701  Training loss = 3.9113  Validation loss = 6.2877  \n",
      "\n",
      "Fold: 10  Epoch: 702  Training loss = 3.9111  Validation loss = 6.2874  \n",
      "\n",
      "Fold: 10  Epoch: 703  Training loss = 3.9110  Validation loss = 6.2872  \n",
      "\n",
      "Fold: 10  Epoch: 704  Training loss = 3.9108  Validation loss = 6.2870  \n",
      "\n",
      "Fold: 10  Epoch: 705  Training loss = 3.9107  Validation loss = 6.2868  \n",
      "\n",
      "Fold: 10  Epoch: 706  Training loss = 3.9105  Validation loss = 6.2866  \n",
      "\n",
      "Fold: 10  Epoch: 707  Training loss = 3.9104  Validation loss = 6.2864  \n",
      "\n",
      "Fold: 10  Epoch: 708  Training loss = 3.9102  Validation loss = 6.2861  \n",
      "\n",
      "Fold: 10  Epoch: 709  Training loss = 3.9101  Validation loss = 6.2859  \n",
      "\n",
      "Fold: 10  Epoch: 710  Training loss = 3.9100  Validation loss = 6.2858  \n",
      "\n",
      "Fold: 10  Epoch: 711  Training loss = 3.9098  Validation loss = 6.2855  \n",
      "\n",
      "Fold: 10  Epoch: 712  Training loss = 3.9097  Validation loss = 6.2853  \n",
      "\n",
      "Fold: 10  Epoch: 713  Training loss = 3.9096  Validation loss = 6.2852  \n",
      "\n",
      "Fold: 10  Epoch: 714  Training loss = 3.9095  Validation loss = 6.2851  \n",
      "\n",
      "Fold: 10  Epoch: 715  Training loss = 3.9093  Validation loss = 6.2848  \n",
      "\n",
      "Fold: 10  Epoch: 716  Training loss = 3.9092  Validation loss = 6.2845  \n",
      "\n",
      "Fold: 10  Epoch: 717  Training loss = 3.9090  Validation loss = 6.2843  \n",
      "\n",
      "Fold: 10  Epoch: 718  Training loss = 3.9089  Validation loss = 6.2842  \n",
      "\n",
      "Fold: 10  Epoch: 719  Training loss = 3.9088  Validation loss = 6.2840  \n",
      "\n",
      "Fold: 10  Epoch: 720  Training loss = 3.9087  Validation loss = 6.2838  \n",
      "\n",
      "Fold: 10  Epoch: 721  Training loss = 3.9085  Validation loss = 6.2836  \n",
      "\n",
      "Fold: 10  Epoch: 722  Training loss = 3.9084  Validation loss = 6.2834  \n",
      "\n",
      "Fold: 10  Epoch: 723  Training loss = 3.9083  Validation loss = 6.2832  \n",
      "\n",
      "Fold: 10  Epoch: 724  Training loss = 3.9081  Validation loss = 6.2830  \n",
      "\n",
      "Fold: 10  Epoch: 725  Training loss = 3.9080  Validation loss = 6.2828  \n",
      "\n",
      "Fold: 10  Epoch: 726  Training loss = 3.9078  Validation loss = 6.2826  \n",
      "\n",
      "Fold: 10  Epoch: 727  Training loss = 3.9077  Validation loss = 6.2824  \n",
      "\n",
      "Fold: 10  Epoch: 728  Training loss = 3.9076  Validation loss = 6.2822  \n",
      "\n",
      "Fold: 10  Epoch: 729  Training loss = 3.9074  Validation loss = 6.2820  \n",
      "\n",
      "Fold: 10  Epoch: 730  Training loss = 3.9073  Validation loss = 6.2819  \n",
      "\n",
      "Fold: 10  Epoch: 731  Training loss = 3.9072  Validation loss = 6.2816  \n",
      "\n",
      "Fold: 10  Epoch: 732  Training loss = 3.9071  Validation loss = 6.2815  \n",
      "\n",
      "Fold: 10  Epoch: 733  Training loss = 3.9069  Validation loss = 6.2812  \n",
      "\n",
      "Fold: 10  Epoch: 734  Training loss = 3.9068  Validation loss = 6.2810  \n",
      "\n",
      "Fold: 10  Epoch: 735  Training loss = 3.9066  Validation loss = 6.2809  \n",
      "\n",
      "Fold: 10  Epoch: 736  Training loss = 3.9065  Validation loss = 6.2807  \n",
      "\n",
      "Fold: 10  Epoch: 737  Training loss = 3.9064  Validation loss = 6.2805  \n",
      "\n",
      "Fold: 10  Epoch: 738  Training loss = 3.9062  Validation loss = 6.2803  \n",
      "\n",
      "Fold: 10  Epoch: 739  Training loss = 3.9061  Validation loss = 6.2801  \n",
      "\n",
      "Fold: 10  Epoch: 740  Training loss = 3.9060  Validation loss = 6.2799  \n",
      "\n",
      "Fold: 10  Epoch: 741  Training loss = 3.9058  Validation loss = 6.2797  \n",
      "\n",
      "Fold: 10  Epoch: 742  Training loss = 3.9057  Validation loss = 6.2795  \n",
      "\n",
      "Fold: 10  Epoch: 743  Training loss = 3.9055  Validation loss = 6.2792  \n",
      "\n",
      "Fold: 10  Epoch: 744  Training loss = 3.9054  Validation loss = 6.2790  \n",
      "\n",
      "Fold: 10  Epoch: 745  Training loss = 3.9052  Validation loss = 6.2787  \n",
      "\n",
      "Fold: 10  Epoch: 746  Training loss = 3.9051  Validation loss = 6.2785  \n",
      "\n",
      "Fold: 10  Epoch: 747  Training loss = 3.9049  Validation loss = 6.2782  \n",
      "\n",
      "Fold: 10  Epoch: 748  Training loss = 3.9047  Validation loss = 6.2780  \n",
      "\n",
      "Fold: 10  Epoch: 749  Training loss = 3.9045  Validation loss = 6.2778  \n",
      "\n",
      "Fold: 10  Epoch: 750  Training loss = 3.9044  Validation loss = 6.2775  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 750  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 4.1946  Validation loss = 3.7857  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 4.1944  Validation loss = 3.7854  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 4.1942  Validation loss = 3.7850  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 4.1940  Validation loss = 3.7847  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 4.1939  Validation loss = 3.7844  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 4.1937  Validation loss = 3.7841  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 4.1936  Validation loss = 3.7839  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 4.1934  Validation loss = 3.7836  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 4.1932  Validation loss = 3.7832  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 4.1930  Validation loss = 3.7828  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 4.1929  Validation loss = 3.7825  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 4.1927  Validation loss = 3.7821  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 4.1925  Validation loss = 3.7819  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 4.1923  Validation loss = 3.7815  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 4.1921  Validation loss = 3.7811  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 4.1919  Validation loss = 3.7808  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 4.1918  Validation loss = 3.7805  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 4.1916  Validation loss = 3.7801  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 4.1915  Validation loss = 3.7799  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 4.1913  Validation loss = 3.7795  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 4.1911  Validation loss = 3.7793  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 4.1910  Validation loss = 3.7789  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 4.1908  Validation loss = 3.7785  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 4.1906  Validation loss = 3.7782  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 4.1904  Validation loss = 3.7778  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 4.1902  Validation loss = 3.7776  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 4.1900  Validation loss = 3.7772  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 4.1899  Validation loss = 3.7769  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 4.1897  Validation loss = 3.7766  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 4.1896  Validation loss = 3.7764  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 4.1895  Validation loss = 3.7762  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 4.1893  Validation loss = 3.7758  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 4.1891  Validation loss = 3.7756  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 4.1890  Validation loss = 3.7753  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 4.1888  Validation loss = 3.7750  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 4.1886  Validation loss = 3.7746  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 4.1885  Validation loss = 3.7743  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 4.1883  Validation loss = 3.7740  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 4.1881  Validation loss = 3.7737  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 4.1879  Validation loss = 3.7734  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 4.1878  Validation loss = 3.7731  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 4.1877  Validation loss = 3.7729  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 4.1875  Validation loss = 3.7726  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 4.1874  Validation loss = 3.7724  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 4.1873  Validation loss = 3.7722  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 4.1871  Validation loss = 3.7719  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 4.1869  Validation loss = 3.7715  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 4.1868  Validation loss = 3.7712  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 4.1866  Validation loss = 3.7709  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 4.1864  Validation loss = 3.7706  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 4.1862  Validation loss = 3.7703  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 4.1861  Validation loss = 3.7700  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 4.1859  Validation loss = 3.7697  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 4.1858  Validation loss = 3.7695  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 4.1856  Validation loss = 3.7691  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 4.1854  Validation loss = 3.7687  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 4.1852  Validation loss = 3.7685  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 4.1851  Validation loss = 3.7682  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 4.1849  Validation loss = 3.7680  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 4.1847  Validation loss = 3.7676  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 4.1846  Validation loss = 3.7674  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 4.1845  Validation loss = 3.7671  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 4.1843  Validation loss = 3.7668  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 4.1841  Validation loss = 3.7665  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 4.1840  Validation loss = 3.7662  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 4.1838  Validation loss = 3.7659  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 4.1836  Validation loss = 3.7656  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 4.1835  Validation loss = 3.7653  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 4.1833  Validation loss = 3.7650  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 4.1831  Validation loss = 3.7647  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 4.1830  Validation loss = 3.7644  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 4.1828  Validation loss = 3.7641  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 4.1826  Validation loss = 3.7638  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 4.1825  Validation loss = 3.7635  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 4.1823  Validation loss = 3.7632  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 4.1821  Validation loss = 3.7629  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 4.1819  Validation loss = 3.7624  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 4.1817  Validation loss = 3.7620  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 4.1815  Validation loss = 3.7618  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 4.1814  Validation loss = 3.7615  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 4.1812  Validation loss = 3.7611  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 4.1810  Validation loss = 3.7608  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 4.1808  Validation loss = 3.7605  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 4.1806  Validation loss = 3.7601  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 4.1805  Validation loss = 3.7598  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 4.1803  Validation loss = 3.7595  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 4.1801  Validation loss = 3.7592  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 4.1799  Validation loss = 3.7589  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 4.1798  Validation loss = 3.7586  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 4.1796  Validation loss = 3.7583  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 4.1794  Validation loss = 3.7580  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 4.1793  Validation loss = 3.7578  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 4.1791  Validation loss = 3.7574  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 4.1789  Validation loss = 3.7571  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 4.1787  Validation loss = 3.7567  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 4.1785  Validation loss = 3.7564  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 4.1783  Validation loss = 3.7560  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 4.1781  Validation loss = 3.7556  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 4.1779  Validation loss = 3.7553  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 4.1777  Validation loss = 3.7548  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 4.1775  Validation loss = 3.7546  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 4.1773  Validation loss = 3.7542  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 4.1771  Validation loss = 3.7538  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 4.1769  Validation loss = 3.7535  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 4.1767  Validation loss = 3.7531  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 4.1765  Validation loss = 3.7528  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 4.1763  Validation loss = 3.7524  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 4.1762  Validation loss = 3.7522  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 4.1760  Validation loss = 3.7519  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 4.1759  Validation loss = 3.7517  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 4.1757  Validation loss = 3.7514  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 4.1756  Validation loss = 3.7511  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 4.1754  Validation loss = 3.7508  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 4.1752  Validation loss = 3.7504  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 4.1750  Validation loss = 3.7501  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 4.1748  Validation loss = 3.7498  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 4.1747  Validation loss = 3.7495  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 4.1744  Validation loss = 3.7491  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 4.1743  Validation loss = 3.7489  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 4.1742  Validation loss = 3.7487  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 4.1740  Validation loss = 3.7484  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 4.1739  Validation loss = 3.7481  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 4.1737  Validation loss = 3.7478  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 4.1735  Validation loss = 3.7474  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 4.1733  Validation loss = 3.7471  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 4.1731  Validation loss = 3.7468  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 4.1729  Validation loss = 3.7465  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 4.1727  Validation loss = 3.7462  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 4.1725  Validation loss = 3.7458  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 4.1724  Validation loss = 3.7456  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 4.1722  Validation loss = 3.7452  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 4.1719  Validation loss = 3.7448  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 4.1717  Validation loss = 3.7445  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 4.1715  Validation loss = 3.7440  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 4.1713  Validation loss = 3.7438  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 4.1711  Validation loss = 3.7434  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 4.1709  Validation loss = 3.7431  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 4.1708  Validation loss = 3.7428  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 4.1706  Validation loss = 3.7425  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 4.1704  Validation loss = 3.7422  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 4.1703  Validation loss = 3.7419  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 4.1701  Validation loss = 3.7416  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 4.1699  Validation loss = 3.7413  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 4.1697  Validation loss = 3.7410  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 4.1696  Validation loss = 3.7408  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 4.1694  Validation loss = 3.7404  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 4.1692  Validation loss = 3.7401  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 4.1690  Validation loss = 3.7398  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 4.1689  Validation loss = 3.7395  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 4.1687  Validation loss = 3.7392  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 4.1685  Validation loss = 3.7389  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 4.1683  Validation loss = 3.7386  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 4.1681  Validation loss = 3.7383  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 4.1680  Validation loss = 3.7380  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 4.1678  Validation loss = 3.7377  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 4.1676  Validation loss = 3.7374  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 4.1674  Validation loss = 3.7371  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 4.1672  Validation loss = 3.7367  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 4.1670  Validation loss = 3.7364  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 4.1668  Validation loss = 3.7360  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 4.1666  Validation loss = 3.7358  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 4.1664  Validation loss = 3.7354  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 4.1663  Validation loss = 3.7352  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 4.1661  Validation loss = 3.7349  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 4.1659  Validation loss = 3.7346  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 4.1657  Validation loss = 3.7342  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 4.1656  Validation loss = 3.7340  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 4.1654  Validation loss = 3.7337  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 4.1652  Validation loss = 3.7333  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 4.1650  Validation loss = 3.7330  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 4.1649  Validation loss = 3.7328  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 4.1647  Validation loss = 3.7325  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 4.1645  Validation loss = 3.7323  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 4.1643  Validation loss = 3.7319  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 4.1641  Validation loss = 3.7315  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 4.1640  Validation loss = 3.7313  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 4.1637  Validation loss = 3.7309  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 4.1635  Validation loss = 3.7306  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 4.1633  Validation loss = 3.7302  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 4.1632  Validation loss = 3.7300  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 4.1630  Validation loss = 3.7297  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 4.1628  Validation loss = 3.7294  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 4.1627  Validation loss = 3.7291  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 4.1625  Validation loss = 3.7288  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 4.1623  Validation loss = 3.7285  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 4.1621  Validation loss = 3.7281  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 4.1619  Validation loss = 3.7278  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 4.1618  Validation loss = 3.7276  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 4.1616  Validation loss = 3.7273  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 4.1614  Validation loss = 3.7270  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 4.1613  Validation loss = 3.7267  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 4.1611  Validation loss = 3.7265  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 4.1609  Validation loss = 3.7261  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 4.1608  Validation loss = 3.7259  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 4.1606  Validation loss = 3.7257  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 4.1605  Validation loss = 3.7254  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 4.1602  Validation loss = 3.7250  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 4.1601  Validation loss = 3.7248  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 4.1599  Validation loss = 3.7245  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 4.1597  Validation loss = 3.7242  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 4.1596  Validation loss = 3.7239  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 4.1594  Validation loss = 3.7236  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 4.1592  Validation loss = 3.7233  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 4.1590  Validation loss = 3.7230  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 4.1588  Validation loss = 3.7227  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 4.1586  Validation loss = 3.7224  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 4.1584  Validation loss = 3.7221  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 4.1582  Validation loss = 3.7218  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 4.1580  Validation loss = 3.7215  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 4.1579  Validation loss = 3.7212  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 4.1577  Validation loss = 3.7209  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 4.1575  Validation loss = 3.7206  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 4.1574  Validation loss = 3.7203  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 4.1572  Validation loss = 3.7201  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 4.1570  Validation loss = 3.7198  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 4.1568  Validation loss = 3.7194  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 4.1566  Validation loss = 3.7190  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 4.1564  Validation loss = 3.7188  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 4.1562  Validation loss = 3.7185  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 4.1561  Validation loss = 3.7182  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 4.1559  Validation loss = 3.7179  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 4.1558  Validation loss = 3.7177  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 4.1556  Validation loss = 3.7175  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 4.1554  Validation loss = 3.7172  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 4.1552  Validation loss = 3.7169  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 4.1551  Validation loss = 3.7166  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 4.1548  Validation loss = 3.7163  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 4.1546  Validation loss = 3.7159  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 4.1544  Validation loss = 3.7156  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 4.1542  Validation loss = 3.7152  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 4.1539  Validation loss = 3.7149  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 4.1538  Validation loss = 3.7146  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 4.1536  Validation loss = 3.7143  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 4.1534  Validation loss = 3.7141  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 4.1532  Validation loss = 3.7137  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 4.1531  Validation loss = 3.7135  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 4.1528  Validation loss = 3.7132  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 4.1527  Validation loss = 3.7129  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 4.1525  Validation loss = 3.7126  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 4.1523  Validation loss = 3.7124  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 4.1522  Validation loss = 3.7121  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 4.1520  Validation loss = 3.7118  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 4.1518  Validation loss = 3.7115  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 4.1515  Validation loss = 3.7111  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 4.1512  Validation loss = 3.7107  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 4.1511  Validation loss = 3.7105  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 4.1509  Validation loss = 3.7102  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 4.1507  Validation loss = 3.7099  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 4.1505  Validation loss = 3.7096  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 4.1503  Validation loss = 3.7093  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 4.1502  Validation loss = 3.7090  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 4.1500  Validation loss = 3.7087  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 4.1497  Validation loss = 3.7083  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 4.1495  Validation loss = 3.7080  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 4.1493  Validation loss = 3.7077  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 4.1491  Validation loss = 3.7075  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 4.1489  Validation loss = 3.7071  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 4.1487  Validation loss = 3.7068  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 4.1486  Validation loss = 3.7066  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 4.1484  Validation loss = 3.7064  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 4.1483  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 4.1480  Validation loss = 3.7058  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 4.1478  Validation loss = 3.7054  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 4.1475  Validation loss = 3.7050  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 4.1473  Validation loss = 3.7047  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 4.1471  Validation loss = 3.7044  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 4.1469  Validation loss = 3.7041  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 4.1467  Validation loss = 3.7038  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 4.1465  Validation loss = 3.7035  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 4.1463  Validation loss = 3.7032  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 4.1461  Validation loss = 3.7029  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 4.1458  Validation loss = 3.7025  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 4.1456  Validation loss = 3.7022  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 4.1454  Validation loss = 3.7019  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 4.1452  Validation loss = 3.7016  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 4.1450  Validation loss = 3.7012  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 4.1448  Validation loss = 3.7010  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 4.1446  Validation loss = 3.7007  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 4.1444  Validation loss = 3.7004  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 4.1442  Validation loss = 3.7001  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 4.1440  Validation loss = 3.6998  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 4.1438  Validation loss = 3.6995  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 4.1436  Validation loss = 3.6992  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 4.1433  Validation loss = 3.6988  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 4.1432  Validation loss = 3.6986  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 4.1430  Validation loss = 3.6983  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 4.1428  Validation loss = 3.6981  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 4.1426  Validation loss = 3.6977  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 4.1423  Validation loss = 3.6974  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 4.1421  Validation loss = 3.6971  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 4.1419  Validation loss = 3.6967  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 4.1416  Validation loss = 3.6964  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 4.1414  Validation loss = 3.6961  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 4.1413  Validation loss = 3.6959  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 4.1412  Validation loss = 3.6957  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 4.1410  Validation loss = 3.6954  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 4.1408  Validation loss = 3.6951  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 4.1406  Validation loss = 3.6949  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 4.1404  Validation loss = 3.6946  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 4.1403  Validation loss = 3.6944  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 4.1400  Validation loss = 3.6940  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 4.1398  Validation loss = 3.6937  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 4.1396  Validation loss = 3.6934  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 4.1394  Validation loss = 3.6931  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 4.1393  Validation loss = 3.6929  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 4.1390  Validation loss = 3.6925  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 4.1388  Validation loss = 3.6923  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 4.1386  Validation loss = 3.6920  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 4.1384  Validation loss = 3.6917  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 4.1382  Validation loss = 3.6914  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 4.1379  Validation loss = 3.6910  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 4.1377  Validation loss = 3.6908  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 4.1375  Validation loss = 3.6905  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 4.1372  Validation loss = 3.6901  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 4.1371  Validation loss = 3.6899  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 4.1369  Validation loss = 3.6896  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 4.1367  Validation loss = 3.6894  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 4.1364  Validation loss = 3.6890  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 4.1363  Validation loss = 3.6888  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 4.1360  Validation loss = 3.6884  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 4.1358  Validation loss = 3.6881  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 4.1356  Validation loss = 3.6878  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 4.1354  Validation loss = 3.6876  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 4.1352  Validation loss = 3.6873  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 4.1350  Validation loss = 3.6870  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 4.1348  Validation loss = 3.6867  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 4.1345  Validation loss = 3.6864  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 4.1342  Validation loss = 3.6860  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 4.1340  Validation loss = 3.6858  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 4.1339  Validation loss = 3.6856  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 4.1336  Validation loss = 3.6852  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 4.1334  Validation loss = 3.6849  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 4.1331  Validation loss = 3.6846  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 4.1329  Validation loss = 3.6843  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 4.1327  Validation loss = 3.6840  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 4.1324  Validation loss = 3.6837  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 4.1322  Validation loss = 3.6834  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 4.1320  Validation loss = 3.6831  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 4.1317  Validation loss = 3.6828  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 4.1315  Validation loss = 3.6825  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 4.1312  Validation loss = 3.6822  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 4.1310  Validation loss = 3.6818  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 4.1307  Validation loss = 3.6815  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 4.1305  Validation loss = 3.6812  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 4.1303  Validation loss = 3.6810  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 4.1301  Validation loss = 3.6807  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 4.1299  Validation loss = 3.6805  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 4.1298  Validation loss = 3.6803  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 4.1295  Validation loss = 3.6799  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 4.1293  Validation loss = 3.6797  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 4.1291  Validation loss = 3.6794  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 4.1289  Validation loss = 3.6791  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 4.1287  Validation loss = 3.6788  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 4.1285  Validation loss = 3.6785  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 4.1283  Validation loss = 3.6783  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 4.1281  Validation loss = 3.6780  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 4.1278  Validation loss = 3.6777  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 4.1276  Validation loss = 3.6775  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 4.1273  Validation loss = 3.6771  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 4.1271  Validation loss = 3.6768  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 4.1268  Validation loss = 3.6765  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 4.1266  Validation loss = 3.6762  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 4.1264  Validation loss = 3.6760  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 4.1262  Validation loss = 3.6757  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 4.1259  Validation loss = 3.6753  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 4.1257  Validation loss = 3.6751  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 4.1255  Validation loss = 3.6748  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 4.1252  Validation loss = 3.6745  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 4.1250  Validation loss = 3.6742  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 4.1248  Validation loss = 3.6739  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 4.1246  Validation loss = 3.6737  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 4.1245  Validation loss = 3.6735  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 4.1243  Validation loss = 3.6732  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 4.1239  Validation loss = 3.6728  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 4.1237  Validation loss = 3.6725  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 4.1235  Validation loss = 3.6723  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 4.1232  Validation loss = 3.6719  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 4.1229  Validation loss = 3.6716  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 4.1227  Validation loss = 3.6713  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 4.1225  Validation loss = 3.6711  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 4.1223  Validation loss = 3.6709  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 4.1221  Validation loss = 3.6706  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 4.1220  Validation loss = 3.6703  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 4.1217  Validation loss = 3.6700  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 4.1216  Validation loss = 3.6698  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 4.1212  Validation loss = 3.6694  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 4.1210  Validation loss = 3.6691  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 4.1208  Validation loss = 3.6689  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 4.1205  Validation loss = 3.6686  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 4.1203  Validation loss = 3.6683  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 4.1201  Validation loss = 3.6680  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 4.1199  Validation loss = 3.6678  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 4.1195  Validation loss = 3.6674  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 4.1193  Validation loss = 3.6672  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 4.1192  Validation loss = 3.6670  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 4.1188  Validation loss = 3.6666  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 4.1186  Validation loss = 3.6663  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 4.1184  Validation loss = 3.6661  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 4.1182  Validation loss = 3.6659  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 4.1179  Validation loss = 3.6656  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 4.1176  Validation loss = 3.6653  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 4.1174  Validation loss = 3.6650  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 4.1172  Validation loss = 3.6648  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 4.1169  Validation loss = 3.6644  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 4.1167  Validation loss = 3.6642  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 4.1165  Validation loss = 3.6639  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 4.1163  Validation loss = 3.6637  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 4.1161  Validation loss = 3.6634  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 4.1157  Validation loss = 3.6630  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 4.1156  Validation loss = 3.6628  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 4.1154  Validation loss = 3.6626  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 4.1152  Validation loss = 3.6624  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 4.1149  Validation loss = 3.6620  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 4.1146  Validation loss = 3.6617  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 4.1144  Validation loss = 3.6615  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 4.1141  Validation loss = 3.6612  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 4.1138  Validation loss = 3.6609  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 4.1136  Validation loss = 3.6607  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 4.1134  Validation loss = 3.6604  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 4.1132  Validation loss = 3.6602  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 4.1129  Validation loss = 3.6599  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 4.1128  Validation loss = 3.6597  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 4.1126  Validation loss = 3.6595  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 4.1124  Validation loss = 3.6593  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 4.1122  Validation loss = 3.6590  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 4.1119  Validation loss = 3.6587  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 4.1117  Validation loss = 3.6585  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 4.1114  Validation loss = 3.6582  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 4.1112  Validation loss = 3.6579  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 4.1111  Validation loss = 3.6577  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 4.1109  Validation loss = 3.6574  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 4.1107  Validation loss = 3.6572  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 4.1103  Validation loss = 3.6569  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 4.1102  Validation loss = 3.6566  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 4.1099  Validation loss = 3.6563  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 4.1096  Validation loss = 3.6560  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 4.1093  Validation loss = 3.6557  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 4.1089  Validation loss = 3.6553  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 4.1088  Validation loss = 3.6552  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 4.1086  Validation loss = 3.6549  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 4.1084  Validation loss = 3.6547  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 4.1081  Validation loss = 3.6544  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 4.1078  Validation loss = 3.6540  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 4.1075  Validation loss = 3.6537  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 4.1073  Validation loss = 3.6534  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 4.1071  Validation loss = 3.6532  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 4.1069  Validation loss = 3.6529  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 4.1067  Validation loss = 3.6526  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 4.1064  Validation loss = 3.6524  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 4.1062  Validation loss = 3.6521  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 4.1060  Validation loss = 3.6519  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 4.1057  Validation loss = 3.6516  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 4.1054  Validation loss = 3.6513  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 4.1050  Validation loss = 3.6510  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 4.1048  Validation loss = 3.6507  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 4.1046  Validation loss = 3.6505  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 4.1043  Validation loss = 3.6502  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 4.1042  Validation loss = 3.6500  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 4.1038  Validation loss = 3.6497  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 4.1036  Validation loss = 3.6494  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 4.1033  Validation loss = 3.6492  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 4.1031  Validation loss = 3.6489  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 4.1028  Validation loss = 3.6486  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 4.1026  Validation loss = 3.6483  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 4.1022  Validation loss = 3.6480  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 4.1020  Validation loss = 3.6478  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 4.1016  Validation loss = 3.6474  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 4.1013  Validation loss = 3.6470  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 4.1011  Validation loss = 3.6468  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 4.1009  Validation loss = 3.6466  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 4.1005  Validation loss = 3.6463  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 4.1003  Validation loss = 3.6460  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 4.1001  Validation loss = 3.6458  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 4.0998  Validation loss = 3.6455  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 4.0996  Validation loss = 3.6452  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 4.0993  Validation loss = 3.6449  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 4.0991  Validation loss = 3.6447  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 4.0988  Validation loss = 3.6444  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 4.0985  Validation loss = 3.6441  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 4.0984  Validation loss = 3.6439  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 4.0980  Validation loss = 3.6435  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 4.0976  Validation loss = 3.6432  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 4.0973  Validation loss = 3.6430  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 4.0970  Validation loss = 3.6427  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 4.0968  Validation loss = 3.6425  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 4.0965  Validation loss = 3.6422  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 4.0963  Validation loss = 3.6419  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 4.0959  Validation loss = 3.6416  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 4.0958  Validation loss = 3.6413  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 4.0956  Validation loss = 3.6411  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 4.0953  Validation loss = 3.6408  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 4.0951  Validation loss = 3.6406  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 4.0948  Validation loss = 3.6403  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 4.0947  Validation loss = 3.6401  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 4.0943  Validation loss = 3.6398  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 4.0941  Validation loss = 3.6396  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 4.0937  Validation loss = 3.6392  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 4.0934  Validation loss = 3.6389  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 4.0932  Validation loss = 3.6386  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 4.0930  Validation loss = 3.6384  \n",
      "\n",
      "Fold: 11  Epoch: 501  Training loss = 4.0928  Validation loss = 3.6381  \n",
      "\n",
      "Fold: 11  Epoch: 502  Training loss = 4.0926  Validation loss = 3.6379  \n",
      "\n",
      "Fold: 11  Epoch: 503  Training loss = 4.0922  Validation loss = 3.6376  \n",
      "\n",
      "Fold: 11  Epoch: 504  Training loss = 4.0920  Validation loss = 3.6374  \n",
      "\n",
      "Fold: 11  Epoch: 505  Training loss = 4.0917  Validation loss = 3.6371  \n",
      "\n",
      "Fold: 11  Epoch: 506  Training loss = 4.0915  Validation loss = 3.6368  \n",
      "\n",
      "Fold: 11  Epoch: 507  Training loss = 4.0912  Validation loss = 3.6365  \n",
      "\n",
      "Fold: 11  Epoch: 508  Training loss = 4.0909  Validation loss = 3.6362  \n",
      "\n",
      "Fold: 11  Epoch: 509  Training loss = 4.0906  Validation loss = 3.6360  \n",
      "\n",
      "Fold: 11  Epoch: 510  Training loss = 4.0905  Validation loss = 3.6357  \n",
      "\n",
      "Fold: 11  Epoch: 511  Training loss = 4.0902  Validation loss = 3.6354  \n",
      "\n",
      "Fold: 11  Epoch: 512  Training loss = 4.0898  Validation loss = 3.6351  \n",
      "\n",
      "Fold: 11  Epoch: 513  Training loss = 4.0895  Validation loss = 3.6349  \n",
      "\n",
      "Fold: 11  Epoch: 514  Training loss = 4.0893  Validation loss = 3.6347  \n",
      "\n",
      "Fold: 11  Epoch: 515  Training loss = 4.0891  Validation loss = 3.6344  \n",
      "\n",
      "Fold: 11  Epoch: 516  Training loss = 4.0889  Validation loss = 3.6341  \n",
      "\n",
      "Fold: 11  Epoch: 517  Training loss = 4.0886  Validation loss = 3.6339  \n",
      "\n",
      "Fold: 11  Epoch: 518  Training loss = 4.0882  Validation loss = 3.6336  \n",
      "\n",
      "Fold: 11  Epoch: 519  Training loss = 4.0880  Validation loss = 3.6333  \n",
      "\n",
      "Fold: 11  Epoch: 520  Training loss = 4.0878  Validation loss = 3.6331  \n",
      "\n",
      "Fold: 11  Epoch: 521  Training loss = 4.0874  Validation loss = 3.6327  \n",
      "\n",
      "Fold: 11  Epoch: 522  Training loss = 4.0872  Validation loss = 3.6325  \n",
      "\n",
      "Fold: 11  Epoch: 523  Training loss = 4.0869  Validation loss = 3.6322  \n",
      "\n",
      "Fold: 11  Epoch: 524  Training loss = 4.0867  Validation loss = 3.6320  \n",
      "\n",
      "Fold: 11  Epoch: 525  Training loss = 4.0864  Validation loss = 3.6317  \n",
      "\n",
      "Fold: 11  Epoch: 526  Training loss = 4.0862  Validation loss = 3.6315  \n",
      "\n",
      "Fold: 11  Epoch: 527  Training loss = 4.0860  Validation loss = 3.6312  \n",
      "\n",
      "Fold: 11  Epoch: 528  Training loss = 4.0858  Validation loss = 3.6310  \n",
      "\n",
      "Fold: 11  Epoch: 529  Training loss = 4.0855  Validation loss = 3.6307  \n",
      "\n",
      "Fold: 11  Epoch: 530  Training loss = 4.0852  Validation loss = 3.6304  \n",
      "\n",
      "Fold: 11  Epoch: 531  Training loss = 4.0851  Validation loss = 3.6302  \n",
      "\n",
      "Fold: 11  Epoch: 532  Training loss = 4.0849  Validation loss = 3.6300  \n",
      "\n",
      "Fold: 11  Epoch: 533  Training loss = 4.0846  Validation loss = 3.6298  \n",
      "\n",
      "Fold: 11  Epoch: 534  Training loss = 4.0843  Validation loss = 3.6294  \n",
      "\n",
      "Fold: 11  Epoch: 535  Training loss = 4.0840  Validation loss = 3.6292  \n",
      "\n",
      "Fold: 11  Epoch: 536  Training loss = 4.0836  Validation loss = 3.6289  \n",
      "\n",
      "Fold: 11  Epoch: 537  Training loss = 4.0833  Validation loss = 3.6287  \n",
      "\n",
      "Fold: 11  Epoch: 538  Training loss = 4.0831  Validation loss = 3.6284  \n",
      "\n",
      "Fold: 11  Epoch: 539  Training loss = 4.0828  Validation loss = 3.6282  \n",
      "\n",
      "Fold: 11  Epoch: 540  Training loss = 4.0826  Validation loss = 3.6279  \n",
      "\n",
      "Fold: 11  Epoch: 541  Training loss = 4.0823  Validation loss = 3.6277  \n",
      "\n",
      "Fold: 11  Epoch: 542  Training loss = 4.0819  Validation loss = 3.6274  \n",
      "\n",
      "Fold: 11  Epoch: 543  Training loss = 4.0815  Validation loss = 3.6270  \n",
      "\n",
      "Fold: 11  Epoch: 544  Training loss = 4.0812  Validation loss = 3.6267  \n",
      "\n",
      "Fold: 11  Epoch: 545  Training loss = 4.0809  Validation loss = 3.6265  \n",
      "\n",
      "Fold: 11  Epoch: 546  Training loss = 4.0806  Validation loss = 3.6261  \n",
      "\n",
      "Fold: 11  Epoch: 547  Training loss = 4.0802  Validation loss = 3.6258  \n",
      "\n",
      "Fold: 11  Epoch: 548  Training loss = 4.0799  Validation loss = 3.6256  \n",
      "\n",
      "Fold: 11  Epoch: 549  Training loss = 4.0796  Validation loss = 3.6253  \n",
      "\n",
      "Fold: 11  Epoch: 550  Training loss = 4.0793  Validation loss = 3.6250  \n",
      "\n",
      "Fold: 11  Epoch: 551  Training loss = 4.0791  Validation loss = 3.6248  \n",
      "\n",
      "Fold: 11  Epoch: 552  Training loss = 4.0789  Validation loss = 3.6245  \n",
      "\n",
      "Fold: 11  Epoch: 553  Training loss = 4.0787  Validation loss = 3.6242  \n",
      "\n",
      "Fold: 11  Epoch: 554  Training loss = 4.0782  Validation loss = 3.6239  \n",
      "\n",
      "Fold: 11  Epoch: 555  Training loss = 4.0779  Validation loss = 3.6236  \n",
      "\n",
      "Fold: 11  Epoch: 556  Training loss = 4.0776  Validation loss = 3.6233  \n",
      "\n",
      "Fold: 11  Epoch: 557  Training loss = 4.0770  Validation loss = 3.6230  \n",
      "\n",
      "Fold: 11  Epoch: 558  Training loss = 4.0767  Validation loss = 3.6227  \n",
      "\n",
      "Fold: 11  Epoch: 559  Training loss = 4.0764  Validation loss = 3.6224  \n",
      "\n",
      "Fold: 11  Epoch: 560  Training loss = 4.0760  Validation loss = 3.6221  \n",
      "\n",
      "Fold: 11  Epoch: 561  Training loss = 4.0757  Validation loss = 3.6219  \n",
      "\n",
      "Fold: 11  Epoch: 562  Training loss = 4.0754  Validation loss = 3.6216  \n",
      "\n",
      "Fold: 11  Epoch: 563  Training loss = 4.0751  Validation loss = 3.6213  \n",
      "\n",
      "Fold: 11  Epoch: 564  Training loss = 4.0748  Validation loss = 3.6211  \n",
      "\n",
      "Fold: 11  Epoch: 565  Training loss = 4.0745  Validation loss = 3.6208  \n",
      "\n",
      "Fold: 11  Epoch: 566  Training loss = 4.0742  Validation loss = 3.6205  \n",
      "\n",
      "Fold: 11  Epoch: 567  Training loss = 4.0739  Validation loss = 3.6203  \n",
      "\n",
      "Fold: 11  Epoch: 568  Training loss = 4.0736  Validation loss = 3.6200  \n",
      "\n",
      "Fold: 11  Epoch: 569  Training loss = 4.0734  Validation loss = 3.6198  \n",
      "\n",
      "Fold: 11  Epoch: 570  Training loss = 4.0729  Validation loss = 3.6195  \n",
      "\n",
      "Fold: 11  Epoch: 571  Training loss = 4.0726  Validation loss = 3.6192  \n",
      "\n",
      "Fold: 11  Epoch: 572  Training loss = 4.0723  Validation loss = 3.6189  \n",
      "\n",
      "Fold: 11  Epoch: 573  Training loss = 4.0719  Validation loss = 3.6186  \n",
      "\n",
      "Fold: 11  Epoch: 574  Training loss = 4.0717  Validation loss = 3.6183  \n",
      "\n",
      "Fold: 11  Epoch: 575  Training loss = 4.0714  Validation loss = 3.6181  \n",
      "\n",
      "Fold: 11  Epoch: 576  Training loss = 4.0710  Validation loss = 3.6178  \n",
      "\n",
      "Fold: 11  Epoch: 577  Training loss = 4.0708  Validation loss = 3.6175  \n",
      "\n",
      "Fold: 11  Epoch: 578  Training loss = 4.0705  Validation loss = 3.6173  \n",
      "\n",
      "Fold: 11  Epoch: 579  Training loss = 4.0703  Validation loss = 3.6170  \n",
      "\n",
      "Fold: 11  Epoch: 580  Training loss = 4.0700  Validation loss = 3.6167  \n",
      "\n",
      "Fold: 11  Epoch: 581  Training loss = 4.0697  Validation loss = 3.6165  \n",
      "\n",
      "Fold: 11  Epoch: 582  Training loss = 4.0694  Validation loss = 3.6162  \n",
      "\n",
      "Fold: 11  Epoch: 583  Training loss = 4.0692  Validation loss = 3.6160  \n",
      "\n",
      "Fold: 11  Epoch: 584  Training loss = 4.0690  Validation loss = 3.6157  \n",
      "\n",
      "Fold: 11  Epoch: 585  Training loss = 4.0687  Validation loss = 3.6155  \n",
      "\n",
      "Fold: 11  Epoch: 586  Training loss = 4.0684  Validation loss = 3.6153  \n",
      "\n",
      "Fold: 11  Epoch: 587  Training loss = 4.0682  Validation loss = 3.6151  \n",
      "\n",
      "Fold: 11  Epoch: 588  Training loss = 4.0680  Validation loss = 3.6149  \n",
      "\n",
      "Fold: 11  Epoch: 589  Training loss = 4.0677  Validation loss = 3.6146  \n",
      "\n",
      "Fold: 11  Epoch: 590  Training loss = 4.0672  Validation loss = 3.6143  \n",
      "\n",
      "Fold: 11  Epoch: 591  Training loss = 4.0668  Validation loss = 3.6139  \n",
      "\n",
      "Fold: 11  Epoch: 592  Training loss = 4.0665  Validation loss = 3.6137  \n",
      "\n",
      "Fold: 11  Epoch: 593  Training loss = 4.0663  Validation loss = 3.6135  \n",
      "\n",
      "Fold: 11  Epoch: 594  Training loss = 4.0660  Validation loss = 3.6132  \n",
      "\n",
      "Fold: 11  Epoch: 595  Training loss = 4.0656  Validation loss = 3.6129  \n",
      "\n",
      "Fold: 11  Epoch: 596  Training loss = 4.0652  Validation loss = 3.6126  \n",
      "\n",
      "Fold: 11  Epoch: 597  Training loss = 4.0650  Validation loss = 3.6124  \n",
      "\n",
      "Fold: 11  Epoch: 598  Training loss = 4.0648  Validation loss = 3.6121  \n",
      "\n",
      "Fold: 11  Epoch: 599  Training loss = 4.0644  Validation loss = 3.6118  \n",
      "\n",
      "Fold: 11  Epoch: 600  Training loss = 4.0640  Validation loss = 3.6115  \n",
      "\n",
      "Fold: 11  Epoch: 601  Training loss = 4.0636  Validation loss = 3.6112  \n",
      "\n",
      "Fold: 11  Epoch: 602  Training loss = 4.0633  Validation loss = 3.6110  \n",
      "\n",
      "Fold: 11  Epoch: 603  Training loss = 4.0629  Validation loss = 3.6107  \n",
      "\n",
      "Fold: 11  Epoch: 604  Training loss = 4.0625  Validation loss = 3.6104  \n",
      "\n",
      "Fold: 11  Epoch: 605  Training loss = 4.0621  Validation loss = 3.6101  \n",
      "\n",
      "Fold: 11  Epoch: 606  Training loss = 4.0618  Validation loss = 3.6098  \n",
      "\n",
      "Fold: 11  Epoch: 607  Training loss = 4.0615  Validation loss = 3.6095  \n",
      "\n",
      "Fold: 11  Epoch: 608  Training loss = 4.0612  Validation loss = 3.6092  \n",
      "\n",
      "Fold: 11  Epoch: 609  Training loss = 4.0608  Validation loss = 3.6089  \n",
      "\n",
      "Fold: 11  Epoch: 610  Training loss = 4.0605  Validation loss = 3.6087  \n",
      "\n",
      "Fold: 11  Epoch: 611  Training loss = 4.0602  Validation loss = 3.6083  \n",
      "\n",
      "Fold: 11  Epoch: 612  Training loss = 4.0598  Validation loss = 3.6081  \n",
      "\n",
      "Fold: 11  Epoch: 613  Training loss = 4.0595  Validation loss = 3.6078  \n",
      "\n",
      "Fold: 11  Epoch: 614  Training loss = 4.0593  Validation loss = 3.6076  \n",
      "\n",
      "Fold: 11  Epoch: 615  Training loss = 4.0590  Validation loss = 3.6073  \n",
      "\n",
      "Fold: 11  Epoch: 616  Training loss = 4.0588  Validation loss = 3.6071  \n",
      "\n",
      "Fold: 11  Epoch: 617  Training loss = 4.0585  Validation loss = 3.6068  \n",
      "\n",
      "Fold: 11  Epoch: 618  Training loss = 4.0581  Validation loss = 3.6066  \n",
      "\n",
      "Fold: 11  Epoch: 619  Training loss = 4.0577  Validation loss = 3.6063  \n",
      "\n",
      "Fold: 11  Epoch: 620  Training loss = 4.0575  Validation loss = 3.6060  \n",
      "\n",
      "Fold: 11  Epoch: 621  Training loss = 4.0572  Validation loss = 3.6058  \n",
      "\n",
      "Fold: 11  Epoch: 622  Training loss = 4.0569  Validation loss = 3.6056  \n",
      "\n",
      "Fold: 11  Epoch: 623  Training loss = 4.0566  Validation loss = 3.6053  \n",
      "\n",
      "Fold: 11  Epoch: 624  Training loss = 4.0563  Validation loss = 3.6051  \n",
      "\n",
      "Fold: 11  Epoch: 625  Training loss = 4.0561  Validation loss = 3.6049  \n",
      "\n",
      "Fold: 11  Epoch: 626  Training loss = 4.0558  Validation loss = 3.6046  \n",
      "\n",
      "Fold: 11  Epoch: 627  Training loss = 4.0553  Validation loss = 3.6043  \n",
      "\n",
      "Fold: 11  Epoch: 628  Training loss = 4.0550  Validation loss = 3.6040  \n",
      "\n",
      "Fold: 11  Epoch: 629  Training loss = 4.0548  Validation loss = 3.6038  \n",
      "\n",
      "Fold: 11  Epoch: 630  Training loss = 4.0545  Validation loss = 3.6036  \n",
      "\n",
      "Fold: 11  Epoch: 631  Training loss = 4.0542  Validation loss = 3.6033  \n",
      "\n",
      "Fold: 11  Epoch: 632  Training loss = 4.0539  Validation loss = 3.6031  \n",
      "\n",
      "Fold: 11  Epoch: 633  Training loss = 4.0536  Validation loss = 3.6028  \n",
      "\n",
      "Fold: 11  Epoch: 634  Training loss = 4.0535  Validation loss = 3.6026  \n",
      "\n",
      "Fold: 11  Epoch: 635  Training loss = 4.0532  Validation loss = 3.6024  \n",
      "\n",
      "Fold: 11  Epoch: 636  Training loss = 4.0528  Validation loss = 3.6021  \n",
      "\n",
      "Fold: 11  Epoch: 637  Training loss = 4.0525  Validation loss = 3.6018  \n",
      "\n",
      "Fold: 11  Epoch: 638  Training loss = 4.0523  Validation loss = 3.6016  \n",
      "\n",
      "Fold: 11  Epoch: 639  Training loss = 4.0520  Validation loss = 3.6013  \n",
      "\n",
      "Fold: 11  Epoch: 640  Training loss = 4.0515  Validation loss = 3.6010  \n",
      "\n",
      "Fold: 11  Epoch: 641  Training loss = 4.0513  Validation loss = 3.6008  \n",
      "\n",
      "Fold: 11  Epoch: 642  Training loss = 4.0510  Validation loss = 3.6005  \n",
      "\n",
      "Fold: 11  Epoch: 643  Training loss = 4.0506  Validation loss = 3.6002  \n",
      "\n",
      "Fold: 11  Epoch: 644  Training loss = 4.0504  Validation loss = 3.6000  \n",
      "\n",
      "Fold: 11  Epoch: 645  Training loss = 4.0501  Validation loss = 3.5998  \n",
      "\n",
      "Fold: 11  Epoch: 646  Training loss = 4.0496  Validation loss = 3.5994  \n",
      "\n",
      "Fold: 11  Epoch: 647  Training loss = 4.0493  Validation loss = 3.5991  \n",
      "\n",
      "Fold: 11  Epoch: 648  Training loss = 4.0490  Validation loss = 3.5989  \n",
      "\n",
      "Fold: 11  Epoch: 649  Training loss = 4.0487  Validation loss = 3.5987  \n",
      "\n",
      "Fold: 11  Epoch: 650  Training loss = 4.0484  Validation loss = 3.5985  \n",
      "\n",
      "Fold: 11  Epoch: 651  Training loss = 4.0482  Validation loss = 3.5983  \n",
      "\n",
      "Fold: 11  Epoch: 652  Training loss = 4.0479  Validation loss = 3.5980  \n",
      "\n",
      "Fold: 11  Epoch: 653  Training loss = 4.0475  Validation loss = 3.5978  \n",
      "\n",
      "Fold: 11  Epoch: 654  Training loss = 4.0472  Validation loss = 3.5975  \n",
      "\n",
      "Fold: 11  Epoch: 655  Training loss = 4.0468  Validation loss = 3.5971  \n",
      "\n",
      "Fold: 11  Epoch: 656  Training loss = 4.0466  Validation loss = 3.5969  \n",
      "\n",
      "Fold: 11  Epoch: 657  Training loss = 4.0463  Validation loss = 3.5967  \n",
      "\n",
      "Fold: 11  Epoch: 658  Training loss = 4.0461  Validation loss = 3.5964  \n",
      "\n",
      "Fold: 11  Epoch: 659  Training loss = 4.0458  Validation loss = 3.5962  \n",
      "\n",
      "Fold: 11  Epoch: 660  Training loss = 4.0454  Validation loss = 3.5958  \n",
      "\n",
      "Fold: 11  Epoch: 661  Training loss = 4.0448  Validation loss = 3.5955  \n",
      "\n",
      "Fold: 11  Epoch: 662  Training loss = 4.0445  Validation loss = 3.5952  \n",
      "\n",
      "Fold: 11  Epoch: 663  Training loss = 4.0442  Validation loss = 3.5949  \n",
      "\n",
      "Fold: 11  Epoch: 664  Training loss = 4.0438  Validation loss = 3.5947  \n",
      "\n",
      "Fold: 11  Epoch: 665  Training loss = 4.0435  Validation loss = 3.5945  \n",
      "\n",
      "Fold: 11  Epoch: 666  Training loss = 4.0430  Validation loss = 3.5941  \n",
      "\n",
      "Fold: 11  Epoch: 667  Training loss = 4.0427  Validation loss = 3.5939  \n",
      "\n",
      "Fold: 11  Epoch: 668  Training loss = 4.0422  Validation loss = 3.5936  \n",
      "\n",
      "Fold: 11  Epoch: 669  Training loss = 4.0420  Validation loss = 3.5934  \n",
      "\n",
      "Fold: 11  Epoch: 670  Training loss = 4.0416  Validation loss = 3.5931  \n",
      "\n",
      "Fold: 11  Epoch: 671  Training loss = 4.0413  Validation loss = 3.5928  \n",
      "\n",
      "Fold: 11  Epoch: 672  Training loss = 4.0411  Validation loss = 3.5926  \n",
      "\n",
      "Fold: 11  Epoch: 673  Training loss = 4.0406  Validation loss = 3.5922  \n",
      "\n",
      "Fold: 11  Epoch: 674  Training loss = 4.0404  Validation loss = 3.5920  \n",
      "\n",
      "Fold: 11  Epoch: 675  Training loss = 4.0400  Validation loss = 3.5917  \n",
      "\n",
      "Fold: 11  Epoch: 676  Training loss = 4.0397  Validation loss = 3.5915  \n",
      "\n",
      "Fold: 11  Epoch: 677  Training loss = 4.0394  Validation loss = 3.5912  \n",
      "\n",
      "Fold: 11  Epoch: 678  Training loss = 4.0391  Validation loss = 3.5910  \n",
      "\n",
      "Fold: 11  Epoch: 679  Training loss = 4.0387  Validation loss = 3.5907  \n",
      "\n",
      "Fold: 11  Epoch: 680  Training loss = 4.0384  Validation loss = 3.5905  \n",
      "\n",
      "Fold: 11  Epoch: 681  Training loss = 4.0380  Validation loss = 3.5902  \n",
      "\n",
      "Fold: 11  Epoch: 682  Training loss = 4.0377  Validation loss = 3.5899  \n",
      "\n",
      "Fold: 11  Epoch: 683  Training loss = 4.0373  Validation loss = 3.5897  \n",
      "\n",
      "Fold: 11  Epoch: 684  Training loss = 4.0370  Validation loss = 3.5894  \n",
      "\n",
      "Fold: 11  Epoch: 685  Training loss = 4.0366  Validation loss = 3.5892  \n",
      "\n",
      "Fold: 11  Epoch: 686  Training loss = 4.0363  Validation loss = 3.5889  \n",
      "\n",
      "Fold: 11  Epoch: 687  Training loss = 4.0362  Validation loss = 3.5888  \n",
      "\n",
      "Fold: 11  Epoch: 688  Training loss = 4.0359  Validation loss = 3.5885  \n",
      "\n",
      "Fold: 11  Epoch: 689  Training loss = 4.0356  Validation loss = 3.5883  \n",
      "\n",
      "Fold: 11  Epoch: 690  Training loss = 4.0353  Validation loss = 3.5880  \n",
      "\n",
      "Fold: 11  Epoch: 691  Training loss = 4.0349  Validation loss = 3.5877  \n",
      "\n",
      "Fold: 11  Epoch: 692  Training loss = 4.0344  Validation loss = 3.5874  \n",
      "\n",
      "Fold: 11  Epoch: 693  Training loss = 4.0341  Validation loss = 3.5871  \n",
      "\n",
      "Fold: 11  Epoch: 694  Training loss = 4.0337  Validation loss = 3.5868  \n",
      "\n",
      "Fold: 11  Epoch: 695  Training loss = 4.0334  Validation loss = 3.5866  \n",
      "\n",
      "Fold: 11  Epoch: 696  Training loss = 4.0330  Validation loss = 3.5863  \n",
      "\n",
      "Fold: 11  Epoch: 697  Training loss = 4.0326  Validation loss = 3.5860  \n",
      "\n",
      "Fold: 11  Epoch: 698  Training loss = 4.0323  Validation loss = 3.5858  \n",
      "\n",
      "Fold: 11  Epoch: 699  Training loss = 4.0320  Validation loss = 3.5854  \n",
      "\n",
      "Fold: 11  Epoch: 700  Training loss = 4.0317  Validation loss = 3.5852  \n",
      "\n",
      "Fold: 11  Epoch: 701  Training loss = 4.0315  Validation loss = 3.5850  \n",
      "\n",
      "Fold: 11  Epoch: 702  Training loss = 4.0310  Validation loss = 3.5847  \n",
      "\n",
      "Fold: 11  Epoch: 703  Training loss = 4.0308  Validation loss = 3.5844  \n",
      "\n",
      "Fold: 11  Epoch: 704  Training loss = 4.0305  Validation loss = 3.5842  \n",
      "\n",
      "Fold: 11  Epoch: 705  Training loss = 4.0302  Validation loss = 3.5839  \n",
      "\n",
      "Fold: 11  Epoch: 706  Training loss = 4.0297  Validation loss = 3.5836  \n",
      "\n",
      "Fold: 11  Epoch: 707  Training loss = 4.0293  Validation loss = 3.5833  \n",
      "\n",
      "Fold: 11  Epoch: 708  Training loss = 4.0289  Validation loss = 3.5831  \n",
      "\n",
      "Fold: 11  Epoch: 709  Training loss = 4.0285  Validation loss = 3.5828  \n",
      "\n",
      "Fold: 11  Epoch: 710  Training loss = 4.0282  Validation loss = 3.5825  \n",
      "\n",
      "Fold: 11  Epoch: 711  Training loss = 4.0280  Validation loss = 3.5823  \n",
      "\n",
      "Fold: 11  Epoch: 712  Training loss = 4.0277  Validation loss = 3.5821  \n",
      "\n",
      "Fold: 11  Epoch: 713  Training loss = 4.0273  Validation loss = 3.5818  \n",
      "\n",
      "Fold: 11  Epoch: 714  Training loss = 4.0270  Validation loss = 3.5816  \n",
      "\n",
      "Fold: 11  Epoch: 715  Training loss = 4.0268  Validation loss = 3.5814  \n",
      "\n",
      "Fold: 11  Epoch: 716  Training loss = 4.0264  Validation loss = 3.5811  \n",
      "\n",
      "Fold: 11  Epoch: 717  Training loss = 4.0261  Validation loss = 3.5808  \n",
      "\n",
      "Fold: 11  Epoch: 718  Training loss = 4.0257  Validation loss = 3.5805  \n",
      "\n",
      "Fold: 11  Epoch: 719  Training loss = 4.0252  Validation loss = 3.5803  \n",
      "\n",
      "Fold: 11  Epoch: 720  Training loss = 4.0248  Validation loss = 3.5800  \n",
      "\n",
      "Fold: 11  Epoch: 721  Training loss = 4.0243  Validation loss = 3.5797  \n",
      "\n",
      "Fold: 11  Epoch: 722  Training loss = 4.0242  Validation loss = 3.5795  \n",
      "\n",
      "Fold: 11  Epoch: 723  Training loss = 4.0238  Validation loss = 3.5792  \n",
      "\n",
      "Fold: 11  Epoch: 724  Training loss = 4.0236  Validation loss = 3.5790  \n",
      "\n",
      "Fold: 11  Epoch: 725  Training loss = 4.0233  Validation loss = 3.5787  \n",
      "\n",
      "Fold: 11  Epoch: 726  Training loss = 4.0230  Validation loss = 3.5784  \n",
      "\n",
      "Fold: 11  Epoch: 727  Training loss = 4.0226  Validation loss = 3.5782  \n",
      "\n",
      "Fold: 11  Epoch: 728  Training loss = 4.0223  Validation loss = 3.5779  \n",
      "\n",
      "Fold: 11  Epoch: 729  Training loss = 4.0220  Validation loss = 3.5776  \n",
      "\n",
      "Fold: 11  Epoch: 730  Training loss = 4.0218  Validation loss = 3.5774  \n",
      "\n",
      "Fold: 11  Epoch: 731  Training loss = 4.0214  Validation loss = 3.5772  \n",
      "\n",
      "Fold: 11  Epoch: 732  Training loss = 4.0211  Validation loss = 3.5769  \n",
      "\n",
      "Fold: 11  Epoch: 733  Training loss = 4.0206  Validation loss = 3.5767  \n",
      "\n",
      "Fold: 11  Epoch: 734  Training loss = 4.0202  Validation loss = 3.5764  \n",
      "\n",
      "Fold: 11  Epoch: 735  Training loss = 4.0198  Validation loss = 3.5761  \n",
      "\n",
      "Fold: 11  Epoch: 736  Training loss = 4.0195  Validation loss = 3.5759  \n",
      "\n",
      "Fold: 11  Epoch: 737  Training loss = 4.0192  Validation loss = 3.5757  \n",
      "\n",
      "Fold: 11  Epoch: 738  Training loss = 4.0189  Validation loss = 3.5754  \n",
      "\n",
      "Fold: 11  Epoch: 739  Training loss = 4.0185  Validation loss = 3.5751  \n",
      "\n",
      "Fold: 11  Epoch: 740  Training loss = 4.0183  Validation loss = 3.5749  \n",
      "\n",
      "Fold: 11  Epoch: 741  Training loss = 4.0181  Validation loss = 3.5747  \n",
      "\n",
      "Fold: 11  Epoch: 742  Training loss = 4.0179  Validation loss = 3.5745  \n",
      "\n",
      "Fold: 11  Epoch: 743  Training loss = 4.0174  Validation loss = 3.5741  \n",
      "\n",
      "Fold: 11  Epoch: 744  Training loss = 4.0172  Validation loss = 3.5739  \n",
      "\n",
      "Fold: 11  Epoch: 745  Training loss = 4.0167  Validation loss = 3.5737  \n",
      "\n",
      "Fold: 11  Epoch: 746  Training loss = 4.0163  Validation loss = 3.5734  \n",
      "\n",
      "Fold: 11  Epoch: 747  Training loss = 4.0159  Validation loss = 3.5731  \n",
      "\n",
      "Fold: 11  Epoch: 748  Training loss = 4.0156  Validation loss = 3.5729  \n",
      "\n",
      "Fold: 11  Epoch: 749  Training loss = 4.0152  Validation loss = 3.5726  \n",
      "\n",
      "Fold: 11  Epoch: 750  Training loss = 4.0148  Validation loss = 3.5723  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 750  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 4.1018  Validation loss = 5.0948  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 4.1015  Validation loss = 5.0945  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 4.1012  Validation loss = 5.0940  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 4.1009  Validation loss = 5.0936  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 4.1005  Validation loss = 5.0932  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 4.1001  Validation loss = 5.0926  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 4.0998  Validation loss = 5.0922  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 4.0996  Validation loss = 5.0918  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 4.0993  Validation loss = 5.0915  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 4.0991  Validation loss = 5.0913  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 4.0988  Validation loss = 5.0909  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 4.0985  Validation loss = 5.0906  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 4.0979  Validation loss = 5.0898  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 4.0976  Validation loss = 5.0894  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 4.0971  Validation loss = 5.0889  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 4.0966  Validation loss = 5.0883  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 4.0963  Validation loss = 5.0879  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 4.0960  Validation loss = 5.0874  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 4.0953  Validation loss = 5.0867  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 4.0948  Validation loss = 5.0861  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 4.0944  Validation loss = 5.0857  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 4.0940  Validation loss = 5.0852  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 4.0934  Validation loss = 5.0845  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 4.0931  Validation loss = 5.0841  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 4.0928  Validation loss = 5.0837  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 4.0924  Validation loss = 5.0833  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 4.0920  Validation loss = 5.0829  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 4.0916  Validation loss = 5.0824  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 4.0914  Validation loss = 5.0822  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 4.0910  Validation loss = 5.0817  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 4.0907  Validation loss = 5.0813  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 4.0903  Validation loss = 5.0807  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 4.0900  Validation loss = 5.0804  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 4.0897  Validation loss = 5.0801  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 4.0892  Validation loss = 5.0795  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 4.0889  Validation loss = 5.0791  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 4.0885  Validation loss = 5.0787  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 4.0880  Validation loss = 5.0782  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 4.0877  Validation loss = 5.0778  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 4.0873  Validation loss = 5.0774  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 4.0871  Validation loss = 5.0771  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 4.0866  Validation loss = 5.0765  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 4.0861  Validation loss = 5.0760  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 4.0858  Validation loss = 5.0756  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 4.0854  Validation loss = 5.0752  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 4.0851  Validation loss = 5.0749  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 4.0848  Validation loss = 5.0744  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 4.0844  Validation loss = 5.0741  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 4.0842  Validation loss = 5.0738  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 4.0839  Validation loss = 5.0735  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 4.0836  Validation loss = 5.0732  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 4.0833  Validation loss = 5.0728  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 4.0828  Validation loss = 5.0721  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 4.0823  Validation loss = 5.0717  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 4.0820  Validation loss = 5.0713  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 4.0815  Validation loss = 5.0707  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 4.0812  Validation loss = 5.0703  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 4.0810  Validation loss = 5.0700  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 4.0806  Validation loss = 5.0696  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 4.0801  Validation loss = 5.0690  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 4.0799  Validation loss = 5.0687  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 4.0793  Validation loss = 5.0682  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 4.0789  Validation loss = 5.0676  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 4.0785  Validation loss = 5.0673  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 4.0782  Validation loss = 5.0668  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 4.0779  Validation loss = 5.0665  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 4.0775  Validation loss = 5.0660  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 4.0771  Validation loss = 5.0656  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 4.0767  Validation loss = 5.0651  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 4.0764  Validation loss = 5.0647  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 4.0760  Validation loss = 5.0642  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 4.0758  Validation loss = 5.0639  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 4.0753  Validation loss = 5.0635  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 4.0751  Validation loss = 5.0632  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 4.0746  Validation loss = 5.0627  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 4.0744  Validation loss = 5.0624  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 4.0739  Validation loss = 5.0619  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 4.0734  Validation loss = 5.0614  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 4.0729  Validation loss = 5.0609  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 4.0725  Validation loss = 5.0604  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 4.0722  Validation loss = 5.0600  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 4.0719  Validation loss = 5.0597  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 4.0717  Validation loss = 5.0594  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 4.0713  Validation loss = 5.0590  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 4.0710  Validation loss = 5.0586  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 4.0707  Validation loss = 5.0582  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 4.0704  Validation loss = 5.0578  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 4.0699  Validation loss = 5.0574  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 4.0697  Validation loss = 5.0571  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 4.0694  Validation loss = 5.0567  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 4.0691  Validation loss = 5.0563  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 4.0687  Validation loss = 5.0558  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 4.0684  Validation loss = 5.0555  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 4.0679  Validation loss = 5.0550  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 4.0676  Validation loss = 5.0546  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 4.0674  Validation loss = 5.0544  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 4.0671  Validation loss = 5.0540  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 4.0669  Validation loss = 5.0537  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 4.0666  Validation loss = 5.0533  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 4.0663  Validation loss = 5.0529  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 4.0660  Validation loss = 5.0526  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 4.0658  Validation loss = 5.0523  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 4.0655  Validation loss = 5.0519  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 4.0651  Validation loss = 5.0514  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 4.0648  Validation loss = 5.0511  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 4.0646  Validation loss = 5.0508  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 4.0643  Validation loss = 5.0505  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 4.0640  Validation loss = 5.0502  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 4.0638  Validation loss = 5.0499  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 4.0635  Validation loss = 5.0495  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 4.0633  Validation loss = 5.0493  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 4.0630  Validation loss = 5.0489  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 4.0627  Validation loss = 5.0487  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 4.0624  Validation loss = 5.0483  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 4.0621  Validation loss = 5.0480  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 4.0619  Validation loss = 5.0477  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 4.0617  Validation loss = 5.0474  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 4.0613  Validation loss = 5.0470  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 4.0611  Validation loss = 5.0467  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 4.0608  Validation loss = 5.0463  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 4.0606  Validation loss = 5.0461  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 4.0602  Validation loss = 5.0456  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 4.0600  Validation loss = 5.0454  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 4.0598  Validation loss = 5.0451  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 4.0595  Validation loss = 5.0448  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 4.0593  Validation loss = 5.0445  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 4.0590  Validation loss = 5.0441  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 4.0586  Validation loss = 5.0437  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 4.0584  Validation loss = 5.0434  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 4.0581  Validation loss = 5.0431  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 4.0579  Validation loss = 5.0428  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 4.0575  Validation loss = 5.0423  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 4.0572  Validation loss = 5.0420  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 4.0570  Validation loss = 5.0417  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 4.0567  Validation loss = 5.0413  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 4.0564  Validation loss = 5.0410  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 4.0562  Validation loss = 5.0407  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 4.0559  Validation loss = 5.0403  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 4.0557  Validation loss = 5.0400  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 4.0554  Validation loss = 5.0396  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 4.0552  Validation loss = 5.0394  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 4.0550  Validation loss = 5.0391  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 4.0548  Validation loss = 5.0388  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 4.0545  Validation loss = 5.0385  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 4.0542  Validation loss = 5.0382  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 4.0540  Validation loss = 5.0378  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 4.0537  Validation loss = 5.0375  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 4.0534  Validation loss = 5.0371  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 4.0531  Validation loss = 5.0368  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 4.0529  Validation loss = 5.0365  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 4.0526  Validation loss = 5.0362  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 4.0523  Validation loss = 5.0359  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 4.0521  Validation loss = 5.0356  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 4.0518  Validation loss = 5.0352  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 4.0515  Validation loss = 5.0348  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 4.0513  Validation loss = 5.0346  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 4.0510  Validation loss = 5.0342  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 4.0507  Validation loss = 5.0338  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 4.0504  Validation loss = 5.0335  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 4.0501  Validation loss = 5.0330  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 4.0498  Validation loss = 5.0327  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 4.0496  Validation loss = 5.0324  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 4.0494  Validation loss = 5.0322  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 4.0492  Validation loss = 5.0320  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 4.0490  Validation loss = 5.0316  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 4.0488  Validation loss = 5.0314  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 4.0486  Validation loss = 5.0311  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 4.0483  Validation loss = 5.0308  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 4.0480  Validation loss = 5.0304  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 4.0478  Validation loss = 5.0301  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 4.0475  Validation loss = 5.0297  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 4.0472  Validation loss = 5.0294  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 4.0470  Validation loss = 5.0291  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 4.0467  Validation loss = 5.0287  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 4.0465  Validation loss = 5.0284  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 4.0462  Validation loss = 5.0280  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 4.0459  Validation loss = 5.0277  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 4.0457  Validation loss = 5.0274  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 4.0455  Validation loss = 5.0271  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 4.0453  Validation loss = 5.0269  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 4.0450  Validation loss = 5.0265  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 4.0447  Validation loss = 5.0261  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 4.0445  Validation loss = 5.0258  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 4.0442  Validation loss = 5.0254  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 4.0439  Validation loss = 5.0251  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 4.0437  Validation loss = 5.0247  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 4.0435  Validation loss = 5.0245  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 4.0432  Validation loss = 5.0241  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 4.0430  Validation loss = 5.0238  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 4.0427  Validation loss = 5.0235  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 4.0425  Validation loss = 5.0232  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 4.0422  Validation loss = 5.0228  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 4.0420  Validation loss = 5.0226  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 4.0417  Validation loss = 5.0221  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 4.0415  Validation loss = 5.0218  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 4.0413  Validation loss = 5.0216  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 4.0411  Validation loss = 5.0213  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 4.0408  Validation loss = 5.0209  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 4.0406  Validation loss = 5.0206  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 4.0404  Validation loss = 5.0203  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 4.0401  Validation loss = 5.0200  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 4.0399  Validation loss = 5.0196  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 4.0396  Validation loss = 5.0193  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 4.0394  Validation loss = 5.0190  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 4.0392  Validation loss = 5.0188  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 4.0389  Validation loss = 5.0184  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 4.0387  Validation loss = 5.0180  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 4.0385  Validation loss = 5.0177  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 4.0382  Validation loss = 5.0173  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 4.0379  Validation loss = 5.0169  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 4.0377  Validation loss = 5.0166  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 4.0375  Validation loss = 5.0164  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 4.0373  Validation loss = 5.0161  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 4.0371  Validation loss = 5.0158  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 4.0368  Validation loss = 5.0154  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 4.0366  Validation loss = 5.0151  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 4.0364  Validation loss = 5.0149  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 4.0361  Validation loss = 5.0144  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 4.0359  Validation loss = 5.0141  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 4.0356  Validation loss = 5.0137  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 4.0354  Validation loss = 5.0134  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 4.0352  Validation loss = 5.0131  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 4.0349  Validation loss = 5.0128  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 4.0347  Validation loss = 5.0125  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 4.0344  Validation loss = 5.0121  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 4.0342  Validation loss = 5.0117  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 4.0340  Validation loss = 5.0114  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 4.0337  Validation loss = 5.0111  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 4.0335  Validation loss = 5.0106  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 4.0332  Validation loss = 5.0102  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 4.0330  Validation loss = 5.0099  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 4.0329  Validation loss = 5.0098  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 4.0327  Validation loss = 5.0095  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 4.0323  Validation loss = 5.0090  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 4.0321  Validation loss = 5.0087  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 4.0319  Validation loss = 5.0084  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 4.0317  Validation loss = 5.0080  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 4.0314  Validation loss = 5.0077  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 4.0312  Validation loss = 5.0074  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 4.0309  Validation loss = 5.0070  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 4.0307  Validation loss = 5.0066  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 4.0305  Validation loss = 5.0064  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 4.0303  Validation loss = 5.0061  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 4.0301  Validation loss = 5.0059  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 4.0299  Validation loss = 5.0055  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 4.0296  Validation loss = 5.0052  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 4.0294  Validation loss = 5.0049  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 4.0292  Validation loss = 5.0045  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 4.0289  Validation loss = 5.0042  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 4.0287  Validation loss = 5.0039  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 4.0284  Validation loss = 5.0036  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 4.0282  Validation loss = 5.0033  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 4.0280  Validation loss = 5.0029  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 4.0278  Validation loss = 5.0027  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 4.0276  Validation loss = 5.0023  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 4.0274  Validation loss = 5.0020  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 4.0271  Validation loss = 5.0016  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 4.0269  Validation loss = 5.0013  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 4.0267  Validation loss = 5.0010  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 4.0264  Validation loss = 5.0007  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 4.0262  Validation loss = 5.0004  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 4.0259  Validation loss = 5.0000  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 4.0258  Validation loss = 4.9998  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 4.0256  Validation loss = 4.9995  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 4.0254  Validation loss = 4.9993  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 4.0252  Validation loss = 4.9990  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 4.0250  Validation loss = 4.9988  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 4.0248  Validation loss = 4.9985  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 4.0246  Validation loss = 4.9983  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 4.0244  Validation loss = 4.9980  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 4.0242  Validation loss = 4.9977  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 4.0240  Validation loss = 4.9973  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 4.0237  Validation loss = 4.9969  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 4.0234  Validation loss = 4.9965  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 4.0232  Validation loss = 4.9962  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 4.0229  Validation loss = 4.9958  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 4.0227  Validation loss = 4.9954  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 4.0224  Validation loss = 4.9951  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 4.0222  Validation loss = 4.9947  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 4.0220  Validation loss = 4.9944  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 4.0218  Validation loss = 4.9941  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 4.0216  Validation loss = 4.9938  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 4.0214  Validation loss = 4.9936  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 4.0212  Validation loss = 4.9934  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 4.0210  Validation loss = 4.9930  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 4.0207  Validation loss = 4.9926  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 4.0205  Validation loss = 4.9924  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 4.0203  Validation loss = 4.9921  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 4.0201  Validation loss = 4.9919  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 4.0199  Validation loss = 4.9915  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 4.0196  Validation loss = 4.9912  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 4.0195  Validation loss = 4.9910  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 4.0193  Validation loss = 4.9907  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 4.0191  Validation loss = 4.9905  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 4.0189  Validation loss = 4.9902  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 4.0187  Validation loss = 4.9899  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 4.0185  Validation loss = 4.9896  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 4.0182  Validation loss = 4.9893  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 4.0181  Validation loss = 4.9890  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 4.0178  Validation loss = 4.9887  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 4.0176  Validation loss = 4.9884  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 4.0174  Validation loss = 4.9881  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 4.0171  Validation loss = 4.9877  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 4.0169  Validation loss = 4.9875  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 4.0167  Validation loss = 4.9872  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 4.0165  Validation loss = 4.9869  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 4.0163  Validation loss = 4.9865  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 4.0160  Validation loss = 4.9861  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 4.0158  Validation loss = 4.9858  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 4.0157  Validation loss = 4.9855  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 4.0154  Validation loss = 4.9851  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 4.0152  Validation loss = 4.9848  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 4.0149  Validation loss = 4.9844  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 4.0146  Validation loss = 4.9840  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 4.0144  Validation loss = 4.9837  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 4.0142  Validation loss = 4.9834  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 4.0139  Validation loss = 4.9830  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 4.0137  Validation loss = 4.9827  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 4.0134  Validation loss = 4.9823  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 4.0131  Validation loss = 4.9818  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 4.0129  Validation loss = 4.9816  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 4.0127  Validation loss = 4.9813  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 4.0124  Validation loss = 4.9809  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 4.0122  Validation loss = 4.9807  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 4.0120  Validation loss = 4.9805  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 4.0119  Validation loss = 4.9802  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 4.0117  Validation loss = 4.9799  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 4.0114  Validation loss = 4.9797  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 4.0112  Validation loss = 4.9794  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 4.0110  Validation loss = 4.9791  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 4.0108  Validation loss = 4.9788  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 4.0106  Validation loss = 4.9785  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 4.0105  Validation loss = 4.9783  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 4.0103  Validation loss = 4.9779  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 4.0100  Validation loss = 4.9776  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 4.0098  Validation loss = 4.9773  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 4.0096  Validation loss = 4.9770  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 4.0095  Validation loss = 4.9767  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 4.0092  Validation loss = 4.9763  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 4.0090  Validation loss = 4.9761  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 4.0088  Validation loss = 4.9757  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 4.0086  Validation loss = 4.9755  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 4.0083  Validation loss = 4.9751  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 4.0081  Validation loss = 4.9746  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 4.0079  Validation loss = 4.9744  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 4.0077  Validation loss = 4.9741  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 4.0075  Validation loss = 4.9738  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 4.0073  Validation loss = 4.9736  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 4.0071  Validation loss = 4.9733  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 4.0068  Validation loss = 4.9729  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 4.0066  Validation loss = 4.9726  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 4.0064  Validation loss = 4.9723  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 4.0062  Validation loss = 4.9720  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 4.0060  Validation loss = 4.9716  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 4.0058  Validation loss = 4.9713  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 4.0056  Validation loss = 4.9710  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 4.0054  Validation loss = 4.9707  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 4.0052  Validation loss = 4.9703  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 4.0049  Validation loss = 4.9699  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 4.0047  Validation loss = 4.9697  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 4.0045  Validation loss = 4.9694  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 4.0043  Validation loss = 4.9691  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 4.0041  Validation loss = 4.9688  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 4.0039  Validation loss = 4.9684  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 4.0037  Validation loss = 4.9681  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 4.0035  Validation loss = 4.9678  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 4.0032  Validation loss = 4.9674  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 4.0030  Validation loss = 4.9671  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 4.0028  Validation loss = 4.9668  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 4.0026  Validation loss = 4.9665  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 4.0024  Validation loss = 4.9662  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 4.0022  Validation loss = 4.9659  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 4.0020  Validation loss = 4.9655  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 4.0017  Validation loss = 4.9651  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 4.0016  Validation loss = 4.9650  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 4.0014  Validation loss = 4.9647  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 4.0011  Validation loss = 4.9643  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 4.0009  Validation loss = 4.9640  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 4.0007  Validation loss = 4.9637  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 4.0005  Validation loss = 4.9635  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 4.0003  Validation loss = 4.9632  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 4.0001  Validation loss = 4.9628  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 3.9999  Validation loss = 4.9625  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 3.9997  Validation loss = 4.9622  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 3.9995  Validation loss = 4.9619  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 3.9993  Validation loss = 4.9616  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 3.9991  Validation loss = 4.9613  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 3.9988  Validation loss = 4.9610  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 3.9986  Validation loss = 4.9606  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 3.9984  Validation loss = 4.9603  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 3.9982  Validation loss = 4.9601  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 3.9980  Validation loss = 4.9598  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 3.9978  Validation loss = 4.9595  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 3.9976  Validation loss = 4.9592  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 3.9974  Validation loss = 4.9589  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 3.9972  Validation loss = 4.9586  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 3.9970  Validation loss = 4.9583  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 3.9968  Validation loss = 4.9580  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 3.9965  Validation loss = 4.9576  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 3.9964  Validation loss = 4.9573  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 3.9962  Validation loss = 4.9570  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 3.9960  Validation loss = 4.9568  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 3.9958  Validation loss = 4.9565  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 3.9956  Validation loss = 4.9562  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 3.9954  Validation loss = 4.9559  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 3.9952  Validation loss = 4.9555  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 3.9951  Validation loss = 4.9553  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 3.9949  Validation loss = 4.9550  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 3.9946  Validation loss = 4.9546  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 3.9944  Validation loss = 4.9544  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 3.9942  Validation loss = 4.9540  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 3.9939  Validation loss = 4.9536  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 3.9937  Validation loss = 4.9533  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 3.9936  Validation loss = 4.9530  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 3.9934  Validation loss = 4.9527  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 3.9931  Validation loss = 4.9524  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 3.9929  Validation loss = 4.9520  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 3.9926  Validation loss = 4.9516  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 3.9924  Validation loss = 4.9513  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 3.9922  Validation loss = 4.9509  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 3.9920  Validation loss = 4.9506  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 3.9918  Validation loss = 4.9503  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 3.9916  Validation loss = 4.9500  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 3.9914  Validation loss = 4.9498  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 3.9912  Validation loss = 4.9494  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 3.9909  Validation loss = 4.9490  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 3.9907  Validation loss = 4.9487  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 3.9906  Validation loss = 4.9485  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 3.9903  Validation loss = 4.9482  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 3.9902  Validation loss = 4.9480  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 3.9900  Validation loss = 4.9477  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 3.9898  Validation loss = 4.9474  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 3.9896  Validation loss = 4.9471  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 3.9893  Validation loss = 4.9468  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 3.9892  Validation loss = 4.9465  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 3.9890  Validation loss = 4.9463  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 3.9888  Validation loss = 4.9459  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 3.9887  Validation loss = 4.9457  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 3.9884  Validation loss = 4.9453  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 3.9882  Validation loss = 4.9450  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 3.9880  Validation loss = 4.9447  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 3.9878  Validation loss = 4.9444  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 3.9876  Validation loss = 4.9442  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 3.9874  Validation loss = 4.9439  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 3.9872  Validation loss = 4.9436  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 3.9871  Validation loss = 4.9434  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 3.9868  Validation loss = 4.9430  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 3.9867  Validation loss = 4.9427  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 3.9865  Validation loss = 4.9425  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 3.9863  Validation loss = 4.9422  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 3.9861  Validation loss = 4.9420  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 3.9859  Validation loss = 4.9416  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 3.9857  Validation loss = 4.9413  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 3.9854  Validation loss = 4.9410  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 3.9852  Validation loss = 4.9406  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 3.9850  Validation loss = 4.9402  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 3.9847  Validation loss = 4.9398  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 3.9845  Validation loss = 4.9396  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 3.9843  Validation loss = 4.9393  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 3.9841  Validation loss = 4.9390  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 3.9838  Validation loss = 4.9386  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 3.9836  Validation loss = 4.9384  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 3.9834  Validation loss = 4.9380  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 3.9832  Validation loss = 4.9377  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 3.9830  Validation loss = 4.9374  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 3.9828  Validation loss = 4.9370  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 3.9826  Validation loss = 4.9367  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 3.9824  Validation loss = 4.9364  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 3.9821  Validation loss = 4.9361  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 3.9819  Validation loss = 4.9356  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 3.9817  Validation loss = 4.9354  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 3.9815  Validation loss = 4.9351  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 3.9813  Validation loss = 4.9348  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 3.9810  Validation loss = 4.9343  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 3.9808  Validation loss = 4.9340  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 3.9806  Validation loss = 4.9337  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 3.9804  Validation loss = 4.9335  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 3.9802  Validation loss = 4.9331  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 3.9800  Validation loss = 4.9328  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 3.9797  Validation loss = 4.9323  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 3.9795  Validation loss = 4.9320  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 3.9793  Validation loss = 4.9318  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 3.9791  Validation loss = 4.9315  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 3.9789  Validation loss = 4.9312  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 3.9787  Validation loss = 4.9309  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 3.9784  Validation loss = 4.9305  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 3.9782  Validation loss = 4.9301  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 3.9780  Validation loss = 4.9299  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 3.9777  Validation loss = 4.9295  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 3.9775  Validation loss = 4.9292  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 3.9774  Validation loss = 4.9289  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 3.9772  Validation loss = 4.9287  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 3.9770  Validation loss = 4.9284  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 3.9769  Validation loss = 4.9282  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 3.9767  Validation loss = 4.9278  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 3.9764  Validation loss = 4.9275  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 3.9763  Validation loss = 4.9273  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 3.9760  Validation loss = 4.9269  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 3.9757  Validation loss = 4.9264  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 3.9755  Validation loss = 4.9261  \n",
      "\n",
      "Fold: 12  Epoch: 501  Training loss = 3.9753  Validation loss = 4.9259  \n",
      "\n",
      "Fold: 12  Epoch: 502  Training loss = 3.9751  Validation loss = 4.9255  \n",
      "\n",
      "Fold: 12  Epoch: 503  Training loss = 3.9749  Validation loss = 4.9253  \n",
      "\n",
      "Fold: 12  Epoch: 504  Training loss = 3.9747  Validation loss = 4.9249  \n",
      "\n",
      "Fold: 12  Epoch: 505  Training loss = 3.9745  Validation loss = 4.9246  \n",
      "\n",
      "Fold: 12  Epoch: 506  Training loss = 3.9742  Validation loss = 4.9242  \n",
      "\n",
      "Fold: 12  Epoch: 507  Training loss = 3.9739  Validation loss = 4.9238  \n",
      "\n",
      "Fold: 12  Epoch: 508  Training loss = 3.9737  Validation loss = 4.9236  \n",
      "\n",
      "Fold: 12  Epoch: 509  Training loss = 3.9736  Validation loss = 4.9233  \n",
      "\n",
      "Fold: 12  Epoch: 510  Training loss = 3.9734  Validation loss = 4.9231  \n",
      "\n",
      "Fold: 12  Epoch: 511  Training loss = 3.9732  Validation loss = 4.9228  \n",
      "\n",
      "Fold: 12  Epoch: 512  Training loss = 3.9729  Validation loss = 4.9223  \n",
      "\n",
      "Fold: 12  Epoch: 513  Training loss = 3.9727  Validation loss = 4.9220  \n",
      "\n",
      "Fold: 12  Epoch: 514  Training loss = 3.9725  Validation loss = 4.9218  \n",
      "\n",
      "Fold: 12  Epoch: 515  Training loss = 3.9723  Validation loss = 4.9214  \n",
      "\n",
      "Fold: 12  Epoch: 516  Training loss = 3.9721  Validation loss = 4.9211  \n",
      "\n",
      "Fold: 12  Epoch: 517  Training loss = 3.9718  Validation loss = 4.9208  \n",
      "\n",
      "Fold: 12  Epoch: 518  Training loss = 3.9716  Validation loss = 4.9205  \n",
      "\n",
      "Fold: 12  Epoch: 519  Training loss = 3.9714  Validation loss = 4.9201  \n",
      "\n",
      "Fold: 12  Epoch: 520  Training loss = 3.9712  Validation loss = 4.9199  \n",
      "\n",
      "Fold: 12  Epoch: 521  Training loss = 3.9711  Validation loss = 4.9197  \n",
      "\n",
      "Fold: 12  Epoch: 522  Training loss = 3.9708  Validation loss = 4.9194  \n",
      "\n",
      "Fold: 12  Epoch: 523  Training loss = 3.9706  Validation loss = 4.9191  \n",
      "\n",
      "Fold: 12  Epoch: 524  Training loss = 3.9704  Validation loss = 4.9188  \n",
      "\n",
      "Fold: 12  Epoch: 525  Training loss = 3.9702  Validation loss = 4.9185  \n",
      "\n",
      "Fold: 12  Epoch: 526  Training loss = 3.9700  Validation loss = 4.9182  \n",
      "\n",
      "Fold: 12  Epoch: 527  Training loss = 3.9698  Validation loss = 4.9180  \n",
      "\n",
      "Fold: 12  Epoch: 528  Training loss = 3.9696  Validation loss = 4.9177  \n",
      "\n",
      "Fold: 12  Epoch: 529  Training loss = 3.9693  Validation loss = 4.9173  \n",
      "\n",
      "Fold: 12  Epoch: 530  Training loss = 3.9691  Validation loss = 4.9170  \n",
      "\n",
      "Fold: 12  Epoch: 531  Training loss = 3.9689  Validation loss = 4.9167  \n",
      "\n",
      "Fold: 12  Epoch: 532  Training loss = 3.9687  Validation loss = 4.9164  \n",
      "\n",
      "Fold: 12  Epoch: 533  Training loss = 3.9685  Validation loss = 4.9160  \n",
      "\n",
      "Fold: 12  Epoch: 534  Training loss = 3.9683  Validation loss = 4.9158  \n",
      "\n",
      "Fold: 12  Epoch: 535  Training loss = 3.9681  Validation loss = 4.9154  \n",
      "\n",
      "Fold: 12  Epoch: 536  Training loss = 3.9679  Validation loss = 4.9152  \n",
      "\n",
      "Fold: 12  Epoch: 537  Training loss = 3.9676  Validation loss = 4.9147  \n",
      "\n",
      "Fold: 12  Epoch: 538  Training loss = 3.9674  Validation loss = 4.9143  \n",
      "\n",
      "Fold: 12  Epoch: 539  Training loss = 3.9672  Validation loss = 4.9140  \n",
      "\n",
      "Fold: 12  Epoch: 540  Training loss = 3.9670  Validation loss = 4.9138  \n",
      "\n",
      "Fold: 12  Epoch: 541  Training loss = 3.9667  Validation loss = 4.9133  \n",
      "\n",
      "Fold: 12  Epoch: 542  Training loss = 3.9665  Validation loss = 4.9129  \n",
      "\n",
      "Fold: 12  Epoch: 543  Training loss = 3.9662  Validation loss = 4.9126  \n",
      "\n",
      "Fold: 12  Epoch: 544  Training loss = 3.9660  Validation loss = 4.9123  \n",
      "\n",
      "Fold: 12  Epoch: 545  Training loss = 3.9658  Validation loss = 4.9120  \n",
      "\n",
      "Fold: 12  Epoch: 546  Training loss = 3.9655  Validation loss = 4.9116  \n",
      "\n",
      "Fold: 12  Epoch: 547  Training loss = 3.9653  Validation loss = 4.9113  \n",
      "\n",
      "Fold: 12  Epoch: 548  Training loss = 3.9650  Validation loss = 4.9109  \n",
      "\n",
      "Fold: 12  Epoch: 549  Training loss = 3.9648  Validation loss = 4.9107  \n",
      "\n",
      "Fold: 12  Epoch: 550  Training loss = 3.9645  Validation loss = 4.9103  \n",
      "\n",
      "Fold: 12  Epoch: 551  Training loss = 3.9644  Validation loss = 4.9101  \n",
      "\n",
      "Fold: 12  Epoch: 552  Training loss = 3.9642  Validation loss = 4.9099  \n",
      "\n",
      "Fold: 12  Epoch: 553  Training loss = 3.9640  Validation loss = 4.9095  \n",
      "\n",
      "Fold: 12  Epoch: 554  Training loss = 3.9638  Validation loss = 4.9092  \n",
      "\n",
      "Fold: 12  Epoch: 555  Training loss = 3.9636  Validation loss = 4.9090  \n",
      "\n",
      "Fold: 12  Epoch: 556  Training loss = 3.9634  Validation loss = 4.9087  \n",
      "\n",
      "Fold: 12  Epoch: 557  Training loss = 3.9632  Validation loss = 4.9084  \n",
      "\n",
      "Fold: 12  Epoch: 558  Training loss = 3.9629  Validation loss = 4.9080  \n",
      "\n",
      "Fold: 12  Epoch: 559  Training loss = 3.9627  Validation loss = 4.9077  \n",
      "\n",
      "Fold: 12  Epoch: 560  Training loss = 3.9625  Validation loss = 4.9073  \n",
      "\n",
      "Fold: 12  Epoch: 561  Training loss = 3.9622  Validation loss = 4.9070  \n",
      "\n",
      "Fold: 12  Epoch: 562  Training loss = 3.9620  Validation loss = 4.9067  \n",
      "\n",
      "Fold: 12  Epoch: 563  Training loss = 3.9618  Validation loss = 4.9064  \n",
      "\n",
      "Fold: 12  Epoch: 564  Training loss = 3.9616  Validation loss = 4.9062  \n",
      "\n",
      "Fold: 12  Epoch: 565  Training loss = 3.9615  Validation loss = 4.9060  \n",
      "\n",
      "Fold: 12  Epoch: 566  Training loss = 3.9613  Validation loss = 4.9057  \n",
      "\n",
      "Fold: 12  Epoch: 567  Training loss = 3.9610  Validation loss = 4.9053  \n",
      "\n",
      "Fold: 12  Epoch: 568  Training loss = 3.9609  Validation loss = 4.9051  \n",
      "\n",
      "Fold: 12  Epoch: 569  Training loss = 3.9607  Validation loss = 4.9049  \n",
      "\n",
      "Fold: 12  Epoch: 570  Training loss = 3.9604  Validation loss = 4.9045  \n",
      "\n",
      "Fold: 12  Epoch: 571  Training loss = 3.9602  Validation loss = 4.9043  \n",
      "\n",
      "Fold: 12  Epoch: 572  Training loss = 3.9600  Validation loss = 4.9040  \n",
      "\n",
      "Fold: 12  Epoch: 573  Training loss = 3.9599  Validation loss = 4.9037  \n",
      "\n",
      "Fold: 12  Epoch: 574  Training loss = 3.9596  Validation loss = 4.9034  \n",
      "\n",
      "Fold: 12  Epoch: 575  Training loss = 3.9594  Validation loss = 4.9031  \n",
      "\n",
      "Fold: 12  Epoch: 576  Training loss = 3.9591  Validation loss = 4.9026  \n",
      "\n",
      "Fold: 12  Epoch: 577  Training loss = 3.9589  Validation loss = 4.9023  \n",
      "\n",
      "Fold: 12  Epoch: 578  Training loss = 3.9587  Validation loss = 4.9021  \n",
      "\n",
      "Fold: 12  Epoch: 579  Training loss = 3.9585  Validation loss = 4.9017  \n",
      "\n",
      "Fold: 12  Epoch: 580  Training loss = 3.9583  Validation loss = 4.9014  \n",
      "\n",
      "Fold: 12  Epoch: 581  Training loss = 3.9580  Validation loss = 4.9010  \n",
      "\n",
      "Fold: 12  Epoch: 582  Training loss = 3.9578  Validation loss = 4.9008  \n",
      "\n",
      "Fold: 12  Epoch: 583  Training loss = 3.9576  Validation loss = 4.9005  \n",
      "\n",
      "Fold: 12  Epoch: 584  Training loss = 3.9574  Validation loss = 4.9002  \n",
      "\n",
      "Fold: 12  Epoch: 585  Training loss = 3.9572  Validation loss = 4.8999  \n",
      "\n",
      "Fold: 12  Epoch: 586  Training loss = 3.9570  Validation loss = 4.8996  \n",
      "\n",
      "Fold: 12  Epoch: 587  Training loss = 3.9567  Validation loss = 4.8993  \n",
      "\n",
      "Fold: 12  Epoch: 588  Training loss = 3.9565  Validation loss = 4.8990  \n",
      "\n",
      "Fold: 12  Epoch: 589  Training loss = 3.9563  Validation loss = 4.8988  \n",
      "\n",
      "Fold: 12  Epoch: 590  Training loss = 3.9562  Validation loss = 4.8986  \n",
      "\n",
      "Fold: 12  Epoch: 591  Training loss = 3.9559  Validation loss = 4.8982  \n",
      "\n",
      "Fold: 12  Epoch: 592  Training loss = 3.9558  Validation loss = 4.8980  \n",
      "\n",
      "Fold: 12  Epoch: 593  Training loss = 3.9555  Validation loss = 4.8977  \n",
      "\n",
      "Fold: 12  Epoch: 594  Training loss = 3.9553  Validation loss = 4.8975  \n",
      "\n",
      "Fold: 12  Epoch: 595  Training loss = 3.9551  Validation loss = 4.8971  \n",
      "\n",
      "Fold: 12  Epoch: 596  Training loss = 3.9549  Validation loss = 4.8969  \n",
      "\n",
      "Fold: 12  Epoch: 597  Training loss = 3.9546  Validation loss = 4.8966  \n",
      "\n",
      "Fold: 12  Epoch: 598  Training loss = 3.9545  Validation loss = 4.8963  \n",
      "\n",
      "Fold: 12  Epoch: 599  Training loss = 3.9543  Validation loss = 4.8960  \n",
      "\n",
      "Fold: 12  Epoch: 600  Training loss = 3.9541  Validation loss = 4.8956  \n",
      "\n",
      "Fold: 12  Epoch: 601  Training loss = 3.9539  Validation loss = 4.8954  \n",
      "\n",
      "Fold: 12  Epoch: 602  Training loss = 3.9536  Validation loss = 4.8951  \n",
      "\n",
      "Fold: 12  Epoch: 603  Training loss = 3.9534  Validation loss = 4.8947  \n",
      "\n",
      "Fold: 12  Epoch: 604  Training loss = 3.9532  Validation loss = 4.8944  \n",
      "\n",
      "Fold: 12  Epoch: 605  Training loss = 3.9530  Validation loss = 4.8942  \n",
      "\n",
      "Fold: 12  Epoch: 606  Training loss = 3.9528  Validation loss = 4.8939  \n",
      "\n",
      "Fold: 12  Epoch: 607  Training loss = 3.9526  Validation loss = 4.8936  \n",
      "\n",
      "Fold: 12  Epoch: 608  Training loss = 3.9524  Validation loss = 4.8934  \n",
      "\n",
      "Fold: 12  Epoch: 609  Training loss = 3.9522  Validation loss = 4.8931  \n",
      "\n",
      "Fold: 12  Epoch: 610  Training loss = 3.9520  Validation loss = 4.8928  \n",
      "\n",
      "Fold: 12  Epoch: 611  Training loss = 3.9517  Validation loss = 4.8924  \n",
      "\n",
      "Fold: 12  Epoch: 612  Training loss = 3.9514  Validation loss = 4.8920  \n",
      "\n",
      "Fold: 12  Epoch: 613  Training loss = 3.9512  Validation loss = 4.8917  \n",
      "\n",
      "Fold: 12  Epoch: 614  Training loss = 3.9511  Validation loss = 4.8915  \n",
      "\n",
      "Fold: 12  Epoch: 615  Training loss = 3.9508  Validation loss = 4.8912  \n",
      "\n",
      "Fold: 12  Epoch: 616  Training loss = 3.9505  Validation loss = 4.8908  \n",
      "\n",
      "Fold: 12  Epoch: 617  Training loss = 3.9502  Validation loss = 4.8904  \n",
      "\n",
      "Fold: 12  Epoch: 618  Training loss = 3.9500  Validation loss = 4.8902  \n",
      "\n",
      "Fold: 12  Epoch: 619  Training loss = 3.9498  Validation loss = 4.8898  \n",
      "\n",
      "Fold: 12  Epoch: 620  Training loss = 3.9495  Validation loss = 4.8894  \n",
      "\n",
      "Fold: 12  Epoch: 621  Training loss = 3.9493  Validation loss = 4.8891  \n",
      "\n",
      "Fold: 12  Epoch: 622  Training loss = 3.9490  Validation loss = 4.8888  \n",
      "\n",
      "Fold: 12  Epoch: 623  Training loss = 3.9488  Validation loss = 4.8885  \n",
      "\n",
      "Fold: 12  Epoch: 624  Training loss = 3.9486  Validation loss = 4.8882  \n",
      "\n",
      "Fold: 12  Epoch: 625  Training loss = 3.9484  Validation loss = 4.8880  \n",
      "\n",
      "Fold: 12  Epoch: 626  Training loss = 3.9482  Validation loss = 4.8877  \n",
      "\n",
      "Fold: 12  Epoch: 627  Training loss = 3.9480  Validation loss = 4.8874  \n",
      "\n",
      "Fold: 12  Epoch: 628  Training loss = 3.9477  Validation loss = 4.8871  \n",
      "\n",
      "Fold: 12  Epoch: 629  Training loss = 3.9475  Validation loss = 4.8866  \n",
      "\n",
      "Fold: 12  Epoch: 630  Training loss = 3.9472  Validation loss = 4.8863  \n",
      "\n",
      "Fold: 12  Epoch: 631  Training loss = 3.9470  Validation loss = 4.8860  \n",
      "\n",
      "Fold: 12  Epoch: 632  Training loss = 3.9468  Validation loss = 4.8857  \n",
      "\n",
      "Fold: 12  Epoch: 633  Training loss = 3.9466  Validation loss = 4.8855  \n",
      "\n",
      "Fold: 12  Epoch: 634  Training loss = 3.9464  Validation loss = 4.8852  \n",
      "\n",
      "Fold: 12  Epoch: 635  Training loss = 3.9462  Validation loss = 4.8848  \n",
      "\n",
      "Fold: 12  Epoch: 636  Training loss = 3.9460  Validation loss = 4.8845  \n",
      "\n",
      "Fold: 12  Epoch: 637  Training loss = 3.9458  Validation loss = 4.8842  \n",
      "\n",
      "Fold: 12  Epoch: 638  Training loss = 3.9456  Validation loss = 4.8840  \n",
      "\n",
      "Fold: 12  Epoch: 639  Training loss = 3.9452  Validation loss = 4.8835  \n",
      "\n",
      "Fold: 12  Epoch: 640  Training loss = 3.9450  Validation loss = 4.8832  \n",
      "\n",
      "Fold: 12  Epoch: 641  Training loss = 3.9447  Validation loss = 4.8828  \n",
      "\n",
      "Fold: 12  Epoch: 642  Training loss = 3.9444  Validation loss = 4.8824  \n",
      "\n",
      "Fold: 12  Epoch: 643  Training loss = 3.9442  Validation loss = 4.8820  \n",
      "\n",
      "Fold: 12  Epoch: 644  Training loss = 3.9439  Validation loss = 4.8816  \n",
      "\n",
      "Fold: 12  Epoch: 645  Training loss = 3.9435  Validation loss = 4.8812  \n",
      "\n",
      "Fold: 12  Epoch: 646  Training loss = 3.9434  Validation loss = 4.8810  \n",
      "\n",
      "Fold: 12  Epoch: 647  Training loss = 3.9431  Validation loss = 4.8806  \n",
      "\n",
      "Fold: 12  Epoch: 648  Training loss = 3.9429  Validation loss = 4.8803  \n",
      "\n",
      "Fold: 12  Epoch: 649  Training loss = 3.9426  Validation loss = 4.8800  \n",
      "\n",
      "Fold: 12  Epoch: 650  Training loss = 3.9424  Validation loss = 4.8798  \n",
      "\n",
      "Fold: 12  Epoch: 651  Training loss = 3.9422  Validation loss = 4.8796  \n",
      "\n",
      "Fold: 12  Epoch: 652  Training loss = 3.9420  Validation loss = 4.8793  \n",
      "\n",
      "Fold: 12  Epoch: 653  Training loss = 3.9417  Validation loss = 4.8790  \n",
      "\n",
      "Fold: 12  Epoch: 654  Training loss = 3.9414  Validation loss = 4.8786  \n",
      "\n",
      "Fold: 12  Epoch: 655  Training loss = 3.9411  Validation loss = 4.8782  \n",
      "\n",
      "Fold: 12  Epoch: 656  Training loss = 3.9409  Validation loss = 4.8779  \n",
      "\n",
      "Fold: 12  Epoch: 657  Training loss = 3.9406  Validation loss = 4.8776  \n",
      "\n",
      "Fold: 12  Epoch: 658  Training loss = 3.9404  Validation loss = 4.8773  \n",
      "\n",
      "Fold: 12  Epoch: 659  Training loss = 3.9401  Validation loss = 4.8770  \n",
      "\n",
      "Fold: 12  Epoch: 660  Training loss = 3.9398  Validation loss = 4.8767  \n",
      "\n",
      "Fold: 12  Epoch: 661  Training loss = 3.9396  Validation loss = 4.8764  \n",
      "\n",
      "Fold: 12  Epoch: 662  Training loss = 3.9393  Validation loss = 4.8760  \n",
      "\n",
      "Fold: 12  Epoch: 663  Training loss = 3.9389  Validation loss = 4.8756  \n",
      "\n",
      "Fold: 12  Epoch: 664  Training loss = 3.9386  Validation loss = 4.8753  \n",
      "\n",
      "Fold: 12  Epoch: 665  Training loss = 3.9384  Validation loss = 4.8751  \n",
      "\n",
      "Fold: 12  Epoch: 666  Training loss = 3.9381  Validation loss = 4.8747  \n",
      "\n",
      "Fold: 12  Epoch: 667  Training loss = 3.9377  Validation loss = 4.8743  \n",
      "\n",
      "Fold: 12  Epoch: 668  Training loss = 3.9375  Validation loss = 4.8740  \n",
      "\n",
      "Fold: 12  Epoch: 669  Training loss = 3.9372  Validation loss = 4.8737  \n",
      "\n",
      "Fold: 12  Epoch: 670  Training loss = 3.9369  Validation loss = 4.8733  \n",
      "\n",
      "Fold: 12  Epoch: 671  Training loss = 3.9367  Validation loss = 4.8731  \n",
      "\n",
      "Fold: 12  Epoch: 672  Training loss = 3.9365  Validation loss = 4.8728  \n",
      "\n",
      "Fold: 12  Epoch: 673  Training loss = 3.9363  Validation loss = 4.8727  \n",
      "\n",
      "Fold: 12  Epoch: 674  Training loss = 3.9361  Validation loss = 4.8723  \n",
      "\n",
      "Fold: 12  Epoch: 675  Training loss = 3.9358  Validation loss = 4.8720  \n",
      "\n",
      "Fold: 12  Epoch: 676  Training loss = 3.9355  Validation loss = 4.8717  \n",
      "\n",
      "Fold: 12  Epoch: 677  Training loss = 3.9353  Validation loss = 4.8714  \n",
      "\n",
      "Fold: 12  Epoch: 678  Training loss = 3.9350  Validation loss = 4.8711  \n",
      "\n",
      "Fold: 12  Epoch: 679  Training loss = 3.9347  Validation loss = 4.8707  \n",
      "\n",
      "Fold: 12  Epoch: 680  Training loss = 3.9344  Validation loss = 4.8705  \n",
      "\n",
      "Fold: 12  Epoch: 681  Training loss = 3.9342  Validation loss = 4.8702  \n",
      "\n",
      "Fold: 12  Epoch: 682  Training loss = 3.9339  Validation loss = 4.8699  \n",
      "\n",
      "Fold: 12  Epoch: 683  Training loss = 3.9335  Validation loss = 4.8696  \n",
      "\n",
      "Fold: 12  Epoch: 684  Training loss = 3.9331  Validation loss = 4.8690  \n",
      "\n",
      "Fold: 12  Epoch: 685  Training loss = 3.9329  Validation loss = 4.8688  \n",
      "\n",
      "Fold: 12  Epoch: 686  Training loss = 3.9325  Validation loss = 4.8685  \n",
      "\n",
      "Fold: 12  Epoch: 687  Training loss = 3.9322  Validation loss = 4.8682  \n",
      "\n",
      "Fold: 12  Epoch: 688  Training loss = 3.9321  Validation loss = 4.8680  \n",
      "\n",
      "Fold: 12  Epoch: 689  Training loss = 3.9318  Validation loss = 4.8677  \n",
      "\n",
      "Fold: 12  Epoch: 690  Training loss = 3.9315  Validation loss = 4.8674  \n",
      "\n",
      "Fold: 12  Epoch: 691  Training loss = 3.9313  Validation loss = 4.8672  \n",
      "\n",
      "Fold: 12  Epoch: 692  Training loss = 3.9311  Validation loss = 4.8669  \n",
      "\n",
      "Fold: 12  Epoch: 693  Training loss = 3.9308  Validation loss = 4.8666  \n",
      "\n",
      "Fold: 12  Epoch: 694  Training loss = 3.9305  Validation loss = 4.8663  \n",
      "\n",
      "Fold: 12  Epoch: 695  Training loss = 3.9303  Validation loss = 4.8660  \n",
      "\n",
      "Fold: 12  Epoch: 696  Training loss = 3.9301  Validation loss = 4.8657  \n",
      "\n",
      "Fold: 12  Epoch: 697  Training loss = 3.9298  Validation loss = 4.8654  \n",
      "\n",
      "Fold: 12  Epoch: 698  Training loss = 3.9293  Validation loss = 4.8649  \n",
      "\n",
      "Fold: 12  Epoch: 699  Training loss = 3.9289  Validation loss = 4.8645  \n",
      "\n",
      "Fold: 12  Epoch: 700  Training loss = 3.9286  Validation loss = 4.8642  \n",
      "\n",
      "Fold: 12  Epoch: 701  Training loss = 3.9284  Validation loss = 4.8640  \n",
      "\n",
      "Fold: 12  Epoch: 702  Training loss = 3.9280  Validation loss = 4.8637  \n",
      "\n",
      "Fold: 12  Epoch: 703  Training loss = 3.9276  Validation loss = 4.8634  \n",
      "\n",
      "Fold: 12  Epoch: 704  Training loss = 3.9273  Validation loss = 4.8631  \n",
      "\n",
      "Fold: 12  Epoch: 705  Training loss = 3.9268  Validation loss = 4.8626  \n",
      "\n",
      "Fold: 12  Epoch: 706  Training loss = 3.9265  Validation loss = 4.8623  \n",
      "\n",
      "Fold: 12  Epoch: 707  Training loss = 3.9259  Validation loss = 4.8619  \n",
      "\n",
      "Fold: 12  Epoch: 708  Training loss = 3.9256  Validation loss = 4.8615  \n",
      "\n",
      "Fold: 12  Epoch: 709  Training loss = 3.9253  Validation loss = 4.8612  \n",
      "\n",
      "Fold: 12  Epoch: 710  Training loss = 3.9246  Validation loss = 4.8607  \n",
      "\n",
      "Fold: 12  Epoch: 711  Training loss = 3.9244  Validation loss = 4.8605  \n",
      "\n",
      "Fold: 12  Epoch: 712  Training loss = 3.9242  Validation loss = 4.8603  \n",
      "\n",
      "Fold: 12  Epoch: 713  Training loss = 3.9237  Validation loss = 4.8598  \n",
      "\n",
      "Fold: 12  Epoch: 714  Training loss = 3.9233  Validation loss = 4.8596  \n",
      "\n",
      "Fold: 12  Epoch: 715  Training loss = 3.9228  Validation loss = 4.8592  \n",
      "\n",
      "Fold: 12  Epoch: 716  Training loss = 3.9226  Validation loss = 4.8590  \n",
      "\n",
      "Fold: 12  Epoch: 717  Training loss = 3.9223  Validation loss = 4.8587  \n",
      "\n",
      "Fold: 12  Epoch: 718  Training loss = 3.9220  Validation loss = 4.8585  \n",
      "\n",
      "Fold: 12  Epoch: 719  Training loss = 3.9217  Validation loss = 4.8582  \n",
      "\n",
      "Fold: 12  Epoch: 720  Training loss = 3.9212  Validation loss = 4.8579  \n",
      "\n",
      "Fold: 12  Epoch: 721  Training loss = 3.9208  Validation loss = 4.8576  \n",
      "\n",
      "Fold: 12  Epoch: 722  Training loss = 3.9204  Validation loss = 4.8572  \n",
      "\n",
      "Fold: 12  Epoch: 723  Training loss = 3.9201  Validation loss = 4.8570  \n",
      "\n",
      "Fold: 12  Epoch: 724  Training loss = 3.9195  Validation loss = 4.8566  \n",
      "\n",
      "Fold: 12  Epoch: 725  Training loss = 3.9189  Validation loss = 4.8562  \n",
      "\n",
      "Fold: 12  Epoch: 726  Training loss = 3.9183  Validation loss = 4.8559  \n",
      "\n",
      "Fold: 12  Epoch: 727  Training loss = 3.9176  Validation loss = 4.8555  \n",
      "\n",
      "Fold: 12  Epoch: 728  Training loss = 3.9173  Validation loss = 4.8552  \n",
      "\n",
      "Fold: 12  Epoch: 729  Training loss = 3.9167  Validation loss = 4.8549  \n",
      "\n",
      "Fold: 12  Epoch: 730  Training loss = 3.9165  Validation loss = 4.8546  \n",
      "\n",
      "Fold: 12  Epoch: 731  Training loss = 3.9158  Validation loss = 4.8544  \n",
      "\n",
      "Fold: 12  Epoch: 732  Training loss = 3.9154  Validation loss = 4.8541  \n",
      "\n",
      "Fold: 12  Epoch: 733  Training loss = 3.9151  Validation loss = 4.8538  \n",
      "\n",
      "Fold: 12  Epoch: 734  Training loss = 3.9148  Validation loss = 4.8536  \n",
      "\n",
      "Fold: 12  Epoch: 735  Training loss = 3.9147  Validation loss = 4.8534  \n",
      "\n",
      "Fold: 12  Epoch: 736  Training loss = 3.9139  Validation loss = 4.8531  \n",
      "\n",
      "Fold: 12  Epoch: 737  Training loss = 3.9131  Validation loss = 4.8527  \n",
      "\n",
      "Fold: 12  Epoch: 738  Training loss = 3.9124  Validation loss = 4.8524  \n",
      "\n",
      "Fold: 12  Epoch: 739  Training loss = 3.9120  Validation loss = 4.8521  \n",
      "\n",
      "Fold: 12  Epoch: 740  Training loss = 3.9111  Validation loss = 4.8516  \n",
      "\n",
      "Fold: 12  Epoch: 741  Training loss = 3.9109  Validation loss = 4.8513  \n",
      "\n",
      "Fold: 12  Epoch: 742  Training loss = 3.9105  Validation loss = 4.8510  \n",
      "\n",
      "Fold: 12  Epoch: 743  Training loss = 3.9103  Validation loss = 4.8507  \n",
      "\n",
      "Fold: 12  Epoch: 744  Training loss = 3.9098  Validation loss = 4.8504  \n",
      "\n",
      "Fold: 12  Epoch: 745  Training loss = 3.9090  Validation loss = 4.8501  \n",
      "\n",
      "Fold: 12  Epoch: 746  Training loss = 3.9086  Validation loss = 4.8498  \n",
      "\n",
      "Fold: 12  Epoch: 747  Training loss = 3.9081  Validation loss = 4.8495  \n",
      "\n",
      "Fold: 12  Epoch: 748  Training loss = 3.9078  Validation loss = 4.8491  \n",
      "\n",
      "Fold: 12  Epoch: 749  Training loss = 3.9071  Validation loss = 4.8487  \n",
      "\n",
      "Fold: 12  Epoch: 750  Training loss = 3.9065  Validation loss = 4.8484  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 750  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 4.0745  Validation loss = 6.9299  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 4.0736  Validation loss = 6.9295  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 4.0730  Validation loss = 6.9290  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 4.0725  Validation loss = 6.9286  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 4.0720  Validation loss = 6.9283  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 4.0715  Validation loss = 6.9280  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 4.0711  Validation loss = 6.9276  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 4.0705  Validation loss = 6.9273  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 4.0699  Validation loss = 6.9269  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 4.0695  Validation loss = 6.9265  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 4.0687  Validation loss = 6.9261  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 4.0683  Validation loss = 6.9258  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 4.0673  Validation loss = 6.9254  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 4.0665  Validation loss = 6.9250  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 4.0661  Validation loss = 6.9245  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 4.0653  Validation loss = 6.9241  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 4.0649  Validation loss = 6.9237  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 4.0645  Validation loss = 6.9235  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 4.0640  Validation loss = 6.9231  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 4.0636  Validation loss = 6.9227  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 4.0632  Validation loss = 6.9223  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 4.0625  Validation loss = 6.9219  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 4.0620  Validation loss = 6.9216  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 4.0616  Validation loss = 6.9211  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 4.0610  Validation loss = 6.9208  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 4.0608  Validation loss = 6.9205  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 4.0604  Validation loss = 6.9201  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 4.0597  Validation loss = 6.9197  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 4.0590  Validation loss = 6.9193  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 4.0584  Validation loss = 6.9189  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 4.0579  Validation loss = 6.9185  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 4.0577  Validation loss = 6.9181  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 4.0571  Validation loss = 6.9177  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 4.0566  Validation loss = 6.9174  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 4.0560  Validation loss = 6.9170  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 4.0557  Validation loss = 6.9166  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 4.0554  Validation loss = 6.9162  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 4.0550  Validation loss = 6.9158  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 4.0546  Validation loss = 6.9154  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 4.0543  Validation loss = 6.9151  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 4.0539  Validation loss = 6.9147  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 4.0534  Validation loss = 6.9143  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 4.0531  Validation loss = 6.9140  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 4.0526  Validation loss = 6.9135  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 4.0522  Validation loss = 6.9131  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 4.0517  Validation loss = 6.9126  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 4.0514  Validation loss = 6.9122  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 4.0509  Validation loss = 6.9119  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 4.0505  Validation loss = 6.9115  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 4.0500  Validation loss = 6.9111  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 4.0496  Validation loss = 6.9107  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 4.0493  Validation loss = 6.9103  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 4.0489  Validation loss = 6.9099  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 4.0486  Validation loss = 6.9096  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 4.0484  Validation loss = 6.9092  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 4.0481  Validation loss = 6.9087  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 4.0476  Validation loss = 6.9084  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 4.0473  Validation loss = 6.9080  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 4.0470  Validation loss = 6.9077  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 4.0466  Validation loss = 6.9072  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 4.0462  Validation loss = 6.9069  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 4.0458  Validation loss = 6.9065  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 4.0455  Validation loss = 6.9061  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 4.0451  Validation loss = 6.9058  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 4.0449  Validation loss = 6.9054  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 4.0446  Validation loss = 6.9051  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 4.0443  Validation loss = 6.9048  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 4.0438  Validation loss = 6.9044  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 4.0435  Validation loss = 6.9040  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 4.0431  Validation loss = 6.9036  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 4.0428  Validation loss = 6.9032  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 4.0424  Validation loss = 6.9028  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 4.0420  Validation loss = 6.9024  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 4.0417  Validation loss = 6.9021  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 4.0414  Validation loss = 6.9018  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 4.0411  Validation loss = 6.9014  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 4.0409  Validation loss = 6.9011  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 4.0406  Validation loss = 6.9007  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 4.0402  Validation loss = 6.9003  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 4.0398  Validation loss = 6.8998  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 4.0394  Validation loss = 6.8994  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 4.0390  Validation loss = 6.8990  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 4.0387  Validation loss = 6.8986  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 4.0385  Validation loss = 6.8982  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 4.0382  Validation loss = 6.8979  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 4.0379  Validation loss = 6.8975  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 4.0374  Validation loss = 6.8970  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 4.0372  Validation loss = 6.8967  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 4.0370  Validation loss = 6.8964  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 4.0367  Validation loss = 6.8960  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 4.0364  Validation loss = 6.8956  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 4.0360  Validation loss = 6.8951  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 4.0357  Validation loss = 6.8948  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 4.0354  Validation loss = 6.8944  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 4.0351  Validation loss = 6.8940  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 4.0348  Validation loss = 6.8937  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 4.0345  Validation loss = 6.8934  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 4.0342  Validation loss = 6.8930  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 4.0339  Validation loss = 6.8926  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 4.0336  Validation loss = 6.8922  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 4.0333  Validation loss = 6.8918  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 4.0331  Validation loss = 6.8914  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 4.0328  Validation loss = 6.8910  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 4.0325  Validation loss = 6.8905  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 4.0323  Validation loss = 6.8902  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 4.0319  Validation loss = 6.8898  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 4.0316  Validation loss = 6.8894  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 4.0314  Validation loss = 6.8890  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 4.0311  Validation loss = 6.8887  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 4.0309  Validation loss = 6.8884  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 4.0307  Validation loss = 6.8881  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 4.0303  Validation loss = 6.8876  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 4.0300  Validation loss = 6.8873  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 4.0297  Validation loss = 6.8869  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 4.0294  Validation loss = 6.8865  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 4.0292  Validation loss = 6.8861  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 4.0287  Validation loss = 6.8856  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 4.0285  Validation loss = 6.8852  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 4.0281  Validation loss = 6.8848  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 4.0279  Validation loss = 6.8844  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 4.0275  Validation loss = 6.8839  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 4.0272  Validation loss = 6.8836  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 4.0270  Validation loss = 6.8832  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 4.0266  Validation loss = 6.8828  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 4.0264  Validation loss = 6.8824  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 4.0261  Validation loss = 6.8820  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 4.0258  Validation loss = 6.8817  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 4.0256  Validation loss = 6.8813  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 4.0253  Validation loss = 6.8809  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 4.0250  Validation loss = 6.8805  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 4.0248  Validation loss = 6.8802  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 4.0245  Validation loss = 6.8798  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 4.0243  Validation loss = 6.8795  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 4.0240  Validation loss = 6.8791  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 4.0238  Validation loss = 6.8787  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 4.0235  Validation loss = 6.8783  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 4.0232  Validation loss = 6.8779  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 4.0229  Validation loss = 6.8775  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 4.0227  Validation loss = 6.8772  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 4.0224  Validation loss = 6.8768  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 4.0222  Validation loss = 6.8764  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 4.0219  Validation loss = 6.8761  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 4.0217  Validation loss = 6.8757  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 4.0213  Validation loss = 6.8753  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 4.0211  Validation loss = 6.8749  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 4.0208  Validation loss = 6.8745  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 4.0205  Validation loss = 6.8741  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 4.0203  Validation loss = 6.8737  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 4.0200  Validation loss = 6.8734  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 4.0198  Validation loss = 6.8730  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 4.0196  Validation loss = 6.8726  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 4.0193  Validation loss = 6.8723  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 4.0190  Validation loss = 6.8718  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 4.0187  Validation loss = 6.8714  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 4.0184  Validation loss = 6.8710  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 4.0181  Validation loss = 6.8706  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 4.0179  Validation loss = 6.8702  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 4.0176  Validation loss = 6.8698  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 4.0173  Validation loss = 6.8694  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 4.0171  Validation loss = 6.8691  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 4.0168  Validation loss = 6.8687  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 4.0165  Validation loss = 6.8683  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 4.0162  Validation loss = 6.8678  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 4.0160  Validation loss = 6.8675  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 4.0157  Validation loss = 6.8670  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 4.0155  Validation loss = 6.8667  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 4.0153  Validation loss = 6.8663  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 4.0149  Validation loss = 6.8659  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 4.0147  Validation loss = 6.8656  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 4.0145  Validation loss = 6.8652  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 4.0142  Validation loss = 6.8647  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 4.0139  Validation loss = 6.8644  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 4.0137  Validation loss = 6.8639  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 4.0134  Validation loss = 6.8636  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 4.0132  Validation loss = 6.8633  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 4.0129  Validation loss = 6.8629  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 4.0127  Validation loss = 6.8625  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 4.0124  Validation loss = 6.8621  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 4.0122  Validation loss = 6.8617  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 4.0119  Validation loss = 6.8614  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 4.0116  Validation loss = 6.8609  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 4.0113  Validation loss = 6.8605  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 4.0111  Validation loss = 6.8602  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 4.0109  Validation loss = 6.8599  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 4.0107  Validation loss = 6.8596  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 4.0105  Validation loss = 6.8593  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 4.0103  Validation loss = 6.8590  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 4.0100  Validation loss = 6.8586  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 4.0098  Validation loss = 6.8582  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 4.0096  Validation loss = 6.8579  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 4.0093  Validation loss = 6.8574  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 4.0091  Validation loss = 6.8571  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 4.0089  Validation loss = 6.8568  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 4.0087  Validation loss = 6.8565  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 4.0084  Validation loss = 6.8560  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 4.0081  Validation loss = 6.8557  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 4.0079  Validation loss = 6.8553  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 4.0076  Validation loss = 6.8549  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 4.0074  Validation loss = 6.8546  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 4.0072  Validation loss = 6.8542  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 4.0069  Validation loss = 6.8538  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 4.0066  Validation loss = 6.8533  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 4.0063  Validation loss = 6.8529  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 4.0060  Validation loss = 6.8525  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 4.0057  Validation loss = 6.8521  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 4.0055  Validation loss = 6.8517  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 4.0052  Validation loss = 6.8513  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 4.0050  Validation loss = 6.8509  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 4.0048  Validation loss = 6.8506  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 4.0046  Validation loss = 6.8503  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 4.0043  Validation loss = 6.8500  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 4.0040  Validation loss = 6.8496  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 4.0038  Validation loss = 6.8492  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 4.0036  Validation loss = 6.8489  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 4.0034  Validation loss = 6.8486  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 4.0031  Validation loss = 6.8482  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 4.0029  Validation loss = 6.8479  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 4.0027  Validation loss = 6.8475  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 4.0024  Validation loss = 6.8472  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 4.0022  Validation loss = 6.8468  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 4.0020  Validation loss = 6.8465  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 4.0017  Validation loss = 6.8460  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 4.0015  Validation loss = 6.8457  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 4.0012  Validation loss = 6.8453  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 4.0009  Validation loss = 6.8449  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 4.0006  Validation loss = 6.8444  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 4.0004  Validation loss = 6.8441  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 4.0002  Validation loss = 6.8438  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 4.0000  Validation loss = 6.8434  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 3.9998  Validation loss = 6.8431  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 3.9995  Validation loss = 6.8427  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 3.9993  Validation loss = 6.8423  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 3.9991  Validation loss = 6.8420  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 3.9988  Validation loss = 6.8416  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 3.9986  Validation loss = 6.8413  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 3.9984  Validation loss = 6.8410  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 3.9982  Validation loss = 6.8407  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 3.9979  Validation loss = 6.8402  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 3.9977  Validation loss = 6.8398  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 3.9975  Validation loss = 6.8395  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 3.9972  Validation loss = 6.8391  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 3.9969  Validation loss = 6.8387  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 3.9967  Validation loss = 6.8383  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 3.9964  Validation loss = 6.8380  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 3.9962  Validation loss = 6.8377  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 3.9959  Validation loss = 6.8372  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 3.9957  Validation loss = 6.8369  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 3.9955  Validation loss = 6.8366  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 3.9952  Validation loss = 6.8362  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 3.9950  Validation loss = 6.8358  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 3.9947  Validation loss = 6.8354  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 3.9945  Validation loss = 6.8351  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 3.9943  Validation loss = 6.8348  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 3.9941  Validation loss = 6.8344  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 3.9939  Validation loss = 6.8341  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 3.9935  Validation loss = 6.8336  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 3.9933  Validation loss = 6.8332  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 3.9931  Validation loss = 6.8328  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 3.9928  Validation loss = 6.8325  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 3.9926  Validation loss = 6.8321  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 3.9923  Validation loss = 6.8317  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 3.9920  Validation loss = 6.8313  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 3.9918  Validation loss = 6.8309  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 3.9916  Validation loss = 6.8306  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 3.9913  Validation loss = 6.8302  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 3.9910  Validation loss = 6.8298  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 3.9908  Validation loss = 6.8294  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 3.9906  Validation loss = 6.8291  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 3.9904  Validation loss = 6.8288  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 3.9902  Validation loss = 6.8285  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 3.9899  Validation loss = 6.8280  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 3.9897  Validation loss = 6.8277  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 3.9895  Validation loss = 6.8273  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 3.9892  Validation loss = 6.8270  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 3.9890  Validation loss = 6.8266  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 3.9887  Validation loss = 6.8262  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 3.9885  Validation loss = 6.8259  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 3.9882  Validation loss = 6.8254  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 3.9880  Validation loss = 6.8251  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 3.9877  Validation loss = 6.8247  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 3.9875  Validation loss = 6.8244  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 3.9872  Validation loss = 6.8240  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 3.9870  Validation loss = 6.8235  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 3.9867  Validation loss = 6.8232  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 3.9864  Validation loss = 6.8227  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 3.9862  Validation loss = 6.8223  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 3.9859  Validation loss = 6.8219  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 3.9856  Validation loss = 6.8214  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 3.9853  Validation loss = 6.8210  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 3.9851  Validation loss = 6.8206  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 3.9849  Validation loss = 6.8203  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 3.9846  Validation loss = 6.8199  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 3.9843  Validation loss = 6.8195  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 3.9841  Validation loss = 6.8191  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 3.9838  Validation loss = 6.8187  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 3.9836  Validation loss = 6.8184  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 3.9834  Validation loss = 6.8181  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 3.9832  Validation loss = 6.8177  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 3.9830  Validation loss = 6.8174  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 3.9827  Validation loss = 6.8170  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 3.9825  Validation loss = 6.8166  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 3.9822  Validation loss = 6.8162  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 3.9820  Validation loss = 6.8159  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 3.9817  Validation loss = 6.8155  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 3.9815  Validation loss = 6.8151  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 3.9813  Validation loss = 6.8148  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 3.9811  Validation loss = 6.8144  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 3.9808  Validation loss = 6.8140  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 3.9805  Validation loss = 6.8136  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 3.9802  Validation loss = 6.8131  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 3.9799  Validation loss = 6.8126  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 3.9797  Validation loss = 6.8123  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 3.9794  Validation loss = 6.8119  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 3.9792  Validation loss = 6.8116  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 3.9790  Validation loss = 6.8112  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 3.9787  Validation loss = 6.8108  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 3.9785  Validation loss = 6.8105  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 3.9782  Validation loss = 6.8100  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 3.9780  Validation loss = 6.8096  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 3.9777  Validation loss = 6.8093  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 3.9775  Validation loss = 6.8089  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 3.9773  Validation loss = 6.8085  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 3.9770  Validation loss = 6.8081  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 3.9768  Validation loss = 6.8078  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 3.9765  Validation loss = 6.8074  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 3.9763  Validation loss = 6.8070  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 3.9760  Validation loss = 6.8066  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 3.9757  Validation loss = 6.8061  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 3.9755  Validation loss = 6.8058  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 3.9753  Validation loss = 6.8054  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 3.9750  Validation loss = 6.8050  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 3.9748  Validation loss = 6.8047  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 3.9745  Validation loss = 6.8042  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 3.9743  Validation loss = 6.8038  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 3.9740  Validation loss = 6.8034  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 3.9737  Validation loss = 6.8030  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 3.9735  Validation loss = 6.8026  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 3.9732  Validation loss = 6.8022  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 3.9730  Validation loss = 6.8019  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 3.9728  Validation loss = 6.8015  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 3.9725  Validation loss = 6.8011  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 3.9722  Validation loss = 6.8007  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 3.9720  Validation loss = 6.8004  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 3.9718  Validation loss = 6.8000  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 3.9716  Validation loss = 6.7997  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 3.9714  Validation loss = 6.7994  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 3.9711  Validation loss = 6.7990  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 3.9708  Validation loss = 6.7985  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 3.9706  Validation loss = 6.7982  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 3.9704  Validation loss = 6.7978  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 3.9701  Validation loss = 6.7974  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 3.9699  Validation loss = 6.7970  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 3.9696  Validation loss = 6.7966  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 3.9694  Validation loss = 6.7963  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 3.9691  Validation loss = 6.7959  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 3.9689  Validation loss = 6.7955  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 3.9687  Validation loss = 6.7951  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 3.9684  Validation loss = 6.7947  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 3.9682  Validation loss = 6.7944  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 3.9680  Validation loss = 6.7941  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 3.9678  Validation loss = 6.7938  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 3.9675  Validation loss = 6.7934  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 3.9673  Validation loss = 6.7930  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 3.9671  Validation loss = 6.7927  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 3.9669  Validation loss = 6.7924  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 3.9667  Validation loss = 6.7920  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 3.9665  Validation loss = 6.7917  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 3.9663  Validation loss = 6.7913  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 3.9661  Validation loss = 6.7911  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 3.9659  Validation loss = 6.7907  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 3.9657  Validation loss = 6.7904  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 3.9655  Validation loss = 6.7901  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 3.9653  Validation loss = 6.7898  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 3.9651  Validation loss = 6.7894  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 3.9648  Validation loss = 6.7890  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 3.9646  Validation loss = 6.7886  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 3.9644  Validation loss = 6.7883  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 3.9641  Validation loss = 6.7879  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 3.9639  Validation loss = 6.7875  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 3.9636  Validation loss = 6.7871  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 3.9633  Validation loss = 6.7867  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 3.9631  Validation loss = 6.7863  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 3.9628  Validation loss = 6.7859  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 3.9626  Validation loss = 6.7855  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 3.9623  Validation loss = 6.7850  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 3.9621  Validation loss = 6.7847  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 3.9619  Validation loss = 6.7844  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 3.9617  Validation loss = 6.7840  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 3.9614  Validation loss = 6.7836  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 3.9612  Validation loss = 6.7833  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 3.9609  Validation loss = 6.7828  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 3.9607  Validation loss = 6.7825  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 3.9605  Validation loss = 6.7822  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 3.9603  Validation loss = 6.7818  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 3.9601  Validation loss = 6.7815  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 3.9598  Validation loss = 6.7811  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 3.9596  Validation loss = 6.7808  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 3.9594  Validation loss = 6.7804  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 3.9591  Validation loss = 6.7800  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 3.9589  Validation loss = 6.7796  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 3.9587  Validation loss = 6.7793  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 3.9584  Validation loss = 6.7789  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 3.9581  Validation loss = 6.7785  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 3.9579  Validation loss = 6.7780  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 3.9576  Validation loss = 6.7777  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 3.9574  Validation loss = 6.7773  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 3.9572  Validation loss = 6.7770  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 3.9570  Validation loss = 6.7766  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 3.9568  Validation loss = 6.7763  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 3.9565  Validation loss = 6.7759  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 3.9563  Validation loss = 6.7755  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 3.9560  Validation loss = 6.7750  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 3.9557  Validation loss = 6.7746  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 3.9555  Validation loss = 6.7743  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 3.9553  Validation loss = 6.7740  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 3.9551  Validation loss = 6.7736  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 3.9549  Validation loss = 6.7733  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 3.9546  Validation loss = 6.7729  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 3.9544  Validation loss = 6.7725  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 3.9542  Validation loss = 6.7722  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 3.9540  Validation loss = 6.7718  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 3.9537  Validation loss = 6.7715  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 3.9535  Validation loss = 6.7711  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 3.9533  Validation loss = 6.7708  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 3.9531  Validation loss = 6.7705  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 3.9529  Validation loss = 6.7701  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 3.9527  Validation loss = 6.7697  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 3.9525  Validation loss = 6.7694  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 3.9523  Validation loss = 6.7691  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 3.9521  Validation loss = 6.7688  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 3.9518  Validation loss = 6.7684  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 3.9516  Validation loss = 6.7680  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 3.9514  Validation loss = 6.7676  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 3.9512  Validation loss = 6.7673  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 3.9509  Validation loss = 6.7669  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 3.9506  Validation loss = 6.7665  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 3.9505  Validation loss = 6.7662  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 3.9503  Validation loss = 6.7659  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 3.9501  Validation loss = 6.7656  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 3.9498  Validation loss = 6.7652  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 3.9496  Validation loss = 6.7648  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 3.9494  Validation loss = 6.7644  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 3.9491  Validation loss = 6.7641  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 3.9489  Validation loss = 6.7637  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 3.9487  Validation loss = 6.7634  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 3.9485  Validation loss = 6.7631  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 3.9483  Validation loss = 6.7628  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 3.9481  Validation loss = 6.7625  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 3.9478  Validation loss = 6.7620  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 3.9477  Validation loss = 6.7618  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 3.9474  Validation loss = 6.7614  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 3.9472  Validation loss = 6.7610  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 3.9469  Validation loss = 6.7605  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 3.9466  Validation loss = 6.7601  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 3.9464  Validation loss = 6.7598  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 3.9462  Validation loss = 6.7594  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 3.9459  Validation loss = 6.7590  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 3.9457  Validation loss = 6.7586  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 3.9455  Validation loss = 6.7583  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 3.9452  Validation loss = 6.7579  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 3.9450  Validation loss = 6.7575  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 3.9448  Validation loss = 6.7572  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 3.9446  Validation loss = 6.7569  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 3.9443  Validation loss = 6.7564  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 3.9440  Validation loss = 6.7560  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 3.9438  Validation loss = 6.7555  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 3.9436  Validation loss = 6.7553  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 3.9434  Validation loss = 6.7549  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 3.9432  Validation loss = 6.7546  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 3.9430  Validation loss = 6.7543  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 3.9428  Validation loss = 6.7540  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 3.9426  Validation loss = 6.7536  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 3.9424  Validation loss = 6.7533  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 3.9422  Validation loss = 6.7529  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 3.9419  Validation loss = 6.7526  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 3.9417  Validation loss = 6.7522  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 3.9415  Validation loss = 6.7519  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 3.9413  Validation loss = 6.7515  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 3.9410  Validation loss = 6.7511  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 3.9408  Validation loss = 6.7508  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 3.9405  Validation loss = 6.7504  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 3.9403  Validation loss = 6.7500  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 3.9401  Validation loss = 6.7497  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 3.9398  Validation loss = 6.7493  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 3.9395  Validation loss = 6.7488  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 3.9393  Validation loss = 6.7484  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 3.9390  Validation loss = 6.7479  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 3.9388  Validation loss = 6.7476  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 3.9386  Validation loss = 6.7473  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 3.9384  Validation loss = 6.7469  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 3.9382  Validation loss = 6.7466  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 3.9380  Validation loss = 6.7463  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 3.9378  Validation loss = 6.7459  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 3.9375  Validation loss = 6.7456  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 3.9374  Validation loss = 6.7453  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 3.9371  Validation loss = 6.7449  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 3.9369  Validation loss = 6.7445  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 3.9367  Validation loss = 6.7442  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 3.9364  Validation loss = 6.7437  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 3.9361  Validation loss = 6.7432  \n",
      "\n",
      "Fold: 13  Epoch: 501  Training loss = 3.9359  Validation loss = 6.7430  \n",
      "\n",
      "Fold: 13  Epoch: 502  Training loss = 3.9357  Validation loss = 6.7426  \n",
      "\n",
      "Fold: 13  Epoch: 503  Training loss = 3.9355  Validation loss = 6.7422  \n",
      "\n",
      "Fold: 13  Epoch: 504  Training loss = 3.9352  Validation loss = 6.7419  \n",
      "\n",
      "Fold: 13  Epoch: 505  Training loss = 3.9351  Validation loss = 6.7416  \n",
      "\n",
      "Fold: 13  Epoch: 506  Training loss = 3.9348  Validation loss = 6.7412  \n",
      "\n",
      "Fold: 13  Epoch: 507  Training loss = 3.9346  Validation loss = 6.7408  \n",
      "\n",
      "Fold: 13  Epoch: 508  Training loss = 3.9344  Validation loss = 6.7404  \n",
      "\n",
      "Fold: 13  Epoch: 509  Training loss = 3.9341  Validation loss = 6.7401  \n",
      "\n",
      "Fold: 13  Epoch: 510  Training loss = 3.9339  Validation loss = 6.7397  \n",
      "\n",
      "Fold: 13  Epoch: 511  Training loss = 3.9336  Validation loss = 6.7393  \n",
      "\n",
      "Fold: 13  Epoch: 512  Training loss = 3.9334  Validation loss = 6.7390  \n",
      "\n",
      "Fold: 13  Epoch: 513  Training loss = 3.9332  Validation loss = 6.7386  \n",
      "\n",
      "Fold: 13  Epoch: 514  Training loss = 3.9329  Validation loss = 6.7381  \n",
      "\n",
      "Fold: 13  Epoch: 515  Training loss = 3.9326  Validation loss = 6.7378  \n",
      "\n",
      "Fold: 13  Epoch: 516  Training loss = 3.9323  Validation loss = 6.7373  \n",
      "\n",
      "Fold: 13  Epoch: 517  Training loss = 3.9320  Validation loss = 6.7370  \n",
      "\n",
      "Fold: 13  Epoch: 518  Training loss = 3.9317  Validation loss = 6.7365  \n",
      "\n",
      "Fold: 13  Epoch: 519  Training loss = 3.9314  Validation loss = 6.7361  \n",
      "\n",
      "Fold: 13  Epoch: 520  Training loss = 3.9312  Validation loss = 6.7359  \n",
      "\n",
      "Fold: 13  Epoch: 521  Training loss = 3.9309  Validation loss = 6.7355  \n",
      "\n",
      "Fold: 13  Epoch: 522  Training loss = 3.9302  Validation loss = 6.7351  \n",
      "\n",
      "Fold: 13  Epoch: 523  Training loss = 3.9291  Validation loss = 6.7347  \n",
      "\n",
      "Fold: 13  Epoch: 524  Training loss = 3.9282  Validation loss = 6.7343  \n",
      "\n",
      "Fold: 13  Epoch: 525  Training loss = 3.9276  Validation loss = 6.7338  \n",
      "\n",
      "Fold: 13  Epoch: 526  Training loss = 3.9272  Validation loss = 6.7334  \n",
      "\n",
      "Fold: 13  Epoch: 527  Training loss = 3.9269  Validation loss = 6.7331  \n",
      "\n",
      "Fold: 13  Epoch: 528  Training loss = 3.9267  Validation loss = 6.7328  \n",
      "\n",
      "Fold: 13  Epoch: 529  Training loss = 3.9264  Validation loss = 6.7324  \n",
      "\n",
      "Fold: 13  Epoch: 530  Training loss = 3.9262  Validation loss = 6.7321  \n",
      "\n",
      "Fold: 13  Epoch: 531  Training loss = 3.9259  Validation loss = 6.7318  \n",
      "\n",
      "Fold: 13  Epoch: 532  Training loss = 3.9257  Validation loss = 6.7314  \n",
      "\n",
      "Fold: 13  Epoch: 533  Training loss = 3.9255  Validation loss = 6.7311  \n",
      "\n",
      "Fold: 13  Epoch: 534  Training loss = 3.9253  Validation loss = 6.7308  \n",
      "\n",
      "Fold: 13  Epoch: 535  Training loss = 3.9251  Validation loss = 6.7304  \n",
      "\n",
      "Fold: 13  Epoch: 536  Training loss = 3.9248  Validation loss = 6.7300  \n",
      "\n",
      "Fold: 13  Epoch: 537  Training loss = 3.9246  Validation loss = 6.7297  \n",
      "\n",
      "Fold: 13  Epoch: 538  Training loss = 3.9244  Validation loss = 6.7293  \n",
      "\n",
      "Fold: 13  Epoch: 539  Training loss = 3.9242  Validation loss = 6.7290  \n",
      "\n",
      "Fold: 13  Epoch: 540  Training loss = 3.9239  Validation loss = 6.7286  \n",
      "\n",
      "Fold: 13  Epoch: 541  Training loss = 3.9237  Validation loss = 6.7282  \n",
      "\n",
      "Fold: 13  Epoch: 542  Training loss = 3.9235  Validation loss = 6.7279  \n",
      "\n",
      "Fold: 13  Epoch: 543  Training loss = 3.9232  Validation loss = 6.7275  \n",
      "\n",
      "Fold: 13  Epoch: 544  Training loss = 3.9229  Validation loss = 6.7270  \n",
      "\n",
      "Fold: 13  Epoch: 545  Training loss = 3.9226  Validation loss = 6.7266  \n",
      "\n",
      "Fold: 13  Epoch: 546  Training loss = 3.9224  Validation loss = 6.7262  \n",
      "\n",
      "Fold: 13  Epoch: 547  Training loss = 3.9222  Validation loss = 6.7259  \n",
      "\n",
      "Fold: 13  Epoch: 548  Training loss = 3.9220  Validation loss = 6.7257  \n",
      "\n",
      "Fold: 13  Epoch: 549  Training loss = 3.9219  Validation loss = 6.7254  \n",
      "\n",
      "Fold: 13  Epoch: 550  Training loss = 3.9216  Validation loss = 6.7250  \n",
      "\n",
      "Fold: 13  Epoch: 551  Training loss = 3.9214  Validation loss = 6.7247  \n",
      "\n",
      "Fold: 13  Epoch: 552  Training loss = 3.9212  Validation loss = 6.7243  \n",
      "\n",
      "Fold: 13  Epoch: 553  Training loss = 3.9210  Validation loss = 6.7240  \n",
      "\n",
      "Fold: 13  Epoch: 554  Training loss = 3.9208  Validation loss = 6.7236  \n",
      "\n",
      "Fold: 13  Epoch: 555  Training loss = 3.9205  Validation loss = 6.7232  \n",
      "\n",
      "Fold: 13  Epoch: 556  Training loss = 3.9203  Validation loss = 6.7229  \n",
      "\n",
      "Fold: 13  Epoch: 557  Training loss = 3.9201  Validation loss = 6.7225  \n",
      "\n",
      "Fold: 13  Epoch: 558  Training loss = 3.9198  Validation loss = 6.7221  \n",
      "\n",
      "Fold: 13  Epoch: 559  Training loss = 3.9196  Validation loss = 6.7218  \n",
      "\n",
      "Fold: 13  Epoch: 560  Training loss = 3.9194  Validation loss = 6.7214  \n",
      "\n",
      "Fold: 13  Epoch: 561  Training loss = 3.9191  Validation loss = 6.7210  \n",
      "\n",
      "Fold: 13  Epoch: 562  Training loss = 3.9189  Validation loss = 6.7207  \n",
      "\n",
      "Fold: 13  Epoch: 563  Training loss = 3.9187  Validation loss = 6.7203  \n",
      "\n",
      "Fold: 13  Epoch: 564  Training loss = 3.9184  Validation loss = 6.7199  \n",
      "\n",
      "Fold: 13  Epoch: 565  Training loss = 3.9182  Validation loss = 6.7195  \n",
      "\n",
      "Fold: 13  Epoch: 566  Training loss = 3.9180  Validation loss = 6.7191  \n",
      "\n",
      "Fold: 13  Epoch: 567  Training loss = 3.9177  Validation loss = 6.7188  \n",
      "\n",
      "Fold: 13  Epoch: 568  Training loss = 3.9175  Validation loss = 6.7184  \n",
      "\n",
      "Fold: 13  Epoch: 569  Training loss = 3.9173  Validation loss = 6.7181  \n",
      "\n",
      "Fold: 13  Epoch: 570  Training loss = 3.9170  Validation loss = 6.7176  \n",
      "\n",
      "Fold: 13  Epoch: 571  Training loss = 3.9168  Validation loss = 6.7172  \n",
      "\n",
      "Fold: 13  Epoch: 572  Training loss = 3.9166  Validation loss = 6.7169  \n",
      "\n",
      "Fold: 13  Epoch: 573  Training loss = 3.9164  Validation loss = 6.7166  \n",
      "\n",
      "Fold: 13  Epoch: 574  Training loss = 3.9161  Validation loss = 6.7162  \n",
      "\n",
      "Fold: 13  Epoch: 575  Training loss = 3.9159  Validation loss = 6.7157  \n",
      "\n",
      "Fold: 13  Epoch: 576  Training loss = 3.9156  Validation loss = 6.7154  \n",
      "\n",
      "Fold: 13  Epoch: 577  Training loss = 3.9154  Validation loss = 6.7151  \n",
      "\n",
      "Fold: 13  Epoch: 578  Training loss = 3.9153  Validation loss = 6.7148  \n",
      "\n",
      "Fold: 13  Epoch: 579  Training loss = 3.9151  Validation loss = 6.7144  \n",
      "\n",
      "Fold: 13  Epoch: 580  Training loss = 3.9149  Validation loss = 6.7141  \n",
      "\n",
      "Fold: 13  Epoch: 581  Training loss = 3.9146  Validation loss = 6.7137  \n",
      "\n",
      "Fold: 13  Epoch: 582  Training loss = 3.9144  Validation loss = 6.7134  \n",
      "\n",
      "Fold: 13  Epoch: 583  Training loss = 3.9141  Validation loss = 6.7130  \n",
      "\n",
      "Fold: 13  Epoch: 584  Training loss = 3.9139  Validation loss = 6.7126  \n",
      "\n",
      "Fold: 13  Epoch: 585  Training loss = 3.9137  Validation loss = 6.7123  \n",
      "\n",
      "Fold: 13  Epoch: 586  Training loss = 3.9135  Validation loss = 6.7119  \n",
      "\n",
      "Fold: 13  Epoch: 587  Training loss = 3.9133  Validation loss = 6.7115  \n",
      "\n",
      "Fold: 13  Epoch: 588  Training loss = 3.9130  Validation loss = 6.7112  \n",
      "\n",
      "Fold: 13  Epoch: 589  Training loss = 3.9128  Validation loss = 6.7109  \n",
      "\n",
      "Fold: 13  Epoch: 590  Training loss = 3.9127  Validation loss = 6.7106  \n",
      "\n",
      "Fold: 13  Epoch: 591  Training loss = 3.9124  Validation loss = 6.7102  \n",
      "\n",
      "Fold: 13  Epoch: 592  Training loss = 3.9122  Validation loss = 6.7098  \n",
      "\n",
      "Fold: 13  Epoch: 593  Training loss = 3.9120  Validation loss = 6.7095  \n",
      "\n",
      "Fold: 13  Epoch: 594  Training loss = 3.9118  Validation loss = 6.7092  \n",
      "\n",
      "Fold: 13  Epoch: 595  Training loss = 3.9116  Validation loss = 6.7089  \n",
      "\n",
      "Fold: 13  Epoch: 596  Training loss = 3.9114  Validation loss = 6.7085  \n",
      "\n",
      "Fold: 13  Epoch: 597  Training loss = 3.9112  Validation loss = 6.7082  \n",
      "\n",
      "Fold: 13  Epoch: 598  Training loss = 3.9110  Validation loss = 6.7079  \n",
      "\n",
      "Fold: 13  Epoch: 599  Training loss = 3.9108  Validation loss = 6.7076  \n",
      "\n",
      "Fold: 13  Epoch: 600  Training loss = 3.9106  Validation loss = 6.7072  \n",
      "\n",
      "Fold: 13  Epoch: 601  Training loss = 3.9104  Validation loss = 6.7068  \n",
      "\n",
      "Fold: 13  Epoch: 602  Training loss = 3.9102  Validation loss = 6.7066  \n",
      "\n",
      "Fold: 13  Epoch: 603  Training loss = 3.9099  Validation loss = 6.7062  \n",
      "\n",
      "Fold: 13  Epoch: 604  Training loss = 3.9097  Validation loss = 6.7058  \n",
      "\n",
      "Fold: 13  Epoch: 605  Training loss = 3.9095  Validation loss = 6.7055  \n",
      "\n",
      "Fold: 13  Epoch: 606  Training loss = 3.9093  Validation loss = 6.7051  \n",
      "\n",
      "Fold: 13  Epoch: 607  Training loss = 3.9091  Validation loss = 6.7048  \n",
      "\n",
      "Fold: 13  Epoch: 608  Training loss = 3.9089  Validation loss = 6.7045  \n",
      "\n",
      "Fold: 13  Epoch: 609  Training loss = 3.9086  Validation loss = 6.7041  \n",
      "\n",
      "Fold: 13  Epoch: 610  Training loss = 3.9085  Validation loss = 6.7038  \n",
      "\n",
      "Fold: 13  Epoch: 611  Training loss = 3.9082  Validation loss = 6.7034  \n",
      "\n",
      "Fold: 13  Epoch: 612  Training loss = 3.9080  Validation loss = 6.7031  \n",
      "\n",
      "Fold: 13  Epoch: 613  Training loss = 3.9078  Validation loss = 6.7027  \n",
      "\n",
      "Fold: 13  Epoch: 614  Training loss = 3.9075  Validation loss = 6.7022  \n",
      "\n",
      "Fold: 13  Epoch: 615  Training loss = 3.9073  Validation loss = 6.7020  \n",
      "\n",
      "Fold: 13  Epoch: 616  Training loss = 3.9071  Validation loss = 6.7016  \n",
      "\n",
      "Fold: 13  Epoch: 617  Training loss = 3.9068  Validation loss = 6.7012  \n",
      "\n",
      "Fold: 13  Epoch: 618  Training loss = 3.9066  Validation loss = 6.7008  \n",
      "\n",
      "Fold: 13  Epoch: 619  Training loss = 3.9064  Validation loss = 6.7005  \n",
      "\n",
      "Fold: 13  Epoch: 620  Training loss = 3.9062  Validation loss = 6.7001  \n",
      "\n",
      "Fold: 13  Epoch: 621  Training loss = 3.9060  Validation loss = 6.6998  \n",
      "\n",
      "Fold: 13  Epoch: 622  Training loss = 3.9058  Validation loss = 6.6995  \n",
      "\n",
      "Fold: 13  Epoch: 623  Training loss = 3.9056  Validation loss = 6.6992  \n",
      "\n",
      "Fold: 13  Epoch: 624  Training loss = 3.9054  Validation loss = 6.6989  \n",
      "\n",
      "Fold: 13  Epoch: 625  Training loss = 3.9051  Validation loss = 6.6984  \n",
      "\n",
      "Fold: 13  Epoch: 626  Training loss = 3.9048  Validation loss = 6.6980  \n",
      "\n",
      "Fold: 13  Epoch: 627  Training loss = 3.9046  Validation loss = 6.6975  \n",
      "\n",
      "Fold: 13  Epoch: 628  Training loss = 3.9044  Validation loss = 6.6972  \n",
      "\n",
      "Fold: 13  Epoch: 629  Training loss = 3.9041  Validation loss = 6.6968  \n",
      "\n",
      "Fold: 13  Epoch: 630  Training loss = 3.9039  Validation loss = 6.6965  \n",
      "\n",
      "Fold: 13  Epoch: 631  Training loss = 3.9036  Validation loss = 6.6960  \n",
      "\n",
      "Fold: 13  Epoch: 632  Training loss = 3.9035  Validation loss = 6.6957  \n",
      "\n",
      "Fold: 13  Epoch: 633  Training loss = 3.9033  Validation loss = 6.6954  \n",
      "\n",
      "Fold: 13  Epoch: 634  Training loss = 3.9030  Validation loss = 6.6951  \n",
      "\n",
      "Fold: 13  Epoch: 635  Training loss = 3.9029  Validation loss = 6.6948  \n",
      "\n",
      "Fold: 13  Epoch: 636  Training loss = 3.9026  Validation loss = 6.6944  \n",
      "\n",
      "Fold: 13  Epoch: 637  Training loss = 3.9024  Validation loss = 6.6940  \n",
      "\n",
      "Fold: 13  Epoch: 638  Training loss = 3.9022  Validation loss = 6.6937  \n",
      "\n",
      "Fold: 13  Epoch: 639  Training loss = 3.9020  Validation loss = 6.6933  \n",
      "\n",
      "Fold: 13  Epoch: 640  Training loss = 3.9018  Validation loss = 6.6930  \n",
      "\n",
      "Fold: 13  Epoch: 641  Training loss = 3.9016  Validation loss = 6.6926  \n",
      "\n",
      "Fold: 13  Epoch: 642  Training loss = 3.9013  Validation loss = 6.6922  \n",
      "\n",
      "Fold: 13  Epoch: 643  Training loss = 3.9011  Validation loss = 6.6919  \n",
      "\n",
      "Fold: 13  Epoch: 644  Training loss = 3.9009  Validation loss = 6.6916  \n",
      "\n",
      "Fold: 13  Epoch: 645  Training loss = 3.9007  Validation loss = 6.6913  \n",
      "\n",
      "Fold: 13  Epoch: 646  Training loss = 3.9005  Validation loss = 6.6909  \n",
      "\n",
      "Fold: 13  Epoch: 647  Training loss = 3.9003  Validation loss = 6.6906  \n",
      "\n",
      "Fold: 13  Epoch: 648  Training loss = 3.9001  Validation loss = 6.6902  \n",
      "\n",
      "Fold: 13  Epoch: 649  Training loss = 3.8998  Validation loss = 6.6898  \n",
      "\n",
      "Fold: 13  Epoch: 650  Training loss = 3.8996  Validation loss = 6.6895  \n",
      "\n",
      "Fold: 13  Epoch: 651  Training loss = 3.8994  Validation loss = 6.6891  \n",
      "\n",
      "Fold: 13  Epoch: 652  Training loss = 3.8992  Validation loss = 6.6888  \n",
      "\n",
      "Fold: 13  Epoch: 653  Training loss = 3.8990  Validation loss = 6.6884  \n",
      "\n",
      "Fold: 13  Epoch: 654  Training loss = 3.8988  Validation loss = 6.6881  \n",
      "\n",
      "Fold: 13  Epoch: 655  Training loss = 3.8985  Validation loss = 6.6877  \n",
      "\n",
      "Fold: 13  Epoch: 656  Training loss = 3.8982  Validation loss = 6.6872  \n",
      "\n",
      "Fold: 13  Epoch: 657  Training loss = 3.8980  Validation loss = 6.6868  \n",
      "\n",
      "Fold: 13  Epoch: 658  Training loss = 3.8977  Validation loss = 6.6864  \n",
      "\n",
      "Fold: 13  Epoch: 659  Training loss = 3.8974  Validation loss = 6.6859  \n",
      "\n",
      "Fold: 13  Epoch: 660  Training loss = 3.8973  Validation loss = 6.6856  \n",
      "\n",
      "Fold: 13  Epoch: 661  Training loss = 3.8971  Validation loss = 6.6853  \n",
      "\n",
      "Fold: 13  Epoch: 662  Training loss = 3.8969  Validation loss = 6.6850  \n",
      "\n",
      "Fold: 13  Epoch: 663  Training loss = 3.8967  Validation loss = 6.6846  \n",
      "\n",
      "Fold: 13  Epoch: 664  Training loss = 3.8965  Validation loss = 6.6843  \n",
      "\n",
      "Fold: 13  Epoch: 665  Training loss = 3.8963  Validation loss = 6.6840  \n",
      "\n",
      "Fold: 13  Epoch: 666  Training loss = 3.8961  Validation loss = 6.6837  \n",
      "\n",
      "Fold: 13  Epoch: 667  Training loss = 3.8959  Validation loss = 6.6834  \n",
      "\n",
      "Fold: 13  Epoch: 668  Training loss = 3.8957  Validation loss = 6.6831  \n",
      "\n",
      "Fold: 13  Epoch: 669  Training loss = 3.8955  Validation loss = 6.6827  \n",
      "\n",
      "Fold: 13  Epoch: 670  Training loss = 3.8952  Validation loss = 6.6822  \n",
      "\n",
      "Fold: 13  Epoch: 671  Training loss = 3.8949  Validation loss = 6.6819  \n",
      "\n",
      "Fold: 13  Epoch: 672  Training loss = 3.8947  Validation loss = 6.6815  \n",
      "\n",
      "Fold: 13  Epoch: 673  Training loss = 3.8945  Validation loss = 6.6812  \n",
      "\n",
      "Fold: 13  Epoch: 674  Training loss = 3.8943  Validation loss = 6.6808  \n",
      "\n",
      "Fold: 13  Epoch: 675  Training loss = 3.8941  Validation loss = 6.6805  \n",
      "\n",
      "Fold: 13  Epoch: 676  Training loss = 3.8939  Validation loss = 6.6802  \n",
      "\n",
      "Fold: 13  Epoch: 677  Training loss = 3.8937  Validation loss = 6.6798  \n",
      "\n",
      "Fold: 13  Epoch: 678  Training loss = 3.8934  Validation loss = 6.6794  \n",
      "\n",
      "Fold: 13  Epoch: 679  Training loss = 3.8932  Validation loss = 6.6790  \n",
      "\n",
      "Fold: 13  Epoch: 680  Training loss = 3.8929  Validation loss = 6.6786  \n",
      "\n",
      "Fold: 13  Epoch: 681  Training loss = 3.8927  Validation loss = 6.6783  \n",
      "\n",
      "Fold: 13  Epoch: 682  Training loss = 3.8924  Validation loss = 6.6778  \n",
      "\n",
      "Fold: 13  Epoch: 683  Training loss = 3.8922  Validation loss = 6.6774  \n",
      "\n",
      "Fold: 13  Epoch: 684  Training loss = 3.8919  Validation loss = 6.6770  \n",
      "\n",
      "Fold: 13  Epoch: 685  Training loss = 3.8917  Validation loss = 6.6766  \n",
      "\n",
      "Fold: 13  Epoch: 686  Training loss = 3.8915  Validation loss = 6.6763  \n",
      "\n",
      "Fold: 13  Epoch: 687  Training loss = 3.8913  Validation loss = 6.6760  \n",
      "\n",
      "Fold: 13  Epoch: 688  Training loss = 3.8911  Validation loss = 6.6756  \n",
      "\n",
      "Fold: 13  Epoch: 689  Training loss = 3.8909  Validation loss = 6.6753  \n",
      "\n",
      "Fold: 13  Epoch: 690  Training loss = 3.8907  Validation loss = 6.6750  \n",
      "\n",
      "Fold: 13  Epoch: 691  Training loss = 3.8905  Validation loss = 6.6746  \n",
      "\n",
      "Fold: 13  Epoch: 692  Training loss = 3.8903  Validation loss = 6.6742  \n",
      "\n",
      "Fold: 13  Epoch: 693  Training loss = 3.8900  Validation loss = 6.6739  \n",
      "\n",
      "Fold: 13  Epoch: 694  Training loss = 3.8898  Validation loss = 6.6735  \n",
      "\n",
      "Fold: 13  Epoch: 695  Training loss = 3.8896  Validation loss = 6.6731  \n",
      "\n",
      "Fold: 13  Epoch: 696  Training loss = 3.8894  Validation loss = 6.6728  \n",
      "\n",
      "Fold: 13  Epoch: 697  Training loss = 3.8892  Validation loss = 6.6725  \n",
      "\n",
      "Fold: 13  Epoch: 698  Training loss = 3.8890  Validation loss = 6.6721  \n",
      "\n",
      "Fold: 13  Epoch: 699  Training loss = 3.8888  Validation loss = 6.6718  \n",
      "\n",
      "Fold: 13  Epoch: 700  Training loss = 3.8885  Validation loss = 6.6714  \n",
      "\n",
      "Fold: 13  Epoch: 701  Training loss = 3.8882  Validation loss = 6.6709  \n",
      "\n",
      "Fold: 13  Epoch: 702  Training loss = 3.8880  Validation loss = 6.6706  \n",
      "\n",
      "Fold: 13  Epoch: 703  Training loss = 3.8878  Validation loss = 6.6702  \n",
      "\n",
      "Fold: 13  Epoch: 704  Training loss = 3.8875  Validation loss = 6.6698  \n",
      "\n",
      "Fold: 13  Epoch: 705  Training loss = 3.8873  Validation loss = 6.6694  \n",
      "\n",
      "Fold: 13  Epoch: 706  Training loss = 3.8871  Validation loss = 6.6691  \n",
      "\n",
      "Fold: 13  Epoch: 707  Training loss = 3.8868  Validation loss = 6.6687  \n",
      "\n",
      "Fold: 13  Epoch: 708  Training loss = 3.8866  Validation loss = 6.6683  \n",
      "\n",
      "Fold: 13  Epoch: 709  Training loss = 3.8863  Validation loss = 6.6679  \n",
      "\n",
      "Fold: 13  Epoch: 710  Training loss = 3.8861  Validation loss = 6.6675  \n",
      "\n",
      "Fold: 13  Epoch: 711  Training loss = 3.8859  Validation loss = 6.6672  \n",
      "\n",
      "Fold: 13  Epoch: 712  Training loss = 3.8857  Validation loss = 6.6668  \n",
      "\n",
      "Fold: 13  Epoch: 713  Training loss = 3.8854  Validation loss = 6.6664  \n",
      "\n",
      "Fold: 13  Epoch: 714  Training loss = 3.8852  Validation loss = 6.6661  \n",
      "\n",
      "Fold: 13  Epoch: 715  Training loss = 3.8850  Validation loss = 6.6657  \n",
      "\n",
      "Fold: 13  Epoch: 716  Training loss = 3.8848  Validation loss = 6.6654  \n",
      "\n",
      "Fold: 13  Epoch: 717  Training loss = 3.8846  Validation loss = 6.6650  \n",
      "\n",
      "Fold: 13  Epoch: 718  Training loss = 3.8843  Validation loss = 6.6646  \n",
      "\n",
      "Fold: 13  Epoch: 719  Training loss = 3.8841  Validation loss = 6.6642  \n",
      "\n",
      "Fold: 13  Epoch: 720  Training loss = 3.8838  Validation loss = 6.6638  \n",
      "\n",
      "Fold: 13  Epoch: 721  Training loss = 3.8836  Validation loss = 6.6634  \n",
      "\n",
      "Fold: 13  Epoch: 722  Training loss = 3.8834  Validation loss = 6.6630  \n",
      "\n",
      "Fold: 13  Epoch: 723  Training loss = 3.8831  Validation loss = 6.6626  \n",
      "\n",
      "Fold: 13  Epoch: 724  Training loss = 3.8829  Validation loss = 6.6623  \n",
      "\n",
      "Fold: 13  Epoch: 725  Training loss = 3.8827  Validation loss = 6.6619  \n",
      "\n",
      "Fold: 13  Epoch: 726  Training loss = 3.8825  Validation loss = 6.6615  \n",
      "\n",
      "Fold: 13  Epoch: 727  Training loss = 3.8823  Validation loss = 6.6612  \n",
      "\n",
      "Fold: 13  Epoch: 728  Training loss = 3.8820  Validation loss = 6.6608  \n",
      "\n",
      "Fold: 13  Epoch: 729  Training loss = 3.8818  Validation loss = 6.6604  \n",
      "\n",
      "Fold: 13  Epoch: 730  Training loss = 3.8816  Validation loss = 6.6601  \n",
      "\n",
      "Fold: 13  Epoch: 731  Training loss = 3.8813  Validation loss = 6.6597  \n",
      "\n",
      "Fold: 13  Epoch: 732  Training loss = 3.8811  Validation loss = 6.6593  \n",
      "\n",
      "Fold: 13  Epoch: 733  Training loss = 3.8809  Validation loss = 6.6589  \n",
      "\n",
      "Fold: 13  Epoch: 734  Training loss = 3.8807  Validation loss = 6.6586  \n",
      "\n",
      "Fold: 13  Epoch: 735  Training loss = 3.8804  Validation loss = 6.6581  \n",
      "\n",
      "Fold: 13  Epoch: 736  Training loss = 3.8802  Validation loss = 6.6577  \n",
      "\n",
      "Fold: 13  Epoch: 737  Training loss = 3.8799  Validation loss = 6.6573  \n",
      "\n",
      "Fold: 13  Epoch: 738  Training loss = 3.8797  Validation loss = 6.6570  \n",
      "\n",
      "Fold: 13  Epoch: 739  Training loss = 3.8795  Validation loss = 6.6566  \n",
      "\n",
      "Fold: 13  Epoch: 740  Training loss = 3.8792  Validation loss = 6.6562  \n",
      "\n",
      "Fold: 13  Epoch: 741  Training loss = 3.8790  Validation loss = 6.6558  \n",
      "\n",
      "Fold: 13  Epoch: 742  Training loss = 3.8787  Validation loss = 6.6554  \n",
      "\n",
      "Fold: 13  Epoch: 743  Training loss = 3.8785  Validation loss = 6.6551  \n",
      "\n",
      "Fold: 13  Epoch: 744  Training loss = 3.8784  Validation loss = 6.6547  \n",
      "\n",
      "Fold: 13  Epoch: 745  Training loss = 3.8781  Validation loss = 6.6544  \n",
      "\n",
      "Fold: 13  Epoch: 746  Training loss = 3.8779  Validation loss = 6.6539  \n",
      "\n",
      "Fold: 13  Epoch: 747  Training loss = 3.8776  Validation loss = 6.6536  \n",
      "\n",
      "Fold: 13  Epoch: 748  Training loss = 3.8774  Validation loss = 6.6532  \n",
      "\n",
      "Fold: 13  Epoch: 749  Training loss = 3.8772  Validation loss = 6.6529  \n",
      "\n",
      "Fold: 13  Epoch: 750  Training loss = 3.8770  Validation loss = 6.6525  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 750  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 4.2097  Validation loss = 10.3693  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 4.2094  Validation loss = 10.3689  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 4.2091  Validation loss = 10.3685  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 4.2088  Validation loss = 10.3681  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 4.2085  Validation loss = 10.3677  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 4.2082  Validation loss = 10.3673  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 4.2079  Validation loss = 10.3669  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 4.2077  Validation loss = 10.3666  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 4.2075  Validation loss = 10.3662  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 4.2071  Validation loss = 10.3658  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 4.2069  Validation loss = 10.3654  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 4.2065  Validation loss = 10.3649  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 4.2063  Validation loss = 10.3646  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 4.2059  Validation loss = 10.3641  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 4.2057  Validation loss = 10.3637  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 4.2054  Validation loss = 10.3634  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 4.2051  Validation loss = 10.3629  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 4.2049  Validation loss = 10.3626  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 4.2046  Validation loss = 10.3622  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 4.2043  Validation loss = 10.3618  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 4.2040  Validation loss = 10.3614  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 4.2037  Validation loss = 10.3610  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 4.2034  Validation loss = 10.3606  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 4.2031  Validation loss = 10.3601  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 4.2028  Validation loss = 10.3597  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 4.2026  Validation loss = 10.3595  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 4.2023  Validation loss = 10.3591  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 4.2021  Validation loss = 10.3588  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 4.2017  Validation loss = 10.3583  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 4.2015  Validation loss = 10.3579  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 4.2012  Validation loss = 10.3575  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 4.2009  Validation loss = 10.3571  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 4.2006  Validation loss = 10.3567  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 4.2004  Validation loss = 10.3564  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 4.2001  Validation loss = 10.3561  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 4.1999  Validation loss = 10.3557  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 4.1996  Validation loss = 10.3553  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 4.1993  Validation loss = 10.3549  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 4.1991  Validation loss = 10.3546  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 4.1989  Validation loss = 10.3543  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 4.1986  Validation loss = 10.3539  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 4.1983  Validation loss = 10.3535  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 4.1981  Validation loss = 10.3532  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 4.1977  Validation loss = 10.3527  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 4.1975  Validation loss = 10.3523  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 4.1972  Validation loss = 10.3519  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 4.1969  Validation loss = 10.3515  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 4.1967  Validation loss = 10.3512  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 4.1964  Validation loss = 10.3508  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 4.1961  Validation loss = 10.3505  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 4.1958  Validation loss = 10.3501  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 4.1955  Validation loss = 10.3497  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 4.1952  Validation loss = 10.3492  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 4.1949  Validation loss = 10.3488  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 4.1947  Validation loss = 10.3484  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 4.1944  Validation loss = 10.3480  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 4.1941  Validation loss = 10.3476  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 4.1938  Validation loss = 10.3472  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 4.1935  Validation loss = 10.3468  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 4.1932  Validation loss = 10.3464  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 4.1930  Validation loss = 10.3461  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 4.1927  Validation loss = 10.3457  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 4.1924  Validation loss = 10.3453  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 4.1922  Validation loss = 10.3450  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 4.1920  Validation loss = 10.3447  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 4.1917  Validation loss = 10.3444  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 4.1914  Validation loss = 10.3439  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 4.1910  Validation loss = 10.3434  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 4.1907  Validation loss = 10.3430  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 4.1904  Validation loss = 10.3426  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 4.1901  Validation loss = 10.3421  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 4.1898  Validation loss = 10.3417  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 4.1895  Validation loss = 10.3413  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 4.1892  Validation loss = 10.3409  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 4.1890  Validation loss = 10.3405  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 4.1887  Validation loss = 10.3402  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 4.1884  Validation loss = 10.3398  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 4.1882  Validation loss = 10.3394  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 4.1879  Validation loss = 10.3390  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 4.1875  Validation loss = 10.3386  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 4.1872  Validation loss = 10.3381  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 4.1870  Validation loss = 10.3378  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 4.1867  Validation loss = 10.3374  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 4.1864  Validation loss = 10.3370  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 4.1861  Validation loss = 10.3366  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 4.1858  Validation loss = 10.3362  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 4.1855  Validation loss = 10.3357  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 4.1853  Validation loss = 10.3354  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 4.1849  Validation loss = 10.3350  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 4.1847  Validation loss = 10.3346  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 4.1844  Validation loss = 10.3342  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 4.1841  Validation loss = 10.3338  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 4.1838  Validation loss = 10.3334  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 4.1835  Validation loss = 10.3330  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 4.1832  Validation loss = 10.3325  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 4.1829  Validation loss = 10.3321  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 4.1826  Validation loss = 10.3317  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 4.1823  Validation loss = 10.3313  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 4.1820  Validation loss = 10.3309  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 4.1817  Validation loss = 10.3305  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 4.1815  Validation loss = 10.3301  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 4.1812  Validation loss = 10.3297  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 4.1809  Validation loss = 10.3293  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 4.1807  Validation loss = 10.3290  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 4.1803  Validation loss = 10.3286  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 4.1801  Validation loss = 10.3282  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 4.1799  Validation loss = 10.3279  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 4.1797  Validation loss = 10.3276  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 4.1794  Validation loss = 10.3272  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 4.1791  Validation loss = 10.3268  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 4.1788  Validation loss = 10.3264  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 4.1785  Validation loss = 10.3259  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 4.1782  Validation loss = 10.3255  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 4.1779  Validation loss = 10.3251  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 4.1776  Validation loss = 10.3247  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 4.1773  Validation loss = 10.3243  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 4.1770  Validation loss = 10.3239  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 4.1768  Validation loss = 10.3235  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 4.1765  Validation loss = 10.3231  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 4.1762  Validation loss = 10.3227  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 4.1759  Validation loss = 10.3223  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 4.1756  Validation loss = 10.3219  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 4.1754  Validation loss = 10.3216  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 4.1751  Validation loss = 10.3211  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 4.1748  Validation loss = 10.3208  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 4.1746  Validation loss = 10.3204  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 4.1743  Validation loss = 10.3200  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 4.1739  Validation loss = 10.3195  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 4.1736  Validation loss = 10.3191  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 4.1734  Validation loss = 10.3187  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 4.1731  Validation loss = 10.3184  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 4.1729  Validation loss = 10.3180  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 4.1726  Validation loss = 10.3177  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 4.1724  Validation loss = 10.3174  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 4.1721  Validation loss = 10.3170  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 4.1718  Validation loss = 10.3166  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 4.1715  Validation loss = 10.3163  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 4.1713  Validation loss = 10.3159  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 4.1710  Validation loss = 10.3155  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 4.1707  Validation loss = 10.3152  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 4.1704  Validation loss = 10.3147  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 4.1701  Validation loss = 10.3143  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 4.1697  Validation loss = 10.3139  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 4.1694  Validation loss = 10.3135  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 4.1691  Validation loss = 10.3131  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 4.1687  Validation loss = 10.3127  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 4.1684  Validation loss = 10.3123  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 4.1681  Validation loss = 10.3120  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 4.1678  Validation loss = 10.3115  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 4.1674  Validation loss = 10.3110  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 4.1666  Validation loss = 10.3106  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 4.1656  Validation loss = 10.3102  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 4.1654  Validation loss = 10.3099  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 4.1651  Validation loss = 10.3095  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 4.1649  Validation loss = 10.3091  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 4.1647  Validation loss = 10.3087  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 4.1624  Validation loss = 10.3085  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 4.1567  Validation loss = 10.3080  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 4.1564  Validation loss = 10.3077  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 4.1561  Validation loss = 10.3073  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 4.1555  Validation loss = 10.3069  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 4.1553  Validation loss = 10.3065  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 4.1549  Validation loss = 10.3061  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 4.1546  Validation loss = 10.3058  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 4.1543  Validation loss = 10.3054  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 4.1540  Validation loss = 10.3049  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 4.1536  Validation loss = 10.3044  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 4.1533  Validation loss = 10.3040  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 4.1530  Validation loss = 10.3036  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 4.1527  Validation loss = 10.3031  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 4.1524  Validation loss = 10.3028  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 4.1521  Validation loss = 10.3024  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 4.1518  Validation loss = 10.3020  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 4.1515  Validation loss = 10.3016  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 4.1512  Validation loss = 10.3012  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 4.1510  Validation loss = 10.3008  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 4.1508  Validation loss = 10.3005  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 4.1505  Validation loss = 10.3000  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 4.1502  Validation loss = 10.2997  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 4.1499  Validation loss = 10.2993  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 4.1497  Validation loss = 10.2990  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 4.1494  Validation loss = 10.2985  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 4.1491  Validation loss = 10.2981  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 4.1488  Validation loss = 10.2977  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 4.1485  Validation loss = 10.2972  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 4.1482  Validation loss = 10.2969  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 4.1479  Validation loss = 10.2965  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 4.1477  Validation loss = 10.2961  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 4.1473  Validation loss = 10.2957  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 4.1470  Validation loss = 10.2952  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 4.1467  Validation loss = 10.2948  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 4.1464  Validation loss = 10.2943  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 4.1461  Validation loss = 10.2940  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 4.1458  Validation loss = 10.2936  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 4.1456  Validation loss = 10.2932  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 4.1453  Validation loss = 10.2929  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 4.1450  Validation loss = 10.2924  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 4.1448  Validation loss = 10.2921  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 4.1446  Validation loss = 10.2918  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 4.1443  Validation loss = 10.2914  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 4.1440  Validation loss = 10.2910  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 4.1438  Validation loss = 10.2906  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 4.1435  Validation loss = 10.2903  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 4.1432  Validation loss = 10.2898  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 4.1429  Validation loss = 10.2895  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 4.1426  Validation loss = 10.2890  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 4.1424  Validation loss = 10.2886  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 4.1421  Validation loss = 10.2883  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 4.1419  Validation loss = 10.2880  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 4.1416  Validation loss = 10.2876  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 4.1413  Validation loss = 10.2871  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 4.1410  Validation loss = 10.2867  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 4.1407  Validation loss = 10.2863  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 4.1404  Validation loss = 10.2859  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 4.1401  Validation loss = 10.2855  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 4.1398  Validation loss = 10.2850  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 4.1396  Validation loss = 10.2847  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 4.1393  Validation loss = 10.2843  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 4.1390  Validation loss = 10.2839  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 4.1388  Validation loss = 10.2836  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 4.1384  Validation loss = 10.2831  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 4.1382  Validation loss = 10.2828  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 4.1379  Validation loss = 10.2824  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 4.1377  Validation loss = 10.2820  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 4.1374  Validation loss = 10.2816  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 4.1371  Validation loss = 10.2812  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 4.1368  Validation loss = 10.2808  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 4.1366  Validation loss = 10.2804  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 4.1363  Validation loss = 10.2801  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 4.1361  Validation loss = 10.2797  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 4.1357  Validation loss = 10.2792  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 4.1354  Validation loss = 10.2788  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 4.1351  Validation loss = 10.2784  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 4.1348  Validation loss = 10.2779  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 4.1345  Validation loss = 10.2775  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 4.1342  Validation loss = 10.2771  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 4.1339  Validation loss = 10.2767  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 4.1337  Validation loss = 10.2763  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 4.1334  Validation loss = 10.2760  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 4.1332  Validation loss = 10.2756  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 4.1329  Validation loss = 10.2752  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 4.1326  Validation loss = 10.2748  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 4.1324  Validation loss = 10.2744  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 4.1321  Validation loss = 10.2740  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 4.1318  Validation loss = 10.2736  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 4.1314  Validation loss = 10.2732  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 4.1312  Validation loss = 10.2729  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 4.1310  Validation loss = 10.2725  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 4.1307  Validation loss = 10.2721  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 4.1304  Validation loss = 10.2717  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 4.1302  Validation loss = 10.2713  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 4.1299  Validation loss = 10.2709  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 4.1296  Validation loss = 10.2705  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 4.1292  Validation loss = 10.2700  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 4.1290  Validation loss = 10.2696  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 4.1287  Validation loss = 10.2692  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 4.1284  Validation loss = 10.2688  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 4.1281  Validation loss = 10.2684  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 4.1278  Validation loss = 10.2680  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 4.1275  Validation loss = 10.2676  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 4.1272  Validation loss = 10.2672  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 4.1270  Validation loss = 10.2668  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 4.1267  Validation loss = 10.2664  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 4.1264  Validation loss = 10.2660  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 4.1261  Validation loss = 10.2655  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 4.1258  Validation loss = 10.2652  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 4.1255  Validation loss = 10.2647  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 4.1253  Validation loss = 10.2643  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 4.1250  Validation loss = 10.2639  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 4.1247  Validation loss = 10.2635  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 4.1245  Validation loss = 10.2632  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 4.1242  Validation loss = 10.2628  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 4.1239  Validation loss = 10.2624  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 4.1237  Validation loss = 10.2620  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 4.1235  Validation loss = 10.2617  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 4.1231  Validation loss = 10.2613  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 4.1229  Validation loss = 10.2609  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 4.1226  Validation loss = 10.2605  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 4.1223  Validation loss = 10.2601  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 4.1220  Validation loss = 10.2598  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 4.1217  Validation loss = 10.2593  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 4.1214  Validation loss = 10.2589  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 4.1212  Validation loss = 10.2585  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 4.1209  Validation loss = 10.2582  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 4.1207  Validation loss = 10.2578  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 4.1204  Validation loss = 10.2574  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 4.1201  Validation loss = 10.2569  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 4.1198  Validation loss = 10.2565  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 4.1195  Validation loss = 10.2562  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 4.1192  Validation loss = 10.2557  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 4.1190  Validation loss = 10.2554  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 4.1187  Validation loss = 10.2549  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 4.1184  Validation loss = 10.2545  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 4.1181  Validation loss = 10.2541  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 4.1178  Validation loss = 10.2537  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 4.1176  Validation loss = 10.2533  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 4.1173  Validation loss = 10.2529  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 4.1170  Validation loss = 10.2526  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 4.1167  Validation loss = 10.2521  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 4.1164  Validation loss = 10.2517  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 4.1161  Validation loss = 10.2513  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 4.1158  Validation loss = 10.2508  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 4.1155  Validation loss = 10.2504  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 4.1152  Validation loss = 10.2499  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 4.1149  Validation loss = 10.2495  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 4.1146  Validation loss = 10.2491  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 4.1143  Validation loss = 10.2487  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 4.1140  Validation loss = 10.2482  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 4.1137  Validation loss = 10.2478  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 4.1135  Validation loss = 10.2475  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 4.1133  Validation loss = 10.2472  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 4.1131  Validation loss = 10.2468  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 4.1128  Validation loss = 10.2465  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 4.1125  Validation loss = 10.2461  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 4.1123  Validation loss = 10.2457  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 4.1120  Validation loss = 10.2454  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 4.1118  Validation loss = 10.2451  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 4.1115  Validation loss = 10.2447  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 4.1113  Validation loss = 10.2443  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 4.1110  Validation loss = 10.2439  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 4.1107  Validation loss = 10.2435  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 4.1105  Validation loss = 10.2431  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 4.1102  Validation loss = 10.2427  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 4.1099  Validation loss = 10.2422  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 4.1096  Validation loss = 10.2419  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 4.1093  Validation loss = 10.2415  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 4.1091  Validation loss = 10.2411  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 4.1088  Validation loss = 10.2407  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 4.1085  Validation loss = 10.2403  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 4.1083  Validation loss = 10.2400  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 4.1080  Validation loss = 10.2395  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 4.1077  Validation loss = 10.2392  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 4.1074  Validation loss = 10.2387  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 4.1072  Validation loss = 10.2384  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 4.1069  Validation loss = 10.2379  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 4.1066  Validation loss = 10.2375  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 4.1063  Validation loss = 10.2371  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 4.1060  Validation loss = 10.2367  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 4.1058  Validation loss = 10.2364  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 4.1055  Validation loss = 10.2359  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 4.1052  Validation loss = 10.2356  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 4.1049  Validation loss = 10.2352  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 4.1046  Validation loss = 10.2347  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 4.1043  Validation loss = 10.2342  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 4.1041  Validation loss = 10.2339  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 4.1038  Validation loss = 10.2336  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 4.1036  Validation loss = 10.2332  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 4.1033  Validation loss = 10.2329  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 4.1031  Validation loss = 10.2326  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 4.1029  Validation loss = 10.2322  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 4.1026  Validation loss = 10.2317  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 4.1023  Validation loss = 10.2314  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 4.1020  Validation loss = 10.2310  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 4.1017  Validation loss = 10.2306  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 4.1015  Validation loss = 10.2302  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 4.1013  Validation loss = 10.2299  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 4.1010  Validation loss = 10.2295  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 4.1006  Validation loss = 10.2290  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 4.1004  Validation loss = 10.2287  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 4.1001  Validation loss = 10.2283  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 4.0999  Validation loss = 10.2280  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 4.0996  Validation loss = 10.2276  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 4.0994  Validation loss = 10.2272  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 4.0991  Validation loss = 10.2268  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 4.0987  Validation loss = 10.2264  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 4.0985  Validation loss = 10.2259  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 4.0982  Validation loss = 10.2256  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 4.0980  Validation loss = 10.2253  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 4.0978  Validation loss = 10.2250  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 4.0976  Validation loss = 10.2246  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 4.0973  Validation loss = 10.2242  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 4.0970  Validation loss = 10.2238  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 4.0967  Validation loss = 10.2234  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 4.0965  Validation loss = 10.2231  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 4.0962  Validation loss = 10.2226  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 4.0959  Validation loss = 10.2222  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 4.0957  Validation loss = 10.2218  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 4.0954  Validation loss = 10.2215  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 4.0952  Validation loss = 10.2211  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 4.0949  Validation loss = 10.2207  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 4.0946  Validation loss = 10.2202  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 4.0943  Validation loss = 10.2198  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 4.0940  Validation loss = 10.2194  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 4.0938  Validation loss = 10.2191  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 4.0936  Validation loss = 10.2188  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 4.0933  Validation loss = 10.2184  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 4.0931  Validation loss = 10.2181  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 4.0928  Validation loss = 10.2177  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 4.0925  Validation loss = 10.2173  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 4.0923  Validation loss = 10.2169  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 4.0920  Validation loss = 10.2165  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 4.0917  Validation loss = 10.2161  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 4.0915  Validation loss = 10.2158  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 4.0912  Validation loss = 10.2154  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 4.0909  Validation loss = 10.2149  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 4.0907  Validation loss = 10.2146  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 4.0904  Validation loss = 10.2142  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 4.0901  Validation loss = 10.2137  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 4.0898  Validation loss = 10.2133  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 4.0895  Validation loss = 10.2129  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 4.0892  Validation loss = 10.2125  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 4.0889  Validation loss = 10.2120  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 4.0887  Validation loss = 10.2117  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 4.0884  Validation loss = 10.2113  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 4.0882  Validation loss = 10.2109  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 4.0879  Validation loss = 10.2105  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 4.0876  Validation loss = 10.2101  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 4.0873  Validation loss = 10.2097  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 4.0870  Validation loss = 10.2093  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 4.0868  Validation loss = 10.2089  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 4.0865  Validation loss = 10.2085  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 4.0862  Validation loss = 10.2081  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 4.0859  Validation loss = 10.2077  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 4.0857  Validation loss = 10.2073  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 4.0853  Validation loss = 10.2069  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 4.0851  Validation loss = 10.2065  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 4.0848  Validation loss = 10.2061  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 4.0845  Validation loss = 10.2056  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 4.0842  Validation loss = 10.2052  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 4.0839  Validation loss = 10.2049  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 4.0837  Validation loss = 10.2045  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 4.0835  Validation loss = 10.2041  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 4.0832  Validation loss = 10.2037  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 4.0829  Validation loss = 10.2033  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 4.0826  Validation loss = 10.2029  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 4.0824  Validation loss = 10.2026  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 4.0821  Validation loss = 10.2021  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 4.0818  Validation loss = 10.2017  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 4.0816  Validation loss = 10.2014  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 4.0813  Validation loss = 10.2010  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 4.0811  Validation loss = 10.2007  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 4.0809  Validation loss = 10.2004  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 4.0806  Validation loss = 10.2000  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 4.0804  Validation loss = 10.1996  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 4.0801  Validation loss = 10.1993  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 4.0799  Validation loss = 10.1989  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 4.0796  Validation loss = 10.1985  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 4.0794  Validation loss = 10.1981  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 4.0790  Validation loss = 10.1977  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 4.0788  Validation loss = 10.1973  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 4.0785  Validation loss = 10.1969  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 4.0782  Validation loss = 10.1965  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 4.0779  Validation loss = 10.1961  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 4.0777  Validation loss = 10.1957  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 4.0774  Validation loss = 10.1953  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 4.0773  Validation loss = 10.1951  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 4.0770  Validation loss = 10.1947  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 4.0768  Validation loss = 10.1944  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 4.0766  Validation loss = 10.1941  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 4.0763  Validation loss = 10.1937  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 4.0760  Validation loss = 10.1933  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 4.0757  Validation loss = 10.1928  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 4.0754  Validation loss = 10.1924  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 4.0752  Validation loss = 10.1920  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 4.0749  Validation loss = 10.1916  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 4.0746  Validation loss = 10.1912  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 4.0743  Validation loss = 10.1907  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 4.0740  Validation loss = 10.1903  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 4.0738  Validation loss = 10.1900  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 4.0735  Validation loss = 10.1895  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 4.0732  Validation loss = 10.1892  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 4.0729  Validation loss = 10.1888  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 4.0727  Validation loss = 10.1885  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 4.0724  Validation loss = 10.1880  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 4.0722  Validation loss = 10.1876  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 4.0719  Validation loss = 10.1873  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 4.0717  Validation loss = 10.1870  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 4.0714  Validation loss = 10.1865  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 4.0711  Validation loss = 10.1861  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 4.0709  Validation loss = 10.1858  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 4.0707  Validation loss = 10.1855  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 4.0704  Validation loss = 10.1851  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 4.0701  Validation loss = 10.1847  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 4.0698  Validation loss = 10.1843  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 4.0696  Validation loss = 10.1839  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 4.0693  Validation loss = 10.1835  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 4.0691  Validation loss = 10.1832  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 4.0688  Validation loss = 10.1828  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 4.0685  Validation loss = 10.1823  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 4.0682  Validation loss = 10.1818  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 4.0678  Validation loss = 10.1814  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 4.0676  Validation loss = 10.1810  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 4.0673  Validation loss = 10.1806  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 4.0671  Validation loss = 10.1802  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 4.0668  Validation loss = 10.1798  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 4.0665  Validation loss = 10.1794  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 4.0662  Validation loss = 10.1790  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 4.0659  Validation loss = 10.1786  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 4.0657  Validation loss = 10.1783  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 4.0654  Validation loss = 10.1779  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 4.0651  Validation loss = 10.1775  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 4.0648  Validation loss = 10.1771  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 4.0645  Validation loss = 10.1768  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 4.0642  Validation loss = 10.1763  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 4.0638  Validation loss = 10.1759  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 4.0635  Validation loss = 10.1755  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 4.0632  Validation loss = 10.1751  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 4.0629  Validation loss = 10.1747  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 4.0625  Validation loss = 10.1743  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 4.0616  Validation loss = 10.1739  \n",
      "\n",
      "Fold: 14  Epoch: 501  Training loss = 4.0614  Validation loss = 10.1735  \n",
      "\n",
      "Fold: 14  Epoch: 502  Training loss = 4.0605  Validation loss = 10.1731  \n",
      "\n",
      "Fold: 14  Epoch: 503  Training loss = 4.0601  Validation loss = 10.1728  \n",
      "\n",
      "Fold: 14  Epoch: 504  Training loss = 4.0598  Validation loss = 10.1724  \n",
      "\n",
      "Fold: 14  Epoch: 505  Training loss = 4.0595  Validation loss = 10.1721  \n",
      "\n",
      "Fold: 14  Epoch: 506  Training loss = 4.0585  Validation loss = 10.1717  \n",
      "\n",
      "Fold: 14  Epoch: 507  Training loss = 4.0576  Validation loss = 10.1713  \n",
      "\n",
      "Fold: 14  Epoch: 508  Training loss = 4.0572  Validation loss = 10.1709  \n",
      "\n",
      "Fold: 14  Epoch: 509  Training loss = 4.0570  Validation loss = 10.1706  \n",
      "\n",
      "Fold: 14  Epoch: 510  Training loss = 4.0567  Validation loss = 10.1702  \n",
      "\n",
      "Fold: 14  Epoch: 511  Training loss = 4.0564  Validation loss = 10.1698  \n",
      "\n",
      "Fold: 14  Epoch: 512  Training loss = 4.0561  Validation loss = 10.1694  \n",
      "\n",
      "Fold: 14  Epoch: 513  Training loss = 4.0558  Validation loss = 10.1690  \n",
      "\n",
      "Fold: 14  Epoch: 514  Training loss = 4.0555  Validation loss = 10.1687  \n",
      "\n",
      "Fold: 14  Epoch: 515  Training loss = 4.0552  Validation loss = 10.1682  \n",
      "\n",
      "Fold: 14  Epoch: 516  Training loss = 4.0549  Validation loss = 10.1678  \n",
      "\n",
      "Fold: 14  Epoch: 517  Training loss = 4.0547  Validation loss = 10.1674  \n",
      "\n",
      "Fold: 14  Epoch: 518  Training loss = 4.0544  Validation loss = 10.1670  \n",
      "\n",
      "Fold: 14  Epoch: 519  Training loss = 4.0541  Validation loss = 10.1666  \n",
      "\n",
      "Fold: 14  Epoch: 520  Training loss = 4.0538  Validation loss = 10.1662  \n",
      "\n",
      "Fold: 14  Epoch: 521  Training loss = 4.0535  Validation loss = 10.1658  \n",
      "\n",
      "Fold: 14  Epoch: 522  Training loss = 4.0532  Validation loss = 10.1654  \n",
      "\n",
      "Fold: 14  Epoch: 523  Training loss = 4.0530  Validation loss = 10.1650  \n",
      "\n",
      "Fold: 14  Epoch: 524  Training loss = 4.0527  Validation loss = 10.1646  \n",
      "\n",
      "Fold: 14  Epoch: 525  Training loss = 4.0524  Validation loss = 10.1641  \n",
      "\n",
      "Fold: 14  Epoch: 526  Training loss = 4.0521  Validation loss = 10.1637  \n",
      "\n",
      "Fold: 14  Epoch: 527  Training loss = 4.0518  Validation loss = 10.1633  \n",
      "\n",
      "Fold: 14  Epoch: 528  Training loss = 4.0515  Validation loss = 10.1629  \n",
      "\n",
      "Fold: 14  Epoch: 529  Training loss = 4.0513  Validation loss = 10.1626  \n",
      "\n",
      "Fold: 14  Epoch: 530  Training loss = 4.0510  Validation loss = 10.1622  \n",
      "\n",
      "Fold: 14  Epoch: 531  Training loss = 4.0507  Validation loss = 10.1617  \n",
      "\n",
      "Fold: 14  Epoch: 532  Training loss = 4.0505  Validation loss = 10.1614  \n",
      "\n",
      "Fold: 14  Epoch: 533  Training loss = 4.0502  Validation loss = 10.1609  \n",
      "\n",
      "Fold: 14  Epoch: 534  Training loss = 4.0499  Validation loss = 10.1606  \n",
      "\n",
      "Fold: 14  Epoch: 535  Training loss = 4.0496  Validation loss = 10.1602  \n",
      "\n",
      "Fold: 14  Epoch: 536  Training loss = 4.0494  Validation loss = 10.1598  \n",
      "\n",
      "Fold: 14  Epoch: 537  Training loss = 4.0491  Validation loss = 10.1594  \n",
      "\n",
      "Fold: 14  Epoch: 538  Training loss = 4.0489  Validation loss = 10.1590  \n",
      "\n",
      "Fold: 14  Epoch: 539  Training loss = 4.0486  Validation loss = 10.1586  \n",
      "\n",
      "Fold: 14  Epoch: 540  Training loss = 4.0483  Validation loss = 10.1582  \n",
      "\n",
      "Fold: 14  Epoch: 541  Training loss = 4.0481  Validation loss = 10.1579  \n",
      "\n",
      "Fold: 14  Epoch: 542  Training loss = 4.0478  Validation loss = 10.1575  \n",
      "\n",
      "Fold: 14  Epoch: 543  Training loss = 4.0475  Validation loss = 10.1570  \n",
      "\n",
      "Fold: 14  Epoch: 544  Training loss = 4.0472  Validation loss = 10.1566  \n",
      "\n",
      "Fold: 14  Epoch: 545  Training loss = 4.0470  Validation loss = 10.1562  \n",
      "\n",
      "Fold: 14  Epoch: 546  Training loss = 4.0467  Validation loss = 10.1559  \n",
      "\n",
      "Fold: 14  Epoch: 547  Training loss = 4.0465  Validation loss = 10.1555  \n",
      "\n",
      "Fold: 14  Epoch: 548  Training loss = 4.0463  Validation loss = 10.1552  \n",
      "\n",
      "Fold: 14  Epoch: 549  Training loss = 4.0461  Validation loss = 10.1549  \n",
      "\n",
      "Fold: 14  Epoch: 550  Training loss = 4.0458  Validation loss = 10.1546  \n",
      "\n",
      "Fold: 14  Epoch: 551  Training loss = 4.0456  Validation loss = 10.1542  \n",
      "\n",
      "Fold: 14  Epoch: 552  Training loss = 4.0454  Validation loss = 10.1539  \n",
      "\n",
      "Fold: 14  Epoch: 553  Training loss = 4.0451  Validation loss = 10.1535  \n",
      "\n",
      "Fold: 14  Epoch: 554  Training loss = 4.0448  Validation loss = 10.1531  \n",
      "\n",
      "Fold: 14  Epoch: 555  Training loss = 4.0446  Validation loss = 10.1527  \n",
      "\n",
      "Fold: 14  Epoch: 556  Training loss = 4.0443  Validation loss = 10.1523  \n",
      "\n",
      "Fold: 14  Epoch: 557  Training loss = 4.0440  Validation loss = 10.1519  \n",
      "\n",
      "Fold: 14  Epoch: 558  Training loss = 4.0437  Validation loss = 10.1515  \n",
      "\n",
      "Fold: 14  Epoch: 559  Training loss = 4.0434  Validation loss = 10.1510  \n",
      "\n",
      "Fold: 14  Epoch: 560  Training loss = 4.0432  Validation loss = 10.1507  \n",
      "\n",
      "Fold: 14  Epoch: 561  Training loss = 4.0429  Validation loss = 10.1503  \n",
      "\n",
      "Fold: 14  Epoch: 562  Training loss = 4.0426  Validation loss = 10.1498  \n",
      "\n",
      "Fold: 14  Epoch: 563  Training loss = 4.0424  Validation loss = 10.1495  \n",
      "\n",
      "Fold: 14  Epoch: 564  Training loss = 4.0421  Validation loss = 10.1491  \n",
      "\n",
      "Fold: 14  Epoch: 565  Training loss = 4.0418  Validation loss = 10.1487  \n",
      "\n",
      "Fold: 14  Epoch: 566  Training loss = 4.0416  Validation loss = 10.1484  \n",
      "\n",
      "Fold: 14  Epoch: 567  Training loss = 4.0414  Validation loss = 10.1480  \n",
      "\n",
      "Fold: 14  Epoch: 568  Training loss = 4.0411  Validation loss = 10.1476  \n",
      "\n",
      "Fold: 14  Epoch: 569  Training loss = 4.0409  Validation loss = 10.1472  \n",
      "\n",
      "Fold: 14  Epoch: 570  Training loss = 4.0406  Validation loss = 10.1469  \n",
      "\n",
      "Fold: 14  Epoch: 571  Training loss = 4.0404  Validation loss = 10.1465  \n",
      "\n",
      "Fold: 14  Epoch: 572  Training loss = 4.0401  Validation loss = 10.1461  \n",
      "\n",
      "Fold: 14  Epoch: 573  Training loss = 4.0398  Validation loss = 10.1457  \n",
      "\n",
      "Fold: 14  Epoch: 574  Training loss = 4.0396  Validation loss = 10.1454  \n",
      "\n",
      "Fold: 14  Epoch: 575  Training loss = 4.0393  Validation loss = 10.1449  \n",
      "\n",
      "Fold: 14  Epoch: 576  Training loss = 4.0390  Validation loss = 10.1445  \n",
      "\n",
      "Fold: 14  Epoch: 577  Training loss = 4.0389  Validation loss = 10.1442  \n",
      "\n",
      "Fold: 14  Epoch: 578  Training loss = 4.0386  Validation loss = 10.1438  \n",
      "\n",
      "Fold: 14  Epoch: 579  Training loss = 4.0383  Validation loss = 10.1433  \n",
      "\n",
      "Fold: 14  Epoch: 580  Training loss = 4.0380  Validation loss = 10.1429  \n",
      "\n",
      "Fold: 14  Epoch: 581  Training loss = 4.0378  Validation loss = 10.1426  \n",
      "\n",
      "Fold: 14  Epoch: 582  Training loss = 4.0375  Validation loss = 10.1422  \n",
      "\n",
      "Fold: 14  Epoch: 583  Training loss = 4.0373  Validation loss = 10.1419  \n",
      "\n",
      "Fold: 14  Epoch: 584  Training loss = 4.0370  Validation loss = 10.1414  \n",
      "\n",
      "Fold: 14  Epoch: 585  Training loss = 4.0368  Validation loss = 10.1411  \n",
      "\n",
      "Fold: 14  Epoch: 586  Training loss = 4.0365  Validation loss = 10.1406  \n",
      "\n",
      "Fold: 14  Epoch: 587  Training loss = 4.0362  Validation loss = 10.1402  \n",
      "\n",
      "Fold: 14  Epoch: 588  Training loss = 4.0359  Validation loss = 10.1398  \n",
      "\n",
      "Fold: 14  Epoch: 589  Training loss = 4.0356  Validation loss = 10.1394  \n",
      "\n",
      "Fold: 14  Epoch: 590  Training loss = 4.0354  Validation loss = 10.1391  \n",
      "\n",
      "Fold: 14  Epoch: 591  Training loss = 4.0351  Validation loss = 10.1386  \n",
      "\n",
      "Fold: 14  Epoch: 592  Training loss = 4.0349  Validation loss = 10.1383  \n",
      "\n",
      "Fold: 14  Epoch: 593  Training loss = 4.0346  Validation loss = 10.1379  \n",
      "\n",
      "Fold: 14  Epoch: 594  Training loss = 4.0344  Validation loss = 10.1375  \n",
      "\n",
      "Fold: 14  Epoch: 595  Training loss = 4.0340  Validation loss = 10.1370  \n",
      "\n",
      "Fold: 14  Epoch: 596  Training loss = 4.0337  Validation loss = 10.1366  \n",
      "\n",
      "Fold: 14  Epoch: 597  Training loss = 4.0335  Validation loss = 10.1362  \n",
      "\n",
      "Fold: 14  Epoch: 598  Training loss = 4.0333  Validation loss = 10.1359  \n",
      "\n",
      "Fold: 14  Epoch: 599  Training loss = 4.0330  Validation loss = 10.1355  \n",
      "\n",
      "Fold: 14  Epoch: 600  Training loss = 4.0327  Validation loss = 10.1351  \n",
      "\n",
      "Fold: 14  Epoch: 601  Training loss = 4.0325  Validation loss = 10.1348  \n",
      "\n",
      "Fold: 14  Epoch: 602  Training loss = 4.0322  Validation loss = 10.1344  \n",
      "\n",
      "Fold: 14  Epoch: 603  Training loss = 4.0319  Validation loss = 10.1338  \n",
      "\n",
      "Fold: 14  Epoch: 604  Training loss = 4.0316  Validation loss = 10.1335  \n",
      "\n",
      "Fold: 14  Epoch: 605  Training loss = 4.0314  Validation loss = 10.1331  \n",
      "\n",
      "Fold: 14  Epoch: 606  Training loss = 4.0311  Validation loss = 10.1327  \n",
      "\n",
      "Fold: 14  Epoch: 607  Training loss = 4.0309  Validation loss = 10.1324  \n",
      "\n",
      "Fold: 14  Epoch: 608  Training loss = 4.0306  Validation loss = 10.1319  \n",
      "\n",
      "Fold: 14  Epoch: 609  Training loss = 4.0303  Validation loss = 10.1315  \n",
      "\n",
      "Fold: 14  Epoch: 610  Training loss = 4.0300  Validation loss = 10.1310  \n",
      "\n",
      "Fold: 14  Epoch: 611  Training loss = 4.0298  Validation loss = 10.1307  \n",
      "\n",
      "Fold: 14  Epoch: 612  Training loss = 4.0295  Validation loss = 10.1303  \n",
      "\n",
      "Fold: 14  Epoch: 613  Training loss = 4.0292  Validation loss = 10.1298  \n",
      "\n",
      "Fold: 14  Epoch: 614  Training loss = 4.0290  Validation loss = 10.1295  \n",
      "\n",
      "Fold: 14  Epoch: 615  Training loss = 4.0287  Validation loss = 10.1292  \n",
      "\n",
      "Fold: 14  Epoch: 616  Training loss = 4.0285  Validation loss = 10.1288  \n",
      "\n",
      "Fold: 14  Epoch: 617  Training loss = 4.0282  Validation loss = 10.1284  \n",
      "\n",
      "Fold: 14  Epoch: 618  Training loss = 4.0280  Validation loss = 10.1281  \n",
      "\n",
      "Fold: 14  Epoch: 619  Training loss = 4.0277  Validation loss = 10.1277  \n",
      "\n",
      "Fold: 14  Epoch: 620  Training loss = 4.0275  Validation loss = 10.1273  \n",
      "\n",
      "Fold: 14  Epoch: 621  Training loss = 4.0273  Validation loss = 10.1270  \n",
      "\n",
      "Fold: 14  Epoch: 622  Training loss = 4.0270  Validation loss = 10.1266  \n",
      "\n",
      "Fold: 14  Epoch: 623  Training loss = 4.0268  Validation loss = 10.1263  \n",
      "\n",
      "Fold: 14  Epoch: 624  Training loss = 4.0265  Validation loss = 10.1259  \n",
      "\n",
      "Fold: 14  Epoch: 625  Training loss = 4.0262  Validation loss = 10.1255  \n",
      "\n",
      "Fold: 14  Epoch: 626  Training loss = 4.0260  Validation loss = 10.1251  \n",
      "\n",
      "Fold: 14  Epoch: 627  Training loss = 4.0257  Validation loss = 10.1248  \n",
      "\n",
      "Fold: 14  Epoch: 628  Training loss = 4.0254  Validation loss = 10.1243  \n",
      "\n",
      "Fold: 14  Epoch: 629  Training loss = 4.0252  Validation loss = 10.1239  \n",
      "\n",
      "Fold: 14  Epoch: 630  Training loss = 4.0249  Validation loss = 10.1235  \n",
      "\n",
      "Fold: 14  Epoch: 631  Training loss = 4.0246  Validation loss = 10.1231  \n",
      "\n",
      "Fold: 14  Epoch: 632  Training loss = 4.0243  Validation loss = 10.1226  \n",
      "\n",
      "Fold: 14  Epoch: 633  Training loss = 4.0240  Validation loss = 10.1222  \n",
      "\n",
      "Fold: 14  Epoch: 634  Training loss = 4.0237  Validation loss = 10.1217  \n",
      "\n",
      "Fold: 14  Epoch: 635  Training loss = 4.0234  Validation loss = 10.1213  \n",
      "\n",
      "Fold: 14  Epoch: 636  Training loss = 4.0232  Validation loss = 10.1209  \n",
      "\n",
      "Fold: 14  Epoch: 637  Training loss = 4.0230  Validation loss = 10.1206  \n",
      "\n",
      "Fold: 14  Epoch: 638  Training loss = 4.0226  Validation loss = 10.1201  \n",
      "\n",
      "Fold: 14  Epoch: 639  Training loss = 4.0225  Validation loss = 10.1199  \n",
      "\n",
      "Fold: 14  Epoch: 640  Training loss = 4.0222  Validation loss = 10.1194  \n",
      "\n",
      "Fold: 14  Epoch: 641  Training loss = 4.0219  Validation loss = 10.1190  \n",
      "\n",
      "Fold: 14  Epoch: 642  Training loss = 4.0217  Validation loss = 10.1187  \n",
      "\n",
      "Fold: 14  Epoch: 643  Training loss = 4.0214  Validation loss = 10.1182  \n",
      "\n",
      "Fold: 14  Epoch: 644  Training loss = 4.0211  Validation loss = 10.1178  \n",
      "\n",
      "Fold: 14  Epoch: 645  Training loss = 4.0209  Validation loss = 10.1175  \n",
      "\n",
      "Fold: 14  Epoch: 646  Training loss = 4.0206  Validation loss = 10.1170  \n",
      "\n",
      "Fold: 14  Epoch: 647  Training loss = 4.0203  Validation loss = 10.1166  \n",
      "\n",
      "Fold: 14  Epoch: 648  Training loss = 4.0201  Validation loss = 10.1163  \n",
      "\n",
      "Fold: 14  Epoch: 649  Training loss = 4.0198  Validation loss = 10.1159  \n",
      "\n",
      "Fold: 14  Epoch: 650  Training loss = 4.0196  Validation loss = 10.1156  \n",
      "\n",
      "Fold: 14  Epoch: 651  Training loss = 4.0194  Validation loss = 10.1152  \n",
      "\n",
      "Fold: 14  Epoch: 652  Training loss = 4.0191  Validation loss = 10.1149  \n",
      "\n",
      "Fold: 14  Epoch: 653  Training loss = 4.0188  Validation loss = 10.1144  \n",
      "\n",
      "Fold: 14  Epoch: 654  Training loss = 4.0185  Validation loss = 10.1140  \n",
      "\n",
      "Fold: 14  Epoch: 655  Training loss = 4.0183  Validation loss = 10.1136  \n",
      "\n",
      "Fold: 14  Epoch: 656  Training loss = 4.0180  Validation loss = 10.1132  \n",
      "\n",
      "Fold: 14  Epoch: 657  Training loss = 4.0177  Validation loss = 10.1127  \n",
      "\n",
      "Fold: 14  Epoch: 658  Training loss = 4.0174  Validation loss = 10.1123  \n",
      "\n",
      "Fold: 14  Epoch: 659  Training loss = 4.0172  Validation loss = 10.1119  \n",
      "\n",
      "Fold: 14  Epoch: 660  Training loss = 4.0169  Validation loss = 10.1116  \n",
      "\n",
      "Fold: 14  Epoch: 661  Training loss = 4.0166  Validation loss = 10.1111  \n",
      "\n",
      "Fold: 14  Epoch: 662  Training loss = 4.0164  Validation loss = 10.1108  \n",
      "\n",
      "Fold: 14  Epoch: 663  Training loss = 4.0161  Validation loss = 10.1103  \n",
      "\n",
      "Fold: 14  Epoch: 664  Training loss = 4.0158  Validation loss = 10.1100  \n",
      "\n",
      "Fold: 14  Epoch: 665  Training loss = 4.0156  Validation loss = 10.1095  \n",
      "\n",
      "Fold: 14  Epoch: 666  Training loss = 4.0153  Validation loss = 10.1092  \n",
      "\n",
      "Fold: 14  Epoch: 667  Training loss = 4.0151  Validation loss = 10.1089  \n",
      "\n",
      "Fold: 14  Epoch: 668  Training loss = 4.0149  Validation loss = 10.1085  \n",
      "\n",
      "Fold: 14  Epoch: 669  Training loss = 4.0146  Validation loss = 10.1081  \n",
      "\n",
      "Fold: 14  Epoch: 670  Training loss = 4.0144  Validation loss = 10.1078  \n",
      "\n",
      "Fold: 14  Epoch: 671  Training loss = 4.0141  Validation loss = 10.1074  \n",
      "\n",
      "Fold: 14  Epoch: 672  Training loss = 4.0138  Validation loss = 10.1069  \n",
      "\n",
      "Fold: 14  Epoch: 673  Training loss = 4.0136  Validation loss = 10.1066  \n",
      "\n",
      "Fold: 14  Epoch: 674  Training loss = 4.0134  Validation loss = 10.1063  \n",
      "\n",
      "Fold: 14  Epoch: 675  Training loss = 4.0131  Validation loss = 10.1058  \n",
      "\n",
      "Fold: 14  Epoch: 676  Training loss = 4.0128  Validation loss = 10.1054  \n",
      "\n",
      "Fold: 14  Epoch: 677  Training loss = 4.0126  Validation loss = 10.1050  \n",
      "\n",
      "Fold: 14  Epoch: 678  Training loss = 4.0124  Validation loss = 10.1047  \n",
      "\n",
      "Fold: 14  Epoch: 679  Training loss = 4.0121  Validation loss = 10.1044  \n",
      "\n",
      "Fold: 14  Epoch: 680  Training loss = 4.0118  Validation loss = 10.1039  \n",
      "\n",
      "Fold: 14  Epoch: 681  Training loss = 4.0116  Validation loss = 10.1035  \n",
      "\n",
      "Fold: 14  Epoch: 682  Training loss = 4.0113  Validation loss = 10.1031  \n",
      "\n",
      "Fold: 14  Epoch: 683  Training loss = 4.0110  Validation loss = 10.1027  \n",
      "\n",
      "Fold: 14  Epoch: 684  Training loss = 4.0108  Validation loss = 10.1023  \n",
      "\n",
      "Fold: 14  Epoch: 685  Training loss = 4.0106  Validation loss = 10.1020  \n",
      "\n",
      "Fold: 14  Epoch: 686  Training loss = 4.0103  Validation loss = 10.1016  \n",
      "\n",
      "Fold: 14  Epoch: 687  Training loss = 4.0100  Validation loss = 10.1012  \n",
      "\n",
      "Fold: 14  Epoch: 688  Training loss = 4.0098  Validation loss = 10.1008  \n",
      "\n",
      "Fold: 14  Epoch: 689  Training loss = 4.0095  Validation loss = 10.1005  \n",
      "\n",
      "Fold: 14  Epoch: 690  Training loss = 4.0093  Validation loss = 10.1001  \n",
      "\n",
      "Fold: 14  Epoch: 691  Training loss = 4.0090  Validation loss = 10.0997  \n",
      "\n",
      "Fold: 14  Epoch: 692  Training loss = 4.0088  Validation loss = 10.0993  \n",
      "\n",
      "Fold: 14  Epoch: 693  Training loss = 4.0085  Validation loss = 10.0989  \n",
      "\n",
      "Fold: 14  Epoch: 694  Training loss = 4.0082  Validation loss = 10.0985  \n",
      "\n",
      "Fold: 14  Epoch: 695  Training loss = 4.0080  Validation loss = 10.0981  \n",
      "\n",
      "Fold: 14  Epoch: 696  Training loss = 4.0077  Validation loss = 10.0978  \n",
      "\n",
      "Fold: 14  Epoch: 697  Training loss = 4.0075  Validation loss = 10.0974  \n",
      "\n",
      "Fold: 14  Epoch: 698  Training loss = 4.0073  Validation loss = 10.0971  \n",
      "\n",
      "Fold: 14  Epoch: 699  Training loss = 4.0070  Validation loss = 10.0966  \n",
      "\n",
      "Fold: 14  Epoch: 700  Training loss = 4.0067  Validation loss = 10.0963  \n",
      "\n",
      "Fold: 14  Epoch: 701  Training loss = 4.0065  Validation loss = 10.0959  \n",
      "\n",
      "Fold: 14  Epoch: 702  Training loss = 4.0062  Validation loss = 10.0955  \n",
      "\n",
      "Fold: 14  Epoch: 703  Training loss = 4.0059  Validation loss = 10.0951  \n",
      "\n",
      "Fold: 14  Epoch: 704  Training loss = 4.0057  Validation loss = 10.0947  \n",
      "\n",
      "Fold: 14  Epoch: 705  Training loss = 4.0054  Validation loss = 10.0943  \n",
      "\n",
      "Fold: 14  Epoch: 706  Training loss = 4.0051  Validation loss = 10.0938  \n",
      "\n",
      "Fold: 14  Epoch: 707  Training loss = 4.0048  Validation loss = 10.0934  \n",
      "\n",
      "Fold: 14  Epoch: 708  Training loss = 4.0046  Validation loss = 10.0930  \n",
      "\n",
      "Fold: 14  Epoch: 709  Training loss = 4.0044  Validation loss = 10.0928  \n",
      "\n",
      "Fold: 14  Epoch: 710  Training loss = 4.0041  Validation loss = 10.0924  \n",
      "\n",
      "Fold: 14  Epoch: 711  Training loss = 4.0038  Validation loss = 10.0919  \n",
      "\n",
      "Fold: 14  Epoch: 712  Training loss = 4.0035  Validation loss = 10.0915  \n",
      "\n",
      "Fold: 14  Epoch: 713  Training loss = 4.0033  Validation loss = 10.0911  \n",
      "\n",
      "Fold: 14  Epoch: 714  Training loss = 4.0031  Validation loss = 10.0908  \n",
      "\n",
      "Fold: 14  Epoch: 715  Training loss = 4.0028  Validation loss = 10.0904  \n",
      "\n",
      "Fold: 14  Epoch: 716  Training loss = 4.0026  Validation loss = 10.0900  \n",
      "\n",
      "Fold: 14  Epoch: 717  Training loss = 4.0023  Validation loss = 10.0897  \n",
      "\n",
      "Fold: 14  Epoch: 718  Training loss = 4.0021  Validation loss = 10.0893  \n",
      "\n",
      "Fold: 14  Epoch: 719  Training loss = 4.0018  Validation loss = 10.0889  \n",
      "\n",
      "Fold: 14  Epoch: 720  Training loss = 4.0016  Validation loss = 10.0885  \n",
      "\n",
      "Fold: 14  Epoch: 721  Training loss = 4.0013  Validation loss = 10.0881  \n",
      "\n",
      "Fold: 14  Epoch: 722  Training loss = 4.0011  Validation loss = 10.0878  \n",
      "\n",
      "Fold: 14  Epoch: 723  Training loss = 4.0007  Validation loss = 10.0873  \n",
      "\n",
      "Fold: 14  Epoch: 724  Training loss = 4.0005  Validation loss = 10.0869  \n",
      "\n",
      "Fold: 14  Epoch: 725  Training loss = 4.0003  Validation loss = 10.0866  \n",
      "\n",
      "Fold: 14  Epoch: 726  Training loss = 4.0000  Validation loss = 10.0862  \n",
      "\n",
      "Fold: 14  Epoch: 727  Training loss = 3.9998  Validation loss = 10.0859  \n",
      "\n",
      "Fold: 14  Epoch: 728  Training loss = 3.9996  Validation loss = 10.0855  \n",
      "\n",
      "Fold: 14  Epoch: 729  Training loss = 3.9993  Validation loss = 10.0852  \n",
      "\n",
      "Fold: 14  Epoch: 730  Training loss = 3.9991  Validation loss = 10.0848  \n",
      "\n",
      "Fold: 14  Epoch: 731  Training loss = 3.9989  Validation loss = 10.0844  \n",
      "\n",
      "Fold: 14  Epoch: 732  Training loss = 3.9986  Validation loss = 10.0841  \n",
      "\n",
      "Fold: 14  Epoch: 733  Training loss = 3.9984  Validation loss = 10.0838  \n",
      "\n",
      "Fold: 14  Epoch: 734  Training loss = 3.9982  Validation loss = 10.0834  \n",
      "\n",
      "Fold: 14  Epoch: 735  Training loss = 3.9979  Validation loss = 10.0831  \n",
      "\n",
      "Fold: 14  Epoch: 736  Training loss = 3.9977  Validation loss = 10.0826  \n",
      "\n",
      "Fold: 14  Epoch: 737  Training loss = 3.9974  Validation loss = 10.0822  \n",
      "\n",
      "Fold: 14  Epoch: 738  Training loss = 3.9971  Validation loss = 10.0818  \n",
      "\n",
      "Fold: 14  Epoch: 739  Training loss = 3.9969  Validation loss = 10.0815  \n",
      "\n",
      "Fold: 14  Epoch: 740  Training loss = 3.9966  Validation loss = 10.0811  \n",
      "\n",
      "Fold: 14  Epoch: 741  Training loss = 3.9964  Validation loss = 10.0807  \n",
      "\n",
      "Fold: 14  Epoch: 742  Training loss = 3.9962  Validation loss = 10.0804  \n",
      "\n",
      "Fold: 14  Epoch: 743  Training loss = 3.9959  Validation loss = 10.0800  \n",
      "\n",
      "Fold: 14  Epoch: 744  Training loss = 3.9956  Validation loss = 10.0795  \n",
      "\n",
      "Fold: 14  Epoch: 745  Training loss = 3.9954  Validation loss = 10.0793  \n",
      "\n",
      "Fold: 14  Epoch: 746  Training loss = 3.9952  Validation loss = 10.0789  \n",
      "\n",
      "Fold: 14  Epoch: 747  Training loss = 3.9950  Validation loss = 10.0785  \n",
      "\n",
      "Fold: 14  Epoch: 748  Training loss = 3.9947  Validation loss = 10.0781  \n",
      "\n",
      "Fold: 14  Epoch: 749  Training loss = 3.9944  Validation loss = 10.0777  \n",
      "\n",
      "Fold: 14  Epoch: 750  Training loss = 3.9942  Validation loss = 10.0774  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 750  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 4.7052  Validation loss = 10.8724  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 4.7049  Validation loss = 10.8721  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 4.7046  Validation loss = 10.8718  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 4.7043  Validation loss = 10.8715  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 4.7039  Validation loss = 10.8712  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 4.7036  Validation loss = 10.8709  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 4.7032  Validation loss = 10.8704  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 4.7029  Validation loss = 10.8700  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 4.7026  Validation loss = 10.8697  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 4.7023  Validation loss = 10.8694  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 4.7019  Validation loss = 10.8691  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 4.7016  Validation loss = 10.8687  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 4.7013  Validation loss = 10.8684  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 4.7010  Validation loss = 10.8681  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 4.7007  Validation loss = 10.8678  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 4.7004  Validation loss = 10.8674  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 4.7001  Validation loss = 10.8671  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 4.6998  Validation loss = 10.8668  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 4.6995  Validation loss = 10.8665  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 4.6991  Validation loss = 10.8660  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 4.6987  Validation loss = 10.8656  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 4.6983  Validation loss = 10.8652  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 4.6980  Validation loss = 10.8649  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 4.6977  Validation loss = 10.8646  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 4.6974  Validation loss = 10.8642  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 4.6970  Validation loss = 10.8638  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 4.6967  Validation loss = 10.8635  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 4.6962  Validation loss = 10.8629  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 4.6959  Validation loss = 10.8625  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 4.6955  Validation loss = 10.8622  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 4.6952  Validation loss = 10.8619  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 4.6948  Validation loss = 10.8616  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 4.6945  Validation loss = 10.8612  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 4.6941  Validation loss = 10.8608  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 4.6938  Validation loss = 10.8605  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 4.6935  Validation loss = 10.8602  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 4.6932  Validation loss = 10.8599  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 4.6928  Validation loss = 10.8595  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 4.6925  Validation loss = 10.8591  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 4.6922  Validation loss = 10.8588  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 4.6918  Validation loss = 10.8584  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 4.6914  Validation loss = 10.8579  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 4.6911  Validation loss = 10.8576  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 4.6908  Validation loss = 10.8571  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 4.6905  Validation loss = 10.8568  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 4.6902  Validation loss = 10.8565  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 4.6899  Validation loss = 10.8562  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 4.6896  Validation loss = 10.8559  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 4.6893  Validation loss = 10.8556  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 4.6889  Validation loss = 10.8551  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 4.6886  Validation loss = 10.8548  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 4.6882  Validation loss = 10.8544  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 4.6878  Validation loss = 10.8539  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 4.6875  Validation loss = 10.8536  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 4.6871  Validation loss = 10.8532  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 4.6868  Validation loss = 10.8528  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 4.6864  Validation loss = 10.8523  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 4.6860  Validation loss = 10.8520  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 4.6857  Validation loss = 10.8517  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 4.6853  Validation loss = 10.8512  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 4.6850  Validation loss = 10.8508  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 4.6847  Validation loss = 10.8505  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 4.6844  Validation loss = 10.8501  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 4.6840  Validation loss = 10.8496  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 4.6837  Validation loss = 10.8492  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 4.6833  Validation loss = 10.8488  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 4.6830  Validation loss = 10.8484  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 4.6827  Validation loss = 10.8480  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 4.6823  Validation loss = 10.8476  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 4.6819  Validation loss = 10.8472  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 4.6816  Validation loss = 10.8469  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 4.6812  Validation loss = 10.8464  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 4.6810  Validation loss = 10.8462  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 4.6807  Validation loss = 10.8458  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 4.6802  Validation loss = 10.8452  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 4.6799  Validation loss = 10.8449  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 4.6796  Validation loss = 10.8445  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 4.6793  Validation loss = 10.8442  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 4.6791  Validation loss = 10.8440  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 4.6788  Validation loss = 10.8436  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 4.6785  Validation loss = 10.8432  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 4.6781  Validation loss = 10.8429  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 4.6778  Validation loss = 10.8425  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 4.6774  Validation loss = 10.8420  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 4.6771  Validation loss = 10.8416  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 4.6767  Validation loss = 10.8411  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 4.6764  Validation loss = 10.8407  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 4.6760  Validation loss = 10.8404  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 4.6756  Validation loss = 10.8399  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 4.6753  Validation loss = 10.8396  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 4.6749  Validation loss = 10.8392  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 4.6746  Validation loss = 10.8389  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 4.6743  Validation loss = 10.8384  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 4.6739  Validation loss = 10.8380  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 4.6735  Validation loss = 10.8375  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 4.6732  Validation loss = 10.8370  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 4.6728  Validation loss = 10.8364  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 4.6724  Validation loss = 10.8360  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 4.6721  Validation loss = 10.8357  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 4.6718  Validation loss = 10.8353  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 4.6714  Validation loss = 10.8350  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 4.6711  Validation loss = 10.8345  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 4.6707  Validation loss = 10.8341  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 4.6704  Validation loss = 10.8337  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 4.6700  Validation loss = 10.8334  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 4.6696  Validation loss = 10.8329  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 4.6693  Validation loss = 10.8325  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 4.6690  Validation loss = 10.8321  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 4.6687  Validation loss = 10.8316  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 4.6683  Validation loss = 10.8312  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 4.6679  Validation loss = 10.8307  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 4.6676  Validation loss = 10.8303  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 4.6673  Validation loss = 10.8301  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 4.6670  Validation loss = 10.8296  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 4.6666  Validation loss = 10.8291  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 4.6663  Validation loss = 10.8286  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 4.6659  Validation loss = 10.8282  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 4.6657  Validation loss = 10.8279  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 4.6653  Validation loss = 10.8275  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 4.6650  Validation loss = 10.8270  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 4.6647  Validation loss = 10.8266  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 4.6643  Validation loss = 10.8262  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 4.6640  Validation loss = 10.8258  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 4.6637  Validation loss = 10.8255  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 4.6633  Validation loss = 10.8251  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 4.6630  Validation loss = 10.8248  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 4.6627  Validation loss = 10.8244  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 4.6624  Validation loss = 10.8239  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 4.6620  Validation loss = 10.8235  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 4.6616  Validation loss = 10.8231  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 4.6613  Validation loss = 10.8228  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 4.6609  Validation loss = 10.8223  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 4.6606  Validation loss = 10.8220  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 4.6603  Validation loss = 10.8216  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 4.6599  Validation loss = 10.8212  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 4.6596  Validation loss = 10.8209  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 4.6593  Validation loss = 10.8205  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 4.6590  Validation loss = 10.8201  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 4.6587  Validation loss = 10.8198  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 4.6583  Validation loss = 10.8193  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 4.6580  Validation loss = 10.8189  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 4.6577  Validation loss = 10.8185  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 4.6573  Validation loss = 10.8181  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 4.6569  Validation loss = 10.8177  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 4.6565  Validation loss = 10.8172  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 4.6562  Validation loss = 10.8169  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 4.6559  Validation loss = 10.8164  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 4.6555  Validation loss = 10.8161  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 4.6552  Validation loss = 10.8156  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 4.6549  Validation loss = 10.8152  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 4.6545  Validation loss = 10.8148  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 4.6542  Validation loss = 10.8144  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 4.6539  Validation loss = 10.8140  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 4.6535  Validation loss = 10.8135  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 4.6532  Validation loss = 10.8133  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 4.6529  Validation loss = 10.8129  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 4.6526  Validation loss = 10.8126  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 4.6522  Validation loss = 10.8122  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 4.6519  Validation loss = 10.8119  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 4.6515  Validation loss = 10.8113  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 4.6511  Validation loss = 10.8109  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 4.6507  Validation loss = 10.8104  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 4.6503  Validation loss = 10.8099  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 4.6500  Validation loss = 10.8095  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 4.6496  Validation loss = 10.8091  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 4.6493  Validation loss = 10.8088  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 4.6490  Validation loss = 10.8083  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 4.6486  Validation loss = 10.8080  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 4.6482  Validation loss = 10.8074  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 4.6479  Validation loss = 10.8071  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 4.6476  Validation loss = 10.8067  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 4.6472  Validation loss = 10.8062  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 4.6469  Validation loss = 10.8058  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 4.6466  Validation loss = 10.8055  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 4.6463  Validation loss = 10.8051  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 4.6459  Validation loss = 10.8047  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 4.6455  Validation loss = 10.8042  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 4.6452  Validation loss = 10.8038  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 4.6448  Validation loss = 10.8034  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 4.6445  Validation loss = 10.8030  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 4.6442  Validation loss = 10.8027  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 4.6438  Validation loss = 10.8022  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 4.6436  Validation loss = 10.8019  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 4.6431  Validation loss = 10.8013  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 4.6428  Validation loss = 10.8009  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 4.6425  Validation loss = 10.8006  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 4.6422  Validation loss = 10.8003  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 4.6419  Validation loss = 10.7999  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 4.6416  Validation loss = 10.7996  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 4.6413  Validation loss = 10.7993  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 4.6409  Validation loss = 10.7989  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 4.6406  Validation loss = 10.7986  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 4.6403  Validation loss = 10.7982  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 4.6400  Validation loss = 10.7979  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 4.6397  Validation loss = 10.7976  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 4.6394  Validation loss = 10.7972  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 4.6391  Validation loss = 10.7969  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 4.6388  Validation loss = 10.7966  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 4.6386  Validation loss = 10.7964  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 4.6382  Validation loss = 10.7960  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 4.6378  Validation loss = 10.7956  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 4.6375  Validation loss = 10.7953  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 4.6372  Validation loss = 10.7948  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 4.6368  Validation loss = 10.7944  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 4.6364  Validation loss = 10.7939  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 4.6361  Validation loss = 10.7936  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 4.6358  Validation loss = 10.7932  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 4.6355  Validation loss = 10.7929  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 4.6351  Validation loss = 10.7925  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 4.6348  Validation loss = 10.7922  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 4.6345  Validation loss = 10.7918  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 4.6342  Validation loss = 10.7915  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 4.6339  Validation loss = 10.7912  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 4.6336  Validation loss = 10.7908  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 4.6333  Validation loss = 10.7906  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 4.6330  Validation loss = 10.7902  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 4.6327  Validation loss = 10.7899  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 4.6324  Validation loss = 10.7897  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 4.6321  Validation loss = 10.7893  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 4.6317  Validation loss = 10.7890  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 4.6314  Validation loss = 10.7886  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 4.6310  Validation loss = 10.7882  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 4.6306  Validation loss = 10.7877  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 4.6303  Validation loss = 10.7874  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 4.6299  Validation loss = 10.7870  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 4.6296  Validation loss = 10.7866  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 4.6292  Validation loss = 10.7860  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 4.6289  Validation loss = 10.7857  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 4.6285  Validation loss = 10.7854  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 4.6282  Validation loss = 10.7850  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 4.6279  Validation loss = 10.7847  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 4.6276  Validation loss = 10.7843  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 4.6272  Validation loss = 10.7839  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 4.6269  Validation loss = 10.7834  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 4.6265  Validation loss = 10.7830  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 4.6261  Validation loss = 10.7826  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 4.6258  Validation loss = 10.7821  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 4.6254  Validation loss = 10.7817  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 4.6251  Validation loss = 10.7813  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 4.6248  Validation loss = 10.7810  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 4.6244  Validation loss = 10.7806  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 4.6241  Validation loss = 10.7802  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 4.6237  Validation loss = 10.7798  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 4.6233  Validation loss = 10.7794  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 4.6231  Validation loss = 10.7791  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 4.6227  Validation loss = 10.7787  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 4.6224  Validation loss = 10.7784  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 4.6221  Validation loss = 10.7780  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 4.6217  Validation loss = 10.7775  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 4.6214  Validation loss = 10.7771  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 4.6210  Validation loss = 10.7768  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 4.6207  Validation loss = 10.7764  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 4.6203  Validation loss = 10.7760  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 4.6199  Validation loss = 10.7755  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 4.6196  Validation loss = 10.7751  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 4.6192  Validation loss = 10.7747  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 4.6189  Validation loss = 10.7744  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 4.6185  Validation loss = 10.7740  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 4.6183  Validation loss = 10.7737  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 4.6180  Validation loss = 10.7734  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 4.6177  Validation loss = 10.7731  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 4.6174  Validation loss = 10.7727  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 4.6170  Validation loss = 10.7724  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 4.6167  Validation loss = 10.7720  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 4.6163  Validation loss = 10.7717  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 4.6160  Validation loss = 10.7713  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 4.6156  Validation loss = 10.7709  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 4.6153  Validation loss = 10.7706  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 4.6150  Validation loss = 10.7702  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 4.6146  Validation loss = 10.7698  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 4.6143  Validation loss = 10.7696  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 4.6140  Validation loss = 10.7693  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 4.6137  Validation loss = 10.7689  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 4.6133  Validation loss = 10.7686  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 4.6130  Validation loss = 10.7682  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 4.6126  Validation loss = 10.7679  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 4.6123  Validation loss = 10.7674  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 4.6120  Validation loss = 10.7671  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 4.6117  Validation loss = 10.7667  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 4.6114  Validation loss = 10.7664  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 4.6111  Validation loss = 10.7661  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 4.6108  Validation loss = 10.7658  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 4.6104  Validation loss = 10.7654  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 4.6101  Validation loss = 10.7651  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 4.6098  Validation loss = 10.7648  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 4.6095  Validation loss = 10.7644  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 4.6092  Validation loss = 10.7641  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 4.6089  Validation loss = 10.7639  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 4.6086  Validation loss = 10.7635  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 4.6082  Validation loss = 10.7631  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 4.6079  Validation loss = 10.7625  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 4.6076  Validation loss = 10.7622  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 4.6072  Validation loss = 10.7618  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 4.6069  Validation loss = 10.7616  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 4.6065  Validation loss = 10.7611  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 4.6062  Validation loss = 10.7608  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 4.6059  Validation loss = 10.7605  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 4.6056  Validation loss = 10.7602  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 4.6053  Validation loss = 10.7599  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 4.6050  Validation loss = 10.7596  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 4.6047  Validation loss = 10.7593  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 4.6043  Validation loss = 10.7588  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 4.6039  Validation loss = 10.7584  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 4.6036  Validation loss = 10.7580  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 4.6032  Validation loss = 10.7577  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 4.6029  Validation loss = 10.7574  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 4.6026  Validation loss = 10.7570  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 4.6022  Validation loss = 10.7567  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 4.6019  Validation loss = 10.7563  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 4.6015  Validation loss = 10.7558  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 4.6012  Validation loss = 10.7555  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 4.6009  Validation loss = 10.7551  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 4.6005  Validation loss = 10.7548  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 4.6002  Validation loss = 10.7544  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 4.5998  Validation loss = 10.7540  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 4.5995  Validation loss = 10.7536  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 4.5992  Validation loss = 10.7533  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 4.5989  Validation loss = 10.7530  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 4.5985  Validation loss = 10.7527  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 4.5983  Validation loss = 10.7524  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 4.5979  Validation loss = 10.7520  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 4.5976  Validation loss = 10.7517  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 4.5972  Validation loss = 10.7512  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 4.5970  Validation loss = 10.7510  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 4.5967  Validation loss = 10.7507  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 4.5964  Validation loss = 10.7504  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 4.5961  Validation loss = 10.7500  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 4.5958  Validation loss = 10.7498  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 4.5954  Validation loss = 10.7494  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 4.5951  Validation loss = 10.7490  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 4.5948  Validation loss = 10.7487  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 4.5944  Validation loss = 10.7484  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 4.5941  Validation loss = 10.7480  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 4.5938  Validation loss = 10.7477  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 4.5935  Validation loss = 10.7474  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 4.5932  Validation loss = 10.7470  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 4.5928  Validation loss = 10.7466  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 4.5926  Validation loss = 10.7463  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 4.5922  Validation loss = 10.7460  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 4.5919  Validation loss = 10.7456  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 4.5915  Validation loss = 10.7452  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 4.5912  Validation loss = 10.7449  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 4.5909  Validation loss = 10.7445  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 4.5906  Validation loss = 10.7442  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 4.5903  Validation loss = 10.7439  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 4.5900  Validation loss = 10.7436  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 4.5897  Validation loss = 10.7433  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 4.5894  Validation loss = 10.7429  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 4.5890  Validation loss = 10.7426  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 4.5887  Validation loss = 10.7422  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 4.5884  Validation loss = 10.7419  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 4.5880  Validation loss = 10.7416  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 4.5877  Validation loss = 10.7411  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 4.5874  Validation loss = 10.7408  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 4.5872  Validation loss = 10.7405  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 4.5868  Validation loss = 10.7401  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 4.5864  Validation loss = 10.7397  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 4.5861  Validation loss = 10.7393  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 4.5858  Validation loss = 10.7390  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 4.5854  Validation loss = 10.7386  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 4.5850  Validation loss = 10.7382  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 4.5847  Validation loss = 10.7379  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 4.5844  Validation loss = 10.7376  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 4.5841  Validation loss = 10.7372  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 4.5838  Validation loss = 10.7369  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 4.5835  Validation loss = 10.7365  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 4.5832  Validation loss = 10.7362  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 4.5828  Validation loss = 10.7358  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 4.5824  Validation loss = 10.7354  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 4.5821  Validation loss = 10.7351  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 4.5817  Validation loss = 10.7348  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 4.5814  Validation loss = 10.7344  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 4.5811  Validation loss = 10.7341  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 4.5808  Validation loss = 10.7338  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 4.5805  Validation loss = 10.7335  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 4.5801  Validation loss = 10.7332  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 4.5798  Validation loss = 10.7327  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 4.5795  Validation loss = 10.7325  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 4.5792  Validation loss = 10.7321  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 4.5789  Validation loss = 10.7318  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 4.5786  Validation loss = 10.7315  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 4.5783  Validation loss = 10.7312  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 4.5779  Validation loss = 10.7308  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 4.5776  Validation loss = 10.7304  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 4.5773  Validation loss = 10.7301  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 4.5769  Validation loss = 10.7297  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 4.5765  Validation loss = 10.7293  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 4.5762  Validation loss = 10.7290  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 4.5760  Validation loss = 10.7287  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 4.5756  Validation loss = 10.7284  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 4.5753  Validation loss = 10.7281  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 4.5750  Validation loss = 10.7278  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 4.5747  Validation loss = 10.7275  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 4.5744  Validation loss = 10.7272  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 4.5740  Validation loss = 10.7268  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 4.5737  Validation loss = 10.7265  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 4.5734  Validation loss = 10.7261  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 4.5731  Validation loss = 10.7258  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 4.5728  Validation loss = 10.7255  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 4.5724  Validation loss = 10.7251  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 4.5721  Validation loss = 10.7248  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 4.5718  Validation loss = 10.7244  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 4.5715  Validation loss = 10.7240  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 4.5712  Validation loss = 10.7237  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 4.5708  Validation loss = 10.7233  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 4.5705  Validation loss = 10.7230  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 4.5703  Validation loss = 10.7228  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 4.5699  Validation loss = 10.7224  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 4.5697  Validation loss = 10.7222  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 4.5693  Validation loss = 10.7217  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 4.5689  Validation loss = 10.7214  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 4.5686  Validation loss = 10.7210  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 4.5683  Validation loss = 10.7207  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 4.5680  Validation loss = 10.7204  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 4.5676  Validation loss = 10.7199  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 4.5672  Validation loss = 10.7195  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 4.5670  Validation loss = 10.7193  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 4.5667  Validation loss = 10.7189  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 4.5663  Validation loss = 10.7186  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 4.5660  Validation loss = 10.7183  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 4.5658  Validation loss = 10.7180  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 4.5654  Validation loss = 10.7176  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 4.5651  Validation loss = 10.7173  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 4.5648  Validation loss = 10.7170  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 4.5645  Validation loss = 10.7167  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 4.5642  Validation loss = 10.7164  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 4.5639  Validation loss = 10.7161  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 4.5636  Validation loss = 10.7158  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 4.5633  Validation loss = 10.7154  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 4.5630  Validation loss = 10.7150  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 4.5627  Validation loss = 10.7147  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 4.5625  Validation loss = 10.7144  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 4.5621  Validation loss = 10.7140  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 4.5618  Validation loss = 10.7137  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 4.5615  Validation loss = 10.7133  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 4.5611  Validation loss = 10.7129  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 4.5608  Validation loss = 10.7126  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 4.5604  Validation loss = 10.7122  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 4.5601  Validation loss = 10.7119  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 4.5598  Validation loss = 10.7114  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 4.5594  Validation loss = 10.7111  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 4.5590  Validation loss = 10.7106  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 4.5587  Validation loss = 10.7102  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 4.5584  Validation loss = 10.7099  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 4.5581  Validation loss = 10.7096  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 4.5577  Validation loss = 10.7092  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 4.5573  Validation loss = 10.7088  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 4.5570  Validation loss = 10.7085  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 4.5566  Validation loss = 10.7081  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 4.5563  Validation loss = 10.7078  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 4.5561  Validation loss = 10.7075  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 4.5558  Validation loss = 10.7072  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 4.5555  Validation loss = 10.7069  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 4.5551  Validation loss = 10.7066  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 4.5548  Validation loss = 10.7062  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 4.5545  Validation loss = 10.7059  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 4.5542  Validation loss = 10.7056  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 4.5539  Validation loss = 10.7052  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 4.5535  Validation loss = 10.7049  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 4.5533  Validation loss = 10.7046  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 4.5529  Validation loss = 10.7043  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 4.5527  Validation loss = 10.7039  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 4.5523  Validation loss = 10.7036  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 4.5520  Validation loss = 10.7033  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 4.5517  Validation loss = 10.7029  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 4.5514  Validation loss = 10.7026  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 4.5511  Validation loss = 10.7022  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 4.5508  Validation loss = 10.7019  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 4.5505  Validation loss = 10.7016  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 4.5502  Validation loss = 10.7013  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 4.5498  Validation loss = 10.7009  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 4.5495  Validation loss = 10.7005  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 4.5492  Validation loss = 10.7002  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 4.5489  Validation loss = 10.6999  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 4.5486  Validation loss = 10.6997  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 4.5484  Validation loss = 10.6994  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 4.5481  Validation loss = 10.6991  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 4.5478  Validation loss = 10.6988  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 4.5475  Validation loss = 10.6984  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 4.5473  Validation loss = 10.6982  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 4.5469  Validation loss = 10.6978  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 4.5466  Validation loss = 10.6974  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 4.5463  Validation loss = 10.6971  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 4.5459  Validation loss = 10.6967  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 4.5456  Validation loss = 10.6964  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 4.5453  Validation loss = 10.6961  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 4.5451  Validation loss = 10.6958  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 4.5448  Validation loss = 10.6956  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 4.5445  Validation loss = 10.6953  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 4.5442  Validation loss = 10.6949  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 4.5440  Validation loss = 10.6946  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 4.5436  Validation loss = 10.6943  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 4.5433  Validation loss = 10.6940  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 4.5430  Validation loss = 10.6937  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 4.5427  Validation loss = 10.6933  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 4.5424  Validation loss = 10.6930  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 4.5421  Validation loss = 10.6927  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 4.5418  Validation loss = 10.6923  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 4.5414  Validation loss = 10.6919  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 4.5411  Validation loss = 10.6916  \n",
      "\n",
      "Fold: 15  Epoch: 501  Training loss = 4.5408  Validation loss = 10.6913  \n",
      "\n",
      "Fold: 15  Epoch: 502  Training loss = 4.5405  Validation loss = 10.6910  \n",
      "\n",
      "Fold: 15  Epoch: 503  Training loss = 4.5402  Validation loss = 10.6906  \n",
      "\n",
      "Fold: 15  Epoch: 504  Training loss = 4.5399  Validation loss = 10.6903  \n",
      "\n",
      "Fold: 15  Epoch: 505  Training loss = 4.5396  Validation loss = 10.6900  \n",
      "\n",
      "Fold: 15  Epoch: 506  Training loss = 4.5393  Validation loss = 10.6896  \n",
      "\n",
      "Fold: 15  Epoch: 507  Training loss = 4.5389  Validation loss = 10.6893  \n",
      "\n",
      "Fold: 15  Epoch: 508  Training loss = 4.5387  Validation loss = 10.6890  \n",
      "\n",
      "Fold: 15  Epoch: 509  Training loss = 4.5384  Validation loss = 10.6887  \n",
      "\n",
      "Fold: 15  Epoch: 510  Training loss = 4.5380  Validation loss = 10.6883  \n",
      "\n",
      "Fold: 15  Epoch: 511  Training loss = 4.5377  Validation loss = 10.6880  \n",
      "\n",
      "Fold: 15  Epoch: 512  Training loss = 4.5373  Validation loss = 10.6876  \n",
      "\n",
      "Fold: 15  Epoch: 513  Training loss = 4.5371  Validation loss = 10.6874  \n",
      "\n",
      "Fold: 15  Epoch: 514  Training loss = 4.5368  Validation loss = 10.6871  \n",
      "\n",
      "Fold: 15  Epoch: 515  Training loss = 4.5365  Validation loss = 10.6868  \n",
      "\n",
      "Fold: 15  Epoch: 516  Training loss = 4.5362  Validation loss = 10.6865  \n",
      "\n",
      "Fold: 15  Epoch: 517  Training loss = 4.5359  Validation loss = 10.6862  \n",
      "\n",
      "Fold: 15  Epoch: 518  Training loss = 4.5356  Validation loss = 10.6859  \n",
      "\n",
      "Fold: 15  Epoch: 519  Training loss = 4.5353  Validation loss = 10.6856  \n",
      "\n",
      "Fold: 15  Epoch: 520  Training loss = 4.5350  Validation loss = 10.6853  \n",
      "\n",
      "Fold: 15  Epoch: 521  Training loss = 4.5347  Validation loss = 10.6849  \n",
      "\n",
      "Fold: 15  Epoch: 522  Training loss = 4.5343  Validation loss = 10.6845  \n",
      "\n",
      "Fold: 15  Epoch: 523  Training loss = 4.5341  Validation loss = 10.6842  \n",
      "\n",
      "Fold: 15  Epoch: 524  Training loss = 4.5337  Validation loss = 10.6838  \n",
      "\n",
      "Fold: 15  Epoch: 525  Training loss = 4.5333  Validation loss = 10.6834  \n",
      "\n",
      "Fold: 15  Epoch: 526  Training loss = 4.5330  Validation loss = 10.6831  \n",
      "\n",
      "Fold: 15  Epoch: 527  Training loss = 4.5327  Validation loss = 10.6827  \n",
      "\n",
      "Fold: 15  Epoch: 528  Training loss = 4.5324  Validation loss = 10.6823  \n",
      "\n",
      "Fold: 15  Epoch: 529  Training loss = 4.5321  Validation loss = 10.6820  \n",
      "\n",
      "Fold: 15  Epoch: 530  Training loss = 4.5317  Validation loss = 10.6817  \n",
      "\n",
      "Fold: 15  Epoch: 531  Training loss = 4.5314  Validation loss = 10.6814  \n",
      "\n",
      "Fold: 15  Epoch: 532  Training loss = 4.5311  Validation loss = 10.6811  \n",
      "\n",
      "Fold: 15  Epoch: 533  Training loss = 4.5308  Validation loss = 10.6807  \n",
      "\n",
      "Fold: 15  Epoch: 534  Training loss = 4.5305  Validation loss = 10.6804  \n",
      "\n",
      "Fold: 15  Epoch: 535  Training loss = 4.5302  Validation loss = 10.6800  \n",
      "\n",
      "Fold: 15  Epoch: 536  Training loss = 4.5299  Validation loss = 10.6798  \n",
      "\n",
      "Fold: 15  Epoch: 537  Training loss = 4.5297  Validation loss = 10.6795  \n",
      "\n",
      "Fold: 15  Epoch: 538  Training loss = 4.5294  Validation loss = 10.6791  \n",
      "\n",
      "Fold: 15  Epoch: 539  Training loss = 4.5291  Validation loss = 10.6789  \n",
      "\n",
      "Fold: 15  Epoch: 540  Training loss = 4.5287  Validation loss = 10.6785  \n",
      "\n",
      "Fold: 15  Epoch: 541  Training loss = 4.5284  Validation loss = 10.6781  \n",
      "\n",
      "Fold: 15  Epoch: 542  Training loss = 4.5282  Validation loss = 10.6778  \n",
      "\n",
      "Fold: 15  Epoch: 543  Training loss = 4.5279  Validation loss = 10.6775  \n",
      "\n",
      "Fold: 15  Epoch: 544  Training loss = 4.5275  Validation loss = 10.6772  \n",
      "\n",
      "Fold: 15  Epoch: 545  Training loss = 4.5273  Validation loss = 10.6769  \n",
      "\n",
      "Fold: 15  Epoch: 546  Training loss = 4.5270  Validation loss = 10.6766  \n",
      "\n",
      "Fold: 15  Epoch: 547  Training loss = 4.5267  Validation loss = 10.6763  \n",
      "\n",
      "Fold: 15  Epoch: 548  Training loss = 4.5264  Validation loss = 10.6760  \n",
      "\n",
      "Fold: 15  Epoch: 549  Training loss = 4.5260  Validation loss = 10.6755  \n",
      "\n",
      "Fold: 15  Epoch: 550  Training loss = 4.5257  Validation loss = 10.6752  \n",
      "\n",
      "Fold: 15  Epoch: 551  Training loss = 4.5253  Validation loss = 10.6749  \n",
      "\n",
      "Fold: 15  Epoch: 552  Training loss = 4.5250  Validation loss = 10.6745  \n",
      "\n",
      "Fold: 15  Epoch: 553  Training loss = 4.5247  Validation loss = 10.6742  \n",
      "\n",
      "Fold: 15  Epoch: 554  Training loss = 4.5244  Validation loss = 10.6739  \n",
      "\n",
      "Fold: 15  Epoch: 555  Training loss = 4.5241  Validation loss = 10.6736  \n",
      "\n",
      "Fold: 15  Epoch: 556  Training loss = 4.5237  Validation loss = 10.6732  \n",
      "\n",
      "Fold: 15  Epoch: 557  Training loss = 4.5233  Validation loss = 10.6728  \n",
      "\n",
      "Fold: 15  Epoch: 558  Training loss = 4.5231  Validation loss = 10.6725  \n",
      "\n",
      "Fold: 15  Epoch: 559  Training loss = 4.5227  Validation loss = 10.6721  \n",
      "\n",
      "Fold: 15  Epoch: 560  Training loss = 4.5224  Validation loss = 10.6718  \n",
      "\n",
      "Fold: 15  Epoch: 561  Training loss = 4.5220  Validation loss = 10.6714  \n",
      "\n",
      "Fold: 15  Epoch: 562  Training loss = 4.5218  Validation loss = 10.6711  \n",
      "\n",
      "Fold: 15  Epoch: 563  Training loss = 4.5214  Validation loss = 10.6708  \n",
      "\n",
      "Fold: 15  Epoch: 564  Training loss = 4.5211  Validation loss = 10.6704  \n",
      "\n",
      "Fold: 15  Epoch: 565  Training loss = 4.5208  Validation loss = 10.6701  \n",
      "\n",
      "Fold: 15  Epoch: 566  Training loss = 4.5205  Validation loss = 10.6697  \n",
      "\n",
      "Fold: 15  Epoch: 567  Training loss = 4.5202  Validation loss = 10.6694  \n",
      "\n",
      "Fold: 15  Epoch: 568  Training loss = 4.5199  Validation loss = 10.6691  \n",
      "\n",
      "Fold: 15  Epoch: 569  Training loss = 4.5196  Validation loss = 10.6688  \n",
      "\n",
      "Fold: 15  Epoch: 570  Training loss = 4.5192  Validation loss = 10.6684  \n",
      "\n",
      "Fold: 15  Epoch: 571  Training loss = 4.5189  Validation loss = 10.6680  \n",
      "\n",
      "Fold: 15  Epoch: 572  Training loss = 4.5186  Validation loss = 10.6676  \n",
      "\n",
      "Fold: 15  Epoch: 573  Training loss = 4.5183  Validation loss = 10.6673  \n",
      "\n",
      "Fold: 15  Epoch: 574  Training loss = 4.5180  Validation loss = 10.6670  \n",
      "\n",
      "Fold: 15  Epoch: 575  Training loss = 4.5177  Validation loss = 10.6667  \n",
      "\n",
      "Fold: 15  Epoch: 576  Training loss = 4.5174  Validation loss = 10.6664  \n",
      "\n",
      "Fold: 15  Epoch: 577  Training loss = 4.5171  Validation loss = 10.6661  \n",
      "\n",
      "Fold: 15  Epoch: 578  Training loss = 4.5167  Validation loss = 10.6658  \n",
      "\n",
      "Fold: 15  Epoch: 579  Training loss = 4.5165  Validation loss = 10.6655  \n",
      "\n",
      "Fold: 15  Epoch: 580  Training loss = 4.5161  Validation loss = 10.6651  \n",
      "\n",
      "Fold: 15  Epoch: 581  Training loss = 4.5158  Validation loss = 10.6648  \n",
      "\n",
      "Fold: 15  Epoch: 582  Training loss = 4.5155  Validation loss = 10.6645  \n",
      "\n",
      "Fold: 15  Epoch: 583  Training loss = 4.5152  Validation loss = 10.6642  \n",
      "\n",
      "Fold: 15  Epoch: 584  Training loss = 4.5149  Validation loss = 10.6638  \n",
      "\n",
      "Fold: 15  Epoch: 585  Training loss = 4.5145  Validation loss = 10.6633  \n",
      "\n",
      "Fold: 15  Epoch: 586  Training loss = 4.5142  Validation loss = 10.6630  \n",
      "\n",
      "Fold: 15  Epoch: 587  Training loss = 4.5139  Validation loss = 10.6627  \n",
      "\n",
      "Fold: 15  Epoch: 588  Training loss = 4.5136  Validation loss = 10.6624  \n",
      "\n",
      "Fold: 15  Epoch: 589  Training loss = 4.5134  Validation loss = 10.6622  \n",
      "\n",
      "Fold: 15  Epoch: 590  Training loss = 4.5130  Validation loss = 10.6617  \n",
      "\n",
      "Fold: 15  Epoch: 591  Training loss = 4.5126  Validation loss = 10.6613  \n",
      "\n",
      "Fold: 15  Epoch: 592  Training loss = 4.5123  Validation loss = 10.6610  \n",
      "\n",
      "Fold: 15  Epoch: 593  Training loss = 4.5121  Validation loss = 10.6607  \n",
      "\n",
      "Fold: 15  Epoch: 594  Training loss = 4.5118  Validation loss = 10.6604  \n",
      "\n",
      "Fold: 15  Epoch: 595  Training loss = 4.5115  Validation loss = 10.6601  \n",
      "\n",
      "Fold: 15  Epoch: 596  Training loss = 4.5111  Validation loss = 10.6598  \n",
      "\n",
      "Fold: 15  Epoch: 597  Training loss = 4.5108  Validation loss = 10.6593  \n",
      "\n",
      "Fold: 15  Epoch: 598  Training loss = 4.5104  Validation loss = 10.6590  \n",
      "\n",
      "Fold: 15  Epoch: 599  Training loss = 4.5100  Validation loss = 10.6586  \n",
      "\n",
      "Fold: 15  Epoch: 600  Training loss = 4.5097  Validation loss = 10.6582  \n",
      "\n",
      "Fold: 15  Epoch: 601  Training loss = 4.5093  Validation loss = 10.6579  \n",
      "\n",
      "Fold: 15  Epoch: 602  Training loss = 4.5090  Validation loss = 10.6576  \n",
      "\n",
      "Fold: 15  Epoch: 603  Training loss = 4.5087  Validation loss = 10.6573  \n",
      "\n",
      "Fold: 15  Epoch: 604  Training loss = 4.5083  Validation loss = 10.6569  \n",
      "\n",
      "Fold: 15  Epoch: 605  Training loss = 4.5080  Validation loss = 10.6566  \n",
      "\n",
      "Fold: 15  Epoch: 606  Training loss = 4.5077  Validation loss = 10.6563  \n",
      "\n",
      "Fold: 15  Epoch: 607  Training loss = 4.5074  Validation loss = 10.6559  \n",
      "\n",
      "Fold: 15  Epoch: 608  Training loss = 4.5071  Validation loss = 10.6556  \n",
      "\n",
      "Fold: 15  Epoch: 609  Training loss = 4.5067  Validation loss = 10.6552  \n",
      "\n",
      "Fold: 15  Epoch: 610  Training loss = 4.5064  Validation loss = 10.6549  \n",
      "\n",
      "Fold: 15  Epoch: 611  Training loss = 4.5061  Validation loss = 10.6545  \n",
      "\n",
      "Fold: 15  Epoch: 612  Training loss = 4.5057  Validation loss = 10.6540  \n",
      "\n",
      "Fold: 15  Epoch: 613  Training loss = 4.5054  Validation loss = 10.6537  \n",
      "\n",
      "Fold: 15  Epoch: 614  Training loss = 4.5051  Validation loss = 10.6534  \n",
      "\n",
      "Fold: 15  Epoch: 615  Training loss = 4.5047  Validation loss = 10.6530  \n",
      "\n",
      "Fold: 15  Epoch: 616  Training loss = 4.5044  Validation loss = 10.6527  \n",
      "\n",
      "Fold: 15  Epoch: 617  Training loss = 4.5040  Validation loss = 10.6523  \n",
      "\n",
      "Fold: 15  Epoch: 618  Training loss = 4.5038  Validation loss = 10.6521  \n",
      "\n",
      "Fold: 15  Epoch: 619  Training loss = 4.5034  Validation loss = 10.6517  \n",
      "\n",
      "Fold: 15  Epoch: 620  Training loss = 4.5032  Validation loss = 10.6514  \n",
      "\n",
      "Fold: 15  Epoch: 621  Training loss = 4.5029  Validation loss = 10.6511  \n",
      "\n",
      "Fold: 15  Epoch: 622  Training loss = 4.5025  Validation loss = 10.6507  \n",
      "\n",
      "Fold: 15  Epoch: 623  Training loss = 4.5023  Validation loss = 10.6504  \n",
      "\n",
      "Fold: 15  Epoch: 624  Training loss = 4.5019  Validation loss = 10.6501  \n",
      "\n",
      "Fold: 15  Epoch: 625  Training loss = 4.5016  Validation loss = 10.6498  \n",
      "\n",
      "Fold: 15  Epoch: 626  Training loss = 4.5014  Validation loss = 10.6495  \n",
      "\n",
      "Fold: 15  Epoch: 627  Training loss = 4.5011  Validation loss = 10.6492  \n",
      "\n",
      "Fold: 15  Epoch: 628  Training loss = 4.5007  Validation loss = 10.6488  \n",
      "\n",
      "Fold: 15  Epoch: 629  Training loss = 4.5005  Validation loss = 10.6485  \n",
      "\n",
      "Fold: 15  Epoch: 630  Training loss = 4.5002  Validation loss = 10.6482  \n",
      "\n",
      "Fold: 15  Epoch: 631  Training loss = 4.4999  Validation loss = 10.6479  \n",
      "\n",
      "Fold: 15  Epoch: 632  Training loss = 4.4995  Validation loss = 10.6475  \n",
      "\n",
      "Fold: 15  Epoch: 633  Training loss = 4.4991  Validation loss = 10.6470  \n",
      "\n",
      "Fold: 15  Epoch: 634  Training loss = 4.4988  Validation loss = 10.6467  \n",
      "\n",
      "Fold: 15  Epoch: 635  Training loss = 4.4985  Validation loss = 10.6463  \n",
      "\n",
      "Fold: 15  Epoch: 636  Training loss = 4.4982  Validation loss = 10.6460  \n",
      "\n",
      "Fold: 15  Epoch: 637  Training loss = 4.4978  Validation loss = 10.6456  \n",
      "\n",
      "Fold: 15  Epoch: 638  Training loss = 4.4975  Validation loss = 10.6453  \n",
      "\n",
      "Fold: 15  Epoch: 639  Training loss = 4.4972  Validation loss = 10.6450  \n",
      "\n",
      "Fold: 15  Epoch: 640  Training loss = 4.4968  Validation loss = 10.6446  \n",
      "\n",
      "Fold: 15  Epoch: 641  Training loss = 4.4965  Validation loss = 10.6442  \n",
      "\n",
      "Fold: 15  Epoch: 642  Training loss = 4.4962  Validation loss = 10.6439  \n",
      "\n",
      "Fold: 15  Epoch: 643  Training loss = 4.4960  Validation loss = 10.6436  \n",
      "\n",
      "Fold: 15  Epoch: 644  Training loss = 4.4957  Validation loss = 10.6433  \n",
      "\n",
      "Fold: 15  Epoch: 645  Training loss = 4.4954  Validation loss = 10.6430  \n",
      "\n",
      "Fold: 15  Epoch: 646  Training loss = 4.4951  Validation loss = 10.6427  \n",
      "\n",
      "Fold: 15  Epoch: 647  Training loss = 4.4948  Validation loss = 10.6424  \n",
      "\n",
      "Fold: 15  Epoch: 648  Training loss = 4.4944  Validation loss = 10.6421  \n",
      "\n",
      "Fold: 15  Epoch: 649  Training loss = 4.4942  Validation loss = 10.6418  \n",
      "\n",
      "Fold: 15  Epoch: 650  Training loss = 4.4939  Validation loss = 10.6416  \n",
      "\n",
      "Fold: 15  Epoch: 651  Training loss = 4.4936  Validation loss = 10.6413  \n",
      "\n",
      "Fold: 15  Epoch: 652  Training loss = 4.4933  Validation loss = 10.6409  \n",
      "\n",
      "Fold: 15  Epoch: 653  Training loss = 4.4931  Validation loss = 10.6406  \n",
      "\n",
      "Fold: 15  Epoch: 654  Training loss = 4.4928  Validation loss = 10.6403  \n",
      "\n",
      "Fold: 15  Epoch: 655  Training loss = 4.4925  Validation loss = 10.6400  \n",
      "\n",
      "Fold: 15  Epoch: 656  Training loss = 4.4922  Validation loss = 10.6396  \n",
      "\n",
      "Fold: 15  Epoch: 657  Training loss = 4.4919  Validation loss = 10.6393  \n",
      "\n",
      "Fold: 15  Epoch: 658  Training loss = 4.4916  Validation loss = 10.6390  \n",
      "\n",
      "Fold: 15  Epoch: 659  Training loss = 4.4913  Validation loss = 10.6387  \n",
      "\n",
      "Fold: 15  Epoch: 660  Training loss = 4.4910  Validation loss = 10.6384  \n",
      "\n",
      "Fold: 15  Epoch: 661  Training loss = 4.4907  Validation loss = 10.6381  \n",
      "\n",
      "Fold: 15  Epoch: 662  Training loss = 4.4904  Validation loss = 10.6378  \n",
      "\n",
      "Fold: 15  Epoch: 663  Training loss = 4.4902  Validation loss = 10.6376  \n",
      "\n",
      "Fold: 15  Epoch: 664  Training loss = 4.4898  Validation loss = 10.6373  \n",
      "\n",
      "Fold: 15  Epoch: 665  Training loss = 4.4895  Validation loss = 10.6369  \n",
      "\n",
      "Fold: 15  Epoch: 666  Training loss = 4.4892  Validation loss = 10.6366  \n",
      "\n",
      "Fold: 15  Epoch: 667  Training loss = 4.4889  Validation loss = 10.6363  \n",
      "\n",
      "Fold: 15  Epoch: 668  Training loss = 4.4886  Validation loss = 10.6359  \n",
      "\n",
      "Fold: 15  Epoch: 669  Training loss = 4.4882  Validation loss = 10.6356  \n",
      "\n",
      "Fold: 15  Epoch: 670  Training loss = 4.4879  Validation loss = 10.6353  \n",
      "\n",
      "Fold: 15  Epoch: 671  Training loss = 4.4876  Validation loss = 10.6348  \n",
      "\n",
      "Fold: 15  Epoch: 672  Training loss = 4.4873  Validation loss = 10.6345  \n",
      "\n",
      "Fold: 15  Epoch: 673  Training loss = 4.4869  Validation loss = 10.6341  \n",
      "\n",
      "Fold: 15  Epoch: 674  Training loss = 4.4866  Validation loss = 10.6338  \n",
      "\n",
      "Fold: 15  Epoch: 675  Training loss = 4.4863  Validation loss = 10.6334  \n",
      "\n",
      "Fold: 15  Epoch: 676  Training loss = 4.4859  Validation loss = 10.6330  \n",
      "\n",
      "Fold: 15  Epoch: 677  Training loss = 4.4856  Validation loss = 10.6327  \n",
      "\n",
      "Fold: 15  Epoch: 678  Training loss = 4.4853  Validation loss = 10.6324  \n",
      "\n",
      "Fold: 15  Epoch: 679  Training loss = 4.4850  Validation loss = 10.6320  \n",
      "\n",
      "Fold: 15  Epoch: 680  Training loss = 4.4847  Validation loss = 10.6317  \n",
      "\n",
      "Fold: 15  Epoch: 681  Training loss = 4.4843  Validation loss = 10.6314  \n",
      "\n",
      "Fold: 15  Epoch: 682  Training loss = 4.4840  Validation loss = 10.6311  \n",
      "\n",
      "Fold: 15  Epoch: 683  Training loss = 4.4838  Validation loss = 10.6308  \n",
      "\n",
      "Fold: 15  Epoch: 684  Training loss = 4.4834  Validation loss = 10.6304  \n",
      "\n",
      "Fold: 15  Epoch: 685  Training loss = 4.4830  Validation loss = 10.6300  \n",
      "\n",
      "Fold: 15  Epoch: 686  Training loss = 4.4827  Validation loss = 10.6297  \n",
      "\n",
      "Fold: 15  Epoch: 687  Training loss = 4.4824  Validation loss = 10.6294  \n",
      "\n",
      "Fold: 15  Epoch: 688  Training loss = 4.4821  Validation loss = 10.6291  \n",
      "\n",
      "Fold: 15  Epoch: 689  Training loss = 4.4818  Validation loss = 10.6288  \n",
      "\n",
      "Fold: 15  Epoch: 690  Training loss = 4.4816  Validation loss = 10.6285  \n",
      "\n",
      "Fold: 15  Epoch: 691  Training loss = 4.4813  Validation loss = 10.6282  \n",
      "\n",
      "Fold: 15  Epoch: 692  Training loss = 4.4810  Validation loss = 10.6278  \n",
      "\n",
      "Fold: 15  Epoch: 693  Training loss = 4.4807  Validation loss = 10.6275  \n",
      "\n",
      "Fold: 15  Epoch: 694  Training loss = 4.4804  Validation loss = 10.6272  \n",
      "\n",
      "Fold: 15  Epoch: 695  Training loss = 4.4802  Validation loss = 10.6269  \n",
      "\n",
      "Fold: 15  Epoch: 696  Training loss = 4.4798  Validation loss = 10.6266  \n",
      "\n",
      "Fold: 15  Epoch: 697  Training loss = 4.4795  Validation loss = 10.6263  \n",
      "\n",
      "Fold: 15  Epoch: 698  Training loss = 4.4792  Validation loss = 10.6259  \n",
      "\n",
      "Fold: 15  Epoch: 699  Training loss = 4.4789  Validation loss = 10.6256  \n",
      "\n",
      "Fold: 15  Epoch: 700  Training loss = 4.4786  Validation loss = 10.6253  \n",
      "\n",
      "Fold: 15  Epoch: 701  Training loss = 4.4782  Validation loss = 10.6250  \n",
      "\n",
      "Fold: 15  Epoch: 702  Training loss = 4.4780  Validation loss = 10.6247  \n",
      "\n",
      "Fold: 15  Epoch: 703  Training loss = 4.4777  Validation loss = 10.6243  \n",
      "\n",
      "Fold: 15  Epoch: 704  Training loss = 4.4773  Validation loss = 10.6240  \n",
      "\n",
      "Fold: 15  Epoch: 705  Training loss = 4.4770  Validation loss = 10.6237  \n",
      "\n",
      "Fold: 15  Epoch: 706  Training loss = 4.4767  Validation loss = 10.6233  \n",
      "\n",
      "Fold: 15  Epoch: 707  Training loss = 4.4764  Validation loss = 10.6230  \n",
      "\n",
      "Fold: 15  Epoch: 708  Training loss = 4.4761  Validation loss = 10.6227  \n",
      "\n",
      "Fold: 15  Epoch: 709  Training loss = 4.4759  Validation loss = 10.6224  \n",
      "\n",
      "Fold: 15  Epoch: 710  Training loss = 4.4756  Validation loss = 10.6221  \n",
      "\n",
      "Fold: 15  Epoch: 711  Training loss = 4.4753  Validation loss = 10.6217  \n",
      "\n",
      "Fold: 15  Epoch: 712  Training loss = 4.4750  Validation loss = 10.6214  \n",
      "\n",
      "Fold: 15  Epoch: 713  Training loss = 4.4747  Validation loss = 10.6211  \n",
      "\n",
      "Fold: 15  Epoch: 714  Training loss = 4.4743  Validation loss = 10.6207  \n",
      "\n",
      "Fold: 15  Epoch: 715  Training loss = 4.4740  Validation loss = 10.6204  \n",
      "\n",
      "Fold: 15  Epoch: 716  Training loss = 4.4737  Validation loss = 10.6201  \n",
      "\n",
      "Fold: 15  Epoch: 717  Training loss = 4.4734  Validation loss = 10.6198  \n",
      "\n",
      "Fold: 15  Epoch: 718  Training loss = 4.4731  Validation loss = 10.6194  \n",
      "\n",
      "Fold: 15  Epoch: 719  Training loss = 4.4726  Validation loss = 10.6190  \n",
      "\n",
      "Fold: 15  Epoch: 720  Training loss = 4.4723  Validation loss = 10.6187  \n",
      "\n",
      "Fold: 15  Epoch: 721  Training loss = 4.4720  Validation loss = 10.6183  \n",
      "\n",
      "Fold: 15  Epoch: 722  Training loss = 4.4716  Validation loss = 10.6179  \n",
      "\n",
      "Fold: 15  Epoch: 723  Training loss = 4.4713  Validation loss = 10.6176  \n",
      "\n",
      "Fold: 15  Epoch: 724  Training loss = 4.4710  Validation loss = 10.6173  \n",
      "\n",
      "Fold: 15  Epoch: 725  Training loss = 4.4707  Validation loss = 10.6170  \n",
      "\n",
      "Fold: 15  Epoch: 726  Training loss = 4.4703  Validation loss = 10.6165  \n",
      "\n",
      "Fold: 15  Epoch: 727  Training loss = 4.4700  Validation loss = 10.6162  \n",
      "\n",
      "Fold: 15  Epoch: 728  Training loss = 4.4697  Validation loss = 10.6159  \n",
      "\n",
      "Fold: 15  Epoch: 729  Training loss = 4.4694  Validation loss = 10.6155  \n",
      "\n",
      "Fold: 15  Epoch: 730  Training loss = 4.4691  Validation loss = 10.6152  \n",
      "\n",
      "Fold: 15  Epoch: 731  Training loss = 4.4687  Validation loss = 10.6148  \n",
      "\n",
      "Fold: 15  Epoch: 732  Training loss = 4.4684  Validation loss = 10.6145  \n",
      "\n",
      "Fold: 15  Epoch: 733  Training loss = 4.4681  Validation loss = 10.6142  \n",
      "\n",
      "Fold: 15  Epoch: 734  Training loss = 4.4678  Validation loss = 10.6139  \n",
      "\n",
      "Fold: 15  Epoch: 735  Training loss = 4.4676  Validation loss = 10.6137  \n",
      "\n",
      "Fold: 15  Epoch: 736  Training loss = 4.4673  Validation loss = 10.6133  \n",
      "\n",
      "Fold: 15  Epoch: 737  Training loss = 4.4670  Validation loss = 10.6130  \n",
      "\n",
      "Fold: 15  Epoch: 738  Training loss = 4.4666  Validation loss = 10.6126  \n",
      "\n",
      "Fold: 15  Epoch: 739  Training loss = 4.4663  Validation loss = 10.6123  \n",
      "\n",
      "Fold: 15  Epoch: 740  Training loss = 4.4661  Validation loss = 10.6120  \n",
      "\n",
      "Fold: 15  Epoch: 741  Training loss = 4.4658  Validation loss = 10.6117  \n",
      "\n",
      "Fold: 15  Epoch: 742  Training loss = 4.4655  Validation loss = 10.6113  \n",
      "\n",
      "Fold: 15  Epoch: 743  Training loss = 4.4652  Validation loss = 10.6110  \n",
      "\n",
      "Fold: 15  Epoch: 744  Training loss = 4.4648  Validation loss = 10.6107  \n",
      "\n",
      "Fold: 15  Epoch: 745  Training loss = 4.4645  Validation loss = 10.6104  \n",
      "\n",
      "Fold: 15  Epoch: 746  Training loss = 4.4642  Validation loss = 10.6100  \n",
      "\n",
      "Fold: 15  Epoch: 747  Training loss = 4.4639  Validation loss = 10.6097  \n",
      "\n",
      "Fold: 15  Epoch: 748  Training loss = 4.4637  Validation loss = 10.6095  \n",
      "\n",
      "Fold: 15  Epoch: 749  Training loss = 4.4634  Validation loss = 10.6092  \n",
      "\n",
      "Fold: 15  Epoch: 750  Training loss = 4.4631  Validation loss = 10.6089  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 750  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 5.1699  Validation loss = 7.3063  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 5.1695  Validation loss = 7.3059  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 5.1692  Validation loss = 7.3055  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 5.1688  Validation loss = 7.3051  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 5.1684  Validation loss = 7.3046  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 5.1680  Validation loss = 7.3041  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 5.1675  Validation loss = 7.3036  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 5.1672  Validation loss = 7.3032  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 5.1668  Validation loss = 7.3028  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 5.1664  Validation loss = 7.3023  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 5.1661  Validation loss = 7.3019  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 5.1656  Validation loss = 7.3014  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 5.1653  Validation loss = 7.3010  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 5.1648  Validation loss = 7.3004  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 5.1644  Validation loss = 7.3000  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 5.1639  Validation loss = 7.2995  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 5.1635  Validation loss = 7.2990  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 5.1632  Validation loss = 7.2985  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 5.1628  Validation loss = 7.2981  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 5.1625  Validation loss = 7.2977  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 5.1621  Validation loss = 7.2973  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 5.1617  Validation loss = 7.2969  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 5.1614  Validation loss = 7.2965  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 5.1610  Validation loss = 7.2961  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 5.1607  Validation loss = 7.2957  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 5.1603  Validation loss = 7.2953  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 5.1599  Validation loss = 7.2948  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 5.1595  Validation loss = 7.2944  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 5.1592  Validation loss = 7.2940  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 5.1589  Validation loss = 7.2936  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 5.1585  Validation loss = 7.2932  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 5.1582  Validation loss = 7.2928  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 5.1578  Validation loss = 7.2924  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 5.1575  Validation loss = 7.2920  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 5.1572  Validation loss = 7.2916  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 5.1569  Validation loss = 7.2912  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 5.1565  Validation loss = 7.2908  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 5.1561  Validation loss = 7.2904  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 5.1558  Validation loss = 7.2900  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 5.1554  Validation loss = 7.2896  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 5.1550  Validation loss = 7.2891  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 5.1547  Validation loss = 7.2887  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 5.1543  Validation loss = 7.2883  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 5.1539  Validation loss = 7.2878  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 5.1535  Validation loss = 7.2874  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 5.1532  Validation loss = 7.2870  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 5.1528  Validation loss = 7.2866  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 5.1524  Validation loss = 7.2862  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 5.1520  Validation loss = 7.2857  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 5.1517  Validation loss = 7.2853  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 5.1514  Validation loss = 7.2849  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 5.1510  Validation loss = 7.2845  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 5.1506  Validation loss = 7.2840  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 5.1502  Validation loss = 7.2835  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 5.1498  Validation loss = 7.2831  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 5.1495  Validation loss = 7.2827  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 5.1491  Validation loss = 7.2822  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 5.1487  Validation loss = 7.2818  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 5.1484  Validation loss = 7.2814  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 5.1480  Validation loss = 7.2810  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 5.1476  Validation loss = 7.2805  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 5.1473  Validation loss = 7.2801  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 5.1469  Validation loss = 7.2797  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 5.1465  Validation loss = 7.2792  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 5.1461  Validation loss = 7.2788  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 5.1457  Validation loss = 7.2783  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 5.1453  Validation loss = 7.2778  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 5.1449  Validation loss = 7.2774  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 5.1446  Validation loss = 7.2770  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 5.1442  Validation loss = 7.2765  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 5.1438  Validation loss = 7.2761  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 5.1435  Validation loss = 7.2757  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 5.1431  Validation loss = 7.2753  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 5.1428  Validation loss = 7.2749  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 5.1424  Validation loss = 7.2745  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 5.1420  Validation loss = 7.2740  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 5.1416  Validation loss = 7.2735  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 5.1412  Validation loss = 7.2730  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 5.1408  Validation loss = 7.2726  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 5.1405  Validation loss = 7.2721  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 5.1400  Validation loss = 7.2716  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 5.1396  Validation loss = 7.2712  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 5.1393  Validation loss = 7.2708  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 5.1389  Validation loss = 7.2703  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 5.1384  Validation loss = 7.2697  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 5.1379  Validation loss = 7.2692  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 5.1375  Validation loss = 7.2687  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 5.1371  Validation loss = 7.2682  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 5.1367  Validation loss = 7.2677  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 5.1363  Validation loss = 7.2673  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 5.1360  Validation loss = 7.2669  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 5.1356  Validation loss = 7.2665  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 5.1352  Validation loss = 7.2660  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 5.1348  Validation loss = 7.2656  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 5.1344  Validation loss = 7.2651  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 5.1340  Validation loss = 7.2647  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 5.1336  Validation loss = 7.2642  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 5.1333  Validation loss = 7.2638  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 5.1329  Validation loss = 7.2634  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 5.1325  Validation loss = 7.2629  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 5.1321  Validation loss = 7.2625  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 5.1317  Validation loss = 7.2620  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 5.1314  Validation loss = 7.2616  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 5.1310  Validation loss = 7.2611  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 5.1306  Validation loss = 7.2607  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 5.1303  Validation loss = 7.2603  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 5.1299  Validation loss = 7.2599  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 5.1295  Validation loss = 7.2593  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 5.1291  Validation loss = 7.2589  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 5.1287  Validation loss = 7.2584  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 5.1283  Validation loss = 7.2579  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 5.1280  Validation loss = 7.2576  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 5.1275  Validation loss = 7.2571  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 5.1271  Validation loss = 7.2566  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 5.1268  Validation loss = 7.2562  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 5.1264  Validation loss = 7.2557  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 5.1260  Validation loss = 7.2554  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 5.1257  Validation loss = 7.2550  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 5.1253  Validation loss = 7.2545  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 5.1250  Validation loss = 7.2541  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 5.1245  Validation loss = 7.2536  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 5.1241  Validation loss = 7.2531  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 5.1238  Validation loss = 7.2527  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 5.1234  Validation loss = 7.2523  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 5.1231  Validation loss = 7.2519  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 5.1228  Validation loss = 7.2516  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 5.1225  Validation loss = 7.2512  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 5.1221  Validation loss = 7.2507  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 5.1216  Validation loss = 7.2502  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 5.1212  Validation loss = 7.2497  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 5.1207  Validation loss = 7.2491  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 5.1203  Validation loss = 7.2486  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 5.1200  Validation loss = 7.2482  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 5.1196  Validation loss = 7.2477  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 5.1191  Validation loss = 7.2472  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 5.1188  Validation loss = 7.2468  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 5.1184  Validation loss = 7.2464  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 5.1180  Validation loss = 7.2459  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 5.1176  Validation loss = 7.2455  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 5.1173  Validation loss = 7.2450  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 5.1169  Validation loss = 7.2446  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 5.1164  Validation loss = 7.2440  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 5.1159  Validation loss = 7.2435  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 5.1155  Validation loss = 7.2430  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 5.1152  Validation loss = 7.2426  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 5.1147  Validation loss = 7.2421  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 5.1144  Validation loss = 7.2417  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 5.1140  Validation loss = 7.2413  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 5.1137  Validation loss = 7.2409  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 5.1133  Validation loss = 7.2404  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 5.1128  Validation loss = 7.2398  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 5.1124  Validation loss = 7.2393  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 5.1120  Validation loss = 7.2390  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 5.1117  Validation loss = 7.2385  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 5.1112  Validation loss = 7.2380  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 5.1108  Validation loss = 7.2376  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 5.1104  Validation loss = 7.2371  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 5.1100  Validation loss = 7.2366  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 5.1096  Validation loss = 7.2361  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 5.1092  Validation loss = 7.2357  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 5.1089  Validation loss = 7.2353  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 5.1084  Validation loss = 7.2348  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 5.1080  Validation loss = 7.2343  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 5.1076  Validation loss = 7.2338  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 5.1072  Validation loss = 7.2333  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 5.1068  Validation loss = 7.2329  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 5.1064  Validation loss = 7.2325  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 5.1061  Validation loss = 7.2321  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 5.1057  Validation loss = 7.2316  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 5.1053  Validation loss = 7.2312  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 5.1049  Validation loss = 7.2307  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 5.1045  Validation loss = 7.2302  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 5.1040  Validation loss = 7.2297  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 5.1035  Validation loss = 7.2292  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 5.1032  Validation loss = 7.2287  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 5.1028  Validation loss = 7.2283  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 5.1023  Validation loss = 7.2278  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 5.1019  Validation loss = 7.2273  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 5.1015  Validation loss = 7.2268  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 5.1011  Validation loss = 7.2264  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 5.1006  Validation loss = 7.2258  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 5.1002  Validation loss = 7.2253  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 5.0998  Validation loss = 7.2248  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 5.0994  Validation loss = 7.2244  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 5.0990  Validation loss = 7.2239  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 5.0987  Validation loss = 7.2236  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 5.0983  Validation loss = 7.2231  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 5.0978  Validation loss = 7.2226  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 5.0974  Validation loss = 7.2220  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 5.0969  Validation loss = 7.2215  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 5.0965  Validation loss = 7.2210  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 5.0961  Validation loss = 7.2206  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 5.0956  Validation loss = 7.2200  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 5.0952  Validation loss = 7.2195  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 5.0948  Validation loss = 7.2191  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 5.0944  Validation loss = 7.2187  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 5.0939  Validation loss = 7.2181  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 5.0934  Validation loss = 7.2176  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 5.0931  Validation loss = 7.2172  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 5.0925  Validation loss = 7.2166  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 5.0920  Validation loss = 7.2161  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 5.0914  Validation loss = 7.2155  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 5.0905  Validation loss = 7.2149  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 5.0889  Validation loss = 7.2143  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 5.0875  Validation loss = 7.2138  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 5.0871  Validation loss = 7.2134  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 5.0864  Validation loss = 7.2129  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 5.0858  Validation loss = 7.2124  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 5.0854  Validation loss = 7.2120  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 5.0848  Validation loss = 7.2115  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 5.0843  Validation loss = 7.2110  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 5.0838  Validation loss = 7.2105  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 5.0834  Validation loss = 7.2100  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 5.0829  Validation loss = 7.2095  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 5.0826  Validation loss = 7.2092  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 5.0822  Validation loss = 7.2088  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 5.0818  Validation loss = 7.2083  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 5.0813  Validation loss = 7.2078  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 5.0810  Validation loss = 7.2074  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 5.0806  Validation loss = 7.2069  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 5.0803  Validation loss = 7.2066  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 5.0799  Validation loss = 7.2061  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 5.0795  Validation loss = 7.2056  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 5.0791  Validation loss = 7.2052  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 5.0787  Validation loss = 7.2047  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 5.0782  Validation loss = 7.2042  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 5.0778  Validation loss = 7.2037  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 5.0773  Validation loss = 7.2032  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 5.0769  Validation loss = 7.2027  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 5.0766  Validation loss = 7.2023  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 5.0761  Validation loss = 7.2018  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 5.0757  Validation loss = 7.2013  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 5.0754  Validation loss = 7.2009  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 5.0750  Validation loss = 7.2004  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 5.0746  Validation loss = 7.1999  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 5.0741  Validation loss = 7.1994  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 5.0738  Validation loss = 7.1990  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 5.0733  Validation loss = 7.1985  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 5.0730  Validation loss = 7.1982  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 5.0727  Validation loss = 7.1978  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 5.0723  Validation loss = 7.1973  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 5.0720  Validation loss = 7.1969  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 5.0716  Validation loss = 7.1965  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 5.0712  Validation loss = 7.1960  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 5.0708  Validation loss = 7.1956  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 5.0704  Validation loss = 7.1951  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 5.0700  Validation loss = 7.1947  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 5.0696  Validation loss = 7.1942  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 5.0693  Validation loss = 7.1938  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 5.0689  Validation loss = 7.1934  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 5.0685  Validation loss = 7.1930  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 5.0681  Validation loss = 7.1925  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 5.0677  Validation loss = 7.1920  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 5.0673  Validation loss = 7.1916  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 5.0669  Validation loss = 7.1911  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 5.0666  Validation loss = 7.1907  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 5.0662  Validation loss = 7.1903  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 5.0659  Validation loss = 7.1898  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 5.0654  Validation loss = 7.1893  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 5.0650  Validation loss = 7.1889  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 5.0646  Validation loss = 7.1884  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 5.0643  Validation loss = 7.1880  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 5.0639  Validation loss = 7.1875  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 5.0635  Validation loss = 7.1871  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 5.0632  Validation loss = 7.1867  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 5.0628  Validation loss = 7.1863  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 5.0624  Validation loss = 7.1858  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 5.0620  Validation loss = 7.1853  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 5.0617  Validation loss = 7.1849  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 5.0613  Validation loss = 7.1845  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 5.0609  Validation loss = 7.1840  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 5.0605  Validation loss = 7.1836  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 5.0601  Validation loss = 7.1831  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 5.0598  Validation loss = 7.1827  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 5.0594  Validation loss = 7.1823  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 5.0590  Validation loss = 7.1819  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 5.0587  Validation loss = 7.1814  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 5.0583  Validation loss = 7.1810  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 5.0579  Validation loss = 7.1806  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 5.0575  Validation loss = 7.1801  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 5.0572  Validation loss = 7.1797  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 5.0568  Validation loss = 7.1793  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 5.0565  Validation loss = 7.1789  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 5.0562  Validation loss = 7.1785  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 5.0558  Validation loss = 7.1780  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 5.0555  Validation loss = 7.1777  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 5.0552  Validation loss = 7.1773  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 5.0548  Validation loss = 7.1769  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 5.0544  Validation loss = 7.1764  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 5.0541  Validation loss = 7.1760  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 5.0536  Validation loss = 7.1755  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 5.0533  Validation loss = 7.1751  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 5.0528  Validation loss = 7.1745  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 5.0524  Validation loss = 7.1741  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 5.0521  Validation loss = 7.1737  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 5.0518  Validation loss = 7.1733  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 5.0514  Validation loss = 7.1729  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 5.0511  Validation loss = 7.1725  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 5.0508  Validation loss = 7.1721  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 5.0504  Validation loss = 7.1717  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 5.0500  Validation loss = 7.1713  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 5.0496  Validation loss = 7.1707  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 5.0493  Validation loss = 7.1704  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 5.0489  Validation loss = 7.1699  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 5.0485  Validation loss = 7.1695  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 5.0482  Validation loss = 7.1691  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 5.0479  Validation loss = 7.1687  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 5.0475  Validation loss = 7.1683  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 5.0471  Validation loss = 7.1678  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 5.0467  Validation loss = 7.1673  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 5.0463  Validation loss = 7.1668  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 5.0459  Validation loss = 7.1664  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 5.0455  Validation loss = 7.1659  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 5.0451  Validation loss = 7.1654  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 5.0446  Validation loss = 7.1649  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 5.0443  Validation loss = 7.1645  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 5.0439  Validation loss = 7.1640  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 5.0435  Validation loss = 7.1636  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 5.0432  Validation loss = 7.1632  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 5.0429  Validation loss = 7.1628  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 5.0425  Validation loss = 7.1624  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 5.0421  Validation loss = 7.1620  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 5.0417  Validation loss = 7.1615  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 5.0414  Validation loss = 7.1611  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 5.0410  Validation loss = 7.1607  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 5.0406  Validation loss = 7.1602  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 5.0401  Validation loss = 7.1597  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 5.0397  Validation loss = 7.1592  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 5.0393  Validation loss = 7.1587  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 5.0389  Validation loss = 7.1582  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 5.0385  Validation loss = 7.1578  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 5.0382  Validation loss = 7.1574  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 5.0378  Validation loss = 7.1569  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 5.0375  Validation loss = 7.1565  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 5.0370  Validation loss = 7.1560  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 5.0366  Validation loss = 7.1555  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 5.0363  Validation loss = 7.1551  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 5.0359  Validation loss = 7.1546  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 5.0356  Validation loss = 7.1543  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 5.0352  Validation loss = 7.1539  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 5.0348  Validation loss = 7.1534  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 5.0344  Validation loss = 7.1529  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 5.0340  Validation loss = 7.1525  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 5.0336  Validation loss = 7.1520  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 5.0333  Validation loss = 7.1516  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 5.0330  Validation loss = 7.1513  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 5.0325  Validation loss = 7.1508  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 5.0322  Validation loss = 7.1503  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 5.0318  Validation loss = 7.1499  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 5.0313  Validation loss = 7.1494  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 5.0309  Validation loss = 7.1489  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 5.0305  Validation loss = 7.1483  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 5.0301  Validation loss = 7.1480  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 5.0297  Validation loss = 7.1475  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 5.0293  Validation loss = 7.1470  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 5.0289  Validation loss = 7.1465  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 5.0285  Validation loss = 7.1461  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 5.0281  Validation loss = 7.1456  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 5.0277  Validation loss = 7.1451  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 5.0273  Validation loss = 7.1446  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 5.0270  Validation loss = 7.1443  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 5.0266  Validation loss = 7.1438  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 5.0263  Validation loss = 7.1435  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 5.0259  Validation loss = 7.1430  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 5.0255  Validation loss = 7.1426  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 5.0251  Validation loss = 7.1421  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 5.0248  Validation loss = 7.1417  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 5.0245  Validation loss = 7.1413  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 5.0241  Validation loss = 7.1409  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 5.0237  Validation loss = 7.1405  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 5.0234  Validation loss = 7.1402  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 5.0231  Validation loss = 7.1397  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 5.0226  Validation loss = 7.1392  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 5.0222  Validation loss = 7.1387  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 5.0218  Validation loss = 7.1382  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 5.0214  Validation loss = 7.1378  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 5.0210  Validation loss = 7.1373  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 5.0206  Validation loss = 7.1369  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 5.0202  Validation loss = 7.1364  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 5.0199  Validation loss = 7.1360  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 5.0196  Validation loss = 7.1356  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 5.0193  Validation loss = 7.1353  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 5.0190  Validation loss = 7.1349  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 5.0185  Validation loss = 7.1345  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 5.0181  Validation loss = 7.1340  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 5.0177  Validation loss = 7.1335  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 5.0174  Validation loss = 7.1331  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 5.0169  Validation loss = 7.1326  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 5.0166  Validation loss = 7.1322  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 5.0162  Validation loss = 7.1318  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 5.0158  Validation loss = 7.1313  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 5.0154  Validation loss = 7.1308  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 5.0150  Validation loss = 7.1303  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 5.0147  Validation loss = 7.1299  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 5.0143  Validation loss = 7.1295  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 5.0140  Validation loss = 7.1291  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 5.0137  Validation loss = 7.1287  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 5.0134  Validation loss = 7.1284  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 5.0129  Validation loss = 7.1279  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 5.0125  Validation loss = 7.1274  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 5.0121  Validation loss = 7.1269  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 5.0117  Validation loss = 7.1264  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 5.0112  Validation loss = 7.1259  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 5.0109  Validation loss = 7.1255  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 5.0106  Validation loss = 7.1251  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 5.0102  Validation loss = 7.1246  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 5.0098  Validation loss = 7.1242  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 5.0094  Validation loss = 7.1238  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 5.0090  Validation loss = 7.1233  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 5.0086  Validation loss = 7.1229  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 5.0083  Validation loss = 7.1224  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 5.0078  Validation loss = 7.1219  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 5.0075  Validation loss = 7.1215  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 5.0071  Validation loss = 7.1210  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 5.0068  Validation loss = 7.1206  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 5.0064  Validation loss = 7.1202  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 5.0060  Validation loss = 7.1198  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 5.0056  Validation loss = 7.1193  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 5.0053  Validation loss = 7.1189  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 5.0049  Validation loss = 7.1184  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 5.0044  Validation loss = 7.1179  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 5.0041  Validation loss = 7.1175  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 5.0037  Validation loss = 7.1170  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 5.0033  Validation loss = 7.1166  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 5.0030  Validation loss = 7.1162  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 5.0026  Validation loss = 7.1157  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 5.0022  Validation loss = 7.1153  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 5.0018  Validation loss = 7.1148  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 5.0015  Validation loss = 7.1144  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 5.0011  Validation loss = 7.1139  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 5.0007  Validation loss = 7.1135  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 5.0004  Validation loss = 7.1131  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 5.0001  Validation loss = 7.1128  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 4.9998  Validation loss = 7.1124  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 4.9994  Validation loss = 7.1120  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 4.9990  Validation loss = 7.1115  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 4.9987  Validation loss = 7.1111  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 4.9983  Validation loss = 7.1107  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 4.9980  Validation loss = 7.1103  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 4.9976  Validation loss = 7.1098  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 4.9972  Validation loss = 7.1094  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 4.9969  Validation loss = 7.1090  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 4.9965  Validation loss = 7.1086  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 4.9961  Validation loss = 7.1081  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 4.9957  Validation loss = 7.1076  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 4.9952  Validation loss = 7.1071  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 4.9949  Validation loss = 7.1067  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 4.9946  Validation loss = 7.1064  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 4.9943  Validation loss = 7.1060  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 4.9939  Validation loss = 7.1056  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 4.9936  Validation loss = 7.1052  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 4.9931  Validation loss = 7.1047  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 4.9928  Validation loss = 7.1042  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 4.9924  Validation loss = 7.1038  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 4.9920  Validation loss = 7.1033  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 4.9916  Validation loss = 7.1028  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 4.9912  Validation loss = 7.1023  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 4.9908  Validation loss = 7.1019  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 4.9904  Validation loss = 7.1014  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 4.9900  Validation loss = 7.1010  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 4.9896  Validation loss = 7.1005  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 4.9893  Validation loss = 7.1001  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 4.9889  Validation loss = 7.0996  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 4.9886  Validation loss = 7.0992  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 4.9881  Validation loss = 7.0987  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 4.9878  Validation loss = 7.0984  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 4.9875  Validation loss = 7.0980  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 4.9870  Validation loss = 7.0974  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 4.9866  Validation loss = 7.0969  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 4.9861  Validation loss = 7.0964  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 4.9858  Validation loss = 7.0960  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 4.9855  Validation loss = 7.0956  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 4.9850  Validation loss = 7.0950  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 4.9846  Validation loss = 7.0946  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 4.9842  Validation loss = 7.0941  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 4.9838  Validation loss = 7.0937  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 4.9834  Validation loss = 7.0932  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 4.9830  Validation loss = 7.0928  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 4.9827  Validation loss = 7.0923  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 4.9823  Validation loss = 7.0919  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 4.9819  Validation loss = 7.0915  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 4.9815  Validation loss = 7.0909  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 4.9811  Validation loss = 7.0905  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 4.9807  Validation loss = 7.0901  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 4.9804  Validation loss = 7.0897  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 4.9800  Validation loss = 7.0893  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 4.9796  Validation loss = 7.0889  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 4.9793  Validation loss = 7.0885  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 4.9789  Validation loss = 7.0880  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 4.9786  Validation loss = 7.0876  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 4.9783  Validation loss = 7.0873  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 4.9779  Validation loss = 7.0868  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 4.9775  Validation loss = 7.0863  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 4.9771  Validation loss = 7.0859  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 4.9768  Validation loss = 7.0856  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 4.9765  Validation loss = 7.0852  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 4.9762  Validation loss = 7.0848  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 4.9758  Validation loss = 7.0843  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 4.9754  Validation loss = 7.0840  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 4.9751  Validation loss = 7.0835  \n",
      "\n",
      "Fold: 16  Epoch: 501  Training loss = 4.9747  Validation loss = 7.0831  \n",
      "\n",
      "Fold: 16  Epoch: 502  Training loss = 4.9742  Validation loss = 7.0826  \n",
      "\n",
      "Fold: 16  Epoch: 503  Training loss = 4.9739  Validation loss = 7.0822  \n",
      "\n",
      "Fold: 16  Epoch: 504  Training loss = 4.9735  Validation loss = 7.0818  \n",
      "\n",
      "Fold: 16  Epoch: 505  Training loss = 4.9732  Validation loss = 7.0814  \n",
      "\n",
      "Fold: 16  Epoch: 506  Training loss = 4.9729  Validation loss = 7.0810  \n",
      "\n",
      "Fold: 16  Epoch: 507  Training loss = 4.9725  Validation loss = 7.0806  \n",
      "\n",
      "Fold: 16  Epoch: 508  Training loss = 4.9721  Validation loss = 7.0801  \n",
      "\n",
      "Fold: 16  Epoch: 509  Training loss = 4.9717  Validation loss = 7.0796  \n",
      "\n",
      "Fold: 16  Epoch: 510  Training loss = 4.9714  Validation loss = 7.0793  \n",
      "\n",
      "Fold: 16  Epoch: 511  Training loss = 4.9711  Validation loss = 7.0788  \n",
      "\n",
      "Fold: 16  Epoch: 512  Training loss = 4.9707  Validation loss = 7.0783  \n",
      "\n",
      "Fold: 16  Epoch: 513  Training loss = 4.9704  Validation loss = 7.0780  \n",
      "\n",
      "Fold: 16  Epoch: 514  Training loss = 4.9700  Validation loss = 7.0775  \n",
      "\n",
      "Fold: 16  Epoch: 515  Training loss = 4.9696  Validation loss = 7.0771  \n",
      "\n",
      "Fold: 16  Epoch: 516  Training loss = 4.9692  Validation loss = 7.0767  \n",
      "\n",
      "Fold: 16  Epoch: 517  Training loss = 4.9689  Validation loss = 7.0762  \n",
      "\n",
      "Fold: 16  Epoch: 518  Training loss = 4.9685  Validation loss = 7.0758  \n",
      "\n",
      "Fold: 16  Epoch: 519  Training loss = 4.9682  Validation loss = 7.0754  \n",
      "\n",
      "Fold: 16  Epoch: 520  Training loss = 4.9678  Validation loss = 7.0750  \n",
      "\n",
      "Fold: 16  Epoch: 521  Training loss = 4.9675  Validation loss = 7.0746  \n",
      "\n",
      "Fold: 16  Epoch: 522  Training loss = 4.9671  Validation loss = 7.0741  \n",
      "\n",
      "Fold: 16  Epoch: 523  Training loss = 4.9668  Validation loss = 7.0738  \n",
      "\n",
      "Fold: 16  Epoch: 524  Training loss = 4.9664  Validation loss = 7.0733  \n",
      "\n",
      "Fold: 16  Epoch: 525  Training loss = 4.9660  Validation loss = 7.0729  \n",
      "\n",
      "Fold: 16  Epoch: 526  Training loss = 4.9656  Validation loss = 7.0725  \n",
      "\n",
      "Fold: 16  Epoch: 527  Training loss = 4.9652  Validation loss = 7.0720  \n",
      "\n",
      "Fold: 16  Epoch: 528  Training loss = 4.9648  Validation loss = 7.0716  \n",
      "\n",
      "Fold: 16  Epoch: 529  Training loss = 4.9644  Validation loss = 7.0711  \n",
      "\n",
      "Fold: 16  Epoch: 530  Training loss = 4.9641  Validation loss = 7.0707  \n",
      "\n",
      "Fold: 16  Epoch: 531  Training loss = 4.9637  Validation loss = 7.0702  \n",
      "\n",
      "Fold: 16  Epoch: 532  Training loss = 4.9633  Validation loss = 7.0698  \n",
      "\n",
      "Fold: 16  Epoch: 533  Training loss = 4.9629  Validation loss = 7.0693  \n",
      "\n",
      "Fold: 16  Epoch: 534  Training loss = 4.9626  Validation loss = 7.0689  \n",
      "\n",
      "Fold: 16  Epoch: 535  Training loss = 4.9622  Validation loss = 7.0685  \n",
      "\n",
      "Fold: 16  Epoch: 536  Training loss = 4.9618  Validation loss = 7.0680  \n",
      "\n",
      "Fold: 16  Epoch: 537  Training loss = 4.9615  Validation loss = 7.0676  \n",
      "\n",
      "Fold: 16  Epoch: 538  Training loss = 4.9611  Validation loss = 7.0672  \n",
      "\n",
      "Fold: 16  Epoch: 539  Training loss = 4.9607  Validation loss = 7.0667  \n",
      "\n",
      "Fold: 16  Epoch: 540  Training loss = 4.9604  Validation loss = 7.0663  \n",
      "\n",
      "Fold: 16  Epoch: 541  Training loss = 4.9601  Validation loss = 7.0660  \n",
      "\n",
      "Fold: 16  Epoch: 542  Training loss = 4.9598  Validation loss = 7.0656  \n",
      "\n",
      "Fold: 16  Epoch: 543  Training loss = 4.9594  Validation loss = 7.0652  \n",
      "\n",
      "Fold: 16  Epoch: 544  Training loss = 4.9590  Validation loss = 7.0647  \n",
      "\n",
      "Fold: 16  Epoch: 545  Training loss = 4.9587  Validation loss = 7.0644  \n",
      "\n",
      "Fold: 16  Epoch: 546  Training loss = 4.9583  Validation loss = 7.0639  \n",
      "\n",
      "Fold: 16  Epoch: 547  Training loss = 4.9580  Validation loss = 7.0636  \n",
      "\n",
      "Fold: 16  Epoch: 548  Training loss = 4.9576  Validation loss = 7.0631  \n",
      "\n",
      "Fold: 16  Epoch: 549  Training loss = 4.9573  Validation loss = 7.0627  \n",
      "\n",
      "Fold: 16  Epoch: 550  Training loss = 4.9569  Validation loss = 7.0622  \n",
      "\n",
      "Fold: 16  Epoch: 551  Training loss = 4.9565  Validation loss = 7.0618  \n",
      "\n",
      "Fold: 16  Epoch: 552  Training loss = 4.9561  Validation loss = 7.0613  \n",
      "\n",
      "Fold: 16  Epoch: 553  Training loss = 4.9558  Validation loss = 7.0610  \n",
      "\n",
      "Fold: 16  Epoch: 554  Training loss = 4.9555  Validation loss = 7.0606  \n",
      "\n",
      "Fold: 16  Epoch: 555  Training loss = 4.9551  Validation loss = 7.0602  \n",
      "\n",
      "Fold: 16  Epoch: 556  Training loss = 4.9548  Validation loss = 7.0598  \n",
      "\n",
      "Fold: 16  Epoch: 557  Training loss = 4.9545  Validation loss = 7.0594  \n",
      "\n",
      "Fold: 16  Epoch: 558  Training loss = 4.9541  Validation loss = 7.0590  \n",
      "\n",
      "Fold: 16  Epoch: 559  Training loss = 4.9537  Validation loss = 7.0585  \n",
      "\n",
      "Fold: 16  Epoch: 560  Training loss = 4.9534  Validation loss = 7.0581  \n",
      "\n",
      "Fold: 16  Epoch: 561  Training loss = 4.9531  Validation loss = 7.0577  \n",
      "\n",
      "Fold: 16  Epoch: 562  Training loss = 4.9527  Validation loss = 7.0573  \n",
      "\n",
      "Fold: 16  Epoch: 563  Training loss = 4.9524  Validation loss = 7.0569  \n",
      "\n",
      "Fold: 16  Epoch: 564  Training loss = 4.9520  Validation loss = 7.0564  \n",
      "\n",
      "Fold: 16  Epoch: 565  Training loss = 4.9516  Validation loss = 7.0559  \n",
      "\n",
      "Fold: 16  Epoch: 566  Training loss = 4.9512  Validation loss = 7.0555  \n",
      "\n",
      "Fold: 16  Epoch: 567  Training loss = 4.9508  Validation loss = 7.0551  \n",
      "\n",
      "Fold: 16  Epoch: 568  Training loss = 4.9504  Validation loss = 7.0546  \n",
      "\n",
      "Fold: 16  Epoch: 569  Training loss = 4.9500  Validation loss = 7.0540  \n",
      "\n",
      "Fold: 16  Epoch: 570  Training loss = 4.9496  Validation loss = 7.0536  \n",
      "\n",
      "Fold: 16  Epoch: 571  Training loss = 4.9493  Validation loss = 7.0533  \n",
      "\n",
      "Fold: 16  Epoch: 572  Training loss = 4.9490  Validation loss = 7.0529  \n",
      "\n",
      "Fold: 16  Epoch: 573  Training loss = 4.9486  Validation loss = 7.0525  \n",
      "\n",
      "Fold: 16  Epoch: 574  Training loss = 4.9482  Validation loss = 7.0520  \n",
      "\n",
      "Fold: 16  Epoch: 575  Training loss = 4.9479  Validation loss = 7.0515  \n",
      "\n",
      "Fold: 16  Epoch: 576  Training loss = 4.9476  Validation loss = 7.0512  \n",
      "\n",
      "Fold: 16  Epoch: 577  Training loss = 4.9472  Validation loss = 7.0508  \n",
      "\n",
      "Fold: 16  Epoch: 578  Training loss = 4.9468  Validation loss = 7.0503  \n",
      "\n",
      "Fold: 16  Epoch: 579  Training loss = 4.9464  Validation loss = 7.0498  \n",
      "\n",
      "Fold: 16  Epoch: 580  Training loss = 4.9461  Validation loss = 7.0494  \n",
      "\n",
      "Fold: 16  Epoch: 581  Training loss = 4.9458  Validation loss = 7.0491  \n",
      "\n",
      "Fold: 16  Epoch: 582  Training loss = 4.9454  Validation loss = 7.0486  \n",
      "\n",
      "Fold: 16  Epoch: 583  Training loss = 4.9451  Validation loss = 7.0482  \n",
      "\n",
      "Fold: 16  Epoch: 584  Training loss = 4.9447  Validation loss = 7.0478  \n",
      "\n",
      "Fold: 16  Epoch: 585  Training loss = 4.9443  Validation loss = 7.0473  \n",
      "\n",
      "Fold: 16  Epoch: 586  Training loss = 4.9441  Validation loss = 7.0470  \n",
      "\n",
      "Fold: 16  Epoch: 587  Training loss = 4.9437  Validation loss = 7.0466  \n",
      "\n",
      "Fold: 16  Epoch: 588  Training loss = 4.9434  Validation loss = 7.0463  \n",
      "\n",
      "Fold: 16  Epoch: 589  Training loss = 4.9431  Validation loss = 7.0459  \n",
      "\n",
      "Fold: 16  Epoch: 590  Training loss = 4.9427  Validation loss = 7.0455  \n",
      "\n",
      "Fold: 16  Epoch: 591  Training loss = 4.9424  Validation loss = 7.0451  \n",
      "\n",
      "Fold: 16  Epoch: 592  Training loss = 4.9421  Validation loss = 7.0447  \n",
      "\n",
      "Fold: 16  Epoch: 593  Training loss = 4.9418  Validation loss = 7.0444  \n",
      "\n",
      "Fold: 16  Epoch: 594  Training loss = 4.9414  Validation loss = 7.0440  \n",
      "\n",
      "Fold: 16  Epoch: 595  Training loss = 4.9411  Validation loss = 7.0436  \n",
      "\n",
      "Fold: 16  Epoch: 596  Training loss = 4.9408  Validation loss = 7.0432  \n",
      "\n",
      "Fold: 16  Epoch: 597  Training loss = 4.9404  Validation loss = 7.0428  \n",
      "\n",
      "Fold: 16  Epoch: 598  Training loss = 4.9401  Validation loss = 7.0423  \n",
      "\n",
      "Fold: 16  Epoch: 599  Training loss = 4.9397  Validation loss = 7.0419  \n",
      "\n",
      "Fold: 16  Epoch: 600  Training loss = 4.9394  Validation loss = 7.0415  \n",
      "\n",
      "Fold: 16  Epoch: 601  Training loss = 4.9390  Validation loss = 7.0411  \n",
      "\n",
      "Fold: 16  Epoch: 602  Training loss = 4.9387  Validation loss = 7.0407  \n",
      "\n",
      "Fold: 16  Epoch: 603  Training loss = 4.9383  Validation loss = 7.0403  \n",
      "\n",
      "Fold: 16  Epoch: 604  Training loss = 4.9380  Validation loss = 7.0398  \n",
      "\n",
      "Fold: 16  Epoch: 605  Training loss = 4.9376  Validation loss = 7.0393  \n",
      "\n",
      "Fold: 16  Epoch: 606  Training loss = 4.9371  Validation loss = 7.0389  \n",
      "\n",
      "Fold: 16  Epoch: 607  Training loss = 4.9367  Validation loss = 7.0384  \n",
      "\n",
      "Fold: 16  Epoch: 608  Training loss = 4.9364  Validation loss = 7.0380  \n",
      "\n",
      "Fold: 16  Epoch: 609  Training loss = 4.9359  Validation loss = 7.0375  \n",
      "\n",
      "Fold: 16  Epoch: 610  Training loss = 4.9356  Validation loss = 7.0371  \n",
      "\n",
      "Fold: 16  Epoch: 611  Training loss = 4.9352  Validation loss = 7.0367  \n",
      "\n",
      "Fold: 16  Epoch: 612  Training loss = 4.9348  Validation loss = 7.0361  \n",
      "\n",
      "Fold: 16  Epoch: 613  Training loss = 4.9344  Validation loss = 7.0357  \n",
      "\n",
      "Fold: 16  Epoch: 614  Training loss = 4.9341  Validation loss = 7.0353  \n",
      "\n",
      "Fold: 16  Epoch: 615  Training loss = 4.9337  Validation loss = 7.0348  \n",
      "\n",
      "Fold: 16  Epoch: 616  Training loss = 4.9333  Validation loss = 7.0344  \n",
      "\n",
      "Fold: 16  Epoch: 617  Training loss = 4.9330  Validation loss = 7.0339  \n",
      "\n",
      "Fold: 16  Epoch: 618  Training loss = 4.9326  Validation loss = 7.0335  \n",
      "\n",
      "Fold: 16  Epoch: 619  Training loss = 4.9322  Validation loss = 7.0331  \n",
      "\n",
      "Fold: 16  Epoch: 620  Training loss = 4.9318  Validation loss = 7.0326  \n",
      "\n",
      "Fold: 16  Epoch: 621  Training loss = 4.9314  Validation loss = 7.0321  \n",
      "\n",
      "Fold: 16  Epoch: 622  Training loss = 4.9310  Validation loss = 7.0316  \n",
      "\n",
      "Fold: 16  Epoch: 623  Training loss = 4.9307  Validation loss = 7.0313  \n",
      "\n",
      "Fold: 16  Epoch: 624  Training loss = 4.9302  Validation loss = 7.0307  \n",
      "\n",
      "Fold: 16  Epoch: 625  Training loss = 4.9298  Validation loss = 7.0303  \n",
      "\n",
      "Fold: 16  Epoch: 626  Training loss = 4.9294  Validation loss = 7.0298  \n",
      "\n",
      "Fold: 16  Epoch: 627  Training loss = 4.9290  Validation loss = 7.0293  \n",
      "\n",
      "Fold: 16  Epoch: 628  Training loss = 4.9286  Validation loss = 7.0289  \n",
      "\n",
      "Fold: 16  Epoch: 629  Training loss = 4.9283  Validation loss = 7.0285  \n",
      "\n",
      "Fold: 16  Epoch: 630  Training loss = 4.9279  Validation loss = 7.0280  \n",
      "\n",
      "Fold: 16  Epoch: 631  Training loss = 4.9274  Validation loss = 7.0275  \n",
      "\n",
      "Fold: 16  Epoch: 632  Training loss = 4.9270  Validation loss = 7.0270  \n",
      "\n",
      "Fold: 16  Epoch: 633  Training loss = 4.9266  Validation loss = 7.0265  \n",
      "\n",
      "Fold: 16  Epoch: 634  Training loss = 4.9263  Validation loss = 7.0262  \n",
      "\n",
      "Fold: 16  Epoch: 635  Training loss = 4.9260  Validation loss = 7.0257  \n",
      "\n",
      "Fold: 16  Epoch: 636  Training loss = 4.9256  Validation loss = 7.0252  \n",
      "\n",
      "Fold: 16  Epoch: 637  Training loss = 4.9253  Validation loss = 7.0249  \n",
      "\n",
      "Fold: 16  Epoch: 638  Training loss = 4.9248  Validation loss = 7.0244  \n",
      "\n",
      "Fold: 16  Epoch: 639  Training loss = 4.9244  Validation loss = 7.0240  \n",
      "\n",
      "Fold: 16  Epoch: 640  Training loss = 4.9241  Validation loss = 7.0236  \n",
      "\n",
      "Fold: 16  Epoch: 641  Training loss = 4.9237  Validation loss = 7.0231  \n",
      "\n",
      "Fold: 16  Epoch: 642  Training loss = 4.9234  Validation loss = 7.0227  \n",
      "\n",
      "Fold: 16  Epoch: 643  Training loss = 4.9230  Validation loss = 7.0223  \n",
      "\n",
      "Fold: 16  Epoch: 644  Training loss = 4.9226  Validation loss = 7.0219  \n",
      "\n",
      "Fold: 16  Epoch: 645  Training loss = 4.9223  Validation loss = 7.0214  \n",
      "\n",
      "Fold: 16  Epoch: 646  Training loss = 4.9218  Validation loss = 7.0209  \n",
      "\n",
      "Fold: 16  Epoch: 647  Training loss = 4.9215  Validation loss = 7.0205  \n",
      "\n",
      "Fold: 16  Epoch: 648  Training loss = 4.9212  Validation loss = 7.0202  \n",
      "\n",
      "Fold: 16  Epoch: 649  Training loss = 4.9208  Validation loss = 7.0197  \n",
      "\n",
      "Fold: 16  Epoch: 650  Training loss = 4.9204  Validation loss = 7.0193  \n",
      "\n",
      "Fold: 16  Epoch: 651  Training loss = 4.9201  Validation loss = 7.0189  \n",
      "\n",
      "Fold: 16  Epoch: 652  Training loss = 4.9197  Validation loss = 7.0184  \n",
      "\n",
      "Fold: 16  Epoch: 653  Training loss = 4.9194  Validation loss = 7.0180  \n",
      "\n",
      "Fold: 16  Epoch: 654  Training loss = 4.9190  Validation loss = 7.0175  \n",
      "\n",
      "Fold: 16  Epoch: 655  Training loss = 4.9185  Validation loss = 7.0170  \n",
      "\n",
      "Fold: 16  Epoch: 656  Training loss = 4.9181  Validation loss = 7.0165  \n",
      "\n",
      "Fold: 16  Epoch: 657  Training loss = 4.9178  Validation loss = 7.0161  \n",
      "\n",
      "Fold: 16  Epoch: 658  Training loss = 4.9175  Validation loss = 7.0157  \n",
      "\n",
      "Fold: 16  Epoch: 659  Training loss = 4.9172  Validation loss = 7.0154  \n",
      "\n",
      "Fold: 16  Epoch: 660  Training loss = 4.9168  Validation loss = 7.0150  \n",
      "\n",
      "Fold: 16  Epoch: 661  Training loss = 4.9165  Validation loss = 7.0146  \n",
      "\n",
      "Fold: 16  Epoch: 662  Training loss = 4.9160  Validation loss = 7.0141  \n",
      "\n",
      "Fold: 16  Epoch: 663  Training loss = 4.9157  Validation loss = 7.0137  \n",
      "\n",
      "Fold: 16  Epoch: 664  Training loss = 4.9152  Validation loss = 7.0132  \n",
      "\n",
      "Fold: 16  Epoch: 665  Training loss = 4.9149  Validation loss = 7.0128  \n",
      "\n",
      "Fold: 16  Epoch: 666  Training loss = 4.9145  Validation loss = 7.0123  \n",
      "\n",
      "Fold: 16  Epoch: 667  Training loss = 4.9141  Validation loss = 7.0118  \n",
      "\n",
      "Fold: 16  Epoch: 668  Training loss = 4.9137  Validation loss = 7.0114  \n",
      "\n",
      "Fold: 16  Epoch: 669  Training loss = 4.9134  Validation loss = 7.0111  \n",
      "\n",
      "Fold: 16  Epoch: 670  Training loss = 4.9131  Validation loss = 7.0107  \n",
      "\n",
      "Fold: 16  Epoch: 671  Training loss = 4.9128  Validation loss = 7.0103  \n",
      "\n",
      "Fold: 16  Epoch: 672  Training loss = 4.9124  Validation loss = 7.0098  \n",
      "\n",
      "Fold: 16  Epoch: 673  Training loss = 4.9120  Validation loss = 7.0094  \n",
      "\n",
      "Fold: 16  Epoch: 674  Training loss = 4.9117  Validation loss = 7.0090  \n",
      "\n",
      "Fold: 16  Epoch: 675  Training loss = 4.9113  Validation loss = 7.0085  \n",
      "\n",
      "Fold: 16  Epoch: 676  Training loss = 4.9109  Validation loss = 7.0080  \n",
      "\n",
      "Fold: 16  Epoch: 677  Training loss = 4.9105  Validation loss = 7.0076  \n",
      "\n",
      "Fold: 16  Epoch: 678  Training loss = 4.9101  Validation loss = 7.0072  \n",
      "\n",
      "Fold: 16  Epoch: 679  Training loss = 4.9097  Validation loss = 7.0067  \n",
      "\n",
      "Fold: 16  Epoch: 680  Training loss = 4.9094  Validation loss = 7.0063  \n",
      "\n",
      "Fold: 16  Epoch: 681  Training loss = 4.9091  Validation loss = 7.0060  \n",
      "\n",
      "Fold: 16  Epoch: 682  Training loss = 4.9087  Validation loss = 7.0055  \n",
      "\n",
      "Fold: 16  Epoch: 683  Training loss = 4.9083  Validation loss = 7.0050  \n",
      "\n",
      "Fold: 16  Epoch: 684  Training loss = 4.9080  Validation loss = 7.0045  \n",
      "\n",
      "Fold: 16  Epoch: 685  Training loss = 4.9076  Validation loss = 7.0042  \n",
      "\n",
      "Fold: 16  Epoch: 686  Training loss = 4.9073  Validation loss = 7.0038  \n",
      "\n",
      "Fold: 16  Epoch: 687  Training loss = 4.9070  Validation loss = 7.0034  \n",
      "\n",
      "Fold: 16  Epoch: 688  Training loss = 4.9067  Validation loss = 7.0031  \n",
      "\n",
      "Fold: 16  Epoch: 689  Training loss = 4.9062  Validation loss = 7.0026  \n",
      "\n",
      "Fold: 16  Epoch: 690  Training loss = 4.9059  Validation loss = 7.0021  \n",
      "\n",
      "Fold: 16  Epoch: 691  Training loss = 4.9055  Validation loss = 7.0016  \n",
      "\n",
      "Fold: 16  Epoch: 692  Training loss = 4.9052  Validation loss = 7.0013  \n",
      "\n",
      "Fold: 16  Epoch: 693  Training loss = 4.9048  Validation loss = 7.0008  \n",
      "\n",
      "Fold: 16  Epoch: 694  Training loss = 4.9045  Validation loss = 7.0005  \n",
      "\n",
      "Fold: 16  Epoch: 695  Training loss = 4.9041  Validation loss = 7.0000  \n",
      "\n",
      "Fold: 16  Epoch: 696  Training loss = 4.9037  Validation loss = 6.9995  \n",
      "\n",
      "Fold: 16  Epoch: 697  Training loss = 4.9033  Validation loss = 6.9991  \n",
      "\n",
      "Fold: 16  Epoch: 698  Training loss = 4.9030  Validation loss = 6.9986  \n",
      "\n",
      "Fold: 16  Epoch: 699  Training loss = 4.9026  Validation loss = 6.9982  \n",
      "\n",
      "Fold: 16  Epoch: 700  Training loss = 4.9022  Validation loss = 6.9978  \n",
      "\n",
      "Fold: 16  Epoch: 701  Training loss = 4.9018  Validation loss = 6.9973  \n",
      "\n",
      "Fold: 16  Epoch: 702  Training loss = 4.9015  Validation loss = 6.9969  \n",
      "\n",
      "Fold: 16  Epoch: 703  Training loss = 4.9012  Validation loss = 6.9966  \n",
      "\n",
      "Fold: 16  Epoch: 704  Training loss = 4.9009  Validation loss = 6.9961  \n",
      "\n",
      "Fold: 16  Epoch: 705  Training loss = 4.9005  Validation loss = 6.9957  \n",
      "\n",
      "Fold: 16  Epoch: 706  Training loss = 4.9001  Validation loss = 6.9952  \n",
      "\n",
      "Fold: 16  Epoch: 707  Training loss = 4.8998  Validation loss = 6.9949  \n",
      "\n",
      "Fold: 16  Epoch: 708  Training loss = 4.8994  Validation loss = 6.9945  \n",
      "\n",
      "Fold: 16  Epoch: 709  Training loss = 4.8992  Validation loss = 6.9941  \n",
      "\n",
      "Fold: 16  Epoch: 710  Training loss = 4.8989  Validation loss = 6.9938  \n",
      "\n",
      "Fold: 16  Epoch: 711  Training loss = 4.8985  Validation loss = 6.9933  \n",
      "\n",
      "Fold: 16  Epoch: 712  Training loss = 4.8981  Validation loss = 6.9929  \n",
      "\n",
      "Fold: 16  Epoch: 713  Training loss = 4.8977  Validation loss = 6.9924  \n",
      "\n",
      "Fold: 16  Epoch: 714  Training loss = 4.8974  Validation loss = 6.9920  \n",
      "\n",
      "Fold: 16  Epoch: 715  Training loss = 4.8969  Validation loss = 6.9915  \n",
      "\n",
      "Fold: 16  Epoch: 716  Training loss = 4.8966  Validation loss = 6.9911  \n",
      "\n",
      "Fold: 16  Epoch: 717  Training loss = 4.8962  Validation loss = 6.9906  \n",
      "\n",
      "Fold: 16  Epoch: 718  Training loss = 4.8958  Validation loss = 6.9902  \n",
      "\n",
      "Fold: 16  Epoch: 719  Training loss = 4.8955  Validation loss = 6.9898  \n",
      "\n",
      "Fold: 16  Epoch: 720  Training loss = 4.8951  Validation loss = 6.9894  \n",
      "\n",
      "Fold: 16  Epoch: 721  Training loss = 4.8947  Validation loss = 6.9890  \n",
      "\n",
      "Fold: 16  Epoch: 722  Training loss = 4.8944  Validation loss = 6.9886  \n",
      "\n",
      "Fold: 16  Epoch: 723  Training loss = 4.8940  Validation loss = 6.9882  \n",
      "\n",
      "Fold: 16  Epoch: 724  Training loss = 4.8936  Validation loss = 6.9878  \n",
      "\n",
      "Fold: 16  Epoch: 725  Training loss = 4.8932  Validation loss = 6.9873  \n",
      "\n",
      "Fold: 16  Epoch: 726  Training loss = 4.8929  Validation loss = 6.9869  \n",
      "\n",
      "Fold: 16  Epoch: 727  Training loss = 4.8925  Validation loss = 6.9864  \n",
      "\n",
      "Fold: 16  Epoch: 728  Training loss = 4.8921  Validation loss = 6.9861  \n",
      "\n",
      "Fold: 16  Epoch: 729  Training loss = 4.8916  Validation loss = 6.9855  \n",
      "\n",
      "Fold: 16  Epoch: 730  Training loss = 4.8912  Validation loss = 6.9850  \n",
      "\n",
      "Fold: 16  Epoch: 731  Training loss = 4.8909  Validation loss = 6.9846  \n",
      "\n",
      "Fold: 16  Epoch: 732  Training loss = 4.8904  Validation loss = 6.9841  \n",
      "\n",
      "Fold: 16  Epoch: 733  Training loss = 4.8901  Validation loss = 6.9837  \n",
      "\n",
      "Fold: 16  Epoch: 734  Training loss = 4.8898  Validation loss = 6.9833  \n",
      "\n",
      "Fold: 16  Epoch: 735  Training loss = 4.8895  Validation loss = 6.9829  \n",
      "\n",
      "Fold: 16  Epoch: 736  Training loss = 4.8890  Validation loss = 6.9825  \n",
      "\n",
      "Fold: 16  Epoch: 737  Training loss = 4.8886  Validation loss = 6.9820  \n",
      "\n",
      "Fold: 16  Epoch: 738  Training loss = 4.8883  Validation loss = 6.9815  \n",
      "\n",
      "Fold: 16  Epoch: 739  Training loss = 4.8879  Validation loss = 6.9811  \n",
      "\n",
      "Fold: 16  Epoch: 740  Training loss = 4.8875  Validation loss = 6.9807  \n",
      "\n",
      "Fold: 16  Epoch: 741  Training loss = 4.8871  Validation loss = 6.9802  \n",
      "\n",
      "Fold: 16  Epoch: 742  Training loss = 4.8867  Validation loss = 6.9797  \n",
      "\n",
      "Fold: 16  Epoch: 743  Training loss = 4.8863  Validation loss = 6.9792  \n",
      "\n",
      "Fold: 16  Epoch: 744  Training loss = 4.8859  Validation loss = 6.9788  \n",
      "\n",
      "Fold: 16  Epoch: 745  Training loss = 4.8855  Validation loss = 6.9783  \n",
      "\n",
      "Fold: 16  Epoch: 746  Training loss = 4.8851  Validation loss = 6.9779  \n",
      "\n",
      "Fold: 16  Epoch: 747  Training loss = 4.8847  Validation loss = 6.9773  \n",
      "\n",
      "Fold: 16  Epoch: 748  Training loss = 4.8843  Validation loss = 6.9770  \n",
      "\n",
      "Fold: 16  Epoch: 749  Training loss = 4.8840  Validation loss = 6.9766  \n",
      "\n",
      "Fold: 16  Epoch: 750  Training loss = 4.8836  Validation loss = 6.9762  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 750  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 5.1758  Validation loss = 2.7417  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 5.1753  Validation loss = 2.7411  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 5.1748  Validation loss = 2.7407  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 5.1744  Validation loss = 2.7403  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 5.1739  Validation loss = 2.7398  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 5.1735  Validation loss = 2.7395  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 5.1731  Validation loss = 2.7391  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 5.1726  Validation loss = 2.7385  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 5.1723  Validation loss = 2.7382  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 5.1718  Validation loss = 2.7376  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 5.1714  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 5.1710  Validation loss = 2.7371  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 5.1705  Validation loss = 2.7367  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 5.1701  Validation loss = 2.7363  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 5.1696  Validation loss = 2.7358  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 5.1691  Validation loss = 2.7352  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 5.1687  Validation loss = 2.7349  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 5.1682  Validation loss = 2.7344  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 5.1678  Validation loss = 2.7341  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 5.1674  Validation loss = 2.7336  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 5.1669  Validation loss = 2.7332  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 5.1664  Validation loss = 2.7327  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 5.1661  Validation loss = 2.7324  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 5.1657  Validation loss = 2.7319  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 5.1652  Validation loss = 2.7314  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 5.1648  Validation loss = 2.7310  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 5.1645  Validation loss = 2.7308  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 5.1640  Validation loss = 2.7303  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 5.1635  Validation loss = 2.7298  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 5.1631  Validation loss = 2.7294  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 5.1627  Validation loss = 2.7291  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 5.1623  Validation loss = 2.7286  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 5.1619  Validation loss = 2.7283  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 5.1615  Validation loss = 2.7281  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 5.1610  Validation loss = 2.7276  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 5.1606  Validation loss = 2.7271  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 5.1601  Validation loss = 2.7266  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 5.1597  Validation loss = 2.7263  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 5.1592  Validation loss = 2.7258  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 5.1588  Validation loss = 2.7253  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 5.1584  Validation loss = 2.7249  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 5.1578  Validation loss = 2.7242  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 5.1574  Validation loss = 2.7239  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 5.1570  Validation loss = 2.7235  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 5.1566  Validation loss = 2.7230  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 5.1561  Validation loss = 2.7224  \n",
      "\n",
      "Fold: 17  Epoch: 47  Training loss = 5.1556  Validation loss = 2.7219  \n",
      "\n",
      "Fold: 17  Epoch: 48  Training loss = 5.1553  Validation loss = 2.7215  \n",
      "\n",
      "Fold: 17  Epoch: 49  Training loss = 5.1548  Validation loss = 2.7208  \n",
      "\n",
      "Fold: 17  Epoch: 50  Training loss = 5.1543  Validation loss = 2.7204  \n",
      "\n",
      "Fold: 17  Epoch: 51  Training loss = 5.1538  Validation loss = 2.7198  \n",
      "\n",
      "Fold: 17  Epoch: 52  Training loss = 5.1533  Validation loss = 2.7194  \n",
      "\n",
      "Fold: 17  Epoch: 53  Training loss = 5.1528  Validation loss = 2.7188  \n",
      "\n",
      "Fold: 17  Epoch: 54  Training loss = 5.1524  Validation loss = 2.7186  \n",
      "\n",
      "Fold: 17  Epoch: 55  Training loss = 5.1521  Validation loss = 2.7181  \n",
      "\n",
      "Fold: 17  Epoch: 56  Training loss = 5.1516  Validation loss = 2.7177  \n",
      "\n",
      "Fold: 17  Epoch: 57  Training loss = 5.1511  Validation loss = 2.7171  \n",
      "\n",
      "Fold: 17  Epoch: 58  Training loss = 5.1507  Validation loss = 2.7166  \n",
      "\n",
      "Fold: 17  Epoch: 59  Training loss = 5.1504  Validation loss = 2.7164  \n",
      "\n",
      "Fold: 17  Epoch: 60  Training loss = 5.1499  Validation loss = 2.7160  \n",
      "\n",
      "Fold: 17  Epoch: 61  Training loss = 5.1495  Validation loss = 2.7155  \n",
      "\n",
      "Fold: 17  Epoch: 62  Training loss = 5.1490  Validation loss = 2.7150  \n",
      "\n",
      "Fold: 17  Epoch: 63  Training loss = 5.1486  Validation loss = 2.7146  \n",
      "\n",
      "Fold: 17  Epoch: 64  Training loss = 5.1482  Validation loss = 2.7143  \n",
      "\n",
      "Fold: 17  Epoch: 65  Training loss = 5.1477  Validation loss = 2.7138  \n",
      "\n",
      "Fold: 17  Epoch: 66  Training loss = 5.1472  Validation loss = 2.7133  \n",
      "\n",
      "Fold: 17  Epoch: 67  Training loss = 5.1468  Validation loss = 2.7129  \n",
      "\n",
      "Fold: 17  Epoch: 68  Training loss = 5.1463  Validation loss = 2.7122  \n",
      "\n",
      "Fold: 17  Epoch: 69  Training loss = 5.1458  Validation loss = 2.7115  \n",
      "\n",
      "Fold: 17  Epoch: 70  Training loss = 5.1453  Validation loss = 2.7111  \n",
      "\n",
      "Fold: 17  Epoch: 71  Training loss = 5.1448  Validation loss = 2.7106  \n",
      "\n",
      "Fold: 17  Epoch: 72  Training loss = 5.1445  Validation loss = 2.7103  \n",
      "\n",
      "Fold: 17  Epoch: 73  Training loss = 5.1441  Validation loss = 2.7098  \n",
      "\n",
      "Fold: 17  Epoch: 74  Training loss = 5.1437  Validation loss = 2.7094  \n",
      "\n",
      "Fold: 17  Epoch: 75  Training loss = 5.1432  Validation loss = 2.7090  \n",
      "\n",
      "Fold: 17  Epoch: 76  Training loss = 5.1428  Validation loss = 2.7087  \n",
      "\n",
      "Fold: 17  Epoch: 77  Training loss = 5.1422  Validation loss = 2.7081  \n",
      "\n",
      "Fold: 17  Epoch: 78  Training loss = 5.1417  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 17  Epoch: 79  Training loss = 5.1413  Validation loss = 2.7069  \n",
      "\n",
      "Fold: 17  Epoch: 80  Training loss = 5.1408  Validation loss = 2.7062  \n",
      "\n",
      "Fold: 17  Epoch: 81  Training loss = 5.1402  Validation loss = 2.7056  \n",
      "\n",
      "Fold: 17  Epoch: 82  Training loss = 5.1399  Validation loss = 2.7053  \n",
      "\n",
      "Fold: 17  Epoch: 83  Training loss = 5.1394  Validation loss = 2.7048  \n",
      "\n",
      "Fold: 17  Epoch: 84  Training loss = 5.1389  Validation loss = 2.7042  \n",
      "\n",
      "Fold: 17  Epoch: 85  Training loss = 5.1384  Validation loss = 2.7037  \n",
      "\n",
      "Fold: 17  Epoch: 86  Training loss = 5.1380  Validation loss = 2.7032  \n",
      "\n",
      "Fold: 17  Epoch: 87  Training loss = 5.1375  Validation loss = 2.7028  \n",
      "\n",
      "Fold: 17  Epoch: 88  Training loss = 5.1372  Validation loss = 2.7023  \n",
      "\n",
      "Fold: 17  Epoch: 89  Training loss = 5.1367  Validation loss = 2.7019  \n",
      "\n",
      "Fold: 17  Epoch: 90  Training loss = 5.1364  Validation loss = 2.7016  \n",
      "\n",
      "Fold: 17  Epoch: 91  Training loss = 5.1359  Validation loss = 2.7012  \n",
      "\n",
      "Fold: 17  Epoch: 92  Training loss = 5.1354  Validation loss = 2.7006  \n",
      "\n",
      "Fold: 17  Epoch: 93  Training loss = 5.1350  Validation loss = 2.7002  \n",
      "\n",
      "Fold: 17  Epoch: 94  Training loss = 5.1345  Validation loss = 2.6996  \n",
      "\n",
      "Fold: 17  Epoch: 95  Training loss = 5.1341  Validation loss = 2.6993  \n",
      "\n",
      "Fold: 17  Epoch: 96  Training loss = 5.1337  Validation loss = 2.6990  \n",
      "\n",
      "Fold: 17  Epoch: 97  Training loss = 5.1332  Validation loss = 2.6985  \n",
      "\n",
      "Fold: 17  Epoch: 98  Training loss = 5.1328  Validation loss = 2.6982  \n",
      "\n",
      "Fold: 17  Epoch: 99  Training loss = 5.1324  Validation loss = 2.6980  \n",
      "\n",
      "Fold: 17  Epoch: 100  Training loss = 5.1321  Validation loss = 2.6976  \n",
      "\n",
      "Fold: 17  Epoch: 101  Training loss = 5.1316  Validation loss = 2.6974  \n",
      "\n",
      "Fold: 17  Epoch: 102  Training loss = 5.1312  Validation loss = 2.6969  \n",
      "\n",
      "Fold: 17  Epoch: 103  Training loss = 5.1308  Validation loss = 2.6964  \n",
      "\n",
      "Fold: 17  Epoch: 104  Training loss = 5.1304  Validation loss = 2.6959  \n",
      "\n",
      "Fold: 17  Epoch: 105  Training loss = 5.1300  Validation loss = 2.6955  \n",
      "\n",
      "Fold: 17  Epoch: 106  Training loss = 5.1296  Validation loss = 2.6951  \n",
      "\n",
      "Fold: 17  Epoch: 107  Training loss = 5.1292  Validation loss = 2.6947  \n",
      "\n",
      "Fold: 17  Epoch: 108  Training loss = 5.1287  Validation loss = 2.6944  \n",
      "\n",
      "Fold: 17  Epoch: 109  Training loss = 5.1283  Validation loss = 2.6939  \n",
      "\n",
      "Fold: 17  Epoch: 110  Training loss = 5.1279  Validation loss = 2.6936  \n",
      "\n",
      "Fold: 17  Epoch: 111  Training loss = 5.1275  Validation loss = 2.6931  \n",
      "\n",
      "Fold: 17  Epoch: 112  Training loss = 5.1272  Validation loss = 2.6929  \n",
      "\n",
      "Fold: 17  Epoch: 113  Training loss = 5.1269  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 17  Epoch: 114  Training loss = 5.1264  Validation loss = 2.6923  \n",
      "\n",
      "Fold: 17  Epoch: 115  Training loss = 5.1260  Validation loss = 2.6918  \n",
      "\n",
      "Fold: 17  Epoch: 116  Training loss = 5.1256  Validation loss = 2.6915  \n",
      "\n",
      "Fold: 17  Epoch: 117  Training loss = 5.1252  Validation loss = 2.6911  \n",
      "\n",
      "Fold: 17  Epoch: 118  Training loss = 5.1247  Validation loss = 2.6908  \n",
      "\n",
      "Fold: 17  Epoch: 119  Training loss = 5.1244  Validation loss = 2.6905  \n",
      "\n",
      "Fold: 17  Epoch: 120  Training loss = 5.1240  Validation loss = 2.6902  \n",
      "\n",
      "Fold: 17  Epoch: 121  Training loss = 5.1236  Validation loss = 2.6900  \n",
      "\n",
      "Fold: 17  Epoch: 122  Training loss = 5.1232  Validation loss = 2.6897  \n",
      "\n",
      "Fold: 17  Epoch: 123  Training loss = 5.1228  Validation loss = 2.6894  \n",
      "\n",
      "Fold: 17  Epoch: 124  Training loss = 5.1224  Validation loss = 2.6890  \n",
      "\n",
      "Fold: 17  Epoch: 125  Training loss = 5.1219  Validation loss = 2.6887  \n",
      "\n",
      "Fold: 17  Epoch: 126  Training loss = 5.1215  Validation loss = 2.6884  \n",
      "\n",
      "Fold: 17  Epoch: 127  Training loss = 5.1210  Validation loss = 2.6881  \n",
      "\n",
      "Fold: 17  Epoch: 128  Training loss = 5.1205  Validation loss = 2.6877  \n",
      "\n",
      "Fold: 17  Epoch: 129  Training loss = 5.1201  Validation loss = 2.6873  \n",
      "\n",
      "Fold: 17  Epoch: 130  Training loss = 5.1197  Validation loss = 2.6869  \n",
      "\n",
      "Fold: 17  Epoch: 131  Training loss = 5.1194  Validation loss = 2.6867  \n",
      "\n",
      "Fold: 17  Epoch: 132  Training loss = 5.1189  Validation loss = 2.6862  \n",
      "\n",
      "Fold: 17  Epoch: 133  Training loss = 5.1185  Validation loss = 2.6858  \n",
      "\n",
      "Fold: 17  Epoch: 134  Training loss = 5.1182  Validation loss = 2.6856  \n",
      "\n",
      "Fold: 17  Epoch: 135  Training loss = 5.1177  Validation loss = 2.6852  \n",
      "\n",
      "Fold: 17  Epoch: 136  Training loss = 5.1173  Validation loss = 2.6848  \n",
      "\n",
      "Fold: 17  Epoch: 137  Training loss = 5.1170  Validation loss = 2.6845  \n",
      "\n",
      "Fold: 17  Epoch: 138  Training loss = 5.1165  Validation loss = 2.6840  \n",
      "\n",
      "Fold: 17  Epoch: 139  Training loss = 5.1161  Validation loss = 2.6837  \n",
      "\n",
      "Fold: 17  Epoch: 140  Training loss = 5.1157  Validation loss = 2.6834  \n",
      "\n",
      "Fold: 17  Epoch: 141  Training loss = 5.1153  Validation loss = 2.6831  \n",
      "\n",
      "Fold: 17  Epoch: 142  Training loss = 5.1149  Validation loss = 2.6826  \n",
      "\n",
      "Fold: 17  Epoch: 143  Training loss = 5.1144  Validation loss = 2.6821  \n",
      "\n",
      "Fold: 17  Epoch: 144  Training loss = 5.1139  Validation loss = 2.6817  \n",
      "\n",
      "Fold: 17  Epoch: 145  Training loss = 5.1135  Validation loss = 2.6815  \n",
      "\n",
      "Fold: 17  Epoch: 146  Training loss = 5.1130  Validation loss = 2.6811  \n",
      "\n",
      "Fold: 17  Epoch: 147  Training loss = 5.1126  Validation loss = 2.6807  \n",
      "\n",
      "Fold: 17  Epoch: 148  Training loss = 5.1121  Validation loss = 2.6803  \n",
      "\n",
      "Fold: 17  Epoch: 149  Training loss = 5.1116  Validation loss = 2.6798  \n",
      "\n",
      "Fold: 17  Epoch: 150  Training loss = 5.1112  Validation loss = 2.6795  \n",
      "\n",
      "Fold: 17  Epoch: 151  Training loss = 5.1109  Validation loss = 2.6792  \n",
      "\n",
      "Fold: 17  Epoch: 152  Training loss = 5.1105  Validation loss = 2.6789  \n",
      "\n",
      "Fold: 17  Epoch: 153  Training loss = 5.1101  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 17  Epoch: 154  Training loss = 5.1097  Validation loss = 2.6783  \n",
      "\n",
      "Fold: 17  Epoch: 155  Training loss = 5.1094  Validation loss = 2.6780  \n",
      "\n",
      "Fold: 17  Epoch: 156  Training loss = 5.1089  Validation loss = 2.6777  \n",
      "\n",
      "Fold: 17  Epoch: 157  Training loss = 5.1085  Validation loss = 2.6774  \n",
      "\n",
      "Fold: 17  Epoch: 158  Training loss = 5.1081  Validation loss = 2.6771  \n",
      "\n",
      "Fold: 17  Epoch: 159  Training loss = 5.1077  Validation loss = 2.6768  \n",
      "\n",
      "Fold: 17  Epoch: 160  Training loss = 5.1072  Validation loss = 2.6764  \n",
      "\n",
      "Fold: 17  Epoch: 161  Training loss = 5.1068  Validation loss = 2.6761  \n",
      "\n",
      "Fold: 17  Epoch: 162  Training loss = 5.1064  Validation loss = 2.6758  \n",
      "\n",
      "Fold: 17  Epoch: 163  Training loss = 5.1060  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 17  Epoch: 164  Training loss = 5.1056  Validation loss = 2.6751  \n",
      "\n",
      "Fold: 17  Epoch: 165  Training loss = 5.1051  Validation loss = 2.6748  \n",
      "\n",
      "Fold: 17  Epoch: 166  Training loss = 5.1046  Validation loss = 2.6742  \n",
      "\n",
      "Fold: 17  Epoch: 167  Training loss = 5.1042  Validation loss = 2.6740  \n",
      "\n",
      "Fold: 17  Epoch: 168  Training loss = 5.1038  Validation loss = 2.6737  \n",
      "\n",
      "Fold: 17  Epoch: 169  Training loss = 5.1034  Validation loss = 2.6733  \n",
      "\n",
      "Fold: 17  Epoch: 170  Training loss = 5.1029  Validation loss = 2.6729  \n",
      "\n",
      "Fold: 17  Epoch: 171  Training loss = 5.1025  Validation loss = 2.6726  \n",
      "\n",
      "Fold: 17  Epoch: 172  Training loss = 5.1021  Validation loss = 2.6723  \n",
      "\n",
      "Fold: 17  Epoch: 173  Training loss = 5.1017  Validation loss = 2.6721  \n",
      "\n",
      "Fold: 17  Epoch: 174  Training loss = 5.1013  Validation loss = 2.6717  \n",
      "\n",
      "Fold: 17  Epoch: 175  Training loss = 5.1010  Validation loss = 2.6715  \n",
      "\n",
      "Fold: 17  Epoch: 176  Training loss = 5.1005  Validation loss = 2.6711  \n",
      "\n",
      "Fold: 17  Epoch: 177  Training loss = 5.1000  Validation loss = 2.6708  \n",
      "\n",
      "Fold: 17  Epoch: 178  Training loss = 5.0995  Validation loss = 2.6704  \n",
      "\n",
      "Fold: 17  Epoch: 179  Training loss = 5.0992  Validation loss = 2.6702  \n",
      "\n",
      "Fold: 17  Epoch: 180  Training loss = 5.0988  Validation loss = 2.6699  \n",
      "\n",
      "Fold: 17  Epoch: 181  Training loss = 5.0983  Validation loss = 2.6695  \n",
      "\n",
      "Fold: 17  Epoch: 182  Training loss = 5.0979  Validation loss = 2.6693  \n",
      "\n",
      "Fold: 17  Epoch: 183  Training loss = 5.0974  Validation loss = 2.6689  \n",
      "\n",
      "Fold: 17  Epoch: 184  Training loss = 5.0970  Validation loss = 2.6685  \n",
      "\n",
      "Fold: 17  Epoch: 185  Training loss = 5.0966  Validation loss = 2.6682  \n",
      "\n",
      "Fold: 17  Epoch: 186  Training loss = 5.0962  Validation loss = 2.6680  \n",
      "\n",
      "Fold: 17  Epoch: 187  Training loss = 5.0958  Validation loss = 2.6677  \n",
      "\n",
      "Fold: 17  Epoch: 188  Training loss = 5.0954  Validation loss = 2.6674  \n",
      "\n",
      "Fold: 17  Epoch: 189  Training loss = 5.0950  Validation loss = 2.6671  \n",
      "\n",
      "Fold: 17  Epoch: 190  Training loss = 5.0946  Validation loss = 2.6667  \n",
      "\n",
      "Fold: 17  Epoch: 191  Training loss = 5.0941  Validation loss = 2.6664  \n",
      "\n",
      "Fold: 17  Epoch: 192  Training loss = 5.0938  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 17  Epoch: 193  Training loss = 5.0935  Validation loss = 2.6659  \n",
      "\n",
      "Fold: 17  Epoch: 194  Training loss = 5.0931  Validation loss = 2.6657  \n",
      "\n",
      "Fold: 17  Epoch: 195  Training loss = 5.0926  Validation loss = 2.6654  \n",
      "\n",
      "Fold: 17  Epoch: 196  Training loss = 5.0922  Validation loss = 2.6650  \n",
      "\n",
      "Fold: 17  Epoch: 197  Training loss = 5.0918  Validation loss = 2.6646  \n",
      "\n",
      "Fold: 17  Epoch: 198  Training loss = 5.0913  Validation loss = 2.6642  \n",
      "\n",
      "Fold: 17  Epoch: 199  Training loss = 5.0909  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 17  Epoch: 200  Training loss = 5.0905  Validation loss = 2.6636  \n",
      "\n",
      "Fold: 17  Epoch: 201  Training loss = 5.0900  Validation loss = 2.6632  \n",
      "\n",
      "Fold: 17  Epoch: 202  Training loss = 5.0896  Validation loss = 2.6629  \n",
      "\n",
      "Fold: 17  Epoch: 203  Training loss = 5.0891  Validation loss = 2.6625  \n",
      "\n",
      "Fold: 17  Epoch: 204  Training loss = 5.0887  Validation loss = 2.6622  \n",
      "\n",
      "Fold: 17  Epoch: 205  Training loss = 5.0883  Validation loss = 2.6619  \n",
      "\n",
      "Fold: 17  Epoch: 206  Training loss = 5.0878  Validation loss = 2.6616  \n",
      "\n",
      "Fold: 17  Epoch: 207  Training loss = 5.0874  Validation loss = 2.6613  \n",
      "\n",
      "Fold: 17  Epoch: 208  Training loss = 5.0870  Validation loss = 2.6611  \n",
      "\n",
      "Fold: 17  Epoch: 209  Training loss = 5.0866  Validation loss = 2.6608  \n",
      "\n",
      "Fold: 17  Epoch: 210  Training loss = 5.0862  Validation loss = 2.6605  \n",
      "\n",
      "Fold: 17  Epoch: 211  Training loss = 5.0858  Validation loss = 2.6603  \n",
      "\n",
      "Fold: 17  Epoch: 212  Training loss = 5.0853  Validation loss = 2.6599  \n",
      "\n",
      "Fold: 17  Epoch: 213  Training loss = 5.0849  Validation loss = 2.6596  \n",
      "\n",
      "Fold: 17  Epoch: 214  Training loss = 5.0845  Validation loss = 2.6593  \n",
      "\n",
      "Fold: 17  Epoch: 215  Training loss = 5.0840  Validation loss = 2.6590  \n",
      "\n",
      "Fold: 17  Epoch: 216  Training loss = 5.0837  Validation loss = 2.6587  \n",
      "\n",
      "Fold: 17  Epoch: 217  Training loss = 5.0832  Validation loss = 2.6582  \n",
      "\n",
      "Fold: 17  Epoch: 218  Training loss = 5.0828  Validation loss = 2.6579  \n",
      "\n",
      "Fold: 17  Epoch: 219  Training loss = 5.0823  Validation loss = 2.6576  \n",
      "\n",
      "Fold: 17  Epoch: 220  Training loss = 5.0819  Validation loss = 2.6574  \n",
      "\n",
      "Fold: 17  Epoch: 221  Training loss = 5.0815  Validation loss = 2.6571  \n",
      "\n",
      "Fold: 17  Epoch: 222  Training loss = 5.0810  Validation loss = 2.6568  \n",
      "\n",
      "Fold: 17  Epoch: 223  Training loss = 5.0807  Validation loss = 2.6565  \n",
      "\n",
      "Fold: 17  Epoch: 224  Training loss = 5.0803  Validation loss = 2.6563  \n",
      "\n",
      "Fold: 17  Epoch: 225  Training loss = 5.0799  Validation loss = 2.6560  \n",
      "\n",
      "Fold: 17  Epoch: 226  Training loss = 5.0796  Validation loss = 2.6557  \n",
      "\n",
      "Fold: 17  Epoch: 227  Training loss = 5.0792  Validation loss = 2.6554  \n",
      "\n",
      "Fold: 17  Epoch: 228  Training loss = 5.0788  Validation loss = 2.6552  \n",
      "\n",
      "Fold: 17  Epoch: 229  Training loss = 5.0784  Validation loss = 2.6548  \n",
      "\n",
      "Fold: 17  Epoch: 230  Training loss = 5.0779  Validation loss = 2.6545  \n",
      "\n",
      "Fold: 17  Epoch: 231  Training loss = 5.0774  Validation loss = 2.6542  \n",
      "\n",
      "Fold: 17  Epoch: 232  Training loss = 5.0770  Validation loss = 2.6539  \n",
      "\n",
      "Fold: 17  Epoch: 233  Training loss = 5.0766  Validation loss = 2.6535  \n",
      "\n",
      "Fold: 17  Epoch: 234  Training loss = 5.0761  Validation loss = 2.6532  \n",
      "\n",
      "Fold: 17  Epoch: 235  Training loss = 5.0756  Validation loss = 2.6528  \n",
      "\n",
      "Fold: 17  Epoch: 236  Training loss = 5.0752  Validation loss = 2.6525  \n",
      "\n",
      "Fold: 17  Epoch: 237  Training loss = 5.0747  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 17  Epoch: 238  Training loss = 5.0744  Validation loss = 2.6520  \n",
      "\n",
      "Fold: 17  Epoch: 239  Training loss = 5.0740  Validation loss = 2.6518  \n",
      "\n",
      "Fold: 17  Epoch: 240  Training loss = 5.0735  Validation loss = 2.6516  \n",
      "\n",
      "Fold: 17  Epoch: 241  Training loss = 5.0731  Validation loss = 2.6513  \n",
      "\n",
      "Fold: 17  Epoch: 242  Training loss = 5.0727  Validation loss = 2.6509  \n",
      "\n",
      "Fold: 17  Epoch: 243  Training loss = 5.0722  Validation loss = 2.6507  \n",
      "\n",
      "Fold: 17  Epoch: 244  Training loss = 5.0719  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 17  Epoch: 245  Training loss = 5.0715  Validation loss = 2.6501  \n",
      "\n",
      "Fold: 17  Epoch: 246  Training loss = 5.0710  Validation loss = 2.6499  \n",
      "\n",
      "Fold: 17  Epoch: 247  Training loss = 5.0706  Validation loss = 2.6496  \n",
      "\n",
      "Fold: 17  Epoch: 248  Training loss = 5.0702  Validation loss = 2.6494  \n",
      "\n",
      "Fold: 17  Epoch: 249  Training loss = 5.0698  Validation loss = 2.6491  \n",
      "\n",
      "Fold: 17  Epoch: 250  Training loss = 5.0695  Validation loss = 2.6489  \n",
      "\n",
      "Fold: 17  Epoch: 251  Training loss = 5.0691  Validation loss = 2.6486  \n",
      "\n",
      "Fold: 17  Epoch: 252  Training loss = 5.0687  Validation loss = 2.6483  \n",
      "\n",
      "Fold: 17  Epoch: 253  Training loss = 5.0683  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 17  Epoch: 254  Training loss = 5.0679  Validation loss = 2.6477  \n",
      "\n",
      "Fold: 17  Epoch: 255  Training loss = 5.0674  Validation loss = 2.6473  \n",
      "\n",
      "Fold: 17  Epoch: 256  Training loss = 5.0669  Validation loss = 2.6470  \n",
      "\n",
      "Fold: 17  Epoch: 257  Training loss = 5.0666  Validation loss = 2.6468  \n",
      "\n",
      "Fold: 17  Epoch: 258  Training loss = 5.0663  Validation loss = 2.6466  \n",
      "\n",
      "Fold: 17  Epoch: 259  Training loss = 5.0659  Validation loss = 2.6463  \n",
      "\n",
      "Fold: 17  Epoch: 260  Training loss = 5.0654  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 17  Epoch: 261  Training loss = 5.0650  Validation loss = 2.6457  \n",
      "\n",
      "Fold: 17  Epoch: 262  Training loss = 5.0646  Validation loss = 2.6455  \n",
      "\n",
      "Fold: 17  Epoch: 263  Training loss = 5.0643  Validation loss = 2.6453  \n",
      "\n",
      "Fold: 17  Epoch: 264  Training loss = 5.0638  Validation loss = 2.6449  \n",
      "\n",
      "Fold: 17  Epoch: 265  Training loss = 5.0633  Validation loss = 2.6446  \n",
      "\n",
      "Fold: 17  Epoch: 266  Training loss = 5.0629  Validation loss = 2.6443  \n",
      "\n",
      "Fold: 17  Epoch: 267  Training loss = 5.0624  Validation loss = 2.6441  \n",
      "\n",
      "Fold: 17  Epoch: 268  Training loss = 5.0620  Validation loss = 2.6438  \n",
      "\n",
      "Fold: 17  Epoch: 269  Training loss = 5.0616  Validation loss = 2.6435  \n",
      "\n",
      "Fold: 17  Epoch: 270  Training loss = 5.0612  Validation loss = 2.6432  \n",
      "\n",
      "Fold: 17  Epoch: 271  Training loss = 5.0608  Validation loss = 2.6430  \n",
      "\n",
      "Fold: 17  Epoch: 272  Training loss = 5.0604  Validation loss = 2.6427  \n",
      "\n",
      "Fold: 17  Epoch: 273  Training loss = 5.0600  Validation loss = 2.6425  \n",
      "\n",
      "Fold: 17  Epoch: 274  Training loss = 5.0596  Validation loss = 2.6423  \n",
      "\n",
      "Fold: 17  Epoch: 275  Training loss = 5.0592  Validation loss = 2.6421  \n",
      "\n",
      "Fold: 17  Epoch: 276  Training loss = 5.0588  Validation loss = 2.6418  \n",
      "\n",
      "Fold: 17  Epoch: 277  Training loss = 5.0584  Validation loss = 2.6416  \n",
      "\n",
      "Fold: 17  Epoch: 278  Training loss = 5.0580  Validation loss = 2.6413  \n",
      "\n",
      "Fold: 17  Epoch: 279  Training loss = 5.0576  Validation loss = 2.6411  \n",
      "\n",
      "Fold: 17  Epoch: 280  Training loss = 5.0573  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 17  Epoch: 281  Training loss = 5.0569  Validation loss = 2.6407  \n",
      "\n",
      "Fold: 17  Epoch: 282  Training loss = 5.0564  Validation loss = 2.6403  \n",
      "\n",
      "Fold: 17  Epoch: 283  Training loss = 5.0559  Validation loss = 2.6400  \n",
      "\n",
      "Fold: 17  Epoch: 284  Training loss = 5.0555  Validation loss = 2.6397  \n",
      "\n",
      "Fold: 17  Epoch: 285  Training loss = 5.0550  Validation loss = 2.6394  \n",
      "\n",
      "Fold: 17  Epoch: 286  Training loss = 5.0546  Validation loss = 2.6392  \n",
      "\n",
      "Fold: 17  Epoch: 287  Training loss = 5.0542  Validation loss = 2.6389  \n",
      "\n",
      "Fold: 17  Epoch: 288  Training loss = 5.0537  Validation loss = 2.6387  \n",
      "\n",
      "Fold: 17  Epoch: 289  Training loss = 5.0533  Validation loss = 2.6384  \n",
      "\n",
      "Fold: 17  Epoch: 290  Training loss = 5.0528  Validation loss = 2.6381  \n",
      "\n",
      "Fold: 17  Epoch: 291  Training loss = 5.0523  Validation loss = 2.6378  \n",
      "\n",
      "Fold: 17  Epoch: 292  Training loss = 5.0519  Validation loss = 2.6375  \n",
      "\n",
      "Fold: 17  Epoch: 293  Training loss = 5.0514  Validation loss = 2.6372  \n",
      "\n",
      "Fold: 17  Epoch: 294  Training loss = 5.0509  Validation loss = 2.6369  \n",
      "\n",
      "Fold: 17  Epoch: 295  Training loss = 5.0505  Validation loss = 2.6365  \n",
      "\n",
      "Fold: 17  Epoch: 296  Training loss = 5.0501  Validation loss = 2.6363  \n",
      "\n",
      "Fold: 17  Epoch: 297  Training loss = 5.0497  Validation loss = 2.6361  \n",
      "\n",
      "Fold: 17  Epoch: 298  Training loss = 5.0492  Validation loss = 2.6358  \n",
      "\n",
      "Fold: 17  Epoch: 299  Training loss = 5.0488  Validation loss = 2.6354  \n",
      "\n",
      "Fold: 17  Epoch: 300  Training loss = 5.0484  Validation loss = 2.6351  \n",
      "\n",
      "Fold: 17  Epoch: 301  Training loss = 5.0479  Validation loss = 2.6349  \n",
      "\n",
      "Fold: 17  Epoch: 302  Training loss = 5.0475  Validation loss = 2.6345  \n",
      "\n",
      "Fold: 17  Epoch: 303  Training loss = 5.0470  Validation loss = 2.6342  \n",
      "\n",
      "Fold: 17  Epoch: 304  Training loss = 5.0466  Validation loss = 2.6339  \n",
      "\n",
      "Fold: 17  Epoch: 305  Training loss = 5.0462  Validation loss = 2.6337  \n",
      "\n",
      "Fold: 17  Epoch: 306  Training loss = 5.0458  Validation loss = 2.6334  \n",
      "\n",
      "Fold: 17  Epoch: 307  Training loss = 5.0454  Validation loss = 2.6332  \n",
      "\n",
      "Fold: 17  Epoch: 308  Training loss = 5.0450  Validation loss = 2.6328  \n",
      "\n",
      "Fold: 17  Epoch: 309  Training loss = 5.0445  Validation loss = 2.6325  \n",
      "\n",
      "Fold: 17  Epoch: 310  Training loss = 5.0441  Validation loss = 2.6323  \n",
      "\n",
      "Fold: 17  Epoch: 311  Training loss = 5.0436  Validation loss = 2.6320  \n",
      "\n",
      "Fold: 17  Epoch: 312  Training loss = 5.0431  Validation loss = 2.6317  \n",
      "\n",
      "Fold: 17  Epoch: 313  Training loss = 5.0427  Validation loss = 2.6314  \n",
      "\n",
      "Fold: 17  Epoch: 314  Training loss = 5.0424  Validation loss = 2.6312  \n",
      "\n",
      "Fold: 17  Epoch: 315  Training loss = 5.0419  Validation loss = 2.6310  \n",
      "\n",
      "Fold: 17  Epoch: 316  Training loss = 5.0415  Validation loss = 2.6308  \n",
      "\n",
      "Fold: 17  Epoch: 317  Training loss = 5.0411  Validation loss = 2.6305  \n",
      "\n",
      "Fold: 17  Epoch: 318  Training loss = 5.0406  Validation loss = 2.6302  \n",
      "\n",
      "Fold: 17  Epoch: 319  Training loss = 5.0402  Validation loss = 2.6300  \n",
      "\n",
      "Fold: 17  Epoch: 320  Training loss = 5.0399  Validation loss = 2.6298  \n",
      "\n",
      "Fold: 17  Epoch: 321  Training loss = 5.0395  Validation loss = 2.6296  \n",
      "\n",
      "Fold: 17  Epoch: 322  Training loss = 5.0391  Validation loss = 2.6294  \n",
      "\n",
      "Fold: 17  Epoch: 323  Training loss = 5.0387  Validation loss = 2.6291  \n",
      "\n",
      "Fold: 17  Epoch: 324  Training loss = 5.0383  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 17  Epoch: 325  Training loss = 5.0378  Validation loss = 2.6285  \n",
      "\n",
      "Fold: 17  Epoch: 326  Training loss = 5.0374  Validation loss = 2.6282  \n",
      "\n",
      "Fold: 17  Epoch: 327  Training loss = 5.0369  Validation loss = 2.6280  \n",
      "\n",
      "Fold: 17  Epoch: 328  Training loss = 5.0365  Validation loss = 2.6277  \n",
      "\n",
      "Fold: 17  Epoch: 329  Training loss = 5.0361  Validation loss = 2.6275  \n",
      "\n",
      "Fold: 17  Epoch: 330  Training loss = 5.0357  Validation loss = 2.6272  \n",
      "\n",
      "Fold: 17  Epoch: 331  Training loss = 5.0352  Validation loss = 2.6269  \n",
      "\n",
      "Fold: 17  Epoch: 332  Training loss = 5.0349  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 17  Epoch: 333  Training loss = 5.0344  Validation loss = 2.6265  \n",
      "\n",
      "Fold: 17  Epoch: 334  Training loss = 5.0340  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 17  Epoch: 335  Training loss = 5.0336  Validation loss = 2.6259  \n",
      "\n",
      "Fold: 17  Epoch: 336  Training loss = 5.0331  Validation loss = 2.6256  \n",
      "\n",
      "Fold: 17  Epoch: 337  Training loss = 5.0327  Validation loss = 2.6254  \n",
      "\n",
      "Fold: 17  Epoch: 338  Training loss = 5.0323  Validation loss = 2.6252  \n",
      "\n",
      "Fold: 17  Epoch: 339  Training loss = 5.0319  Validation loss = 2.6249  \n",
      "\n",
      "Fold: 17  Epoch: 340  Training loss = 5.0316  Validation loss = 2.6247  \n",
      "\n",
      "Fold: 17  Epoch: 341  Training loss = 5.0312  Validation loss = 2.6245  \n",
      "\n",
      "Fold: 17  Epoch: 342  Training loss = 5.0308  Validation loss = 2.6243  \n",
      "\n",
      "Fold: 17  Epoch: 343  Training loss = 5.0303  Validation loss = 2.6240  \n",
      "\n",
      "Fold: 17  Epoch: 344  Training loss = 5.0299  Validation loss = 2.6238  \n",
      "\n",
      "Fold: 17  Epoch: 345  Training loss = 5.0295  Validation loss = 2.6235  \n",
      "\n",
      "Fold: 17  Epoch: 346  Training loss = 5.0291  Validation loss = 2.6232  \n",
      "\n",
      "Fold: 17  Epoch: 347  Training loss = 5.0286  Validation loss = 2.6229  \n",
      "\n",
      "Fold: 17  Epoch: 348  Training loss = 5.0281  Validation loss = 2.6226  \n",
      "\n",
      "Fold: 17  Epoch: 349  Training loss = 5.0276  Validation loss = 2.6223  \n",
      "\n",
      "Fold: 17  Epoch: 350  Training loss = 5.0272  Validation loss = 2.6221  \n",
      "\n",
      "Fold: 17  Epoch: 351  Training loss = 5.0267  Validation loss = 2.6218  \n",
      "\n",
      "Fold: 17  Epoch: 352  Training loss = 5.0263  Validation loss = 2.6215  \n",
      "\n",
      "Fold: 17  Epoch: 353  Training loss = 5.0258  Validation loss = 2.6212  \n",
      "\n",
      "Fold: 17  Epoch: 354  Training loss = 5.0253  Validation loss = 2.6209  \n",
      "\n",
      "Fold: 17  Epoch: 355  Training loss = 5.0248  Validation loss = 2.6205  \n",
      "\n",
      "Fold: 17  Epoch: 356  Training loss = 5.0244  Validation loss = 2.6203  \n",
      "\n",
      "Fold: 17  Epoch: 357  Training loss = 5.0239  Validation loss = 2.6201  \n",
      "\n",
      "Fold: 17  Epoch: 358  Training loss = 5.0235  Validation loss = 2.6198  \n",
      "\n",
      "Fold: 17  Epoch: 359  Training loss = 5.0231  Validation loss = 2.6196  \n",
      "\n",
      "Fold: 17  Epoch: 360  Training loss = 5.0227  Validation loss = 2.6193  \n",
      "\n",
      "Fold: 17  Epoch: 361  Training loss = 5.0222  Validation loss = 2.6190  \n",
      "\n",
      "Fold: 17  Epoch: 362  Training loss = 5.0217  Validation loss = 2.6188  \n",
      "\n",
      "Fold: 17  Epoch: 363  Training loss = 5.0213  Validation loss = 2.6185  \n",
      "\n",
      "Fold: 17  Epoch: 364  Training loss = 5.0208  Validation loss = 2.6182  \n",
      "\n",
      "Fold: 17  Epoch: 365  Training loss = 5.0204  Validation loss = 2.6180  \n",
      "\n",
      "Fold: 17  Epoch: 366  Training loss = 5.0200  Validation loss = 2.6178  \n",
      "\n",
      "Fold: 17  Epoch: 367  Training loss = 5.0195  Validation loss = 2.6176  \n",
      "\n",
      "Fold: 17  Epoch: 368  Training loss = 5.0191  Validation loss = 2.6173  \n",
      "\n",
      "Fold: 17  Epoch: 369  Training loss = 5.0187  Validation loss = 2.6170  \n",
      "\n",
      "Fold: 17  Epoch: 370  Training loss = 5.0183  Validation loss = 2.6168  \n",
      "\n",
      "Fold: 17  Epoch: 371  Training loss = 5.0178  Validation loss = 2.6165  \n",
      "\n",
      "Fold: 17  Epoch: 372  Training loss = 5.0174  Validation loss = 2.6163  \n",
      "\n",
      "Fold: 17  Epoch: 373  Training loss = 5.0170  Validation loss = 2.6160  \n",
      "\n",
      "Fold: 17  Epoch: 374  Training loss = 5.0166  Validation loss = 2.6158  \n",
      "\n",
      "Fold: 17  Epoch: 375  Training loss = 5.0161  Validation loss = 2.6155  \n",
      "\n",
      "Fold: 17  Epoch: 376  Training loss = 5.0156  Validation loss = 2.6152  \n",
      "\n",
      "Fold: 17  Epoch: 377  Training loss = 5.0153  Validation loss = 2.6150  \n",
      "\n",
      "Fold: 17  Epoch: 378  Training loss = 5.0148  Validation loss = 2.6147  \n",
      "\n",
      "Fold: 17  Epoch: 379  Training loss = 5.0144  Validation loss = 2.6145  \n",
      "\n",
      "Fold: 17  Epoch: 380  Training loss = 5.0139  Validation loss = 2.6142  \n",
      "\n",
      "Fold: 17  Epoch: 381  Training loss = 5.0135  Validation loss = 2.6139  \n",
      "\n",
      "Fold: 17  Epoch: 382  Training loss = 5.0131  Validation loss = 2.6137  \n",
      "\n",
      "Fold: 17  Epoch: 383  Training loss = 5.0127  Validation loss = 2.6134  \n",
      "\n",
      "Fold: 17  Epoch: 384  Training loss = 5.0122  Validation loss = 2.6132  \n",
      "\n",
      "Fold: 17  Epoch: 385  Training loss = 5.0118  Validation loss = 2.6129  \n",
      "\n",
      "Fold: 17  Epoch: 386  Training loss = 5.0114  Validation loss = 2.6127  \n",
      "\n",
      "Fold: 17  Epoch: 387  Training loss = 5.0110  Validation loss = 2.6125  \n",
      "\n",
      "Fold: 17  Epoch: 388  Training loss = 5.0105  Validation loss = 2.6122  \n",
      "\n",
      "Fold: 17  Epoch: 389  Training loss = 5.0101  Validation loss = 2.6119  \n",
      "\n",
      "Fold: 17  Epoch: 390  Training loss = 5.0096  Validation loss = 2.6117  \n",
      "\n",
      "Fold: 17  Epoch: 391  Training loss = 5.0092  Validation loss = 2.6114  \n",
      "\n",
      "Fold: 17  Epoch: 392  Training loss = 5.0087  Validation loss = 2.6112  \n",
      "\n",
      "Fold: 17  Epoch: 393  Training loss = 5.0083  Validation loss = 2.6109  \n",
      "\n",
      "Fold: 17  Epoch: 394  Training loss = 5.0079  Validation loss = 2.6106  \n",
      "\n",
      "Fold: 17  Epoch: 395  Training loss = 5.0075  Validation loss = 2.6104  \n",
      "\n",
      "Fold: 17  Epoch: 396  Training loss = 5.0071  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 17  Epoch: 397  Training loss = 5.0066  Validation loss = 2.6099  \n",
      "\n",
      "Fold: 17  Epoch: 398  Training loss = 5.0062  Validation loss = 2.6096  \n",
      "\n",
      "Fold: 17  Epoch: 399  Training loss = 5.0059  Validation loss = 2.6095  \n",
      "\n",
      "Fold: 17  Epoch: 400  Training loss = 5.0054  Validation loss = 2.6091  \n",
      "\n",
      "Fold: 17  Epoch: 401  Training loss = 5.0050  Validation loss = 2.6089  \n",
      "\n",
      "Fold: 17  Epoch: 402  Training loss = 5.0046  Validation loss = 2.6087  \n",
      "\n",
      "Fold: 17  Epoch: 403  Training loss = 5.0042  Validation loss = 2.6084  \n",
      "\n",
      "Fold: 17  Epoch: 404  Training loss = 5.0038  Validation loss = 2.6083  \n",
      "\n",
      "Fold: 17  Epoch: 405  Training loss = 5.0034  Validation loss = 2.6081  \n",
      "\n",
      "Fold: 17  Epoch: 406  Training loss = 5.0030  Validation loss = 2.6078  \n",
      "\n",
      "Fold: 17  Epoch: 407  Training loss = 5.0026  Validation loss = 2.6076  \n",
      "\n",
      "Fold: 17  Epoch: 408  Training loss = 5.0022  Validation loss = 2.6073  \n",
      "\n",
      "Fold: 17  Epoch: 409  Training loss = 5.0019  Validation loss = 2.6071  \n",
      "\n",
      "Fold: 17  Epoch: 410  Training loss = 5.0014  Validation loss = 2.6068  \n",
      "\n",
      "Fold: 17  Epoch: 411  Training loss = 5.0009  Validation loss = 2.6066  \n",
      "\n",
      "Fold: 17  Epoch: 412  Training loss = 5.0005  Validation loss = 2.6064  \n",
      "\n",
      "Fold: 17  Epoch: 413  Training loss = 5.0000  Validation loss = 2.6061  \n",
      "\n",
      "Fold: 17  Epoch: 414  Training loss = 4.9995  Validation loss = 2.6058  \n",
      "\n",
      "Fold: 17  Epoch: 415  Training loss = 4.9991  Validation loss = 2.6056  \n",
      "\n",
      "Fold: 17  Epoch: 416  Training loss = 4.9987  Validation loss = 2.6054  \n",
      "\n",
      "Fold: 17  Epoch: 417  Training loss = 4.9982  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 17  Epoch: 418  Training loss = 4.9978  Validation loss = 2.6049  \n",
      "\n",
      "Fold: 17  Epoch: 419  Training loss = 4.9974  Validation loss = 2.6046  \n",
      "\n",
      "Fold: 17  Epoch: 420  Training loss = 4.9969  Validation loss = 2.6044  \n",
      "\n",
      "Fold: 17  Epoch: 421  Training loss = 4.9965  Validation loss = 2.6042  \n",
      "\n",
      "Fold: 17  Epoch: 422  Training loss = 4.9961  Validation loss = 2.6039  \n",
      "\n",
      "Fold: 17  Epoch: 423  Training loss = 4.9956  Validation loss = 2.6037  \n",
      "\n",
      "Fold: 17  Epoch: 424  Training loss = 4.9952  Validation loss = 2.6034  \n",
      "\n",
      "Fold: 17  Epoch: 425  Training loss = 4.9948  Validation loss = 2.6032  \n",
      "\n",
      "Fold: 17  Epoch: 426  Training loss = 4.9943  Validation loss = 2.6029  \n",
      "\n",
      "Fold: 17  Epoch: 427  Training loss = 4.9939  Validation loss = 2.6027  \n",
      "\n",
      "Fold: 17  Epoch: 428  Training loss = 4.9935  Validation loss = 2.6025  \n",
      "\n",
      "Fold: 17  Epoch: 429  Training loss = 4.9931  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 17  Epoch: 430  Training loss = 4.9927  Validation loss = 2.6021  \n",
      "\n",
      "Fold: 17  Epoch: 431  Training loss = 4.9923  Validation loss = 2.6018  \n",
      "\n",
      "Fold: 17  Epoch: 432  Training loss = 4.9918  Validation loss = 2.6016  \n",
      "\n",
      "Fold: 17  Epoch: 433  Training loss = 4.9912  Validation loss = 2.6013  \n",
      "\n",
      "Fold: 17  Epoch: 434  Training loss = 4.9908  Validation loss = 2.6011  \n",
      "\n",
      "Fold: 17  Epoch: 435  Training loss = 4.9904  Validation loss = 2.6008  \n",
      "\n",
      "Fold: 17  Epoch: 436  Training loss = 4.9900  Validation loss = 2.6006  \n",
      "\n",
      "Fold: 17  Epoch: 437  Training loss = 4.9896  Validation loss = 2.6004  \n",
      "\n",
      "Fold: 17  Epoch: 438  Training loss = 4.9892  Validation loss = 2.6001  \n",
      "\n",
      "Fold: 17  Epoch: 439  Training loss = 4.9888  Validation loss = 2.5999  \n",
      "\n",
      "Fold: 17  Epoch: 440  Training loss = 4.9884  Validation loss = 2.5996  \n",
      "\n",
      "Fold: 17  Epoch: 441  Training loss = 4.9880  Validation loss = 2.5994  \n",
      "\n",
      "Fold: 17  Epoch: 442  Training loss = 4.9876  Validation loss = 2.5992  \n",
      "\n",
      "Fold: 17  Epoch: 443  Training loss = 4.9872  Validation loss = 2.5989  \n",
      "\n",
      "Fold: 17  Epoch: 444  Training loss = 4.9868  Validation loss = 2.5987  \n",
      "\n",
      "Fold: 17  Epoch: 445  Training loss = 4.9864  Validation loss = 2.5985  \n",
      "\n",
      "Fold: 17  Epoch: 446  Training loss = 4.9858  Validation loss = 2.5982  \n",
      "\n",
      "Fold: 17  Epoch: 447  Training loss = 4.9854  Validation loss = 2.5980  \n",
      "\n",
      "Fold: 17  Epoch: 448  Training loss = 4.9850  Validation loss = 2.5977  \n",
      "\n",
      "Fold: 17  Epoch: 449  Training loss = 4.9845  Validation loss = 2.5975  \n",
      "\n",
      "Fold: 17  Epoch: 450  Training loss = 4.9840  Validation loss = 2.5973  \n",
      "\n",
      "Fold: 17  Epoch: 451  Training loss = 4.9836  Validation loss = 2.5970  \n",
      "\n",
      "Fold: 17  Epoch: 452  Training loss = 4.9831  Validation loss = 2.5967  \n",
      "\n",
      "Fold: 17  Epoch: 453  Training loss = 4.9826  Validation loss = 2.5965  \n",
      "\n",
      "Fold: 17  Epoch: 454  Training loss = 4.9823  Validation loss = 2.5963  \n",
      "\n",
      "Fold: 17  Epoch: 455  Training loss = 4.9819  Validation loss = 2.5961  \n",
      "\n",
      "Fold: 17  Epoch: 456  Training loss = 4.9815  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 17  Epoch: 457  Training loss = 4.9811  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 17  Epoch: 458  Training loss = 4.9807  Validation loss = 2.5953  \n",
      "\n",
      "Fold: 17  Epoch: 459  Training loss = 4.9803  Validation loss = 2.5951  \n",
      "\n",
      "Fold: 17  Epoch: 460  Training loss = 4.9799  Validation loss = 2.5949  \n",
      "\n",
      "Fold: 17  Epoch: 461  Training loss = 4.9795  Validation loss = 2.5947  \n",
      "\n",
      "Fold: 17  Epoch: 462  Training loss = 4.9790  Validation loss = 2.5944  \n",
      "\n",
      "Fold: 17  Epoch: 463  Training loss = 4.9786  Validation loss = 2.5942  \n",
      "\n",
      "Fold: 17  Epoch: 464  Training loss = 4.9780  Validation loss = 2.5939  \n",
      "\n",
      "Fold: 17  Epoch: 465  Training loss = 4.9776  Validation loss = 2.5937  \n",
      "\n",
      "Fold: 17  Epoch: 466  Training loss = 4.9772  Validation loss = 2.5934  \n",
      "\n",
      "Fold: 17  Epoch: 467  Training loss = 4.9768  Validation loss = 2.5932  \n",
      "\n",
      "Fold: 17  Epoch: 468  Training loss = 4.9764  Validation loss = 2.5930  \n",
      "\n",
      "Fold: 17  Epoch: 469  Training loss = 4.9759  Validation loss = 2.5927  \n",
      "\n",
      "Fold: 17  Epoch: 470  Training loss = 4.9755  Validation loss = 2.5925  \n",
      "\n",
      "Fold: 17  Epoch: 471  Training loss = 4.9751  Validation loss = 2.5923  \n",
      "\n",
      "Fold: 17  Epoch: 472  Training loss = 4.9746  Validation loss = 2.5920  \n",
      "\n",
      "Fold: 17  Epoch: 473  Training loss = 4.9742  Validation loss = 2.5918  \n",
      "\n",
      "Fold: 17  Epoch: 474  Training loss = 4.9738  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 17  Epoch: 475  Training loss = 4.9734  Validation loss = 2.5914  \n",
      "\n",
      "Fold: 17  Epoch: 476  Training loss = 4.9731  Validation loss = 2.5912  \n",
      "\n",
      "Fold: 17  Epoch: 477  Training loss = 4.9727  Validation loss = 2.5910  \n",
      "\n",
      "Fold: 17  Epoch: 478  Training loss = 4.9723  Validation loss = 2.5908  \n",
      "\n",
      "Fold: 17  Epoch: 479  Training loss = 4.9719  Validation loss = 2.5906  \n",
      "\n",
      "Fold: 17  Epoch: 480  Training loss = 4.9715  Validation loss = 2.5904  \n",
      "\n",
      "Fold: 17  Epoch: 481  Training loss = 4.9711  Validation loss = 2.5902  \n",
      "\n",
      "Fold: 17  Epoch: 482  Training loss = 4.9707  Validation loss = 2.5899  \n",
      "\n",
      "Fold: 17  Epoch: 483  Training loss = 4.9702  Validation loss = 2.5897  \n",
      "\n",
      "Fold: 17  Epoch: 484  Training loss = 4.9698  Validation loss = 2.5895  \n",
      "\n",
      "Fold: 17  Epoch: 485  Training loss = 4.9694  Validation loss = 2.5892  \n",
      "\n",
      "Fold: 17  Epoch: 486  Training loss = 4.9690  Validation loss = 2.5890  \n",
      "\n",
      "Fold: 17  Epoch: 487  Training loss = 4.9686  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 17  Epoch: 488  Training loss = 4.9682  Validation loss = 2.5886  \n",
      "\n",
      "Fold: 17  Epoch: 489  Training loss = 4.9677  Validation loss = 2.5883  \n",
      "\n",
      "Fold: 17  Epoch: 490  Training loss = 4.9673  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 17  Epoch: 491  Training loss = 4.9668  Validation loss = 2.5878  \n",
      "\n",
      "Fold: 17  Epoch: 492  Training loss = 4.9664  Validation loss = 2.5876  \n",
      "\n",
      "Fold: 17  Epoch: 493  Training loss = 4.9659  Validation loss = 2.5873  \n",
      "\n",
      "Fold: 17  Epoch: 494  Training loss = 4.9655  Validation loss = 2.5871  \n",
      "\n",
      "Fold: 17  Epoch: 495  Training loss = 4.9651  Validation loss = 2.5869  \n",
      "\n",
      "Fold: 17  Epoch: 496  Training loss = 4.9647  Validation loss = 2.5867  \n",
      "\n",
      "Fold: 17  Epoch: 497  Training loss = 4.9643  Validation loss = 2.5864  \n",
      "\n",
      "Fold: 17  Epoch: 498  Training loss = 4.9638  Validation loss = 2.5861  \n",
      "\n",
      "Fold: 17  Epoch: 499  Training loss = 4.9634  Validation loss = 2.5859  \n",
      "\n",
      "Fold: 17  Epoch: 500  Training loss = 4.9628  Validation loss = 2.5856  \n",
      "\n",
      "Fold: 17  Epoch: 501  Training loss = 4.9623  Validation loss = 2.5854  \n",
      "\n",
      "Fold: 17  Epoch: 502  Training loss = 4.9619  Validation loss = 2.5852  \n",
      "\n",
      "Fold: 17  Epoch: 503  Training loss = 4.9615  Validation loss = 2.5850  \n",
      "\n",
      "Fold: 17  Epoch: 504  Training loss = 4.9611  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 17  Epoch: 505  Training loss = 4.9607  Validation loss = 2.5846  \n",
      "\n",
      "Fold: 17  Epoch: 506  Training loss = 4.9603  Validation loss = 2.5844  \n",
      "\n",
      "Fold: 17  Epoch: 507  Training loss = 4.9599  Validation loss = 2.5842  \n",
      "\n",
      "Fold: 17  Epoch: 508  Training loss = 4.9595  Validation loss = 2.5839  \n",
      "\n",
      "Fold: 17  Epoch: 509  Training loss = 4.9591  Validation loss = 2.5836  \n",
      "\n",
      "Fold: 17  Epoch: 510  Training loss = 4.9586  Validation loss = 2.5834  \n",
      "\n",
      "Fold: 17  Epoch: 511  Training loss = 4.9581  Validation loss = 2.5832  \n",
      "\n",
      "Fold: 17  Epoch: 512  Training loss = 4.9576  Validation loss = 2.5829  \n",
      "\n",
      "Fold: 17  Epoch: 513  Training loss = 4.9572  Validation loss = 2.5827  \n",
      "\n",
      "Fold: 17  Epoch: 514  Training loss = 4.9568  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 17  Epoch: 515  Training loss = 4.9564  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 17  Epoch: 516  Training loss = 4.9560  Validation loss = 2.5821  \n",
      "\n",
      "Fold: 17  Epoch: 517  Training loss = 4.9556  Validation loss = 2.5819  \n",
      "\n",
      "Fold: 17  Epoch: 518  Training loss = 4.9553  Validation loss = 2.5818  \n",
      "\n",
      "Fold: 17  Epoch: 519  Training loss = 4.9548  Validation loss = 2.5816  \n",
      "\n",
      "Fold: 17  Epoch: 520  Training loss = 4.9544  Validation loss = 2.5814  \n",
      "\n",
      "Fold: 17  Epoch: 521  Training loss = 4.9540  Validation loss = 2.5812  \n",
      "\n",
      "Fold: 17  Epoch: 522  Training loss = 4.9536  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 17  Epoch: 523  Training loss = 4.9531  Validation loss = 2.5807  \n",
      "\n",
      "Fold: 17  Epoch: 524  Training loss = 4.9527  Validation loss = 2.5805  \n",
      "\n",
      "Fold: 17  Epoch: 525  Training loss = 4.9524  Validation loss = 2.5803  \n",
      "\n",
      "Fold: 17  Epoch: 526  Training loss = 4.9519  Validation loss = 2.5800  \n",
      "\n",
      "Fold: 17  Epoch: 527  Training loss = 4.9515  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 17  Epoch: 528  Training loss = 4.9511  Validation loss = 2.5797  \n",
      "\n",
      "Fold: 17  Epoch: 529  Training loss = 4.9506  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 17  Epoch: 530  Training loss = 4.9501  Validation loss = 2.5791  \n",
      "\n",
      "Fold: 17  Epoch: 531  Training loss = 4.9497  Validation loss = 2.5789  \n",
      "\n",
      "Fold: 17  Epoch: 532  Training loss = 4.9492  Validation loss = 2.5787  \n",
      "\n",
      "Fold: 17  Epoch: 533  Training loss = 4.9489  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 17  Epoch: 534  Training loss = 4.9484  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 17  Epoch: 535  Training loss = 4.9480  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 17  Epoch: 536  Training loss = 4.9476  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 17  Epoch: 537  Training loss = 4.9472  Validation loss = 2.5777  \n",
      "\n",
      "Fold: 17  Epoch: 538  Training loss = 4.9468  Validation loss = 2.5775  \n",
      "\n",
      "Fold: 17  Epoch: 539  Training loss = 4.9463  Validation loss = 2.5773  \n",
      "\n",
      "Fold: 17  Epoch: 540  Training loss = 4.9457  Validation loss = 2.5770  \n",
      "\n",
      "Fold: 17  Epoch: 541  Training loss = 4.9453  Validation loss = 2.5768  \n",
      "\n",
      "Fold: 17  Epoch: 542  Training loss = 4.9448  Validation loss = 2.5765  \n",
      "\n",
      "Fold: 17  Epoch: 543  Training loss = 4.9445  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 17  Epoch: 544  Training loss = 4.9440  Validation loss = 2.5762  \n",
      "\n",
      "Fold: 17  Epoch: 545  Training loss = 4.9436  Validation loss = 2.5759  \n",
      "\n",
      "Fold: 17  Epoch: 546  Training loss = 4.9431  Validation loss = 2.5757  \n",
      "\n",
      "Fold: 17  Epoch: 547  Training loss = 4.9427  Validation loss = 2.5755  \n",
      "\n",
      "Fold: 17  Epoch: 548  Training loss = 4.9423  Validation loss = 2.5752  \n",
      "\n",
      "Fold: 17  Epoch: 549  Training loss = 4.9419  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 17  Epoch: 550  Training loss = 4.9414  Validation loss = 2.5748  \n",
      "\n",
      "Fold: 17  Epoch: 551  Training loss = 4.9410  Validation loss = 2.5745  \n",
      "\n",
      "Fold: 17  Epoch: 552  Training loss = 4.9405  Validation loss = 2.5743  \n",
      "\n",
      "Fold: 17  Epoch: 553  Training loss = 4.9401  Validation loss = 2.5741  \n",
      "\n",
      "Fold: 17  Epoch: 554  Training loss = 4.9396  Validation loss = 2.5738  \n",
      "\n",
      "Fold: 17  Epoch: 555  Training loss = 4.9391  Validation loss = 2.5736  \n",
      "\n",
      "Fold: 17  Epoch: 556  Training loss = 4.9387  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 17  Epoch: 557  Training loss = 4.9382  Validation loss = 2.5731  \n",
      "\n",
      "Fold: 17  Epoch: 558  Training loss = 4.9378  Validation loss = 2.5729  \n",
      "\n",
      "Fold: 17  Epoch: 559  Training loss = 4.9374  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 17  Epoch: 560  Training loss = 4.9370  Validation loss = 2.5725  \n",
      "\n",
      "Fold: 17  Epoch: 561  Training loss = 4.9367  Validation loss = 2.5724  \n",
      "\n",
      "Fold: 17  Epoch: 562  Training loss = 4.9363  Validation loss = 2.5721  \n",
      "\n",
      "Fold: 17  Epoch: 563  Training loss = 4.9358  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 17  Epoch: 564  Training loss = 4.9354  Validation loss = 2.5717  \n",
      "\n",
      "Fold: 17  Epoch: 565  Training loss = 4.9350  Validation loss = 2.5715  \n",
      "\n",
      "Fold: 17  Epoch: 566  Training loss = 4.9345  Validation loss = 2.5713  \n",
      "\n",
      "Fold: 17  Epoch: 567  Training loss = 4.9341  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 17  Epoch: 568  Training loss = 4.9337  Validation loss = 2.5708  \n",
      "\n",
      "Fold: 17  Epoch: 569  Training loss = 4.9333  Validation loss = 2.5706  \n",
      "\n",
      "Fold: 17  Epoch: 570  Training loss = 4.9329  Validation loss = 2.5704  \n",
      "\n",
      "Fold: 17  Epoch: 571  Training loss = 4.9324  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 17  Epoch: 572  Training loss = 4.9320  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 17  Epoch: 573  Training loss = 4.9316  Validation loss = 2.5697  \n",
      "\n",
      "Fold: 17  Epoch: 574  Training loss = 4.9312  Validation loss = 2.5695  \n",
      "\n",
      "Fold: 17  Epoch: 575  Training loss = 4.9307  Validation loss = 2.5693  \n",
      "\n",
      "Fold: 17  Epoch: 576  Training loss = 4.9303  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 17  Epoch: 577  Training loss = 4.9299  Validation loss = 2.5689  \n",
      "\n",
      "Fold: 17  Epoch: 578  Training loss = 4.9293  Validation loss = 2.5686  \n",
      "\n",
      "Fold: 17  Epoch: 579  Training loss = 4.9290  Validation loss = 2.5684  \n",
      "\n",
      "Fold: 17  Epoch: 580  Training loss = 4.9287  Validation loss = 2.5683  \n",
      "\n",
      "Fold: 17  Epoch: 581  Training loss = 4.9282  Validation loss = 2.5681  \n",
      "\n",
      "Fold: 17  Epoch: 582  Training loss = 4.9278  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 17  Epoch: 583  Training loss = 4.9274  Validation loss = 2.5677  \n",
      "\n",
      "Fold: 17  Epoch: 584  Training loss = 4.9270  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 17  Epoch: 585  Training loss = 4.9266  Validation loss = 2.5673  \n",
      "\n",
      "Fold: 17  Epoch: 586  Training loss = 4.9261  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 17  Epoch: 587  Training loss = 4.9256  Validation loss = 2.5669  \n",
      "\n",
      "Fold: 17  Epoch: 588  Training loss = 4.9253  Validation loss = 2.5667  \n",
      "\n",
      "Fold: 17  Epoch: 589  Training loss = 4.9249  Validation loss = 2.5665  \n",
      "\n",
      "Fold: 17  Epoch: 590  Training loss = 4.9244  Validation loss = 2.5663  \n",
      "\n",
      "Fold: 17  Epoch: 591  Training loss = 4.9241  Validation loss = 2.5662  \n",
      "\n",
      "Fold: 17  Epoch: 592  Training loss = 4.9235  Validation loss = 2.5659  \n",
      "\n",
      "Fold: 17  Epoch: 593  Training loss = 4.9231  Validation loss = 2.5657  \n",
      "\n",
      "Fold: 17  Epoch: 594  Training loss = 4.9228  Validation loss = 2.5655  \n",
      "\n",
      "Fold: 17  Epoch: 595  Training loss = 4.9224  Validation loss = 2.5653  \n",
      "\n",
      "Fold: 17  Epoch: 596  Training loss = 4.9220  Validation loss = 2.5651  \n",
      "\n",
      "Fold: 17  Epoch: 597  Training loss = 4.9216  Validation loss = 2.5649  \n",
      "\n",
      "Fold: 17  Epoch: 598  Training loss = 4.9212  Validation loss = 2.5647  \n",
      "\n",
      "Fold: 17  Epoch: 599  Training loss = 4.9207  Validation loss = 2.5645  \n",
      "\n",
      "Fold: 17  Epoch: 600  Training loss = 4.9204  Validation loss = 2.5643  \n",
      "\n",
      "Fold: 17  Epoch: 601  Training loss = 4.9199  Validation loss = 2.5641  \n",
      "\n",
      "Fold: 17  Epoch: 602  Training loss = 4.9195  Validation loss = 2.5639  \n",
      "\n",
      "Fold: 17  Epoch: 603  Training loss = 4.9190  Validation loss = 2.5636  \n",
      "\n",
      "Fold: 17  Epoch: 604  Training loss = 4.9186  Validation loss = 2.5634  \n",
      "\n",
      "Fold: 17  Epoch: 605  Training loss = 4.9182  Validation loss = 2.5632  \n",
      "\n",
      "Fold: 17  Epoch: 606  Training loss = 4.9179  Validation loss = 2.5630  \n",
      "\n",
      "Fold: 17  Epoch: 607  Training loss = 4.9174  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 17  Epoch: 608  Training loss = 4.9170  Validation loss = 2.5626  \n",
      "\n",
      "Fold: 17  Epoch: 609  Training loss = 4.9165  Validation loss = 2.5625  \n",
      "\n",
      "Fold: 17  Epoch: 610  Training loss = 4.9162  Validation loss = 2.5623  \n",
      "\n",
      "Fold: 17  Epoch: 611  Training loss = 4.9158  Validation loss = 2.5621  \n",
      "\n",
      "Fold: 17  Epoch: 612  Training loss = 4.9153  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 17  Epoch: 613  Training loss = 4.9150  Validation loss = 2.5617  \n",
      "\n",
      "Fold: 17  Epoch: 614  Training loss = 4.9144  Validation loss = 2.5614  \n",
      "\n",
      "Fold: 17  Epoch: 615  Training loss = 4.9140  Validation loss = 2.5611  \n",
      "\n",
      "Fold: 17  Epoch: 616  Training loss = 4.9136  Validation loss = 2.5609  \n",
      "\n",
      "Fold: 17  Epoch: 617  Training loss = 4.9132  Validation loss = 2.5607  \n",
      "\n",
      "Fold: 17  Epoch: 618  Training loss = 4.9128  Validation loss = 2.5605  \n",
      "\n",
      "Fold: 17  Epoch: 619  Training loss = 4.9124  Validation loss = 2.5603  \n",
      "\n",
      "Fold: 17  Epoch: 620  Training loss = 4.9120  Validation loss = 2.5600  \n",
      "\n",
      "Fold: 17  Epoch: 621  Training loss = 4.9115  Validation loss = 2.5597  \n",
      "\n",
      "Fold: 17  Epoch: 622  Training loss = 4.9110  Validation loss = 2.5595  \n",
      "\n",
      "Fold: 17  Epoch: 623  Training loss = 4.9106  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 17  Epoch: 624  Training loss = 4.9101  Validation loss = 2.5591  \n",
      "\n",
      "Fold: 17  Epoch: 625  Training loss = 4.9097  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 17  Epoch: 626  Training loss = 4.9093  Validation loss = 2.5587  \n",
      "\n",
      "Fold: 17  Epoch: 627  Training loss = 4.9089  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 17  Epoch: 628  Training loss = 4.9085  Validation loss = 2.5583  \n",
      "\n",
      "Fold: 17  Epoch: 629  Training loss = 4.9081  Validation loss = 2.5582  \n",
      "\n",
      "Fold: 17  Epoch: 630  Training loss = 4.9076  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 17  Epoch: 631  Training loss = 4.9072  Validation loss = 2.5578  \n",
      "\n",
      "Fold: 17  Epoch: 632  Training loss = 4.9068  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 17  Epoch: 633  Training loss = 4.9064  Validation loss = 2.5574  \n",
      "\n",
      "Fold: 17  Epoch: 634  Training loss = 4.9060  Validation loss = 2.5572  \n",
      "\n",
      "Fold: 17  Epoch: 635  Training loss = 4.9056  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 17  Epoch: 636  Training loss = 4.9052  Validation loss = 2.5569  \n",
      "\n",
      "Fold: 17  Epoch: 637  Training loss = 4.9048  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 17  Epoch: 638  Training loss = 4.9044  Validation loss = 2.5565  \n",
      "\n",
      "Fold: 17  Epoch: 639  Training loss = 4.9040  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 17  Epoch: 640  Training loss = 4.9035  Validation loss = 2.5562  \n",
      "\n",
      "Fold: 17  Epoch: 641  Training loss = 4.9031  Validation loss = 2.5560  \n",
      "\n",
      "Fold: 17  Epoch: 642  Training loss = 4.9027  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 17  Epoch: 643  Training loss = 4.9023  Validation loss = 2.5556  \n",
      "\n",
      "Fold: 17  Epoch: 644  Training loss = 4.9020  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 17  Epoch: 645  Training loss = 4.9015  Validation loss = 2.5552  \n",
      "\n",
      "Fold: 17  Epoch: 646  Training loss = 4.9011  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 17  Epoch: 647  Training loss = 4.9006  Validation loss = 2.5548  \n",
      "\n",
      "Fold: 17  Epoch: 648  Training loss = 4.9003  Validation loss = 2.5546  \n",
      "\n",
      "Fold: 17  Epoch: 649  Training loss = 4.8998  Validation loss = 2.5544  \n",
      "\n",
      "Fold: 17  Epoch: 650  Training loss = 4.8994  Validation loss = 2.5542  \n",
      "\n",
      "Fold: 17  Epoch: 651  Training loss = 4.8989  Validation loss = 2.5540  \n",
      "\n",
      "Fold: 17  Epoch: 652  Training loss = 4.8985  Validation loss = 2.5538  \n",
      "\n",
      "Fold: 17  Epoch: 653  Training loss = 4.8981  Validation loss = 2.5536  \n",
      "\n",
      "Fold: 17  Epoch: 654  Training loss = 4.8976  Validation loss = 2.5534  \n",
      "\n",
      "Fold: 17  Epoch: 655  Training loss = 4.8972  Validation loss = 2.5533  \n",
      "\n",
      "Fold: 17  Epoch: 656  Training loss = 4.8967  Validation loss = 2.5530  \n",
      "\n",
      "Fold: 17  Epoch: 657  Training loss = 4.8963  Validation loss = 2.5528  \n",
      "\n",
      "Fold: 17  Epoch: 658  Training loss = 4.8960  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 17  Epoch: 659  Training loss = 4.8956  Validation loss = 2.5525  \n",
      "\n",
      "Fold: 17  Epoch: 660  Training loss = 4.8952  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 17  Epoch: 661  Training loss = 4.8949  Validation loss = 2.5521  \n",
      "\n",
      "Fold: 17  Epoch: 662  Training loss = 4.8944  Validation loss = 2.5519  \n",
      "\n",
      "Fold: 17  Epoch: 663  Training loss = 4.8940  Validation loss = 2.5517  \n",
      "\n",
      "Fold: 17  Epoch: 664  Training loss = 4.8936  Validation loss = 2.5515  \n",
      "\n",
      "Fold: 17  Epoch: 665  Training loss = 4.8932  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 17  Epoch: 666  Training loss = 4.8929  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 17  Epoch: 667  Training loss = 4.8925  Validation loss = 2.5510  \n",
      "\n",
      "Fold: 17  Epoch: 668  Training loss = 4.8920  Validation loss = 2.5508  \n",
      "\n",
      "Fold: 17  Epoch: 669  Training loss = 4.8915  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 17  Epoch: 670  Training loss = 4.8911  Validation loss = 2.5504  \n",
      "\n",
      "Fold: 17  Epoch: 671  Training loss = 4.8907  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 17  Epoch: 672  Training loss = 4.8903  Validation loss = 2.5500  \n",
      "\n",
      "Fold: 17  Epoch: 673  Training loss = 4.8900  Validation loss = 2.5499  \n",
      "\n",
      "Fold: 17  Epoch: 674  Training loss = 4.8896  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 17  Epoch: 675  Training loss = 4.8891  Validation loss = 2.5495  \n",
      "\n",
      "Fold: 17  Epoch: 676  Training loss = 4.8887  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 17  Epoch: 677  Training loss = 4.8882  Validation loss = 2.5491  \n",
      "\n",
      "Fold: 17  Epoch: 678  Training loss = 4.8877  Validation loss = 2.5489  \n",
      "\n",
      "Fold: 17  Epoch: 679  Training loss = 4.8872  Validation loss = 2.5487  \n",
      "\n",
      "Fold: 17  Epoch: 680  Training loss = 4.8868  Validation loss = 2.5485  \n",
      "\n",
      "Fold: 17  Epoch: 681  Training loss = 4.8865  Validation loss = 2.5483  \n",
      "\n",
      "Fold: 17  Epoch: 682  Training loss = 4.8861  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 17  Epoch: 683  Training loss = 4.8857  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 17  Epoch: 684  Training loss = 4.8854  Validation loss = 2.5478  \n",
      "\n",
      "Fold: 17  Epoch: 685  Training loss = 4.8848  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 17  Epoch: 686  Training loss = 4.8844  Validation loss = 2.5473  \n",
      "\n",
      "Fold: 17  Epoch: 687  Training loss = 4.8839  Validation loss = 2.5472  \n",
      "\n",
      "Fold: 17  Epoch: 688  Training loss = 4.8836  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 17  Epoch: 689  Training loss = 4.8832  Validation loss = 2.5468  \n",
      "\n",
      "Fold: 17  Epoch: 690  Training loss = 4.8827  Validation loss = 2.5465  \n",
      "\n",
      "Fold: 17  Epoch: 691  Training loss = 4.8822  Validation loss = 2.5463  \n",
      "\n",
      "Fold: 17  Epoch: 692  Training loss = 4.8817  Validation loss = 2.5461  \n",
      "\n",
      "Fold: 17  Epoch: 693  Training loss = 4.8812  Validation loss = 2.5460  \n",
      "\n",
      "Fold: 17  Epoch: 694  Training loss = 4.8807  Validation loss = 2.5457  \n",
      "\n",
      "Fold: 17  Epoch: 695  Training loss = 4.8803  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 17  Epoch: 696  Training loss = 4.8798  Validation loss = 2.5453  \n",
      "\n",
      "Fold: 17  Epoch: 697  Training loss = 4.8794  Validation loss = 2.5451  \n",
      "\n",
      "Fold: 17  Epoch: 698  Training loss = 4.8790  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 17  Epoch: 699  Training loss = 4.8786  Validation loss = 2.5448  \n",
      "\n",
      "Fold: 17  Epoch: 700  Training loss = 4.8782  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 17  Epoch: 701  Training loss = 4.8777  Validation loss = 2.5445  \n",
      "\n",
      "Fold: 17  Epoch: 702  Training loss = 4.8772  Validation loss = 2.5442  \n",
      "\n",
      "Fold: 17  Epoch: 703  Training loss = 4.8768  Validation loss = 2.5441  \n",
      "\n",
      "Fold: 17  Epoch: 704  Training loss = 4.8764  Validation loss = 2.5439  \n",
      "\n",
      "Fold: 17  Epoch: 705  Training loss = 4.8759  Validation loss = 2.5436  \n",
      "\n",
      "Fold: 17  Epoch: 706  Training loss = 4.8754  Validation loss = 2.5434  \n",
      "\n",
      "Fold: 17  Epoch: 707  Training loss = 4.8750  Validation loss = 2.5432  \n",
      "\n",
      "Fold: 17  Epoch: 708  Training loss = 4.8746  Validation loss = 2.5430  \n",
      "\n",
      "Fold: 17  Epoch: 709  Training loss = 4.8741  Validation loss = 2.5428  \n",
      "\n",
      "Fold: 17  Epoch: 710  Training loss = 4.8737  Validation loss = 2.5426  \n",
      "\n",
      "Fold: 17  Epoch: 711  Training loss = 4.8733  Validation loss = 2.5424  \n",
      "\n",
      "Fold: 17  Epoch: 712  Training loss = 4.8729  Validation loss = 2.5423  \n",
      "\n",
      "Fold: 17  Epoch: 713  Training loss = 4.8726  Validation loss = 2.5421  \n",
      "\n",
      "Fold: 17  Epoch: 714  Training loss = 4.8723  Validation loss = 2.5419  \n",
      "\n",
      "Fold: 17  Epoch: 715  Training loss = 4.8718  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 17  Epoch: 716  Training loss = 4.8715  Validation loss = 2.5416  \n",
      "\n",
      "Fold: 17  Epoch: 717  Training loss = 4.8710  Validation loss = 2.5415  \n",
      "\n",
      "Fold: 17  Epoch: 718  Training loss = 4.8705  Validation loss = 2.5413  \n",
      "\n",
      "Fold: 17  Epoch: 719  Training loss = 4.8701  Validation loss = 2.5411  \n",
      "\n",
      "Fold: 17  Epoch: 720  Training loss = 4.8697  Validation loss = 2.5409  \n",
      "\n",
      "Fold: 17  Epoch: 721  Training loss = 4.8693  Validation loss = 2.5408  \n",
      "\n",
      "Fold: 17  Epoch: 722  Training loss = 4.8689  Validation loss = 2.5406  \n",
      "\n",
      "Fold: 17  Epoch: 723  Training loss = 4.8685  Validation loss = 2.5404  \n",
      "\n",
      "Fold: 17  Epoch: 724  Training loss = 4.8680  Validation loss = 2.5402  \n",
      "\n",
      "Fold: 17  Epoch: 725  Training loss = 4.8675  Validation loss = 2.5400  \n",
      "\n",
      "Fold: 17  Epoch: 726  Training loss = 4.8670  Validation loss = 2.5399  \n",
      "\n",
      "Fold: 17  Epoch: 727  Training loss = 4.8666  Validation loss = 2.5397  \n",
      "\n",
      "Fold: 17  Epoch: 728  Training loss = 4.8661  Validation loss = 2.5395  \n",
      "\n",
      "Fold: 17  Epoch: 729  Training loss = 4.8657  Validation loss = 2.5393  \n",
      "\n",
      "Fold: 17  Epoch: 730  Training loss = 4.8652  Validation loss = 2.5391  \n",
      "\n",
      "Fold: 17  Epoch: 731  Training loss = 4.8647  Validation loss = 2.5389  \n",
      "\n",
      "Fold: 17  Epoch: 732  Training loss = 4.8643  Validation loss = 2.5387  \n",
      "\n",
      "Fold: 17  Epoch: 733  Training loss = 4.8639  Validation loss = 2.5385  \n",
      "\n",
      "Fold: 17  Epoch: 734  Training loss = 4.8636  Validation loss = 2.5384  \n",
      "\n",
      "Fold: 17  Epoch: 735  Training loss = 4.8632  Validation loss = 2.5382  \n",
      "\n",
      "Fold: 17  Epoch: 736  Training loss = 4.8627  Validation loss = 2.5380  \n",
      "\n",
      "Fold: 17  Epoch: 737  Training loss = 4.8624  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 17  Epoch: 738  Training loss = 4.8619  Validation loss = 2.5376  \n",
      "\n",
      "Fold: 17  Epoch: 739  Training loss = 4.8614  Validation loss = 2.5374  \n",
      "\n",
      "Fold: 17  Epoch: 740  Training loss = 4.8609  Validation loss = 2.5372  \n",
      "\n",
      "Fold: 17  Epoch: 741  Training loss = 4.8605  Validation loss = 2.5371  \n",
      "\n",
      "Fold: 17  Epoch: 742  Training loss = 4.8600  Validation loss = 2.5369  \n",
      "\n",
      "Fold: 17  Epoch: 743  Training loss = 4.8596  Validation loss = 2.5367  \n",
      "\n",
      "Fold: 17  Epoch: 744  Training loss = 4.8592  Validation loss = 2.5365  \n",
      "\n",
      "Fold: 17  Epoch: 745  Training loss = 4.8587  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 17  Epoch: 746  Training loss = 4.8583  Validation loss = 2.5361  \n",
      "\n",
      "Fold: 17  Epoch: 747  Training loss = 4.8578  Validation loss = 2.5359  \n",
      "\n",
      "Fold: 17  Epoch: 748  Training loss = 4.8573  Validation loss = 2.5357  \n",
      "\n",
      "Fold: 17  Epoch: 749  Training loss = 4.8570  Validation loss = 2.5356  \n",
      "\n",
      "Fold: 17  Epoch: 750  Training loss = 4.8567  Validation loss = 2.5354  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 750  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 4.8947  Validation loss = 1.2734  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 4.8942  Validation loss = 1.2730  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 4.8937  Validation loss = 1.2727  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 4.8933  Validation loss = 1.2724  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 4.8929  Validation loss = 1.2721  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 4.8925  Validation loss = 1.2718  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 4.8920  Validation loss = 1.2715  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 4.8916  Validation loss = 1.2712  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 4.8912  Validation loss = 1.2709  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 4.8907  Validation loss = 1.2706  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 4.8902  Validation loss = 1.2702  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 4.8898  Validation loss = 1.2698  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 4.8893  Validation loss = 1.2695  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 4.8889  Validation loss = 1.2692  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 4.8883  Validation loss = 1.2688  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 4.8879  Validation loss = 1.2685  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 4.8873  Validation loss = 1.2681  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 4.8868  Validation loss = 1.2677  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 4.8864  Validation loss = 1.2674  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 4.8859  Validation loss = 1.2671  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 4.8855  Validation loss = 1.2668  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 4.8850  Validation loss = 1.2665  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 4.8845  Validation loss = 1.2661  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 4.8841  Validation loss = 1.2657  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 4.8836  Validation loss = 1.2654  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 4.8832  Validation loss = 1.2651  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 4.8828  Validation loss = 1.2649  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 4.8824  Validation loss = 1.2646  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 4.8819  Validation loss = 1.2642  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 4.8815  Validation loss = 1.2639  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 4.8811  Validation loss = 1.2637  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 4.8807  Validation loss = 1.2634  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 4.8802  Validation loss = 1.2631  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 4.8798  Validation loss = 1.2628  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 4.8793  Validation loss = 1.2626  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 4.8790  Validation loss = 1.2624  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 4.8785  Validation loss = 1.2620  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 4.8780  Validation loss = 1.2616  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 4.8776  Validation loss = 1.2614  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 4.8770  Validation loss = 1.2609  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 4.8766  Validation loss = 1.2606  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 4.8761  Validation loss = 1.2603  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 4.8756  Validation loss = 1.2599  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 4.8752  Validation loss = 1.2596  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 4.8747  Validation loss = 1.2593  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 4.8744  Validation loss = 1.2590  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 4.8739  Validation loss = 1.2587  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 4.8734  Validation loss = 1.2584  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 4.8729  Validation loss = 1.2580  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 4.8725  Validation loss = 1.2577  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 4.8721  Validation loss = 1.2574  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 4.8717  Validation loss = 1.2571  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 4.8711  Validation loss = 1.2567  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 4.8706  Validation loss = 1.2564  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 4.8703  Validation loss = 1.2561  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 4.8698  Validation loss = 1.2558  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 4.8693  Validation loss = 1.2554  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 4.8689  Validation loss = 1.2551  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 4.8686  Validation loss = 1.2549  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 4.8682  Validation loss = 1.2546  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 4.8678  Validation loss = 1.2543  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 4.8673  Validation loss = 1.2539  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 4.8668  Validation loss = 1.2536  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 4.8665  Validation loss = 1.2533  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 4.8660  Validation loss = 1.2530  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 4.8656  Validation loss = 1.2527  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 4.8652  Validation loss = 1.2524  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 4.8648  Validation loss = 1.2521  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 4.8644  Validation loss = 1.2519  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 4.8640  Validation loss = 1.2516  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 4.8635  Validation loss = 1.2512  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 4.8631  Validation loss = 1.2509  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 4.8627  Validation loss = 1.2506  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 4.8623  Validation loss = 1.2504  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 4.8619  Validation loss = 1.2501  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 4.8614  Validation loss = 1.2498  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 4.8610  Validation loss = 1.2495  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 4.8606  Validation loss = 1.2493  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 4.8601  Validation loss = 1.2489  \n",
      "\n",
      "Fold: 18  Epoch: 80  Training loss = 4.8598  Validation loss = 1.2487  \n",
      "\n",
      "Fold: 18  Epoch: 81  Training loss = 4.8594  Validation loss = 1.2484  \n",
      "\n",
      "Fold: 18  Epoch: 82  Training loss = 4.8590  Validation loss = 1.2481  \n",
      "\n",
      "Fold: 18  Epoch: 83  Training loss = 4.8587  Validation loss = 1.2479  \n",
      "\n",
      "Fold: 18  Epoch: 84  Training loss = 4.8582  Validation loss = 1.2476  \n",
      "\n",
      "Fold: 18  Epoch: 85  Training loss = 4.8578  Validation loss = 1.2472  \n",
      "\n",
      "Fold: 18  Epoch: 86  Training loss = 4.8574  Validation loss = 1.2470  \n",
      "\n",
      "Fold: 18  Epoch: 87  Training loss = 4.8571  Validation loss = 1.2468  \n",
      "\n",
      "Fold: 18  Epoch: 88  Training loss = 4.8567  Validation loss = 1.2466  \n",
      "\n",
      "Fold: 18  Epoch: 89  Training loss = 4.8562  Validation loss = 1.2462  \n",
      "\n",
      "Fold: 18  Epoch: 90  Training loss = 4.8559  Validation loss = 1.2459  \n",
      "\n",
      "Fold: 18  Epoch: 91  Training loss = 4.8553  Validation loss = 1.2455  \n",
      "\n",
      "Fold: 18  Epoch: 92  Training loss = 4.8550  Validation loss = 1.2453  \n",
      "\n",
      "Fold: 18  Epoch: 93  Training loss = 4.8546  Validation loss = 1.2450  \n",
      "\n",
      "Fold: 18  Epoch: 94  Training loss = 4.8542  Validation loss = 1.2447  \n",
      "\n",
      "Fold: 18  Epoch: 95  Training loss = 4.8538  Validation loss = 1.2445  \n",
      "\n",
      "Fold: 18  Epoch: 96  Training loss = 4.8534  Validation loss = 1.2442  \n",
      "\n",
      "Fold: 18  Epoch: 97  Training loss = 4.8530  Validation loss = 1.2439  \n",
      "\n",
      "Fold: 18  Epoch: 98  Training loss = 4.8526  Validation loss = 1.2435  \n",
      "\n",
      "Fold: 18  Epoch: 99  Training loss = 4.8522  Validation loss = 1.2433  \n",
      "\n",
      "Fold: 18  Epoch: 100  Training loss = 4.8518  Validation loss = 1.2430  \n",
      "\n",
      "Fold: 18  Epoch: 101  Training loss = 4.8514  Validation loss = 1.2427  \n",
      "\n",
      "Fold: 18  Epoch: 102  Training loss = 4.8510  Validation loss = 1.2424  \n",
      "\n",
      "Fold: 18  Epoch: 103  Training loss = 4.8506  Validation loss = 1.2422  \n",
      "\n",
      "Fold: 18  Epoch: 104  Training loss = 4.8501  Validation loss = 1.2419  \n",
      "\n",
      "Fold: 18  Epoch: 105  Training loss = 4.8497  Validation loss = 1.2416  \n",
      "\n",
      "Fold: 18  Epoch: 106  Training loss = 4.8493  Validation loss = 1.2412  \n",
      "\n",
      "Fold: 18  Epoch: 107  Training loss = 4.8488  Validation loss = 1.2409  \n",
      "\n",
      "Fold: 18  Epoch: 108  Training loss = 4.8483  Validation loss = 1.2406  \n",
      "\n",
      "Fold: 18  Epoch: 109  Training loss = 4.8477  Validation loss = 1.2401  \n",
      "\n",
      "Fold: 18  Epoch: 110  Training loss = 4.8473  Validation loss = 1.2399  \n",
      "\n",
      "Fold: 18  Epoch: 111  Training loss = 4.8469  Validation loss = 1.2396  \n",
      "\n",
      "Fold: 18  Epoch: 112  Training loss = 4.8466  Validation loss = 1.2394  \n",
      "\n",
      "Fold: 18  Epoch: 113  Training loss = 4.8462  Validation loss = 1.2391  \n",
      "\n",
      "Fold: 18  Epoch: 114  Training loss = 4.8458  Validation loss = 1.2388  \n",
      "\n",
      "Fold: 18  Epoch: 115  Training loss = 4.8454  Validation loss = 1.2386  \n",
      "\n",
      "Fold: 18  Epoch: 116  Training loss = 4.8450  Validation loss = 1.2383  \n",
      "\n",
      "Fold: 18  Epoch: 117  Training loss = 4.8446  Validation loss = 1.2380  \n",
      "\n",
      "Fold: 18  Epoch: 118  Training loss = 4.8442  Validation loss = 1.2377  \n",
      "\n",
      "Fold: 18  Epoch: 119  Training loss = 4.8437  Validation loss = 1.2374  \n",
      "\n",
      "Fold: 18  Epoch: 120  Training loss = 4.8433  Validation loss = 1.2371  \n",
      "\n",
      "Fold: 18  Epoch: 121  Training loss = 4.8428  Validation loss = 1.2368  \n",
      "\n",
      "Fold: 18  Epoch: 122  Training loss = 4.8424  Validation loss = 1.2365  \n",
      "\n",
      "Fold: 18  Epoch: 123  Training loss = 4.8419  Validation loss = 1.2362  \n",
      "\n",
      "Fold: 18  Epoch: 124  Training loss = 4.8415  Validation loss = 1.2358  \n",
      "\n",
      "Fold: 18  Epoch: 125  Training loss = 4.8412  Validation loss = 1.2356  \n",
      "\n",
      "Fold: 18  Epoch: 126  Training loss = 4.8408  Validation loss = 1.2354  \n",
      "\n",
      "Fold: 18  Epoch: 127  Training loss = 4.8404  Validation loss = 1.2351  \n",
      "\n",
      "Fold: 18  Epoch: 128  Training loss = 4.8400  Validation loss = 1.2348  \n",
      "\n",
      "Fold: 18  Epoch: 129  Training loss = 4.8396  Validation loss = 1.2346  \n",
      "\n",
      "Fold: 18  Epoch: 130  Training loss = 4.8392  Validation loss = 1.2343  \n",
      "\n",
      "Fold: 18  Epoch: 131  Training loss = 4.8387  Validation loss = 1.2339  \n",
      "\n",
      "Fold: 18  Epoch: 132  Training loss = 4.8383  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 18  Epoch: 133  Training loss = 4.8379  Validation loss = 1.2334  \n",
      "\n",
      "Fold: 18  Epoch: 134  Training loss = 4.8375  Validation loss = 1.2332  \n",
      "\n",
      "Fold: 18  Epoch: 135  Training loss = 4.8372  Validation loss = 1.2330  \n",
      "\n",
      "Fold: 18  Epoch: 136  Training loss = 4.8367  Validation loss = 1.2327  \n",
      "\n",
      "Fold: 18  Epoch: 137  Training loss = 4.8364  Validation loss = 1.2324  \n",
      "\n",
      "Fold: 18  Epoch: 138  Training loss = 4.8360  Validation loss = 1.2322  \n",
      "\n",
      "Fold: 18  Epoch: 139  Training loss = 4.8356  Validation loss = 1.2319  \n",
      "\n",
      "Fold: 18  Epoch: 140  Training loss = 4.8351  Validation loss = 1.2316  \n",
      "\n",
      "Fold: 18  Epoch: 141  Training loss = 4.8348  Validation loss = 1.2314  \n",
      "\n",
      "Fold: 18  Epoch: 142  Training loss = 4.8344  Validation loss = 1.2311  \n",
      "\n",
      "Fold: 18  Epoch: 143  Training loss = 4.8339  Validation loss = 1.2308  \n",
      "\n",
      "Fold: 18  Epoch: 144  Training loss = 4.8335  Validation loss = 1.2305  \n",
      "\n",
      "Fold: 18  Epoch: 145  Training loss = 4.8330  Validation loss = 1.2300  \n",
      "\n",
      "Fold: 18  Epoch: 146  Training loss = 4.8325  Validation loss = 1.2296  \n",
      "\n",
      "Fold: 18  Epoch: 147  Training loss = 4.8320  Validation loss = 1.2293  \n",
      "\n",
      "Fold: 18  Epoch: 148  Training loss = 4.8316  Validation loss = 1.2291  \n",
      "\n",
      "Fold: 18  Epoch: 149  Training loss = 4.8312  Validation loss = 1.2287  \n",
      "\n",
      "Fold: 18  Epoch: 150  Training loss = 4.8307  Validation loss = 1.2284  \n",
      "\n",
      "Fold: 18  Epoch: 151  Training loss = 4.8303  Validation loss = 1.2282  \n",
      "\n",
      "Fold: 18  Epoch: 152  Training loss = 4.8299  Validation loss = 1.2279  \n",
      "\n",
      "Fold: 18  Epoch: 153  Training loss = 4.8295  Validation loss = 1.2277  \n",
      "\n",
      "Fold: 18  Epoch: 154  Training loss = 4.8289  Validation loss = 1.2272  \n",
      "\n",
      "Fold: 18  Epoch: 155  Training loss = 4.8284  Validation loss = 1.2269  \n",
      "\n",
      "Fold: 18  Epoch: 156  Training loss = 4.8280  Validation loss = 1.2266  \n",
      "\n",
      "Fold: 18  Epoch: 157  Training loss = 4.8277  Validation loss = 1.2264  \n",
      "\n",
      "Fold: 18  Epoch: 158  Training loss = 4.8272  Validation loss = 1.2261  \n",
      "\n",
      "Fold: 18  Epoch: 159  Training loss = 4.8268  Validation loss = 1.2259  \n",
      "\n",
      "Fold: 18  Epoch: 160  Training loss = 4.8264  Validation loss = 1.2255  \n",
      "\n",
      "Fold: 18  Epoch: 161  Training loss = 4.8260  Validation loss = 1.2253  \n",
      "\n",
      "Fold: 18  Epoch: 162  Training loss = 4.8256  Validation loss = 1.2250  \n",
      "\n",
      "Fold: 18  Epoch: 163  Training loss = 4.8252  Validation loss = 1.2246  \n",
      "\n",
      "Fold: 18  Epoch: 164  Training loss = 4.8248  Validation loss = 1.2244  \n",
      "\n",
      "Fold: 18  Epoch: 165  Training loss = 4.8244  Validation loss = 1.2241  \n",
      "\n",
      "Fold: 18  Epoch: 166  Training loss = 4.8241  Validation loss = 1.2239  \n",
      "\n",
      "Fold: 18  Epoch: 167  Training loss = 4.8236  Validation loss = 1.2236  \n",
      "\n",
      "Fold: 18  Epoch: 168  Training loss = 4.8232  Validation loss = 1.2233  \n",
      "\n",
      "Fold: 18  Epoch: 169  Training loss = 4.8228  Validation loss = 1.2231  \n",
      "\n",
      "Fold: 18  Epoch: 170  Training loss = 4.8225  Validation loss = 1.2228  \n",
      "\n",
      "Fold: 18  Epoch: 171  Training loss = 4.8221  Validation loss = 1.2225  \n",
      "\n",
      "Fold: 18  Epoch: 172  Training loss = 4.8217  Validation loss = 1.2222  \n",
      "\n",
      "Fold: 18  Epoch: 173  Training loss = 4.8213  Validation loss = 1.2220  \n",
      "\n",
      "Fold: 18  Epoch: 174  Training loss = 4.8209  Validation loss = 1.2218  \n",
      "\n",
      "Fold: 18  Epoch: 175  Training loss = 4.8204  Validation loss = 1.2215  \n",
      "\n",
      "Fold: 18  Epoch: 176  Training loss = 4.8199  Validation loss = 1.2211  \n",
      "\n",
      "Fold: 18  Epoch: 177  Training loss = 4.8194  Validation loss = 1.2207  \n",
      "\n",
      "Fold: 18  Epoch: 178  Training loss = 4.8190  Validation loss = 1.2204  \n",
      "\n",
      "Fold: 18  Epoch: 179  Training loss = 4.8186  Validation loss = 1.2201  \n",
      "\n",
      "Fold: 18  Epoch: 180  Training loss = 4.8182  Validation loss = 1.2198  \n",
      "\n",
      "Fold: 18  Epoch: 181  Training loss = 4.8178  Validation loss = 1.2196  \n",
      "\n",
      "Fold: 18  Epoch: 182  Training loss = 4.8173  Validation loss = 1.2192  \n",
      "\n",
      "Fold: 18  Epoch: 183  Training loss = 4.8170  Validation loss = 1.2190  \n",
      "\n",
      "Fold: 18  Epoch: 184  Training loss = 4.8166  Validation loss = 1.2187  \n",
      "\n",
      "Fold: 18  Epoch: 185  Training loss = 4.8161  Validation loss = 1.2185  \n",
      "\n",
      "Fold: 18  Epoch: 186  Training loss = 4.8157  Validation loss = 1.2182  \n",
      "\n",
      "Fold: 18  Epoch: 187  Training loss = 4.8154  Validation loss = 1.2180  \n",
      "\n",
      "Fold: 18  Epoch: 188  Training loss = 4.8149  Validation loss = 1.2177  \n",
      "\n",
      "Fold: 18  Epoch: 189  Training loss = 4.8146  Validation loss = 1.2174  \n",
      "\n",
      "Fold: 18  Epoch: 190  Training loss = 4.8141  Validation loss = 1.2171  \n",
      "\n",
      "Fold: 18  Epoch: 191  Training loss = 4.8137  Validation loss = 1.2168  \n",
      "\n",
      "Fold: 18  Epoch: 192  Training loss = 4.8134  Validation loss = 1.2166  \n",
      "\n",
      "Fold: 18  Epoch: 193  Training loss = 4.8129  Validation loss = 1.2163  \n",
      "\n",
      "Fold: 18  Epoch: 194  Training loss = 4.8125  Validation loss = 1.2161  \n",
      "\n",
      "Fold: 18  Epoch: 195  Training loss = 4.8121  Validation loss = 1.2157  \n",
      "\n",
      "Fold: 18  Epoch: 196  Training loss = 4.8118  Validation loss = 1.2155  \n",
      "\n",
      "Fold: 18  Epoch: 197  Training loss = 4.8113  Validation loss = 1.2152  \n",
      "\n",
      "Fold: 18  Epoch: 198  Training loss = 4.8109  Validation loss = 1.2149  \n",
      "\n",
      "Fold: 18  Epoch: 199  Training loss = 4.8105  Validation loss = 1.2147  \n",
      "\n",
      "Fold: 18  Epoch: 200  Training loss = 4.8101  Validation loss = 1.2144  \n",
      "\n",
      "Fold: 18  Epoch: 201  Training loss = 4.8096  Validation loss = 1.2141  \n",
      "\n",
      "Fold: 18  Epoch: 202  Training loss = 4.8092  Validation loss = 1.2139  \n",
      "\n",
      "Fold: 18  Epoch: 203  Training loss = 4.8089  Validation loss = 1.2136  \n",
      "\n",
      "Fold: 18  Epoch: 204  Training loss = 4.8086  Validation loss = 1.2135  \n",
      "\n",
      "Fold: 18  Epoch: 205  Training loss = 4.8081  Validation loss = 1.2131  \n",
      "\n",
      "Fold: 18  Epoch: 206  Training loss = 4.8077  Validation loss = 1.2129  \n",
      "\n",
      "Fold: 18  Epoch: 207  Training loss = 4.8072  Validation loss = 1.2126  \n",
      "\n",
      "Fold: 18  Epoch: 208  Training loss = 4.8068  Validation loss = 1.2124  \n",
      "\n",
      "Fold: 18  Epoch: 209  Training loss = 4.8065  Validation loss = 1.2121  \n",
      "\n",
      "Fold: 18  Epoch: 210  Training loss = 4.8061  Validation loss = 1.2118  \n",
      "\n",
      "Fold: 18  Epoch: 211  Training loss = 4.8057  Validation loss = 1.2116  \n",
      "\n",
      "Fold: 18  Epoch: 212  Training loss = 4.8053  Validation loss = 1.2114  \n",
      "\n",
      "Fold: 18  Epoch: 213  Training loss = 4.8049  Validation loss = 1.2110  \n",
      "\n",
      "Fold: 18  Epoch: 214  Training loss = 4.8045  Validation loss = 1.2108  \n",
      "\n",
      "Fold: 18  Epoch: 215  Training loss = 4.8041  Validation loss = 1.2105  \n",
      "\n",
      "Fold: 18  Epoch: 216  Training loss = 4.8037  Validation loss = 1.2102  \n",
      "\n",
      "Fold: 18  Epoch: 217  Training loss = 4.8033  Validation loss = 1.2100  \n",
      "\n",
      "Fold: 18  Epoch: 218  Training loss = 4.8030  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 18  Epoch: 219  Training loss = 4.8026  Validation loss = 1.2095  \n",
      "\n",
      "Fold: 18  Epoch: 220  Training loss = 4.8021  Validation loss = 1.2092  \n",
      "\n",
      "Fold: 18  Epoch: 221  Training loss = 4.8018  Validation loss = 1.2090  \n",
      "\n",
      "Fold: 18  Epoch: 222  Training loss = 4.8014  Validation loss = 1.2087  \n",
      "\n",
      "Fold: 18  Epoch: 223  Training loss = 4.8010  Validation loss = 1.2084  \n",
      "\n",
      "Fold: 18  Epoch: 224  Training loss = 4.8005  Validation loss = 1.2081  \n",
      "\n",
      "Fold: 18  Epoch: 225  Training loss = 4.8002  Validation loss = 1.2079  \n",
      "\n",
      "Fold: 18  Epoch: 226  Training loss = 4.7998  Validation loss = 1.2077  \n",
      "\n",
      "Fold: 18  Epoch: 227  Training loss = 4.7994  Validation loss = 1.2074  \n",
      "\n",
      "Fold: 18  Epoch: 228  Training loss = 4.7989  Validation loss = 1.2072  \n",
      "\n",
      "Fold: 18  Epoch: 229  Training loss = 4.7985  Validation loss = 1.2069  \n",
      "\n",
      "Fold: 18  Epoch: 230  Training loss = 4.7981  Validation loss = 1.2066  \n",
      "\n",
      "Fold: 18  Epoch: 231  Training loss = 4.7977  Validation loss = 1.2064  \n",
      "\n",
      "Fold: 18  Epoch: 232  Training loss = 4.7974  Validation loss = 1.2062  \n",
      "\n",
      "Fold: 18  Epoch: 233  Training loss = 4.7970  Validation loss = 1.2060  \n",
      "\n",
      "Fold: 18  Epoch: 234  Training loss = 4.7966  Validation loss = 1.2058  \n",
      "\n",
      "Fold: 18  Epoch: 235  Training loss = 4.7963  Validation loss = 1.2056  \n",
      "\n",
      "Fold: 18  Epoch: 236  Training loss = 4.7959  Validation loss = 1.2053  \n",
      "\n",
      "Fold: 18  Epoch: 237  Training loss = 4.7954  Validation loss = 1.2050  \n",
      "\n",
      "Fold: 18  Epoch: 238  Training loss = 4.7950  Validation loss = 1.2048  \n",
      "\n",
      "Fold: 18  Epoch: 239  Training loss = 4.7946  Validation loss = 1.2046  \n",
      "\n",
      "Fold: 18  Epoch: 240  Training loss = 4.7942  Validation loss = 1.2043  \n",
      "\n",
      "Fold: 18  Epoch: 241  Training loss = 4.7939  Validation loss = 1.2041  \n",
      "\n",
      "Fold: 18  Epoch: 242  Training loss = 4.7935  Validation loss = 1.2039  \n",
      "\n",
      "Fold: 18  Epoch: 243  Training loss = 4.7930  Validation loss = 1.2036  \n",
      "\n",
      "Fold: 18  Epoch: 244  Training loss = 4.7926  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 18  Epoch: 245  Training loss = 4.7922  Validation loss = 1.2030  \n",
      "\n",
      "Fold: 18  Epoch: 246  Training loss = 4.7917  Validation loss = 1.2028  \n",
      "\n",
      "Fold: 18  Epoch: 247  Training loss = 4.7913  Validation loss = 1.2025  \n",
      "\n",
      "Fold: 18  Epoch: 248  Training loss = 4.7910  Validation loss = 1.2022  \n",
      "\n",
      "Fold: 18  Epoch: 249  Training loss = 4.7906  Validation loss = 1.2020  \n",
      "\n",
      "Fold: 18  Epoch: 250  Training loss = 4.7901  Validation loss = 1.2017  \n",
      "\n",
      "Fold: 18  Epoch: 251  Training loss = 4.7898  Validation loss = 1.2015  \n",
      "\n",
      "Fold: 18  Epoch: 252  Training loss = 4.7894  Validation loss = 1.2013  \n",
      "\n",
      "Fold: 18  Epoch: 253  Training loss = 4.7890  Validation loss = 1.2010  \n",
      "\n",
      "Fold: 18  Epoch: 254  Training loss = 4.7886  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 18  Epoch: 255  Training loss = 4.7883  Validation loss = 1.2005  \n",
      "\n",
      "Fold: 18  Epoch: 256  Training loss = 4.7878  Validation loss = 1.2002  \n",
      "\n",
      "Fold: 18  Epoch: 257  Training loss = 4.7873  Validation loss = 1.1999  \n",
      "\n",
      "Fold: 18  Epoch: 258  Training loss = 4.7870  Validation loss = 1.1998  \n",
      "\n",
      "Fold: 18  Epoch: 259  Training loss = 4.7866  Validation loss = 1.1995  \n",
      "\n",
      "Fold: 18  Epoch: 260  Training loss = 4.7863  Validation loss = 1.1993  \n",
      "\n",
      "Fold: 18  Epoch: 261  Training loss = 4.7860  Validation loss = 1.1991  \n",
      "\n",
      "Fold: 18  Epoch: 262  Training loss = 4.7856  Validation loss = 1.1988  \n",
      "\n",
      "Fold: 18  Epoch: 263  Training loss = 4.7852  Validation loss = 1.1986  \n",
      "\n",
      "Fold: 18  Epoch: 264  Training loss = 4.7849  Validation loss = 1.1984  \n",
      "\n",
      "Fold: 18  Epoch: 265  Training loss = 4.7843  Validation loss = 1.1981  \n",
      "\n",
      "Fold: 18  Epoch: 266  Training loss = 4.7840  Validation loss = 1.1978  \n",
      "\n",
      "Fold: 18  Epoch: 267  Training loss = 4.7835  Validation loss = 1.1975  \n",
      "\n",
      "Fold: 18  Epoch: 268  Training loss = 4.7831  Validation loss = 1.1973  \n",
      "\n",
      "Fold: 18  Epoch: 269  Training loss = 4.7826  Validation loss = 1.1969  \n",
      "\n",
      "Fold: 18  Epoch: 270  Training loss = 4.7822  Validation loss = 1.1967  \n",
      "\n",
      "Fold: 18  Epoch: 271  Training loss = 4.7818  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 18  Epoch: 272  Training loss = 4.7814  Validation loss = 1.1962  \n",
      "\n",
      "Fold: 18  Epoch: 273  Training loss = 4.7810  Validation loss = 1.1959  \n",
      "\n",
      "Fold: 18  Epoch: 274  Training loss = 4.7806  Validation loss = 1.1957  \n",
      "\n",
      "Fold: 18  Epoch: 275  Training loss = 4.7802  Validation loss = 1.1955  \n",
      "\n",
      "Fold: 18  Epoch: 276  Training loss = 4.7797  Validation loss = 1.1951  \n",
      "\n",
      "Fold: 18  Epoch: 277  Training loss = 4.7793  Validation loss = 1.1949  \n",
      "\n",
      "Fold: 18  Epoch: 278  Training loss = 4.7788  Validation loss = 1.1945  \n",
      "\n",
      "Fold: 18  Epoch: 279  Training loss = 4.7783  Validation loss = 1.1942  \n",
      "\n",
      "Fold: 18  Epoch: 280  Training loss = 4.7779  Validation loss = 1.1940  \n",
      "\n",
      "Fold: 18  Epoch: 281  Training loss = 4.7775  Validation loss = 1.1937  \n",
      "\n",
      "Fold: 18  Epoch: 282  Training loss = 4.7772  Validation loss = 1.1935  \n",
      "\n",
      "Fold: 18  Epoch: 283  Training loss = 4.7768  Validation loss = 1.1932  \n",
      "\n",
      "Fold: 18  Epoch: 284  Training loss = 4.7764  Validation loss = 1.1929  \n",
      "\n",
      "Fold: 18  Epoch: 285  Training loss = 4.7760  Validation loss = 1.1926  \n",
      "\n",
      "Fold: 18  Epoch: 286  Training loss = 4.7755  Validation loss = 1.1923  \n",
      "\n",
      "Fold: 18  Epoch: 287  Training loss = 4.7751  Validation loss = 1.1921  \n",
      "\n",
      "Fold: 18  Epoch: 288  Training loss = 4.7748  Validation loss = 1.1919  \n",
      "\n",
      "Fold: 18  Epoch: 289  Training loss = 4.7743  Validation loss = 1.1916  \n",
      "\n",
      "Fold: 18  Epoch: 290  Training loss = 4.7739  Validation loss = 1.1914  \n",
      "\n",
      "Fold: 18  Epoch: 291  Training loss = 4.7736  Validation loss = 1.1912  \n",
      "\n",
      "Fold: 18  Epoch: 292  Training loss = 4.7731  Validation loss = 1.1909  \n",
      "\n",
      "Fold: 18  Epoch: 293  Training loss = 4.7728  Validation loss = 1.1907  \n",
      "\n",
      "Fold: 18  Epoch: 294  Training loss = 4.7724  Validation loss = 1.1905  \n",
      "\n",
      "Fold: 18  Epoch: 295  Training loss = 4.7720  Validation loss = 1.1902  \n",
      "\n",
      "Fold: 18  Epoch: 296  Training loss = 4.7716  Validation loss = 1.1900  \n",
      "\n",
      "Fold: 18  Epoch: 297  Training loss = 4.7712  Validation loss = 1.1898  \n",
      "\n",
      "Fold: 18  Epoch: 298  Training loss = 4.7708  Validation loss = 1.1896  \n",
      "\n",
      "Fold: 18  Epoch: 299  Training loss = 4.7704  Validation loss = 1.1894  \n",
      "\n",
      "Fold: 18  Epoch: 300  Training loss = 4.7700  Validation loss = 1.1892  \n",
      "\n",
      "Fold: 18  Epoch: 301  Training loss = 4.7696  Validation loss = 1.1890  \n",
      "\n",
      "Fold: 18  Epoch: 302  Training loss = 4.7691  Validation loss = 1.1886  \n",
      "\n",
      "Fold: 18  Epoch: 303  Training loss = 4.7687  Validation loss = 1.1882  \n",
      "\n",
      "Fold: 18  Epoch: 304  Training loss = 4.7684  Validation loss = 1.1881  \n",
      "\n",
      "Fold: 18  Epoch: 305  Training loss = 4.7679  Validation loss = 1.1878  \n",
      "\n",
      "Fold: 18  Epoch: 306  Training loss = 4.7675  Validation loss = 1.1876  \n",
      "\n",
      "Fold: 18  Epoch: 307  Training loss = 4.7670  Validation loss = 1.1873  \n",
      "\n",
      "Fold: 18  Epoch: 308  Training loss = 4.7667  Validation loss = 1.1870  \n",
      "\n",
      "Fold: 18  Epoch: 309  Training loss = 4.7663  Validation loss = 1.1868  \n",
      "\n",
      "Fold: 18  Epoch: 310  Training loss = 4.7659  Validation loss = 1.1866  \n",
      "\n",
      "Fold: 18  Epoch: 311  Training loss = 4.7655  Validation loss = 1.1864  \n",
      "\n",
      "Fold: 18  Epoch: 312  Training loss = 4.7651  Validation loss = 1.1862  \n",
      "\n",
      "Fold: 18  Epoch: 313  Training loss = 4.7646  Validation loss = 1.1858  \n",
      "\n",
      "Fold: 18  Epoch: 314  Training loss = 4.7642  Validation loss = 1.1855  \n",
      "\n",
      "Fold: 18  Epoch: 315  Training loss = 4.7638  Validation loss = 1.1853  \n",
      "\n",
      "Fold: 18  Epoch: 316  Training loss = 4.7633  Validation loss = 1.1850  \n",
      "\n",
      "Fold: 18  Epoch: 317  Training loss = 4.7630  Validation loss = 1.1847  \n",
      "\n",
      "Fold: 18  Epoch: 318  Training loss = 4.7626  Validation loss = 1.1844  \n",
      "\n",
      "Fold: 18  Epoch: 319  Training loss = 4.7621  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 18  Epoch: 320  Training loss = 4.7617  Validation loss = 1.1839  \n",
      "\n",
      "Fold: 18  Epoch: 321  Training loss = 4.7613  Validation loss = 1.1836  \n",
      "\n",
      "Fold: 18  Epoch: 322  Training loss = 4.7608  Validation loss = 1.1833  \n",
      "\n",
      "Fold: 18  Epoch: 323  Training loss = 4.7605  Validation loss = 1.1831  \n",
      "\n",
      "Fold: 18  Epoch: 324  Training loss = 4.7601  Validation loss = 1.1829  \n",
      "\n",
      "Fold: 18  Epoch: 325  Training loss = 4.7597  Validation loss = 1.1826  \n",
      "\n",
      "Fold: 18  Epoch: 326  Training loss = 4.7593  Validation loss = 1.1823  \n",
      "\n",
      "Fold: 18  Epoch: 327  Training loss = 4.7588  Validation loss = 1.1820  \n",
      "\n",
      "Fold: 18  Epoch: 328  Training loss = 4.7585  Validation loss = 1.1818  \n",
      "\n",
      "Fold: 18  Epoch: 329  Training loss = 4.7580  Validation loss = 1.1815  \n",
      "\n",
      "Fold: 18  Epoch: 330  Training loss = 4.7576  Validation loss = 1.1813  \n",
      "\n",
      "Fold: 18  Epoch: 331  Training loss = 4.7572  Validation loss = 1.1810  \n",
      "\n",
      "Fold: 18  Epoch: 332  Training loss = 4.7568  Validation loss = 1.1807  \n",
      "\n",
      "Fold: 18  Epoch: 333  Training loss = 4.7563  Validation loss = 1.1804  \n",
      "\n",
      "Fold: 18  Epoch: 334  Training loss = 4.7557  Validation loss = 1.1801  \n",
      "\n",
      "Fold: 18  Epoch: 335  Training loss = 4.7553  Validation loss = 1.1798  \n",
      "\n",
      "Fold: 18  Epoch: 336  Training loss = 4.7550  Validation loss = 1.1796  \n",
      "\n",
      "Fold: 18  Epoch: 337  Training loss = 4.7546  Validation loss = 1.1794  \n",
      "\n",
      "Fold: 18  Epoch: 338  Training loss = 4.7542  Validation loss = 1.1791  \n",
      "\n",
      "Fold: 18  Epoch: 339  Training loss = 4.7538  Validation loss = 1.1788  \n",
      "\n",
      "Fold: 18  Epoch: 340  Training loss = 4.7534  Validation loss = 1.1786  \n",
      "\n",
      "Fold: 18  Epoch: 341  Training loss = 4.7530  Validation loss = 1.1784  \n",
      "\n",
      "Fold: 18  Epoch: 342  Training loss = 4.7527  Validation loss = 1.1781  \n",
      "\n",
      "Fold: 18  Epoch: 343  Training loss = 4.7523  Validation loss = 1.1778  \n",
      "\n",
      "Fold: 18  Epoch: 344  Training loss = 4.7518  Validation loss = 1.1775  \n",
      "\n",
      "Fold: 18  Epoch: 345  Training loss = 4.7514  Validation loss = 1.1772  \n",
      "\n",
      "Fold: 18  Epoch: 346  Training loss = 4.7511  Validation loss = 1.1771  \n",
      "\n",
      "Fold: 18  Epoch: 347  Training loss = 4.7507  Validation loss = 1.1768  \n",
      "\n",
      "Fold: 18  Epoch: 348  Training loss = 4.7503  Validation loss = 1.1766  \n",
      "\n",
      "Fold: 18  Epoch: 349  Training loss = 4.7499  Validation loss = 1.1763  \n",
      "\n",
      "Fold: 18  Epoch: 350  Training loss = 4.7494  Validation loss = 1.1760  \n",
      "\n",
      "Fold: 18  Epoch: 351  Training loss = 4.7491  Validation loss = 1.1758  \n",
      "\n",
      "Fold: 18  Epoch: 352  Training loss = 4.7487  Validation loss = 1.1756  \n",
      "\n",
      "Fold: 18  Epoch: 353  Training loss = 4.7484  Validation loss = 1.1754  \n",
      "\n",
      "Fold: 18  Epoch: 354  Training loss = 4.7480  Validation loss = 1.1752  \n",
      "\n",
      "Fold: 18  Epoch: 355  Training loss = 4.7477  Validation loss = 1.1750  \n",
      "\n",
      "Fold: 18  Epoch: 356  Training loss = 4.7473  Validation loss = 1.1749  \n",
      "\n",
      "Fold: 18  Epoch: 357  Training loss = 4.7468  Validation loss = 1.1745  \n",
      "\n",
      "Fold: 18  Epoch: 358  Training loss = 4.7464  Validation loss = 1.1743  \n",
      "\n",
      "Fold: 18  Epoch: 359  Training loss = 4.7459  Validation loss = 1.1740  \n",
      "\n",
      "Fold: 18  Epoch: 360  Training loss = 4.7455  Validation loss = 1.1737  \n",
      "\n",
      "Fold: 18  Epoch: 361  Training loss = 4.7450  Validation loss = 1.1735  \n",
      "\n",
      "Fold: 18  Epoch: 362  Training loss = 4.7445  Validation loss = 1.1731  \n",
      "\n",
      "Fold: 18  Epoch: 363  Training loss = 4.7442  Validation loss = 1.1730  \n",
      "\n",
      "Fold: 18  Epoch: 364  Training loss = 4.7437  Validation loss = 1.1728  \n",
      "\n",
      "Fold: 18  Epoch: 365  Training loss = 4.7434  Validation loss = 1.1725  \n",
      "\n",
      "Fold: 18  Epoch: 366  Training loss = 4.7430  Validation loss = 1.1723  \n",
      "\n",
      "Fold: 18  Epoch: 367  Training loss = 4.7425  Validation loss = 1.1720  \n",
      "\n",
      "Fold: 18  Epoch: 368  Training loss = 4.7421  Validation loss = 1.1718  \n",
      "\n",
      "Fold: 18  Epoch: 369  Training loss = 4.7417  Validation loss = 1.1715  \n",
      "\n",
      "Fold: 18  Epoch: 370  Training loss = 4.7412  Validation loss = 1.1712  \n",
      "\n",
      "Fold: 18  Epoch: 371  Training loss = 4.7408  Validation loss = 1.1708  \n",
      "\n",
      "Fold: 18  Epoch: 372  Training loss = 4.7404  Validation loss = 1.1706  \n",
      "\n",
      "Fold: 18  Epoch: 373  Training loss = 4.7399  Validation loss = 1.1702  \n",
      "\n",
      "Fold: 18  Epoch: 374  Training loss = 4.7397  Validation loss = 1.1701  \n",
      "\n",
      "Fold: 18  Epoch: 375  Training loss = 4.7391  Validation loss = 1.1698  \n",
      "\n",
      "Fold: 18  Epoch: 376  Training loss = 4.7387  Validation loss = 1.1695  \n",
      "\n",
      "Fold: 18  Epoch: 377  Training loss = 4.7383  Validation loss = 1.1693  \n",
      "\n",
      "Fold: 18  Epoch: 378  Training loss = 4.7379  Validation loss = 1.1691  \n",
      "\n",
      "Fold: 18  Epoch: 379  Training loss = 4.7376  Validation loss = 1.1689  \n",
      "\n",
      "Fold: 18  Epoch: 380  Training loss = 4.7371  Validation loss = 1.1686  \n",
      "\n",
      "Fold: 18  Epoch: 381  Training loss = 4.7365  Validation loss = 1.1683  \n",
      "\n",
      "Fold: 18  Epoch: 382  Training loss = 4.7359  Validation loss = 1.1679  \n",
      "\n",
      "Fold: 18  Epoch: 383  Training loss = 4.7354  Validation loss = 1.1676  \n",
      "\n",
      "Fold: 18  Epoch: 384  Training loss = 4.7350  Validation loss = 1.1673  \n",
      "\n",
      "Fold: 18  Epoch: 385  Training loss = 4.7346  Validation loss = 1.1671  \n",
      "\n",
      "Fold: 18  Epoch: 386  Training loss = 4.7341  Validation loss = 1.1669  \n",
      "\n",
      "Fold: 18  Epoch: 387  Training loss = 4.7337  Validation loss = 1.1666  \n",
      "\n",
      "Fold: 18  Epoch: 388  Training loss = 4.7332  Validation loss = 1.1663  \n",
      "\n",
      "Fold: 18  Epoch: 389  Training loss = 4.7328  Validation loss = 1.1661  \n",
      "\n",
      "Fold: 18  Epoch: 390  Training loss = 4.7324  Validation loss = 1.1659  \n",
      "\n",
      "Fold: 18  Epoch: 391  Training loss = 4.7320  Validation loss = 1.1656  \n",
      "\n",
      "Fold: 18  Epoch: 392  Training loss = 4.7316  Validation loss = 1.1655  \n",
      "\n",
      "Fold: 18  Epoch: 393  Training loss = 4.7313  Validation loss = 1.1653  \n",
      "\n",
      "Fold: 18  Epoch: 394  Training loss = 4.7307  Validation loss = 1.1650  \n",
      "\n",
      "Fold: 18  Epoch: 395  Training loss = 4.7303  Validation loss = 1.1648  \n",
      "\n",
      "Fold: 18  Epoch: 396  Training loss = 4.7299  Validation loss = 1.1645  \n",
      "\n",
      "Fold: 18  Epoch: 397  Training loss = 4.7295  Validation loss = 1.1642  \n",
      "\n",
      "Fold: 18  Epoch: 398  Training loss = 4.7291  Validation loss = 1.1640  \n",
      "\n",
      "Fold: 18  Epoch: 399  Training loss = 4.7287  Validation loss = 1.1638  \n",
      "\n",
      "Fold: 18  Epoch: 400  Training loss = 4.7283  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 18  Epoch: 401  Training loss = 4.7278  Validation loss = 1.1633  \n",
      "\n",
      "Fold: 18  Epoch: 402  Training loss = 4.7273  Validation loss = 1.1630  \n",
      "\n",
      "Fold: 18  Epoch: 403  Training loss = 4.7269  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 18  Epoch: 404  Training loss = 4.7264  Validation loss = 1.1624  \n",
      "\n",
      "Fold: 18  Epoch: 405  Training loss = 4.7260  Validation loss = 1.1622  \n",
      "\n",
      "Fold: 18  Epoch: 406  Training loss = 4.7256  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 18  Epoch: 407  Training loss = 4.7251  Validation loss = 1.1617  \n",
      "\n",
      "Fold: 18  Epoch: 408  Training loss = 4.7247  Validation loss = 1.1614  \n",
      "\n",
      "Fold: 18  Epoch: 409  Training loss = 4.7242  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 18  Epoch: 410  Training loss = 4.7238  Validation loss = 1.1609  \n",
      "\n",
      "Fold: 18  Epoch: 411  Training loss = 4.7234  Validation loss = 1.1607  \n",
      "\n",
      "Fold: 18  Epoch: 412  Training loss = 4.7229  Validation loss = 1.1605  \n",
      "\n",
      "Fold: 18  Epoch: 413  Training loss = 4.7225  Validation loss = 1.1602  \n",
      "\n",
      "Fold: 18  Epoch: 414  Training loss = 4.7221  Validation loss = 1.1600  \n",
      "\n",
      "Fold: 18  Epoch: 415  Training loss = 4.7217  Validation loss = 1.1597  \n",
      "\n",
      "Fold: 18  Epoch: 416  Training loss = 4.7213  Validation loss = 1.1595  \n",
      "\n",
      "Fold: 18  Epoch: 417  Training loss = 4.7209  Validation loss = 1.1593  \n",
      "\n",
      "Fold: 18  Epoch: 418  Training loss = 4.7205  Validation loss = 1.1590  \n",
      "\n",
      "Fold: 18  Epoch: 419  Training loss = 4.7201  Validation loss = 1.1588  \n",
      "\n",
      "Fold: 18  Epoch: 420  Training loss = 4.7196  Validation loss = 1.1586  \n",
      "\n",
      "Fold: 18  Epoch: 421  Training loss = 4.7192  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 18  Epoch: 422  Training loss = 4.7188  Validation loss = 1.1582  \n",
      "\n",
      "Fold: 18  Epoch: 423  Training loss = 4.7184  Validation loss = 1.1580  \n",
      "\n",
      "Fold: 18  Epoch: 424  Training loss = 4.7180  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 18  Epoch: 425  Training loss = 4.7176  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 18  Epoch: 426  Training loss = 4.7172  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 18  Epoch: 427  Training loss = 4.7168  Validation loss = 1.1572  \n",
      "\n",
      "Fold: 18  Epoch: 428  Training loss = 4.7164  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 18  Epoch: 429  Training loss = 4.7159  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 18  Epoch: 430  Training loss = 4.7156  Validation loss = 1.1565  \n",
      "\n",
      "Fold: 18  Epoch: 431  Training loss = 4.7151  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 18  Epoch: 432  Training loss = 4.7147  Validation loss = 1.1560  \n",
      "\n",
      "Fold: 18  Epoch: 433  Training loss = 4.7143  Validation loss = 1.1558  \n",
      "\n",
      "Fold: 18  Epoch: 434  Training loss = 4.7138  Validation loss = 1.1555  \n",
      "\n",
      "Fold: 18  Epoch: 435  Training loss = 4.7134  Validation loss = 1.1553  \n",
      "\n",
      "Fold: 18  Epoch: 436  Training loss = 4.7130  Validation loss = 1.1550  \n",
      "\n",
      "Fold: 18  Epoch: 437  Training loss = 4.7125  Validation loss = 1.1548  \n",
      "\n",
      "Fold: 18  Epoch: 438  Training loss = 4.7122  Validation loss = 1.1546  \n",
      "\n",
      "Fold: 18  Epoch: 439  Training loss = 4.7118  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 18  Epoch: 440  Training loss = 4.7115  Validation loss = 1.1542  \n",
      "\n",
      "Fold: 18  Epoch: 441  Training loss = 4.7110  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 18  Epoch: 442  Training loss = 4.7106  Validation loss = 1.1538  \n",
      "\n",
      "Fold: 18  Epoch: 443  Training loss = 4.7102  Validation loss = 1.1535  \n",
      "\n",
      "Fold: 18  Epoch: 444  Training loss = 4.7097  Validation loss = 1.1533  \n",
      "\n",
      "Fold: 18  Epoch: 445  Training loss = 4.7094  Validation loss = 1.1532  \n",
      "\n",
      "Fold: 18  Epoch: 446  Training loss = 4.7090  Validation loss = 1.1529  \n",
      "\n",
      "Fold: 18  Epoch: 447  Training loss = 4.7086  Validation loss = 1.1528  \n",
      "\n",
      "Fold: 18  Epoch: 448  Training loss = 4.7082  Validation loss = 1.1526  \n",
      "\n",
      "Fold: 18  Epoch: 449  Training loss = 4.7078  Validation loss = 1.1524  \n",
      "\n",
      "Fold: 18  Epoch: 450  Training loss = 4.7073  Validation loss = 1.1521  \n",
      "\n",
      "Fold: 18  Epoch: 451  Training loss = 4.7068  Validation loss = 1.1519  \n",
      "\n",
      "Fold: 18  Epoch: 452  Training loss = 4.7064  Validation loss = 1.1517  \n",
      "\n",
      "Fold: 18  Epoch: 453  Training loss = 4.7059  Validation loss = 1.1515  \n",
      "\n",
      "Fold: 18  Epoch: 454  Training loss = 4.7056  Validation loss = 1.1513  \n",
      "\n",
      "Fold: 18  Epoch: 455  Training loss = 4.7052  Validation loss = 1.1511  \n",
      "\n",
      "Fold: 18  Epoch: 456  Training loss = 4.7049  Validation loss = 1.1509  \n",
      "\n",
      "Fold: 18  Epoch: 457  Training loss = 4.7044  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 18  Epoch: 458  Training loss = 4.7041  Validation loss = 1.1505  \n",
      "\n",
      "Fold: 18  Epoch: 459  Training loss = 4.7037  Validation loss = 1.1504  \n",
      "\n",
      "Fold: 18  Epoch: 460  Training loss = 4.7033  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 18  Epoch: 461  Training loss = 4.7028  Validation loss = 1.1499  \n",
      "\n",
      "Fold: 18  Epoch: 462  Training loss = 4.7025  Validation loss = 1.1497  \n",
      "\n",
      "Fold: 18  Epoch: 463  Training loss = 4.7020  Validation loss = 1.1495  \n",
      "\n",
      "Fold: 18  Epoch: 464  Training loss = 4.7017  Validation loss = 1.1494  \n",
      "\n",
      "Fold: 18  Epoch: 465  Training loss = 4.7013  Validation loss = 1.1491  \n",
      "\n",
      "Fold: 18  Epoch: 466  Training loss = 4.7007  Validation loss = 1.1489  \n",
      "\n",
      "Fold: 18  Epoch: 467  Training loss = 4.7003  Validation loss = 1.1487  \n",
      "\n",
      "Fold: 18  Epoch: 468  Training loss = 4.6999  Validation loss = 1.1485  \n",
      "\n",
      "Fold: 18  Epoch: 469  Training loss = 4.6995  Validation loss = 1.1483  \n",
      "\n",
      "Fold: 18  Epoch: 470  Training loss = 4.6992  Validation loss = 1.1481  \n",
      "\n",
      "Fold: 18  Epoch: 471  Training loss = 4.6987  Validation loss = 1.1479  \n",
      "\n",
      "Fold: 18  Epoch: 472  Training loss = 4.6984  Validation loss = 1.1477  \n",
      "\n",
      "Fold: 18  Epoch: 473  Training loss = 4.6979  Validation loss = 1.1475  \n",
      "\n",
      "Fold: 18  Epoch: 474  Training loss = 4.6975  Validation loss = 1.1473  \n",
      "\n",
      "Fold: 18  Epoch: 475  Training loss = 4.6972  Validation loss = 1.1471  \n",
      "\n",
      "Fold: 18  Epoch: 476  Training loss = 4.6967  Validation loss = 1.1469  \n",
      "\n",
      "Fold: 18  Epoch: 477  Training loss = 4.6963  Validation loss = 1.1467  \n",
      "\n",
      "Fold: 18  Epoch: 478  Training loss = 4.6959  Validation loss = 1.1465  \n",
      "\n",
      "Fold: 18  Epoch: 479  Training loss = 4.6955  Validation loss = 1.1464  \n",
      "\n",
      "Fold: 18  Epoch: 480  Training loss = 4.6951  Validation loss = 1.1461  \n",
      "\n",
      "Fold: 18  Epoch: 481  Training loss = 4.6946  Validation loss = 1.1459  \n",
      "\n",
      "Fold: 18  Epoch: 482  Training loss = 4.6942  Validation loss = 1.1457  \n",
      "\n",
      "Fold: 18  Epoch: 483  Training loss = 4.6938  Validation loss = 1.1456  \n",
      "\n",
      "Fold: 18  Epoch: 484  Training loss = 4.6933  Validation loss = 1.1453  \n",
      "\n",
      "Fold: 18  Epoch: 485  Training loss = 4.6928  Validation loss = 1.1451  \n",
      "\n",
      "Fold: 18  Epoch: 486  Training loss = 4.6924  Validation loss = 1.1449  \n",
      "\n",
      "Fold: 18  Epoch: 487  Training loss = 4.6920  Validation loss = 1.1447  \n",
      "\n",
      "Fold: 18  Epoch: 488  Training loss = 4.6916  Validation loss = 1.1445  \n",
      "\n",
      "Fold: 18  Epoch: 489  Training loss = 4.6911  Validation loss = 1.1444  \n",
      "\n",
      "Fold: 18  Epoch: 490  Training loss = 4.6907  Validation loss = 1.1442  \n",
      "\n",
      "Fold: 18  Epoch: 491  Training loss = 4.6903  Validation loss = 1.1440  \n",
      "\n",
      "Fold: 18  Epoch: 492  Training loss = 4.6899  Validation loss = 1.1438  \n",
      "\n",
      "Fold: 18  Epoch: 493  Training loss = 4.6894  Validation loss = 1.1435  \n",
      "\n",
      "Fold: 18  Epoch: 494  Training loss = 4.6891  Validation loss = 1.1434  \n",
      "\n",
      "Fold: 18  Epoch: 495  Training loss = 4.6885  Validation loss = 1.1432  \n",
      "\n",
      "Fold: 18  Epoch: 496  Training loss = 4.6880  Validation loss = 1.1430  \n",
      "\n",
      "Fold: 18  Epoch: 497  Training loss = 4.6876  Validation loss = 1.1428  \n",
      "\n",
      "Fold: 18  Epoch: 498  Training loss = 4.6873  Validation loss = 1.1426  \n",
      "\n",
      "Fold: 18  Epoch: 499  Training loss = 4.6869  Validation loss = 1.1424  \n",
      "\n",
      "Fold: 18  Epoch: 500  Training loss = 4.6865  Validation loss = 1.1422  \n",
      "\n",
      "Fold: 18  Epoch: 501  Training loss = 4.6860  Validation loss = 1.1421  \n",
      "\n",
      "Fold: 18  Epoch: 502  Training loss = 4.6856  Validation loss = 1.1419  \n",
      "\n",
      "Fold: 18  Epoch: 503  Training loss = 4.6852  Validation loss = 1.1417  \n",
      "\n",
      "Fold: 18  Epoch: 504  Training loss = 4.6848  Validation loss = 1.1414  \n",
      "\n",
      "Fold: 18  Epoch: 505  Training loss = 4.6844  Validation loss = 1.1412  \n",
      "\n",
      "Fold: 18  Epoch: 506  Training loss = 4.6841  Validation loss = 1.1411  \n",
      "\n",
      "Fold: 18  Epoch: 507  Training loss = 4.6835  Validation loss = 1.1409  \n",
      "\n",
      "Fold: 18  Epoch: 508  Training loss = 4.6831  Validation loss = 1.1407  \n",
      "\n",
      "Fold: 18  Epoch: 509  Training loss = 4.6826  Validation loss = 1.1405  \n",
      "\n",
      "Fold: 18  Epoch: 510  Training loss = 4.6821  Validation loss = 1.1403  \n",
      "\n",
      "Fold: 18  Epoch: 511  Training loss = 4.6817  Validation loss = 1.1401  \n",
      "\n",
      "Fold: 18  Epoch: 512  Training loss = 4.6813  Validation loss = 1.1399  \n",
      "\n",
      "Fold: 18  Epoch: 513  Training loss = 4.6809  Validation loss = 1.1397  \n",
      "\n",
      "Fold: 18  Epoch: 514  Training loss = 4.6804  Validation loss = 1.1395  \n",
      "\n",
      "Fold: 18  Epoch: 515  Training loss = 4.6799  Validation loss = 1.1393  \n",
      "\n",
      "Fold: 18  Epoch: 516  Training loss = 4.6795  Validation loss = 1.1391  \n",
      "\n",
      "Fold: 18  Epoch: 517  Training loss = 4.6791  Validation loss = 1.1389  \n",
      "\n",
      "Fold: 18  Epoch: 518  Training loss = 4.6787  Validation loss = 1.1388  \n",
      "\n",
      "Fold: 18  Epoch: 519  Training loss = 4.6783  Validation loss = 1.1386  \n",
      "\n",
      "Fold: 18  Epoch: 520  Training loss = 4.6778  Validation loss = 1.1384  \n",
      "\n",
      "Fold: 18  Epoch: 521  Training loss = 4.6773  Validation loss = 1.1382  \n",
      "\n",
      "Fold: 18  Epoch: 522  Training loss = 4.6769  Validation loss = 1.1380  \n",
      "\n",
      "Fold: 18  Epoch: 523  Training loss = 4.6765  Validation loss = 1.1377  \n",
      "\n",
      "Fold: 18  Epoch: 524  Training loss = 4.6761  Validation loss = 1.1375  \n",
      "\n",
      "Fold: 18  Epoch: 525  Training loss = 4.6756  Validation loss = 1.1373  \n",
      "\n",
      "Fold: 18  Epoch: 526  Training loss = 4.6752  Validation loss = 1.1371  \n",
      "\n",
      "Fold: 18  Epoch: 527  Training loss = 4.6748  Validation loss = 1.1370  \n",
      "\n",
      "Fold: 18  Epoch: 528  Training loss = 4.6744  Validation loss = 1.1367  \n",
      "\n",
      "Fold: 18  Epoch: 529  Training loss = 4.6739  Validation loss = 1.1365  \n",
      "\n",
      "Fold: 18  Epoch: 530  Training loss = 4.6735  Validation loss = 1.1363  \n",
      "\n",
      "Fold: 18  Epoch: 531  Training loss = 4.6729  Validation loss = 1.1361  \n",
      "\n",
      "Fold: 18  Epoch: 532  Training loss = 4.6725  Validation loss = 1.1358  \n",
      "\n",
      "Fold: 18  Epoch: 533  Training loss = 4.6720  Validation loss = 1.1357  \n",
      "\n",
      "Fold: 18  Epoch: 534  Training loss = 4.6714  Validation loss = 1.1354  \n",
      "\n",
      "Fold: 18  Epoch: 535  Training loss = 4.6711  Validation loss = 1.1352  \n",
      "\n",
      "Fold: 18  Epoch: 536  Training loss = 4.6702  Validation loss = 1.1346  \n",
      "\n",
      "Fold: 18  Epoch: 537  Training loss = 4.6692  Validation loss = 1.1341  \n",
      "\n",
      "Fold: 18  Epoch: 538  Training loss = 4.6668  Validation loss = 1.1333  \n",
      "\n",
      "Fold: 18  Epoch: 539  Training loss = 4.6639  Validation loss = 1.1323  \n",
      "\n",
      "Fold: 18  Epoch: 540  Training loss = 4.6635  Validation loss = 1.1322  \n",
      "\n",
      "Fold: 18  Epoch: 541  Training loss = 4.6621  Validation loss = 1.1314  \n",
      "\n",
      "Fold: 18  Epoch: 542  Training loss = 4.6617  Validation loss = 1.1313  \n",
      "\n",
      "Fold: 18  Epoch: 543  Training loss = 4.6613  Validation loss = 1.1312  \n",
      "\n",
      "Fold: 18  Epoch: 544  Training loss = 4.6608  Validation loss = 1.1310  \n",
      "\n",
      "Fold: 18  Epoch: 545  Training loss = 4.6603  Validation loss = 1.1307  \n",
      "\n",
      "Fold: 18  Epoch: 546  Training loss = 4.6598  Validation loss = 1.1302  \n",
      "\n",
      "Fold: 18  Epoch: 547  Training loss = 4.6592  Validation loss = 1.1299  \n",
      "\n",
      "Fold: 18  Epoch: 548  Training loss = 4.6587  Validation loss = 1.1297  \n",
      "\n",
      "Fold: 18  Epoch: 549  Training loss = 4.6583  Validation loss = 1.1295  \n",
      "\n",
      "Fold: 18  Epoch: 550  Training loss = 4.6579  Validation loss = 1.1293  \n",
      "\n",
      "Fold: 18  Epoch: 551  Training loss = 4.6574  Validation loss = 1.1290  \n",
      "\n",
      "Fold: 18  Epoch: 552  Training loss = 4.6569  Validation loss = 1.1288  \n",
      "\n",
      "Fold: 18  Epoch: 553  Training loss = 4.6563  Validation loss = 1.1286  \n",
      "\n",
      "Fold: 18  Epoch: 554  Training loss = 4.6559  Validation loss = 1.1284  \n",
      "\n",
      "Fold: 18  Epoch: 555  Training loss = 4.6554  Validation loss = 1.1282  \n",
      "\n",
      "Fold: 18  Epoch: 556  Training loss = 4.6550  Validation loss = 1.1281  \n",
      "\n",
      "Fold: 18  Epoch: 557  Training loss = 4.6545  Validation loss = 1.1279  \n",
      "\n",
      "Fold: 18  Epoch: 558  Training loss = 4.6539  Validation loss = 1.1277  \n",
      "\n",
      "Fold: 18  Epoch: 559  Training loss = 4.6534  Validation loss = 1.1275  \n",
      "\n",
      "Fold: 18  Epoch: 560  Training loss = 4.6530  Validation loss = 1.1274  \n",
      "\n",
      "Fold: 18  Epoch: 561  Training loss = 4.6524  Validation loss = 1.1271  \n",
      "\n",
      "Fold: 18  Epoch: 562  Training loss = 4.6520  Validation loss = 1.1270  \n",
      "\n",
      "Fold: 18  Epoch: 563  Training loss = 4.6516  Validation loss = 1.1268  \n",
      "\n",
      "Fold: 18  Epoch: 564  Training loss = 4.6512  Validation loss = 1.1266  \n",
      "\n",
      "Fold: 18  Epoch: 565  Training loss = 4.6508  Validation loss = 1.1265  \n",
      "\n",
      "Fold: 18  Epoch: 566  Training loss = 4.6504  Validation loss = 1.1263  \n",
      "\n",
      "Fold: 18  Epoch: 567  Training loss = 4.6499  Validation loss = 1.1261  \n",
      "\n",
      "Fold: 18  Epoch: 568  Training loss = 4.6495  Validation loss = 1.1259  \n",
      "\n",
      "Fold: 18  Epoch: 569  Training loss = 4.6491  Validation loss = 1.1258  \n",
      "\n",
      "Fold: 18  Epoch: 570  Training loss = 4.6487  Validation loss = 1.1256  \n",
      "\n",
      "Fold: 18  Epoch: 571  Training loss = 4.6483  Validation loss = 1.1254  \n",
      "\n",
      "Fold: 18  Epoch: 572  Training loss = 4.6478  Validation loss = 1.1252  \n",
      "\n",
      "Fold: 18  Epoch: 573  Training loss = 4.6472  Validation loss = 1.1250  \n",
      "\n",
      "Fold: 18  Epoch: 574  Training loss = 4.6468  Validation loss = 1.1248  \n",
      "\n",
      "Fold: 18  Epoch: 575  Training loss = 4.6464  Validation loss = 1.1247  \n",
      "\n",
      "Fold: 18  Epoch: 576  Training loss = 4.6461  Validation loss = 1.1246  \n",
      "\n",
      "Fold: 18  Epoch: 577  Training loss = 4.6457  Validation loss = 1.1244  \n",
      "\n",
      "Fold: 18  Epoch: 578  Training loss = 4.6450  Validation loss = 1.1242  \n",
      "\n",
      "Fold: 18  Epoch: 579  Training loss = 4.6448  Validation loss = 1.1241  \n",
      "\n",
      "Fold: 18  Epoch: 580  Training loss = 4.6444  Validation loss = 1.1239  \n",
      "\n",
      "Fold: 18  Epoch: 581  Training loss = 4.6439  Validation loss = 1.1237  \n",
      "\n",
      "Fold: 18  Epoch: 582  Training loss = 4.6435  Validation loss = 1.1236  \n",
      "\n",
      "Fold: 18  Epoch: 583  Training loss = 4.6429  Validation loss = 1.1234  \n",
      "\n",
      "Fold: 18  Epoch: 584  Training loss = 4.6425  Validation loss = 1.1232  \n",
      "\n",
      "Fold: 18  Epoch: 585  Training loss = 4.6421  Validation loss = 1.1231  \n",
      "\n",
      "Fold: 18  Epoch: 586  Training loss = 4.6417  Validation loss = 1.1230  \n",
      "\n",
      "Fold: 18  Epoch: 587  Training loss = 4.6413  Validation loss = 1.1228  \n",
      "\n",
      "Fold: 18  Epoch: 588  Training loss = 4.6410  Validation loss = 1.1227  \n",
      "\n",
      "Fold: 18  Epoch: 589  Training loss = 4.6405  Validation loss = 1.1225  \n",
      "\n",
      "Fold: 18  Epoch: 590  Training loss = 4.6401  Validation loss = 1.1223  \n",
      "\n",
      "Fold: 18  Epoch: 591  Training loss = 4.6396  Validation loss = 1.1222  \n",
      "\n",
      "Fold: 18  Epoch: 592  Training loss = 4.6391  Validation loss = 1.1220  \n",
      "\n",
      "Fold: 18  Epoch: 593  Training loss = 4.6385  Validation loss = 1.1218  \n",
      "\n",
      "Fold: 18  Epoch: 594  Training loss = 4.6381  Validation loss = 1.1217  \n",
      "\n",
      "Fold: 18  Epoch: 595  Training loss = 4.6377  Validation loss = 1.1215  \n",
      "\n",
      "Fold: 18  Epoch: 596  Training loss = 4.6373  Validation loss = 1.1213  \n",
      "\n",
      "Fold: 18  Epoch: 597  Training loss = 4.6369  Validation loss = 1.1212  \n",
      "\n",
      "Fold: 18  Epoch: 598  Training loss = 4.6366  Validation loss = 1.1211  \n",
      "\n",
      "Fold: 18  Epoch: 599  Training loss = 4.6362  Validation loss = 1.1209  \n",
      "\n",
      "Fold: 18  Epoch: 600  Training loss = 4.6358  Validation loss = 1.1208  \n",
      "\n",
      "Fold: 18  Epoch: 601  Training loss = 4.6353  Validation loss = 1.1206  \n",
      "\n",
      "Fold: 18  Epoch: 602  Training loss = 4.6348  Validation loss = 1.1205  \n",
      "\n",
      "Fold: 18  Epoch: 603  Training loss = 4.6343  Validation loss = 1.1203  \n",
      "\n",
      "Fold: 18  Epoch: 604  Training loss = 4.6338  Validation loss = 1.1201  \n",
      "\n",
      "Fold: 18  Epoch: 605  Training loss = 4.6334  Validation loss = 1.1200  \n",
      "\n",
      "Fold: 18  Epoch: 606  Training loss = 4.6329  Validation loss = 1.1198  \n",
      "\n",
      "Fold: 18  Epoch: 607  Training loss = 4.6325  Validation loss = 1.1196  \n",
      "\n",
      "Fold: 18  Epoch: 608  Training loss = 4.6321  Validation loss = 1.1195  \n",
      "\n",
      "Fold: 18  Epoch: 609  Training loss = 4.6318  Validation loss = 1.1193  \n",
      "\n",
      "Fold: 18  Epoch: 610  Training loss = 4.6313  Validation loss = 1.1192  \n",
      "\n",
      "Fold: 18  Epoch: 611  Training loss = 4.6309  Validation loss = 1.1190  \n",
      "\n",
      "Fold: 18  Epoch: 612  Training loss = 4.6303  Validation loss = 1.1188  \n",
      "\n",
      "Fold: 18  Epoch: 613  Training loss = 4.6299  Validation loss = 1.1187  \n",
      "\n",
      "Fold: 18  Epoch: 614  Training loss = 4.6295  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 18  Epoch: 615  Training loss = 4.6291  Validation loss = 1.1183  \n",
      "\n",
      "Fold: 18  Epoch: 616  Training loss = 4.6286  Validation loss = 1.1181  \n",
      "\n",
      "Fold: 18  Epoch: 617  Training loss = 4.6280  Validation loss = 1.1180  \n",
      "\n",
      "Fold: 18  Epoch: 618  Training loss = 4.6275  Validation loss = 1.1178  \n",
      "\n",
      "Fold: 18  Epoch: 619  Training loss = 4.6271  Validation loss = 1.1176  \n",
      "\n",
      "Fold: 18  Epoch: 620  Training loss = 4.6267  Validation loss = 1.1175  \n",
      "\n",
      "Fold: 18  Epoch: 621  Training loss = 4.6263  Validation loss = 1.1174  \n",
      "\n",
      "Fold: 18  Epoch: 622  Training loss = 4.6259  Validation loss = 1.1172  \n",
      "\n",
      "Fold: 18  Epoch: 623  Training loss = 4.6255  Validation loss = 1.1171  \n",
      "\n",
      "Fold: 18  Epoch: 624  Training loss = 4.6251  Validation loss = 1.1169  \n",
      "\n",
      "Fold: 18  Epoch: 625  Training loss = 4.6246  Validation loss = 1.1167  \n",
      "\n",
      "Fold: 18  Epoch: 626  Training loss = 4.6242  Validation loss = 1.1166  \n",
      "\n",
      "Fold: 18  Epoch: 627  Training loss = 4.6237  Validation loss = 1.1164  \n",
      "\n",
      "Fold: 18  Epoch: 628  Training loss = 4.6234  Validation loss = 1.1163  \n",
      "\n",
      "Fold: 18  Epoch: 629  Training loss = 4.6230  Validation loss = 1.1161  \n",
      "\n",
      "Fold: 18  Epoch: 630  Training loss = 4.6227  Validation loss = 1.1160  \n",
      "\n",
      "Fold: 18  Epoch: 631  Training loss = 4.6223  Validation loss = 1.1158  \n",
      "\n",
      "Fold: 18  Epoch: 632  Training loss = 4.6218  Validation loss = 1.1157  \n",
      "\n",
      "Fold: 18  Epoch: 633  Training loss = 4.6214  Validation loss = 1.1155  \n",
      "\n",
      "Fold: 18  Epoch: 634  Training loss = 4.6209  Validation loss = 1.1153  \n",
      "\n",
      "Fold: 18  Epoch: 635  Training loss = 4.6204  Validation loss = 1.1151  \n",
      "\n",
      "Fold: 18  Epoch: 636  Training loss = 4.6199  Validation loss = 1.1149  \n",
      "\n",
      "Fold: 18  Epoch: 637  Training loss = 4.6195  Validation loss = 1.1148  \n",
      "\n",
      "Fold: 18  Epoch: 638  Training loss = 4.6191  Validation loss = 1.1146  \n",
      "\n",
      "Fold: 18  Epoch: 639  Training loss = 4.6187  Validation loss = 1.1145  \n",
      "\n",
      "Fold: 18  Epoch: 640  Training loss = 4.6184  Validation loss = 1.1144  \n",
      "\n",
      "Fold: 18  Epoch: 641  Training loss = 4.6179  Validation loss = 1.1142  \n",
      "\n",
      "Fold: 18  Epoch: 642  Training loss = 4.6176  Validation loss = 1.1141  \n",
      "\n",
      "Fold: 18  Epoch: 643  Training loss = 4.6172  Validation loss = 1.1139  \n",
      "\n",
      "Fold: 18  Epoch: 644  Training loss = 4.6169  Validation loss = 1.1138  \n",
      "\n",
      "Fold: 18  Epoch: 645  Training loss = 4.6164  Validation loss = 1.1136  \n",
      "\n",
      "Fold: 18  Epoch: 646  Training loss = 4.6161  Validation loss = 1.1135  \n",
      "\n",
      "Fold: 18  Epoch: 647  Training loss = 4.6158  Validation loss = 1.1134  \n",
      "\n",
      "Fold: 18  Epoch: 648  Training loss = 4.6154  Validation loss = 1.1132  \n",
      "\n",
      "Fold: 18  Epoch: 649  Training loss = 4.6149  Validation loss = 1.1130  \n",
      "\n",
      "Fold: 18  Epoch: 650  Training loss = 4.6145  Validation loss = 1.1129  \n",
      "\n",
      "Fold: 18  Epoch: 651  Training loss = 4.6140  Validation loss = 1.1127  \n",
      "\n",
      "Fold: 18  Epoch: 652  Training loss = 4.6136  Validation loss = 1.1126  \n",
      "\n",
      "Fold: 18  Epoch: 653  Training loss = 4.6131  Validation loss = 1.1124  \n",
      "\n",
      "Fold: 18  Epoch: 654  Training loss = 4.6126  Validation loss = 1.1123  \n",
      "\n",
      "Fold: 18  Epoch: 655  Training loss = 4.6123  Validation loss = 1.1121  \n",
      "\n",
      "Fold: 18  Epoch: 656  Training loss = 4.6118  Validation loss = 1.1119  \n",
      "\n",
      "Fold: 18  Epoch: 657  Training loss = 4.6114  Validation loss = 1.1118  \n",
      "\n",
      "Fold: 18  Epoch: 658  Training loss = 4.6111  Validation loss = 1.1116  \n",
      "\n",
      "Fold: 18  Epoch: 659  Training loss = 4.6106  Validation loss = 1.1115  \n",
      "\n",
      "Fold: 18  Epoch: 660  Training loss = 4.6101  Validation loss = 1.1112  \n",
      "\n",
      "Fold: 18  Epoch: 661  Training loss = 4.6096  Validation loss = 1.1111  \n",
      "\n",
      "Fold: 18  Epoch: 662  Training loss = 4.6092  Validation loss = 1.1109  \n",
      "\n",
      "Fold: 18  Epoch: 663  Training loss = 4.6088  Validation loss = 1.1108  \n",
      "\n",
      "Fold: 18  Epoch: 664  Training loss = 4.6084  Validation loss = 1.1107  \n",
      "\n",
      "Fold: 18  Epoch: 665  Training loss = 4.6080  Validation loss = 1.1105  \n",
      "\n",
      "Fold: 18  Epoch: 666  Training loss = 4.6077  Validation loss = 1.1104  \n",
      "\n",
      "Fold: 18  Epoch: 667  Training loss = 4.6073  Validation loss = 1.1102  \n",
      "\n",
      "Fold: 18  Epoch: 668  Training loss = 4.6069  Validation loss = 1.1101  \n",
      "\n",
      "Fold: 18  Epoch: 669  Training loss = 4.6065  Validation loss = 1.1099  \n",
      "\n",
      "Fold: 18  Epoch: 670  Training loss = 4.6061  Validation loss = 1.1098  \n",
      "\n",
      "Fold: 18  Epoch: 671  Training loss = 4.6057  Validation loss = 1.1096  \n",
      "\n",
      "Fold: 18  Epoch: 672  Training loss = 4.6053  Validation loss = 1.1095  \n",
      "\n",
      "Fold: 18  Epoch: 673  Training loss = 4.6048  Validation loss = 1.1093  \n",
      "\n",
      "Fold: 18  Epoch: 674  Training loss = 4.6043  Validation loss = 1.1092  \n",
      "\n",
      "Fold: 18  Epoch: 675  Training loss = 4.6040  Validation loss = 1.1090  \n",
      "\n",
      "Fold: 18  Epoch: 676  Training loss = 4.6036  Validation loss = 1.1089  \n",
      "\n",
      "Fold: 18  Epoch: 677  Training loss = 4.6031  Validation loss = 1.1087  \n",
      "\n",
      "Fold: 18  Epoch: 678  Training loss = 4.6027  Validation loss = 1.1085  \n",
      "\n",
      "Fold: 18  Epoch: 679  Training loss = 4.6021  Validation loss = 1.1083  \n",
      "\n",
      "Fold: 18  Epoch: 680  Training loss = 4.6018  Validation loss = 1.1082  \n",
      "\n",
      "Fold: 18  Epoch: 681  Training loss = 4.6015  Validation loss = 1.1081  \n",
      "\n",
      "Fold: 18  Epoch: 682  Training loss = 4.6012  Validation loss = 1.1079  \n",
      "\n",
      "Fold: 18  Epoch: 683  Training loss = 4.6007  Validation loss = 1.1077  \n",
      "\n",
      "Fold: 18  Epoch: 684  Training loss = 4.6003  Validation loss = 1.1076  \n",
      "\n",
      "Fold: 18  Epoch: 685  Training loss = 4.5999  Validation loss = 1.1075  \n",
      "\n",
      "Fold: 18  Epoch: 686  Training loss = 4.5996  Validation loss = 1.1073  \n",
      "\n",
      "Fold: 18  Epoch: 687  Training loss = 4.5992  Validation loss = 1.1072  \n",
      "\n",
      "Fold: 18  Epoch: 688  Training loss = 4.5987  Validation loss = 1.1070  \n",
      "\n",
      "Fold: 18  Epoch: 689  Training loss = 4.5983  Validation loss = 1.1069  \n",
      "\n",
      "Fold: 18  Epoch: 690  Training loss = 4.5981  Validation loss = 1.1068  \n",
      "\n",
      "Fold: 18  Epoch: 691  Training loss = 4.5977  Validation loss = 1.1066  \n",
      "\n",
      "Fold: 18  Epoch: 692  Training loss = 4.5974  Validation loss = 1.1065  \n",
      "\n",
      "Fold: 18  Epoch: 693  Training loss = 4.5969  Validation loss = 1.1064  \n",
      "\n",
      "Fold: 18  Epoch: 694  Training loss = 4.5966  Validation loss = 1.1062  \n",
      "\n",
      "Fold: 18  Epoch: 695  Training loss = 4.5962  Validation loss = 1.1061  \n",
      "\n",
      "Fold: 18  Epoch: 696  Training loss = 4.5959  Validation loss = 1.1060  \n",
      "\n",
      "Fold: 18  Epoch: 697  Training loss = 4.5954  Validation loss = 1.1058  \n",
      "\n",
      "Fold: 18  Epoch: 698  Training loss = 4.5950  Validation loss = 1.1056  \n",
      "\n",
      "Fold: 18  Epoch: 699  Training loss = 4.5945  Validation loss = 1.1055  \n",
      "\n",
      "Fold: 18  Epoch: 700  Training loss = 4.5941  Validation loss = 1.1053  \n",
      "\n",
      "Fold: 18  Epoch: 701  Training loss = 4.5936  Validation loss = 1.1052  \n",
      "\n",
      "Fold: 18  Epoch: 702  Training loss = 4.5932  Validation loss = 1.1050  \n",
      "\n",
      "Fold: 18  Epoch: 703  Training loss = 4.5929  Validation loss = 1.1049  \n",
      "\n",
      "Fold: 18  Epoch: 704  Training loss = 4.5924  Validation loss = 1.1047  \n",
      "\n",
      "Fold: 18  Epoch: 705  Training loss = 4.5920  Validation loss = 1.1045  \n",
      "\n",
      "Fold: 18  Epoch: 706  Training loss = 4.5917  Validation loss = 1.1044  \n",
      "\n",
      "Fold: 18  Epoch: 707  Training loss = 4.5913  Validation loss = 1.1042  \n",
      "\n",
      "Fold: 18  Epoch: 708  Training loss = 4.5908  Validation loss = 1.1041  \n",
      "\n",
      "Fold: 18  Epoch: 709  Training loss = 4.5905  Validation loss = 1.1039  \n",
      "\n",
      "Fold: 18  Epoch: 710  Training loss = 4.5900  Validation loss = 1.1038  \n",
      "\n",
      "Fold: 18  Epoch: 711  Training loss = 4.5896  Validation loss = 1.1036  \n",
      "\n",
      "Fold: 18  Epoch: 712  Training loss = 4.5892  Validation loss = 1.1035  \n",
      "\n",
      "Fold: 18  Epoch: 713  Training loss = 4.5889  Validation loss = 1.1033  \n",
      "\n",
      "Fold: 18  Epoch: 714  Training loss = 4.5885  Validation loss = 1.1032  \n",
      "\n",
      "Fold: 18  Epoch: 715  Training loss = 4.5882  Validation loss = 1.1031  \n",
      "\n",
      "Fold: 18  Epoch: 716  Training loss = 4.5878  Validation loss = 1.1029  \n",
      "\n",
      "Fold: 18  Epoch: 717  Training loss = 4.5873  Validation loss = 1.1027  \n",
      "\n",
      "Fold: 18  Epoch: 718  Training loss = 4.5869  Validation loss = 1.1026  \n",
      "\n",
      "Fold: 18  Epoch: 719  Training loss = 4.5866  Validation loss = 1.1025  \n",
      "\n",
      "Fold: 18  Epoch: 720  Training loss = 4.5861  Validation loss = 1.1023  \n",
      "\n",
      "Fold: 18  Epoch: 721  Training loss = 4.5857  Validation loss = 1.1022  \n",
      "\n",
      "Fold: 18  Epoch: 722  Training loss = 4.5853  Validation loss = 1.1021  \n",
      "\n",
      "Fold: 18  Epoch: 723  Training loss = 4.5849  Validation loss = 1.1019  \n",
      "\n",
      "Fold: 18  Epoch: 724  Training loss = 4.5844  Validation loss = 1.1018  \n",
      "\n",
      "Fold: 18  Epoch: 725  Training loss = 4.5840  Validation loss = 1.1016  \n",
      "\n",
      "Fold: 18  Epoch: 726  Training loss = 4.5836  Validation loss = 1.1015  \n",
      "\n",
      "Fold: 18  Epoch: 727  Training loss = 4.5830  Validation loss = 1.1013  \n",
      "\n",
      "Fold: 18  Epoch: 728  Training loss = 4.5827  Validation loss = 1.1012  \n",
      "\n",
      "Fold: 18  Epoch: 729  Training loss = 4.5823  Validation loss = 1.1010  \n",
      "\n",
      "Fold: 18  Epoch: 730  Training loss = 4.5820  Validation loss = 1.1009  \n",
      "\n",
      "Fold: 18  Epoch: 731  Training loss = 4.5815  Validation loss = 1.1008  \n",
      "\n",
      "Fold: 18  Epoch: 732  Training loss = 4.5813  Validation loss = 1.1007  \n",
      "\n",
      "Fold: 18  Epoch: 733  Training loss = 4.5809  Validation loss = 1.1005  \n",
      "\n",
      "Fold: 18  Epoch: 734  Training loss = 4.5806  Validation loss = 1.1004  \n",
      "\n",
      "Fold: 18  Epoch: 735  Training loss = 4.5803  Validation loss = 1.1003  \n",
      "\n",
      "Fold: 18  Epoch: 736  Training loss = 4.5799  Validation loss = 1.1002  \n",
      "\n",
      "Fold: 18  Epoch: 737  Training loss = 4.5796  Validation loss = 1.1000  \n",
      "\n",
      "Fold: 18  Epoch: 738  Training loss = 4.5793  Validation loss = 1.0999  \n",
      "\n",
      "Fold: 18  Epoch: 739  Training loss = 4.5789  Validation loss = 1.0998  \n",
      "\n",
      "Fold: 18  Epoch: 740  Training loss = 4.5784  Validation loss = 1.0996  \n",
      "\n",
      "Fold: 18  Epoch: 741  Training loss = 4.5780  Validation loss = 1.0995  \n",
      "\n",
      "Fold: 18  Epoch: 742  Training loss = 4.5777  Validation loss = 1.0993  \n",
      "\n",
      "Fold: 18  Epoch: 743  Training loss = 4.5773  Validation loss = 1.0992  \n",
      "\n",
      "Fold: 18  Epoch: 744  Training loss = 4.5770  Validation loss = 1.0991  \n",
      "\n",
      "Fold: 18  Epoch: 745  Training loss = 4.5766  Validation loss = 1.0989  \n",
      "\n",
      "Fold: 18  Epoch: 746  Training loss = 4.5761  Validation loss = 1.0988  \n",
      "\n",
      "Fold: 18  Epoch: 747  Training loss = 4.5758  Validation loss = 1.0986  \n",
      "\n",
      "Fold: 18  Epoch: 748  Training loss = 4.5753  Validation loss = 1.0985  \n",
      "\n",
      "Fold: 18  Epoch: 749  Training loss = 4.5749  Validation loss = 1.0983  \n",
      "\n",
      "Fold: 18  Epoch: 750  Training loss = 4.5745  Validation loss = 1.0982  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 750  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 4.5642  Validation loss = 2.2059  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 4.5639  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 4.5635  Validation loss = 2.2059  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 4.5630  Validation loss = 2.2059  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 4.5627  Validation loss = 2.2059  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 4.5624  Validation loss = 2.2059  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 4.5620  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 4.5616  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 4.5612  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 4.5608  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 4.5605  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 4.5602  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 4.5598  Validation loss = 2.2057  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 4.5594  Validation loss = 2.2057  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 4.5591  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 4.5588  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 4.5583  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 4.5579  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 4.5575  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 4.5571  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 4.5567  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 4.5564  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 4.5561  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 4.5556  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 4.5552  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 4.5548  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 4.5544  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 4.5540  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 4.5536  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 4.5533  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 4.5529  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 4.5526  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 4.5522  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 4.5519  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 4.5515  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 4.5511  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 4.5508  Validation loss = 2.2056  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 34  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 4.5790  Validation loss = 0.9847  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 4.5786  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 4.5783  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 4.5779  Validation loss = 0.9845  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 4.5775  Validation loss = 0.9845  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 4.5771  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 4.5768  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 4.5764  Validation loss = 0.9842  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 4.5761  Validation loss = 0.9841  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 4.5756  Validation loss = 0.9841  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 4.5753  Validation loss = 0.9840  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 4.5749  Validation loss = 0.9839  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 4.5745  Validation loss = 0.9839  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 4.5741  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 4.5737  Validation loss = 0.9837  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 4.5733  Validation loss = 0.9836  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 4.5730  Validation loss = 0.9836  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 4.5726  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 4.5723  Validation loss = 0.9834  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 4.5719  Validation loss = 0.9834  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 4.5716  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 4.5713  Validation loss = 0.9831  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 4.5709  Validation loss = 0.9830  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 4.5706  Validation loss = 0.9830  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 4.5702  Validation loss = 0.9829  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 4.5698  Validation loss = 0.9828  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 4.5693  Validation loss = 0.9827  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 4.5690  Validation loss = 0.9826  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 4.5687  Validation loss = 0.9825  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 4.5683  Validation loss = 0.9824  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 4.5679  Validation loss = 0.9824  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 4.5676  Validation loss = 0.9823  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 4.5672  Validation loss = 0.9823  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 4.5669  Validation loss = 0.9822  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 4.5666  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 4.5663  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 4.5660  Validation loss = 0.9820  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 4.5657  Validation loss = 0.9819  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 4.5654  Validation loss = 0.9819  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 4.5650  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 4.5647  Validation loss = 0.9817  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 4.5643  Validation loss = 0.9817  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 4.5639  Validation loss = 0.9816  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 4.5637  Validation loss = 0.9815  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 4.5633  Validation loss = 0.9815  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 4.5630  Validation loss = 0.9814  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 4.5627  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 4.5624  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 4.5620  Validation loss = 0.9812  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 4.5616  Validation loss = 0.9812  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 4.5614  Validation loss = 0.9812  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 4.5610  Validation loss = 0.9811  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 4.5607  Validation loss = 0.9811  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 4.5603  Validation loss = 0.9810  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 4.5599  Validation loss = 0.9809  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 4.5596  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 4.5592  Validation loss = 0.9806  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 4.5588  Validation loss = 0.9805  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 4.5586  Validation loss = 0.9804  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 4.5582  Validation loss = 0.9804  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 4.5579  Validation loss = 0.9803  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 4.5575  Validation loss = 0.9802  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 4.5572  Validation loss = 0.9802  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 4.5569  Validation loss = 0.9801  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 4.5565  Validation loss = 0.9800  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 4.5562  Validation loss = 0.9800  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 4.5558  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 4.5556  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 4.5552  Validation loss = 0.9798  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 4.5548  Validation loss = 0.9798  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 4.5544  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 4.5540  Validation loss = 0.9796  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 4.5538  Validation loss = 0.9795  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 4.5534  Validation loss = 0.9794  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 4.5530  Validation loss = 0.9793  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 4.5527  Validation loss = 0.9792  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 4.5524  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 4.5522  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 4.5518  Validation loss = 0.9790  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 4.5514  Validation loss = 0.9789  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 4.5511  Validation loss = 0.9788  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 4.5507  Validation loss = 0.9788  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 4.5504  Validation loss = 0.9787  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 4.5501  Validation loss = 0.9787  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 4.5497  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 4.5495  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 4.5492  Validation loss = 0.9785  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 4.5489  Validation loss = 0.9784  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 4.5485  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 4.5482  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 4.5479  Validation loss = 0.9782  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 4.5476  Validation loss = 0.9781  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 4.5472  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 4.5469  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 4.5465  Validation loss = 0.9779  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 4.5462  Validation loss = 0.9778  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 4.5458  Validation loss = 0.9777  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 4.5454  Validation loss = 0.9777  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 4.5451  Validation loss = 0.9776  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 4.5447  Validation loss = 0.9775  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 4.5443  Validation loss = 0.9775  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 4.5439  Validation loss = 0.9775  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 4.5435  Validation loss = 0.9774  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 4.5433  Validation loss = 0.9773  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 4.5429  Validation loss = 0.9773  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 4.5425  Validation loss = 0.9772  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 4.5421  Validation loss = 0.9772  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 4.5418  Validation loss = 0.9771  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 4.5414  Validation loss = 0.9771  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 4.5411  Validation loss = 0.9770  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 4.5408  Validation loss = 0.9770  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 4.5404  Validation loss = 0.9769  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 4.5401  Validation loss = 0.9769  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 4.5397  Validation loss = 0.9768  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 4.5394  Validation loss = 0.9767  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 4.5390  Validation loss = 0.9767  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 4.5388  Validation loss = 0.9766  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 4.5384  Validation loss = 0.9766  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 4.5381  Validation loss = 0.9765  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 4.5377  Validation loss = 0.9765  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 4.5374  Validation loss = 0.9764  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 4.5371  Validation loss = 0.9763  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 4.5367  Validation loss = 0.9763  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 4.5364  Validation loss = 0.9762  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 4.5360  Validation loss = 0.9761  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 4.5357  Validation loss = 0.9760  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 4.5354  Validation loss = 0.9760  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 4.5350  Validation loss = 0.9759  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 4.5347  Validation loss = 0.9758  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 4.5343  Validation loss = 0.9757  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 4.5340  Validation loss = 0.9756  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 4.5337  Validation loss = 0.9755  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 4.5333  Validation loss = 0.9754  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 4.5329  Validation loss = 0.9753  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 4.5326  Validation loss = 0.9752  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 4.5323  Validation loss = 0.9752  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 4.5319  Validation loss = 0.9752  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 4.5316  Validation loss = 0.9751  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 4.5312  Validation loss = 0.9750  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 4.5308  Validation loss = 0.9750  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 4.5305  Validation loss = 0.9749  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 4.5301  Validation loss = 0.9748  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 4.5298  Validation loss = 0.9747  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 4.5295  Validation loss = 0.9747  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 4.5292  Validation loss = 0.9746  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 4.5288  Validation loss = 0.9746  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 4.5285  Validation loss = 0.9745  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 4.5282  Validation loss = 0.9745  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 4.5278  Validation loss = 0.9744  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 4.5275  Validation loss = 0.9743  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 4.5272  Validation loss = 0.9742  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 4.5268  Validation loss = 0.9742  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 4.5265  Validation loss = 0.9741  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 4.5261  Validation loss = 0.9741  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 4.5257  Validation loss = 0.9740  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 4.5253  Validation loss = 0.9740  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 4.5249  Validation loss = 0.9739  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 4.5247  Validation loss = 0.9739  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 4.5243  Validation loss = 0.9738  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 4.5239  Validation loss = 0.9738  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 4.5235  Validation loss = 0.9738  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 4.5232  Validation loss = 0.9736  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 4.5228  Validation loss = 0.9736  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 4.5225  Validation loss = 0.9735  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 4.5222  Validation loss = 0.9734  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 4.5219  Validation loss = 0.9734  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 4.5216  Validation loss = 0.9734  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 4.5212  Validation loss = 0.9734  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 4.5209  Validation loss = 0.9733  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 4.5206  Validation loss = 0.9733  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 4.5202  Validation loss = 0.9733  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 4.5199  Validation loss = 0.9733  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 4.5195  Validation loss = 0.9732  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 4.5192  Validation loss = 0.9732  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 4.5189  Validation loss = 0.9731  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 4.5186  Validation loss = 0.9730  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 4.5183  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 4.5180  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 4.5176  Validation loss = 0.9728  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 4.5172  Validation loss = 0.9727  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 4.5170  Validation loss = 0.9727  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 4.5167  Validation loss = 0.9727  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 4.5163  Validation loss = 0.9726  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 4.5161  Validation loss = 0.9725  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 4.5157  Validation loss = 0.9725  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 4.5153  Validation loss = 0.9724  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 4.5150  Validation loss = 0.9723  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 4.5147  Validation loss = 0.9722  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 4.5144  Validation loss = 0.9721  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 4.5140  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 4.5137  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 4.5133  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 4.5130  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 4.5126  Validation loss = 0.9719  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 4.5123  Validation loss = 0.9719  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 4.5119  Validation loss = 0.9718  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 4.5115  Validation loss = 0.9718  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 4.5111  Validation loss = 0.9716  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 4.5107  Validation loss = 0.9715  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 4.5104  Validation loss = 0.9715  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 4.5101  Validation loss = 0.9715  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 4.5098  Validation loss = 0.9715  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 4.5094  Validation loss = 0.9714  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 4.5092  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 4.5088  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 4.5085  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 4.5081  Validation loss = 0.9712  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 4.5078  Validation loss = 0.9711  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 4.5074  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 4.5071  Validation loss = 0.9711  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 4.5069  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 4.5066  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 4.5062  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 4.5058  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 4.5055  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 4.5052  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 4.5049  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 4.5045  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 4.5043  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 4.5040  Validation loss = 0.9708  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 4.5036  Validation loss = 0.9707  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 4.5032  Validation loss = 0.9707  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 4.5030  Validation loss = 0.9707  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 4.5027  Validation loss = 0.9706  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 4.5024  Validation loss = 0.9706  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 4.5021  Validation loss = 0.9705  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 4.5017  Validation loss = 0.9705  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 4.5013  Validation loss = 0.9704  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 4.5010  Validation loss = 0.9703  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 4.5007  Validation loss = 0.9703  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 4.5004  Validation loss = 0.9702  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 4.5000  Validation loss = 0.9702  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 4.4997  Validation loss = 0.9700  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 4.4993  Validation loss = 0.9699  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 4.4991  Validation loss = 0.9699  \n",
      "\n",
      "Fold: 20  Epoch: 236  Training loss = 4.4987  Validation loss = 0.9699  \n",
      "\n",
      "Fold: 20  Epoch: 237  Training loss = 4.4984  Validation loss = 0.9698  \n",
      "\n",
      "Fold: 20  Epoch: 238  Training loss = 4.4982  Validation loss = 0.9698  \n",
      "\n",
      "Fold: 20  Epoch: 239  Training loss = 4.4977  Validation loss = 0.9698  \n",
      "\n",
      "Fold: 20  Epoch: 240  Training loss = 4.4974  Validation loss = 0.9698  \n",
      "\n",
      "Fold: 20  Epoch: 241  Training loss = 4.4971  Validation loss = 0.9697  \n",
      "\n",
      "Fold: 20  Epoch: 242  Training loss = 4.4968  Validation loss = 0.9697  \n",
      "\n",
      "Fold: 20  Epoch: 243  Training loss = 4.4965  Validation loss = 0.9697  \n",
      "\n",
      "Fold: 20  Epoch: 244  Training loss = 4.4961  Validation loss = 0.9697  \n",
      "\n",
      "Fold: 20  Epoch: 245  Training loss = 4.4958  Validation loss = 0.9696  \n",
      "\n",
      "Fold: 20  Epoch: 246  Training loss = 4.4954  Validation loss = 0.9696  \n",
      "\n",
      "Fold: 20  Epoch: 247  Training loss = 4.4951  Validation loss = 0.9696  \n",
      "\n",
      "Fold: 20  Epoch: 248  Training loss = 4.4947  Validation loss = 0.9696  \n",
      "\n",
      "Fold: 20  Epoch: 249  Training loss = 4.4944  Validation loss = 0.9696  \n",
      "\n",
      "Fold: 20  Epoch: 250  Training loss = 4.4940  Validation loss = 0.9695  \n",
      "\n",
      "Fold: 20  Epoch: 251  Training loss = 4.4938  Validation loss = 0.9695  \n",
      "\n",
      "Fold: 20  Epoch: 252  Training loss = 4.4934  Validation loss = 0.9693  \n",
      "\n",
      "Fold: 20  Epoch: 253  Training loss = 4.4932  Validation loss = 0.9693  \n",
      "\n",
      "Fold: 20  Epoch: 254  Training loss = 4.4929  Validation loss = 0.9692  \n",
      "\n",
      "Fold: 20  Epoch: 255  Training loss = 4.4926  Validation loss = 0.9692  \n",
      "\n",
      "Fold: 20  Epoch: 256  Training loss = 4.4922  Validation loss = 0.9691  \n",
      "\n",
      "Fold: 20  Epoch: 257  Training loss = 4.4919  Validation loss = 0.9690  \n",
      "\n",
      "Fold: 20  Epoch: 258  Training loss = 4.4915  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 20  Epoch: 259  Training loss = 4.4911  Validation loss = 0.9688  \n",
      "\n",
      "Fold: 20  Epoch: 260  Training loss = 4.4908  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 20  Epoch: 261  Training loss = 4.4904  Validation loss = 0.9688  \n",
      "\n",
      "Fold: 20  Epoch: 262  Training loss = 4.4901  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 20  Epoch: 263  Training loss = 4.4898  Validation loss = 0.9687  \n",
      "\n",
      "Fold: 20  Epoch: 264  Training loss = 4.4895  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 20  Epoch: 265  Training loss = 4.4891  Validation loss = 0.9686  \n",
      "\n",
      "Fold: 20  Epoch: 266  Training loss = 4.4888  Validation loss = 0.9685  \n",
      "\n",
      "Fold: 20  Epoch: 267  Training loss = 4.4885  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 20  Epoch: 268  Training loss = 4.4883  Validation loss = 0.9684  \n",
      "\n",
      "Fold: 20  Epoch: 269  Training loss = 4.4880  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 20  Epoch: 270  Training loss = 4.4877  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 20  Epoch: 271  Training loss = 4.4874  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 20  Epoch: 272  Training loss = 4.4871  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 20  Epoch: 273  Training loss = 4.4868  Validation loss = 0.9682  \n",
      "\n",
      "Fold: 20  Epoch: 274  Training loss = 4.4865  Validation loss = 0.9682  \n",
      "\n",
      "Fold: 20  Epoch: 275  Training loss = 4.4861  Validation loss = 0.9682  \n",
      "\n",
      "Fold: 20  Epoch: 276  Training loss = 4.4857  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 20  Epoch: 277  Training loss = 4.4854  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 20  Epoch: 278  Training loss = 4.4851  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 20  Epoch: 279  Training loss = 4.4848  Validation loss = 0.9680  \n",
      "\n",
      "Fold: 20  Epoch: 280  Training loss = 4.4845  Validation loss = 0.9680  \n",
      "\n",
      "Fold: 20  Epoch: 281  Training loss = 4.4842  Validation loss = 0.9680  \n",
      "\n",
      "Fold: 20  Epoch: 282  Training loss = 4.4839  Validation loss = 0.9680  \n",
      "\n",
      "Fold: 20  Epoch: 283  Training loss = 4.4835  Validation loss = 0.9680  \n",
      "\n",
      "Fold: 20  Epoch: 284  Training loss = 4.4832  Validation loss = 0.9679  \n",
      "\n",
      "Fold: 20  Epoch: 285  Training loss = 4.4829  Validation loss = 0.9679  \n",
      "\n",
      "Fold: 20  Epoch: 286  Training loss = 4.4826  Validation loss = 0.9679  \n",
      "\n",
      "Fold: 20  Epoch: 287  Training loss = 4.4823  Validation loss = 0.9679  \n",
      "\n",
      "Fold: 20  Epoch: 288  Training loss = 4.4819  Validation loss = 0.9678  \n",
      "\n",
      "Fold: 20  Epoch: 289  Training loss = 4.4815  Validation loss = 0.9678  \n",
      "\n",
      "Fold: 20  Epoch: 290  Training loss = 4.4813  Validation loss = 0.9677  \n",
      "\n",
      "Fold: 20  Epoch: 291  Training loss = 4.4810  Validation loss = 0.9676  \n",
      "\n",
      "Fold: 20  Epoch: 292  Training loss = 4.4807  Validation loss = 0.9676  \n",
      "\n",
      "Fold: 20  Epoch: 293  Training loss = 4.4803  Validation loss = 0.9676  \n",
      "\n",
      "Fold: 20  Epoch: 294  Training loss = 4.4801  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 20  Epoch: 295  Training loss = 4.4797  Validation loss = 0.9674  \n",
      "\n",
      "Fold: 20  Epoch: 296  Training loss = 4.4794  Validation loss = 0.9674  \n",
      "\n",
      "Fold: 20  Epoch: 297  Training loss = 4.4790  Validation loss = 0.9674  \n",
      "\n",
      "Fold: 20  Epoch: 298  Training loss = 4.4786  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 299  Training loss = 4.4783  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 300  Training loss = 4.4780  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 301  Training loss = 4.4777  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 302  Training loss = 4.4774  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 303  Training loss = 4.4770  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 304  Training loss = 4.4767  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 305  Training loss = 4.4764  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 306  Training loss = 4.4761  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 307  Training loss = 4.4757  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 308  Training loss = 4.4753  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 309  Training loss = 4.4750  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 310  Training loss = 4.4747  Validation loss = 0.9672  \n",
      "\n",
      "Fold: 20  Epoch: 311  Training loss = 4.4744  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 312  Training loss = 4.4741  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 313  Training loss = 4.4739  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 314  Training loss = 4.4736  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 315  Training loss = 4.4733  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 316  Training loss = 4.4730  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 317  Training loss = 4.4727  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 318  Training loss = 4.4724  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 319  Training loss = 4.4720  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 320  Training loss = 4.4716  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 321  Training loss = 4.4713  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 322  Training loss = 4.4710  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 20  Epoch: 323  Training loss = 4.4707  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 324  Training loss = 4.4704  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 325  Training loss = 4.4701  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 326  Training loss = 4.4697  Validation loss = 0.9670  \n",
      "\n",
      "Fold: 20  Epoch: 327  Training loss = 4.4695  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 328  Training loss = 4.4691  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 329  Training loss = 4.4688  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 330  Training loss = 4.4685  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 331  Training loss = 4.4682  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 332  Training loss = 4.4678  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 20  Epoch: 333  Training loss = 4.4675  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 334  Training loss = 4.4671  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 20  Epoch: 335  Training loss = 4.4668  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 20  Epoch: 336  Training loss = 4.4665  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 20  Epoch: 337  Training loss = 4.4661  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 20  Epoch: 338  Training loss = 4.4658  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 20  Epoch: 339  Training loss = 4.4655  Validation loss = 0.9666  \n",
      "\n",
      "Fold: 20  Epoch: 340  Training loss = 4.4652  Validation loss = 0.9666  \n",
      "\n",
      "Fold: 20  Epoch: 341  Training loss = 4.4648  Validation loss = 0.9665  \n",
      "\n",
      "Fold: 20  Epoch: 342  Training loss = 4.4645  Validation loss = 0.9665  \n",
      "\n",
      "Fold: 20  Epoch: 343  Training loss = 4.4641  Validation loss = 0.9664  \n",
      "\n",
      "Fold: 20  Epoch: 344  Training loss = 4.4638  Validation loss = 0.9664  \n",
      "\n",
      "Fold: 20  Epoch: 345  Training loss = 4.4635  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 346  Training loss = 4.4632  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 347  Training loss = 4.4629  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 348  Training loss = 4.4625  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 349  Training loss = 4.4622  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 350  Training loss = 4.4618  Validation loss = 0.9663  \n",
      "\n",
      "Fold: 20  Epoch: 351  Training loss = 4.4615  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 20  Epoch: 352  Training loss = 4.4611  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 20  Epoch: 353  Training loss = 4.4607  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 354  Training loss = 4.4604  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 355  Training loss = 4.4602  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 356  Training loss = 4.4598  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 357  Training loss = 4.4595  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 358  Training loss = 4.4592  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 20  Epoch: 359  Training loss = 4.4589  Validation loss = 0.9660  \n",
      "\n",
      "Fold: 20  Epoch: 360  Training loss = 4.4586  Validation loss = 0.9660  \n",
      "\n",
      "Fold: 20  Epoch: 361  Training loss = 4.4582  Validation loss = 0.9659  \n",
      "\n",
      "Fold: 20  Epoch: 362  Training loss = 4.4578  Validation loss = 0.9659  \n",
      "\n",
      "Fold: 20  Epoch: 363  Training loss = 4.4575  Validation loss = 0.9658  \n",
      "\n",
      "Fold: 20  Epoch: 364  Training loss = 4.4571  Validation loss = 0.9657  \n",
      "\n",
      "Fold: 20  Epoch: 365  Training loss = 4.4567  Validation loss = 0.9657  \n",
      "\n",
      "Fold: 20  Epoch: 366  Training loss = 4.4565  Validation loss = 0.9657  \n",
      "\n",
      "Fold: 20  Epoch: 367  Training loss = 4.4561  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 368  Training loss = 4.4559  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 369  Training loss = 4.4556  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 370  Training loss = 4.4554  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 371  Training loss = 4.4551  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 372  Training loss = 4.4547  Validation loss = 0.9655  \n",
      "\n",
      "Fold: 20  Epoch: 373  Training loss = 4.4543  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 374  Training loss = 4.4541  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 375  Training loss = 4.4537  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 376  Training loss = 4.4534  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 377  Training loss = 4.4530  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 378  Training loss = 4.4527  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 379  Training loss = 4.4523  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 380  Training loss = 4.4520  Validation loss = 0.9655  \n",
      "\n",
      "Fold: 20  Epoch: 381  Training loss = 4.4517  Validation loss = 0.9655  \n",
      "\n",
      "Fold: 20  Epoch: 382  Training loss = 4.4514  Validation loss = 0.9655  \n",
      "\n",
      "Fold: 20  Epoch: 383  Training loss = 4.4511  Validation loss = 0.9655  \n",
      "\n",
      "Fold: 20  Epoch: 384  Training loss = 4.4508  Validation loss = 0.9654  \n",
      "\n",
      "Fold: 20  Epoch: 385  Training loss = 4.4504  Validation loss = 0.9654  \n",
      "\n",
      "Fold: 20  Epoch: 386  Training loss = 4.4501  Validation loss = 0.9653  \n",
      "\n",
      "Fold: 20  Epoch: 387  Training loss = 4.4498  Validation loss = 0.9653  \n",
      "\n",
      "Fold: 20  Epoch: 388  Training loss = 4.4494  Validation loss = 0.9652  \n",
      "\n",
      "Fold: 20  Epoch: 389  Training loss = 4.4492  Validation loss = 0.9652  \n",
      "\n",
      "Fold: 20  Epoch: 390  Training loss = 4.4488  Validation loss = 0.9651  \n",
      "\n",
      "Fold: 20  Epoch: 391  Training loss = 4.4485  Validation loss = 0.9651  \n",
      "\n",
      "Fold: 20  Epoch: 392  Training loss = 4.4482  Validation loss = 0.9651  \n",
      "\n",
      "Fold: 20  Epoch: 393  Training loss = 4.4480  Validation loss = 0.9651  \n",
      "\n",
      "Fold: 20  Epoch: 394  Training loss = 4.4477  Validation loss = 0.9650  \n",
      "\n",
      "Fold: 20  Epoch: 395  Training loss = 4.4475  Validation loss = 0.9650  \n",
      "\n",
      "Fold: 20  Epoch: 396  Training loss = 4.4471  Validation loss = 0.9650  \n",
      "\n",
      "Fold: 20  Epoch: 397  Training loss = 4.4467  Validation loss = 0.9650  \n",
      "\n",
      "Fold: 20  Epoch: 398  Training loss = 4.4464  Validation loss = 0.9650  \n",
      "\n",
      "Fold: 20  Epoch: 399  Training loss = 4.4460  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 20  Epoch: 400  Training loss = 4.4457  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 20  Epoch: 401  Training loss = 4.4454  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 20  Epoch: 402  Training loss = 4.4451  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 20  Epoch: 403  Training loss = 4.4449  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 20  Epoch: 404  Training loss = 4.4446  Validation loss = 0.9648  \n",
      "\n",
      "Fold: 20  Epoch: 405  Training loss = 4.4443  Validation loss = 0.9648  \n",
      "\n",
      "Fold: 20  Epoch: 406  Training loss = 4.4439  Validation loss = 0.9647  \n",
      "\n",
      "Fold: 20  Epoch: 407  Training loss = 4.4436  Validation loss = 0.9647  \n",
      "\n",
      "Fold: 20  Epoch: 408  Training loss = 4.4433  Validation loss = 0.9648  \n",
      "\n",
      "Fold: 20  Epoch: 409  Training loss = 4.4431  Validation loss = 0.9647  \n",
      "\n",
      "Fold: 20  Epoch: 410  Training loss = 4.4427  Validation loss = 0.9647  \n",
      "\n",
      "Fold: 20  Epoch: 411  Training loss = 4.4423  Validation loss = 0.9647  \n",
      "\n",
      "Fold: 20  Epoch: 412  Training loss = 4.4420  Validation loss = 0.9647  \n",
      "\n",
      "Fold: 20  Epoch: 413  Training loss = 4.4417  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 414  Training loss = 4.4414  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 415  Training loss = 4.4410  Validation loss = 0.9647  \n",
      "\n",
      "Fold: 20  Epoch: 416  Training loss = 4.4407  Validation loss = 0.9647  \n",
      "\n",
      "Fold: 20  Epoch: 417  Training loss = 4.4404  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 418  Training loss = 4.4400  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 419  Training loss = 4.4397  Validation loss = 0.9647  \n",
      "\n",
      "Fold: 20  Epoch: 420  Training loss = 4.4394  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 421  Training loss = 4.4391  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 422  Training loss = 4.4388  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 423  Training loss = 4.4385  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 424  Training loss = 4.4382  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 425  Training loss = 4.4379  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 426  Training loss = 4.4376  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 427  Training loss = 4.4373  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 428  Training loss = 4.4369  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 429  Training loss = 4.4367  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 430  Training loss = 4.4364  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 431  Training loss = 4.4361  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 432  Training loss = 4.4358  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 433  Training loss = 4.4354  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 434  Training loss = 4.4350  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 435  Training loss = 4.4348  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 436  Training loss = 4.4344  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 437  Training loss = 4.4340  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 20  Epoch: 438  Training loss = 4.4337  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 439  Training loss = 4.4334  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 440  Training loss = 4.4330  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 441  Training loss = 4.4327  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 442  Training loss = 4.4325  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 443  Training loss = 4.4322  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 444  Training loss = 4.4319  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 445  Training loss = 4.4315  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 446  Training loss = 4.4312  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 447  Training loss = 4.4309  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 20  Epoch: 448  Training loss = 4.4306  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 449  Training loss = 4.4303  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 450  Training loss = 4.4300  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 451  Training loss = 4.4297  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 452  Training loss = 4.4294  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 453  Training loss = 4.4291  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 454  Training loss = 4.4289  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 455  Training loss = 4.4286  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 456  Training loss = 4.4283  Validation loss = 0.9643  \n",
      "\n",
      "Fold: 20  Epoch: 457  Training loss = 4.4280  Validation loss = 0.9642  \n",
      "\n",
      "Fold: 20  Epoch: 458  Training loss = 4.4276  Validation loss = 0.9642  \n",
      "\n",
      "Fold: 20  Epoch: 459  Training loss = 4.4273  Validation loss = 0.9642  \n",
      "\n",
      "Fold: 20  Epoch: 460  Training loss = 4.4270  Validation loss = 0.9642  \n",
      "\n",
      "Fold: 20  Epoch: 461  Training loss = 4.4268  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 462  Training loss = 4.4265  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 463  Training loss = 4.4262  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 464  Training loss = 4.4260  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 465  Training loss = 4.4256  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 466  Training loss = 4.4253  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 467  Training loss = 4.4249  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 468  Training loss = 4.4246  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 469  Training loss = 4.4243  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 470  Training loss = 4.4239  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 471  Training loss = 4.4236  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 472  Training loss = 4.4233  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 473  Training loss = 4.4229  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 474  Training loss = 4.4226  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 475  Training loss = 4.4224  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 476  Training loss = 4.4222  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 20  Epoch: 477  Training loss = 4.4218  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 478  Training loss = 4.4215  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 479  Training loss = 4.4213  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 480  Training loss = 4.4210  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 481  Training loss = 4.4207  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 482  Training loss = 4.4205  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 483  Training loss = 4.4202  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 484  Training loss = 4.4199  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 20  Epoch: 485  Training loss = 4.4196  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 20  Epoch: 486  Training loss = 4.4193  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 20  Epoch: 487  Training loss = 4.4189  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 20  Epoch: 488  Training loss = 4.4186  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 20  Epoch: 489  Training loss = 4.4183  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 20  Epoch: 490  Training loss = 4.4180  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 20  Epoch: 491  Training loss = 4.4177  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 20  Epoch: 492  Training loss = 4.4174  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 20  Epoch: 493  Training loss = 4.4171  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 494  Training loss = 4.4167  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 495  Training loss = 4.4163  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 496  Training loss = 4.4160  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 497  Training loss = 4.4157  Validation loss = 0.9637  \n",
      "\n",
      "Fold: 20  Epoch: 498  Training loss = 4.4154  Validation loss = 0.9637  \n",
      "\n",
      "Fold: 20  Epoch: 499  Training loss = 4.4151  Validation loss = 0.9637  \n",
      "\n",
      "Fold: 20  Epoch: 500  Training loss = 4.4147  Validation loss = 0.9637  \n",
      "\n",
      "Fold: 20  Epoch: 501  Training loss = 4.4144  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 502  Training loss = 4.4141  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 503  Training loss = 4.4138  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 504  Training loss = 4.4135  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 505  Training loss = 4.4133  Validation loss = 0.9637  \n",
      "\n",
      "Fold: 20  Epoch: 506  Training loss = 4.4129  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 507  Training loss = 4.4125  Validation loss = 0.9637  \n",
      "\n",
      "Fold: 20  Epoch: 508  Training loss = 4.4122  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 509  Training loss = 4.4119  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 510  Training loss = 4.4116  Validation loss = 0.9638  \n",
      "\n",
      "Fold: 20  Epoch: 511  Training loss = 4.4113  Validation loss = 0.9638  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 499  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 4.4019  Validation loss = 3.4783  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 4.4015  Validation loss = 3.4788  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 4.4013  Validation loss = 3.4792  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 4.4010  Validation loss = 3.4796  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 4.4007  Validation loss = 3.4800  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 4.4003  Validation loss = 3.4804  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 4.4001  Validation loss = 3.4808  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 4.3998  Validation loss = 3.4812  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 4.3995  Validation loss = 3.4815  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 4.3992  Validation loss = 3.4820  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 4.3988  Validation loss = 3.4825  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 4.3985  Validation loss = 3.4829  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 4.3982  Validation loss = 3.4833  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 4.3980  Validation loss = 3.4836  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 4.3977  Validation loss = 3.4841  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 4.3973  Validation loss = 3.4845  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 4.4659  Validation loss = 2.3435  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 4.4657  Validation loss = 2.3434  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 4.4655  Validation loss = 2.3432  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 4.4652  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 4.4650  Validation loss = 2.3428  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 4.4648  Validation loss = 2.3427  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 4.4646  Validation loss = 2.3424  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 4.4644  Validation loss = 2.3421  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 4.4641  Validation loss = 2.3419  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 4.4640  Validation loss = 2.3416  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 4.4638  Validation loss = 2.3414  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 4.4635  Validation loss = 2.3413  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 4.4633  Validation loss = 2.3410  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 4.4630  Validation loss = 2.3408  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 4.4628  Validation loss = 2.3406  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 4.4625  Validation loss = 2.3402  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 4.4623  Validation loss = 2.3402  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 4.4621  Validation loss = 2.3399  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 4.4617  Validation loss = 2.3398  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 4.4615  Validation loss = 2.3395  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 4.4613  Validation loss = 2.3394  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 4.4610  Validation loss = 2.3392  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 4.4608  Validation loss = 2.3391  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 4.4605  Validation loss = 2.3389  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 4.4602  Validation loss = 2.3388  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 4.4600  Validation loss = 2.3386  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 4.4597  Validation loss = 2.3385  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 4.4594  Validation loss = 2.3384  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 4.4592  Validation loss = 2.3383  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 4.4590  Validation loss = 2.3381  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 4.4587  Validation loss = 2.3381  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 4.4585  Validation loss = 2.3379  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 4.4582  Validation loss = 2.3376  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 4.4580  Validation loss = 2.3374  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 4.4578  Validation loss = 2.3372  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 4.4575  Validation loss = 2.3369  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 4.4573  Validation loss = 2.3367  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 4.4571  Validation loss = 2.3366  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 4.4568  Validation loss = 2.3365  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 4.4565  Validation loss = 2.3361  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 4.4563  Validation loss = 2.3360  \n",
      "\n",
      "Fold: 22  Epoch: 42  Training loss = 4.4561  Validation loss = 2.3358  \n",
      "\n",
      "Fold: 22  Epoch: 43  Training loss = 4.4558  Validation loss = 2.3356  \n",
      "\n",
      "Fold: 22  Epoch: 44  Training loss = 4.4556  Validation loss = 2.3354  \n",
      "\n",
      "Fold: 22  Epoch: 45  Training loss = 4.4554  Validation loss = 2.3352  \n",
      "\n",
      "Fold: 22  Epoch: 46  Training loss = 4.4551  Validation loss = 2.3351  \n",
      "\n",
      "Fold: 22  Epoch: 47  Training loss = 4.4549  Validation loss = 2.3349  \n",
      "\n",
      "Fold: 22  Epoch: 48  Training loss = 4.4547  Validation loss = 2.3347  \n",
      "\n",
      "Fold: 22  Epoch: 49  Training loss = 4.4545  Validation loss = 2.3344  \n",
      "\n",
      "Fold: 22  Epoch: 50  Training loss = 4.4543  Validation loss = 2.3343  \n",
      "\n",
      "Fold: 22  Epoch: 51  Training loss = 4.4541  Validation loss = 2.3342  \n",
      "\n",
      "Fold: 22  Epoch: 52  Training loss = 4.4538  Validation loss = 2.3340  \n",
      "\n",
      "Fold: 22  Epoch: 53  Training loss = 4.4536  Validation loss = 2.3339  \n",
      "\n",
      "Fold: 22  Epoch: 54  Training loss = 4.4534  Validation loss = 2.3337  \n",
      "\n",
      "Fold: 22  Epoch: 55  Training loss = 4.4531  Validation loss = 2.3336  \n",
      "\n",
      "Fold: 22  Epoch: 56  Training loss = 4.4529  Validation loss = 2.3335  \n",
      "\n",
      "Fold: 22  Epoch: 57  Training loss = 4.4526  Validation loss = 2.3332  \n",
      "\n",
      "Fold: 22  Epoch: 58  Training loss = 4.4524  Validation loss = 2.3330  \n",
      "\n",
      "Fold: 22  Epoch: 59  Training loss = 4.4521  Validation loss = 2.3329  \n",
      "\n",
      "Fold: 22  Epoch: 60  Training loss = 4.4519  Validation loss = 2.3328  \n",
      "\n",
      "Fold: 22  Epoch: 61  Training loss = 4.4517  Validation loss = 2.3326  \n",
      "\n",
      "Fold: 22  Epoch: 62  Training loss = 4.4515  Validation loss = 2.3323  \n",
      "\n",
      "Fold: 22  Epoch: 63  Training loss = 4.4513  Validation loss = 2.3321  \n",
      "\n",
      "Fold: 22  Epoch: 64  Training loss = 4.4511  Validation loss = 2.3320  \n",
      "\n",
      "Fold: 22  Epoch: 65  Training loss = 4.4509  Validation loss = 2.3317  \n",
      "\n",
      "Fold: 22  Epoch: 66  Training loss = 4.4507  Validation loss = 2.3316  \n",
      "\n",
      "Fold: 22  Epoch: 67  Training loss = 4.4505  Validation loss = 2.3314  \n",
      "\n",
      "Fold: 22  Epoch: 68  Training loss = 4.4502  Validation loss = 2.3312  \n",
      "\n",
      "Fold: 22  Epoch: 69  Training loss = 4.4500  Validation loss = 2.3310  \n",
      "\n",
      "Fold: 22  Epoch: 70  Training loss = 4.4498  Validation loss = 2.3308  \n",
      "\n",
      "Fold: 22  Epoch: 71  Training loss = 4.4495  Validation loss = 2.3307  \n",
      "\n",
      "Fold: 22  Epoch: 72  Training loss = 4.4492  Validation loss = 2.3303  \n",
      "\n",
      "Fold: 22  Epoch: 73  Training loss = 4.4490  Validation loss = 2.3301  \n",
      "\n",
      "Fold: 22  Epoch: 74  Training loss = 4.4488  Validation loss = 2.3298  \n",
      "\n",
      "Fold: 22  Epoch: 75  Training loss = 4.4486  Validation loss = 2.3296  \n",
      "\n",
      "Fold: 22  Epoch: 76  Training loss = 4.4483  Validation loss = 2.3294  \n",
      "\n",
      "Fold: 22  Epoch: 77  Training loss = 4.4480  Validation loss = 2.3293  \n",
      "\n",
      "Fold: 22  Epoch: 78  Training loss = 4.4478  Validation loss = 2.3290  \n",
      "\n",
      "Fold: 22  Epoch: 79  Training loss = 4.4475  Validation loss = 2.3289  \n",
      "\n",
      "Fold: 22  Epoch: 80  Training loss = 4.4472  Validation loss = 2.3286  \n",
      "\n",
      "Fold: 22  Epoch: 81  Training loss = 4.4470  Validation loss = 2.3286  \n",
      "\n",
      "Fold: 22  Epoch: 82  Training loss = 4.4467  Validation loss = 2.3285  \n",
      "\n",
      "Fold: 22  Epoch: 83  Training loss = 4.4465  Validation loss = 2.3282  \n",
      "\n",
      "Fold: 22  Epoch: 84  Training loss = 4.4462  Validation loss = 2.3279  \n",
      "\n",
      "Fold: 22  Epoch: 85  Training loss = 4.4460  Validation loss = 2.3278  \n",
      "\n",
      "Fold: 22  Epoch: 86  Training loss = 4.4457  Validation loss = 2.3275  \n",
      "\n",
      "Fold: 22  Epoch: 87  Training loss = 4.4455  Validation loss = 2.3273  \n",
      "\n",
      "Fold: 22  Epoch: 88  Training loss = 4.4452  Validation loss = 2.3270  \n",
      "\n",
      "Fold: 22  Epoch: 89  Training loss = 4.4450  Validation loss = 2.3266  \n",
      "\n",
      "Fold: 22  Epoch: 90  Training loss = 4.4448  Validation loss = 2.3263  \n",
      "\n",
      "Fold: 22  Epoch: 91  Training loss = 4.4445  Validation loss = 2.3262  \n",
      "\n",
      "Fold: 22  Epoch: 92  Training loss = 4.4443  Validation loss = 2.3259  \n",
      "\n",
      "Fold: 22  Epoch: 93  Training loss = 4.4440  Validation loss = 2.3257  \n",
      "\n",
      "Fold: 22  Epoch: 94  Training loss = 4.4438  Validation loss = 2.3255  \n",
      "\n",
      "Fold: 22  Epoch: 95  Training loss = 4.4436  Validation loss = 2.3253  \n",
      "\n",
      "Fold: 22  Epoch: 96  Training loss = 4.4432  Validation loss = 2.3251  \n",
      "\n",
      "Fold: 22  Epoch: 97  Training loss = 4.4430  Validation loss = 2.3249  \n",
      "\n",
      "Fold: 22  Epoch: 98  Training loss = 4.4428  Validation loss = 2.3248  \n",
      "\n",
      "Fold: 22  Epoch: 99  Training loss = 4.4425  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 22  Epoch: 100  Training loss = 4.4423  Validation loss = 2.3243  \n",
      "\n",
      "Fold: 22  Epoch: 101  Training loss = 4.4421  Validation loss = 2.3241  \n",
      "\n",
      "Fold: 22  Epoch: 102  Training loss = 4.4418  Validation loss = 2.3238  \n",
      "\n",
      "Fold: 22  Epoch: 103  Training loss = 4.4416  Validation loss = 2.3236  \n",
      "\n",
      "Fold: 22  Epoch: 104  Training loss = 4.4414  Validation loss = 2.3236  \n",
      "\n",
      "Fold: 22  Epoch: 105  Training loss = 4.4412  Validation loss = 2.3234  \n",
      "\n",
      "Fold: 22  Epoch: 106  Training loss = 4.4410  Validation loss = 2.3232  \n",
      "\n",
      "Fold: 22  Epoch: 107  Training loss = 4.4409  Validation loss = 2.3231  \n",
      "\n",
      "Fold: 22  Epoch: 108  Training loss = 4.4406  Validation loss = 2.3229  \n",
      "\n",
      "Fold: 22  Epoch: 109  Training loss = 4.4404  Validation loss = 2.3227  \n",
      "\n",
      "Fold: 22  Epoch: 110  Training loss = 4.4402  Validation loss = 2.3225  \n",
      "\n",
      "Fold: 22  Epoch: 111  Training loss = 4.4400  Validation loss = 2.3224  \n",
      "\n",
      "Fold: 22  Epoch: 112  Training loss = 4.4399  Validation loss = 2.3221  \n",
      "\n",
      "Fold: 22  Epoch: 113  Training loss = 4.4396  Validation loss = 2.3218  \n",
      "\n",
      "Fold: 22  Epoch: 114  Training loss = 4.4394  Validation loss = 2.3217  \n",
      "\n",
      "Fold: 22  Epoch: 115  Training loss = 4.4391  Validation loss = 2.3215  \n",
      "\n",
      "Fold: 22  Epoch: 116  Training loss = 4.4389  Validation loss = 2.3213  \n",
      "\n",
      "Fold: 22  Epoch: 117  Training loss = 4.4387  Validation loss = 2.3212  \n",
      "\n",
      "Fold: 22  Epoch: 118  Training loss = 4.4385  Validation loss = 2.3211  \n",
      "\n",
      "Fold: 22  Epoch: 119  Training loss = 4.4381  Validation loss = 2.3209  \n",
      "\n",
      "Fold: 22  Epoch: 120  Training loss = 4.4378  Validation loss = 2.3207  \n",
      "\n",
      "Fold: 22  Epoch: 121  Training loss = 4.4377  Validation loss = 2.3204  \n",
      "\n",
      "Fold: 22  Epoch: 122  Training loss = 4.4374  Validation loss = 2.3203  \n",
      "\n",
      "Fold: 22  Epoch: 123  Training loss = 4.4372  Validation loss = 2.3201  \n",
      "\n",
      "Fold: 22  Epoch: 124  Training loss = 4.4370  Validation loss = 2.3200  \n",
      "\n",
      "Fold: 22  Epoch: 125  Training loss = 4.4367  Validation loss = 2.3197  \n",
      "\n",
      "Fold: 22  Epoch: 126  Training loss = 4.4365  Validation loss = 2.3196  \n",
      "\n",
      "Fold: 22  Epoch: 127  Training loss = 4.4362  Validation loss = 2.3193  \n",
      "\n",
      "Fold: 22  Epoch: 128  Training loss = 4.4361  Validation loss = 2.3192  \n",
      "\n",
      "Fold: 22  Epoch: 129  Training loss = 4.4359  Validation loss = 2.3190  \n",
      "\n",
      "Fold: 22  Epoch: 130  Training loss = 4.4355  Validation loss = 2.3189  \n",
      "\n",
      "Fold: 22  Epoch: 131  Training loss = 4.4353  Validation loss = 2.3187  \n",
      "\n",
      "Fold: 22  Epoch: 132  Training loss = 4.4351  Validation loss = 2.3185  \n",
      "\n",
      "Fold: 22  Epoch: 133  Training loss = 4.4349  Validation loss = 2.3184  \n",
      "\n",
      "Fold: 22  Epoch: 134  Training loss = 4.4346  Validation loss = 2.3182  \n",
      "\n",
      "Fold: 22  Epoch: 135  Training loss = 4.4343  Validation loss = 2.3179  \n",
      "\n",
      "Fold: 22  Epoch: 136  Training loss = 4.4341  Validation loss = 2.3177  \n",
      "\n",
      "Fold: 22  Epoch: 137  Training loss = 4.4339  Validation loss = 2.3176  \n",
      "\n",
      "Fold: 22  Epoch: 138  Training loss = 4.4336  Validation loss = 2.3175  \n",
      "\n",
      "Fold: 22  Epoch: 139  Training loss = 4.4334  Validation loss = 2.3175  \n",
      "\n",
      "Fold: 22  Epoch: 140  Training loss = 4.4331  Validation loss = 2.3173  \n",
      "\n",
      "Fold: 22  Epoch: 141  Training loss = 4.4328  Validation loss = 2.3172  \n",
      "\n",
      "Fold: 22  Epoch: 142  Training loss = 4.4326  Validation loss = 2.3169  \n",
      "\n",
      "Fold: 22  Epoch: 143  Training loss = 4.4323  Validation loss = 2.3168  \n",
      "\n",
      "Fold: 22  Epoch: 144  Training loss = 4.4321  Validation loss = 2.3165  \n",
      "\n",
      "Fold: 22  Epoch: 145  Training loss = 4.4320  Validation loss = 2.3164  \n",
      "\n",
      "Fold: 22  Epoch: 146  Training loss = 4.4318  Validation loss = 2.3162  \n",
      "\n",
      "Fold: 22  Epoch: 147  Training loss = 4.4316  Validation loss = 2.3160  \n",
      "\n",
      "Fold: 22  Epoch: 148  Training loss = 4.4314  Validation loss = 2.3157  \n",
      "\n",
      "Fold: 22  Epoch: 149  Training loss = 4.4311  Validation loss = 2.3154  \n",
      "\n",
      "Fold: 22  Epoch: 150  Training loss = 4.4309  Validation loss = 2.3153  \n",
      "\n",
      "Fold: 22  Epoch: 151  Training loss = 4.4307  Validation loss = 2.3153  \n",
      "\n",
      "Fold: 22  Epoch: 152  Training loss = 4.4305  Validation loss = 2.3150  \n",
      "\n",
      "Fold: 22  Epoch: 153  Training loss = 4.4303  Validation loss = 2.3149  \n",
      "\n",
      "Fold: 22  Epoch: 154  Training loss = 4.4301  Validation loss = 2.3148  \n",
      "\n",
      "Fold: 22  Epoch: 155  Training loss = 4.4299  Validation loss = 2.3146  \n",
      "\n",
      "Fold: 22  Epoch: 156  Training loss = 4.4297  Validation loss = 2.3144  \n",
      "\n",
      "Fold: 22  Epoch: 157  Training loss = 4.4294  Validation loss = 2.3142  \n",
      "\n",
      "Fold: 22  Epoch: 158  Training loss = 4.4292  Validation loss = 2.3138  \n",
      "\n",
      "Fold: 22  Epoch: 159  Training loss = 4.4289  Validation loss = 2.3136  \n",
      "\n",
      "Fold: 22  Epoch: 160  Training loss = 4.4286  Validation loss = 2.3134  \n",
      "\n",
      "Fold: 22  Epoch: 161  Training loss = 4.4284  Validation loss = 2.3132  \n",
      "\n",
      "Fold: 22  Epoch: 162  Training loss = 4.4281  Validation loss = 2.3131  \n",
      "\n",
      "Fold: 22  Epoch: 163  Training loss = 4.4279  Validation loss = 2.3130  \n",
      "\n",
      "Fold: 22  Epoch: 164  Training loss = 4.4277  Validation loss = 2.3128  \n",
      "\n",
      "Fold: 22  Epoch: 165  Training loss = 4.4274  Validation loss = 2.3126  \n",
      "\n",
      "Fold: 22  Epoch: 166  Training loss = 4.4273  Validation loss = 2.3124  \n",
      "\n",
      "Fold: 22  Epoch: 167  Training loss = 4.4270  Validation loss = 2.3119  \n",
      "\n",
      "Fold: 22  Epoch: 168  Training loss = 4.4267  Validation loss = 2.3118  \n",
      "\n",
      "Fold: 22  Epoch: 169  Training loss = 4.4266  Validation loss = 2.3118  \n",
      "\n",
      "Fold: 22  Epoch: 170  Training loss = 4.4264  Validation loss = 2.3117  \n",
      "\n",
      "Fold: 22  Epoch: 171  Training loss = 4.4261  Validation loss = 2.3114  \n",
      "\n",
      "Fold: 22  Epoch: 172  Training loss = 4.4260  Validation loss = 2.3112  \n",
      "\n",
      "Fold: 22  Epoch: 173  Training loss = 4.4258  Validation loss = 2.3110  \n",
      "\n",
      "Fold: 22  Epoch: 174  Training loss = 4.4256  Validation loss = 2.3108  \n",
      "\n",
      "Fold: 22  Epoch: 175  Training loss = 4.4254  Validation loss = 2.3106  \n",
      "\n",
      "Fold: 22  Epoch: 176  Training loss = 4.4251  Validation loss = 2.3103  \n",
      "\n",
      "Fold: 22  Epoch: 177  Training loss = 4.4248  Validation loss = 2.3101  \n",
      "\n",
      "Fold: 22  Epoch: 178  Training loss = 4.4247  Validation loss = 2.3097  \n",
      "\n",
      "Fold: 22  Epoch: 179  Training loss = 4.4244  Validation loss = 2.3094  \n",
      "\n",
      "Fold: 22  Epoch: 180  Training loss = 4.4241  Validation loss = 2.3092  \n",
      "\n",
      "Fold: 22  Epoch: 181  Training loss = 4.4238  Validation loss = 2.3088  \n",
      "\n",
      "Fold: 22  Epoch: 182  Training loss = 4.4237  Validation loss = 2.3086  \n",
      "\n",
      "Fold: 22  Epoch: 183  Training loss = 4.4234  Validation loss = 2.3084  \n",
      "\n",
      "Fold: 22  Epoch: 184  Training loss = 4.4231  Validation loss = 2.3083  \n",
      "\n",
      "Fold: 22  Epoch: 185  Training loss = 4.4229  Validation loss = 2.3082  \n",
      "\n",
      "Fold: 22  Epoch: 186  Training loss = 4.4227  Validation loss = 2.3081  \n",
      "\n",
      "Fold: 22  Epoch: 187  Training loss = 4.4225  Validation loss = 2.3079  \n",
      "\n",
      "Fold: 22  Epoch: 188  Training loss = 4.4222  Validation loss = 2.3075  \n",
      "\n",
      "Fold: 22  Epoch: 189  Training loss = 4.4220  Validation loss = 2.3072  \n",
      "\n",
      "Fold: 22  Epoch: 190  Training loss = 4.4217  Validation loss = 2.3070  \n",
      "\n",
      "Fold: 22  Epoch: 191  Training loss = 4.4215  Validation loss = 2.3069  \n",
      "\n",
      "Fold: 22  Epoch: 192  Training loss = 4.4213  Validation loss = 2.3068  \n",
      "\n",
      "Fold: 22  Epoch: 193  Training loss = 4.4211  Validation loss = 2.3064  \n",
      "\n",
      "Fold: 22  Epoch: 194  Training loss = 4.4209  Validation loss = 2.3064  \n",
      "\n",
      "Fold: 22  Epoch: 195  Training loss = 4.4206  Validation loss = 2.3061  \n",
      "\n",
      "Fold: 22  Epoch: 196  Training loss = 4.4204  Validation loss = 2.3060  \n",
      "\n",
      "Fold: 22  Epoch: 197  Training loss = 4.4202  Validation loss = 2.3059  \n",
      "\n",
      "Fold: 22  Epoch: 198  Training loss = 4.4199  Validation loss = 2.3056  \n",
      "\n",
      "Fold: 22  Epoch: 199  Training loss = 4.4197  Validation loss = 2.3053  \n",
      "\n",
      "Fold: 22  Epoch: 200  Training loss = 4.4195  Validation loss = 2.3052  \n",
      "\n",
      "Fold: 22  Epoch: 201  Training loss = 4.4193  Validation loss = 2.3049  \n",
      "\n",
      "Fold: 22  Epoch: 202  Training loss = 4.4191  Validation loss = 2.3047  \n",
      "\n",
      "Fold: 22  Epoch: 203  Training loss = 4.4188  Validation loss = 2.3043  \n",
      "\n",
      "Fold: 22  Epoch: 204  Training loss = 4.4186  Validation loss = 2.3042  \n",
      "\n",
      "Fold: 22  Epoch: 205  Training loss = 4.4183  Validation loss = 2.3041  \n",
      "\n",
      "Fold: 22  Epoch: 206  Training loss = 4.4180  Validation loss = 2.3039  \n",
      "\n",
      "Fold: 22  Epoch: 207  Training loss = 4.4177  Validation loss = 2.3039  \n",
      "\n",
      "Fold: 22  Epoch: 208  Training loss = 4.4174  Validation loss = 2.3037  \n",
      "\n",
      "Fold: 22  Epoch: 209  Training loss = 4.4171  Validation loss = 2.3035  \n",
      "\n",
      "Fold: 22  Epoch: 210  Training loss = 4.4168  Validation loss = 2.3033  \n",
      "\n",
      "Fold: 22  Epoch: 211  Training loss = 4.4166  Validation loss = 2.3031  \n",
      "\n",
      "Fold: 22  Epoch: 212  Training loss = 4.4163  Validation loss = 2.3028  \n",
      "\n",
      "Fold: 22  Epoch: 213  Training loss = 4.4161  Validation loss = 2.3026  \n",
      "\n",
      "Fold: 22  Epoch: 214  Training loss = 4.4159  Validation loss = 2.3023  \n",
      "\n",
      "Fold: 22  Epoch: 215  Training loss = 4.4157  Validation loss = 2.3022  \n",
      "\n",
      "Fold: 22  Epoch: 216  Training loss = 4.4154  Validation loss = 2.3020  \n",
      "\n",
      "Fold: 22  Epoch: 217  Training loss = 4.4152  Validation loss = 2.3017  \n",
      "\n",
      "Fold: 22  Epoch: 218  Training loss = 4.4149  Validation loss = 2.3015  \n",
      "\n",
      "Fold: 22  Epoch: 219  Training loss = 4.4147  Validation loss = 2.3012  \n",
      "\n",
      "Fold: 22  Epoch: 220  Training loss = 4.4144  Validation loss = 2.3010  \n",
      "\n",
      "Fold: 22  Epoch: 221  Training loss = 4.4142  Validation loss = 2.3009  \n",
      "\n",
      "Fold: 22  Epoch: 222  Training loss = 4.4140  Validation loss = 2.3006  \n",
      "\n",
      "Fold: 22  Epoch: 223  Training loss = 4.4137  Validation loss = 2.3006  \n",
      "\n",
      "Fold: 22  Epoch: 224  Training loss = 4.4135  Validation loss = 2.3003  \n",
      "\n",
      "Fold: 22  Epoch: 225  Training loss = 4.4133  Validation loss = 2.3002  \n",
      "\n",
      "Fold: 22  Epoch: 226  Training loss = 4.4131  Validation loss = 2.3001  \n",
      "\n",
      "Fold: 22  Epoch: 227  Training loss = 4.4128  Validation loss = 2.2999  \n",
      "\n",
      "Fold: 22  Epoch: 228  Training loss = 4.4126  Validation loss = 2.2998  \n",
      "\n",
      "Fold: 22  Epoch: 229  Training loss = 4.4123  Validation loss = 2.2995  \n",
      "\n",
      "Fold: 22  Epoch: 230  Training loss = 4.4121  Validation loss = 2.2994  \n",
      "\n",
      "Fold: 22  Epoch: 231  Training loss = 4.4119  Validation loss = 2.2992  \n",
      "\n",
      "Fold: 22  Epoch: 232  Training loss = 4.4117  Validation loss = 2.2991  \n",
      "\n",
      "Fold: 22  Epoch: 233  Training loss = 4.4114  Validation loss = 2.2990  \n",
      "\n",
      "Fold: 22  Epoch: 234  Training loss = 4.4111  Validation loss = 2.2988  \n",
      "\n",
      "Fold: 22  Epoch: 235  Training loss = 4.4109  Validation loss = 2.2986  \n",
      "\n",
      "Fold: 22  Epoch: 236  Training loss = 4.4107  Validation loss = 2.2985  \n",
      "\n",
      "Fold: 22  Epoch: 237  Training loss = 4.4105  Validation loss = 2.2981  \n",
      "\n",
      "Fold: 22  Epoch: 238  Training loss = 4.4103  Validation loss = 2.2980  \n",
      "\n",
      "Fold: 22  Epoch: 239  Training loss = 4.4100  Validation loss = 2.2978  \n",
      "\n",
      "Fold: 22  Epoch: 240  Training loss = 4.4098  Validation loss = 2.2976  \n",
      "\n",
      "Fold: 22  Epoch: 241  Training loss = 4.4096  Validation loss = 2.2974  \n",
      "\n",
      "Fold: 22  Epoch: 242  Training loss = 4.4094  Validation loss = 2.2973  \n",
      "\n",
      "Fold: 22  Epoch: 243  Training loss = 4.4093  Validation loss = 2.2971  \n",
      "\n",
      "Fold: 22  Epoch: 244  Training loss = 4.4091  Validation loss = 2.2971  \n",
      "\n",
      "Fold: 22  Epoch: 245  Training loss = 4.4088  Validation loss = 2.2970  \n",
      "\n",
      "Fold: 22  Epoch: 246  Training loss = 4.4085  Validation loss = 2.2968  \n",
      "\n",
      "Fold: 22  Epoch: 247  Training loss = 4.4082  Validation loss = 2.2967  \n",
      "\n",
      "Fold: 22  Epoch: 248  Training loss = 4.4081  Validation loss = 2.2964  \n",
      "\n",
      "Fold: 22  Epoch: 249  Training loss = 4.4079  Validation loss = 2.2963  \n",
      "\n",
      "Fold: 22  Epoch: 250  Training loss = 4.4076  Validation loss = 2.2961  \n",
      "\n",
      "Fold: 22  Epoch: 251  Training loss = 4.4075  Validation loss = 2.2959  \n",
      "\n",
      "Fold: 22  Epoch: 252  Training loss = 4.4073  Validation loss = 2.2958  \n",
      "\n",
      "Fold: 22  Epoch: 253  Training loss = 4.4071  Validation loss = 2.2957  \n",
      "\n",
      "Fold: 22  Epoch: 254  Training loss = 4.4068  Validation loss = 2.2954  \n",
      "\n",
      "Fold: 22  Epoch: 255  Training loss = 4.4066  Validation loss = 2.2951  \n",
      "\n",
      "Fold: 22  Epoch: 256  Training loss = 4.4063  Validation loss = 2.2950  \n",
      "\n",
      "Fold: 22  Epoch: 257  Training loss = 4.4061  Validation loss = 2.2948  \n",
      "\n",
      "Fold: 22  Epoch: 258  Training loss = 4.4058  Validation loss = 2.2945  \n",
      "\n",
      "Fold: 22  Epoch: 259  Training loss = 4.4056  Validation loss = 2.2942  \n",
      "\n",
      "Fold: 22  Epoch: 260  Training loss = 4.4054  Validation loss = 2.2940  \n",
      "\n",
      "Fold: 22  Epoch: 261  Training loss = 4.4051  Validation loss = 2.2937  \n",
      "\n",
      "Fold: 22  Epoch: 262  Training loss = 4.4049  Validation loss = 2.2936  \n",
      "\n",
      "Fold: 22  Epoch: 263  Training loss = 4.4046  Validation loss = 2.2935  \n",
      "\n",
      "Fold: 22  Epoch: 264  Training loss = 4.4043  Validation loss = 2.2933  \n",
      "\n",
      "Fold: 22  Epoch: 265  Training loss = 4.4042  Validation loss = 2.2931  \n",
      "\n",
      "Fold: 22  Epoch: 266  Training loss = 4.4040  Validation loss = 2.2930  \n",
      "\n",
      "Fold: 22  Epoch: 267  Training loss = 4.4038  Validation loss = 2.2929  \n",
      "\n",
      "Fold: 22  Epoch: 268  Training loss = 4.4036  Validation loss = 2.2927  \n",
      "\n",
      "Fold: 22  Epoch: 269  Training loss = 4.4034  Validation loss = 2.2925  \n",
      "\n",
      "Fold: 22  Epoch: 270  Training loss = 4.4031  Validation loss = 2.2923  \n",
      "\n",
      "Fold: 22  Epoch: 271  Training loss = 4.4029  Validation loss = 2.2920  \n",
      "\n",
      "Fold: 22  Epoch: 272  Training loss = 4.4026  Validation loss = 2.2918  \n",
      "\n",
      "Fold: 22  Epoch: 273  Training loss = 4.4024  Validation loss = 2.2914  \n",
      "\n",
      "Fold: 22  Epoch: 274  Training loss = 4.4022  Validation loss = 2.2910  \n",
      "\n",
      "Fold: 22  Epoch: 275  Training loss = 4.4019  Validation loss = 2.2909  \n",
      "\n",
      "Fold: 22  Epoch: 276  Training loss = 4.4017  Validation loss = 2.2906  \n",
      "\n",
      "Fold: 22  Epoch: 277  Training loss = 4.4014  Validation loss = 2.2906  \n",
      "\n",
      "Fold: 22  Epoch: 278  Training loss = 4.4012  Validation loss = 2.2905  \n",
      "\n",
      "Fold: 22  Epoch: 279  Training loss = 4.4009  Validation loss = 2.2903  \n",
      "\n",
      "Fold: 22  Epoch: 280  Training loss = 4.4006  Validation loss = 2.2900  \n",
      "\n",
      "Fold: 22  Epoch: 281  Training loss = 4.4004  Validation loss = 2.2899  \n",
      "\n",
      "Fold: 22  Epoch: 282  Training loss = 4.4001  Validation loss = 2.2898  \n",
      "\n",
      "Fold: 22  Epoch: 283  Training loss = 4.3998  Validation loss = 2.2895  \n",
      "\n",
      "Fold: 22  Epoch: 284  Training loss = 4.3995  Validation loss = 2.2895  \n",
      "\n",
      "Fold: 22  Epoch: 285  Training loss = 4.3993  Validation loss = 2.2892  \n",
      "\n",
      "Fold: 22  Epoch: 286  Training loss = 4.3991  Validation loss = 2.2890  \n",
      "\n",
      "Fold: 22  Epoch: 287  Training loss = 4.3989  Validation loss = 2.2889  \n",
      "\n",
      "Fold: 22  Epoch: 288  Training loss = 4.3986  Validation loss = 2.2888  \n",
      "\n",
      "Fold: 22  Epoch: 289  Training loss = 4.3983  Validation loss = 2.2884  \n",
      "\n",
      "Fold: 22  Epoch: 290  Training loss = 4.3981  Validation loss = 2.2881  \n",
      "\n",
      "Fold: 22  Epoch: 291  Training loss = 4.3978  Validation loss = 2.2879  \n",
      "\n",
      "Fold: 22  Epoch: 292  Training loss = 4.3976  Validation loss = 2.2878  \n",
      "\n",
      "Fold: 22  Epoch: 293  Training loss = 4.3973  Validation loss = 2.2877  \n",
      "\n",
      "Fold: 22  Epoch: 294  Training loss = 4.3971  Validation loss = 2.2875  \n",
      "\n",
      "Fold: 22  Epoch: 295  Training loss = 4.3968  Validation loss = 2.2874  \n",
      "\n",
      "Fold: 22  Epoch: 296  Training loss = 4.3966  Validation loss = 2.2872  \n",
      "\n",
      "Fold: 22  Epoch: 297  Training loss = 4.3963  Validation loss = 2.2871  \n",
      "\n",
      "Fold: 22  Epoch: 298  Training loss = 4.3961  Validation loss = 2.2870  \n",
      "\n",
      "Fold: 22  Epoch: 299  Training loss = 4.3958  Validation loss = 2.2867  \n",
      "\n",
      "Fold: 22  Epoch: 300  Training loss = 4.3956  Validation loss = 2.2866  \n",
      "\n",
      "Fold: 22  Epoch: 301  Training loss = 4.3953  Validation loss = 2.2864  \n",
      "\n",
      "Fold: 22  Epoch: 302  Training loss = 4.3950  Validation loss = 2.2863  \n",
      "\n",
      "Fold: 22  Epoch: 303  Training loss = 4.3948  Validation loss = 2.2862  \n",
      "\n",
      "Fold: 22  Epoch: 304  Training loss = 4.3946  Validation loss = 2.2861  \n",
      "\n",
      "Fold: 22  Epoch: 305  Training loss = 4.3943  Validation loss = 2.2857  \n",
      "\n",
      "Fold: 22  Epoch: 306  Training loss = 4.3941  Validation loss = 2.2855  \n",
      "\n",
      "Fold: 22  Epoch: 307  Training loss = 4.3939  Validation loss = 2.2853  \n",
      "\n",
      "Fold: 22  Epoch: 308  Training loss = 4.3937  Validation loss = 2.2852  \n",
      "\n",
      "Fold: 22  Epoch: 309  Training loss = 4.3936  Validation loss = 2.2850  \n",
      "\n",
      "Fold: 22  Epoch: 310  Training loss = 4.3934  Validation loss = 2.2848  \n",
      "\n",
      "Fold: 22  Epoch: 311  Training loss = 4.3931  Validation loss = 2.2844  \n",
      "\n",
      "Fold: 22  Epoch: 312  Training loss = 4.3929  Validation loss = 2.2843  \n",
      "\n",
      "Fold: 22  Epoch: 313  Training loss = 4.3926  Validation loss = 2.2842  \n",
      "\n",
      "Fold: 22  Epoch: 314  Training loss = 4.3922  Validation loss = 2.2841  \n",
      "\n",
      "Fold: 22  Epoch: 315  Training loss = 4.3920  Validation loss = 2.2838  \n",
      "\n",
      "Fold: 22  Epoch: 316  Training loss = 4.3917  Validation loss = 2.2835  \n",
      "\n",
      "Fold: 22  Epoch: 317  Training loss = 4.3915  Validation loss = 2.2832  \n",
      "\n",
      "Fold: 22  Epoch: 318  Training loss = 4.3913  Validation loss = 2.2831  \n",
      "\n",
      "Fold: 22  Epoch: 319  Training loss = 4.3911  Validation loss = 2.2829  \n",
      "\n",
      "Fold: 22  Epoch: 320  Training loss = 4.3909  Validation loss = 2.2825  \n",
      "\n",
      "Fold: 22  Epoch: 321  Training loss = 4.3906  Validation loss = 2.2822  \n",
      "\n",
      "Fold: 22  Epoch: 322  Training loss = 4.3904  Validation loss = 2.2820  \n",
      "\n",
      "Fold: 22  Epoch: 323  Training loss = 4.3901  Validation loss = 2.2818  \n",
      "\n",
      "Fold: 22  Epoch: 324  Training loss = 4.3900  Validation loss = 2.2816  \n",
      "\n",
      "Fold: 22  Epoch: 325  Training loss = 4.3897  Validation loss = 2.2815  \n",
      "\n",
      "Fold: 22  Epoch: 326  Training loss = 4.3895  Validation loss = 2.2814  \n",
      "\n",
      "Fold: 22  Epoch: 327  Training loss = 4.3892  Validation loss = 2.2811  \n",
      "\n",
      "Fold: 22  Epoch: 328  Training loss = 4.3890  Validation loss = 2.2808  \n",
      "\n",
      "Fold: 22  Epoch: 329  Training loss = 4.3888  Validation loss = 2.2804  \n",
      "\n",
      "Fold: 22  Epoch: 330  Training loss = 4.3886  Validation loss = 2.2803  \n",
      "\n",
      "Fold: 22  Epoch: 331  Training loss = 4.3884  Validation loss = 2.2801  \n",
      "\n",
      "Fold: 22  Epoch: 332  Training loss = 4.3882  Validation loss = 2.2800  \n",
      "\n",
      "Fold: 22  Epoch: 333  Training loss = 4.3880  Validation loss = 2.2799  \n",
      "\n",
      "Fold: 22  Epoch: 334  Training loss = 4.3876  Validation loss = 2.2797  \n",
      "\n",
      "Fold: 22  Epoch: 335  Training loss = 4.3874  Validation loss = 2.2795  \n",
      "\n",
      "Fold: 22  Epoch: 336  Training loss = 4.3871  Validation loss = 2.2793  \n",
      "\n",
      "Fold: 22  Epoch: 337  Training loss = 4.3868  Validation loss = 2.2792  \n",
      "\n",
      "Fold: 22  Epoch: 338  Training loss = 4.3865  Validation loss = 2.2791  \n",
      "\n",
      "Fold: 22  Epoch: 339  Training loss = 4.3862  Validation loss = 2.2790  \n",
      "\n",
      "Fold: 22  Epoch: 340  Training loss = 4.3861  Validation loss = 2.2790  \n",
      "\n",
      "Fold: 22  Epoch: 341  Training loss = 4.3857  Validation loss = 2.2788  \n",
      "\n",
      "Fold: 22  Epoch: 342  Training loss = 4.3856  Validation loss = 2.2788  \n",
      "\n",
      "Fold: 22  Epoch: 343  Training loss = 4.3853  Validation loss = 2.2785  \n",
      "\n",
      "Fold: 22  Epoch: 344  Training loss = 4.3851  Validation loss = 2.2782  \n",
      "\n",
      "Fold: 22  Epoch: 345  Training loss = 4.3848  Validation loss = 2.2781  \n",
      "\n",
      "Fold: 22  Epoch: 346  Training loss = 4.3846  Validation loss = 2.2780  \n",
      "\n",
      "Fold: 22  Epoch: 347  Training loss = 4.3844  Validation loss = 2.2779  \n",
      "\n",
      "Fold: 22  Epoch: 348  Training loss = 4.3842  Validation loss = 2.2777  \n",
      "\n",
      "Fold: 22  Epoch: 349  Training loss = 4.3839  Validation loss = 2.2776  \n",
      "\n",
      "Fold: 22  Epoch: 350  Training loss = 4.3837  Validation loss = 2.2775  \n",
      "\n",
      "Fold: 22  Epoch: 351  Training loss = 4.3835  Validation loss = 2.2772  \n",
      "\n",
      "Fold: 22  Epoch: 352  Training loss = 4.3833  Validation loss = 2.2772  \n",
      "\n",
      "Fold: 22  Epoch: 353  Training loss = 4.3831  Validation loss = 2.2771  \n",
      "\n",
      "Fold: 22  Epoch: 354  Training loss = 4.3829  Validation loss = 2.2768  \n",
      "\n",
      "Fold: 22  Epoch: 355  Training loss = 4.3826  Validation loss = 2.2765  \n",
      "\n",
      "Fold: 22  Epoch: 356  Training loss = 4.3824  Validation loss = 2.2763  \n",
      "\n",
      "Fold: 22  Epoch: 357  Training loss = 4.3822  Validation loss = 2.2762  \n",
      "\n",
      "Fold: 22  Epoch: 358  Training loss = 4.3820  Validation loss = 2.2757  \n",
      "\n",
      "Fold: 22  Epoch: 359  Training loss = 4.3817  Validation loss = 2.2754  \n",
      "\n",
      "Fold: 22  Epoch: 360  Training loss = 4.3814  Validation loss = 2.2752  \n",
      "\n",
      "Fold: 22  Epoch: 361  Training loss = 4.3811  Validation loss = 2.2748  \n",
      "\n",
      "Fold: 22  Epoch: 362  Training loss = 4.3810  Validation loss = 2.2747  \n",
      "\n",
      "Fold: 22  Epoch: 363  Training loss = 4.3808  Validation loss = 2.2744  \n",
      "\n",
      "Fold: 22  Epoch: 364  Training loss = 4.3806  Validation loss = 2.2743  \n",
      "\n",
      "Fold: 22  Epoch: 365  Training loss = 4.3804  Validation loss = 2.2742  \n",
      "\n",
      "Fold: 22  Epoch: 366  Training loss = 4.3801  Validation loss = 2.2738  \n",
      "\n",
      "Fold: 22  Epoch: 367  Training loss = 4.3799  Validation loss = 2.2736  \n",
      "\n",
      "Fold: 22  Epoch: 368  Training loss = 4.3795  Validation loss = 2.2733  \n",
      "\n",
      "Fold: 22  Epoch: 369  Training loss = 4.3792  Validation loss = 2.2730  \n",
      "\n",
      "Fold: 22  Epoch: 370  Training loss = 4.3790  Validation loss = 2.2730  \n",
      "\n",
      "Fold: 22  Epoch: 371  Training loss = 4.3788  Validation loss = 2.2727  \n",
      "\n",
      "Fold: 22  Epoch: 372  Training loss = 4.3785  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 22  Epoch: 373  Training loss = 4.3783  Validation loss = 2.2724  \n",
      "\n",
      "Fold: 22  Epoch: 374  Training loss = 4.3781  Validation loss = 2.2722  \n",
      "\n",
      "Fold: 22  Epoch: 375  Training loss = 4.3779  Validation loss = 2.2718  \n",
      "\n",
      "Fold: 22  Epoch: 376  Training loss = 4.3776  Validation loss = 2.2717  \n",
      "\n",
      "Fold: 22  Epoch: 377  Training loss = 4.3774  Validation loss = 2.2714  \n",
      "\n",
      "Fold: 22  Epoch: 378  Training loss = 4.3772  Validation loss = 2.2712  \n",
      "\n",
      "Fold: 22  Epoch: 379  Training loss = 4.3770  Validation loss = 2.2710  \n",
      "\n",
      "Fold: 22  Epoch: 380  Training loss = 4.3769  Validation loss = 2.2709  \n",
      "\n",
      "Fold: 22  Epoch: 381  Training loss = 4.3767  Validation loss = 2.2707  \n",
      "\n",
      "Fold: 22  Epoch: 382  Training loss = 4.3764  Validation loss = 2.2706  \n",
      "\n",
      "Fold: 22  Epoch: 383  Training loss = 4.3760  Validation loss = 2.2705  \n",
      "\n",
      "Fold: 22  Epoch: 384  Training loss = 4.3758  Validation loss = 2.2703  \n",
      "\n",
      "Fold: 22  Epoch: 385  Training loss = 4.3755  Validation loss = 2.2702  \n",
      "\n",
      "Fold: 22  Epoch: 386  Training loss = 4.3753  Validation loss = 2.2699  \n",
      "\n",
      "Fold: 22  Epoch: 387  Training loss = 4.3751  Validation loss = 2.2698  \n",
      "\n",
      "Fold: 22  Epoch: 388  Training loss = 4.3749  Validation loss = 2.2694  \n",
      "\n",
      "Fold: 22  Epoch: 389  Training loss = 4.3746  Validation loss = 2.2694  \n",
      "\n",
      "Fold: 22  Epoch: 390  Training loss = 4.3743  Validation loss = 2.2692  \n",
      "\n",
      "Fold: 22  Epoch: 391  Training loss = 4.3740  Validation loss = 2.2691  \n",
      "\n",
      "Fold: 22  Epoch: 392  Training loss = 4.3738  Validation loss = 2.2689  \n",
      "\n",
      "Fold: 22  Epoch: 393  Training loss = 4.3736  Validation loss = 2.2686  \n",
      "\n",
      "Fold: 22  Epoch: 394  Training loss = 4.3733  Validation loss = 2.2683  \n",
      "\n",
      "Fold: 22  Epoch: 395  Training loss = 4.3730  Validation loss = 2.2681  \n",
      "\n",
      "Fold: 22  Epoch: 396  Training loss = 4.3728  Validation loss = 2.2680  \n",
      "\n",
      "Fold: 22  Epoch: 397  Training loss = 4.3727  Validation loss = 2.2679  \n",
      "\n",
      "Fold: 22  Epoch: 398  Training loss = 4.3724  Validation loss = 2.2678  \n",
      "\n",
      "Fold: 22  Epoch: 399  Training loss = 4.3721  Validation loss = 2.2676  \n",
      "\n",
      "Fold: 22  Epoch: 400  Training loss = 4.3719  Validation loss = 2.2675  \n",
      "\n",
      "Fold: 22  Epoch: 401  Training loss = 4.3716  Validation loss = 2.2674  \n",
      "\n",
      "Fold: 22  Epoch: 402  Training loss = 4.3714  Validation loss = 2.2671  \n",
      "\n",
      "Fold: 22  Epoch: 403  Training loss = 4.3712  Validation loss = 2.2671  \n",
      "\n",
      "Fold: 22  Epoch: 404  Training loss = 4.3710  Validation loss = 2.2668  \n",
      "\n",
      "Fold: 22  Epoch: 405  Training loss = 4.3707  Validation loss = 2.2665  \n",
      "\n",
      "Fold: 22  Epoch: 406  Training loss = 4.3705  Validation loss = 2.2662  \n",
      "\n",
      "Fold: 22  Epoch: 407  Training loss = 4.3703  Validation loss = 2.2661  \n",
      "\n",
      "Fold: 22  Epoch: 408  Training loss = 4.3700  Validation loss = 2.2659  \n",
      "\n",
      "Fold: 22  Epoch: 409  Training loss = 4.3698  Validation loss = 2.2658  \n",
      "\n",
      "Fold: 22  Epoch: 410  Training loss = 4.3696  Validation loss = 2.2657  \n",
      "\n",
      "Fold: 22  Epoch: 411  Training loss = 4.3693  Validation loss = 2.2656  \n",
      "\n",
      "Fold: 22  Epoch: 412  Training loss = 4.3691  Validation loss = 2.2654  \n",
      "\n",
      "Fold: 22  Epoch: 413  Training loss = 4.3689  Validation loss = 2.2651  \n",
      "\n",
      "Fold: 22  Epoch: 414  Training loss = 4.3686  Validation loss = 2.2650  \n",
      "\n",
      "Fold: 22  Epoch: 415  Training loss = 4.3683  Validation loss = 2.2649  \n",
      "\n",
      "Fold: 22  Epoch: 416  Training loss = 4.3680  Validation loss = 2.2647  \n",
      "\n",
      "Fold: 22  Epoch: 417  Training loss = 4.3677  Validation loss = 2.2645  \n",
      "\n",
      "Fold: 22  Epoch: 418  Training loss = 4.3675  Validation loss = 2.2644  \n",
      "\n",
      "Fold: 22  Epoch: 419  Training loss = 4.3673  Validation loss = 2.2643  \n",
      "\n",
      "Fold: 22  Epoch: 420  Training loss = 4.3671  Validation loss = 2.2641  \n",
      "\n",
      "Fold: 22  Epoch: 421  Training loss = 4.3667  Validation loss = 2.2640  \n",
      "\n",
      "Fold: 22  Epoch: 422  Training loss = 4.3665  Validation loss = 2.2639  \n",
      "\n",
      "Fold: 22  Epoch: 423  Training loss = 4.3663  Validation loss = 2.2634  \n",
      "\n",
      "Fold: 22  Epoch: 424  Training loss = 4.3661  Validation loss = 2.2633  \n",
      "\n",
      "Fold: 22  Epoch: 425  Training loss = 4.3658  Validation loss = 2.2631  \n",
      "\n",
      "Fold: 22  Epoch: 426  Training loss = 4.3656  Validation loss = 2.2630  \n",
      "\n",
      "Fold: 22  Epoch: 427  Training loss = 4.3654  Validation loss = 2.2628  \n",
      "\n",
      "Fold: 22  Epoch: 428  Training loss = 4.3652  Validation loss = 2.2628  \n",
      "\n",
      "Fold: 22  Epoch: 429  Training loss = 4.3649  Validation loss = 2.2623  \n",
      "\n",
      "Fold: 22  Epoch: 430  Training loss = 4.3646  Validation loss = 2.2622  \n",
      "\n",
      "Fold: 22  Epoch: 431  Training loss = 4.3643  Validation loss = 2.2620  \n",
      "\n",
      "Fold: 22  Epoch: 432  Training loss = 4.3641  Validation loss = 2.2618  \n",
      "\n",
      "Fold: 22  Epoch: 433  Training loss = 4.3639  Validation loss = 2.2616  \n",
      "\n",
      "Fold: 22  Epoch: 434  Training loss = 4.3638  Validation loss = 2.2616  \n",
      "\n",
      "Fold: 22  Epoch: 435  Training loss = 4.3636  Validation loss = 2.2615  \n",
      "\n",
      "Fold: 22  Epoch: 436  Training loss = 4.3633  Validation loss = 2.2615  \n",
      "\n",
      "Fold: 22  Epoch: 437  Training loss = 4.3631  Validation loss = 2.2614  \n",
      "\n",
      "Fold: 22  Epoch: 438  Training loss = 4.3629  Validation loss = 2.2611  \n",
      "\n",
      "Fold: 22  Epoch: 439  Training loss = 4.3627  Validation loss = 2.2610  \n",
      "\n",
      "Fold: 22  Epoch: 440  Training loss = 4.3625  Validation loss = 2.2609  \n",
      "\n",
      "Fold: 22  Epoch: 441  Training loss = 4.3623  Validation loss = 2.2607  \n",
      "\n",
      "Fold: 22  Epoch: 442  Training loss = 4.3621  Validation loss = 2.2605  \n",
      "\n",
      "Fold: 22  Epoch: 443  Training loss = 4.3617  Validation loss = 2.2604  \n",
      "\n",
      "Fold: 22  Epoch: 444  Training loss = 4.3615  Validation loss = 2.2602  \n",
      "\n",
      "Fold: 22  Epoch: 445  Training loss = 4.3614  Validation loss = 2.2602  \n",
      "\n",
      "Fold: 22  Epoch: 446  Training loss = 4.3611  Validation loss = 2.2599  \n",
      "\n",
      "Fold: 22  Epoch: 447  Training loss = 4.3609  Validation loss = 2.2596  \n",
      "\n",
      "Fold: 22  Epoch: 448  Training loss = 4.3607  Validation loss = 2.2592  \n",
      "\n",
      "Fold: 22  Epoch: 449  Training loss = 4.3603  Validation loss = 2.2590  \n",
      "\n",
      "Fold: 22  Epoch: 450  Training loss = 4.3600  Validation loss = 2.2587  \n",
      "\n",
      "Fold: 22  Epoch: 451  Training loss = 4.3597  Validation loss = 2.2586  \n",
      "\n",
      "Fold: 22  Epoch: 452  Training loss = 4.3595  Validation loss = 2.2584  \n",
      "\n",
      "Fold: 22  Epoch: 453  Training loss = 4.3592  Validation loss = 2.2583  \n",
      "\n",
      "Fold: 22  Epoch: 454  Training loss = 4.3588  Validation loss = 2.2581  \n",
      "\n",
      "Fold: 22  Epoch: 455  Training loss = 4.3586  Validation loss = 2.2577  \n",
      "\n",
      "Fold: 22  Epoch: 456  Training loss = 4.3584  Validation loss = 2.2577  \n",
      "\n",
      "Fold: 22  Epoch: 457  Training loss = 4.3581  Validation loss = 2.2575  \n",
      "\n",
      "Fold: 22  Epoch: 458  Training loss = 4.3579  Validation loss = 2.2571  \n",
      "\n",
      "Fold: 22  Epoch: 459  Training loss = 4.3577  Validation loss = 2.2570  \n",
      "\n",
      "Fold: 22  Epoch: 460  Training loss = 4.3573  Validation loss = 2.2570  \n",
      "\n",
      "Fold: 22  Epoch: 461  Training loss = 4.3572  Validation loss = 2.2568  \n",
      "\n",
      "Fold: 22  Epoch: 462  Training loss = 4.3569  Validation loss = 2.2564  \n",
      "\n",
      "Fold: 22  Epoch: 463  Training loss = 4.3567  Validation loss = 2.2563  \n",
      "\n",
      "Fold: 22  Epoch: 464  Training loss = 4.3564  Validation loss = 2.2562  \n",
      "\n",
      "Fold: 22  Epoch: 465  Training loss = 4.3561  Validation loss = 2.2561  \n",
      "\n",
      "Fold: 22  Epoch: 466  Training loss = 4.3559  Validation loss = 2.2557  \n",
      "\n",
      "Fold: 22  Epoch: 467  Training loss = 4.3557  Validation loss = 2.2555  \n",
      "\n",
      "Fold: 22  Epoch: 468  Training loss = 4.3554  Validation loss = 2.2552  \n",
      "\n",
      "Fold: 22  Epoch: 469  Training loss = 4.3552  Validation loss = 2.2552  \n",
      "\n",
      "Fold: 22  Epoch: 470  Training loss = 4.3550  Validation loss = 2.2551  \n",
      "\n",
      "Fold: 22  Epoch: 471  Training loss = 4.3547  Validation loss = 2.2550  \n",
      "\n",
      "Fold: 22  Epoch: 472  Training loss = 4.3544  Validation loss = 2.2548  \n",
      "\n",
      "Fold: 22  Epoch: 473  Training loss = 4.3541  Validation loss = 2.2546  \n",
      "\n",
      "Fold: 22  Epoch: 474  Training loss = 4.3539  Validation loss = 2.2543  \n",
      "\n",
      "Fold: 22  Epoch: 475  Training loss = 4.3536  Validation loss = 2.2541  \n",
      "\n",
      "Fold: 22  Epoch: 476  Training loss = 4.3535  Validation loss = 2.2539  \n",
      "\n",
      "Fold: 22  Epoch: 477  Training loss = 4.3532  Validation loss = 2.2535  \n",
      "\n",
      "Fold: 22  Epoch: 478  Training loss = 4.3529  Validation loss = 2.2535  \n",
      "\n",
      "Fold: 22  Epoch: 479  Training loss = 4.3527  Validation loss = 2.2535  \n",
      "\n",
      "Fold: 22  Epoch: 480  Training loss = 4.3524  Validation loss = 2.2533  \n",
      "\n",
      "Fold: 22  Epoch: 481  Training loss = 4.3522  Validation loss = 2.2533  \n",
      "\n",
      "Fold: 22  Epoch: 482  Training loss = 4.3519  Validation loss = 2.2530  \n",
      "\n",
      "Fold: 22  Epoch: 483  Training loss = 4.3516  Validation loss = 2.2529  \n",
      "\n",
      "Fold: 22  Epoch: 484  Training loss = 4.3515  Validation loss = 2.2526  \n",
      "\n",
      "Fold: 22  Epoch: 485  Training loss = 4.3512  Validation loss = 2.2525  \n",
      "\n",
      "Fold: 22  Epoch: 486  Training loss = 4.3510  Validation loss = 2.2523  \n",
      "\n",
      "Fold: 22  Epoch: 487  Training loss = 4.3507  Validation loss = 2.2520  \n",
      "\n",
      "Fold: 22  Epoch: 488  Training loss = 4.3504  Validation loss = 2.2514  \n",
      "\n",
      "Fold: 22  Epoch: 489  Training loss = 4.3501  Validation loss = 2.2512  \n",
      "\n",
      "Fold: 22  Epoch: 490  Training loss = 4.3499  Validation loss = 2.2509  \n",
      "\n",
      "Fold: 22  Epoch: 491  Training loss = 4.3496  Validation loss = 2.2506  \n",
      "\n",
      "Fold: 22  Epoch: 492  Training loss = 4.3493  Validation loss = 2.2504  \n",
      "\n",
      "Fold: 22  Epoch: 493  Training loss = 4.3491  Validation loss = 2.2502  \n",
      "\n",
      "Fold: 22  Epoch: 494  Training loss = 4.3488  Validation loss = 2.2501  \n",
      "\n",
      "Fold: 22  Epoch: 495  Training loss = 4.3485  Validation loss = 2.2500  \n",
      "\n",
      "Fold: 22  Epoch: 496  Training loss = 4.3482  Validation loss = 2.2499  \n",
      "\n",
      "Fold: 22  Epoch: 497  Training loss = 4.3480  Validation loss = 2.2498  \n",
      "\n",
      "Fold: 22  Epoch: 498  Training loss = 4.3478  Validation loss = 2.2496  \n",
      "\n",
      "Fold: 22  Epoch: 499  Training loss = 4.3475  Validation loss = 2.2495  \n",
      "\n",
      "Fold: 22  Epoch: 500  Training loss = 4.3473  Validation loss = 2.2493  \n",
      "\n",
      "Fold: 22  Epoch: 501  Training loss = 4.3470  Validation loss = 2.2491  \n",
      "\n",
      "Fold: 22  Epoch: 502  Training loss = 4.3468  Validation loss = 2.2487  \n",
      "\n",
      "Fold: 22  Epoch: 503  Training loss = 4.3465  Validation loss = 2.2485  \n",
      "\n",
      "Fold: 22  Epoch: 504  Training loss = 4.3463  Validation loss = 2.2483  \n",
      "\n",
      "Fold: 22  Epoch: 505  Training loss = 4.3460  Validation loss = 2.2481  \n",
      "\n",
      "Fold: 22  Epoch: 506  Training loss = 4.3458  Validation loss = 2.2481  \n",
      "\n",
      "Fold: 22  Epoch: 507  Training loss = 4.3456  Validation loss = 2.2480  \n",
      "\n",
      "Fold: 22  Epoch: 508  Training loss = 4.3453  Validation loss = 2.2479  \n",
      "\n",
      "Fold: 22  Epoch: 509  Training loss = 4.3450  Validation loss = 2.2477  \n",
      "\n",
      "Fold: 22  Epoch: 510  Training loss = 4.3448  Validation loss = 2.2476  \n",
      "\n",
      "Fold: 22  Epoch: 511  Training loss = 4.3445  Validation loss = 2.2474  \n",
      "\n",
      "Fold: 22  Epoch: 512  Training loss = 4.3443  Validation loss = 2.2474  \n",
      "\n",
      "Fold: 22  Epoch: 513  Training loss = 4.3440  Validation loss = 2.2471  \n",
      "\n",
      "Fold: 22  Epoch: 514  Training loss = 4.3437  Validation loss = 2.2470  \n",
      "\n",
      "Fold: 22  Epoch: 515  Training loss = 4.3435  Validation loss = 2.2468  \n",
      "\n",
      "Fold: 22  Epoch: 516  Training loss = 4.3433  Validation loss = 2.2467  \n",
      "\n",
      "Fold: 22  Epoch: 517  Training loss = 4.3430  Validation loss = 2.2465  \n",
      "\n",
      "Fold: 22  Epoch: 518  Training loss = 4.3427  Validation loss = 2.2463  \n",
      "\n",
      "Fold: 22  Epoch: 519  Training loss = 4.3426  Validation loss = 2.2461  \n",
      "\n",
      "Fold: 22  Epoch: 520  Training loss = 4.3422  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 22  Epoch: 521  Training loss = 4.3420  Validation loss = 2.2456  \n",
      "\n",
      "Fold: 22  Epoch: 522  Training loss = 4.3417  Validation loss = 2.2455  \n",
      "\n",
      "Fold: 22  Epoch: 523  Training loss = 4.3414  Validation loss = 2.2453  \n",
      "\n",
      "Fold: 22  Epoch: 524  Training loss = 4.3413  Validation loss = 2.2450  \n",
      "\n",
      "Fold: 22  Epoch: 525  Training loss = 4.3410  Validation loss = 2.2449  \n",
      "\n",
      "Fold: 22  Epoch: 526  Training loss = 4.3408  Validation loss = 2.2448  \n",
      "\n",
      "Fold: 22  Epoch: 527  Training loss = 4.3407  Validation loss = 2.2448  \n",
      "\n",
      "Fold: 22  Epoch: 528  Training loss = 4.3404  Validation loss = 2.2444  \n",
      "\n",
      "Fold: 22  Epoch: 529  Training loss = 4.3401  Validation loss = 2.2443  \n",
      "\n",
      "Fold: 22  Epoch: 530  Training loss = 4.3398  Validation loss = 2.2440  \n",
      "\n",
      "Fold: 22  Epoch: 531  Training loss = 4.3396  Validation loss = 2.2438  \n",
      "\n",
      "Fold: 22  Epoch: 532  Training loss = 4.3394  Validation loss = 2.2436  \n",
      "\n",
      "Fold: 22  Epoch: 533  Training loss = 4.3391  Validation loss = 2.2433  \n",
      "\n",
      "Fold: 22  Epoch: 534  Training loss = 4.3389  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 22  Epoch: 535  Training loss = 4.3387  Validation loss = 2.2428  \n",
      "\n",
      "Fold: 22  Epoch: 536  Training loss = 4.3385  Validation loss = 2.2426  \n",
      "\n",
      "Fold: 22  Epoch: 537  Training loss = 4.3382  Validation loss = 2.2425  \n",
      "\n",
      "Fold: 22  Epoch: 538  Training loss = 4.3380  Validation loss = 2.2423  \n",
      "\n",
      "Fold: 22  Epoch: 539  Training loss = 4.3377  Validation loss = 2.2420  \n",
      "\n",
      "Fold: 22  Epoch: 540  Training loss = 4.3375  Validation loss = 2.2418  \n",
      "\n",
      "Fold: 22  Epoch: 541  Training loss = 4.3372  Validation loss = 2.2416  \n",
      "\n",
      "Fold: 22  Epoch: 542  Training loss = 4.3370  Validation loss = 2.2413  \n",
      "\n",
      "Fold: 22  Epoch: 543  Training loss = 4.3368  Validation loss = 2.2409  \n",
      "\n",
      "Fold: 22  Epoch: 544  Training loss = 4.3366  Validation loss = 2.2407  \n",
      "\n",
      "Fold: 22  Epoch: 545  Training loss = 4.3363  Validation loss = 2.2403  \n",
      "\n",
      "Fold: 22  Epoch: 546  Training loss = 4.3361  Validation loss = 2.2401  \n",
      "\n",
      "Fold: 22  Epoch: 547  Training loss = 4.3358  Validation loss = 2.2398  \n",
      "\n",
      "Fold: 22  Epoch: 548  Training loss = 4.3355  Validation loss = 2.2396  \n",
      "\n",
      "Fold: 22  Epoch: 549  Training loss = 4.3352  Validation loss = 2.2393  \n",
      "\n",
      "Fold: 22  Epoch: 550  Training loss = 4.3349  Validation loss = 2.2390  \n",
      "\n",
      "Fold: 22  Epoch: 551  Training loss = 4.3346  Validation loss = 2.2388  \n",
      "\n",
      "Fold: 22  Epoch: 552  Training loss = 4.3344  Validation loss = 2.2384  \n",
      "\n",
      "Fold: 22  Epoch: 553  Training loss = 4.3341  Validation loss = 2.2381  \n",
      "\n",
      "Fold: 22  Epoch: 554  Training loss = 4.3339  Validation loss = 2.2381  \n",
      "\n",
      "Fold: 22  Epoch: 555  Training loss = 4.3335  Validation loss = 2.2380  \n",
      "\n",
      "Fold: 22  Epoch: 556  Training loss = 4.3333  Validation loss = 2.2378  \n",
      "\n",
      "Fold: 22  Epoch: 557  Training loss = 4.3330  Validation loss = 2.2377  \n",
      "\n",
      "Fold: 22  Epoch: 558  Training loss = 4.3327  Validation loss = 2.2375  \n",
      "\n",
      "Fold: 22  Epoch: 559  Training loss = 4.3324  Validation loss = 2.2371  \n",
      "\n",
      "Fold: 22  Epoch: 560  Training loss = 4.3322  Validation loss = 2.2371  \n",
      "\n",
      "Fold: 22  Epoch: 561  Training loss = 4.3319  Validation loss = 2.2370  \n",
      "\n",
      "Fold: 22  Epoch: 562  Training loss = 4.3317  Validation loss = 2.2368  \n",
      "\n",
      "Fold: 22  Epoch: 563  Training loss = 4.3314  Validation loss = 2.2366  \n",
      "\n",
      "Fold: 22  Epoch: 564  Training loss = 4.3311  Validation loss = 2.2365  \n",
      "\n",
      "Fold: 22  Epoch: 565  Training loss = 4.3308  Validation loss = 2.2364  \n",
      "\n",
      "Fold: 22  Epoch: 566  Training loss = 4.3304  Validation loss = 2.2363  \n",
      "\n",
      "Fold: 22  Epoch: 567  Training loss = 4.3303  Validation loss = 2.2360  \n",
      "\n",
      "Fold: 22  Epoch: 568  Training loss = 4.3299  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 22  Epoch: 569  Training loss = 4.3297  Validation loss = 2.2355  \n",
      "\n",
      "Fold: 22  Epoch: 570  Training loss = 4.3294  Validation loss = 2.2353  \n",
      "\n",
      "Fold: 22  Epoch: 571  Training loss = 4.3290  Validation loss = 2.2351  \n",
      "\n",
      "Fold: 22  Epoch: 572  Training loss = 4.3288  Validation loss = 2.2347  \n",
      "\n",
      "Fold: 22  Epoch: 573  Training loss = 4.3285  Validation loss = 2.2346  \n",
      "\n",
      "Fold: 22  Epoch: 574  Training loss = 4.3282  Validation loss = 2.2345  \n",
      "\n",
      "Fold: 22  Epoch: 575  Training loss = 4.3280  Validation loss = 2.2341  \n",
      "\n",
      "Fold: 22  Epoch: 576  Training loss = 4.3276  Validation loss = 2.2339  \n",
      "\n",
      "Fold: 22  Epoch: 577  Training loss = 4.3272  Validation loss = 2.2338  \n",
      "\n",
      "Fold: 22  Epoch: 578  Training loss = 4.3255  Validation loss = 2.2337  \n",
      "\n",
      "Fold: 22  Epoch: 579  Training loss = 4.3233  Validation loss = 2.2334  \n",
      "\n",
      "Fold: 22  Epoch: 580  Training loss = 4.3228  Validation loss = 2.2333  \n",
      "\n",
      "Fold: 22  Epoch: 581  Training loss = 4.3225  Validation loss = 2.2330  \n",
      "\n",
      "Fold: 22  Epoch: 582  Training loss = 4.3221  Validation loss = 2.2330  \n",
      "\n",
      "Fold: 22  Epoch: 583  Training loss = 4.3219  Validation loss = 2.2327  \n",
      "\n",
      "Fold: 22  Epoch: 584  Training loss = 4.3216  Validation loss = 2.2326  \n",
      "\n",
      "Fold: 22  Epoch: 585  Training loss = 4.3213  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 22  Epoch: 586  Training loss = 4.3211  Validation loss = 2.2320  \n",
      "\n",
      "Fold: 22  Epoch: 587  Training loss = 4.3209  Validation loss = 2.2318  \n",
      "\n",
      "Fold: 22  Epoch: 588  Training loss = 4.3207  Validation loss = 2.2317  \n",
      "\n",
      "Fold: 22  Epoch: 589  Training loss = 4.3205  Validation loss = 2.2317  \n",
      "\n",
      "Fold: 22  Epoch: 590  Training loss = 4.3202  Validation loss = 2.2314  \n",
      "\n",
      "Fold: 22  Epoch: 591  Training loss = 4.3200  Validation loss = 2.2311  \n",
      "\n",
      "Fold: 22  Epoch: 592  Training loss = 4.3196  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 22  Epoch: 593  Training loss = 4.3195  Validation loss = 2.2308  \n",
      "\n",
      "Fold: 22  Epoch: 594  Training loss = 4.3192  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 22  Epoch: 595  Training loss = 4.3190  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 22  Epoch: 596  Training loss = 4.3186  Validation loss = 2.2305  \n",
      "\n",
      "Fold: 22  Epoch: 597  Training loss = 4.3184  Validation loss = 2.2305  \n",
      "\n",
      "Fold: 22  Epoch: 598  Training loss = 4.3182  Validation loss = 2.2303  \n",
      "\n",
      "Fold: 22  Epoch: 599  Training loss = 4.3180  Validation loss = 2.2302  \n",
      "\n",
      "Fold: 22  Epoch: 600  Training loss = 4.3177  Validation loss = 2.2299  \n",
      "\n",
      "Fold: 22  Epoch: 601  Training loss = 4.3175  Validation loss = 2.2299  \n",
      "\n",
      "Fold: 22  Epoch: 602  Training loss = 4.3173  Validation loss = 2.2295  \n",
      "\n",
      "Fold: 22  Epoch: 603  Training loss = 4.3171  Validation loss = 2.2295  \n",
      "\n",
      "Fold: 22  Epoch: 604  Training loss = 4.3168  Validation loss = 2.2294  \n",
      "\n",
      "Fold: 22  Epoch: 605  Training loss = 4.3166  Validation loss = 2.2292  \n",
      "\n",
      "Fold: 22  Epoch: 606  Training loss = 4.3163  Validation loss = 2.2291  \n",
      "\n",
      "Fold: 22  Epoch: 607  Training loss = 4.3160  Validation loss = 2.2289  \n",
      "\n",
      "Fold: 22  Epoch: 608  Training loss = 4.3157  Validation loss = 2.2286  \n",
      "\n",
      "Fold: 22  Epoch: 609  Training loss = 4.3155  Validation loss = 2.2284  \n",
      "\n",
      "Fold: 22  Epoch: 610  Training loss = 4.3152  Validation loss = 2.2280  \n",
      "\n",
      "Fold: 22  Epoch: 611  Training loss = 4.3149  Validation loss = 2.2279  \n",
      "\n",
      "Fold: 22  Epoch: 612  Training loss = 4.3147  Validation loss = 2.2279  \n",
      "\n",
      "Fold: 22  Epoch: 613  Training loss = 4.3145  Validation loss = 2.2277  \n",
      "\n",
      "Fold: 22  Epoch: 614  Training loss = 4.3142  Validation loss = 2.2277  \n",
      "\n",
      "Fold: 22  Epoch: 615  Training loss = 4.3140  Validation loss = 2.2276  \n",
      "\n",
      "Fold: 22  Epoch: 616  Training loss = 4.3139  Validation loss = 2.2273  \n",
      "\n",
      "Fold: 22  Epoch: 617  Training loss = 4.3136  Validation loss = 2.2268  \n",
      "\n",
      "Fold: 22  Epoch: 618  Training loss = 4.3134  Validation loss = 2.2267  \n",
      "\n",
      "Fold: 22  Epoch: 619  Training loss = 4.3131  Validation loss = 2.2263  \n",
      "\n",
      "Fold: 22  Epoch: 620  Training loss = 4.3129  Validation loss = 2.2260  \n",
      "\n",
      "Fold: 22  Epoch: 621  Training loss = 4.3127  Validation loss = 2.2258  \n",
      "\n",
      "Fold: 22  Epoch: 622  Training loss = 4.3123  Validation loss = 2.2257  \n",
      "\n",
      "Fold: 22  Epoch: 623  Training loss = 4.3120  Validation loss = 2.2253  \n",
      "\n",
      "Fold: 22  Epoch: 624  Training loss = 4.3117  Validation loss = 2.2250  \n",
      "\n",
      "Fold: 22  Epoch: 625  Training loss = 4.3115  Validation loss = 2.2246  \n",
      "\n",
      "Fold: 22  Epoch: 626  Training loss = 4.3114  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 22  Epoch: 627  Training loss = 4.3111  Validation loss = 2.2242  \n",
      "\n",
      "Fold: 22  Epoch: 628  Training loss = 4.3109  Validation loss = 2.2238  \n",
      "\n",
      "Fold: 22  Epoch: 629  Training loss = 4.3106  Validation loss = 2.2238  \n",
      "\n",
      "Fold: 22  Epoch: 630  Training loss = 4.3104  Validation loss = 2.2237  \n",
      "\n",
      "Fold: 22  Epoch: 631  Training loss = 4.3101  Validation loss = 2.2237  \n",
      "\n",
      "Fold: 22  Epoch: 632  Training loss = 4.3099  Validation loss = 2.2234  \n",
      "\n",
      "Fold: 22  Epoch: 633  Training loss = 4.3096  Validation loss = 2.2233  \n",
      "\n",
      "Fold: 22  Epoch: 634  Training loss = 4.3093  Validation loss = 2.2231  \n",
      "\n",
      "Fold: 22  Epoch: 635  Training loss = 4.3090  Validation loss = 2.2229  \n",
      "\n",
      "Fold: 22  Epoch: 636  Training loss = 4.3087  Validation loss = 2.2229  \n",
      "\n",
      "Fold: 22  Epoch: 637  Training loss = 4.3085  Validation loss = 2.2226  \n",
      "\n",
      "Fold: 22  Epoch: 638  Training loss = 4.3082  Validation loss = 2.2226  \n",
      "\n",
      "Fold: 22  Epoch: 639  Training loss = 4.3080  Validation loss = 2.2223  \n",
      "\n",
      "Fold: 22  Epoch: 640  Training loss = 4.3077  Validation loss = 2.2221  \n",
      "\n",
      "Fold: 22  Epoch: 641  Training loss = 4.3074  Validation loss = 2.2220  \n",
      "\n",
      "Fold: 22  Epoch: 642  Training loss = 4.3072  Validation loss = 2.2214  \n",
      "\n",
      "Fold: 22  Epoch: 643  Training loss = 4.3069  Validation loss = 2.2214  \n",
      "\n",
      "Fold: 22  Epoch: 644  Training loss = 4.3066  Validation loss = 2.2214  \n",
      "\n",
      "Fold: 22  Epoch: 645  Training loss = 4.3063  Validation loss = 2.2212  \n",
      "\n",
      "Fold: 22  Epoch: 646  Training loss = 4.3060  Validation loss = 2.2211  \n",
      "\n",
      "Fold: 22  Epoch: 647  Training loss = 4.3057  Validation loss = 2.2209  \n",
      "\n",
      "Fold: 22  Epoch: 648  Training loss = 4.3054  Validation loss = 2.2207  \n",
      "\n",
      "Fold: 22  Epoch: 649  Training loss = 4.3053  Validation loss = 2.2205  \n",
      "\n",
      "Fold: 22  Epoch: 650  Training loss = 4.3049  Validation loss = 2.2203  \n",
      "\n",
      "Fold: 22  Epoch: 651  Training loss = 4.3046  Validation loss = 2.2200  \n",
      "\n",
      "Fold: 22  Epoch: 652  Training loss = 4.3044  Validation loss = 2.2198  \n",
      "\n",
      "Fold: 22  Epoch: 653  Training loss = 4.3041  Validation loss = 2.2195  \n",
      "\n",
      "Fold: 22  Epoch: 654  Training loss = 4.3038  Validation loss = 2.2192  \n",
      "\n",
      "Fold: 22  Epoch: 655  Training loss = 4.3036  Validation loss = 2.2192  \n",
      "\n",
      "Fold: 22  Epoch: 656  Training loss = 4.3034  Validation loss = 2.2192  \n",
      "\n",
      "Fold: 22  Epoch: 657  Training loss = 4.3031  Validation loss = 2.2190  \n",
      "\n",
      "Fold: 22  Epoch: 658  Training loss = 4.3028  Validation loss = 2.2189  \n",
      "\n",
      "Fold: 22  Epoch: 659  Training loss = 4.3025  Validation loss = 2.2187  \n",
      "\n",
      "Fold: 22  Epoch: 660  Training loss = 4.3021  Validation loss = 2.2186  \n",
      "\n",
      "Fold: 22  Epoch: 661  Training loss = 4.3020  Validation loss = 2.2185  \n",
      "\n",
      "Fold: 22  Epoch: 662  Training loss = 4.3017  Validation loss = 2.2183  \n",
      "\n",
      "Fold: 22  Epoch: 663  Training loss = 4.3016  Validation loss = 2.2182  \n",
      "\n",
      "Fold: 22  Epoch: 664  Training loss = 4.3014  Validation loss = 2.2179  \n",
      "\n",
      "Fold: 22  Epoch: 665  Training loss = 4.3011  Validation loss = 2.2177  \n",
      "\n",
      "Fold: 22  Epoch: 666  Training loss = 4.3009  Validation loss = 2.2177  \n",
      "\n",
      "Fold: 22  Epoch: 667  Training loss = 4.3006  Validation loss = 2.2175  \n",
      "\n",
      "Fold: 22  Epoch: 668  Training loss = 4.3004  Validation loss = 2.2174  \n",
      "\n",
      "Fold: 22  Epoch: 669  Training loss = 4.3000  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 22  Epoch: 670  Training loss = 4.2998  Validation loss = 2.2169  \n",
      "\n",
      "Fold: 22  Epoch: 671  Training loss = 4.2996  Validation loss = 2.2168  \n",
      "\n",
      "Fold: 22  Epoch: 672  Training loss = 4.2993  Validation loss = 2.2168  \n",
      "\n",
      "Fold: 22  Epoch: 673  Training loss = 4.2990  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 22  Epoch: 674  Training loss = 4.2986  Validation loss = 2.2161  \n",
      "\n",
      "Fold: 22  Epoch: 675  Training loss = 4.2983  Validation loss = 2.2159  \n",
      "\n",
      "Fold: 22  Epoch: 676  Training loss = 4.2981  Validation loss = 2.2155  \n",
      "\n",
      "Fold: 22  Epoch: 677  Training loss = 4.2978  Validation loss = 2.2155  \n",
      "\n",
      "Fold: 22  Epoch: 678  Training loss = 4.2976  Validation loss = 2.2153  \n",
      "\n",
      "Fold: 22  Epoch: 679  Training loss = 4.2974  Validation loss = 2.2149  \n",
      "\n",
      "Fold: 22  Epoch: 680  Training loss = 4.2971  Validation loss = 2.2147  \n",
      "\n",
      "Fold: 22  Epoch: 681  Training loss = 4.2969  Validation loss = 2.2147  \n",
      "\n",
      "Fold: 22  Epoch: 682  Training loss = 4.2966  Validation loss = 2.2145  \n",
      "\n",
      "Fold: 22  Epoch: 683  Training loss = 4.2964  Validation loss = 2.2143  \n",
      "\n",
      "Fold: 22  Epoch: 684  Training loss = 4.2962  Validation loss = 2.2143  \n",
      "\n",
      "Fold: 22  Epoch: 685  Training loss = 4.2959  Validation loss = 2.2143  \n",
      "\n",
      "Fold: 22  Epoch: 686  Training loss = 4.2957  Validation loss = 2.2141  \n",
      "\n",
      "Fold: 22  Epoch: 687  Training loss = 4.2954  Validation loss = 2.2141  \n",
      "\n",
      "Fold: 22  Epoch: 688  Training loss = 4.2952  Validation loss = 2.2137  \n",
      "\n",
      "Fold: 22  Epoch: 689  Training loss = 4.2950  Validation loss = 2.2137  \n",
      "\n",
      "Fold: 22  Epoch: 690  Training loss = 4.2948  Validation loss = 2.2133  \n",
      "\n",
      "Fold: 22  Epoch: 691  Training loss = 4.2946  Validation loss = 2.2131  \n",
      "\n",
      "Fold: 22  Epoch: 692  Training loss = 4.2945  Validation loss = 2.2129  \n",
      "\n",
      "Fold: 22  Epoch: 693  Training loss = 4.2943  Validation loss = 2.2128  \n",
      "\n",
      "Fold: 22  Epoch: 694  Training loss = 4.2940  Validation loss = 2.2126  \n",
      "\n",
      "Fold: 22  Epoch: 695  Training loss = 4.2937  Validation loss = 2.2124  \n",
      "\n",
      "Fold: 22  Epoch: 696  Training loss = 4.2934  Validation loss = 2.2124  \n",
      "\n",
      "Fold: 22  Epoch: 697  Training loss = 4.2931  Validation loss = 2.2123  \n",
      "\n",
      "Fold: 22  Epoch: 698  Training loss = 4.2930  Validation loss = 2.2121  \n",
      "\n",
      "Fold: 22  Epoch: 699  Training loss = 4.2927  Validation loss = 2.2121  \n",
      "\n",
      "Fold: 22  Epoch: 700  Training loss = 4.2923  Validation loss = 2.2118  \n",
      "\n",
      "Fold: 22  Epoch: 701  Training loss = 4.2921  Validation loss = 2.2116  \n",
      "\n",
      "Fold: 22  Epoch: 702  Training loss = 4.2919  Validation loss = 2.2111  \n",
      "\n",
      "Fold: 22  Epoch: 703  Training loss = 4.2916  Validation loss = 2.2110  \n",
      "\n",
      "Fold: 22  Epoch: 704  Training loss = 4.2914  Validation loss = 2.2108  \n",
      "\n",
      "Fold: 22  Epoch: 705  Training loss = 4.2912  Validation loss = 2.2106  \n",
      "\n",
      "Fold: 22  Epoch: 706  Training loss = 4.2907  Validation loss = 2.2103  \n",
      "\n",
      "Fold: 22  Epoch: 707  Training loss = 4.2905  Validation loss = 2.2100  \n",
      "\n",
      "Fold: 22  Epoch: 708  Training loss = 4.2902  Validation loss = 2.2099  \n",
      "\n",
      "Fold: 22  Epoch: 709  Training loss = 4.2900  Validation loss = 2.2097  \n",
      "\n",
      "Fold: 22  Epoch: 710  Training loss = 4.2897  Validation loss = 2.2095  \n",
      "\n",
      "Fold: 22  Epoch: 711  Training loss = 4.2893  Validation loss = 2.2093  \n",
      "\n",
      "Fold: 22  Epoch: 712  Training loss = 4.2891  Validation loss = 2.2091  \n",
      "\n",
      "Fold: 22  Epoch: 713  Training loss = 4.2887  Validation loss = 2.2091  \n",
      "\n",
      "Fold: 22  Epoch: 714  Training loss = 4.2883  Validation loss = 2.2088  \n",
      "\n",
      "Fold: 22  Epoch: 715  Training loss = 4.2881  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 22  Epoch: 716  Training loss = 4.2879  Validation loss = 2.2084  \n",
      "\n",
      "Fold: 22  Epoch: 717  Training loss = 4.2875  Validation loss = 2.2082  \n",
      "\n",
      "Fold: 22  Epoch: 718  Training loss = 4.2872  Validation loss = 2.2081  \n",
      "\n",
      "Fold: 22  Epoch: 719  Training loss = 4.2869  Validation loss = 2.2077  \n",
      "\n",
      "Fold: 22  Epoch: 720  Training loss = 4.2866  Validation loss = 2.2076  \n",
      "\n",
      "Fold: 22  Epoch: 721  Training loss = 4.2863  Validation loss = 2.2073  \n",
      "\n",
      "Fold: 22  Epoch: 722  Training loss = 4.2862  Validation loss = 2.2073  \n",
      "\n",
      "Fold: 22  Epoch: 723  Training loss = 4.2860  Validation loss = 2.2070  \n",
      "\n",
      "Fold: 22  Epoch: 724  Training loss = 4.2857  Validation loss = 2.2069  \n",
      "\n",
      "Fold: 22  Epoch: 725  Training loss = 4.2854  Validation loss = 2.2069  \n",
      "\n",
      "Fold: 22  Epoch: 726  Training loss = 4.2852  Validation loss = 2.2066  \n",
      "\n",
      "Fold: 22  Epoch: 727  Training loss = 4.2850  Validation loss = 2.2065  \n",
      "\n",
      "Fold: 22  Epoch: 728  Training loss = 4.2847  Validation loss = 2.2063  \n",
      "\n",
      "Fold: 22  Epoch: 729  Training loss = 4.2844  Validation loss = 2.2062  \n",
      "\n",
      "Fold: 22  Epoch: 730  Training loss = 4.2841  Validation loss = 2.2060  \n",
      "\n",
      "Fold: 22  Epoch: 731  Training loss = 4.2839  Validation loss = 2.2059  \n",
      "\n",
      "Fold: 22  Epoch: 732  Training loss = 4.2835  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 22  Epoch: 733  Training loss = 4.2833  Validation loss = 2.2056  \n",
      "\n",
      "Fold: 22  Epoch: 734  Training loss = 4.2830  Validation loss = 2.2054  \n",
      "\n",
      "Fold: 22  Epoch: 735  Training loss = 4.2827  Validation loss = 2.2052  \n",
      "\n",
      "Fold: 22  Epoch: 736  Training loss = 4.2824  Validation loss = 2.2049  \n",
      "\n",
      "Fold: 22  Epoch: 737  Training loss = 4.2821  Validation loss = 2.2048  \n",
      "\n",
      "Fold: 22  Epoch: 738  Training loss = 4.2819  Validation loss = 2.2046  \n",
      "\n",
      "Fold: 22  Epoch: 739  Training loss = 4.2816  Validation loss = 2.2044  \n",
      "\n",
      "Fold: 22  Epoch: 740  Training loss = 4.2813  Validation loss = 2.2042  \n",
      "\n",
      "Fold: 22  Epoch: 741  Training loss = 4.2811  Validation loss = 2.2041  \n",
      "\n",
      "Fold: 22  Epoch: 742  Training loss = 4.2809  Validation loss = 2.2039  \n",
      "\n",
      "Fold: 22  Epoch: 743  Training loss = 4.2807  Validation loss = 2.2037  \n",
      "\n",
      "Fold: 22  Epoch: 744  Training loss = 4.2803  Validation loss = 2.2035  \n",
      "\n",
      "Fold: 22  Epoch: 745  Training loss = 4.2801  Validation loss = 2.2033  \n",
      "\n",
      "Fold: 22  Epoch: 746  Training loss = 4.2799  Validation loss = 2.2030  \n",
      "\n",
      "Fold: 22  Epoch: 747  Training loss = 4.2797  Validation loss = 2.2029  \n",
      "\n",
      "Fold: 22  Epoch: 748  Training loss = 4.2794  Validation loss = 2.2025  \n",
      "\n",
      "Fold: 22  Epoch: 749  Training loss = 4.2792  Validation loss = 2.2022  \n",
      "\n",
      "Fold: 22  Epoch: 750  Training loss = 4.2790  Validation loss = 2.2021  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 750  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 4.3059  Validation loss = 1.4745  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 4.3055  Validation loss = 1.4745  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 4.3053  Validation loss = 1.4744  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 4.3049  Validation loss = 1.4745  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 4.3045  Validation loss = 1.4745  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 4.3043  Validation loss = 1.4746  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 4.3040  Validation loss = 1.4746  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 4.3038  Validation loss = 1.4747  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 4.3035  Validation loss = 1.4747  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 4.3032  Validation loss = 1.4747  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 4.3029  Validation loss = 1.4746  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 4.3026  Validation loss = 1.4746  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 4.3024  Validation loss = 1.4747  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 4.3021  Validation loss = 1.4747  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 4.3019  Validation loss = 1.4747  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 4.3016  Validation loss = 1.4746  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 4.3014  Validation loss = 1.4746  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 4.3011  Validation loss = 1.4745  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 4.3010  Validation loss = 1.4746  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 4.3007  Validation loss = 1.4747  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 4.3004  Validation loss = 1.4748  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 3  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 4.2921  Validation loss = 1.9819  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 4.2919  Validation loss = 1.9815  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 4.2916  Validation loss = 1.9807  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 4.2913  Validation loss = 1.9802  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 4.2909  Validation loss = 1.9794  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 4.2907  Validation loss = 1.9791  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 4.2902  Validation loss = 1.9785  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 4.2898  Validation loss = 1.9780  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 4.2896  Validation loss = 1.9776  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 4.2893  Validation loss = 1.9771  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 4.2890  Validation loss = 1.9766  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 4.2885  Validation loss = 1.9761  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 4.2881  Validation loss = 1.9756  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 4.2880  Validation loss = 1.9754  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 4.2878  Validation loss = 1.9745  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 4.2875  Validation loss = 1.9740  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 4.2871  Validation loss = 1.9734  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 4.2869  Validation loss = 1.9730  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 4.2866  Validation loss = 1.9723  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 4.2862  Validation loss = 1.9716  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 4.2859  Validation loss = 1.9714  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 4.2856  Validation loss = 1.9708  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 4.2853  Validation loss = 1.9700  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 4.2850  Validation loss = 1.9693  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 4.2848  Validation loss = 1.9687  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 4.2845  Validation loss = 1.9681  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 4.2843  Validation loss = 1.9678  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 4.2840  Validation loss = 1.9671  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 4.2837  Validation loss = 1.9666  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 4.2834  Validation loss = 1.9659  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 4.2831  Validation loss = 1.9654  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 4.2827  Validation loss = 1.9648  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 4.2824  Validation loss = 1.9637  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 4.2821  Validation loss = 1.9631  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 4.2818  Validation loss = 1.9628  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 4.2815  Validation loss = 1.9624  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 4.2812  Validation loss = 1.9621  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 4.2809  Validation loss = 1.9613  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 4.2807  Validation loss = 1.9608  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 4.2804  Validation loss = 1.9602  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 4.2801  Validation loss = 1.9594  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 4.2799  Validation loss = 1.9589  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 4.2796  Validation loss = 1.9584  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 4.2794  Validation loss = 1.9581  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 4.2791  Validation loss = 1.9578  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 4.2788  Validation loss = 1.9572  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 4.2785  Validation loss = 1.9569  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 4.2781  Validation loss = 1.9559  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 4.2778  Validation loss = 1.9548  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 4.2774  Validation loss = 1.9542  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 4.2772  Validation loss = 1.9539  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 4.2769  Validation loss = 1.9535  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 4.2766  Validation loss = 1.9528  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 4.2764  Validation loss = 1.9525  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 4.2761  Validation loss = 1.9514  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 4.2759  Validation loss = 1.9509  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 4.2756  Validation loss = 1.9506  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 4.2754  Validation loss = 1.9501  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 4.2752  Validation loss = 1.9498  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 4.2749  Validation loss = 1.9492  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 4.2747  Validation loss = 1.9484  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 4.2743  Validation loss = 1.9477  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 4.2739  Validation loss = 1.9472  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 4.2738  Validation loss = 1.9468  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 4.2735  Validation loss = 1.9465  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 4.2732  Validation loss = 1.9458  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 4.2730  Validation loss = 1.9454  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 4.2726  Validation loss = 1.9446  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 4.2725  Validation loss = 1.9444  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 4.2722  Validation loss = 1.9439  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 4.2719  Validation loss = 1.9434  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 4.2717  Validation loss = 1.9429  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 4.2713  Validation loss = 1.9424  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 4.2711  Validation loss = 1.9418  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 4.2709  Validation loss = 1.9414  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 4.2706  Validation loss = 1.9408  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 4.2703  Validation loss = 1.9399  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 4.2701  Validation loss = 1.9395  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 4.2698  Validation loss = 1.9391  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 4.2696  Validation loss = 1.9384  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 4.2694  Validation loss = 1.9374  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 4.2691  Validation loss = 1.9370  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 4.2688  Validation loss = 1.9364  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 4.2686  Validation loss = 1.9359  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 4.2683  Validation loss = 1.9354  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 4.2680  Validation loss = 1.9351  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 4.2677  Validation loss = 1.9342  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 4.2674  Validation loss = 1.9337  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 4.2671  Validation loss = 1.9331  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 4.2669  Validation loss = 1.9328  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 4.2666  Validation loss = 1.9323  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 4.2664  Validation loss = 1.9319  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 4.2661  Validation loss = 1.9310  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 4.2658  Validation loss = 1.9303  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 4.2655  Validation loss = 1.9298  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 4.2653  Validation loss = 1.9291  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 4.2650  Validation loss = 1.9281  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 4.2648  Validation loss = 1.9275  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 4.2645  Validation loss = 1.9270  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 4.2642  Validation loss = 1.9265  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 4.2639  Validation loss = 1.9256  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 4.2636  Validation loss = 1.9252  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 4.2634  Validation loss = 1.9249  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 4.2631  Validation loss = 1.9246  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 4.2629  Validation loss = 1.9240  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 4.2626  Validation loss = 1.9237  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 4.2624  Validation loss = 1.9227  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 4.2621  Validation loss = 1.9221  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 4.2618  Validation loss = 1.9217  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 4.2615  Validation loss = 1.9213  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 4.2612  Validation loss = 1.9206  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 4.2611  Validation loss = 1.9203  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 4.2608  Validation loss = 1.9195  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 4.2605  Validation loss = 1.9191  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 4.2603  Validation loss = 1.9188  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 4.2600  Validation loss = 1.9181  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 4.2597  Validation loss = 1.9176  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 4.2593  Validation loss = 1.9171  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 4.2590  Validation loss = 1.9167  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 4.2587  Validation loss = 1.9160  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 4.2585  Validation loss = 1.9157  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 4.2582  Validation loss = 1.9150  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 4.2580  Validation loss = 1.9146  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 4.2577  Validation loss = 1.9140  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 4.2574  Validation loss = 1.9135  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 4.2572  Validation loss = 1.9132  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 4.2570  Validation loss = 1.9129  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 4.2567  Validation loss = 1.9123  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 4.2565  Validation loss = 1.9119  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 4.2563  Validation loss = 1.9116  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 4.2560  Validation loss = 1.9112  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 4.2558  Validation loss = 1.9109  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 4.2556  Validation loss = 1.9105  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 4.2553  Validation loss = 1.9102  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 4.2550  Validation loss = 1.9094  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 4.2547  Validation loss = 1.9088  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 4.2545  Validation loss = 1.9081  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 4.2543  Validation loss = 1.9075  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 4.2539  Validation loss = 1.9068  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 4.2537  Validation loss = 1.9063  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 4.2535  Validation loss = 1.9057  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 4.2532  Validation loss = 1.9052  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 4.2529  Validation loss = 1.9045  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 4.2527  Validation loss = 1.9041  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 4.2524  Validation loss = 1.9037  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 4.2521  Validation loss = 1.9029  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 4.2518  Validation loss = 1.9020  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 4.2516  Validation loss = 1.9016  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 4.2512  Validation loss = 1.9006  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 4.2509  Validation loss = 1.9000  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 4.2507  Validation loss = 1.8997  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 4.2505  Validation loss = 1.8990  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 4.2502  Validation loss = 1.8984  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 4.2499  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 4.2496  Validation loss = 1.8970  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 4.2493  Validation loss = 1.8962  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 4.2491  Validation loss = 1.8958  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 4.2488  Validation loss = 1.8954  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 4.2485  Validation loss = 1.8949  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 4.2483  Validation loss = 1.8946  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 4.2481  Validation loss = 1.8941  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 4.2478  Validation loss = 1.8936  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 4.2476  Validation loss = 1.8933  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 4.2472  Validation loss = 1.8925  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 4.2470  Validation loss = 1.8921  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 4.2468  Validation loss = 1.8918  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 4.2465  Validation loss = 1.8914  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 4.2463  Validation loss = 1.8909  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 4.2460  Validation loss = 1.8906  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 4.2457  Validation loss = 1.8903  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 4.2455  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 4.2452  Validation loss = 1.8889  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 4.2449  Validation loss = 1.8885  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 4.2446  Validation loss = 1.8882  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 4.2443  Validation loss = 1.8874  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 4.2442  Validation loss = 1.8867  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 4.2440  Validation loss = 1.8862  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 4.2437  Validation loss = 1.8856  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 4.2435  Validation loss = 1.8852  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 4.2432  Validation loss = 1.8847  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 4.2429  Validation loss = 1.8839  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 4.2427  Validation loss = 1.8833  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 4.2425  Validation loss = 1.8826  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 4.2422  Validation loss = 1.8821  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 4.2419  Validation loss = 1.8814  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 4.2417  Validation loss = 1.8811  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 4.2415  Validation loss = 1.8803  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 4.2412  Validation loss = 1.8797  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 4.2409  Validation loss = 1.8789  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 4.2407  Validation loss = 1.8786  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 4.2404  Validation loss = 1.8781  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 4.2402  Validation loss = 1.8777  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 4.2400  Validation loss = 1.8770  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 4.2397  Validation loss = 1.8761  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 4.2395  Validation loss = 1.8753  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 4.2392  Validation loss = 1.8745  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 4.2390  Validation loss = 1.8738  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 4.2387  Validation loss = 1.8730  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 4.2385  Validation loss = 1.8725  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 4.2382  Validation loss = 1.8719  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 4.2379  Validation loss = 1.8710  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 4.2377  Validation loss = 1.8707  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 4.2374  Validation loss = 1.8700  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 4.2371  Validation loss = 1.8695  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 4.2369  Validation loss = 1.8690  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 4.2366  Validation loss = 1.8685  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 4.2363  Validation loss = 1.8680  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 4.2362  Validation loss = 1.8676  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 4.2359  Validation loss = 1.8672  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 4.2356  Validation loss = 1.8668  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 4.2354  Validation loss = 1.8665  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 4.2352  Validation loss = 1.8659  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 4.2350  Validation loss = 1.8656  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 4.2347  Validation loss = 1.8652  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 4.2344  Validation loss = 1.8647  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 4.2342  Validation loss = 1.8642  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 4.2340  Validation loss = 1.8638  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 4.2338  Validation loss = 1.8631  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 4.2335  Validation loss = 1.8625  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 4.2334  Validation loss = 1.8619  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 4.2331  Validation loss = 1.8614  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 4.2329  Validation loss = 1.8609  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 4.2327  Validation loss = 1.8607  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 4.2325  Validation loss = 1.8603  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 4.2323  Validation loss = 1.8598  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 4.2321  Validation loss = 1.8594  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 4.2317  Validation loss = 1.8585  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 4.2315  Validation loss = 1.8580  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 4.2313  Validation loss = 1.8577  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 4.2312  Validation loss = 1.8573  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 4.2308  Validation loss = 1.8569  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 4.2305  Validation loss = 1.8566  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 4.2303  Validation loss = 1.8562  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 4.2301  Validation loss = 1.8559  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 4.2299  Validation loss = 1.8554  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 4.2297  Validation loss = 1.8545  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 4.2294  Validation loss = 1.8543  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 4.2292  Validation loss = 1.8539  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 4.2290  Validation loss = 1.8534  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 4.2288  Validation loss = 1.8527  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 4.2285  Validation loss = 1.8518  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 4.2282  Validation loss = 1.8514  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 4.2280  Validation loss = 1.8509  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 4.2278  Validation loss = 1.8504  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 4.2274  Validation loss = 1.8498  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 4.2272  Validation loss = 1.8494  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 4.2270  Validation loss = 1.8490  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 4.2268  Validation loss = 1.8486  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 4.2266  Validation loss = 1.8486  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 4.2264  Validation loss = 1.8483  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 4.2262  Validation loss = 1.8479  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 4.2259  Validation loss = 1.8472  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 4.2257  Validation loss = 1.8468  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 4.2255  Validation loss = 1.8462  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 4.2252  Validation loss = 1.8456  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 4.2249  Validation loss = 1.8452  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 4.2247  Validation loss = 1.8446  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 4.2244  Validation loss = 1.8441  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 4.2242  Validation loss = 1.8436  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 4.2239  Validation loss = 1.8433  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 4.2237  Validation loss = 1.8430  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 4.2234  Validation loss = 1.8425  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 4.2232  Validation loss = 1.8419  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 4.2230  Validation loss = 1.8415  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 4.2227  Validation loss = 1.8412  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 4.2225  Validation loss = 1.8407  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 4.2222  Validation loss = 1.8402  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 4.2220  Validation loss = 1.8398  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 4.2217  Validation loss = 1.8398  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 4.2216  Validation loss = 1.8395  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 4.2214  Validation loss = 1.8393  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 4.2212  Validation loss = 1.8388  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 4.2209  Validation loss = 1.8383  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 4.2207  Validation loss = 1.8378  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 4.2204  Validation loss = 1.8373  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 4.2202  Validation loss = 1.8366  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 4.2200  Validation loss = 1.8363  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 4.2197  Validation loss = 1.8358  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 4.2195  Validation loss = 1.8356  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 4.2194  Validation loss = 1.8355  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 4.2191  Validation loss = 1.8351  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 4.2188  Validation loss = 1.8349  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 4.2186  Validation loss = 1.8344  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 4.2184  Validation loss = 1.8341  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 4.2181  Validation loss = 1.8337  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 4.2179  Validation loss = 1.8331  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 4.2177  Validation loss = 1.8329  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 4.2175  Validation loss = 1.8323  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 4.2172  Validation loss = 1.8319  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 4.2170  Validation loss = 1.8313  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 4.2168  Validation loss = 1.8310  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 4.2165  Validation loss = 1.8305  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 4.2162  Validation loss = 1.8301  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 4.2161  Validation loss = 1.8300  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 4.2160  Validation loss = 1.8296  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 4.2157  Validation loss = 1.8291  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 4.2154  Validation loss = 1.8284  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 4.2152  Validation loss = 1.8281  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 4.2150  Validation loss = 1.8277  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 4.2148  Validation loss = 1.8271  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 4.2146  Validation loss = 1.8264  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 4.2143  Validation loss = 1.8260  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 4.2141  Validation loss = 1.8256  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 4.2139  Validation loss = 1.8250  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 4.2138  Validation loss = 1.8244  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 4.2135  Validation loss = 1.8238  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 4.2133  Validation loss = 1.8235  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 4.2131  Validation loss = 1.8230  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 4.2128  Validation loss = 1.8225  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 4.2126  Validation loss = 1.8219  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 4.2124  Validation loss = 1.8214  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 4.2122  Validation loss = 1.8209  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 4.2120  Validation loss = 1.8205  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 4.2118  Validation loss = 1.8202  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 4.2115  Validation loss = 1.8199  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 4.2113  Validation loss = 1.8196  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 4.2111  Validation loss = 1.8191  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 4.2110  Validation loss = 1.8188  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 4.2108  Validation loss = 1.8184  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 4.2107  Validation loss = 1.8183  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 4.2104  Validation loss = 1.8176  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 4.2101  Validation loss = 1.8166  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 4.2099  Validation loss = 1.8162  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 4.2096  Validation loss = 1.8154  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 4.2093  Validation loss = 1.8151  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 4.2091  Validation loss = 1.8145  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 4.2088  Validation loss = 1.8139  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 4.2086  Validation loss = 1.8133  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 4.2084  Validation loss = 1.8129  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 4.2082  Validation loss = 1.8125  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 4.2079  Validation loss = 1.8121  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 4.2077  Validation loss = 1.8115  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 4.2074  Validation loss = 1.8111  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 4.2072  Validation loss = 1.8106  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 4.2070  Validation loss = 1.8102  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 4.2068  Validation loss = 1.8100  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 4.2065  Validation loss = 1.8095  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 4.2063  Validation loss = 1.8091  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 4.2061  Validation loss = 1.8087  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 4.2059  Validation loss = 1.8083  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 4.2057  Validation loss = 1.8080  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 4.2054  Validation loss = 1.8076  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 4.2051  Validation loss = 1.8071  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 4.2049  Validation loss = 1.8067  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 4.2047  Validation loss = 1.8062  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 4.2045  Validation loss = 1.8057  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 4.2042  Validation loss = 1.8051  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 4.2040  Validation loss = 1.8048  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 4.2038  Validation loss = 1.8045  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 4.2035  Validation loss = 1.8040  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 4.2033  Validation loss = 1.8034  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 4.2031  Validation loss = 1.8029  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 4.2029  Validation loss = 1.8025  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 4.2027  Validation loss = 1.8021  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 4.2025  Validation loss = 1.8017  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 4.2022  Validation loss = 1.8011  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 4.2020  Validation loss = 1.8005  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 4.2019  Validation loss = 1.8004  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 4.2016  Validation loss = 1.7994  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 4.2014  Validation loss = 1.7990  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 4.2012  Validation loss = 1.7986  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 4.2009  Validation loss = 1.7981  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 4.2007  Validation loss = 1.7974  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 4.2005  Validation loss = 1.7970  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 4.2002  Validation loss = 1.7966  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 4.2000  Validation loss = 1.7961  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 4.1998  Validation loss = 1.7958  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 4.1996  Validation loss = 1.7953  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 4.1994  Validation loss = 1.7949  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 4.1992  Validation loss = 1.7948  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 4.1990  Validation loss = 1.7943  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 4.1988  Validation loss = 1.7938  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 4.1986  Validation loss = 1.7932  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 4.1983  Validation loss = 1.7926  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 4.1981  Validation loss = 1.7922  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 4.1979  Validation loss = 1.7916  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 4.1977  Validation loss = 1.7911  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 4.1975  Validation loss = 1.7908  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 4.1972  Validation loss = 1.7904  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 4.1970  Validation loss = 1.7900  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 4.1969  Validation loss = 1.7898  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 4.1967  Validation loss = 1.7893  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 4.1964  Validation loss = 1.7888  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 4.1962  Validation loss = 1.7883  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 4.1961  Validation loss = 1.7878  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 4.1959  Validation loss = 1.7873  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 4.1957  Validation loss = 1.7867  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 4.1955  Validation loss = 1.7862  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 4.1953  Validation loss = 1.7858  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 4.1951  Validation loss = 1.7854  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 4.1949  Validation loss = 1.7851  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 4.1947  Validation loss = 1.7847  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 4.1945  Validation loss = 1.7842  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 4.1943  Validation loss = 1.7840  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 4.1941  Validation loss = 1.7834  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 4.1938  Validation loss = 1.7829  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 4.1936  Validation loss = 1.7824  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 4.1934  Validation loss = 1.7820  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 4.1932  Validation loss = 1.7815  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 4.1929  Validation loss = 1.7808  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 4.1927  Validation loss = 1.7804  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 4.1925  Validation loss = 1.7798  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 4.1924  Validation loss = 1.7794  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 4.1921  Validation loss = 1.7788  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 4.1918  Validation loss = 1.7784  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 4.1916  Validation loss = 1.7780  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 4.1914  Validation loss = 1.7777  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 4.1912  Validation loss = 1.7773  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 4.1909  Validation loss = 1.7769  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 4.1907  Validation loss = 1.7764  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 4.1905  Validation loss = 1.7761  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 4.1903  Validation loss = 1.7757  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 4.1901  Validation loss = 1.7753  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 4.1899  Validation loss = 1.7747  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 4.1897  Validation loss = 1.7743  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 4.1895  Validation loss = 1.7739  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 4.1893  Validation loss = 1.7735  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 4.1891  Validation loss = 1.7732  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 4.1889  Validation loss = 1.7729  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 4.1887  Validation loss = 1.7725  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 4.1884  Validation loss = 1.7719  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 4.1882  Validation loss = 1.7715  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 4.1880  Validation loss = 1.7710  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 4.1878  Validation loss = 1.7706  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 4.1877  Validation loss = 1.7702  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 4.1875  Validation loss = 1.7698  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 4.1872  Validation loss = 1.7691  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 4.1870  Validation loss = 1.7686  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 4.1869  Validation loss = 1.7684  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 4.1867  Validation loss = 1.7681  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 4.1865  Validation loss = 1.7677  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 4.1862  Validation loss = 1.7672  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 4.1861  Validation loss = 1.7670  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 4.1859  Validation loss = 1.7667  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 4.1856  Validation loss = 1.7659  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 4.1854  Validation loss = 1.7654  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 4.1852  Validation loss = 1.7649  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 4.1850  Validation loss = 1.7644  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 4.1848  Validation loss = 1.7640  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 4.1845  Validation loss = 1.7636  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 4.1843  Validation loss = 1.7632  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 4.1841  Validation loss = 1.7629  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 4.1840  Validation loss = 1.7624  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 4.1837  Validation loss = 1.7620  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 4.1836  Validation loss = 1.7618  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 4.1833  Validation loss = 1.7615  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 4.1831  Validation loss = 1.7607  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 4.1829  Validation loss = 1.7603  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 4.1827  Validation loss = 1.7600  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 4.1825  Validation loss = 1.7595  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 4.1824  Validation loss = 1.7591  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 4.1822  Validation loss = 1.7585  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 4.1819  Validation loss = 1.7582  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 4.1817  Validation loss = 1.7580  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 4.1815  Validation loss = 1.7574  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 4.1813  Validation loss = 1.7571  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 4.1810  Validation loss = 1.7567  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 4.1808  Validation loss = 1.7564  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 4.1806  Validation loss = 1.7562  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 4.1804  Validation loss = 1.7557  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 4.1802  Validation loss = 1.7550  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 4.1801  Validation loss = 1.7550  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 4.1798  Validation loss = 1.7546  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 4.1797  Validation loss = 1.7542  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 4.1794  Validation loss = 1.7537  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 4.1792  Validation loss = 1.7535  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 4.1790  Validation loss = 1.7529  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 4.1789  Validation loss = 1.7526  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 4.1787  Validation loss = 1.7519  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 4.1785  Validation loss = 1.7515  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 4.1783  Validation loss = 1.7510  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 4.1781  Validation loss = 1.7506  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 4.1779  Validation loss = 1.7500  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 4.1776  Validation loss = 1.7496  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 4.1775  Validation loss = 1.7491  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 4.1773  Validation loss = 1.7487  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 4.1771  Validation loss = 1.7482  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 4.1769  Validation loss = 1.7476  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 4.1768  Validation loss = 1.7474  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 4.1765  Validation loss = 1.7470  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 4.1763  Validation loss = 1.7464  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 4.1761  Validation loss = 1.7461  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 4.1758  Validation loss = 1.7457  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 4.1757  Validation loss = 1.7452  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 4.1756  Validation loss = 1.7448  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 4.1754  Validation loss = 1.7446  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 4.1752  Validation loss = 1.7443  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 4.1750  Validation loss = 1.7440  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 4.1749  Validation loss = 1.7437  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 4.1747  Validation loss = 1.7432  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 4.1745  Validation loss = 1.7426  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 4.1743  Validation loss = 1.7424  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 4.1741  Validation loss = 1.7419  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 4.1740  Validation loss = 1.7413  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 4.1738  Validation loss = 1.7411  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 4.1736  Validation loss = 1.7407  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 4.1734  Validation loss = 1.7402  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 4.1732  Validation loss = 1.7398  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 4.1730  Validation loss = 1.7394  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 4.1729  Validation loss = 1.7391  \n",
      "\n",
      "Fold: 24  Epoch: 501  Training loss = 4.1727  Validation loss = 1.7389  \n",
      "\n",
      "Fold: 24  Epoch: 502  Training loss = 4.1725  Validation loss = 1.7384  \n",
      "\n",
      "Fold: 24  Epoch: 503  Training loss = 4.1723  Validation loss = 1.7382  \n",
      "\n",
      "Fold: 24  Epoch: 504  Training loss = 4.1722  Validation loss = 1.7379  \n",
      "\n",
      "Fold: 24  Epoch: 505  Training loss = 4.1720  Validation loss = 1.7376  \n",
      "\n",
      "Fold: 24  Epoch: 506  Training loss = 4.1718  Validation loss = 1.7368  \n",
      "\n",
      "Fold: 24  Epoch: 507  Training loss = 4.1716  Validation loss = 1.7364  \n",
      "\n",
      "Fold: 24  Epoch: 508  Training loss = 4.1714  Validation loss = 1.7360  \n",
      "\n",
      "Fold: 24  Epoch: 509  Training loss = 4.1712  Validation loss = 1.7355  \n",
      "\n",
      "Fold: 24  Epoch: 510  Training loss = 4.1710  Validation loss = 1.7350  \n",
      "\n",
      "Fold: 24  Epoch: 511  Training loss = 4.1707  Validation loss = 1.7346  \n",
      "\n",
      "Fold: 24  Epoch: 512  Training loss = 4.1705  Validation loss = 1.7343  \n",
      "\n",
      "Fold: 24  Epoch: 513  Training loss = 4.1704  Validation loss = 1.7338  \n",
      "\n",
      "Fold: 24  Epoch: 514  Training loss = 4.1701  Validation loss = 1.7333  \n",
      "\n",
      "Fold: 24  Epoch: 515  Training loss = 4.1700  Validation loss = 1.7330  \n",
      "\n",
      "Fold: 24  Epoch: 516  Training loss = 4.1698  Validation loss = 1.7324  \n",
      "\n",
      "Fold: 24  Epoch: 517  Training loss = 4.1696  Validation loss = 1.7321  \n",
      "\n",
      "Fold: 24  Epoch: 518  Training loss = 4.1695  Validation loss = 1.7318  \n",
      "\n",
      "Fold: 24  Epoch: 519  Training loss = 4.1693  Validation loss = 1.7316  \n",
      "\n",
      "Fold: 24  Epoch: 520  Training loss = 4.1691  Validation loss = 1.7312  \n",
      "\n",
      "Fold: 24  Epoch: 521  Training loss = 4.1689  Validation loss = 1.7309  \n",
      "\n",
      "Fold: 24  Epoch: 522  Training loss = 4.1688  Validation loss = 1.7307  \n",
      "\n",
      "Fold: 24  Epoch: 523  Training loss = 4.1686  Validation loss = 1.7302  \n",
      "\n",
      "Fold: 24  Epoch: 524  Training loss = 4.1684  Validation loss = 1.7299  \n",
      "\n",
      "Fold: 24  Epoch: 525  Training loss = 4.1682  Validation loss = 1.7296  \n",
      "\n",
      "Fold: 24  Epoch: 526  Training loss = 4.1680  Validation loss = 1.7291  \n",
      "\n",
      "Fold: 24  Epoch: 527  Training loss = 4.1677  Validation loss = 1.7287  \n",
      "\n",
      "Fold: 24  Epoch: 528  Training loss = 4.1675  Validation loss = 1.7281  \n",
      "\n",
      "Fold: 24  Epoch: 529  Training loss = 4.1673  Validation loss = 1.7276  \n",
      "\n",
      "Fold: 24  Epoch: 530  Training loss = 4.1671  Validation loss = 1.7272  \n",
      "\n",
      "Fold: 24  Epoch: 531  Training loss = 4.1669  Validation loss = 1.7267  \n",
      "\n",
      "Fold: 24  Epoch: 532  Training loss = 4.1667  Validation loss = 1.7265  \n",
      "\n",
      "Fold: 24  Epoch: 533  Training loss = 4.1666  Validation loss = 1.7261  \n",
      "\n",
      "Fold: 24  Epoch: 534  Training loss = 4.1664  Validation loss = 1.7255  \n",
      "\n",
      "Fold: 24  Epoch: 535  Training loss = 4.1662  Validation loss = 1.7253  \n",
      "\n",
      "Fold: 24  Epoch: 536  Training loss = 4.1660  Validation loss = 1.7250  \n",
      "\n",
      "Fold: 24  Epoch: 537  Training loss = 4.1657  Validation loss = 1.7243  \n",
      "\n",
      "Fold: 24  Epoch: 538  Training loss = 4.1656  Validation loss = 1.7239  \n",
      "\n",
      "Fold: 24  Epoch: 539  Training loss = 4.1654  Validation loss = 1.7235  \n",
      "\n",
      "Fold: 24  Epoch: 540  Training loss = 4.1651  Validation loss = 1.7229  \n",
      "\n",
      "Fold: 24  Epoch: 541  Training loss = 4.1650  Validation loss = 1.7226  \n",
      "\n",
      "Fold: 24  Epoch: 542  Training loss = 4.1648  Validation loss = 1.7220  \n",
      "\n",
      "Fold: 24  Epoch: 543  Training loss = 4.1647  Validation loss = 1.7217  \n",
      "\n",
      "Fold: 24  Epoch: 544  Training loss = 4.1645  Validation loss = 1.7214  \n",
      "\n",
      "Fold: 24  Epoch: 545  Training loss = 4.1643  Validation loss = 1.7211  \n",
      "\n",
      "Fold: 24  Epoch: 546  Training loss = 4.1641  Validation loss = 1.7204  \n",
      "\n",
      "Fold: 24  Epoch: 547  Training loss = 4.1640  Validation loss = 1.7201  \n",
      "\n",
      "Fold: 24  Epoch: 548  Training loss = 4.1638  Validation loss = 1.7196  \n",
      "\n",
      "Fold: 24  Epoch: 549  Training loss = 4.1635  Validation loss = 1.7189  \n",
      "\n",
      "Fold: 24  Epoch: 550  Training loss = 4.1633  Validation loss = 1.7186  \n",
      "\n",
      "Fold: 24  Epoch: 551  Training loss = 4.1631  Validation loss = 1.7183  \n",
      "\n",
      "Fold: 24  Epoch: 552  Training loss = 4.1629  Validation loss = 1.7177  \n",
      "\n",
      "Fold: 24  Epoch: 553  Training loss = 4.1627  Validation loss = 1.7172  \n",
      "\n",
      "Fold: 24  Epoch: 554  Training loss = 4.1626  Validation loss = 1.7167  \n",
      "\n",
      "Fold: 24  Epoch: 555  Training loss = 4.1623  Validation loss = 1.7163  \n",
      "\n",
      "Fold: 24  Epoch: 556  Training loss = 4.1622  Validation loss = 1.7158  \n",
      "\n",
      "Fold: 24  Epoch: 557  Training loss = 4.1619  Validation loss = 1.7155  \n",
      "\n",
      "Fold: 24  Epoch: 558  Training loss = 4.1617  Validation loss = 1.7149  \n",
      "\n",
      "Fold: 24  Epoch: 559  Training loss = 4.1615  Validation loss = 1.7147  \n",
      "\n",
      "Fold: 24  Epoch: 560  Training loss = 4.1614  Validation loss = 1.7142  \n",
      "\n",
      "Fold: 24  Epoch: 561  Training loss = 4.1611  Validation loss = 1.7138  \n",
      "\n",
      "Fold: 24  Epoch: 562  Training loss = 4.1610  Validation loss = 1.7135  \n",
      "\n",
      "Fold: 24  Epoch: 563  Training loss = 4.1608  Validation loss = 1.7130  \n",
      "\n",
      "Fold: 24  Epoch: 564  Training loss = 4.1606  Validation loss = 1.7127  \n",
      "\n",
      "Fold: 24  Epoch: 565  Training loss = 4.1603  Validation loss = 1.7120  \n",
      "\n",
      "Fold: 24  Epoch: 566  Training loss = 4.1602  Validation loss = 1.7115  \n",
      "\n",
      "Fold: 24  Epoch: 567  Training loss = 4.1600  Validation loss = 1.7109  \n",
      "\n",
      "Fold: 24  Epoch: 568  Training loss = 4.1598  Validation loss = 1.7105  \n",
      "\n",
      "Fold: 24  Epoch: 569  Training loss = 4.1596  Validation loss = 1.7100  \n",
      "\n",
      "Fold: 24  Epoch: 570  Training loss = 4.1594  Validation loss = 1.7097  \n",
      "\n",
      "Fold: 24  Epoch: 571  Training loss = 4.1592  Validation loss = 1.7093  \n",
      "\n",
      "Fold: 24  Epoch: 572  Training loss = 4.1591  Validation loss = 1.7089  \n",
      "\n",
      "Fold: 24  Epoch: 573  Training loss = 4.1589  Validation loss = 1.7082  \n",
      "\n",
      "Fold: 24  Epoch: 574  Training loss = 4.1587  Validation loss = 1.7074  \n",
      "\n",
      "Fold: 24  Epoch: 575  Training loss = 4.1585  Validation loss = 1.7070  \n",
      "\n",
      "Fold: 24  Epoch: 576  Training loss = 4.1583  Validation loss = 1.7064  \n",
      "\n",
      "Fold: 24  Epoch: 577  Training loss = 4.1581  Validation loss = 1.7059  \n",
      "\n",
      "Fold: 24  Epoch: 578  Training loss = 4.1579  Validation loss = 1.7054  \n",
      "\n",
      "Fold: 24  Epoch: 579  Training loss = 4.1577  Validation loss = 1.7051  \n",
      "\n",
      "Fold: 24  Epoch: 580  Training loss = 4.1575  Validation loss = 1.7046  \n",
      "\n",
      "Fold: 24  Epoch: 581  Training loss = 4.1574  Validation loss = 1.7042  \n",
      "\n",
      "Fold: 24  Epoch: 582  Training loss = 4.1571  Validation loss = 1.7036  \n",
      "\n",
      "Fold: 24  Epoch: 583  Training loss = 4.1570  Validation loss = 1.7034  \n",
      "\n",
      "Fold: 24  Epoch: 584  Training loss = 4.1568  Validation loss = 1.7028  \n",
      "\n",
      "Fold: 24  Epoch: 585  Training loss = 4.1566  Validation loss = 1.7023  \n",
      "\n",
      "Fold: 24  Epoch: 586  Training loss = 4.1564  Validation loss = 1.7017  \n",
      "\n",
      "Fold: 24  Epoch: 587  Training loss = 4.1562  Validation loss = 1.7013  \n",
      "\n",
      "Fold: 24  Epoch: 588  Training loss = 4.1560  Validation loss = 1.7004  \n",
      "\n",
      "Fold: 24  Epoch: 589  Training loss = 4.1559  Validation loss = 1.7002  \n",
      "\n",
      "Fold: 24  Epoch: 590  Training loss = 4.1557  Validation loss = 1.6996  \n",
      "\n",
      "Fold: 24  Epoch: 591  Training loss = 4.1555  Validation loss = 1.6992  \n",
      "\n",
      "Fold: 24  Epoch: 592  Training loss = 4.1554  Validation loss = 1.6987  \n",
      "\n",
      "Fold: 24  Epoch: 593  Training loss = 4.1551  Validation loss = 1.6982  \n",
      "\n",
      "Fold: 24  Epoch: 594  Training loss = 4.1550  Validation loss = 1.6977  \n",
      "\n",
      "Fold: 24  Epoch: 595  Training loss = 4.1548  Validation loss = 1.6975  \n",
      "\n",
      "Fold: 24  Epoch: 596  Training loss = 4.1546  Validation loss = 1.6969  \n",
      "\n",
      "Fold: 24  Epoch: 597  Training loss = 4.1544  Validation loss = 1.6966  \n",
      "\n",
      "Fold: 24  Epoch: 598  Training loss = 4.1542  Validation loss = 1.6960  \n",
      "\n",
      "Fold: 24  Epoch: 599  Training loss = 4.1540  Validation loss = 1.6957  \n",
      "\n",
      "Fold: 24  Epoch: 600  Training loss = 4.1538  Validation loss = 1.6951  \n",
      "\n",
      "Fold: 24  Epoch: 601  Training loss = 4.1536  Validation loss = 1.6944  \n",
      "\n",
      "Fold: 24  Epoch: 602  Training loss = 4.1534  Validation loss = 1.6939  \n",
      "\n",
      "Fold: 24  Epoch: 603  Training loss = 4.1533  Validation loss = 1.6933  \n",
      "\n",
      "Fold: 24  Epoch: 604  Training loss = 4.1530  Validation loss = 1.6929  \n",
      "\n",
      "Fold: 24  Epoch: 605  Training loss = 4.1529  Validation loss = 1.6925  \n",
      "\n",
      "Fold: 24  Epoch: 606  Training loss = 4.1526  Validation loss = 1.6918  \n",
      "\n",
      "Fold: 24  Epoch: 607  Training loss = 4.1524  Validation loss = 1.6914  \n",
      "\n",
      "Fold: 24  Epoch: 608  Training loss = 4.1522  Validation loss = 1.6908  \n",
      "\n",
      "Fold: 24  Epoch: 609  Training loss = 4.1520  Validation loss = 1.6905  \n",
      "\n",
      "Fold: 24  Epoch: 610  Training loss = 4.1518  Validation loss = 1.6900  \n",
      "\n",
      "Fold: 24  Epoch: 611  Training loss = 4.1516  Validation loss = 1.6893  \n",
      "\n",
      "Fold: 24  Epoch: 612  Training loss = 4.1514  Validation loss = 1.6890  \n",
      "\n",
      "Fold: 24  Epoch: 613  Training loss = 4.1513  Validation loss = 1.6886  \n",
      "\n",
      "Fold: 24  Epoch: 614  Training loss = 4.1512  Validation loss = 1.6879  \n",
      "\n",
      "Fold: 24  Epoch: 615  Training loss = 4.1510  Validation loss = 1.6875  \n",
      "\n",
      "Fold: 24  Epoch: 616  Training loss = 4.1508  Validation loss = 1.6871  \n",
      "\n",
      "Fold: 24  Epoch: 617  Training loss = 4.1506  Validation loss = 1.6868  \n",
      "\n",
      "Fold: 24  Epoch: 618  Training loss = 4.1504  Validation loss = 1.6865  \n",
      "\n",
      "Fold: 24  Epoch: 619  Training loss = 4.1503  Validation loss = 1.6862  \n",
      "\n",
      "Fold: 24  Epoch: 620  Training loss = 4.1501  Validation loss = 1.6858  \n",
      "\n",
      "Fold: 24  Epoch: 621  Training loss = 4.1499  Validation loss = 1.6854  \n",
      "\n",
      "Fold: 24  Epoch: 622  Training loss = 4.1497  Validation loss = 1.6848  \n",
      "\n",
      "Fold: 24  Epoch: 623  Training loss = 4.1495  Validation loss = 1.6843  \n",
      "\n",
      "Fold: 24  Epoch: 624  Training loss = 4.1493  Validation loss = 1.6840  \n",
      "\n",
      "Fold: 24  Epoch: 625  Training loss = 4.1491  Validation loss = 1.6835  \n",
      "\n",
      "Fold: 24  Epoch: 626  Training loss = 4.1490  Validation loss = 1.6829  \n",
      "\n",
      "Fold: 24  Epoch: 627  Training loss = 4.1488  Validation loss = 1.6825  \n",
      "\n",
      "Fold: 24  Epoch: 628  Training loss = 4.1485  Validation loss = 1.6824  \n",
      "\n",
      "Fold: 24  Epoch: 629  Training loss = 4.1482  Validation loss = 1.6820  \n",
      "\n",
      "Fold: 24  Epoch: 630  Training loss = 4.1480  Validation loss = 1.6816  \n",
      "\n",
      "Fold: 24  Epoch: 631  Training loss = 4.1478  Validation loss = 1.6813  \n",
      "\n",
      "Fold: 24  Epoch: 632  Training loss = 4.1477  Validation loss = 1.6809  \n",
      "\n",
      "Fold: 24  Epoch: 633  Training loss = 4.1475  Validation loss = 1.6806  \n",
      "\n",
      "Fold: 24  Epoch: 634  Training loss = 4.1473  Validation loss = 1.6802  \n",
      "\n",
      "Fold: 24  Epoch: 635  Training loss = 4.1471  Validation loss = 1.6796  \n",
      "\n",
      "Fold: 24  Epoch: 636  Training loss = 4.1469  Validation loss = 1.6791  \n",
      "\n",
      "Fold: 24  Epoch: 637  Training loss = 4.1467  Validation loss = 1.6785  \n",
      "\n",
      "Fold: 24  Epoch: 638  Training loss = 4.1466  Validation loss = 1.6783  \n",
      "\n",
      "Fold: 24  Epoch: 639  Training loss = 4.1464  Validation loss = 1.6778  \n",
      "\n",
      "Fold: 24  Epoch: 640  Training loss = 4.1462  Validation loss = 1.6776  \n",
      "\n",
      "Fold: 24  Epoch: 641  Training loss = 4.1460  Validation loss = 1.6767  \n",
      "\n",
      "Fold: 24  Epoch: 642  Training loss = 4.1458  Validation loss = 1.6764  \n",
      "\n",
      "Fold: 24  Epoch: 643  Training loss = 4.1456  Validation loss = 1.6761  \n",
      "\n",
      "Fold: 24  Epoch: 644  Training loss = 4.1454  Validation loss = 1.6754  \n",
      "\n",
      "Fold: 24  Epoch: 645  Training loss = 4.1452  Validation loss = 1.6752  \n",
      "\n",
      "Fold: 24  Epoch: 646  Training loss = 4.1450  Validation loss = 1.6750  \n",
      "\n",
      "Fold: 24  Epoch: 647  Training loss = 4.1448  Validation loss = 1.6743  \n",
      "\n",
      "Fold: 24  Epoch: 648  Training loss = 4.1447  Validation loss = 1.6739  \n",
      "\n",
      "Fold: 24  Epoch: 649  Training loss = 4.1445  Validation loss = 1.6730  \n",
      "\n",
      "Fold: 24  Epoch: 650  Training loss = 4.1443  Validation loss = 1.6723  \n",
      "\n",
      "Fold: 24  Epoch: 651  Training loss = 4.1441  Validation loss = 1.6720  \n",
      "\n",
      "Fold: 24  Epoch: 652  Training loss = 4.1439  Validation loss = 1.6718  \n",
      "\n",
      "Fold: 24  Epoch: 653  Training loss = 4.1438  Validation loss = 1.6713  \n",
      "\n",
      "Fold: 24  Epoch: 654  Training loss = 4.1436  Validation loss = 1.6711  \n",
      "\n",
      "Fold: 24  Epoch: 655  Training loss = 4.1435  Validation loss = 1.6705  \n",
      "\n",
      "Fold: 24  Epoch: 656  Training loss = 4.1433  Validation loss = 1.6700  \n",
      "\n",
      "Fold: 24  Epoch: 657  Training loss = 4.1431  Validation loss = 1.6697  \n",
      "\n",
      "Fold: 24  Epoch: 658  Training loss = 4.1429  Validation loss = 1.6690  \n",
      "\n",
      "Fold: 24  Epoch: 659  Training loss = 4.1427  Validation loss = 1.6683  \n",
      "\n",
      "Fold: 24  Epoch: 660  Training loss = 4.1425  Validation loss = 1.6682  \n",
      "\n",
      "Fold: 24  Epoch: 661  Training loss = 4.1423  Validation loss = 1.6678  \n",
      "\n",
      "Fold: 24  Epoch: 662  Training loss = 4.1421  Validation loss = 1.6676  \n",
      "\n",
      "Fold: 24  Epoch: 663  Training loss = 4.1420  Validation loss = 1.6672  \n",
      "\n",
      "Fold: 24  Epoch: 664  Training loss = 4.1418  Validation loss = 1.6668  \n",
      "\n",
      "Fold: 24  Epoch: 665  Training loss = 4.1416  Validation loss = 1.6661  \n",
      "\n",
      "Fold: 24  Epoch: 666  Training loss = 4.1414  Validation loss = 1.6657  \n",
      "\n",
      "Fold: 24  Epoch: 667  Training loss = 4.1412  Validation loss = 1.6653  \n",
      "\n",
      "Fold: 24  Epoch: 668  Training loss = 4.1410  Validation loss = 1.6649  \n",
      "\n",
      "Fold: 24  Epoch: 669  Training loss = 4.1409  Validation loss = 1.6645  \n",
      "\n",
      "Fold: 24  Epoch: 670  Training loss = 4.1408  Validation loss = 1.6642  \n",
      "\n",
      "Fold: 24  Epoch: 671  Training loss = 4.1405  Validation loss = 1.6638  \n",
      "\n",
      "Fold: 24  Epoch: 672  Training loss = 4.1403  Validation loss = 1.6637  \n",
      "\n",
      "Fold: 24  Epoch: 673  Training loss = 4.1401  Validation loss = 1.6630  \n",
      "\n",
      "Fold: 24  Epoch: 674  Training loss = 4.1399  Validation loss = 1.6622  \n",
      "\n",
      "Fold: 24  Epoch: 675  Training loss = 4.1397  Validation loss = 1.6617  \n",
      "\n",
      "Fold: 24  Epoch: 676  Training loss = 4.1396  Validation loss = 1.6612  \n",
      "\n",
      "Fold: 24  Epoch: 677  Training loss = 4.1394  Validation loss = 1.6605  \n",
      "\n",
      "Fold: 24  Epoch: 678  Training loss = 4.1393  Validation loss = 1.6602  \n",
      "\n",
      "Fold: 24  Epoch: 679  Training loss = 4.1391  Validation loss = 1.6596  \n",
      "\n",
      "Fold: 24  Epoch: 680  Training loss = 4.1389  Validation loss = 1.6594  \n",
      "\n",
      "Fold: 24  Epoch: 681  Training loss = 4.1388  Validation loss = 1.6589  \n",
      "\n",
      "Fold: 24  Epoch: 682  Training loss = 4.1386  Validation loss = 1.6584  \n",
      "\n",
      "Fold: 24  Epoch: 683  Training loss = 4.1384  Validation loss = 1.6580  \n",
      "\n",
      "Fold: 24  Epoch: 684  Training loss = 4.1382  Validation loss = 1.6577  \n",
      "\n",
      "Fold: 24  Epoch: 685  Training loss = 4.1381  Validation loss = 1.6573  \n",
      "\n",
      "Fold: 24  Epoch: 686  Training loss = 4.1379  Validation loss = 1.6569  \n",
      "\n",
      "Fold: 24  Epoch: 687  Training loss = 4.1377  Validation loss = 1.6566  \n",
      "\n",
      "Fold: 24  Epoch: 688  Training loss = 4.1375  Validation loss = 1.6563  \n",
      "\n",
      "Fold: 24  Epoch: 689  Training loss = 4.1374  Validation loss = 1.6558  \n",
      "\n",
      "Fold: 24  Epoch: 690  Training loss = 4.1372  Validation loss = 1.6556  \n",
      "\n",
      "Fold: 24  Epoch: 691  Training loss = 4.1370  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 24  Epoch: 692  Training loss = 4.1368  Validation loss = 1.6546  \n",
      "\n",
      "Fold: 24  Epoch: 693  Training loss = 4.1367  Validation loss = 1.6543  \n",
      "\n",
      "Fold: 24  Epoch: 694  Training loss = 4.1365  Validation loss = 1.6536  \n",
      "\n",
      "Fold: 24  Epoch: 695  Training loss = 4.1363  Validation loss = 1.6530  \n",
      "\n",
      "Fold: 24  Epoch: 696  Training loss = 4.1361  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 24  Epoch: 697  Training loss = 4.1359  Validation loss = 1.6519  \n",
      "\n",
      "Fold: 24  Epoch: 698  Training loss = 4.1356  Validation loss = 1.6511  \n",
      "\n",
      "Fold: 24  Epoch: 699  Training loss = 4.1354  Validation loss = 1.6507  \n",
      "\n",
      "Fold: 24  Epoch: 700  Training loss = 4.1352  Validation loss = 1.6498  \n",
      "\n",
      "Fold: 24  Epoch: 701  Training loss = 4.1350  Validation loss = 1.6495  \n",
      "\n",
      "Fold: 24  Epoch: 702  Training loss = 4.1349  Validation loss = 1.6488  \n",
      "\n",
      "Fold: 24  Epoch: 703  Training loss = 4.1347  Validation loss = 1.6483  \n",
      "\n",
      "Fold: 24  Epoch: 704  Training loss = 4.1345  Validation loss = 1.6481  \n",
      "\n",
      "Fold: 24  Epoch: 705  Training loss = 4.1344  Validation loss = 1.6480  \n",
      "\n",
      "Fold: 24  Epoch: 706  Training loss = 4.1343  Validation loss = 1.6474  \n",
      "\n",
      "Fold: 24  Epoch: 707  Training loss = 4.1340  Validation loss = 1.6470  \n",
      "\n",
      "Fold: 24  Epoch: 708  Training loss = 4.1338  Validation loss = 1.6461  \n",
      "\n",
      "Fold: 24  Epoch: 709  Training loss = 4.1336  Validation loss = 1.6456  \n",
      "\n",
      "Fold: 24  Epoch: 710  Training loss = 4.1333  Validation loss = 1.6448  \n",
      "\n",
      "Fold: 24  Epoch: 711  Training loss = 4.1331  Validation loss = 1.6445  \n",
      "\n",
      "Fold: 24  Epoch: 712  Training loss = 4.1330  Validation loss = 1.6442  \n",
      "\n",
      "Fold: 24  Epoch: 713  Training loss = 4.1329  Validation loss = 1.6439  \n",
      "\n",
      "Fold: 24  Epoch: 714  Training loss = 4.1327  Validation loss = 1.6436  \n",
      "\n",
      "Fold: 24  Epoch: 715  Training loss = 4.1325  Validation loss = 1.6431  \n",
      "\n",
      "Fold: 24  Epoch: 716  Training loss = 4.1323  Validation loss = 1.6427  \n",
      "\n",
      "Fold: 24  Epoch: 717  Training loss = 4.1321  Validation loss = 1.6425  \n",
      "\n",
      "Fold: 24  Epoch: 718  Training loss = 4.1319  Validation loss = 1.6420  \n",
      "\n",
      "Fold: 24  Epoch: 719  Training loss = 4.1318  Validation loss = 1.6417  \n",
      "\n",
      "Fold: 24  Epoch: 720  Training loss = 4.1316  Validation loss = 1.6415  \n",
      "\n",
      "Fold: 24  Epoch: 721  Training loss = 4.1314  Validation loss = 1.6410  \n",
      "\n",
      "Fold: 24  Epoch: 722  Training loss = 4.1311  Validation loss = 1.6407  \n",
      "\n",
      "Fold: 24  Epoch: 723  Training loss = 4.1309  Validation loss = 1.6399  \n",
      "\n",
      "Fold: 24  Epoch: 724  Training loss = 4.1307  Validation loss = 1.6395  \n",
      "\n",
      "Fold: 24  Epoch: 725  Training loss = 4.1305  Validation loss = 1.6391  \n",
      "\n",
      "Fold: 24  Epoch: 726  Training loss = 4.1303  Validation loss = 1.6386  \n",
      "\n",
      "Fold: 24  Epoch: 727  Training loss = 4.1302  Validation loss = 1.6381  \n",
      "\n",
      "Fold: 24  Epoch: 728  Training loss = 4.1301  Validation loss = 1.6378  \n",
      "\n",
      "Fold: 24  Epoch: 729  Training loss = 4.1300  Validation loss = 1.6374  \n",
      "\n",
      "Fold: 24  Epoch: 730  Training loss = 4.1298  Validation loss = 1.6370  \n",
      "\n",
      "Fold: 24  Epoch: 731  Training loss = 4.1297  Validation loss = 1.6368  \n",
      "\n",
      "Fold: 24  Epoch: 732  Training loss = 4.1295  Validation loss = 1.6363  \n",
      "\n",
      "Fold: 24  Epoch: 733  Training loss = 4.1294  Validation loss = 1.6359  \n",
      "\n",
      "Fold: 24  Epoch: 734  Training loss = 4.1292  Validation loss = 1.6355  \n",
      "\n",
      "Fold: 24  Epoch: 735  Training loss = 4.1290  Validation loss = 1.6351  \n",
      "\n",
      "Fold: 24  Epoch: 736  Training loss = 4.1289  Validation loss = 1.6348  \n",
      "\n",
      "Fold: 24  Epoch: 737  Training loss = 4.1287  Validation loss = 1.6346  \n",
      "\n",
      "Fold: 24  Epoch: 738  Training loss = 4.1285  Validation loss = 1.6339  \n",
      "\n",
      "Fold: 24  Epoch: 739  Training loss = 4.1283  Validation loss = 1.6334  \n",
      "\n",
      "Fold: 24  Epoch: 740  Training loss = 4.1282  Validation loss = 1.6331  \n",
      "\n",
      "Fold: 24  Epoch: 741  Training loss = 4.1280  Validation loss = 1.6324  \n",
      "\n",
      "Fold: 24  Epoch: 742  Training loss = 4.1279  Validation loss = 1.6318  \n",
      "\n",
      "Fold: 24  Epoch: 743  Training loss = 4.1276  Validation loss = 1.6315  \n",
      "\n",
      "Fold: 24  Epoch: 744  Training loss = 4.1274  Validation loss = 1.6313  \n",
      "\n",
      "Fold: 24  Epoch: 745  Training loss = 4.1272  Validation loss = 1.6311  \n",
      "\n",
      "Fold: 24  Epoch: 746  Training loss = 4.1270  Validation loss = 1.6303  \n",
      "\n",
      "Fold: 24  Epoch: 747  Training loss = 4.1268  Validation loss = 1.6297  \n",
      "\n",
      "Fold: 24  Epoch: 748  Training loss = 4.1267  Validation loss = 1.6292  \n",
      "\n",
      "Fold: 24  Epoch: 749  Training loss = 4.1264  Validation loss = 1.6287  \n",
      "\n",
      "Fold: 24  Epoch: 750  Training loss = 4.1263  Validation loss = 1.6287  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 750  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 4.0864  Validation loss = 2.6885  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 4.0862  Validation loss = 2.6882  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 4.0860  Validation loss = 2.6880  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 4.0858  Validation loss = 2.6876  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 4.0856  Validation loss = 2.6872  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 4.0854  Validation loss = 2.6869  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 4.0852  Validation loss = 2.6865  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 4.0850  Validation loss = 2.6863  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 4.0849  Validation loss = 2.6861  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 4.0847  Validation loss = 2.6858  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 4.0845  Validation loss = 2.6856  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 4.0844  Validation loss = 2.6853  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 4.0842  Validation loss = 2.6850  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 4.0840  Validation loss = 2.6849  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 4.0838  Validation loss = 2.6846  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 4.0836  Validation loss = 2.6843  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 4.0835  Validation loss = 2.6840  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 4.0833  Validation loss = 2.6836  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 4.0832  Validation loss = 2.6833  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 4.0829  Validation loss = 2.6829  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 4.0827  Validation loss = 2.6826  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 4.0825  Validation loss = 2.6821  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 4.0824  Validation loss = 2.6819  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 4.0822  Validation loss = 2.6816  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 4.0820  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 4.0818  Validation loss = 2.6809  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 4.0816  Validation loss = 2.6807  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 4.0814  Validation loss = 2.6801  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 4.0812  Validation loss = 2.6798  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 4.0810  Validation loss = 2.6795  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 4.0809  Validation loss = 2.6793  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 4.0807  Validation loss = 2.6792  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 4.0805  Validation loss = 2.6789  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 4.0803  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 4.0802  Validation loss = 2.6785  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 4.0800  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 4.0798  Validation loss = 2.6777  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 4.0797  Validation loss = 2.6777  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 4.0795  Validation loss = 2.6772  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 4.0793  Validation loss = 2.6770  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 4.0791  Validation loss = 2.6766  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 4.0789  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 4.0788  Validation loss = 2.6761  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 4.0786  Validation loss = 2.6760  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 4.0784  Validation loss = 2.6757  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 4.0782  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 4.0780  Validation loss = 2.6751  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 4.0779  Validation loss = 2.6749  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 4.0777  Validation loss = 2.6747  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 4.0775  Validation loss = 2.6743  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 4.0774  Validation loss = 2.6741  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 4.0772  Validation loss = 2.6739  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 4.0771  Validation loss = 2.6738  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 4.0769  Validation loss = 2.6736  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 4.0767  Validation loss = 2.6733  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 4.0765  Validation loss = 2.6730  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 4.0764  Validation loss = 2.6728  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 4.0762  Validation loss = 2.6725  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 4.0760  Validation loss = 2.6722  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 4.0758  Validation loss = 2.6720  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 4.0756  Validation loss = 2.6717  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 4.0754  Validation loss = 2.6713  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 4.0752  Validation loss = 2.6709  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 4.0750  Validation loss = 2.6707  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 4.0748  Validation loss = 2.6703  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 4.0745  Validation loss = 2.6698  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 4.0743  Validation loss = 2.6694  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 4.0742  Validation loss = 2.6693  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 4.0741  Validation loss = 2.6690  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 4.0739  Validation loss = 2.6688  \n",
      "\n",
      "Fold: 25  Epoch: 71  Training loss = 4.0738  Validation loss = 2.6686  \n",
      "\n",
      "Fold: 25  Epoch: 72  Training loss = 4.0737  Validation loss = 2.6683  \n",
      "\n",
      "Fold: 25  Epoch: 73  Training loss = 4.0735  Validation loss = 2.6681  \n",
      "\n",
      "Fold: 25  Epoch: 74  Training loss = 4.0733  Validation loss = 2.6678  \n",
      "\n",
      "Fold: 25  Epoch: 75  Training loss = 4.0731  Validation loss = 2.6674  \n",
      "\n",
      "Fold: 25  Epoch: 76  Training loss = 4.0730  Validation loss = 2.6673  \n",
      "\n",
      "Fold: 25  Epoch: 77  Training loss = 4.0728  Validation loss = 2.6670  \n",
      "\n",
      "Fold: 25  Epoch: 78  Training loss = 4.0726  Validation loss = 2.6667  \n",
      "\n",
      "Fold: 25  Epoch: 79  Training loss = 4.0725  Validation loss = 2.6666  \n",
      "\n",
      "Fold: 25  Epoch: 80  Training loss = 4.0723  Validation loss = 2.6662  \n",
      "\n",
      "Fold: 25  Epoch: 81  Training loss = 4.0722  Validation loss = 2.6660  \n",
      "\n",
      "Fold: 25  Epoch: 82  Training loss = 4.0720  Validation loss = 2.6659  \n",
      "\n",
      "Fold: 25  Epoch: 83  Training loss = 4.0717  Validation loss = 2.6656  \n",
      "\n",
      "Fold: 25  Epoch: 84  Training loss = 4.0716  Validation loss = 2.6653  \n",
      "\n",
      "Fold: 25  Epoch: 85  Training loss = 4.0714  Validation loss = 2.6650  \n",
      "\n",
      "Fold: 25  Epoch: 86  Training loss = 4.0712  Validation loss = 2.6648  \n",
      "\n",
      "Fold: 25  Epoch: 87  Training loss = 4.0711  Validation loss = 2.6647  \n",
      "\n",
      "Fold: 25  Epoch: 88  Training loss = 4.0709  Validation loss = 2.6644  \n",
      "\n",
      "Fold: 25  Epoch: 89  Training loss = 4.0707  Validation loss = 2.6642  \n",
      "\n",
      "Fold: 25  Epoch: 90  Training loss = 4.0706  Validation loss = 2.6641  \n",
      "\n",
      "Fold: 25  Epoch: 91  Training loss = 4.0705  Validation loss = 2.6638  \n",
      "\n",
      "Fold: 25  Epoch: 92  Training loss = 4.0703  Validation loss = 2.6635  \n",
      "\n",
      "Fold: 25  Epoch: 93  Training loss = 4.0701  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 25  Epoch: 94  Training loss = 4.0699  Validation loss = 2.6628  \n",
      "\n",
      "Fold: 25  Epoch: 95  Training loss = 4.0697  Validation loss = 2.6628  \n",
      "\n",
      "Fold: 25  Epoch: 96  Training loss = 4.0695  Validation loss = 2.6624  \n",
      "\n",
      "Fold: 25  Epoch: 97  Training loss = 4.0693  Validation loss = 2.6622  \n",
      "\n",
      "Fold: 25  Epoch: 98  Training loss = 4.0691  Validation loss = 2.6620  \n",
      "\n",
      "Fold: 25  Epoch: 99  Training loss = 4.0689  Validation loss = 2.6617  \n",
      "\n",
      "Fold: 25  Epoch: 100  Training loss = 4.0688  Validation loss = 2.6615  \n",
      "\n",
      "Fold: 25  Epoch: 101  Training loss = 4.0686  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 25  Epoch: 102  Training loss = 4.0684  Validation loss = 2.6609  \n",
      "\n",
      "Fold: 25  Epoch: 103  Training loss = 4.0683  Validation loss = 2.6607  \n",
      "\n",
      "Fold: 25  Epoch: 104  Training loss = 4.0680  Validation loss = 2.6602  \n",
      "\n",
      "Fold: 25  Epoch: 105  Training loss = 4.0678  Validation loss = 2.6598  \n",
      "\n",
      "Fold: 25  Epoch: 106  Training loss = 4.0676  Validation loss = 2.6596  \n",
      "\n",
      "Fold: 25  Epoch: 107  Training loss = 4.0675  Validation loss = 2.6594  \n",
      "\n",
      "Fold: 25  Epoch: 108  Training loss = 4.0673  Validation loss = 2.6592  \n",
      "\n",
      "Fold: 25  Epoch: 109  Training loss = 4.0672  Validation loss = 2.6590  \n",
      "\n",
      "Fold: 25  Epoch: 110  Training loss = 4.0670  Validation loss = 2.6587  \n",
      "\n",
      "Fold: 25  Epoch: 111  Training loss = 4.0669  Validation loss = 2.6586  \n",
      "\n",
      "Fold: 25  Epoch: 112  Training loss = 4.0666  Validation loss = 2.6583  \n",
      "\n",
      "Fold: 25  Epoch: 113  Training loss = 4.0665  Validation loss = 2.6580  \n",
      "\n",
      "Fold: 25  Epoch: 114  Training loss = 4.0663  Validation loss = 2.6579  \n",
      "\n",
      "Fold: 25  Epoch: 115  Training loss = 4.0662  Validation loss = 2.6576  \n",
      "\n",
      "Fold: 25  Epoch: 116  Training loss = 4.0660  Validation loss = 2.6573  \n",
      "\n",
      "Fold: 25  Epoch: 117  Training loss = 4.0659  Validation loss = 2.6572  \n",
      "\n",
      "Fold: 25  Epoch: 118  Training loss = 4.0657  Validation loss = 2.6569  \n",
      "\n",
      "Fold: 25  Epoch: 119  Training loss = 4.0655  Validation loss = 2.6566  \n",
      "\n",
      "Fold: 25  Epoch: 120  Training loss = 4.0654  Validation loss = 2.6564  \n",
      "\n",
      "Fold: 25  Epoch: 121  Training loss = 4.0652  Validation loss = 2.6562  \n",
      "\n",
      "Fold: 25  Epoch: 122  Training loss = 4.0650  Validation loss = 2.6561  \n",
      "\n",
      "Fold: 25  Epoch: 123  Training loss = 4.0649  Validation loss = 2.6560  \n",
      "\n",
      "Fold: 25  Epoch: 124  Training loss = 4.0648  Validation loss = 2.6558  \n",
      "\n",
      "Fold: 25  Epoch: 125  Training loss = 4.0646  Validation loss = 2.6556  \n",
      "\n",
      "Fold: 25  Epoch: 126  Training loss = 4.0645  Validation loss = 2.6554  \n",
      "\n",
      "Fold: 25  Epoch: 127  Training loss = 4.0643  Validation loss = 2.6552  \n",
      "\n",
      "Fold: 25  Epoch: 128  Training loss = 4.0642  Validation loss = 2.6550  \n",
      "\n",
      "Fold: 25  Epoch: 129  Training loss = 4.0639  Validation loss = 2.6546  \n",
      "\n",
      "Fold: 25  Epoch: 130  Training loss = 4.0637  Validation loss = 2.6541  \n",
      "\n",
      "Fold: 25  Epoch: 131  Training loss = 4.0636  Validation loss = 2.6538  \n",
      "\n",
      "Fold: 25  Epoch: 132  Training loss = 4.0633  Validation loss = 2.6534  \n",
      "\n",
      "Fold: 25  Epoch: 133  Training loss = 4.0632  Validation loss = 2.6531  \n",
      "\n",
      "Fold: 25  Epoch: 134  Training loss = 4.0630  Validation loss = 2.6530  \n",
      "\n",
      "Fold: 25  Epoch: 135  Training loss = 4.0629  Validation loss = 2.6530  \n",
      "\n",
      "Fold: 25  Epoch: 136  Training loss = 4.0627  Validation loss = 2.6528  \n",
      "\n",
      "Fold: 25  Epoch: 137  Training loss = 4.0625  Validation loss = 2.6526  \n",
      "\n",
      "Fold: 25  Epoch: 138  Training loss = 4.0623  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 25  Epoch: 139  Training loss = 4.0621  Validation loss = 2.6520  \n",
      "\n",
      "Fold: 25  Epoch: 140  Training loss = 4.0620  Validation loss = 2.6519  \n",
      "\n",
      "Fold: 25  Epoch: 141  Training loss = 4.0619  Validation loss = 2.6518  \n",
      "\n",
      "Fold: 25  Epoch: 142  Training loss = 4.0617  Validation loss = 2.6516  \n",
      "\n",
      "Fold: 25  Epoch: 143  Training loss = 4.0616  Validation loss = 2.6513  \n",
      "\n",
      "Fold: 25  Epoch: 144  Training loss = 4.0614  Validation loss = 2.6510  \n",
      "\n",
      "Fold: 25  Epoch: 145  Training loss = 4.0612  Validation loss = 2.6508  \n",
      "\n",
      "Fold: 25  Epoch: 146  Training loss = 4.0611  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 25  Epoch: 147  Training loss = 4.0609  Validation loss = 2.6504  \n",
      "\n",
      "Fold: 25  Epoch: 148  Training loss = 4.0608  Validation loss = 2.6502  \n",
      "\n",
      "Fold: 25  Epoch: 149  Training loss = 4.0606  Validation loss = 2.6501  \n",
      "\n",
      "Fold: 25  Epoch: 150  Training loss = 4.0604  Validation loss = 2.6497  \n",
      "\n",
      "Fold: 25  Epoch: 151  Training loss = 4.0603  Validation loss = 2.6496  \n",
      "\n",
      "Fold: 25  Epoch: 152  Training loss = 4.0602  Validation loss = 2.6494  \n",
      "\n",
      "Fold: 25  Epoch: 153  Training loss = 4.0601  Validation loss = 2.6494  \n",
      "\n",
      "Fold: 25  Epoch: 154  Training loss = 4.0599  Validation loss = 2.6491  \n",
      "\n",
      "Fold: 25  Epoch: 155  Training loss = 4.0597  Validation loss = 2.6489  \n",
      "\n",
      "Fold: 25  Epoch: 156  Training loss = 4.0595  Validation loss = 2.6486  \n",
      "\n",
      "Fold: 25  Epoch: 157  Training loss = 4.0594  Validation loss = 2.6483  \n",
      "\n",
      "Fold: 25  Epoch: 158  Training loss = 4.0592  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 25  Epoch: 159  Training loss = 4.0590  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 25  Epoch: 160  Training loss = 4.0589  Validation loss = 2.6475  \n",
      "\n",
      "Fold: 25  Epoch: 161  Training loss = 4.0587  Validation loss = 2.6474  \n",
      "\n",
      "Fold: 25  Epoch: 162  Training loss = 4.0586  Validation loss = 2.6471  \n",
      "\n",
      "Fold: 25  Epoch: 163  Training loss = 4.0584  Validation loss = 2.6468  \n",
      "\n",
      "Fold: 25  Epoch: 164  Training loss = 4.0583  Validation loss = 2.6467  \n",
      "\n",
      "Fold: 25  Epoch: 165  Training loss = 4.0581  Validation loss = 2.6464  \n",
      "\n",
      "Fold: 25  Epoch: 166  Training loss = 4.0579  Validation loss = 2.6462  \n",
      "\n",
      "Fold: 25  Epoch: 167  Training loss = 4.0577  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 25  Epoch: 168  Training loss = 4.0576  Validation loss = 2.6459  \n",
      "\n",
      "Fold: 25  Epoch: 169  Training loss = 4.0574  Validation loss = 2.6455  \n",
      "\n",
      "Fold: 25  Epoch: 170  Training loss = 4.0572  Validation loss = 2.6454  \n",
      "\n",
      "Fold: 25  Epoch: 171  Training loss = 4.0571  Validation loss = 2.6451  \n",
      "\n",
      "Fold: 25  Epoch: 172  Training loss = 4.0569  Validation loss = 2.6449  \n",
      "\n",
      "Fold: 25  Epoch: 173  Training loss = 4.0568  Validation loss = 2.6447  \n",
      "\n",
      "Fold: 25  Epoch: 174  Training loss = 4.0566  Validation loss = 2.6445  \n",
      "\n",
      "Fold: 25  Epoch: 175  Training loss = 4.0565  Validation loss = 2.6444  \n",
      "\n",
      "Fold: 25  Epoch: 176  Training loss = 4.0563  Validation loss = 2.6440  \n",
      "\n",
      "Fold: 25  Epoch: 177  Training loss = 4.0561  Validation loss = 2.6439  \n",
      "\n",
      "Fold: 25  Epoch: 178  Training loss = 4.0559  Validation loss = 2.6436  \n",
      "\n",
      "Fold: 25  Epoch: 179  Training loss = 4.0557  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 25  Epoch: 180  Training loss = 4.0556  Validation loss = 2.6428  \n",
      "\n",
      "Fold: 25  Epoch: 181  Training loss = 4.0554  Validation loss = 2.6426  \n",
      "\n",
      "Fold: 25  Epoch: 182  Training loss = 4.0553  Validation loss = 2.6425  \n",
      "\n",
      "Fold: 25  Epoch: 183  Training loss = 4.0550  Validation loss = 2.6421  \n",
      "\n",
      "Fold: 25  Epoch: 184  Training loss = 4.0549  Validation loss = 2.6419  \n",
      "\n",
      "Fold: 25  Epoch: 185  Training loss = 4.0547  Validation loss = 2.6416  \n",
      "\n",
      "Fold: 25  Epoch: 186  Training loss = 4.0545  Validation loss = 2.6413  \n",
      "\n",
      "Fold: 25  Epoch: 187  Training loss = 4.0544  Validation loss = 2.6411  \n",
      "\n",
      "Fold: 25  Epoch: 188  Training loss = 4.0542  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 25  Epoch: 189  Training loss = 4.0540  Validation loss = 2.6406  \n",
      "\n",
      "Fold: 25  Epoch: 190  Training loss = 4.0539  Validation loss = 2.6403  \n",
      "\n",
      "Fold: 25  Epoch: 191  Training loss = 4.0538  Validation loss = 2.6402  \n",
      "\n",
      "Fold: 25  Epoch: 192  Training loss = 4.0536  Validation loss = 2.6400  \n",
      "\n",
      "Fold: 25  Epoch: 193  Training loss = 4.0534  Validation loss = 2.6398  \n",
      "\n",
      "Fold: 25  Epoch: 194  Training loss = 4.0534  Validation loss = 2.6398  \n",
      "\n",
      "Fold: 25  Epoch: 195  Training loss = 4.0532  Validation loss = 2.6396  \n",
      "\n",
      "Fold: 25  Epoch: 196  Training loss = 4.0530  Validation loss = 2.6393  \n",
      "\n",
      "Fold: 25  Epoch: 197  Training loss = 4.0529  Validation loss = 2.6394  \n",
      "\n",
      "Fold: 25  Epoch: 198  Training loss = 4.0527  Validation loss = 2.6391  \n",
      "\n",
      "Fold: 25  Epoch: 199  Training loss = 4.0526  Validation loss = 2.6390  \n",
      "\n",
      "Fold: 25  Epoch: 200  Training loss = 4.0525  Validation loss = 2.6388  \n",
      "\n",
      "Fold: 25  Epoch: 201  Training loss = 4.0524  Validation loss = 2.6386  \n",
      "\n",
      "Fold: 25  Epoch: 202  Training loss = 4.0522  Validation loss = 2.6384  \n",
      "\n",
      "Fold: 25  Epoch: 203  Training loss = 4.0520  Validation loss = 2.6382  \n",
      "\n",
      "Fold: 25  Epoch: 204  Training loss = 4.0518  Validation loss = 2.6377  \n",
      "\n",
      "Fold: 25  Epoch: 205  Training loss = 4.0516  Validation loss = 2.6374  \n",
      "\n",
      "Fold: 25  Epoch: 206  Training loss = 4.0514  Validation loss = 2.6372  \n",
      "\n",
      "Fold: 25  Epoch: 207  Training loss = 4.0512  Validation loss = 2.6369  \n",
      "\n",
      "Fold: 25  Epoch: 208  Training loss = 4.0510  Validation loss = 2.6366  \n",
      "\n",
      "Fold: 25  Epoch: 209  Training loss = 4.0509  Validation loss = 2.6364  \n",
      "\n",
      "Fold: 25  Epoch: 210  Training loss = 4.0507  Validation loss = 2.6361  \n",
      "\n",
      "Fold: 25  Epoch: 211  Training loss = 4.0505  Validation loss = 2.6358  \n",
      "\n",
      "Fold: 25  Epoch: 212  Training loss = 4.0503  Validation loss = 2.6354  \n",
      "\n",
      "Fold: 25  Epoch: 213  Training loss = 4.0501  Validation loss = 2.6350  \n",
      "\n",
      "Fold: 25  Epoch: 214  Training loss = 4.0501  Validation loss = 2.6350  \n",
      "\n",
      "Fold: 25  Epoch: 215  Training loss = 4.0499  Validation loss = 2.6348  \n",
      "\n",
      "Fold: 25  Epoch: 216  Training loss = 4.0498  Validation loss = 2.6345  \n",
      "\n",
      "Fold: 25  Epoch: 217  Training loss = 4.0496  Validation loss = 2.6341  \n",
      "\n",
      "Fold: 25  Epoch: 218  Training loss = 4.0494  Validation loss = 2.6339  \n",
      "\n",
      "Fold: 25  Epoch: 219  Training loss = 4.0493  Validation loss = 2.6336  \n",
      "\n",
      "Fold: 25  Epoch: 220  Training loss = 4.0491  Validation loss = 2.6333  \n",
      "\n",
      "Fold: 25  Epoch: 221  Training loss = 4.0489  Validation loss = 2.6330  \n",
      "\n",
      "Fold: 25  Epoch: 222  Training loss = 4.0487  Validation loss = 2.6326  \n",
      "\n",
      "Fold: 25  Epoch: 223  Training loss = 4.0486  Validation loss = 2.6325  \n",
      "\n",
      "Fold: 25  Epoch: 224  Training loss = 4.0483  Validation loss = 2.6320  \n",
      "\n",
      "Fold: 25  Epoch: 225  Training loss = 4.0482  Validation loss = 2.6321  \n",
      "\n",
      "Fold: 25  Epoch: 226  Training loss = 4.0480  Validation loss = 2.6317  \n",
      "\n",
      "Fold: 25  Epoch: 227  Training loss = 4.0478  Validation loss = 2.6314  \n",
      "\n",
      "Fold: 25  Epoch: 228  Training loss = 4.0477  Validation loss = 2.6312  \n",
      "\n",
      "Fold: 25  Epoch: 229  Training loss = 4.0475  Validation loss = 2.6309  \n",
      "\n",
      "Fold: 25  Epoch: 230  Training loss = 4.0474  Validation loss = 2.6307  \n",
      "\n",
      "Fold: 25  Epoch: 231  Training loss = 4.0472  Validation loss = 2.6305  \n",
      "\n",
      "Fold: 25  Epoch: 232  Training loss = 4.0470  Validation loss = 2.6301  \n",
      "\n",
      "Fold: 25  Epoch: 233  Training loss = 4.0469  Validation loss = 2.6299  \n",
      "\n",
      "Fold: 25  Epoch: 234  Training loss = 4.0467  Validation loss = 2.6294  \n",
      "\n",
      "Fold: 25  Epoch: 235  Training loss = 4.0465  Validation loss = 2.6292  \n",
      "\n",
      "Fold: 25  Epoch: 236  Training loss = 4.0463  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 25  Epoch: 237  Training loss = 4.0462  Validation loss = 2.6286  \n",
      "\n",
      "Fold: 25  Epoch: 238  Training loss = 4.0460  Validation loss = 2.6281  \n",
      "\n",
      "Fold: 25  Epoch: 239  Training loss = 4.0459  Validation loss = 2.6281  \n",
      "\n",
      "Fold: 25  Epoch: 240  Training loss = 4.0456  Validation loss = 2.6275  \n",
      "\n",
      "Fold: 25  Epoch: 241  Training loss = 4.0455  Validation loss = 2.6273  \n",
      "\n",
      "Fold: 25  Epoch: 242  Training loss = 4.0454  Validation loss = 2.6273  \n",
      "\n",
      "Fold: 25  Epoch: 243  Training loss = 4.0452  Validation loss = 2.6270  \n",
      "\n",
      "Fold: 25  Epoch: 244  Training loss = 4.0450  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 25  Epoch: 245  Training loss = 4.0448  Validation loss = 2.6264  \n",
      "\n",
      "Fold: 25  Epoch: 246  Training loss = 4.0446  Validation loss = 2.6258  \n",
      "\n",
      "Fold: 25  Epoch: 247  Training loss = 4.0445  Validation loss = 2.6255  \n",
      "\n",
      "Fold: 25  Epoch: 248  Training loss = 4.0442  Validation loss = 2.6252  \n",
      "\n",
      "Fold: 25  Epoch: 249  Training loss = 4.0441  Validation loss = 2.6249  \n",
      "\n",
      "Fold: 25  Epoch: 250  Training loss = 4.0440  Validation loss = 2.6248  \n",
      "\n",
      "Fold: 25  Epoch: 251  Training loss = 4.0439  Validation loss = 2.6247  \n",
      "\n",
      "Fold: 25  Epoch: 252  Training loss = 4.0438  Validation loss = 2.6244  \n",
      "\n",
      "Fold: 25  Epoch: 253  Training loss = 4.0435  Validation loss = 2.6239  \n",
      "\n",
      "Fold: 25  Epoch: 254  Training loss = 4.0434  Validation loss = 2.6237  \n",
      "\n",
      "Fold: 25  Epoch: 255  Training loss = 4.0433  Validation loss = 2.6237  \n",
      "\n",
      "Fold: 25  Epoch: 256  Training loss = 4.0432  Validation loss = 2.6235  \n",
      "\n",
      "Fold: 25  Epoch: 257  Training loss = 4.0430  Validation loss = 2.6233  \n",
      "\n",
      "Fold: 25  Epoch: 258  Training loss = 4.0429  Validation loss = 2.6231  \n",
      "\n",
      "Fold: 25  Epoch: 259  Training loss = 4.0427  Validation loss = 2.6229  \n",
      "\n",
      "Fold: 25  Epoch: 260  Training loss = 4.0426  Validation loss = 2.6227  \n",
      "\n",
      "Fold: 25  Epoch: 261  Training loss = 4.0424  Validation loss = 2.6224  \n",
      "\n",
      "Fold: 25  Epoch: 262  Training loss = 4.0422  Validation loss = 2.6219  \n",
      "\n",
      "Fold: 25  Epoch: 263  Training loss = 4.0421  Validation loss = 2.6217  \n",
      "\n",
      "Fold: 25  Epoch: 264  Training loss = 4.0419  Validation loss = 2.6214  \n",
      "\n",
      "Fold: 25  Epoch: 265  Training loss = 4.0417  Validation loss = 2.6210  \n",
      "\n",
      "Fold: 25  Epoch: 266  Training loss = 4.0416  Validation loss = 2.6208  \n",
      "\n",
      "Fold: 25  Epoch: 267  Training loss = 4.0414  Validation loss = 2.6206  \n",
      "\n",
      "Fold: 25  Epoch: 268  Training loss = 4.0413  Validation loss = 2.6204  \n",
      "\n",
      "Fold: 25  Epoch: 269  Training loss = 4.0411  Validation loss = 2.6202  \n",
      "\n",
      "Fold: 25  Epoch: 270  Training loss = 4.0410  Validation loss = 2.6200  \n",
      "\n",
      "Fold: 25  Epoch: 271  Training loss = 4.0408  Validation loss = 2.6197  \n",
      "\n",
      "Fold: 25  Epoch: 272  Training loss = 4.0406  Validation loss = 2.6195  \n",
      "\n",
      "Fold: 25  Epoch: 273  Training loss = 4.0404  Validation loss = 2.6193  \n",
      "\n",
      "Fold: 25  Epoch: 274  Training loss = 4.0402  Validation loss = 2.6190  \n",
      "\n",
      "Fold: 25  Epoch: 275  Training loss = 4.0401  Validation loss = 2.6188  \n",
      "\n",
      "Fold: 25  Epoch: 276  Training loss = 4.0399  Validation loss = 2.6186  \n",
      "\n",
      "Fold: 25  Epoch: 277  Training loss = 4.0397  Validation loss = 2.6181  \n",
      "\n",
      "Fold: 25  Epoch: 278  Training loss = 4.0395  Validation loss = 2.6179  \n",
      "\n",
      "Fold: 25  Epoch: 279  Training loss = 4.0393  Validation loss = 2.6176  \n",
      "\n",
      "Fold: 25  Epoch: 280  Training loss = 4.0392  Validation loss = 2.6175  \n",
      "\n",
      "Fold: 25  Epoch: 281  Training loss = 4.0390  Validation loss = 2.6173  \n",
      "\n",
      "Fold: 25  Epoch: 282  Training loss = 4.0388  Validation loss = 2.6169  \n",
      "\n",
      "Fold: 25  Epoch: 283  Training loss = 4.0386  Validation loss = 2.6166  \n",
      "\n",
      "Fold: 25  Epoch: 284  Training loss = 4.0384  Validation loss = 2.6165  \n",
      "\n",
      "Fold: 25  Epoch: 285  Training loss = 4.0383  Validation loss = 2.6164  \n",
      "\n",
      "Fold: 25  Epoch: 286  Training loss = 4.0381  Validation loss = 2.6160  \n",
      "\n",
      "Fold: 25  Epoch: 287  Training loss = 4.0379  Validation loss = 2.6159  \n",
      "\n",
      "Fold: 25  Epoch: 288  Training loss = 4.0377  Validation loss = 2.6154  \n",
      "\n",
      "Fold: 25  Epoch: 289  Training loss = 4.0375  Validation loss = 2.6148  \n",
      "\n",
      "Fold: 25  Epoch: 290  Training loss = 4.0373  Validation loss = 2.6143  \n",
      "\n",
      "Fold: 25  Epoch: 291  Training loss = 4.0370  Validation loss = 2.6138  \n",
      "\n",
      "Fold: 25  Epoch: 292  Training loss = 4.0369  Validation loss = 2.6134  \n",
      "\n",
      "Fold: 25  Epoch: 293  Training loss = 4.0367  Validation loss = 2.6131  \n",
      "\n",
      "Fold: 25  Epoch: 294  Training loss = 4.0366  Validation loss = 2.6130  \n",
      "\n",
      "Fold: 25  Epoch: 295  Training loss = 4.0364  Validation loss = 2.6129  \n",
      "\n",
      "Fold: 25  Epoch: 296  Training loss = 4.0363  Validation loss = 2.6128  \n",
      "\n",
      "Fold: 25  Epoch: 297  Training loss = 4.0361  Validation loss = 2.6124  \n",
      "\n",
      "Fold: 25  Epoch: 298  Training loss = 4.0359  Validation loss = 2.6120  \n",
      "\n",
      "Fold: 25  Epoch: 299  Training loss = 4.0357  Validation loss = 2.6116  \n",
      "\n",
      "Fold: 25  Epoch: 300  Training loss = 4.0355  Validation loss = 2.6112  \n",
      "\n",
      "Fold: 25  Epoch: 301  Training loss = 4.0353  Validation loss = 2.6109  \n",
      "\n",
      "Fold: 25  Epoch: 302  Training loss = 4.0352  Validation loss = 2.6107  \n",
      "\n",
      "Fold: 25  Epoch: 303  Training loss = 4.0351  Validation loss = 2.6106  \n",
      "\n",
      "Fold: 25  Epoch: 304  Training loss = 4.0350  Validation loss = 2.6105  \n",
      "\n",
      "Fold: 25  Epoch: 305  Training loss = 4.0348  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 25  Epoch: 306  Training loss = 4.0347  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 25  Epoch: 307  Training loss = 4.0346  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 25  Epoch: 308  Training loss = 4.0345  Validation loss = 2.6101  \n",
      "\n",
      "Fold: 25  Epoch: 309  Training loss = 4.0343  Validation loss = 2.6098  \n",
      "\n",
      "Fold: 25  Epoch: 310  Training loss = 4.0342  Validation loss = 2.6096  \n",
      "\n",
      "Fold: 25  Epoch: 311  Training loss = 4.0339  Validation loss = 2.6091  \n",
      "\n",
      "Fold: 25  Epoch: 312  Training loss = 4.0338  Validation loss = 2.6089  \n",
      "\n",
      "Fold: 25  Epoch: 313  Training loss = 4.0336  Validation loss = 2.6087  \n",
      "\n",
      "Fold: 25  Epoch: 314  Training loss = 4.0335  Validation loss = 2.6085  \n",
      "\n",
      "Fold: 25  Epoch: 315  Training loss = 4.0333  Validation loss = 2.6082  \n",
      "\n",
      "Fold: 25  Epoch: 316  Training loss = 4.0332  Validation loss = 2.6081  \n",
      "\n",
      "Fold: 25  Epoch: 317  Training loss = 4.0330  Validation loss = 2.6076  \n",
      "\n",
      "Fold: 25  Epoch: 318  Training loss = 4.0329  Validation loss = 2.6072  \n",
      "\n",
      "Fold: 25  Epoch: 319  Training loss = 4.0327  Validation loss = 2.6068  \n",
      "\n",
      "Fold: 25  Epoch: 320  Training loss = 4.0325  Validation loss = 2.6067  \n",
      "\n",
      "Fold: 25  Epoch: 321  Training loss = 4.0323  Validation loss = 2.6065  \n",
      "\n",
      "Fold: 25  Epoch: 322  Training loss = 4.0322  Validation loss = 2.6063  \n",
      "\n",
      "Fold: 25  Epoch: 323  Training loss = 4.0320  Validation loss = 2.6060  \n",
      "\n",
      "Fold: 25  Epoch: 324  Training loss = 4.0319  Validation loss = 2.6058  \n",
      "\n",
      "Fold: 25  Epoch: 325  Training loss = 4.0318  Validation loss = 2.6057  \n",
      "\n",
      "Fold: 25  Epoch: 326  Training loss = 4.0316  Validation loss = 2.6056  \n",
      "\n",
      "Fold: 25  Epoch: 327  Training loss = 4.0315  Validation loss = 2.6054  \n",
      "\n",
      "Fold: 25  Epoch: 328  Training loss = 4.0314  Validation loss = 2.6053  \n",
      "\n",
      "Fold: 25  Epoch: 329  Training loss = 4.0312  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 25  Epoch: 330  Training loss = 4.0311  Validation loss = 2.6050  \n",
      "\n",
      "Fold: 25  Epoch: 331  Training loss = 4.0309  Validation loss = 2.6048  \n",
      "\n",
      "Fold: 25  Epoch: 332  Training loss = 4.0308  Validation loss = 2.6047  \n",
      "\n",
      "Fold: 25  Epoch: 333  Training loss = 4.0306  Validation loss = 2.6045  \n",
      "\n",
      "Fold: 25  Epoch: 334  Training loss = 4.0305  Validation loss = 2.6042  \n",
      "\n",
      "Fold: 25  Epoch: 335  Training loss = 4.0303  Validation loss = 2.6039  \n",
      "\n",
      "Fold: 25  Epoch: 336  Training loss = 4.0302  Validation loss = 2.6037  \n",
      "\n",
      "Fold: 25  Epoch: 337  Training loss = 4.0300  Validation loss = 2.6035  \n",
      "\n",
      "Fold: 25  Epoch: 338  Training loss = 4.0298  Validation loss = 2.6032  \n",
      "\n",
      "Fold: 25  Epoch: 339  Training loss = 4.0296  Validation loss = 2.6027  \n",
      "\n",
      "Fold: 25  Epoch: 340  Training loss = 4.0295  Validation loss = 2.6028  \n",
      "\n",
      "Fold: 25  Epoch: 341  Training loss = 4.0292  Validation loss = 2.6024  \n",
      "\n",
      "Fold: 25  Epoch: 342  Training loss = 4.0291  Validation loss = 2.6020  \n",
      "\n",
      "Fold: 25  Epoch: 343  Training loss = 4.0290  Validation loss = 2.6018  \n",
      "\n",
      "Fold: 25  Epoch: 344  Training loss = 4.0288  Validation loss = 2.6016  \n",
      "\n",
      "Fold: 25  Epoch: 345  Training loss = 4.0286  Validation loss = 2.6012  \n",
      "\n",
      "Fold: 25  Epoch: 346  Training loss = 4.0284  Validation loss = 2.6011  \n",
      "\n",
      "Fold: 25  Epoch: 347  Training loss = 4.0283  Validation loss = 2.6008  \n",
      "\n",
      "Fold: 25  Epoch: 348  Training loss = 4.0281  Validation loss = 2.6006  \n",
      "\n",
      "Fold: 25  Epoch: 349  Training loss = 4.0279  Validation loss = 2.6005  \n",
      "\n",
      "Fold: 25  Epoch: 350  Training loss = 4.0277  Validation loss = 2.6002  \n",
      "\n",
      "Fold: 25  Epoch: 351  Training loss = 4.0276  Validation loss = 2.6000  \n",
      "\n",
      "Fold: 25  Epoch: 352  Training loss = 4.0274  Validation loss = 2.5996  \n",
      "\n",
      "Fold: 25  Epoch: 353  Training loss = 4.0272  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 25  Epoch: 354  Training loss = 4.0271  Validation loss = 2.5992  \n",
      "\n",
      "Fold: 25  Epoch: 355  Training loss = 4.0270  Validation loss = 2.5992  \n",
      "\n",
      "Fold: 25  Epoch: 356  Training loss = 4.0269  Validation loss = 2.5990  \n",
      "\n",
      "Fold: 25  Epoch: 357  Training loss = 4.0267  Validation loss = 2.5986  \n",
      "\n",
      "Fold: 25  Epoch: 358  Training loss = 4.0266  Validation loss = 2.5985  \n",
      "\n",
      "Fold: 25  Epoch: 359  Training loss = 4.0263  Validation loss = 2.5981  \n",
      "\n",
      "Fold: 25  Epoch: 360  Training loss = 4.0262  Validation loss = 2.5979  \n",
      "\n",
      "Fold: 25  Epoch: 361  Training loss = 4.0260  Validation loss = 2.5976  \n",
      "\n",
      "Fold: 25  Epoch: 362  Training loss = 4.0259  Validation loss = 2.5972  \n",
      "\n",
      "Fold: 25  Epoch: 363  Training loss = 4.0257  Validation loss = 2.5970  \n",
      "\n",
      "Fold: 25  Epoch: 364  Training loss = 4.0256  Validation loss = 2.5968  \n",
      "\n",
      "Fold: 25  Epoch: 365  Training loss = 4.0254  Validation loss = 2.5966  \n",
      "\n",
      "Fold: 25  Epoch: 366  Training loss = 4.0253  Validation loss = 2.5963  \n",
      "\n",
      "Fold: 25  Epoch: 367  Training loss = 4.0251  Validation loss = 2.5961  \n",
      "\n",
      "Fold: 25  Epoch: 368  Training loss = 4.0250  Validation loss = 2.5959  \n",
      "\n",
      "Fold: 25  Epoch: 369  Training loss = 4.0248  Validation loss = 2.5957  \n",
      "\n",
      "Fold: 25  Epoch: 370  Training loss = 4.0247  Validation loss = 2.5954  \n",
      "\n",
      "Fold: 25  Epoch: 371  Training loss = 4.0245  Validation loss = 2.5951  \n",
      "\n",
      "Fold: 25  Epoch: 372  Training loss = 4.0243  Validation loss = 2.5948  \n",
      "\n",
      "Fold: 25  Epoch: 373  Training loss = 4.0242  Validation loss = 2.5946  \n",
      "\n",
      "Fold: 25  Epoch: 374  Training loss = 4.0240  Validation loss = 2.5945  \n",
      "\n",
      "Fold: 25  Epoch: 375  Training loss = 4.0239  Validation loss = 2.5945  \n",
      "\n",
      "Fold: 25  Epoch: 376  Training loss = 4.0238  Validation loss = 2.5944  \n",
      "\n",
      "Fold: 25  Epoch: 377  Training loss = 4.0237  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 25  Epoch: 378  Training loss = 4.0234  Validation loss = 2.5937  \n",
      "\n",
      "Fold: 25  Epoch: 379  Training loss = 4.0232  Validation loss = 2.5934  \n",
      "\n",
      "Fold: 25  Epoch: 380  Training loss = 4.0231  Validation loss = 2.5932  \n",
      "\n",
      "Fold: 25  Epoch: 381  Training loss = 4.0230  Validation loss = 2.5928  \n",
      "\n",
      "Fold: 25  Epoch: 382  Training loss = 4.0228  Validation loss = 2.5926  \n",
      "\n",
      "Fold: 25  Epoch: 383  Training loss = 4.0226  Validation loss = 2.5924  \n",
      "\n",
      "Fold: 25  Epoch: 384  Training loss = 4.0225  Validation loss = 2.5921  \n",
      "\n",
      "Fold: 25  Epoch: 385  Training loss = 4.0223  Validation loss = 2.5918  \n",
      "\n",
      "Fold: 25  Epoch: 386  Training loss = 4.0222  Validation loss = 2.5915  \n",
      "\n",
      "Fold: 25  Epoch: 387  Training loss = 4.0220  Validation loss = 2.5911  \n",
      "\n",
      "Fold: 25  Epoch: 388  Training loss = 4.0218  Validation loss = 2.5909  \n",
      "\n",
      "Fold: 25  Epoch: 389  Training loss = 4.0217  Validation loss = 2.5907  \n",
      "\n",
      "Fold: 25  Epoch: 390  Training loss = 4.0215  Validation loss = 2.5904  \n",
      "\n",
      "Fold: 25  Epoch: 391  Training loss = 4.0214  Validation loss = 2.5902  \n",
      "\n",
      "Fold: 25  Epoch: 392  Training loss = 4.0212  Validation loss = 2.5898  \n",
      "\n",
      "Fold: 25  Epoch: 393  Training loss = 4.0210  Validation loss = 2.5895  \n",
      "\n",
      "Fold: 25  Epoch: 394  Training loss = 4.0208  Validation loss = 2.5893  \n",
      "\n",
      "Fold: 25  Epoch: 395  Training loss = 4.0207  Validation loss = 2.5892  \n",
      "\n",
      "Fold: 25  Epoch: 396  Training loss = 4.0205  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 25  Epoch: 397  Training loss = 4.0203  Validation loss = 2.5885  \n",
      "\n",
      "Fold: 25  Epoch: 398  Training loss = 4.0201  Validation loss = 2.5881  \n",
      "\n",
      "Fold: 25  Epoch: 399  Training loss = 4.0199  Validation loss = 2.5878  \n",
      "\n",
      "Fold: 25  Epoch: 400  Training loss = 4.0197  Validation loss = 2.5875  \n",
      "\n",
      "Fold: 25  Epoch: 401  Training loss = 4.0195  Validation loss = 2.5872  \n",
      "\n",
      "Fold: 25  Epoch: 402  Training loss = 4.0193  Validation loss = 2.5868  \n",
      "\n",
      "Fold: 25  Epoch: 403  Training loss = 4.0192  Validation loss = 2.5867  \n",
      "\n",
      "Fold: 25  Epoch: 404  Training loss = 4.0190  Validation loss = 2.5867  \n",
      "\n",
      "Fold: 25  Epoch: 405  Training loss = 4.0189  Validation loss = 2.5864  \n",
      "\n",
      "Fold: 25  Epoch: 406  Training loss = 4.0187  Validation loss = 2.5862  \n",
      "\n",
      "Fold: 25  Epoch: 407  Training loss = 4.0186  Validation loss = 2.5863  \n",
      "\n",
      "Fold: 25  Epoch: 408  Training loss = 4.0185  Validation loss = 2.5861  \n",
      "\n",
      "Fold: 25  Epoch: 409  Training loss = 4.0183  Validation loss = 2.5860  \n",
      "\n",
      "Fold: 25  Epoch: 410  Training loss = 4.0182  Validation loss = 2.5860  \n",
      "\n",
      "Fold: 25  Epoch: 411  Training loss = 4.0181  Validation loss = 2.5858  \n",
      "\n",
      "Fold: 25  Epoch: 412  Training loss = 4.0179  Validation loss = 2.5856  \n",
      "\n",
      "Fold: 25  Epoch: 413  Training loss = 4.0177  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 25  Epoch: 414  Training loss = 4.0176  Validation loss = 2.5849  \n",
      "\n",
      "Fold: 25  Epoch: 415  Training loss = 4.0174  Validation loss = 2.5847  \n",
      "\n",
      "Fold: 25  Epoch: 416  Training loss = 4.0173  Validation loss = 2.5845  \n",
      "\n",
      "Fold: 25  Epoch: 417  Training loss = 4.0171  Validation loss = 2.5842  \n",
      "\n",
      "Fold: 25  Epoch: 418  Training loss = 4.0169  Validation loss = 2.5837  \n",
      "\n",
      "Fold: 25  Epoch: 419  Training loss = 4.0168  Validation loss = 2.5835  \n",
      "\n",
      "Fold: 25  Epoch: 420  Training loss = 4.0167  Validation loss = 2.5834  \n",
      "\n",
      "Fold: 25  Epoch: 421  Training loss = 4.0165  Validation loss = 2.5833  \n",
      "\n",
      "Fold: 25  Epoch: 422  Training loss = 4.0164  Validation loss = 2.5829  \n",
      "\n",
      "Fold: 25  Epoch: 423  Training loss = 4.0162  Validation loss = 2.5827  \n",
      "\n",
      "Fold: 25  Epoch: 424  Training loss = 4.0161  Validation loss = 2.5826  \n",
      "\n",
      "Fold: 25  Epoch: 425  Training loss = 4.0159  Validation loss = 2.5822  \n",
      "\n",
      "Fold: 25  Epoch: 426  Training loss = 4.0158  Validation loss = 2.5820  \n",
      "\n",
      "Fold: 25  Epoch: 427  Training loss = 4.0156  Validation loss = 2.5819  \n",
      "\n",
      "Fold: 25  Epoch: 428  Training loss = 4.0155  Validation loss = 2.5818  \n",
      "\n",
      "Fold: 25  Epoch: 429  Training loss = 4.0154  Validation loss = 2.5815  \n",
      "\n",
      "Fold: 25  Epoch: 430  Training loss = 4.0153  Validation loss = 2.5812  \n",
      "\n",
      "Fold: 25  Epoch: 431  Training loss = 4.0151  Validation loss = 2.5807  \n",
      "\n",
      "Fold: 25  Epoch: 432  Training loss = 4.0150  Validation loss = 2.5806  \n",
      "\n",
      "Fold: 25  Epoch: 433  Training loss = 4.0148  Validation loss = 2.5805  \n",
      "\n",
      "Fold: 25  Epoch: 434  Training loss = 4.0147  Validation loss = 2.5804  \n",
      "\n",
      "Fold: 25  Epoch: 435  Training loss = 4.0146  Validation loss = 2.5802  \n",
      "\n",
      "Fold: 25  Epoch: 436  Training loss = 4.0145  Validation loss = 2.5800  \n",
      "\n",
      "Fold: 25  Epoch: 437  Training loss = 4.0143  Validation loss = 2.5797  \n",
      "\n",
      "Fold: 25  Epoch: 438  Training loss = 4.0141  Validation loss = 2.5795  \n",
      "\n",
      "Fold: 25  Epoch: 439  Training loss = 4.0139  Validation loss = 2.5793  \n",
      "\n",
      "Fold: 25  Epoch: 440  Training loss = 4.0138  Validation loss = 2.5789  \n",
      "\n",
      "Fold: 25  Epoch: 441  Training loss = 4.0136  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 25  Epoch: 442  Training loss = 4.0134  Validation loss = 2.5785  \n",
      "\n",
      "Fold: 25  Epoch: 443  Training loss = 4.0133  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 25  Epoch: 444  Training loss = 4.0131  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 25  Epoch: 445  Training loss = 4.0129  Validation loss = 2.5777  \n",
      "\n",
      "Fold: 25  Epoch: 446  Training loss = 4.0127  Validation loss = 2.5775  \n",
      "\n",
      "Fold: 25  Epoch: 447  Training loss = 4.0126  Validation loss = 2.5773  \n",
      "\n",
      "Fold: 25  Epoch: 448  Training loss = 4.0124  Validation loss = 2.5771  \n",
      "\n",
      "Fold: 25  Epoch: 449  Training loss = 4.0123  Validation loss = 2.5769  \n",
      "\n",
      "Fold: 25  Epoch: 450  Training loss = 4.0121  Validation loss = 2.5768  \n",
      "\n",
      "Fold: 25  Epoch: 451  Training loss = 4.0120  Validation loss = 2.5765  \n",
      "\n",
      "Fold: 25  Epoch: 452  Training loss = 4.0118  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 25  Epoch: 453  Training loss = 4.0117  Validation loss = 2.5763  \n",
      "\n",
      "Fold: 25  Epoch: 454  Training loss = 4.0116  Validation loss = 2.5763  \n",
      "\n",
      "Fold: 25  Epoch: 455  Training loss = 4.0114  Validation loss = 2.5760  \n",
      "\n",
      "Fold: 25  Epoch: 456  Training loss = 4.0112  Validation loss = 2.5759  \n",
      "\n",
      "Fold: 25  Epoch: 457  Training loss = 4.0111  Validation loss = 2.5756  \n",
      "\n",
      "Fold: 25  Epoch: 458  Training loss = 4.0109  Validation loss = 2.5754  \n",
      "\n",
      "Fold: 25  Epoch: 459  Training loss = 4.0109  Validation loss = 2.5755  \n",
      "\n",
      "Fold: 25  Epoch: 460  Training loss = 4.0107  Validation loss = 2.5752  \n",
      "\n",
      "Fold: 25  Epoch: 461  Training loss = 4.0106  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 25  Epoch: 462  Training loss = 4.0104  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 25  Epoch: 463  Training loss = 4.0103  Validation loss = 2.5749  \n",
      "\n",
      "Fold: 25  Epoch: 464  Training loss = 4.0101  Validation loss = 2.5746  \n",
      "\n",
      "Fold: 25  Epoch: 465  Training loss = 4.0100  Validation loss = 2.5744  \n",
      "\n",
      "Fold: 25  Epoch: 466  Training loss = 4.0098  Validation loss = 2.5742  \n",
      "\n",
      "Fold: 25  Epoch: 467  Training loss = 4.0097  Validation loss = 2.5740  \n",
      "\n",
      "Fold: 25  Epoch: 468  Training loss = 4.0095  Validation loss = 2.5738  \n",
      "\n",
      "Fold: 25  Epoch: 469  Training loss = 4.0094  Validation loss = 2.5736  \n",
      "\n",
      "Fold: 25  Epoch: 470  Training loss = 4.0092  Validation loss = 2.5736  \n",
      "\n",
      "Fold: 25  Epoch: 471  Training loss = 4.0091  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 25  Epoch: 472  Training loss = 4.0089  Validation loss = 2.5730  \n",
      "\n",
      "Fold: 25  Epoch: 473  Training loss = 4.0088  Validation loss = 2.5730  \n",
      "\n",
      "Fold: 25  Epoch: 474  Training loss = 4.0087  Validation loss = 2.5729  \n",
      "\n",
      "Fold: 25  Epoch: 475  Training loss = 4.0086  Validation loss = 2.5726  \n",
      "\n",
      "Fold: 25  Epoch: 476  Training loss = 4.0084  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 25  Epoch: 477  Training loss = 4.0083  Validation loss = 2.5718  \n",
      "\n",
      "Fold: 25  Epoch: 478  Training loss = 4.0081  Validation loss = 2.5717  \n",
      "\n",
      "Fold: 25  Epoch: 479  Training loss = 4.0080  Validation loss = 2.5715  \n",
      "\n",
      "Fold: 25  Epoch: 480  Training loss = 4.0078  Validation loss = 2.5713  \n",
      "\n",
      "Fold: 25  Epoch: 481  Training loss = 4.0077  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 25  Epoch: 482  Training loss = 4.0076  Validation loss = 2.5709  \n",
      "\n",
      "Fold: 25  Epoch: 483  Training loss = 4.0074  Validation loss = 2.5707  \n",
      "\n",
      "Fold: 25  Epoch: 484  Training loss = 4.0072  Validation loss = 2.5705  \n",
      "\n",
      "Fold: 25  Epoch: 485  Training loss = 4.0070  Validation loss = 2.5703  \n",
      "\n",
      "Fold: 25  Epoch: 486  Training loss = 4.0069  Validation loss = 2.5702  \n",
      "\n",
      "Fold: 25  Epoch: 487  Training loss = 4.0068  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 25  Epoch: 488  Training loss = 4.0067  Validation loss = 2.5700  \n",
      "\n",
      "Fold: 25  Epoch: 489  Training loss = 4.0065  Validation loss = 2.5698  \n",
      "\n",
      "Fold: 25  Epoch: 490  Training loss = 4.0064  Validation loss = 2.5696  \n",
      "\n",
      "Fold: 25  Epoch: 491  Training loss = 4.0062  Validation loss = 2.5694  \n",
      "\n",
      "Fold: 25  Epoch: 492  Training loss = 4.0061  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 25  Epoch: 493  Training loss = 4.0059  Validation loss = 2.5690  \n",
      "\n",
      "Fold: 25  Epoch: 494  Training loss = 4.0058  Validation loss = 2.5688  \n",
      "\n",
      "Fold: 25  Epoch: 495  Training loss = 4.0057  Validation loss = 2.5688  \n",
      "\n",
      "Fold: 25  Epoch: 496  Training loss = 4.0055  Validation loss = 2.5686  \n",
      "\n",
      "Fold: 25  Epoch: 497  Training loss = 4.0054  Validation loss = 2.5685  \n",
      "\n",
      "Fold: 25  Epoch: 498  Training loss = 4.0052  Validation loss = 2.5682  \n",
      "\n",
      "Fold: 25  Epoch: 499  Training loss = 4.0051  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 25  Epoch: 500  Training loss = 4.0050  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 25  Epoch: 501  Training loss = 4.0048  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 25  Epoch: 502  Training loss = 4.0047  Validation loss = 2.5676  \n",
      "\n",
      "Fold: 25  Epoch: 503  Training loss = 4.0045  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 25  Epoch: 504  Training loss = 4.0043  Validation loss = 2.5672  \n",
      "\n",
      "Fold: 25  Epoch: 505  Training loss = 4.0041  Validation loss = 2.5670  \n",
      "\n",
      "Fold: 25  Epoch: 506  Training loss = 4.0040  Validation loss = 2.5670  \n",
      "\n",
      "Fold: 25  Epoch: 507  Training loss = 4.0039  Validation loss = 2.5669  \n",
      "\n",
      "Fold: 25  Epoch: 508  Training loss = 4.0037  Validation loss = 2.5666  \n",
      "\n",
      "Fold: 25  Epoch: 509  Training loss = 4.0036  Validation loss = 2.5665  \n",
      "\n",
      "Fold: 25  Epoch: 510  Training loss = 4.0035  Validation loss = 2.5665  \n",
      "\n",
      "Fold: 25  Epoch: 511  Training loss = 4.0033  Validation loss = 2.5662  \n",
      "\n",
      "Fold: 25  Epoch: 512  Training loss = 4.0031  Validation loss = 2.5660  \n",
      "\n",
      "Fold: 25  Epoch: 513  Training loss = 4.0030  Validation loss = 2.5659  \n",
      "\n",
      "Fold: 25  Epoch: 514  Training loss = 4.0028  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 25  Epoch: 515  Training loss = 4.0027  Validation loss = 2.5652  \n",
      "\n",
      "Fold: 25  Epoch: 516  Training loss = 4.0026  Validation loss = 2.5653  \n",
      "\n",
      "Fold: 25  Epoch: 517  Training loss = 4.0024  Validation loss = 2.5651  \n",
      "\n",
      "Fold: 25  Epoch: 518  Training loss = 4.0023  Validation loss = 2.5650  \n",
      "\n",
      "Fold: 25  Epoch: 519  Training loss = 4.0021  Validation loss = 2.5646  \n",
      "\n",
      "Fold: 25  Epoch: 520  Training loss = 4.0020  Validation loss = 2.5646  \n",
      "\n",
      "Fold: 25  Epoch: 521  Training loss = 4.0019  Validation loss = 2.5645  \n",
      "\n",
      "Fold: 25  Epoch: 522  Training loss = 4.0018  Validation loss = 2.5642  \n",
      "\n",
      "Fold: 25  Epoch: 523  Training loss = 4.0016  Validation loss = 2.5641  \n",
      "\n",
      "Fold: 25  Epoch: 524  Training loss = 4.0015  Validation loss = 2.5640  \n",
      "\n",
      "Fold: 25  Epoch: 525  Training loss = 4.0014  Validation loss = 2.5638  \n",
      "\n",
      "Fold: 25  Epoch: 526  Training loss = 4.0012  Validation loss = 2.5635  \n",
      "\n",
      "Fold: 25  Epoch: 527  Training loss = 4.0011  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 25  Epoch: 528  Training loss = 4.0009  Validation loss = 2.5630  \n",
      "\n",
      "Fold: 25  Epoch: 529  Training loss = 4.0008  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 25  Epoch: 530  Training loss = 4.0006  Validation loss = 2.5626  \n",
      "\n",
      "Fold: 25  Epoch: 531  Training loss = 4.0005  Validation loss = 2.5622  \n",
      "\n",
      "Fold: 25  Epoch: 532  Training loss = 4.0003  Validation loss = 2.5619  \n",
      "\n",
      "Fold: 25  Epoch: 533  Training loss = 4.0001  Validation loss = 2.5617  \n",
      "\n",
      "Fold: 25  Epoch: 534  Training loss = 4.0000  Validation loss = 2.5616  \n",
      "\n",
      "Fold: 25  Epoch: 535  Training loss = 3.9999  Validation loss = 2.5616  \n",
      "\n",
      "Fold: 25  Epoch: 536  Training loss = 3.9998  Validation loss = 2.5615  \n",
      "\n",
      "Fold: 25  Epoch: 537  Training loss = 3.9996  Validation loss = 2.5612  \n",
      "\n",
      "Fold: 25  Epoch: 538  Training loss = 3.9995  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 25  Epoch: 539  Training loss = 3.9993  Validation loss = 2.5608  \n",
      "\n",
      "Fold: 25  Epoch: 540  Training loss = 3.9991  Validation loss = 2.5605  \n",
      "\n",
      "Fold: 25  Epoch: 541  Training loss = 3.9989  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 25  Epoch: 542  Training loss = 3.9987  Validation loss = 2.5600  \n",
      "\n",
      "Fold: 25  Epoch: 543  Training loss = 3.9985  Validation loss = 2.5598  \n",
      "\n",
      "Fold: 25  Epoch: 544  Training loss = 3.9984  Validation loss = 2.5597  \n",
      "\n",
      "Fold: 25  Epoch: 545  Training loss = 3.9983  Validation loss = 2.5595  \n",
      "\n",
      "Fold: 25  Epoch: 546  Training loss = 3.9981  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 25  Epoch: 547  Training loss = 3.9979  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 25  Epoch: 548  Training loss = 3.9977  Validation loss = 2.5587  \n",
      "\n",
      "Fold: 25  Epoch: 549  Training loss = 3.9976  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 25  Epoch: 550  Training loss = 3.9974  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 25  Epoch: 551  Training loss = 3.9973  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 25  Epoch: 552  Training loss = 3.9971  Validation loss = 2.5581  \n",
      "\n",
      "Fold: 25  Epoch: 553  Training loss = 3.9970  Validation loss = 2.5579  \n",
      "\n",
      "Fold: 25  Epoch: 554  Training loss = 3.9969  Validation loss = 2.5578  \n",
      "\n",
      "Fold: 25  Epoch: 555  Training loss = 3.9967  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 25  Epoch: 556  Training loss = 3.9966  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 25  Epoch: 557  Training loss = 3.9964  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 25  Epoch: 558  Training loss = 3.9963  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 25  Epoch: 559  Training loss = 3.9962  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 25  Epoch: 560  Training loss = 3.9961  Validation loss = 2.5569  \n",
      "\n",
      "Fold: 25  Epoch: 561  Training loss = 3.9959  Validation loss = 2.5566  \n",
      "\n",
      "Fold: 25  Epoch: 562  Training loss = 3.9957  Validation loss = 2.5565  \n",
      "\n",
      "Fold: 25  Epoch: 563  Training loss = 3.9956  Validation loss = 2.5562  \n",
      "\n",
      "Fold: 25  Epoch: 564  Training loss = 3.9954  Validation loss = 2.5561  \n",
      "\n",
      "Fold: 25  Epoch: 565  Training loss = 3.9952  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 25  Epoch: 566  Training loss = 3.9951  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 25  Epoch: 567  Training loss = 3.9950  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 25  Epoch: 568  Training loss = 3.9948  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 25  Epoch: 569  Training loss = 3.9947  Validation loss = 2.5551  \n",
      "\n",
      "Fold: 25  Epoch: 570  Training loss = 3.9946  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 25  Epoch: 571  Training loss = 3.9945  Validation loss = 2.5547  \n",
      "\n",
      "Fold: 25  Epoch: 572  Training loss = 3.9943  Validation loss = 2.5545  \n",
      "\n",
      "Fold: 25  Epoch: 573  Training loss = 3.9942  Validation loss = 2.5543  \n",
      "\n",
      "Fold: 25  Epoch: 574  Training loss = 3.9940  Validation loss = 2.5543  \n",
      "\n",
      "Fold: 25  Epoch: 575  Training loss = 3.9939  Validation loss = 2.5541  \n",
      "\n",
      "Fold: 25  Epoch: 576  Training loss = 3.9937  Validation loss = 2.5539  \n",
      "\n",
      "Fold: 25  Epoch: 577  Training loss = 3.9936  Validation loss = 2.5537  \n",
      "\n",
      "Fold: 25  Epoch: 578  Training loss = 3.9935  Validation loss = 2.5536  \n",
      "\n",
      "Fold: 25  Epoch: 579  Training loss = 3.9933  Validation loss = 2.5535  \n",
      "\n",
      "Fold: 25  Epoch: 580  Training loss = 3.9932  Validation loss = 2.5534  \n",
      "\n",
      "Fold: 25  Epoch: 581  Training loss = 3.9930  Validation loss = 2.5532  \n",
      "\n",
      "Fold: 25  Epoch: 582  Training loss = 3.9929  Validation loss = 2.5529  \n",
      "\n",
      "Fold: 25  Epoch: 583  Training loss = 3.9927  Validation loss = 2.5528  \n",
      "\n",
      "Fold: 25  Epoch: 584  Training loss = 3.9926  Validation loss = 2.5529  \n",
      "\n",
      "Fold: 25  Epoch: 585  Training loss = 3.9925  Validation loss = 2.5528  \n",
      "\n",
      "Fold: 25  Epoch: 586  Training loss = 3.9924  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 25  Epoch: 587  Training loss = 3.9921  Validation loss = 2.5524  \n",
      "\n",
      "Fold: 25  Epoch: 588  Training loss = 3.9920  Validation loss = 2.5520  \n",
      "\n",
      "Fold: 25  Epoch: 589  Training loss = 3.9919  Validation loss = 2.5518  \n",
      "\n",
      "Fold: 25  Epoch: 590  Training loss = 3.9917  Validation loss = 2.5516  \n",
      "\n",
      "Fold: 25  Epoch: 591  Training loss = 3.9916  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 25  Epoch: 592  Training loss = 3.9914  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 25  Epoch: 593  Training loss = 3.9912  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 25  Epoch: 594  Training loss = 3.9910  Validation loss = 2.5511  \n",
      "\n",
      "Fold: 25  Epoch: 595  Training loss = 3.9909  Validation loss = 2.5507  \n",
      "\n",
      "Fold: 25  Epoch: 596  Training loss = 3.9908  Validation loss = 2.5508  \n",
      "\n",
      "Fold: 25  Epoch: 597  Training loss = 3.9907  Validation loss = 2.5507  \n",
      "\n",
      "Fold: 25  Epoch: 598  Training loss = 3.9905  Validation loss = 2.5506  \n",
      "\n",
      "Fold: 25  Epoch: 599  Training loss = 3.9904  Validation loss = 2.5504  \n",
      "\n",
      "Fold: 25  Epoch: 600  Training loss = 3.9902  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 25  Epoch: 601  Training loss = 3.9900  Validation loss = 2.5498  \n",
      "\n",
      "Fold: 25  Epoch: 602  Training loss = 3.9898  Validation loss = 2.5496  \n",
      "\n",
      "Fold: 25  Epoch: 603  Training loss = 3.9896  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 25  Epoch: 604  Training loss = 3.9894  Validation loss = 2.5491  \n",
      "\n",
      "Fold: 25  Epoch: 605  Training loss = 3.9893  Validation loss = 2.5490  \n",
      "\n",
      "Fold: 25  Epoch: 606  Training loss = 3.9891  Validation loss = 2.5488  \n",
      "\n",
      "Fold: 25  Epoch: 607  Training loss = 3.9890  Validation loss = 2.5487  \n",
      "\n",
      "Fold: 25  Epoch: 608  Training loss = 3.9888  Validation loss = 2.5485  \n",
      "\n",
      "Fold: 25  Epoch: 609  Training loss = 3.9887  Validation loss = 2.5483  \n",
      "\n",
      "Fold: 25  Epoch: 610  Training loss = 3.9885  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 25  Epoch: 611  Training loss = 3.9884  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 25  Epoch: 612  Training loss = 3.9883  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 25  Epoch: 613  Training loss = 3.9881  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 25  Epoch: 614  Training loss = 3.9880  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 25  Epoch: 615  Training loss = 3.9878  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 25  Epoch: 616  Training loss = 3.9877  Validation loss = 2.5474  \n",
      "\n",
      "Fold: 25  Epoch: 617  Training loss = 3.9875  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 25  Epoch: 618  Training loss = 3.9874  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 25  Epoch: 619  Training loss = 3.9872  Validation loss = 2.5468  \n",
      "\n",
      "Fold: 25  Epoch: 620  Training loss = 3.9871  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 25  Epoch: 621  Training loss = 3.9870  Validation loss = 2.5466  \n",
      "\n",
      "Fold: 25  Epoch: 622  Training loss = 3.9868  Validation loss = 2.5464  \n",
      "\n",
      "Fold: 25  Epoch: 623  Training loss = 3.9866  Validation loss = 2.5463  \n",
      "\n",
      "Fold: 25  Epoch: 624  Training loss = 3.9865  Validation loss = 2.5461  \n",
      "\n",
      "Fold: 25  Epoch: 625  Training loss = 3.9864  Validation loss = 2.5460  \n",
      "\n",
      "Fold: 25  Epoch: 626  Training loss = 3.9862  Validation loss = 2.5461  \n",
      "\n",
      "Fold: 25  Epoch: 627  Training loss = 3.9861  Validation loss = 2.5458  \n",
      "\n",
      "Fold: 25  Epoch: 628  Training loss = 3.9859  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 25  Epoch: 629  Training loss = 3.9857  Validation loss = 2.5452  \n",
      "\n",
      "Fold: 25  Epoch: 630  Training loss = 3.9856  Validation loss = 2.5450  \n",
      "\n",
      "Fold: 25  Epoch: 631  Training loss = 3.9854  Validation loss = 2.5448  \n",
      "\n",
      "Fold: 25  Epoch: 632  Training loss = 3.9853  Validation loss = 2.5446  \n",
      "\n",
      "Fold: 25  Epoch: 633  Training loss = 3.9852  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 25  Epoch: 634  Training loss = 3.9850  Validation loss = 2.5446  \n",
      "\n",
      "Fold: 25  Epoch: 635  Training loss = 3.9848  Validation loss = 2.5443  \n",
      "\n",
      "Fold: 25  Epoch: 636  Training loss = 3.9847  Validation loss = 2.5443  \n",
      "\n",
      "Fold: 25  Epoch: 637  Training loss = 3.9845  Validation loss = 2.5441  \n",
      "\n",
      "Fold: 25  Epoch: 638  Training loss = 3.9844  Validation loss = 2.5440  \n",
      "\n",
      "Fold: 25  Epoch: 639  Training loss = 3.9842  Validation loss = 2.5436  \n",
      "\n",
      "Fold: 25  Epoch: 640  Training loss = 3.9841  Validation loss = 2.5435  \n",
      "\n",
      "Fold: 25  Epoch: 641  Training loss = 3.9839  Validation loss = 2.5431  \n",
      "\n",
      "Fold: 25  Epoch: 642  Training loss = 3.9838  Validation loss = 2.5429  \n",
      "\n",
      "Fold: 25  Epoch: 643  Training loss = 3.9836  Validation loss = 2.5427  \n",
      "\n",
      "Fold: 25  Epoch: 644  Training loss = 3.9835  Validation loss = 2.5427  \n",
      "\n",
      "Fold: 25  Epoch: 645  Training loss = 3.9834  Validation loss = 2.5427  \n",
      "\n",
      "Fold: 25  Epoch: 646  Training loss = 3.9832  Validation loss = 2.5426  \n",
      "\n",
      "Fold: 25  Epoch: 647  Training loss = 3.9831  Validation loss = 2.5425  \n",
      "\n",
      "Fold: 25  Epoch: 648  Training loss = 3.9829  Validation loss = 2.5422  \n",
      "\n",
      "Fold: 25  Epoch: 649  Training loss = 3.9828  Validation loss = 2.5420  \n",
      "\n",
      "Fold: 25  Epoch: 650  Training loss = 3.9826  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 25  Epoch: 651  Training loss = 3.9825  Validation loss = 2.5415  \n",
      "\n",
      "Fold: 25  Epoch: 652  Training loss = 3.9824  Validation loss = 2.5414  \n",
      "\n",
      "Fold: 25  Epoch: 653  Training loss = 3.9822  Validation loss = 2.5412  \n",
      "\n",
      "Fold: 25  Epoch: 654  Training loss = 3.9821  Validation loss = 2.5411  \n",
      "\n",
      "Fold: 25  Epoch: 655  Training loss = 3.9819  Validation loss = 2.5409  \n",
      "\n",
      "Fold: 25  Epoch: 656  Training loss = 3.9818  Validation loss = 2.5407  \n",
      "\n",
      "Fold: 25  Epoch: 657  Training loss = 3.9817  Validation loss = 2.5406  \n",
      "\n",
      "Fold: 25  Epoch: 658  Training loss = 3.9816  Validation loss = 2.5405  \n",
      "\n",
      "Fold: 25  Epoch: 659  Training loss = 3.9815  Validation loss = 2.5405  \n",
      "\n",
      "Fold: 25  Epoch: 660  Training loss = 3.9813  Validation loss = 2.5403  \n",
      "\n",
      "Fold: 25  Epoch: 661  Training loss = 3.9812  Validation loss = 2.5400  \n",
      "\n",
      "Fold: 25  Epoch: 662  Training loss = 3.9810  Validation loss = 2.5397  \n",
      "\n",
      "Fold: 25  Epoch: 663  Training loss = 3.9809  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 25  Epoch: 664  Training loss = 3.9807  Validation loss = 2.5393  \n",
      "\n",
      "Fold: 25  Epoch: 665  Training loss = 3.9806  Validation loss = 2.5390  \n",
      "\n",
      "Fold: 25  Epoch: 666  Training loss = 3.9805  Validation loss = 2.5389  \n",
      "\n",
      "Fold: 25  Epoch: 667  Training loss = 3.9803  Validation loss = 2.5386  \n",
      "\n",
      "Fold: 25  Epoch: 668  Training loss = 3.9802  Validation loss = 2.5383  \n",
      "\n",
      "Fold: 25  Epoch: 669  Training loss = 3.9801  Validation loss = 2.5382  \n",
      "\n",
      "Fold: 25  Epoch: 670  Training loss = 3.9799  Validation loss = 2.5380  \n",
      "\n",
      "Fold: 25  Epoch: 671  Training loss = 3.9797  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 25  Epoch: 672  Training loss = 3.9796  Validation loss = 2.5377  \n",
      "\n",
      "Fold: 25  Epoch: 673  Training loss = 3.9795  Validation loss = 2.5376  \n",
      "\n",
      "Fold: 25  Epoch: 674  Training loss = 3.9793  Validation loss = 2.5375  \n",
      "\n",
      "Fold: 25  Epoch: 675  Training loss = 3.9792  Validation loss = 2.5374  \n",
      "\n",
      "Fold: 25  Epoch: 676  Training loss = 3.9791  Validation loss = 2.5374  \n",
      "\n",
      "Fold: 25  Epoch: 677  Training loss = 3.9789  Validation loss = 2.5372  \n",
      "\n",
      "Fold: 25  Epoch: 678  Training loss = 3.9788  Validation loss = 2.5369  \n",
      "\n",
      "Fold: 25  Epoch: 679  Training loss = 3.9787  Validation loss = 2.5369  \n",
      "\n",
      "Fold: 25  Epoch: 680  Training loss = 3.9785  Validation loss = 2.5367  \n",
      "\n",
      "Fold: 25  Epoch: 681  Training loss = 3.9784  Validation loss = 2.5366  \n",
      "\n",
      "Fold: 25  Epoch: 682  Training loss = 3.9782  Validation loss = 2.5364  \n",
      "\n",
      "Fold: 25  Epoch: 683  Training loss = 3.9781  Validation loss = 2.5361  \n",
      "\n",
      "Fold: 25  Epoch: 684  Training loss = 3.9779  Validation loss = 2.5359  \n",
      "\n",
      "Fold: 25  Epoch: 685  Training loss = 3.9778  Validation loss = 2.5355  \n",
      "\n",
      "Fold: 25  Epoch: 686  Training loss = 3.9776  Validation loss = 2.5352  \n",
      "\n",
      "Fold: 25  Epoch: 687  Training loss = 3.9775  Validation loss = 2.5351  \n",
      "\n",
      "Fold: 25  Epoch: 688  Training loss = 3.9774  Validation loss = 2.5348  \n",
      "\n",
      "Fold: 25  Epoch: 689  Training loss = 3.9772  Validation loss = 2.5347  \n",
      "\n",
      "Fold: 25  Epoch: 690  Training loss = 3.9771  Validation loss = 2.5345  \n",
      "\n",
      "Fold: 25  Epoch: 691  Training loss = 3.9769  Validation loss = 2.5343  \n",
      "\n",
      "Fold: 25  Epoch: 692  Training loss = 3.9768  Validation loss = 2.5342  \n",
      "\n",
      "Fold: 25  Epoch: 693  Training loss = 3.9767  Validation loss = 2.5341  \n",
      "\n",
      "Fold: 25  Epoch: 694  Training loss = 3.9766  Validation loss = 2.5340  \n",
      "\n",
      "Fold: 25  Epoch: 695  Training loss = 3.9764  Validation loss = 2.5338  \n",
      "\n",
      "Fold: 25  Epoch: 696  Training loss = 3.9763  Validation loss = 2.5337  \n",
      "\n",
      "Fold: 25  Epoch: 697  Training loss = 3.9762  Validation loss = 2.5336  \n",
      "\n",
      "Fold: 25  Epoch: 698  Training loss = 3.9760  Validation loss = 2.5334  \n",
      "\n",
      "Fold: 25  Epoch: 699  Training loss = 3.9759  Validation loss = 2.5330  \n",
      "\n",
      "Fold: 25  Epoch: 700  Training loss = 3.9758  Validation loss = 2.5329  \n",
      "\n",
      "Fold: 25  Epoch: 701  Training loss = 3.9756  Validation loss = 2.5326  \n",
      "\n",
      "Fold: 25  Epoch: 702  Training loss = 3.9754  Validation loss = 2.5325  \n",
      "\n",
      "Fold: 25  Epoch: 703  Training loss = 3.9752  Validation loss = 2.5323  \n",
      "\n",
      "Fold: 25  Epoch: 704  Training loss = 3.9750  Validation loss = 2.5321  \n",
      "\n",
      "Fold: 25  Epoch: 705  Training loss = 3.9749  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 25  Epoch: 706  Training loss = 3.9747  Validation loss = 2.5318  \n",
      "\n",
      "Fold: 25  Epoch: 707  Training loss = 3.9746  Validation loss = 2.5316  \n",
      "\n",
      "Fold: 25  Epoch: 708  Training loss = 3.9744  Validation loss = 2.5313  \n",
      "\n",
      "Fold: 25  Epoch: 709  Training loss = 3.9743  Validation loss = 2.5311  \n",
      "\n",
      "Fold: 25  Epoch: 710  Training loss = 3.9741  Validation loss = 2.5308  \n",
      "\n",
      "Fold: 25  Epoch: 711  Training loss = 3.9739  Validation loss = 2.5305  \n",
      "\n",
      "Fold: 25  Epoch: 712  Training loss = 3.9737  Validation loss = 2.5302  \n",
      "\n",
      "Fold: 25  Epoch: 713  Training loss = 3.9736  Validation loss = 2.5300  \n",
      "\n",
      "Fold: 25  Epoch: 714  Training loss = 3.9734  Validation loss = 2.5297  \n",
      "\n",
      "Fold: 25  Epoch: 715  Training loss = 3.9732  Validation loss = 2.5295  \n",
      "\n",
      "Fold: 25  Epoch: 716  Training loss = 3.9731  Validation loss = 2.5293  \n",
      "\n",
      "Fold: 25  Epoch: 717  Training loss = 3.9730  Validation loss = 2.5292  \n",
      "\n",
      "Fold: 25  Epoch: 718  Training loss = 3.9728  Validation loss = 2.5290  \n",
      "\n",
      "Fold: 25  Epoch: 719  Training loss = 3.9727  Validation loss = 2.5288  \n",
      "\n",
      "Fold: 25  Epoch: 720  Training loss = 3.9725  Validation loss = 2.5288  \n",
      "\n",
      "Fold: 25  Epoch: 721  Training loss = 3.9724  Validation loss = 2.5288  \n",
      "\n",
      "Fold: 25  Epoch: 722  Training loss = 3.9723  Validation loss = 2.5286  \n",
      "\n",
      "Fold: 25  Epoch: 723  Training loss = 3.9722  Validation loss = 2.5284  \n",
      "\n",
      "Fold: 25  Epoch: 724  Training loss = 3.9720  Validation loss = 2.5283  \n",
      "\n",
      "Fold: 25  Epoch: 725  Training loss = 3.9719  Validation loss = 2.5281  \n",
      "\n",
      "Fold: 25  Epoch: 726  Training loss = 3.9717  Validation loss = 2.5280  \n",
      "\n",
      "Fold: 25  Epoch: 727  Training loss = 3.9715  Validation loss = 2.5279  \n",
      "\n",
      "Fold: 25  Epoch: 728  Training loss = 3.9714  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 25  Epoch: 729  Training loss = 3.9712  Validation loss = 2.5274  \n",
      "\n",
      "Fold: 25  Epoch: 730  Training loss = 3.9710  Validation loss = 2.5273  \n",
      "\n",
      "Fold: 25  Epoch: 731  Training loss = 3.9709  Validation loss = 2.5270  \n",
      "\n",
      "Fold: 25  Epoch: 732  Training loss = 3.9708  Validation loss = 2.5269  \n",
      "\n",
      "Fold: 25  Epoch: 733  Training loss = 3.9706  Validation loss = 2.5267  \n",
      "\n",
      "Fold: 25  Epoch: 734  Training loss = 3.9705  Validation loss = 2.5266  \n",
      "\n",
      "Fold: 25  Epoch: 735  Training loss = 3.9703  Validation loss = 2.5263  \n",
      "\n",
      "Fold: 25  Epoch: 736  Training loss = 3.9702  Validation loss = 2.5262  \n",
      "\n",
      "Fold: 25  Epoch: 737  Training loss = 3.9700  Validation loss = 2.5260  \n",
      "\n",
      "Fold: 25  Epoch: 738  Training loss = 3.9699  Validation loss = 2.5259  \n",
      "\n",
      "Fold: 25  Epoch: 739  Training loss = 3.9698  Validation loss = 2.5258  \n",
      "\n",
      "Fold: 25  Epoch: 740  Training loss = 3.9696  Validation loss = 2.5257  \n",
      "\n",
      "Fold: 25  Epoch: 741  Training loss = 3.9695  Validation loss = 2.5256  \n",
      "\n",
      "Fold: 25  Epoch: 742  Training loss = 3.9694  Validation loss = 2.5254  \n",
      "\n",
      "Fold: 25  Epoch: 743  Training loss = 3.9692  Validation loss = 2.5253  \n",
      "\n",
      "Fold: 25  Epoch: 744  Training loss = 3.9691  Validation loss = 2.5249  \n",
      "\n",
      "Fold: 25  Epoch: 745  Training loss = 3.9690  Validation loss = 2.5246  \n",
      "\n",
      "Fold: 25  Epoch: 746  Training loss = 3.9688  Validation loss = 2.5242  \n",
      "\n",
      "Fold: 25  Epoch: 747  Training loss = 3.9687  Validation loss = 2.5239  \n",
      "\n",
      "Fold: 25  Epoch: 748  Training loss = 3.9685  Validation loss = 2.5238  \n",
      "\n",
      "Fold: 25  Epoch: 749  Training loss = 3.9684  Validation loss = 2.5238  \n",
      "\n",
      "Fold: 25  Epoch: 750  Training loss = 3.9683  Validation loss = 2.5237  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 750  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.7085  Validation loss = 1.6316  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.7084  Validation loss = 1.6316  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.7083  Validation loss = 1.6312  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.7081  Validation loss = 1.6313  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.7081  Validation loss = 1.6318  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.7079  Validation loss = 1.6322  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.7078  Validation loss = 1.6329  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.7077  Validation loss = 1.6329  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.7075  Validation loss = 1.6333  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.7074  Validation loss = 1.6341  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.7073  Validation loss = 1.6346  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 3.7073  Validation loss = 1.6337  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 3.7072  Validation loss = 1.6347  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 3.7071  Validation loss = 1.6354  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 3.7070  Validation loss = 1.6356  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 3.7069  Validation loss = 1.6354  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 3.7068  Validation loss = 1.6355  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 3.7067  Validation loss = 1.6358  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 3  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.5869  Validation loss = 1.2932  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.5867  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.5866  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.5865  Validation loss = 1.2929  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.5863  Validation loss = 1.2929  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.5862  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.5861  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.5859  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.5858  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.5857  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.5856  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 3.5855  Validation loss = 1.2930  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 3.5853  Validation loss = 1.2929  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 3.5852  Validation loss = 1.2930  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 3.5851  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 3.5850  Validation loss = 1.2930  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 3.5849  Validation loss = 1.2929  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 3.5847  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 3.5846  Validation loss = 1.2927  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 3.5845  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 3.5843  Validation loss = 1.2927  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 3.5842  Validation loss = 1.2926  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 3.5841  Validation loss = 1.2927  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 3.5839  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 3.5838  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 3.5837  Validation loss = 1.2926  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 3.5836  Validation loss = 1.2925  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 3.5834  Validation loss = 1.2925  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 3.5833  Validation loss = 1.2925  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 3.5832  Validation loss = 1.2924  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 3.5831  Validation loss = 1.2925  \n",
      "\n",
      "Fold: 27  Epoch: 32  Training loss = 3.5831  Validation loss = 1.2925  \n",
      "\n",
      "Fold: 27  Epoch: 33  Training loss = 3.5829  Validation loss = 1.2923  \n",
      "\n",
      "Fold: 27  Epoch: 34  Training loss = 3.5828  Validation loss = 1.2923  \n",
      "\n",
      "Fold: 27  Epoch: 35  Training loss = 3.5826  Validation loss = 1.2921  \n",
      "\n",
      "Fold: 27  Epoch: 36  Training loss = 3.5825  Validation loss = 1.2921  \n",
      "\n",
      "Fold: 27  Epoch: 37  Training loss = 3.5824  Validation loss = 1.2920  \n",
      "\n",
      "Fold: 27  Epoch: 38  Training loss = 3.5823  Validation loss = 1.2921  \n",
      "\n",
      "Fold: 27  Epoch: 39  Training loss = 3.5822  Validation loss = 1.2922  \n",
      "\n",
      "Fold: 27  Epoch: 40  Training loss = 3.5820  Validation loss = 1.2921  \n",
      "\n",
      "Fold: 27  Epoch: 41  Training loss = 3.5819  Validation loss = 1.2921  \n",
      "\n",
      "Fold: 27  Epoch: 42  Training loss = 3.5818  Validation loss = 1.2920  \n",
      "\n",
      "Fold: 27  Epoch: 43  Training loss = 3.5817  Validation loss = 1.2919  \n",
      "\n",
      "Fold: 27  Epoch: 44  Training loss = 3.5816  Validation loss = 1.2919  \n",
      "\n",
      "Fold: 27  Epoch: 45  Training loss = 3.5814  Validation loss = 1.2918  \n",
      "\n",
      "Fold: 27  Epoch: 46  Training loss = 3.5813  Validation loss = 1.2917  \n",
      "\n",
      "Fold: 27  Epoch: 47  Training loss = 3.5812  Validation loss = 1.2916  \n",
      "\n",
      "Fold: 27  Epoch: 48  Training loss = 3.5811  Validation loss = 1.2915  \n",
      "\n",
      "Fold: 27  Epoch: 49  Training loss = 3.5810  Validation loss = 1.2915  \n",
      "\n",
      "Fold: 27  Epoch: 50  Training loss = 3.5809  Validation loss = 1.2913  \n",
      "\n",
      "Fold: 27  Epoch: 51  Training loss = 3.5807  Validation loss = 1.2913  \n",
      "\n",
      "Fold: 27  Epoch: 52  Training loss = 3.5806  Validation loss = 1.2913  \n",
      "\n",
      "Fold: 27  Epoch: 53  Training loss = 3.5806  Validation loss = 1.2913  \n",
      "\n",
      "Fold: 27  Epoch: 54  Training loss = 3.5804  Validation loss = 1.2914  \n",
      "\n",
      "Fold: 27  Epoch: 55  Training loss = 3.5803  Validation loss = 1.2913  \n",
      "\n",
      "Fold: 27  Epoch: 56  Training loss = 3.5802  Validation loss = 1.2912  \n",
      "\n",
      "Fold: 27  Epoch: 57  Training loss = 3.5800  Validation loss = 1.2909  \n",
      "\n",
      "Fold: 27  Epoch: 58  Training loss = 3.5799  Validation loss = 1.2908  \n",
      "\n",
      "Fold: 27  Epoch: 59  Training loss = 3.5797  Validation loss = 1.2909  \n",
      "\n",
      "Fold: 27  Epoch: 60  Training loss = 3.5797  Validation loss = 1.2911  \n",
      "\n",
      "Fold: 27  Epoch: 61  Training loss = 3.5796  Validation loss = 1.2911  \n",
      "\n",
      "Fold: 27  Epoch: 62  Training loss = 3.5794  Validation loss = 1.2913  \n",
      "\n",
      "Fold: 27  Epoch: 63  Training loss = 3.5793  Validation loss = 1.2915  \n",
      "\n",
      "Fold: 27  Epoch: 64  Training loss = 3.5792  Validation loss = 1.2914  \n",
      "\n",
      "Fold: 27  Epoch: 65  Training loss = 3.5791  Validation loss = 1.2915  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 58  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.5779  Validation loss = 1.9081  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.5778  Validation loss = 1.9080  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.5776  Validation loss = 1.9081  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.5775  Validation loss = 1.9080  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.5774  Validation loss = 1.9082  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.5773  Validation loss = 1.9083  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.5771  Validation loss = 1.9080  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.5771  Validation loss = 1.9082  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.5770  Validation loss = 1.9078  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.5768  Validation loss = 1.9076  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.5768  Validation loss = 1.9079  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.5766  Validation loss = 1.9081  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 3.5765  Validation loss = 1.9078  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 3.5764  Validation loss = 1.9074  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 3.5763  Validation loss = 1.9070  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 3.5762  Validation loss = 1.9067  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 3.5761  Validation loss = 1.9064  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 3.5759  Validation loss = 1.9062  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 3.5758  Validation loss = 1.9062  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 3.5758  Validation loss = 1.9060  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 3.5756  Validation loss = 1.9058  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 3.5756  Validation loss = 1.9059  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 3.5755  Validation loss = 1.9059  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 3.5754  Validation loss = 1.9056  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 3.5752  Validation loss = 1.9051  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 3.5751  Validation loss = 1.9053  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 3.5751  Validation loss = 1.9053  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 3.5749  Validation loss = 1.9050  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 3.5749  Validation loss = 1.9049  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 3.5748  Validation loss = 1.9048  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 3.5746  Validation loss = 1.9044  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 3.5744  Validation loss = 1.9044  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 3.5743  Validation loss = 1.9045  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 3.5742  Validation loss = 1.9041  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 3.5740  Validation loss = 1.9039  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 3.5739  Validation loss = 1.9038  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 3.5738  Validation loss = 1.9032  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 3.5736  Validation loss = 1.9032  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 3.5735  Validation loss = 1.9030  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 3.5735  Validation loss = 1.9031  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 3.5734  Validation loss = 1.9033  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 3.5733  Validation loss = 1.9031  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 3.5732  Validation loss = 1.9031  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 3.5731  Validation loss = 1.9029  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 3.5730  Validation loss = 1.9031  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 3.5729  Validation loss = 1.9032  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 3.5728  Validation loss = 1.9030  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 3.5727  Validation loss = 1.9027  \n",
      "\n",
      "Fold: 28  Epoch: 49  Training loss = 3.5726  Validation loss = 1.9028  \n",
      "\n",
      "Fold: 28  Epoch: 50  Training loss = 3.5725  Validation loss = 1.9029  \n",
      "\n",
      "Fold: 28  Epoch: 51  Training loss = 3.5723  Validation loss = 1.9025  \n",
      "\n",
      "Fold: 28  Epoch: 52  Training loss = 3.5722  Validation loss = 1.9022  \n",
      "\n",
      "Fold: 28  Epoch: 53  Training loss = 3.5720  Validation loss = 1.9019  \n",
      "\n",
      "Fold: 28  Epoch: 54  Training loss = 3.5719  Validation loss = 1.9017  \n",
      "\n",
      "Fold: 28  Epoch: 55  Training loss = 3.5718  Validation loss = 1.9015  \n",
      "\n",
      "Fold: 28  Epoch: 56  Training loss = 3.5716  Validation loss = 1.9011  \n",
      "\n",
      "Fold: 28  Epoch: 57  Training loss = 3.5714  Validation loss = 1.9008  \n",
      "\n",
      "Fold: 28  Epoch: 58  Training loss = 3.5713  Validation loss = 1.9009  \n",
      "\n",
      "Fold: 28  Epoch: 59  Training loss = 3.5712  Validation loss = 1.9011  \n",
      "\n",
      "Fold: 28  Epoch: 60  Training loss = 3.5712  Validation loss = 1.9013  \n",
      "\n",
      "Fold: 28  Epoch: 61  Training loss = 3.5711  Validation loss = 1.9014  \n",
      "\n",
      "Fold: 28  Epoch: 62  Training loss = 3.5710  Validation loss = 1.9013  \n",
      "\n",
      "Fold: 28  Epoch: 63  Training loss = 3.5709  Validation loss = 1.9008  \n",
      "\n",
      "Fold: 28  Epoch: 64  Training loss = 3.5707  Validation loss = 1.9007  \n",
      "\n",
      "Fold: 28  Epoch: 65  Training loss = 3.5706  Validation loss = 1.9008  \n",
      "\n",
      "Fold: 28  Epoch: 66  Training loss = 3.5705  Validation loss = 1.9007  \n",
      "\n",
      "Fold: 28  Epoch: 67  Training loss = 3.5704  Validation loss = 1.9007  \n",
      "\n",
      "Fold: 28  Epoch: 68  Training loss = 3.5703  Validation loss = 1.9002  \n",
      "\n",
      "Fold: 28  Epoch: 69  Training loss = 3.5702  Validation loss = 1.9000  \n",
      "\n",
      "Fold: 28  Epoch: 70  Training loss = 3.5701  Validation loss = 1.8996  \n",
      "\n",
      "Fold: 28  Epoch: 71  Training loss = 3.5700  Validation loss = 1.8998  \n",
      "\n",
      "Fold: 28  Epoch: 72  Training loss = 3.5699  Validation loss = 1.8994  \n",
      "\n",
      "Fold: 28  Epoch: 73  Training loss = 3.5698  Validation loss = 1.8994  \n",
      "\n",
      "Fold: 28  Epoch: 74  Training loss = 3.5697  Validation loss = 1.8990  \n",
      "\n",
      "Fold: 28  Epoch: 75  Training loss = 3.5696  Validation loss = 1.8989  \n",
      "\n",
      "Fold: 28  Epoch: 76  Training loss = 3.5694  Validation loss = 1.8985  \n",
      "\n",
      "Fold: 28  Epoch: 77  Training loss = 3.5693  Validation loss = 1.8984  \n",
      "\n",
      "Fold: 28  Epoch: 78  Training loss = 3.5692  Validation loss = 1.8983  \n",
      "\n",
      "Fold: 28  Epoch: 79  Training loss = 3.5691  Validation loss = 1.8981  \n",
      "\n",
      "Fold: 28  Epoch: 80  Training loss = 3.5690  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 28  Epoch: 81  Training loss = 3.5689  Validation loss = 1.8976  \n",
      "\n",
      "Fold: 28  Epoch: 82  Training loss = 3.5688  Validation loss = 1.8979  \n",
      "\n",
      "Fold: 28  Epoch: 83  Training loss = 3.5687  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 28  Epoch: 84  Training loss = 3.5687  Validation loss = 1.8982  \n",
      "\n",
      "Fold: 28  Epoch: 85  Training loss = 3.5686  Validation loss = 1.8982  \n",
      "\n",
      "Fold: 28  Epoch: 86  Training loss = 3.5686  Validation loss = 1.8982  \n",
      "\n",
      "Fold: 28  Epoch: 87  Training loss = 3.5685  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 28  Epoch: 88  Training loss = 3.5684  Validation loss = 1.8981  \n",
      "\n",
      "Fold: 28  Epoch: 89  Training loss = 3.5683  Validation loss = 1.8983  \n",
      "\n",
      "Fold: 28  Epoch: 90  Training loss = 3.5682  Validation loss = 1.8984  \n",
      "\n",
      "Fold: 28  Epoch: 91  Training loss = 3.5681  Validation loss = 1.8983  \n",
      "\n",
      "Fold: 28  Epoch: 92  Training loss = 3.5680  Validation loss = 1.8987  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 81  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.5745  Validation loss = 1.2455  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.5744  Validation loss = 1.2448  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.5743  Validation loss = 1.2446  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.5742  Validation loss = 1.2443  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.5740  Validation loss = 1.2445  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.5739  Validation loss = 1.2441  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.5737  Validation loss = 1.2440  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.5736  Validation loss = 1.2444  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.5735  Validation loss = 1.2444  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.5735  Validation loss = 1.2444  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.5734  Validation loss = 1.2445  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 3.5733  Validation loss = 1.2445  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.5733  Validation loss = 1.2445  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 3.5731  Validation loss = 1.2449  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 3.5730  Validation loss = 1.2451  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 3.5729  Validation loss = 1.2454  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 7  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.5173  Validation loss = 1.8350  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.5172  Validation loss = 1.8344  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.5171  Validation loss = 1.8348  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.5170  Validation loss = 1.8346  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.5169  Validation loss = 1.8340  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.5168  Validation loss = 1.8334  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.5167  Validation loss = 1.8329  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.5166  Validation loss = 1.8329  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.5165  Validation loss = 1.8318  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.5164  Validation loss = 1.8313  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.5163  Validation loss = 1.8307  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.5163  Validation loss = 1.8307  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.5161  Validation loss = 1.8300  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 3.5160  Validation loss = 1.8294  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 3.5159  Validation loss = 1.8288  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 3.5158  Validation loss = 1.8283  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 3.5157  Validation loss = 1.8287  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 3.5156  Validation loss = 1.8285  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 3.5155  Validation loss = 1.8281  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 3.5155  Validation loss = 1.8279  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 3.5154  Validation loss = 1.8277  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 3.5154  Validation loss = 1.8279  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 3.5153  Validation loss = 1.8273  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 3.5151  Validation loss = 1.8264  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 3.5151  Validation loss = 1.8267  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 3.5150  Validation loss = 1.8261  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 3.5150  Validation loss = 1.8257  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 3.5149  Validation loss = 1.8257  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 3.5148  Validation loss = 1.8251  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 3.5147  Validation loss = 1.8247  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 3.5146  Validation loss = 1.8238  \n",
      "\n",
      "Fold: 30  Epoch: 32  Training loss = 3.5145  Validation loss = 1.8242  \n",
      "\n",
      "Fold: 30  Epoch: 33  Training loss = 3.5145  Validation loss = 1.8241  \n",
      "\n",
      "Fold: 30  Epoch: 34  Training loss = 3.5145  Validation loss = 1.8245  \n",
      "\n",
      "Fold: 30  Epoch: 35  Training loss = 3.5144  Validation loss = 1.8246  \n",
      "\n",
      "Fold: 30  Epoch: 36  Training loss = 3.5143  Validation loss = 1.8234  \n",
      "\n",
      "Fold: 30  Epoch: 37  Training loss = 3.5143  Validation loss = 1.8236  \n",
      "\n",
      "Fold: 30  Epoch: 38  Training loss = 3.5142  Validation loss = 1.8234  \n",
      "\n",
      "Fold: 30  Epoch: 39  Training loss = 3.5141  Validation loss = 1.8234  \n",
      "\n",
      "Fold: 30  Epoch: 40  Training loss = 3.5141  Validation loss = 1.8235  \n",
      "\n",
      "Fold: 30  Epoch: 41  Training loss = 3.5140  Validation loss = 1.8235  \n",
      "\n",
      "Fold: 30  Epoch: 42  Training loss = 3.5140  Validation loss = 1.8236  \n",
      "\n",
      "Fold: 30  Epoch: 43  Training loss = 3.5139  Validation loss = 1.8233  \n",
      "\n",
      "Fold: 30  Epoch: 44  Training loss = 3.5139  Validation loss = 1.8235  \n",
      "\n",
      "Fold: 30  Epoch: 45  Training loss = 3.5138  Validation loss = 1.8234  \n",
      "\n",
      "Fold: 30  Epoch: 46  Training loss = 3.5138  Validation loss = 1.8233  \n",
      "\n",
      "Fold: 30  Epoch: 47  Training loss = 3.5137  Validation loss = 1.8234  \n",
      "\n",
      "Fold: 30  Epoch: 48  Training loss = 3.5137  Validation loss = 1.8233  \n",
      "\n",
      "Fold: 30  Epoch: 49  Training loss = 3.5136  Validation loss = 1.8234  \n",
      "\n",
      "Fold: 30  Epoch: 50  Training loss = 3.5135  Validation loss = 1.8231  \n",
      "\n",
      "Fold: 30  Epoch: 51  Training loss = 3.5134  Validation loss = 1.8225  \n",
      "\n",
      "Fold: 30  Epoch: 52  Training loss = 3.5134  Validation loss = 1.8220  \n",
      "\n",
      "Fold: 30  Epoch: 53  Training loss = 3.5134  Validation loss = 1.8219  \n",
      "\n",
      "Fold: 30  Epoch: 54  Training loss = 3.5133  Validation loss = 1.8219  \n",
      "\n",
      "Fold: 30  Epoch: 55  Training loss = 3.5132  Validation loss = 1.8214  \n",
      "\n",
      "Fold: 30  Epoch: 56  Training loss = 3.5131  Validation loss = 1.8219  \n",
      "\n",
      "Fold: 30  Epoch: 57  Training loss = 3.5131  Validation loss = 1.8222  \n",
      "\n",
      "Fold: 30  Epoch: 58  Training loss = 3.5131  Validation loss = 1.8214  \n",
      "\n",
      "Fold: 30  Epoch: 59  Training loss = 3.5130  Validation loss = 1.8212  \n",
      "\n",
      "Fold: 30  Epoch: 60  Training loss = 3.5130  Validation loss = 1.8209  \n",
      "\n",
      "Fold: 30  Epoch: 61  Training loss = 3.5129  Validation loss = 1.8210  \n",
      "\n",
      "Fold: 30  Epoch: 62  Training loss = 3.5128  Validation loss = 1.8208  \n",
      "\n",
      "Fold: 30  Epoch: 63  Training loss = 3.5128  Validation loss = 1.8206  \n",
      "\n",
      "Fold: 30  Epoch: 64  Training loss = 3.5127  Validation loss = 1.8208  \n",
      "\n",
      "Fold: 30  Epoch: 65  Training loss = 3.5127  Validation loss = 1.8202  \n",
      "\n",
      "Fold: 30  Epoch: 66  Training loss = 3.5126  Validation loss = 1.8200  \n",
      "\n",
      "Fold: 30  Epoch: 67  Training loss = 3.5126  Validation loss = 1.8204  \n",
      "\n",
      "Fold: 30  Epoch: 68  Training loss = 3.5125  Validation loss = 1.8196  \n",
      "\n",
      "Fold: 30  Epoch: 69  Training loss = 3.5125  Validation loss = 1.8196  \n",
      "\n",
      "Fold: 30  Epoch: 70  Training loss = 3.5124  Validation loss = 1.8195  \n",
      "\n",
      "Fold: 30  Epoch: 71  Training loss = 3.5124  Validation loss = 1.8198  \n",
      "\n",
      "Fold: 30  Epoch: 72  Training loss = 3.5123  Validation loss = 1.8193  \n",
      "\n",
      "Fold: 30  Epoch: 73  Training loss = 3.5123  Validation loss = 1.8197  \n",
      "\n",
      "Fold: 30  Epoch: 74  Training loss = 3.5123  Validation loss = 1.8204  \n",
      "\n",
      "Fold: 30  Epoch: 75  Training loss = 3.5122  Validation loss = 1.8200  \n",
      "\n",
      "Fold: 30  Epoch: 76  Training loss = 3.5122  Validation loss = 1.8197  \n",
      "\n",
      "Fold: 30  Epoch: 77  Training loss = 3.5121  Validation loss = 1.8197  \n",
      "\n",
      "Fold: 30  Epoch: 78  Training loss = 3.5121  Validation loss = 1.8196  \n",
      "\n",
      "Fold: 30  Epoch: 79  Training loss = 3.5120  Validation loss = 1.8196  \n",
      "\n",
      "Fold: 30  Epoch: 80  Training loss = 3.5119  Validation loss = 1.8189  \n",
      "\n",
      "Fold: 30  Epoch: 81  Training loss = 3.5118  Validation loss = 1.8183  \n",
      "\n",
      "Fold: 30  Epoch: 82  Training loss = 3.5118  Validation loss = 1.8189  \n",
      "\n",
      "Fold: 30  Epoch: 83  Training loss = 3.5118  Validation loss = 1.8187  \n",
      "\n",
      "Fold: 30  Epoch: 84  Training loss = 3.5117  Validation loss = 1.8184  \n",
      "\n",
      "Fold: 30  Epoch: 85  Training loss = 3.5117  Validation loss = 1.8185  \n",
      "\n",
      "Fold: 30  Epoch: 86  Training loss = 3.5117  Validation loss = 1.8177  \n",
      "\n",
      "Fold: 30  Epoch: 87  Training loss = 3.5116  Validation loss = 1.8182  \n",
      "\n",
      "Fold: 30  Epoch: 88  Training loss = 3.5116  Validation loss = 1.8178  \n",
      "\n",
      "Fold: 30  Epoch: 89  Training loss = 3.5115  Validation loss = 1.8182  \n",
      "\n",
      "Fold: 30  Epoch: 90  Training loss = 3.5115  Validation loss = 1.8185  \n",
      "\n",
      "Fold: 30  Epoch: 91  Training loss = 3.5114  Validation loss = 1.8182  \n",
      "\n",
      "Fold: 30  Epoch: 92  Training loss = 3.5114  Validation loss = 1.8176  \n",
      "\n",
      "Fold: 30  Epoch: 93  Training loss = 3.5113  Validation loss = 1.8172  \n",
      "\n",
      "Fold: 30  Epoch: 94  Training loss = 3.5113  Validation loss = 1.8168  \n",
      "\n",
      "Fold: 30  Epoch: 95  Training loss = 3.5112  Validation loss = 1.8170  \n",
      "\n",
      "Fold: 30  Epoch: 96  Training loss = 3.5112  Validation loss = 1.8174  \n",
      "\n",
      "Fold: 30  Epoch: 97  Training loss = 3.5111  Validation loss = 1.8170  \n",
      "\n",
      "Fold: 30  Epoch: 98  Training loss = 3.5111  Validation loss = 1.8164  \n",
      "\n",
      "Fold: 30  Epoch: 99  Training loss = 3.5110  Validation loss = 1.8160  \n",
      "\n",
      "Fold: 30  Epoch: 100  Training loss = 3.5110  Validation loss = 1.8161  \n",
      "\n",
      "Fold: 30  Epoch: 101  Training loss = 3.5109  Validation loss = 1.8160  \n",
      "\n",
      "Fold: 30  Epoch: 102  Training loss = 3.5109  Validation loss = 1.8159  \n",
      "\n",
      "Fold: 30  Epoch: 103  Training loss = 3.5109  Validation loss = 1.8155  \n",
      "\n",
      "Fold: 30  Epoch: 104  Training loss = 3.5108  Validation loss = 1.8153  \n",
      "\n",
      "Fold: 30  Epoch: 105  Training loss = 3.5108  Validation loss = 1.8154  \n",
      "\n",
      "Fold: 30  Epoch: 106  Training loss = 3.5107  Validation loss = 1.8160  \n",
      "\n",
      "Fold: 30  Epoch: 107  Training loss = 3.5107  Validation loss = 1.8156  \n",
      "\n",
      "Fold: 30  Epoch: 108  Training loss = 3.5106  Validation loss = 1.8161  \n",
      "\n",
      "Fold: 30  Epoch: 109  Training loss = 3.5105  Validation loss = 1.8161  \n",
      "\n",
      "Fold: 30  Epoch: 110  Training loss = 3.5105  Validation loss = 1.8161  \n",
      "\n",
      "Fold: 30  Epoch: 111  Training loss = 3.5104  Validation loss = 1.8164  \n",
      "\n",
      "Fold: 30  Epoch: 112  Training loss = 3.5104  Validation loss = 1.8160  \n",
      "\n",
      "Fold: 30  Epoch: 113  Training loss = 3.5103  Validation loss = 1.8158  \n",
      "\n",
      "Fold: 30  Epoch: 114  Training loss = 3.5103  Validation loss = 1.8162  \n",
      "\n",
      "Fold: 30  Epoch: 115  Training loss = 3.5102  Validation loss = 1.8166  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 104  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 3.1634  Validation loss = 1.1634  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 3.1634  Validation loss = 1.1633  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 3.1633  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 3.1633  Validation loss = 1.1630  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 3.1633  Validation loss = 1.1630  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 3.1633  Validation loss = 1.1625  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 3.1632  Validation loss = 1.1623  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 3.1632  Validation loss = 1.1626  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 3.1632  Validation loss = 1.1628  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 3.1632  Validation loss = 1.1625  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 3.1632  Validation loss = 1.1622  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 3.1631  Validation loss = 1.1622  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 3.1632  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 3.1632  Validation loss = 1.1628  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 3.1632  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 3.1631  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 3.1631  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 3.1632  Validation loss = 1.1629  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 3.1632  Validation loss = 1.1630  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 3.1631  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 3.1632  Validation loss = 1.1632  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 11  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.3648  Validation loss = 2.8555  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.3647  Validation loss = 2.8550  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.3645  Validation loss = 2.8540  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.3643  Validation loss = 2.8529  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.3639  Validation loss = 2.8512  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.3637  Validation loss = 2.8500  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.3634  Validation loss = 2.8486  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.3632  Validation loss = 2.8470  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.3629  Validation loss = 2.8460  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.3627  Validation loss = 2.8450  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.3625  Validation loss = 2.8437  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.3622  Validation loss = 2.8422  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.3621  Validation loss = 2.8414  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.3619  Validation loss = 2.8407  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.3618  Validation loss = 2.8399  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.3616  Validation loss = 2.8391  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.3612  Validation loss = 2.8373  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.3611  Validation loss = 2.8368  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.3609  Validation loss = 2.8357  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.3607  Validation loss = 2.8346  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.3606  Validation loss = 2.8340  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.3604  Validation loss = 2.8327  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.3601  Validation loss = 2.8315  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.3599  Validation loss = 2.8301  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.3597  Validation loss = 2.8287  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.3595  Validation loss = 2.8280  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.3594  Validation loss = 2.8273  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.3591  Validation loss = 2.8258  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.3590  Validation loss = 2.8249  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.3588  Validation loss = 2.8242  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.3586  Validation loss = 2.8231  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.3585  Validation loss = 2.8226  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.3583  Validation loss = 2.8214  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.3580  Validation loss = 2.8201  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.3579  Validation loss = 2.8192  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.3577  Validation loss = 2.8184  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.3575  Validation loss = 2.8174  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.3573  Validation loss = 2.8164  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.3571  Validation loss = 2.8153  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.3569  Validation loss = 2.8141  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.3567  Validation loss = 2.8131  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.3566  Validation loss = 2.8125  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.3565  Validation loss = 2.8117  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.3562  Validation loss = 2.8104  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.3560  Validation loss = 2.8096  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.3559  Validation loss = 2.8087  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.3557  Validation loss = 2.8080  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.3556  Validation loss = 2.8069  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.3554  Validation loss = 2.8060  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.3552  Validation loss = 2.8048  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.3550  Validation loss = 2.8038  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.3548  Validation loss = 2.8025  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.3546  Validation loss = 2.8012  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.3543  Validation loss = 2.7998  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.3542  Validation loss = 2.7992  \n",
      "\n",
      "Fold: 32  Epoch: 56  Training loss = 2.3539  Validation loss = 2.7977  \n",
      "\n",
      "Fold: 32  Epoch: 57  Training loss = 2.3540  Validation loss = 2.7981  \n",
      "\n",
      "Fold: 32  Epoch: 58  Training loss = 2.3538  Validation loss = 2.7971  \n",
      "\n",
      "Fold: 32  Epoch: 59  Training loss = 2.3537  Validation loss = 2.7962  \n",
      "\n",
      "Fold: 32  Epoch: 60  Training loss = 2.3536  Validation loss = 2.7959  \n",
      "\n",
      "Fold: 32  Epoch: 61  Training loss = 2.3534  Validation loss = 2.7950  \n",
      "\n",
      "Fold: 32  Epoch: 62  Training loss = 2.3532  Validation loss = 2.7936  \n",
      "\n",
      "Fold: 32  Epoch: 63  Training loss = 2.3531  Validation loss = 2.7929  \n",
      "\n",
      "Fold: 32  Epoch: 64  Training loss = 2.3530  Validation loss = 2.7926  \n",
      "\n",
      "Fold: 32  Epoch: 65  Training loss = 2.3529  Validation loss = 2.7916  \n",
      "\n",
      "Fold: 32  Epoch: 66  Training loss = 2.3527  Validation loss = 2.7906  \n",
      "\n",
      "Fold: 32  Epoch: 67  Training loss = 2.3525  Validation loss = 2.7894  \n",
      "\n",
      "Fold: 32  Epoch: 68  Training loss = 2.3523  Validation loss = 2.7885  \n",
      "\n",
      "Fold: 32  Epoch: 69  Training loss = 2.3522  Validation loss = 2.7878  \n",
      "\n",
      "Fold: 32  Epoch: 70  Training loss = 2.3520  Validation loss = 2.7869  \n",
      "\n",
      "Fold: 32  Epoch: 71  Training loss = 2.3519  Validation loss = 2.7864  \n",
      "\n",
      "Fold: 32  Epoch: 72  Training loss = 2.3518  Validation loss = 2.7860  \n",
      "\n",
      "Fold: 32  Epoch: 73  Training loss = 2.3517  Validation loss = 2.7852  \n",
      "\n",
      "Fold: 32  Epoch: 74  Training loss = 2.3516  Validation loss = 2.7845  \n",
      "\n",
      "Fold: 32  Epoch: 75  Training loss = 2.3514  Validation loss = 2.7835  \n",
      "\n",
      "Fold: 32  Epoch: 76  Training loss = 2.3512  Validation loss = 2.7827  \n",
      "\n",
      "Fold: 32  Epoch: 77  Training loss = 2.3511  Validation loss = 2.7823  \n",
      "\n",
      "Fold: 32  Epoch: 78  Training loss = 2.3510  Validation loss = 2.7817  \n",
      "\n",
      "Fold: 32  Epoch: 79  Training loss = 2.3508  Validation loss = 2.7803  \n",
      "\n",
      "Fold: 32  Epoch: 80  Training loss = 2.3508  Validation loss = 2.7802  \n",
      "\n",
      "Fold: 32  Epoch: 81  Training loss = 2.3508  Validation loss = 2.7803  \n",
      "\n",
      "Fold: 32  Epoch: 82  Training loss = 2.3506  Validation loss = 2.7793  \n",
      "\n",
      "Fold: 32  Epoch: 83  Training loss = 2.3504  Validation loss = 2.7784  \n",
      "\n",
      "Fold: 32  Epoch: 84  Training loss = 2.3503  Validation loss = 2.7779  \n",
      "\n",
      "Fold: 32  Epoch: 85  Training loss = 2.3502  Validation loss = 2.7770  \n",
      "\n",
      "Fold: 32  Epoch: 86  Training loss = 2.3500  Validation loss = 2.7763  \n",
      "\n",
      "Fold: 32  Epoch: 87  Training loss = 2.3498  Validation loss = 2.7751  \n",
      "\n",
      "Fold: 32  Epoch: 88  Training loss = 2.3497  Validation loss = 2.7744  \n",
      "\n",
      "Fold: 32  Epoch: 89  Training loss = 2.3496  Validation loss = 2.7737  \n",
      "\n",
      "Fold: 32  Epoch: 90  Training loss = 2.3494  Validation loss = 2.7729  \n",
      "\n",
      "Fold: 32  Epoch: 91  Training loss = 2.3493  Validation loss = 2.7718  \n",
      "\n",
      "Fold: 32  Epoch: 92  Training loss = 2.3491  Validation loss = 2.7712  \n",
      "\n",
      "Fold: 32  Epoch: 93  Training loss = 2.3490  Validation loss = 2.7706  \n",
      "\n",
      "Fold: 32  Epoch: 94  Training loss = 2.3489  Validation loss = 2.7703  \n",
      "\n",
      "Fold: 32  Epoch: 95  Training loss = 2.3488  Validation loss = 2.7697  \n",
      "\n",
      "Fold: 32  Epoch: 96  Training loss = 2.3487  Validation loss = 2.7691  \n",
      "\n",
      "Fold: 32  Epoch: 97  Training loss = 2.3485  Validation loss = 2.7680  \n",
      "\n",
      "Fold: 32  Epoch: 98  Training loss = 2.3483  Validation loss = 2.7668  \n",
      "\n",
      "Fold: 32  Epoch: 99  Training loss = 2.3481  Validation loss = 2.7658  \n",
      "\n",
      "Fold: 32  Epoch: 100  Training loss = 2.3479  Validation loss = 2.7650  \n",
      "\n",
      "Fold: 32  Epoch: 101  Training loss = 2.3478  Validation loss = 2.7640  \n",
      "\n",
      "Fold: 32  Epoch: 102  Training loss = 2.3477  Validation loss = 2.7636  \n",
      "\n",
      "Fold: 32  Epoch: 103  Training loss = 2.3476  Validation loss = 2.7631  \n",
      "\n",
      "Fold: 32  Epoch: 104  Training loss = 2.3475  Validation loss = 2.7623  \n",
      "\n",
      "Fold: 32  Epoch: 105  Training loss = 2.3474  Validation loss = 2.7621  \n",
      "\n",
      "Fold: 32  Epoch: 106  Training loss = 2.3474  Validation loss = 2.7618  \n",
      "\n",
      "Fold: 32  Epoch: 107  Training loss = 2.3473  Validation loss = 2.7614  \n",
      "\n",
      "Fold: 32  Epoch: 108  Training loss = 2.3472  Validation loss = 2.7607  \n",
      "\n",
      "Fold: 32  Epoch: 109  Training loss = 2.3470  Validation loss = 2.7593  \n",
      "\n",
      "Fold: 32  Epoch: 110  Training loss = 2.3469  Validation loss = 2.7588  \n",
      "\n",
      "Fold: 32  Epoch: 111  Training loss = 2.3467  Validation loss = 2.7579  \n",
      "\n",
      "Fold: 32  Epoch: 112  Training loss = 2.3466  Validation loss = 2.7572  \n",
      "\n",
      "Fold: 32  Epoch: 113  Training loss = 2.3465  Validation loss = 2.7567  \n",
      "\n",
      "Fold: 32  Epoch: 114  Training loss = 2.3464  Validation loss = 2.7563  \n",
      "\n",
      "Fold: 32  Epoch: 115  Training loss = 2.3463  Validation loss = 2.7558  \n",
      "\n",
      "Fold: 32  Epoch: 116  Training loss = 2.3461  Validation loss = 2.7546  \n",
      "\n",
      "Fold: 32  Epoch: 117  Training loss = 2.3460  Validation loss = 2.7538  \n",
      "\n",
      "Fold: 32  Epoch: 118  Training loss = 2.3458  Validation loss = 2.7529  \n",
      "\n",
      "Fold: 32  Epoch: 119  Training loss = 2.3458  Validation loss = 2.7529  \n",
      "\n",
      "Fold: 32  Epoch: 120  Training loss = 2.3458  Validation loss = 2.7527  \n",
      "\n",
      "Fold: 32  Epoch: 121  Training loss = 2.3455  Validation loss = 2.7513  \n",
      "\n",
      "Fold: 32  Epoch: 122  Training loss = 2.3454  Validation loss = 2.7505  \n",
      "\n",
      "Fold: 32  Epoch: 123  Training loss = 2.3454  Validation loss = 2.7507  \n",
      "\n",
      "Fold: 32  Epoch: 124  Training loss = 2.3453  Validation loss = 2.7499  \n",
      "\n",
      "Fold: 32  Epoch: 125  Training loss = 2.3451  Validation loss = 2.7492  \n",
      "\n",
      "Fold: 32  Epoch: 126  Training loss = 2.3450  Validation loss = 2.7485  \n",
      "\n",
      "Fold: 32  Epoch: 127  Training loss = 2.3450  Validation loss = 2.7482  \n",
      "\n",
      "Fold: 32  Epoch: 128  Training loss = 2.3448  Validation loss = 2.7473  \n",
      "\n",
      "Fold: 32  Epoch: 129  Training loss = 2.3446  Validation loss = 2.7464  \n",
      "\n",
      "Fold: 32  Epoch: 130  Training loss = 2.3446  Validation loss = 2.7461  \n",
      "\n",
      "Fold: 32  Epoch: 131  Training loss = 2.3445  Validation loss = 2.7455  \n",
      "\n",
      "Fold: 32  Epoch: 132  Training loss = 2.3443  Validation loss = 2.7444  \n",
      "\n",
      "Fold: 32  Epoch: 133  Training loss = 2.3442  Validation loss = 2.7438  \n",
      "\n",
      "Fold: 32  Epoch: 134  Training loss = 2.3441  Validation loss = 2.7431  \n",
      "\n",
      "Fold: 32  Epoch: 135  Training loss = 2.3440  Validation loss = 2.7425  \n",
      "\n",
      "Fold: 32  Epoch: 136  Training loss = 2.3438  Validation loss = 2.7416  \n",
      "\n",
      "Fold: 32  Epoch: 137  Training loss = 2.3437  Validation loss = 2.7409  \n",
      "\n",
      "Fold: 32  Epoch: 138  Training loss = 2.3435  Validation loss = 2.7402  \n",
      "\n",
      "Fold: 32  Epoch: 139  Training loss = 2.3434  Validation loss = 2.7392  \n",
      "\n",
      "Fold: 32  Epoch: 140  Training loss = 2.3432  Validation loss = 2.7385  \n",
      "\n",
      "Fold: 32  Epoch: 141  Training loss = 2.3431  Validation loss = 2.7377  \n",
      "\n",
      "Fold: 32  Epoch: 142  Training loss = 2.3430  Validation loss = 2.7372  \n",
      "\n",
      "Fold: 32  Epoch: 143  Training loss = 2.3429  Validation loss = 2.7365  \n",
      "\n",
      "Fold: 32  Epoch: 144  Training loss = 2.3428  Validation loss = 2.7361  \n",
      "\n",
      "Fold: 32  Epoch: 145  Training loss = 2.3427  Validation loss = 2.7353  \n",
      "\n",
      "Fold: 32  Epoch: 146  Training loss = 2.3425  Validation loss = 2.7344  \n",
      "\n",
      "Fold: 32  Epoch: 147  Training loss = 2.3424  Validation loss = 2.7338  \n",
      "\n",
      "Fold: 32  Epoch: 148  Training loss = 2.3423  Validation loss = 2.7332  \n",
      "\n",
      "Fold: 32  Epoch: 149  Training loss = 2.3422  Validation loss = 2.7325  \n",
      "\n",
      "Fold: 32  Epoch: 150  Training loss = 2.3422  Validation loss = 2.7321  \n",
      "\n",
      "Fold: 32  Epoch: 151  Training loss = 2.3420  Validation loss = 2.7314  \n",
      "\n",
      "Fold: 32  Epoch: 152  Training loss = 2.3418  Validation loss = 2.7300  \n",
      "\n",
      "Fold: 32  Epoch: 153  Training loss = 2.3418  Validation loss = 2.7302  \n",
      "\n",
      "Fold: 32  Epoch: 154  Training loss = 2.3416  Validation loss = 2.7293  \n",
      "\n",
      "Fold: 32  Epoch: 155  Training loss = 2.3415  Validation loss = 2.7289  \n",
      "\n",
      "Fold: 32  Epoch: 156  Training loss = 2.3414  Validation loss = 2.7282  \n",
      "\n",
      "Fold: 32  Epoch: 157  Training loss = 2.3413  Validation loss = 2.7274  \n",
      "\n",
      "Fold: 32  Epoch: 158  Training loss = 2.3412  Validation loss = 2.7267  \n",
      "\n",
      "Fold: 32  Epoch: 159  Training loss = 2.3410  Validation loss = 2.7260  \n",
      "\n",
      "Fold: 32  Epoch: 160  Training loss = 2.3410  Validation loss = 2.7257  \n",
      "\n",
      "Fold: 32  Epoch: 161  Training loss = 2.3408  Validation loss = 2.7245  \n",
      "\n",
      "Fold: 32  Epoch: 162  Training loss = 2.3406  Validation loss = 2.7236  \n",
      "\n",
      "Fold: 32  Epoch: 163  Training loss = 2.3405  Validation loss = 2.7234  \n",
      "\n",
      "Fold: 32  Epoch: 164  Training loss = 2.3405  Validation loss = 2.7232  \n",
      "\n",
      "Fold: 32  Epoch: 165  Training loss = 2.3404  Validation loss = 2.7230  \n",
      "\n",
      "Fold: 32  Epoch: 166  Training loss = 2.3403  Validation loss = 2.7224  \n",
      "\n",
      "Fold: 32  Epoch: 167  Training loss = 2.3401  Validation loss = 2.7212  \n",
      "\n",
      "Fold: 32  Epoch: 168  Training loss = 2.3401  Validation loss = 2.7210  \n",
      "\n",
      "Fold: 32  Epoch: 169  Training loss = 2.3400  Validation loss = 2.7203  \n",
      "\n",
      "Fold: 32  Epoch: 170  Training loss = 2.3398  Validation loss = 2.7195  \n",
      "\n",
      "Fold: 32  Epoch: 171  Training loss = 2.3396  Validation loss = 2.7181  \n",
      "\n",
      "Fold: 32  Epoch: 172  Training loss = 2.3396  Validation loss = 2.7177  \n",
      "\n",
      "Fold: 32  Epoch: 173  Training loss = 2.3395  Validation loss = 2.7173  \n",
      "\n",
      "Fold: 32  Epoch: 174  Training loss = 2.3394  Validation loss = 2.7169  \n",
      "\n",
      "Fold: 32  Epoch: 175  Training loss = 2.3393  Validation loss = 2.7163  \n",
      "\n",
      "Fold: 32  Epoch: 176  Training loss = 2.3391  Validation loss = 2.7156  \n",
      "\n",
      "Fold: 32  Epoch: 177  Training loss = 2.3390  Validation loss = 2.7149  \n",
      "\n",
      "Fold: 32  Epoch: 178  Training loss = 2.3389  Validation loss = 2.7145  \n",
      "\n",
      "Fold: 32  Epoch: 179  Training loss = 2.3388  Validation loss = 2.7138  \n",
      "\n",
      "Fold: 32  Epoch: 180  Training loss = 2.3386  Validation loss = 2.7128  \n",
      "\n",
      "Fold: 32  Epoch: 181  Training loss = 2.3385  Validation loss = 2.7120  \n",
      "\n",
      "Fold: 32  Epoch: 182  Training loss = 2.3385  Validation loss = 2.7117  \n",
      "\n",
      "Fold: 32  Epoch: 183  Training loss = 2.3384  Validation loss = 2.7116  \n",
      "\n",
      "Fold: 32  Epoch: 184  Training loss = 2.3383  Validation loss = 2.7109  \n",
      "\n",
      "Fold: 32  Epoch: 185  Training loss = 2.3383  Validation loss = 2.7111  \n",
      "\n",
      "Fold: 32  Epoch: 186  Training loss = 2.3382  Validation loss = 2.7103  \n",
      "\n",
      "Fold: 32  Epoch: 187  Training loss = 2.3380  Validation loss = 2.7094  \n",
      "\n",
      "Fold: 32  Epoch: 188  Training loss = 2.3379  Validation loss = 2.7087  \n",
      "\n",
      "Fold: 32  Epoch: 189  Training loss = 2.3378  Validation loss = 2.7083  \n",
      "\n",
      "Fold: 32  Epoch: 190  Training loss = 2.3377  Validation loss = 2.7082  \n",
      "\n",
      "Fold: 32  Epoch: 191  Training loss = 2.3376  Validation loss = 2.7078  \n",
      "\n",
      "Fold: 32  Epoch: 192  Training loss = 2.3375  Validation loss = 2.7073  \n",
      "\n",
      "Fold: 32  Epoch: 193  Training loss = 2.3375  Validation loss = 2.7070  \n",
      "\n",
      "Fold: 32  Epoch: 194  Training loss = 2.3374  Validation loss = 2.7067  \n",
      "\n",
      "Fold: 32  Epoch: 195  Training loss = 2.3374  Validation loss = 2.7066  \n",
      "\n",
      "Fold: 32  Epoch: 196  Training loss = 2.3372  Validation loss = 2.7057  \n",
      "\n",
      "Fold: 32  Epoch: 197  Training loss = 2.3372  Validation loss = 2.7055  \n",
      "\n",
      "Fold: 32  Epoch: 198  Training loss = 2.3371  Validation loss = 2.7053  \n",
      "\n",
      "Fold: 32  Epoch: 199  Training loss = 2.3369  Validation loss = 2.7043  \n",
      "\n",
      "Fold: 32  Epoch: 200  Training loss = 2.3368  Validation loss = 2.7039  \n",
      "\n",
      "Fold: 32  Epoch: 201  Training loss = 2.3368  Validation loss = 2.7039  \n",
      "\n",
      "Fold: 32  Epoch: 202  Training loss = 2.3366  Validation loss = 2.7030  \n",
      "\n",
      "Fold: 32  Epoch: 203  Training loss = 2.3365  Validation loss = 2.7023  \n",
      "\n",
      "Fold: 32  Epoch: 204  Training loss = 2.3364  Validation loss = 2.7018  \n",
      "\n",
      "Fold: 32  Epoch: 205  Training loss = 2.3363  Validation loss = 2.7012  \n",
      "\n",
      "Fold: 32  Epoch: 206  Training loss = 2.3362  Validation loss = 2.7007  \n",
      "\n",
      "Fold: 32  Epoch: 207  Training loss = 2.3362  Validation loss = 2.7011  \n",
      "\n",
      "Fold: 32  Epoch: 208  Training loss = 2.3362  Validation loss = 2.7006  \n",
      "\n",
      "Fold: 32  Epoch: 209  Training loss = 2.3361  Validation loss = 2.7007  \n",
      "\n",
      "Fold: 32  Epoch: 210  Training loss = 2.3360  Validation loss = 2.7002  \n",
      "\n",
      "Fold: 32  Epoch: 211  Training loss = 2.3360  Validation loss = 2.7002  \n",
      "\n",
      "Fold: 32  Epoch: 212  Training loss = 2.3359  Validation loss = 2.6996  \n",
      "\n",
      "Fold: 32  Epoch: 213  Training loss = 2.3358  Validation loss = 2.6989  \n",
      "\n",
      "Fold: 32  Epoch: 214  Training loss = 2.3357  Validation loss = 2.6984  \n",
      "\n",
      "Fold: 32  Epoch: 215  Training loss = 2.3355  Validation loss = 2.6974  \n",
      "\n",
      "Fold: 32  Epoch: 216  Training loss = 2.3353  Validation loss = 2.6965  \n",
      "\n",
      "Fold: 32  Epoch: 217  Training loss = 2.3352  Validation loss = 2.6957  \n",
      "\n",
      "Fold: 32  Epoch: 218  Training loss = 2.3351  Validation loss = 2.6949  \n",
      "\n",
      "Fold: 32  Epoch: 219  Training loss = 2.3350  Validation loss = 2.6943  \n",
      "\n",
      "Fold: 32  Epoch: 220  Training loss = 2.3349  Validation loss = 2.6936  \n",
      "\n",
      "Fold: 32  Epoch: 221  Training loss = 2.3348  Validation loss = 2.6930  \n",
      "\n",
      "Fold: 32  Epoch: 222  Training loss = 2.3347  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 32  Epoch: 223  Training loss = 2.3345  Validation loss = 2.6916  \n",
      "\n",
      "Fold: 32  Epoch: 224  Training loss = 2.3345  Validation loss = 2.6915  \n",
      "\n",
      "Fold: 32  Epoch: 225  Training loss = 2.3343  Validation loss = 2.6907  \n",
      "\n",
      "Fold: 32  Epoch: 226  Training loss = 2.3342  Validation loss = 2.6900  \n",
      "\n",
      "Fold: 32  Epoch: 227  Training loss = 2.3341  Validation loss = 2.6894  \n",
      "\n",
      "Fold: 32  Epoch: 228  Training loss = 2.3341  Validation loss = 2.6893  \n",
      "\n",
      "Fold: 32  Epoch: 229  Training loss = 2.3341  Validation loss = 2.6890  \n",
      "\n",
      "Fold: 32  Epoch: 230  Training loss = 2.3340  Validation loss = 2.6883  \n",
      "\n",
      "Fold: 32  Epoch: 231  Training loss = 2.3337  Validation loss = 2.6870  \n",
      "\n",
      "Fold: 32  Epoch: 232  Training loss = 2.3336  Validation loss = 2.6865  \n",
      "\n",
      "Fold: 32  Epoch: 233  Training loss = 2.3335  Validation loss = 2.6858  \n",
      "\n",
      "Fold: 32  Epoch: 234  Training loss = 2.3334  Validation loss = 2.6853  \n",
      "\n",
      "Fold: 32  Epoch: 235  Training loss = 2.3333  Validation loss = 2.6847  \n",
      "\n",
      "Fold: 32  Epoch: 236  Training loss = 2.3332  Validation loss = 2.6840  \n",
      "\n",
      "Fold: 32  Epoch: 237  Training loss = 2.3331  Validation loss = 2.6836  \n",
      "\n",
      "Fold: 32  Epoch: 238  Training loss = 2.3331  Validation loss = 2.6835  \n",
      "\n",
      "Fold: 32  Epoch: 239  Training loss = 2.3330  Validation loss = 2.6828  \n",
      "\n",
      "Fold: 32  Epoch: 240  Training loss = 2.3330  Validation loss = 2.6823  \n",
      "\n",
      "Fold: 32  Epoch: 241  Training loss = 2.3330  Validation loss = 2.6826  \n",
      "\n",
      "Fold: 32  Epoch: 242  Training loss = 2.3328  Validation loss = 2.6816  \n",
      "\n",
      "Fold: 32  Epoch: 243  Training loss = 2.3328  Validation loss = 2.6814  \n",
      "\n",
      "Fold: 32  Epoch: 244  Training loss = 2.3327  Validation loss = 2.6808  \n",
      "\n",
      "Fold: 32  Epoch: 245  Training loss = 2.3326  Validation loss = 2.6801  \n",
      "\n",
      "Fold: 32  Epoch: 246  Training loss = 2.3324  Validation loss = 2.6791  \n",
      "\n",
      "Fold: 32  Epoch: 247  Training loss = 2.3323  Validation loss = 2.6784  \n",
      "\n",
      "Fold: 32  Epoch: 248  Training loss = 2.3323  Validation loss = 2.6785  \n",
      "\n",
      "Fold: 32  Epoch: 249  Training loss = 2.3322  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 32  Epoch: 250  Training loss = 2.3322  Validation loss = 2.6785  \n",
      "\n",
      "Fold: 32  Epoch: 251  Training loss = 2.3321  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 32  Epoch: 252  Training loss = 2.3321  Validation loss = 2.6777  \n",
      "\n",
      "Fold: 32  Epoch: 253  Training loss = 2.3319  Validation loss = 2.6766  \n",
      "\n",
      "Fold: 32  Epoch: 254  Training loss = 2.3318  Validation loss = 2.6758  \n",
      "\n",
      "Fold: 32  Epoch: 255  Training loss = 2.3317  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 32  Epoch: 256  Training loss = 2.3316  Validation loss = 2.6746  \n",
      "\n",
      "Fold: 32  Epoch: 257  Training loss = 2.3315  Validation loss = 2.6741  \n",
      "\n",
      "Fold: 32  Epoch: 258  Training loss = 2.3313  Validation loss = 2.6731  \n",
      "\n",
      "Fold: 32  Epoch: 259  Training loss = 2.3312  Validation loss = 2.6724  \n",
      "\n",
      "Fold: 32  Epoch: 260  Training loss = 2.3311  Validation loss = 2.6720  \n",
      "\n",
      "Fold: 32  Epoch: 261  Training loss = 2.3310  Validation loss = 2.6713  \n",
      "\n",
      "Fold: 32  Epoch: 262  Training loss = 2.3309  Validation loss = 2.6707  \n",
      "\n",
      "Fold: 32  Epoch: 263  Training loss = 2.3308  Validation loss = 2.6702  \n",
      "\n",
      "Fold: 32  Epoch: 264  Training loss = 2.3307  Validation loss = 2.6698  \n",
      "\n",
      "Fold: 32  Epoch: 265  Training loss = 2.3306  Validation loss = 2.6692  \n",
      "\n",
      "Fold: 32  Epoch: 266  Training loss = 2.3305  Validation loss = 2.6687  \n",
      "\n",
      "Fold: 32  Epoch: 267  Training loss = 2.3304  Validation loss = 2.6681  \n",
      "\n",
      "Fold: 32  Epoch: 268  Training loss = 2.3303  Validation loss = 2.6674  \n",
      "\n",
      "Fold: 32  Epoch: 269  Training loss = 2.3302  Validation loss = 2.6670  \n",
      "\n",
      "Fold: 32  Epoch: 270  Training loss = 2.3302  Validation loss = 2.6666  \n",
      "\n",
      "Fold: 32  Epoch: 271  Training loss = 2.3300  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 32  Epoch: 272  Training loss = 2.3299  Validation loss = 2.6653  \n",
      "\n",
      "Fold: 32  Epoch: 273  Training loss = 2.3299  Validation loss = 2.6651  \n",
      "\n",
      "Fold: 32  Epoch: 274  Training loss = 2.3297  Validation loss = 2.6642  \n",
      "\n",
      "Fold: 32  Epoch: 275  Training loss = 2.3296  Validation loss = 2.6635  \n",
      "\n",
      "Fold: 32  Epoch: 276  Training loss = 2.3295  Validation loss = 2.6627  \n",
      "\n",
      "Fold: 32  Epoch: 277  Training loss = 2.3294  Validation loss = 2.6625  \n",
      "\n",
      "Fold: 32  Epoch: 278  Training loss = 2.3293  Validation loss = 2.6618  \n",
      "\n",
      "Fold: 32  Epoch: 279  Training loss = 2.3293  Validation loss = 2.6619  \n",
      "\n",
      "Fold: 32  Epoch: 280  Training loss = 2.3292  Validation loss = 2.6607  \n",
      "\n",
      "Fold: 32  Epoch: 281  Training loss = 2.3291  Validation loss = 2.6602  \n",
      "\n",
      "Fold: 32  Epoch: 282  Training loss = 2.3290  Validation loss = 2.6597  \n",
      "\n",
      "Fold: 32  Epoch: 283  Training loss = 2.3288  Validation loss = 2.6588  \n",
      "\n",
      "Fold: 32  Epoch: 284  Training loss = 2.3287  Validation loss = 2.6580  \n",
      "\n",
      "Fold: 32  Epoch: 285  Training loss = 2.3286  Validation loss = 2.6573  \n",
      "\n",
      "Fold: 32  Epoch: 286  Training loss = 2.3285  Validation loss = 2.6568  \n",
      "\n",
      "Fold: 32  Epoch: 287  Training loss = 2.3284  Validation loss = 2.6565  \n",
      "\n",
      "Fold: 32  Epoch: 288  Training loss = 2.3283  Validation loss = 2.6559  \n",
      "\n",
      "Fold: 32  Epoch: 289  Training loss = 2.3282  Validation loss = 2.6553  \n",
      "\n",
      "Fold: 32  Epoch: 290  Training loss = 2.3282  Validation loss = 2.6549  \n",
      "\n",
      "Fold: 32  Epoch: 291  Training loss = 2.3281  Validation loss = 2.6549  \n",
      "\n",
      "Fold: 32  Epoch: 292  Training loss = 2.3281  Validation loss = 2.6546  \n",
      "\n",
      "Fold: 32  Epoch: 293  Training loss = 2.3280  Validation loss = 2.6541  \n",
      "\n",
      "Fold: 32  Epoch: 294  Training loss = 2.3279  Validation loss = 2.6533  \n",
      "\n",
      "Fold: 32  Epoch: 295  Training loss = 2.3278  Validation loss = 2.6529  \n",
      "\n",
      "Fold: 32  Epoch: 296  Training loss = 2.3277  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 32  Epoch: 297  Training loss = 2.3275  Validation loss = 2.6516  \n",
      "\n",
      "Fold: 32  Epoch: 298  Training loss = 2.3275  Validation loss = 2.6513  \n",
      "\n",
      "Fold: 32  Epoch: 299  Training loss = 2.3274  Validation loss = 2.6508  \n",
      "\n",
      "Fold: 32  Epoch: 300  Training loss = 2.3272  Validation loss = 2.6495  \n",
      "\n",
      "Fold: 32  Epoch: 301  Training loss = 2.3272  Validation loss = 2.6494  \n",
      "\n",
      "Fold: 32  Epoch: 302  Training loss = 2.3271  Validation loss = 2.6490  \n",
      "\n",
      "Fold: 32  Epoch: 303  Training loss = 2.3270  Validation loss = 2.6487  \n",
      "\n",
      "Fold: 32  Epoch: 304  Training loss = 2.3270  Validation loss = 2.6485  \n",
      "\n",
      "Fold: 32  Epoch: 305  Training loss = 2.3269  Validation loss = 2.6478  \n",
      "\n",
      "Fold: 32  Epoch: 306  Training loss = 2.3268  Validation loss = 2.6477  \n",
      "\n",
      "Fold: 32  Epoch: 307  Training loss = 2.3267  Validation loss = 2.6469  \n",
      "\n",
      "Fold: 32  Epoch: 308  Training loss = 2.3267  Validation loss = 2.6466  \n",
      "\n",
      "Fold: 32  Epoch: 309  Training loss = 2.3266  Validation loss = 2.6463  \n",
      "\n",
      "Fold: 32  Epoch: 310  Training loss = 2.3265  Validation loss = 2.6454  \n",
      "\n",
      "Fold: 32  Epoch: 311  Training loss = 2.3264  Validation loss = 2.6448  \n",
      "\n",
      "Fold: 32  Epoch: 312  Training loss = 2.3263  Validation loss = 2.6446  \n",
      "\n",
      "Fold: 32  Epoch: 313  Training loss = 2.3263  Validation loss = 2.6441  \n",
      "\n",
      "Fold: 32  Epoch: 314  Training loss = 2.3262  Validation loss = 2.6437  \n",
      "\n",
      "Fold: 32  Epoch: 315  Training loss = 2.3261  Validation loss = 2.6432  \n",
      "\n",
      "Fold: 32  Epoch: 316  Training loss = 2.3261  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 32  Epoch: 317  Training loss = 2.3259  Validation loss = 2.6422  \n",
      "\n",
      "Fold: 32  Epoch: 318  Training loss = 2.3258  Validation loss = 2.6417  \n",
      "\n",
      "Fold: 32  Epoch: 319  Training loss = 2.3257  Validation loss = 2.6412  \n",
      "\n",
      "Fold: 32  Epoch: 320  Training loss = 2.3257  Validation loss = 2.6410  \n",
      "\n",
      "Fold: 32  Epoch: 321  Training loss = 2.3256  Validation loss = 2.6405  \n",
      "\n",
      "Fold: 32  Epoch: 322  Training loss = 2.3255  Validation loss = 2.6400  \n",
      "\n",
      "Fold: 32  Epoch: 323  Training loss = 2.3255  Validation loss = 2.6397  \n",
      "\n",
      "Fold: 32  Epoch: 324  Training loss = 2.3254  Validation loss = 2.6393  \n",
      "\n",
      "Fold: 32  Epoch: 325  Training loss = 2.3254  Validation loss = 2.6392  \n",
      "\n",
      "Fold: 32  Epoch: 326  Training loss = 2.3253  Validation loss = 2.6386  \n",
      "\n",
      "Fold: 32  Epoch: 327  Training loss = 2.3253  Validation loss = 2.6385  \n",
      "\n",
      "Fold: 32  Epoch: 328  Training loss = 2.3252  Validation loss = 2.6375  \n",
      "\n",
      "Fold: 32  Epoch: 329  Training loss = 2.3250  Validation loss = 2.6366  \n",
      "\n",
      "Fold: 32  Epoch: 330  Training loss = 2.3249  Validation loss = 2.6358  \n",
      "\n",
      "Fold: 32  Epoch: 331  Training loss = 2.3249  Validation loss = 2.6359  \n",
      "\n",
      "Fold: 32  Epoch: 332  Training loss = 2.3249  Validation loss = 2.6358  \n",
      "\n",
      "Fold: 32  Epoch: 333  Training loss = 2.3248  Validation loss = 2.6355  \n",
      "\n",
      "Fold: 32  Epoch: 334  Training loss = 2.3247  Validation loss = 2.6350  \n",
      "\n",
      "Fold: 32  Epoch: 335  Training loss = 2.3247  Validation loss = 2.6344  \n",
      "\n",
      "Fold: 32  Epoch: 336  Training loss = 2.3246  Validation loss = 2.6338  \n",
      "\n",
      "Fold: 32  Epoch: 337  Training loss = 2.3245  Validation loss = 2.6333  \n",
      "\n",
      "Fold: 32  Epoch: 338  Training loss = 2.3244  Validation loss = 2.6327  \n",
      "\n",
      "Fold: 32  Epoch: 339  Training loss = 2.3243  Validation loss = 2.6319  \n",
      "\n",
      "Fold: 32  Epoch: 340  Training loss = 2.3242  Validation loss = 2.6316  \n",
      "\n",
      "Fold: 32  Epoch: 341  Training loss = 2.3241  Validation loss = 2.6309  \n",
      "\n",
      "Fold: 32  Epoch: 342  Training loss = 2.3241  Validation loss = 2.6308  \n",
      "\n",
      "Fold: 32  Epoch: 343  Training loss = 2.3240  Validation loss = 2.6302  \n",
      "\n",
      "Fold: 32  Epoch: 344  Training loss = 2.3239  Validation loss = 2.6293  \n",
      "\n",
      "Fold: 32  Epoch: 345  Training loss = 2.3238  Validation loss = 2.6284  \n",
      "\n",
      "Fold: 32  Epoch: 346  Training loss = 2.3237  Validation loss = 2.6283  \n",
      "\n",
      "Fold: 32  Epoch: 347  Training loss = 2.3237  Validation loss = 2.6283  \n",
      "\n",
      "Fold: 32  Epoch: 348  Training loss = 2.3236  Validation loss = 2.6279  \n",
      "\n",
      "Fold: 32  Epoch: 349  Training loss = 2.3236  Validation loss = 2.6276  \n",
      "\n",
      "Fold: 32  Epoch: 350  Training loss = 2.3235  Validation loss = 2.6271  \n",
      "\n",
      "Fold: 32  Epoch: 351  Training loss = 2.3234  Validation loss = 2.6263  \n",
      "\n",
      "Fold: 32  Epoch: 352  Training loss = 2.3233  Validation loss = 2.6261  \n",
      "\n",
      "Fold: 32  Epoch: 353  Training loss = 2.3233  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 32  Epoch: 354  Training loss = 2.3233  Validation loss = 2.6259  \n",
      "\n",
      "Fold: 32  Epoch: 355  Training loss = 2.3232  Validation loss = 2.6260  \n",
      "\n",
      "Fold: 32  Epoch: 356  Training loss = 2.3232  Validation loss = 2.6254  \n",
      "\n",
      "Fold: 32  Epoch: 357  Training loss = 2.3231  Validation loss = 2.6250  \n",
      "\n",
      "Fold: 32  Epoch: 358  Training loss = 2.3230  Validation loss = 2.6244  \n",
      "\n",
      "Fold: 32  Epoch: 359  Training loss = 2.3229  Validation loss = 2.6240  \n",
      "\n",
      "Fold: 32  Epoch: 360  Training loss = 2.3229  Validation loss = 2.6241  \n",
      "\n",
      "Fold: 32  Epoch: 361  Training loss = 2.3229  Validation loss = 2.6237  \n",
      "\n",
      "Fold: 32  Epoch: 362  Training loss = 2.3228  Validation loss = 2.6229  \n",
      "\n",
      "Fold: 32  Epoch: 363  Training loss = 2.3227  Validation loss = 2.6228  \n",
      "\n",
      "Fold: 32  Epoch: 364  Training loss = 2.3226  Validation loss = 2.6221  \n",
      "\n",
      "Fold: 32  Epoch: 365  Training loss = 2.3225  Validation loss = 2.6218  \n",
      "\n",
      "Fold: 32  Epoch: 366  Training loss = 2.3225  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 32  Epoch: 367  Training loss = 2.3224  Validation loss = 2.6208  \n",
      "\n",
      "Fold: 32  Epoch: 368  Training loss = 2.3223  Validation loss = 2.6201  \n",
      "\n",
      "Fold: 32  Epoch: 369  Training loss = 2.3222  Validation loss = 2.6199  \n",
      "\n",
      "Fold: 32  Epoch: 370  Training loss = 2.3222  Validation loss = 2.6198  \n",
      "\n",
      "Fold: 32  Epoch: 371  Training loss = 2.3221  Validation loss = 2.6195  \n",
      "\n",
      "Fold: 32  Epoch: 372  Training loss = 2.3220  Validation loss = 2.6189  \n",
      "\n",
      "Fold: 32  Epoch: 373  Training loss = 2.3220  Validation loss = 2.6186  \n",
      "\n",
      "Fold: 32  Epoch: 374  Training loss = 2.3219  Validation loss = 2.6181  \n",
      "\n",
      "Fold: 32  Epoch: 375  Training loss = 2.3218  Validation loss = 2.6179  \n",
      "\n",
      "Fold: 32  Epoch: 376  Training loss = 2.3217  Validation loss = 2.6173  \n",
      "\n",
      "Fold: 32  Epoch: 377  Training loss = 2.3217  Validation loss = 2.6168  \n",
      "\n",
      "Fold: 32  Epoch: 378  Training loss = 2.3216  Validation loss = 2.6163  \n",
      "\n",
      "Fold: 32  Epoch: 379  Training loss = 2.3215  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 32  Epoch: 380  Training loss = 2.3214  Validation loss = 2.6151  \n",
      "\n",
      "Fold: 32  Epoch: 381  Training loss = 2.3214  Validation loss = 2.6149  \n",
      "\n",
      "Fold: 32  Epoch: 382  Training loss = 2.3213  Validation loss = 2.6145  \n",
      "\n",
      "Fold: 32  Epoch: 383  Training loss = 2.3212  Validation loss = 2.6140  \n",
      "\n",
      "Fold: 32  Epoch: 384  Training loss = 2.3211  Validation loss = 2.6134  \n",
      "\n",
      "Fold: 32  Epoch: 385  Training loss = 2.3211  Validation loss = 2.6135  \n",
      "\n",
      "Fold: 32  Epoch: 386  Training loss = 2.3211  Validation loss = 2.6138  \n",
      "\n",
      "Fold: 32  Epoch: 387  Training loss = 2.3211  Validation loss = 2.6132  \n",
      "\n",
      "Fold: 32  Epoch: 388  Training loss = 2.3210  Validation loss = 2.6126  \n",
      "\n",
      "Fold: 32  Epoch: 389  Training loss = 2.3209  Validation loss = 2.6124  \n",
      "\n",
      "Fold: 32  Epoch: 390  Training loss = 2.3209  Validation loss = 2.6124  \n",
      "\n",
      "Fold: 32  Epoch: 391  Training loss = 2.3208  Validation loss = 2.6116  \n",
      "\n",
      "Fold: 32  Epoch: 392  Training loss = 2.3207  Validation loss = 2.6112  \n",
      "\n",
      "Fold: 32  Epoch: 393  Training loss = 2.3208  Validation loss = 2.6119  \n",
      "\n",
      "Fold: 32  Epoch: 394  Training loss = 2.3207  Validation loss = 2.6108  \n",
      "\n",
      "Fold: 32  Epoch: 395  Training loss = 2.3207  Validation loss = 2.6105  \n",
      "\n",
      "Fold: 32  Epoch: 396  Training loss = 2.3206  Validation loss = 2.6101  \n",
      "\n",
      "Fold: 32  Epoch: 397  Training loss = 2.3205  Validation loss = 2.6096  \n",
      "\n",
      "Fold: 32  Epoch: 398  Training loss = 2.3204  Validation loss = 2.6090  \n",
      "\n",
      "Fold: 32  Epoch: 399  Training loss = 2.3203  Validation loss = 2.6083  \n",
      "\n",
      "Fold: 32  Epoch: 400  Training loss = 2.3203  Validation loss = 2.6083  \n",
      "\n",
      "Fold: 32  Epoch: 401  Training loss = 2.3202  Validation loss = 2.6076  \n",
      "\n",
      "Fold: 32  Epoch: 402  Training loss = 2.3201  Validation loss = 2.6068  \n",
      "\n",
      "Fold: 32  Epoch: 403  Training loss = 2.3200  Validation loss = 2.6062  \n",
      "\n",
      "Fold: 32  Epoch: 404  Training loss = 2.3200  Validation loss = 2.6059  \n",
      "\n",
      "Fold: 32  Epoch: 405  Training loss = 2.3198  Validation loss = 2.6048  \n",
      "\n",
      "Fold: 32  Epoch: 406  Training loss = 2.3197  Validation loss = 2.6039  \n",
      "\n",
      "Fold: 32  Epoch: 407  Training loss = 2.3196  Validation loss = 2.6034  \n",
      "\n",
      "Fold: 32  Epoch: 408  Training loss = 2.3195  Validation loss = 2.6027  \n",
      "\n",
      "Fold: 32  Epoch: 409  Training loss = 2.3195  Validation loss = 2.6027  \n",
      "\n",
      "Fold: 32  Epoch: 410  Training loss = 2.3195  Validation loss = 2.6028  \n",
      "\n",
      "Fold: 32  Epoch: 411  Training loss = 2.3194  Validation loss = 2.6022  \n",
      "\n",
      "Fold: 32  Epoch: 412  Training loss = 2.3194  Validation loss = 2.6020  \n",
      "\n",
      "Fold: 32  Epoch: 413  Training loss = 2.3193  Validation loss = 2.6015  \n",
      "\n",
      "Fold: 32  Epoch: 414  Training loss = 2.3193  Validation loss = 2.6011  \n",
      "\n",
      "Fold: 32  Epoch: 415  Training loss = 2.3193  Validation loss = 2.6014  \n",
      "\n",
      "Fold: 32  Epoch: 416  Training loss = 2.3192  Validation loss = 2.6008  \n",
      "\n",
      "Fold: 32  Epoch: 417  Training loss = 2.3192  Validation loss = 2.6007  \n",
      "\n",
      "Fold: 32  Epoch: 418  Training loss = 2.3192  Validation loss = 2.6009  \n",
      "\n",
      "Fold: 32  Epoch: 419  Training loss = 2.3191  Validation loss = 2.6005  \n",
      "\n",
      "Fold: 32  Epoch: 420  Training loss = 2.3191  Validation loss = 2.6007  \n",
      "\n",
      "Fold: 32  Epoch: 421  Training loss = 2.3191  Validation loss = 2.6002  \n",
      "\n",
      "Fold: 32  Epoch: 422  Training loss = 2.3192  Validation loss = 2.6010  \n",
      "\n",
      "Fold: 32  Epoch: 423  Training loss = 2.3190  Validation loss = 2.6003  \n",
      "\n",
      "Fold: 32  Epoch: 424  Training loss = 2.3190  Validation loss = 2.5999  \n",
      "\n",
      "Fold: 32  Epoch: 425  Training loss = 2.3189  Validation loss = 2.5994  \n",
      "\n",
      "Fold: 32  Epoch: 426  Training loss = 2.3188  Validation loss = 2.5989  \n",
      "\n",
      "Fold: 32  Epoch: 427  Training loss = 2.3188  Validation loss = 2.5988  \n",
      "\n",
      "Fold: 32  Epoch: 428  Training loss = 2.3188  Validation loss = 2.5985  \n",
      "\n",
      "Fold: 32  Epoch: 429  Training loss = 2.3187  Validation loss = 2.5984  \n",
      "\n",
      "Fold: 32  Epoch: 430  Training loss = 2.3187  Validation loss = 2.5981  \n",
      "\n",
      "Fold: 32  Epoch: 431  Training loss = 2.3187  Validation loss = 2.5983  \n",
      "\n",
      "Fold: 32  Epoch: 432  Training loss = 2.3186  Validation loss = 2.5980  \n",
      "\n",
      "Fold: 32  Epoch: 433  Training loss = 2.3186  Validation loss = 2.5980  \n",
      "\n",
      "Fold: 32  Epoch: 434  Training loss = 2.3185  Validation loss = 2.5977  \n",
      "\n",
      "Fold: 32  Epoch: 435  Training loss = 2.3185  Validation loss = 2.5978  \n",
      "\n",
      "Fold: 32  Epoch: 436  Training loss = 2.3185  Validation loss = 2.5975  \n",
      "\n",
      "Fold: 32  Epoch: 437  Training loss = 2.3185  Validation loss = 2.5977  \n",
      "\n",
      "Fold: 32  Epoch: 438  Training loss = 2.3184  Validation loss = 2.5974  \n",
      "\n",
      "Fold: 32  Epoch: 439  Training loss = 2.3183  Validation loss = 2.5966  \n",
      "\n",
      "Fold: 32  Epoch: 440  Training loss = 2.3182  Validation loss = 2.5960  \n",
      "\n",
      "Fold: 32  Epoch: 441  Training loss = 2.3182  Validation loss = 2.5957  \n",
      "\n",
      "Fold: 32  Epoch: 442  Training loss = 2.3181  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 32  Epoch: 443  Training loss = 2.3181  Validation loss = 2.5957  \n",
      "\n",
      "Fold: 32  Epoch: 444  Training loss = 2.3181  Validation loss = 2.5953  \n",
      "\n",
      "Fold: 32  Epoch: 445  Training loss = 2.3180  Validation loss = 2.5948  \n",
      "\n",
      "Fold: 32  Epoch: 446  Training loss = 2.3179  Validation loss = 2.5942  \n",
      "\n",
      "Fold: 32  Epoch: 447  Training loss = 2.3178  Validation loss = 2.5938  \n",
      "\n",
      "Fold: 32  Epoch: 448  Training loss = 2.3178  Validation loss = 2.5934  \n",
      "\n",
      "Fold: 32  Epoch: 449  Training loss = 2.3177  Validation loss = 2.5930  \n",
      "\n",
      "Fold: 32  Epoch: 450  Training loss = 2.3177  Validation loss = 2.5928  \n",
      "\n",
      "Fold: 32  Epoch: 451  Training loss = 2.3176  Validation loss = 2.5925  \n",
      "\n",
      "Fold: 32  Epoch: 452  Training loss = 2.3175  Validation loss = 2.5921  \n",
      "\n",
      "Fold: 32  Epoch: 453  Training loss = 2.3176  Validation loss = 2.5923  \n",
      "\n",
      "Fold: 32  Epoch: 454  Training loss = 2.3175  Validation loss = 2.5918  \n",
      "\n",
      "Fold: 32  Epoch: 455  Training loss = 2.3174  Validation loss = 2.5910  \n",
      "\n",
      "Fold: 32  Epoch: 456  Training loss = 2.3173  Validation loss = 2.5907  \n",
      "\n",
      "Fold: 32  Epoch: 457  Training loss = 2.3173  Validation loss = 2.5905  \n",
      "\n",
      "Fold: 32  Epoch: 458  Training loss = 2.3172  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 32  Epoch: 459  Training loss = 2.3172  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 32  Epoch: 460  Training loss = 2.3172  Validation loss = 2.5900  \n",
      "\n",
      "Fold: 32  Epoch: 461  Training loss = 2.3171  Validation loss = 2.5898  \n",
      "\n",
      "Fold: 32  Epoch: 462  Training loss = 2.3171  Validation loss = 2.5899  \n",
      "\n",
      "Fold: 32  Epoch: 463  Training loss = 2.3172  Validation loss = 2.5905  \n",
      "\n",
      "Fold: 32  Epoch: 464  Training loss = 2.3171  Validation loss = 2.5898  \n",
      "\n",
      "Fold: 32  Epoch: 465  Training loss = 2.3170  Validation loss = 2.5894  \n",
      "\n",
      "Fold: 32  Epoch: 466  Training loss = 2.3169  Validation loss = 2.5887  \n",
      "\n",
      "Fold: 32  Epoch: 467  Training loss = 2.3169  Validation loss = 2.5885  \n",
      "\n",
      "Fold: 32  Epoch: 468  Training loss = 2.3168  Validation loss = 2.5881  \n",
      "\n",
      "Fold: 32  Epoch: 469  Training loss = 2.3167  Validation loss = 2.5876  \n",
      "\n",
      "Fold: 32  Epoch: 470  Training loss = 2.3168  Validation loss = 2.5881  \n",
      "\n",
      "Fold: 32  Epoch: 471  Training loss = 2.3167  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 32  Epoch: 472  Training loss = 2.3167  Validation loss = 2.5879  \n",
      "\n",
      "Fold: 32  Epoch: 473  Training loss = 2.3167  Validation loss = 2.5876  \n",
      "\n",
      "Fold: 32  Epoch: 474  Training loss = 2.3166  Validation loss = 2.5873  \n",
      "\n",
      "Fold: 32  Epoch: 475  Training loss = 2.3165  Validation loss = 2.5868  \n",
      "\n",
      "Fold: 32  Epoch: 476  Training loss = 2.3165  Validation loss = 2.5863  \n",
      "\n",
      "Fold: 32  Epoch: 477  Training loss = 2.3165  Validation loss = 2.5863  \n",
      "\n",
      "Fold: 32  Epoch: 478  Training loss = 2.3164  Validation loss = 2.5859  \n",
      "\n",
      "Fold: 32  Epoch: 479  Training loss = 2.3163  Validation loss = 2.5855  \n",
      "\n",
      "Fold: 32  Epoch: 480  Training loss = 2.3162  Validation loss = 2.5849  \n",
      "\n",
      "Fold: 32  Epoch: 481  Training loss = 2.3162  Validation loss = 2.5844  \n",
      "\n",
      "Fold: 32  Epoch: 482  Training loss = 2.3161  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 32  Epoch: 483  Training loss = 2.3161  Validation loss = 2.5839  \n",
      "\n",
      "Fold: 32  Epoch: 484  Training loss = 2.3161  Validation loss = 2.5836  \n",
      "\n",
      "Fold: 32  Epoch: 485  Training loss = 2.3160  Validation loss = 2.5834  \n",
      "\n",
      "Fold: 32  Epoch: 486  Training loss = 2.3159  Validation loss = 2.5830  \n",
      "\n",
      "Fold: 32  Epoch: 487  Training loss = 2.3159  Validation loss = 2.5827  \n",
      "\n",
      "Fold: 32  Epoch: 488  Training loss = 2.3159  Validation loss = 2.5826  \n",
      "\n",
      "Fold: 32  Epoch: 489  Training loss = 2.3158  Validation loss = 2.5821  \n",
      "\n",
      "Fold: 32  Epoch: 490  Training loss = 2.3157  Validation loss = 2.5817  \n",
      "\n",
      "Fold: 32  Epoch: 491  Training loss = 2.3157  Validation loss = 2.5811  \n",
      "\n",
      "Fold: 32  Epoch: 492  Training loss = 2.3156  Validation loss = 2.5811  \n",
      "\n",
      "Fold: 32  Epoch: 493  Training loss = 2.3156  Validation loss = 2.5808  \n",
      "\n",
      "Fold: 32  Epoch: 494  Training loss = 2.3156  Validation loss = 2.5812  \n",
      "\n",
      "Fold: 32  Epoch: 495  Training loss = 2.3155  Validation loss = 2.5804  \n",
      "\n",
      "Fold: 32  Epoch: 496  Training loss = 2.3155  Validation loss = 2.5804  \n",
      "\n",
      "Fold: 32  Epoch: 497  Training loss = 2.3154  Validation loss = 2.5797  \n",
      "\n",
      "Fold: 32  Epoch: 498  Training loss = 2.3154  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 32  Epoch: 499  Training loss = 2.3153  Validation loss = 2.5793  \n",
      "\n",
      "Fold: 32  Epoch: 500  Training loss = 2.3153  Validation loss = 2.5793  \n",
      "\n",
      "Fold: 32  Epoch: 501  Training loss = 2.3152  Validation loss = 2.5790  \n",
      "\n",
      "Fold: 32  Epoch: 502  Training loss = 2.3153  Validation loss = 2.5793  \n",
      "\n",
      "Fold: 32  Epoch: 503  Training loss = 2.3152  Validation loss = 2.5792  \n",
      "\n",
      "Fold: 32  Epoch: 504  Training loss = 2.3152  Validation loss = 2.5788  \n",
      "\n",
      "Fold: 32  Epoch: 505  Training loss = 2.3151  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 32  Epoch: 506  Training loss = 2.3151  Validation loss = 2.5785  \n",
      "\n",
      "Fold: 32  Epoch: 507  Training loss = 2.3150  Validation loss = 2.5778  \n",
      "\n",
      "Fold: 32  Epoch: 508  Training loss = 2.3150  Validation loss = 2.5780  \n",
      "\n",
      "Fold: 32  Epoch: 509  Training loss = 2.3149  Validation loss = 2.5773  \n",
      "\n",
      "Fold: 32  Epoch: 510  Training loss = 2.3148  Validation loss = 2.5767  \n",
      "\n",
      "Fold: 32  Epoch: 511  Training loss = 2.3148  Validation loss = 2.5769  \n",
      "\n",
      "Fold: 32  Epoch: 512  Training loss = 2.3147  Validation loss = 2.5765  \n",
      "\n",
      "Fold: 32  Epoch: 513  Training loss = 2.3147  Validation loss = 2.5767  \n",
      "\n",
      "Fold: 32  Epoch: 514  Training loss = 2.3147  Validation loss = 2.5767  \n",
      "\n",
      "Fold: 32  Epoch: 515  Training loss = 2.3147  Validation loss = 2.5761  \n",
      "\n",
      "Fold: 32  Epoch: 516  Training loss = 2.3147  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 32  Epoch: 517  Training loss = 2.3146  Validation loss = 2.5763  \n",
      "\n",
      "Fold: 32  Epoch: 518  Training loss = 2.3146  Validation loss = 2.5763  \n",
      "\n",
      "Fold: 32  Epoch: 519  Training loss = 2.3146  Validation loss = 2.5763  \n",
      "\n",
      "Fold: 32  Epoch: 520  Training loss = 2.3145  Validation loss = 2.5761  \n",
      "\n",
      "Fold: 32  Epoch: 521  Training loss = 2.3145  Validation loss = 2.5759  \n",
      "\n",
      "Fold: 32  Epoch: 522  Training loss = 2.3144  Validation loss = 2.5752  \n",
      "\n",
      "Fold: 32  Epoch: 523  Training loss = 2.3144  Validation loss = 2.5753  \n",
      "\n",
      "Fold: 32  Epoch: 524  Training loss = 2.3143  Validation loss = 2.5746  \n",
      "\n",
      "Fold: 32  Epoch: 525  Training loss = 2.3142  Validation loss = 2.5740  \n",
      "\n",
      "Fold: 32  Epoch: 526  Training loss = 2.3142  Validation loss = 2.5736  \n",
      "\n",
      "Fold: 32  Epoch: 527  Training loss = 2.3142  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 32  Epoch: 528  Training loss = 2.3142  Validation loss = 2.5737  \n",
      "\n",
      "Fold: 32  Epoch: 529  Training loss = 2.3141  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 32  Epoch: 530  Training loss = 2.3141  Validation loss = 2.5734  \n",
      "\n",
      "Fold: 32  Epoch: 531  Training loss = 2.3141  Validation loss = 2.5730  \n",
      "\n",
      "Fold: 32  Epoch: 532  Training loss = 2.3140  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 32  Epoch: 533  Training loss = 2.3139  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 32  Epoch: 534  Training loss = 2.3139  Validation loss = 2.5716  \n",
      "\n",
      "Fold: 32  Epoch: 535  Training loss = 2.3138  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 32  Epoch: 536  Training loss = 2.3137  Validation loss = 2.5705  \n",
      "\n",
      "Fold: 32  Epoch: 537  Training loss = 2.3137  Validation loss = 2.5707  \n",
      "\n",
      "Fold: 32  Epoch: 538  Training loss = 2.3137  Validation loss = 2.5706  \n",
      "\n",
      "Fold: 32  Epoch: 539  Training loss = 2.3137  Validation loss = 2.5704  \n",
      "\n",
      "Fold: 32  Epoch: 540  Training loss = 2.3137  Validation loss = 2.5705  \n",
      "\n",
      "Fold: 32  Epoch: 541  Training loss = 2.3136  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 32  Epoch: 542  Training loss = 2.3136  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 32  Epoch: 543  Training loss = 2.3136  Validation loss = 2.5700  \n",
      "\n",
      "Fold: 32  Epoch: 544  Training loss = 2.3135  Validation loss = 2.5697  \n",
      "\n",
      "Fold: 32  Epoch: 545  Training loss = 2.3135  Validation loss = 2.5695  \n",
      "\n",
      "Fold: 32  Epoch: 546  Training loss = 2.3134  Validation loss = 2.5691  \n",
      "\n",
      "Fold: 32  Epoch: 547  Training loss = 2.3134  Validation loss = 2.5684  \n",
      "\n",
      "Fold: 32  Epoch: 548  Training loss = 2.3133  Validation loss = 2.5680  \n",
      "\n",
      "Fold: 32  Epoch: 549  Training loss = 2.3133  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 32  Epoch: 550  Training loss = 2.3132  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 32  Epoch: 551  Training loss = 2.3133  Validation loss = 2.5681  \n",
      "\n",
      "Fold: 32  Epoch: 552  Training loss = 2.3132  Validation loss = 2.5680  \n",
      "\n",
      "Fold: 32  Epoch: 553  Training loss = 2.3132  Validation loss = 2.5680  \n",
      "\n",
      "Fold: 32  Epoch: 554  Training loss = 2.3133  Validation loss = 2.5686  \n",
      "\n",
      "Fold: 32  Epoch: 555  Training loss = 2.3132  Validation loss = 2.5680  \n",
      "\n",
      "Fold: 32  Epoch: 556  Training loss = 2.3131  Validation loss = 2.5677  \n",
      "\n",
      "Fold: 32  Epoch: 557  Training loss = 2.3131  Validation loss = 2.5677  \n",
      "\n",
      "Fold: 32  Epoch: 558  Training loss = 2.3131  Validation loss = 2.5676  \n",
      "\n",
      "Fold: 32  Epoch: 559  Training loss = 2.3131  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 32  Epoch: 560  Training loss = 2.3130  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 32  Epoch: 561  Training loss = 2.3129  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 32  Epoch: 562  Training loss = 2.3129  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 32  Epoch: 563  Training loss = 2.3129  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 32  Epoch: 564  Training loss = 2.3128  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 32  Epoch: 565  Training loss = 2.3128  Validation loss = 2.5664  \n",
      "\n",
      "Fold: 32  Epoch: 566  Training loss = 2.3128  Validation loss = 2.5665  \n",
      "\n",
      "Fold: 32  Epoch: 567  Training loss = 2.3127  Validation loss = 2.5660  \n",
      "\n",
      "Fold: 32  Epoch: 568  Training loss = 2.3127  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 32  Epoch: 569  Training loss = 2.3127  Validation loss = 2.5657  \n",
      "\n",
      "Fold: 32  Epoch: 570  Training loss = 2.3126  Validation loss = 2.5654  \n",
      "\n",
      "Fold: 32  Epoch: 571  Training loss = 2.3126  Validation loss = 2.5651  \n",
      "\n",
      "Fold: 32  Epoch: 572  Training loss = 2.3125  Validation loss = 2.5649  \n",
      "\n",
      "Fold: 32  Epoch: 573  Training loss = 2.3125  Validation loss = 2.5647  \n",
      "\n",
      "Fold: 32  Epoch: 574  Training loss = 2.3126  Validation loss = 2.5655  \n",
      "\n",
      "Fold: 32  Epoch: 575  Training loss = 2.3125  Validation loss = 2.5651  \n",
      "\n",
      "Fold: 32  Epoch: 576  Training loss = 2.3125  Validation loss = 2.5647  \n",
      "\n",
      "Fold: 32  Epoch: 577  Training loss = 2.3124  Validation loss = 2.5645  \n",
      "\n",
      "Fold: 32  Epoch: 578  Training loss = 2.3124  Validation loss = 2.5640  \n",
      "\n",
      "Fold: 32  Epoch: 579  Training loss = 2.3123  Validation loss = 2.5636  \n",
      "\n",
      "Fold: 32  Epoch: 580  Training loss = 2.3122  Validation loss = 2.5630  \n",
      "\n",
      "Fold: 32  Epoch: 581  Training loss = 2.3122  Validation loss = 2.5630  \n",
      "\n",
      "Fold: 32  Epoch: 582  Training loss = 2.3122  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 32  Epoch: 583  Training loss = 2.3121  Validation loss = 2.5623  \n",
      "\n",
      "Fold: 32  Epoch: 584  Training loss = 2.3121  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 32  Epoch: 585  Training loss = 2.3120  Validation loss = 2.5615  \n",
      "\n",
      "Fold: 32  Epoch: 586  Training loss = 2.3119  Validation loss = 2.5606  \n",
      "\n",
      "Fold: 32  Epoch: 587  Training loss = 2.3119  Validation loss = 2.5606  \n",
      "\n",
      "Fold: 32  Epoch: 588  Training loss = 2.3118  Validation loss = 2.5599  \n",
      "\n",
      "Fold: 32  Epoch: 589  Training loss = 2.3118  Validation loss = 2.5595  \n",
      "\n",
      "Fold: 32  Epoch: 590  Training loss = 2.3117  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 32  Epoch: 591  Training loss = 2.3117  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 32  Epoch: 592  Training loss = 2.3116  Validation loss = 2.5583  \n",
      "\n",
      "Fold: 32  Epoch: 593  Training loss = 2.3116  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 32  Epoch: 594  Training loss = 2.3116  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 32  Epoch: 595  Training loss = 2.3115  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 32  Epoch: 596  Training loss = 2.3115  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 32  Epoch: 597  Training loss = 2.3115  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 32  Epoch: 598  Training loss = 2.3115  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 32  Epoch: 599  Training loss = 2.3114  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 32  Epoch: 600  Training loss = 2.3114  Validation loss = 2.5568  \n",
      "\n",
      "Fold: 32  Epoch: 601  Training loss = 2.3113  Validation loss = 2.5564  \n",
      "\n",
      "Fold: 32  Epoch: 602  Training loss = 2.3112  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 32  Epoch: 603  Training loss = 2.3112  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 32  Epoch: 604  Training loss = 2.3111  Validation loss = 2.5548  \n",
      "\n",
      "Fold: 32  Epoch: 605  Training loss = 2.3111  Validation loss = 2.5541  \n",
      "\n",
      "Fold: 32  Epoch: 606  Training loss = 2.3110  Validation loss = 2.5535  \n",
      "\n",
      "Fold: 32  Epoch: 607  Training loss = 2.3110  Validation loss = 2.5535  \n",
      "\n",
      "Fold: 32  Epoch: 608  Training loss = 2.3109  Validation loss = 2.5532  \n",
      "\n",
      "Fold: 32  Epoch: 609  Training loss = 2.3109  Validation loss = 2.5529  \n",
      "\n",
      "Fold: 32  Epoch: 610  Training loss = 2.3108  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 32  Epoch: 611  Training loss = 2.3108  Validation loss = 2.5524  \n",
      "\n",
      "Fold: 32  Epoch: 612  Training loss = 2.3108  Validation loss = 2.5522  \n",
      "\n",
      "Fold: 32  Epoch: 613  Training loss = 2.3108  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 32  Epoch: 614  Training loss = 2.3107  Validation loss = 2.5519  \n",
      "\n",
      "Fold: 32  Epoch: 615  Training loss = 2.3106  Validation loss = 2.5515  \n",
      "\n",
      "Fold: 32  Epoch: 616  Training loss = 2.3106  Validation loss = 2.5511  \n",
      "\n",
      "Fold: 32  Epoch: 617  Training loss = 2.3105  Validation loss = 2.5508  \n",
      "\n",
      "Fold: 32  Epoch: 618  Training loss = 2.3105  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 32  Epoch: 619  Training loss = 2.3105  Validation loss = 2.5506  \n",
      "\n",
      "Fold: 32  Epoch: 620  Training loss = 2.3105  Validation loss = 2.5504  \n",
      "\n",
      "Fold: 32  Epoch: 621  Training loss = 2.3104  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 32  Epoch: 622  Training loss = 2.3104  Validation loss = 2.5496  \n",
      "\n",
      "Fold: 32  Epoch: 623  Training loss = 2.3103  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 32  Epoch: 624  Training loss = 2.3102  Validation loss = 2.5485  \n",
      "\n",
      "Fold: 32  Epoch: 625  Training loss = 2.3102  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 32  Epoch: 626  Training loss = 2.3102  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 32  Epoch: 627  Training loss = 2.3101  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 32  Epoch: 628  Training loss = 2.3101  Validation loss = 2.5469  \n",
      "\n",
      "Fold: 32  Epoch: 629  Training loss = 2.3100  Validation loss = 2.5464  \n",
      "\n",
      "Fold: 32  Epoch: 630  Training loss = 2.3099  Validation loss = 2.5462  \n",
      "\n",
      "Fold: 32  Epoch: 631  Training loss = 2.3099  Validation loss = 2.5462  \n",
      "\n",
      "Fold: 32  Epoch: 632  Training loss = 2.3099  Validation loss = 2.5460  \n",
      "\n",
      "Fold: 32  Epoch: 633  Training loss = 2.3098  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 32  Epoch: 634  Training loss = 2.3098  Validation loss = 2.5453  \n",
      "\n",
      "Fold: 32  Epoch: 635  Training loss = 2.3098  Validation loss = 2.5454  \n",
      "\n",
      "Fold: 32  Epoch: 636  Training loss = 2.3097  Validation loss = 2.5452  \n",
      "\n",
      "Fold: 32  Epoch: 637  Training loss = 2.3097  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 32  Epoch: 638  Training loss = 2.3096  Validation loss = 2.5443  \n",
      "\n",
      "Fold: 32  Epoch: 639  Training loss = 2.3096  Validation loss = 2.5442  \n",
      "\n",
      "Fold: 32  Epoch: 640  Training loss = 2.3096  Validation loss = 2.5444  \n",
      "\n",
      "Fold: 32  Epoch: 641  Training loss = 2.3096  Validation loss = 2.5442  \n",
      "\n",
      "Fold: 32  Epoch: 642  Training loss = 2.3096  Validation loss = 2.5442  \n",
      "\n",
      "Fold: 32  Epoch: 643  Training loss = 2.3095  Validation loss = 2.5438  \n",
      "\n",
      "Fold: 32  Epoch: 644  Training loss = 2.3095  Validation loss = 2.5436  \n",
      "\n",
      "Fold: 32  Epoch: 645  Training loss = 2.3094  Validation loss = 2.5432  \n",
      "\n",
      "Fold: 32  Epoch: 646  Training loss = 2.3094  Validation loss = 2.5427  \n",
      "\n",
      "Fold: 32  Epoch: 647  Training loss = 2.3093  Validation loss = 2.5426  \n",
      "\n",
      "Fold: 32  Epoch: 648  Training loss = 2.3093  Validation loss = 2.5426  \n",
      "\n",
      "Fold: 32  Epoch: 649  Training loss = 2.3093  Validation loss = 2.5426  \n",
      "\n",
      "Fold: 32  Epoch: 650  Training loss = 2.3093  Validation loss = 2.5429  \n",
      "\n",
      "Fold: 32  Epoch: 651  Training loss = 2.3092  Validation loss = 2.5424  \n",
      "\n",
      "Fold: 32  Epoch: 652  Training loss = 2.3092  Validation loss = 2.5422  \n",
      "\n",
      "Fold: 32  Epoch: 653  Training loss = 2.3092  Validation loss = 2.5419  \n",
      "\n",
      "Fold: 32  Epoch: 654  Training loss = 2.3092  Validation loss = 2.5420  \n",
      "\n",
      "Fold: 32  Epoch: 655  Training loss = 2.3091  Validation loss = 2.5416  \n",
      "\n",
      "Fold: 32  Epoch: 656  Training loss = 2.3090  Validation loss = 2.5413  \n",
      "\n",
      "Fold: 32  Epoch: 657  Training loss = 2.3090  Validation loss = 2.5412  \n",
      "\n",
      "Fold: 32  Epoch: 658  Training loss = 2.3089  Validation loss = 2.5408  \n",
      "\n",
      "Fold: 32  Epoch: 659  Training loss = 2.3090  Validation loss = 2.5410  \n",
      "\n",
      "Fold: 32  Epoch: 660  Training loss = 2.3089  Validation loss = 2.5407  \n",
      "\n",
      "Fold: 32  Epoch: 661  Training loss = 2.3089  Validation loss = 2.5403  \n",
      "\n",
      "Fold: 32  Epoch: 662  Training loss = 2.3088  Validation loss = 2.5400  \n",
      "\n",
      "Fold: 32  Epoch: 663  Training loss = 2.3088  Validation loss = 2.5397  \n",
      "\n",
      "Fold: 32  Epoch: 664  Training loss = 2.3088  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 32  Epoch: 665  Training loss = 2.3087  Validation loss = 2.5395  \n",
      "\n",
      "Fold: 32  Epoch: 666  Training loss = 2.3087  Validation loss = 2.5394  \n",
      "\n",
      "Fold: 32  Epoch: 667  Training loss = 2.3086  Validation loss = 2.5389  \n",
      "\n",
      "Fold: 32  Epoch: 668  Training loss = 2.3086  Validation loss = 2.5388  \n",
      "\n",
      "Fold: 32  Epoch: 669  Training loss = 2.3086  Validation loss = 2.5386  \n",
      "\n",
      "Fold: 32  Epoch: 670  Training loss = 2.3085  Validation loss = 2.5383  \n",
      "\n",
      "Fold: 32  Epoch: 671  Training loss = 2.3085  Validation loss = 2.5379  \n",
      "\n",
      "Fold: 32  Epoch: 672  Training loss = 2.3085  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 32  Epoch: 673  Training loss = 2.3084  Validation loss = 2.5375  \n",
      "\n",
      "Fold: 32  Epoch: 674  Training loss = 2.3084  Validation loss = 2.5372  \n",
      "\n",
      "Fold: 32  Epoch: 675  Training loss = 2.3084  Validation loss = 2.5372  \n",
      "\n",
      "Fold: 32  Epoch: 676  Training loss = 2.3083  Validation loss = 2.5368  \n",
      "\n",
      "Fold: 32  Epoch: 677  Training loss = 2.3083  Validation loss = 2.5370  \n",
      "\n",
      "Fold: 32  Epoch: 678  Training loss = 2.3083  Validation loss = 2.5371  \n",
      "\n",
      "Fold: 32  Epoch: 679  Training loss = 2.3083  Validation loss = 2.5373  \n",
      "\n",
      "Fold: 32  Epoch: 680  Training loss = 2.3083  Validation loss = 2.5374  \n",
      "\n",
      "Fold: 32  Epoch: 681  Training loss = 2.3082  Validation loss = 2.5370  \n",
      "\n",
      "Fold: 32  Epoch: 682  Training loss = 2.3082  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 32  Epoch: 683  Training loss = 2.3081  Validation loss = 2.5364  \n",
      "\n",
      "Fold: 32  Epoch: 684  Training loss = 2.3081  Validation loss = 2.5360  \n",
      "\n",
      "Fold: 32  Epoch: 685  Training loss = 2.3081  Validation loss = 2.5359  \n",
      "\n",
      "Fold: 32  Epoch: 686  Training loss = 2.3080  Validation loss = 2.5359  \n",
      "\n",
      "Fold: 32  Epoch: 687  Training loss = 2.3080  Validation loss = 2.5352  \n",
      "\n",
      "Fold: 32  Epoch: 688  Training loss = 2.3079  Validation loss = 2.5346  \n",
      "\n",
      "Fold: 32  Epoch: 689  Training loss = 2.3078  Validation loss = 2.5341  \n",
      "\n",
      "Fold: 32  Epoch: 690  Training loss = 2.3078  Validation loss = 2.5338  \n",
      "\n",
      "Fold: 32  Epoch: 691  Training loss = 2.3078  Validation loss = 2.5343  \n",
      "\n",
      "Fold: 32  Epoch: 692  Training loss = 2.3077  Validation loss = 2.5336  \n",
      "\n",
      "Fold: 32  Epoch: 693  Training loss = 2.3077  Validation loss = 2.5332  \n",
      "\n",
      "Fold: 32  Epoch: 694  Training loss = 2.3076  Validation loss = 2.5327  \n",
      "\n",
      "Fold: 32  Epoch: 695  Training loss = 2.3076  Validation loss = 2.5329  \n",
      "\n",
      "Fold: 32  Epoch: 696  Training loss = 2.3076  Validation loss = 2.5327  \n",
      "\n",
      "Fold: 32  Epoch: 697  Training loss = 2.3076  Validation loss = 2.5327  \n",
      "\n",
      "Fold: 32  Epoch: 698  Training loss = 2.3076  Validation loss = 2.5328  \n",
      "\n",
      "Fold: 32  Epoch: 699  Training loss = 2.3075  Validation loss = 2.5323  \n",
      "\n",
      "Fold: 32  Epoch: 700  Training loss = 2.3075  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 32  Epoch: 701  Training loss = 2.3075  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 32  Epoch: 702  Training loss = 2.3075  Validation loss = 2.5323  \n",
      "\n",
      "Fold: 32  Epoch: 703  Training loss = 2.3074  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 32  Epoch: 704  Training loss = 2.3074  Validation loss = 2.5315  \n",
      "\n",
      "Fold: 32  Epoch: 705  Training loss = 2.3073  Validation loss = 2.5312  \n",
      "\n",
      "Fold: 32  Epoch: 706  Training loss = 2.3073  Validation loss = 2.5309  \n",
      "\n",
      "Fold: 32  Epoch: 707  Training loss = 2.3072  Validation loss = 2.5304  \n",
      "\n",
      "Fold: 32  Epoch: 708  Training loss = 2.3072  Validation loss = 2.5306  \n",
      "\n",
      "Fold: 32  Epoch: 709  Training loss = 2.3072  Validation loss = 2.5303  \n",
      "\n",
      "Fold: 32  Epoch: 710  Training loss = 2.3072  Validation loss = 2.5306  \n",
      "\n",
      "Fold: 32  Epoch: 711  Training loss = 2.3072  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 32  Epoch: 712  Training loss = 2.3072  Validation loss = 2.5308  \n",
      "\n",
      "Fold: 32  Epoch: 713  Training loss = 2.3071  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 32  Epoch: 714  Training loss = 2.3071  Validation loss = 2.5308  \n",
      "\n",
      "Fold: 32  Epoch: 715  Training loss = 2.3071  Validation loss = 2.5301  \n",
      "\n",
      "Fold: 32  Epoch: 716  Training loss = 2.3070  Validation loss = 2.5297  \n",
      "\n",
      "Fold: 32  Epoch: 717  Training loss = 2.3069  Validation loss = 2.5291  \n",
      "\n",
      "Fold: 32  Epoch: 718  Training loss = 2.3069  Validation loss = 2.5287  \n",
      "\n",
      "Fold: 32  Epoch: 719  Training loss = 2.3068  Validation loss = 2.5281  \n",
      "\n",
      "Fold: 32  Epoch: 720  Training loss = 2.3068  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 32  Epoch: 721  Training loss = 2.3067  Validation loss = 2.5274  \n",
      "\n",
      "Fold: 32  Epoch: 722  Training loss = 2.3067  Validation loss = 2.5272  \n",
      "\n",
      "Fold: 32  Epoch: 723  Training loss = 2.3066  Validation loss = 2.5270  \n",
      "\n",
      "Fold: 32  Epoch: 724  Training loss = 2.3066  Validation loss = 2.5268  \n",
      "\n",
      "Fold: 32  Epoch: 725  Training loss = 2.3066  Validation loss = 2.5264  \n",
      "\n",
      "Fold: 32  Epoch: 726  Training loss = 2.3066  Validation loss = 2.5263  \n",
      "\n",
      "Fold: 32  Epoch: 727  Training loss = 2.3066  Validation loss = 2.5266  \n",
      "\n",
      "Fold: 32  Epoch: 728  Training loss = 2.3065  Validation loss = 2.5263  \n",
      "\n",
      "Fold: 32  Epoch: 729  Training loss = 2.3065  Validation loss = 2.5262  \n",
      "\n",
      "Fold: 32  Epoch: 730  Training loss = 2.3065  Validation loss = 2.5261  \n",
      "\n",
      "Fold: 32  Epoch: 731  Training loss = 2.3064  Validation loss = 2.5258  \n",
      "\n",
      "Fold: 32  Epoch: 732  Training loss = 2.3064  Validation loss = 2.5258  \n",
      "\n",
      "Fold: 32  Epoch: 733  Training loss = 2.3064  Validation loss = 2.5254  \n",
      "\n",
      "Fold: 32  Epoch: 734  Training loss = 2.3064  Validation loss = 2.5254  \n",
      "\n",
      "Fold: 32  Epoch: 735  Training loss = 2.3064  Validation loss = 2.5257  \n",
      "\n",
      "Fold: 32  Epoch: 736  Training loss = 2.3063  Validation loss = 2.5253  \n",
      "\n",
      "Fold: 32  Epoch: 737  Training loss = 2.3063  Validation loss = 2.5246  \n",
      "\n",
      "Fold: 32  Epoch: 738  Training loss = 2.3062  Validation loss = 2.5244  \n",
      "\n",
      "Fold: 32  Epoch: 739  Training loss = 2.3062  Validation loss = 2.5243  \n",
      "\n",
      "Fold: 32  Epoch: 740  Training loss = 2.3061  Validation loss = 2.5237  \n",
      "\n",
      "Fold: 32  Epoch: 741  Training loss = 2.3061  Validation loss = 2.5237  \n",
      "\n",
      "Fold: 32  Epoch: 742  Training loss = 2.3061  Validation loss = 2.5235  \n",
      "\n",
      "Fold: 32  Epoch: 743  Training loss = 2.3061  Validation loss = 2.5237  \n",
      "\n",
      "Fold: 32  Epoch: 744  Training loss = 2.3060  Validation loss = 2.5234  \n",
      "\n",
      "Fold: 32  Epoch: 745  Training loss = 2.3060  Validation loss = 2.5231  \n",
      "\n",
      "Fold: 32  Epoch: 746  Training loss = 2.3059  Validation loss = 2.5228  \n",
      "\n",
      "Fold: 32  Epoch: 747  Training loss = 2.3059  Validation loss = 2.5226  \n",
      "\n",
      "Fold: 32  Epoch: 748  Training loss = 2.3059  Validation loss = 2.5223  \n",
      "\n",
      "Fold: 32  Epoch: 749  Training loss = 2.3058  Validation loss = 2.5222  \n",
      "\n",
      "Fold: 32  Epoch: 750  Training loss = 2.3058  Validation loss = 2.5218  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 750  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 540\n",
      "Average validation error: 3.85388\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.9115  Test loss = 2.7075  \n",
      "\n",
      "Epoch: 2  Training loss = 1.9115  Test loss = 2.7075  \n",
      "\n",
      "Epoch: 3  Training loss = 1.9115  Test loss = 2.7075  \n",
      "\n",
      "Epoch: 4  Training loss = 1.9115  Test loss = 2.7075  \n",
      "\n",
      "Epoch: 5  Training loss = 1.9114  Test loss = 2.7074  \n",
      "\n",
      "Epoch: 6  Training loss = 1.9114  Test loss = 2.7074  \n",
      "\n",
      "Epoch: 7  Training loss = 1.9114  Test loss = 2.7074  \n",
      "\n",
      "Epoch: 8  Training loss = 1.9114  Test loss = 2.7074  \n",
      "\n",
      "Epoch: 9  Training loss = 1.9114  Test loss = 2.7074  \n",
      "\n",
      "Epoch: 10  Training loss = 1.9114  Test loss = 2.7073  \n",
      "\n",
      "Epoch: 11  Training loss = 1.9113  Test loss = 2.7073  \n",
      "\n",
      "Epoch: 12  Training loss = 1.9113  Test loss = 2.7073  \n",
      "\n",
      "Epoch: 13  Training loss = 1.9113  Test loss = 2.7073  \n",
      "\n",
      "Epoch: 14  Training loss = 1.9113  Test loss = 2.7072  \n",
      "\n",
      "Epoch: 15  Training loss = 1.9113  Test loss = 2.7072  \n",
      "\n",
      "Epoch: 16  Training loss = 1.9112  Test loss = 2.7072  \n",
      "\n",
      "Epoch: 17  Training loss = 1.9112  Test loss = 2.7072  \n",
      "\n",
      "Epoch: 18  Training loss = 1.9112  Test loss = 2.7071  \n",
      "\n",
      "Epoch: 19  Training loss = 1.9112  Test loss = 2.7071  \n",
      "\n",
      "Epoch: 20  Training loss = 1.9112  Test loss = 2.7071  \n",
      "\n",
      "Epoch: 21  Training loss = 1.9112  Test loss = 2.7071  \n",
      "\n",
      "Epoch: 22  Training loss = 1.9111  Test loss = 2.7070  \n",
      "\n",
      "Epoch: 23  Training loss = 1.9111  Test loss = 2.7070  \n",
      "\n",
      "Epoch: 24  Training loss = 1.9111  Test loss = 2.7070  \n",
      "\n",
      "Epoch: 25  Training loss = 1.9111  Test loss = 2.7070  \n",
      "\n",
      "Epoch: 26  Training loss = 1.9111  Test loss = 2.7070  \n",
      "\n",
      "Epoch: 27  Training loss = 1.9110  Test loss = 2.7069  \n",
      "\n",
      "Epoch: 28  Training loss = 1.9110  Test loss = 2.7069  \n",
      "\n",
      "Epoch: 29  Training loss = 1.9110  Test loss = 2.7069  \n",
      "\n",
      "Epoch: 30  Training loss = 1.9110  Test loss = 2.7069  \n",
      "\n",
      "Epoch: 31  Training loss = 1.9110  Test loss = 2.7068  \n",
      "\n",
      "Epoch: 32  Training loss = 1.9110  Test loss = 2.7068  \n",
      "\n",
      "Epoch: 33  Training loss = 1.9109  Test loss = 2.7068  \n",
      "\n",
      "Epoch: 34  Training loss = 1.9109  Test loss = 2.7068  \n",
      "\n",
      "Epoch: 35  Training loss = 1.9109  Test loss = 2.7067  \n",
      "\n",
      "Epoch: 36  Training loss = 1.9109  Test loss = 2.7067  \n",
      "\n",
      "Epoch: 37  Training loss = 1.9109  Test loss = 2.7067  \n",
      "\n",
      "Epoch: 38  Training loss = 1.9108  Test loss = 2.7067  \n",
      "\n",
      "Epoch: 39  Training loss = 1.9108  Test loss = 2.7067  \n",
      "\n",
      "Epoch: 40  Training loss = 1.9108  Test loss = 2.7066  \n",
      "\n",
      "Epoch: 41  Training loss = 1.9108  Test loss = 2.7066  \n",
      "\n",
      "Epoch: 42  Training loss = 1.9108  Test loss = 2.7066  \n",
      "\n",
      "Epoch: 43  Training loss = 1.9108  Test loss = 2.7066  \n",
      "\n",
      "Epoch: 44  Training loss = 1.9107  Test loss = 2.7065  \n",
      "\n",
      "Epoch: 45  Training loss = 1.9107  Test loss = 2.7065  \n",
      "\n",
      "Epoch: 46  Training loss = 1.9107  Test loss = 2.7065  \n",
      "\n",
      "Epoch: 47  Training loss = 1.9107  Test loss = 2.7065  \n",
      "\n",
      "Epoch: 48  Training loss = 1.9107  Test loss = 2.7064  \n",
      "\n",
      "Epoch: 49  Training loss = 1.9107  Test loss = 2.7064  \n",
      "\n",
      "Epoch: 50  Training loss = 1.9106  Test loss = 2.7064  \n",
      "\n",
      "Epoch: 51  Training loss = 1.9106  Test loss = 2.7064  \n",
      "\n",
      "Epoch: 52  Training loss = 1.9106  Test loss = 2.7063  \n",
      "\n",
      "Epoch: 53  Training loss = 1.9106  Test loss = 2.7063  \n",
      "\n",
      "Epoch: 54  Training loss = 1.9106  Test loss = 2.7063  \n",
      "\n",
      "Epoch: 55  Training loss = 1.9105  Test loss = 2.7063  \n",
      "\n",
      "Epoch: 56  Training loss = 1.9105  Test loss = 2.7063  \n",
      "\n",
      "Epoch: 57  Training loss = 1.9105  Test loss = 2.7062  \n",
      "\n",
      "Epoch: 58  Training loss = 1.9105  Test loss = 2.7062  \n",
      "\n",
      "Epoch: 59  Training loss = 1.9105  Test loss = 2.7062  \n",
      "\n",
      "Epoch: 60  Training loss = 1.9105  Test loss = 2.7062  \n",
      "\n",
      "Epoch: 61  Training loss = 1.9104  Test loss = 2.7061  \n",
      "\n",
      "Epoch: 62  Training loss = 1.9104  Test loss = 2.7061  \n",
      "\n",
      "Epoch: 63  Training loss = 1.9104  Test loss = 2.7061  \n",
      "\n",
      "Epoch: 64  Training loss = 1.9104  Test loss = 2.7061  \n",
      "\n",
      "Epoch: 65  Training loss = 1.9104  Test loss = 2.7060  \n",
      "\n",
      "Epoch: 66  Training loss = 1.9103  Test loss = 2.7060  \n",
      "\n",
      "Epoch: 67  Training loss = 1.9103  Test loss = 2.7060  \n",
      "\n",
      "Epoch: 68  Training loss = 1.9103  Test loss = 2.7060  \n",
      "\n",
      "Epoch: 69  Training loss = 1.9103  Test loss = 2.7060  \n",
      "\n",
      "Epoch: 70  Training loss = 1.9103  Test loss = 2.7059  \n",
      "\n",
      "Epoch: 71  Training loss = 1.9103  Test loss = 2.7059  \n",
      "\n",
      "Epoch: 72  Training loss = 1.9102  Test loss = 2.7059  \n",
      "\n",
      "Epoch: 73  Training loss = 1.9102  Test loss = 2.7059  \n",
      "\n",
      "Epoch: 74  Training loss = 1.9102  Test loss = 2.7058  \n",
      "\n",
      "Epoch: 75  Training loss = 1.9102  Test loss = 2.7058  \n",
      "\n",
      "Epoch: 76  Training loss = 1.9102  Test loss = 2.7058  \n",
      "\n",
      "Epoch: 77  Training loss = 1.9101  Test loss = 2.7058  \n",
      "\n",
      "Epoch: 78  Training loss = 1.9101  Test loss = 2.7057  \n",
      "\n",
      "Epoch: 79  Training loss = 1.9101  Test loss = 2.7057  \n",
      "\n",
      "Epoch: 80  Training loss = 1.9101  Test loss = 2.7057  \n",
      "\n",
      "Epoch: 81  Training loss = 1.9101  Test loss = 2.7057  \n",
      "\n",
      "Epoch: 82  Training loss = 1.9101  Test loss = 2.7057  \n",
      "\n",
      "Epoch: 83  Training loss = 1.9100  Test loss = 2.7056  \n",
      "\n",
      "Epoch: 84  Training loss = 1.9100  Test loss = 2.7056  \n",
      "\n",
      "Epoch: 85  Training loss = 1.9100  Test loss = 2.7056  \n",
      "\n",
      "Epoch: 86  Training loss = 1.9100  Test loss = 2.7056  \n",
      "\n",
      "Epoch: 87  Training loss = 1.9100  Test loss = 2.7055  \n",
      "\n",
      "Epoch: 88  Training loss = 1.9100  Test loss = 2.7055  \n",
      "\n",
      "Epoch: 89  Training loss = 1.9099  Test loss = 2.7055  \n",
      "\n",
      "Epoch: 90  Training loss = 1.9099  Test loss = 2.7055  \n",
      "\n",
      "Epoch: 91  Training loss = 1.9099  Test loss = 2.7054  \n",
      "\n",
      "Epoch: 92  Training loss = 1.9099  Test loss = 2.7054  \n",
      "\n",
      "Epoch: 93  Training loss = 1.9099  Test loss = 2.7054  \n",
      "\n",
      "Epoch: 94  Training loss = 1.9098  Test loss = 2.7054  \n",
      "\n",
      "Epoch: 95  Training loss = 1.9098  Test loss = 2.7054  \n",
      "\n",
      "Epoch: 96  Training loss = 1.9098  Test loss = 2.7053  \n",
      "\n",
      "Epoch: 97  Training loss = 1.9098  Test loss = 2.7053  \n",
      "\n",
      "Epoch: 98  Training loss = 1.9098  Test loss = 2.7053  \n",
      "\n",
      "Epoch: 99  Training loss = 1.9098  Test loss = 2.7053  \n",
      "\n",
      "Epoch: 100  Training loss = 1.9097  Test loss = 2.7052  \n",
      "\n",
      "Epoch: 101  Training loss = 1.9097  Test loss = 2.7052  \n",
      "\n",
      "Epoch: 102  Training loss = 1.9097  Test loss = 2.7052  \n",
      "\n",
      "Epoch: 103  Training loss = 1.9097  Test loss = 2.7052  \n",
      "\n",
      "Epoch: 104  Training loss = 1.9097  Test loss = 2.7051  \n",
      "\n",
      "Epoch: 105  Training loss = 1.9096  Test loss = 2.7051  \n",
      "\n",
      "Epoch: 106  Training loss = 1.9096  Test loss = 2.7051  \n",
      "\n",
      "Epoch: 107  Training loss = 1.9096  Test loss = 2.7051  \n",
      "\n",
      "Epoch: 108  Training loss = 1.9096  Test loss = 2.7051  \n",
      "\n",
      "Epoch: 109  Training loss = 1.9096  Test loss = 2.7050  \n",
      "\n",
      "Epoch: 110  Training loss = 1.9096  Test loss = 2.7050  \n",
      "\n",
      "Epoch: 111  Training loss = 1.9095  Test loss = 2.7050  \n",
      "\n",
      "Epoch: 112  Training loss = 1.9095  Test loss = 2.7050  \n",
      "\n",
      "Epoch: 113  Training loss = 1.9095  Test loss = 2.7049  \n",
      "\n",
      "Epoch: 114  Training loss = 1.9095  Test loss = 2.7049  \n",
      "\n",
      "Epoch: 115  Training loss = 1.9095  Test loss = 2.7049  \n",
      "\n",
      "Epoch: 116  Training loss = 1.9095  Test loss = 2.7049  \n",
      "\n",
      "Epoch: 117  Training loss = 1.9094  Test loss = 2.7048  \n",
      "\n",
      "Epoch: 118  Training loss = 1.9094  Test loss = 2.7048  \n",
      "\n",
      "Epoch: 119  Training loss = 1.9094  Test loss = 2.7048  \n",
      "\n",
      "Epoch: 120  Training loss = 1.9094  Test loss = 2.7048  \n",
      "\n",
      "Epoch: 121  Training loss = 1.9094  Test loss = 2.7048  \n",
      "\n",
      "Epoch: 122  Training loss = 1.9093  Test loss = 2.7047  \n",
      "\n",
      "Epoch: 123  Training loss = 1.9093  Test loss = 2.7047  \n",
      "\n",
      "Epoch: 124  Training loss = 1.9093  Test loss = 2.7047  \n",
      "\n",
      "Epoch: 125  Training loss = 1.9093  Test loss = 2.7047  \n",
      "\n",
      "Epoch: 126  Training loss = 1.9093  Test loss = 2.7046  \n",
      "\n",
      "Epoch: 127  Training loss = 1.9093  Test loss = 2.7046  \n",
      "\n",
      "Epoch: 128  Training loss = 1.9092  Test loss = 2.7046  \n",
      "\n",
      "Epoch: 129  Training loss = 1.9092  Test loss = 2.7046  \n",
      "\n",
      "Epoch: 130  Training loss = 1.9092  Test loss = 2.7045  \n",
      "\n",
      "Epoch: 131  Training loss = 1.9092  Test loss = 2.7045  \n",
      "\n",
      "Epoch: 132  Training loss = 1.9092  Test loss = 2.7045  \n",
      "\n",
      "Epoch: 133  Training loss = 1.9092  Test loss = 2.7045  \n",
      "\n",
      "Epoch: 134  Training loss = 1.9091  Test loss = 2.7045  \n",
      "\n",
      "Epoch: 135  Training loss = 1.9091  Test loss = 2.7044  \n",
      "\n",
      "Epoch: 136  Training loss = 1.9091  Test loss = 2.7044  \n",
      "\n",
      "Epoch: 137  Training loss = 1.9091  Test loss = 2.7044  \n",
      "\n",
      "Epoch: 138  Training loss = 1.9091  Test loss = 2.7044  \n",
      "\n",
      "Epoch: 139  Training loss = 1.9090  Test loss = 2.7043  \n",
      "\n",
      "Epoch: 140  Training loss = 1.9090  Test loss = 2.7043  \n",
      "\n",
      "Epoch: 141  Training loss = 1.9090  Test loss = 2.7043  \n",
      "\n",
      "Epoch: 142  Training loss = 1.9090  Test loss = 2.7043  \n",
      "\n",
      "Epoch: 143  Training loss = 1.9090  Test loss = 2.7043  \n",
      "\n",
      "Epoch: 144  Training loss = 1.9090  Test loss = 2.7042  \n",
      "\n",
      "Epoch: 145  Training loss = 1.9089  Test loss = 2.7042  \n",
      "\n",
      "Epoch: 146  Training loss = 1.9089  Test loss = 2.7042  \n",
      "\n",
      "Epoch: 147  Training loss = 1.9089  Test loss = 2.7042  \n",
      "\n",
      "Epoch: 148  Training loss = 1.9089  Test loss = 2.7041  \n",
      "\n",
      "Epoch: 149  Training loss = 1.9089  Test loss = 2.7041  \n",
      "\n",
      "Epoch: 150  Training loss = 1.9088  Test loss = 2.7041  \n",
      "\n",
      "Epoch: 151  Training loss = 1.9088  Test loss = 2.7041  \n",
      "\n",
      "Epoch: 152  Training loss = 1.9088  Test loss = 2.7040  \n",
      "\n",
      "Epoch: 153  Training loss = 1.9088  Test loss = 2.7040  \n",
      "\n",
      "Epoch: 154  Training loss = 1.9088  Test loss = 2.7040  \n",
      "\n",
      "Epoch: 155  Training loss = 1.9088  Test loss = 2.7040  \n",
      "\n",
      "Epoch: 156  Training loss = 1.9087  Test loss = 2.7040  \n",
      "\n",
      "Epoch: 157  Training loss = 1.9087  Test loss = 2.7039  \n",
      "\n",
      "Epoch: 158  Training loss = 1.9087  Test loss = 2.7039  \n",
      "\n",
      "Epoch: 159  Training loss = 1.9087  Test loss = 2.7039  \n",
      "\n",
      "Epoch: 160  Training loss = 1.9087  Test loss = 2.7039  \n",
      "\n",
      "Epoch: 161  Training loss = 1.9087  Test loss = 2.7038  \n",
      "\n",
      "Epoch: 162  Training loss = 1.9086  Test loss = 2.7038  \n",
      "\n",
      "Epoch: 163  Training loss = 1.9086  Test loss = 2.7038  \n",
      "\n",
      "Epoch: 164  Training loss = 1.9086  Test loss = 2.7038  \n",
      "\n",
      "Epoch: 165  Training loss = 1.9086  Test loss = 2.7037  \n",
      "\n",
      "Epoch: 166  Training loss = 1.9086  Test loss = 2.7037  \n",
      "\n",
      "Epoch: 167  Training loss = 1.9085  Test loss = 2.7037  \n",
      "\n",
      "Epoch: 168  Training loss = 1.9085  Test loss = 2.7037  \n",
      "\n",
      "Epoch: 169  Training loss = 1.9085  Test loss = 2.7037  \n",
      "\n",
      "Epoch: 170  Training loss = 1.9085  Test loss = 2.7036  \n",
      "\n",
      "Epoch: 171  Training loss = 1.9085  Test loss = 2.7036  \n",
      "\n",
      "Epoch: 172  Training loss = 1.9085  Test loss = 2.7036  \n",
      "\n",
      "Epoch: 173  Training loss = 1.9084  Test loss = 2.7036  \n",
      "\n",
      "Epoch: 174  Training loss = 1.9084  Test loss = 2.7035  \n",
      "\n",
      "Epoch: 175  Training loss = 1.9084  Test loss = 2.7035  \n",
      "\n",
      "Epoch: 176  Training loss = 1.9084  Test loss = 2.7035  \n",
      "\n",
      "Epoch: 177  Training loss = 1.9084  Test loss = 2.7035  \n",
      "\n",
      "Epoch: 178  Training loss = 1.9084  Test loss = 2.7035  \n",
      "\n",
      "Epoch: 179  Training loss = 1.9083  Test loss = 2.7034  \n",
      "\n",
      "Epoch: 180  Training loss = 1.9083  Test loss = 2.7034  \n",
      "\n",
      "Epoch: 181  Training loss = 1.9083  Test loss = 2.7034  \n",
      "\n",
      "Epoch: 182  Training loss = 1.9083  Test loss = 2.7034  \n",
      "\n",
      "Epoch: 183  Training loss = 1.9083  Test loss = 2.7033  \n",
      "\n",
      "Epoch: 184  Training loss = 1.9082  Test loss = 2.7033  \n",
      "\n",
      "Epoch: 185  Training loss = 1.9082  Test loss = 2.7033  \n",
      "\n",
      "Epoch: 186  Training loss = 1.9082  Test loss = 2.7033  \n",
      "\n",
      "Epoch: 187  Training loss = 1.9082  Test loss = 2.7032  \n",
      "\n",
      "Epoch: 188  Training loss = 1.9082  Test loss = 2.7032  \n",
      "\n",
      "Epoch: 189  Training loss = 1.9082  Test loss = 2.7032  \n",
      "\n",
      "Epoch: 190  Training loss = 1.9081  Test loss = 2.7032  \n",
      "\n",
      "Epoch: 191  Training loss = 1.9081  Test loss = 2.7032  \n",
      "\n",
      "Epoch: 192  Training loss = 1.9081  Test loss = 2.7031  \n",
      "\n",
      "Epoch: 193  Training loss = 1.9081  Test loss = 2.7031  \n",
      "\n",
      "Epoch: 194  Training loss = 1.9081  Test loss = 2.7031  \n",
      "\n",
      "Epoch: 195  Training loss = 1.9080  Test loss = 2.7031  \n",
      "\n",
      "Epoch: 196  Training loss = 1.9080  Test loss = 2.7030  \n",
      "\n",
      "Epoch: 197  Training loss = 1.9080  Test loss = 2.7030  \n",
      "\n",
      "Epoch: 198  Training loss = 1.9080  Test loss = 2.7030  \n",
      "\n",
      "Epoch: 199  Training loss = 1.9080  Test loss = 2.7030  \n",
      "\n",
      "Epoch: 200  Training loss = 1.9080  Test loss = 2.7030  \n",
      "\n",
      "Epoch: 201  Training loss = 1.9079  Test loss = 2.7029  \n",
      "\n",
      "Epoch: 202  Training loss = 1.9079  Test loss = 2.7029  \n",
      "\n",
      "Epoch: 203  Training loss = 1.9079  Test loss = 2.7029  \n",
      "\n",
      "Epoch: 204  Training loss = 1.9079  Test loss = 2.7029  \n",
      "\n",
      "Epoch: 205  Training loss = 1.9079  Test loss = 2.7028  \n",
      "\n",
      "Epoch: 206  Training loss = 1.9079  Test loss = 2.7028  \n",
      "\n",
      "Epoch: 207  Training loss = 1.9078  Test loss = 2.7028  \n",
      "\n",
      "Epoch: 208  Training loss = 1.9078  Test loss = 2.7028  \n",
      "\n",
      "Epoch: 209  Training loss = 1.9078  Test loss = 2.7027  \n",
      "\n",
      "Epoch: 210  Training loss = 1.9078  Test loss = 2.7027  \n",
      "\n",
      "Epoch: 211  Training loss = 1.9078  Test loss = 2.7027  \n",
      "\n",
      "Epoch: 212  Training loss = 1.9077  Test loss = 2.7027  \n",
      "\n",
      "Epoch: 213  Training loss = 1.9077  Test loss = 2.7027  \n",
      "\n",
      "Epoch: 214  Training loss = 1.9077  Test loss = 2.7026  \n",
      "\n",
      "Epoch: 215  Training loss = 1.9077  Test loss = 2.7026  \n",
      "\n",
      "Epoch: 216  Training loss = 1.9077  Test loss = 2.7026  \n",
      "\n",
      "Epoch: 217  Training loss = 1.9077  Test loss = 2.7026  \n",
      "\n",
      "Epoch: 218  Training loss = 1.9076  Test loss = 2.7025  \n",
      "\n",
      "Epoch: 219  Training loss = 1.9076  Test loss = 2.7025  \n",
      "\n",
      "Epoch: 220  Training loss = 1.9076  Test loss = 2.7025  \n",
      "\n",
      "Epoch: 221  Training loss = 1.9076  Test loss = 2.7025  \n",
      "\n",
      "Epoch: 222  Training loss = 1.9076  Test loss = 2.7025  \n",
      "\n",
      "Epoch: 223  Training loss = 1.9076  Test loss = 2.7024  \n",
      "\n",
      "Epoch: 224  Training loss = 1.9075  Test loss = 2.7024  \n",
      "\n",
      "Epoch: 225  Training loss = 1.9075  Test loss = 2.7024  \n",
      "\n",
      "Epoch: 226  Training loss = 1.9075  Test loss = 2.7024  \n",
      "\n",
      "Epoch: 227  Training loss = 1.9075  Test loss = 2.7023  \n",
      "\n",
      "Epoch: 228  Training loss = 1.9075  Test loss = 2.7023  \n",
      "\n",
      "Epoch: 229  Training loss = 1.9074  Test loss = 2.7023  \n",
      "\n",
      "Epoch: 230  Training loss = 1.9074  Test loss = 2.7023  \n",
      "\n",
      "Epoch: 231  Training loss = 1.9074  Test loss = 2.7023  \n",
      "\n",
      "Epoch: 232  Training loss = 1.9074  Test loss = 2.7022  \n",
      "\n",
      "Epoch: 233  Training loss = 1.9074  Test loss = 2.7022  \n",
      "\n",
      "Epoch: 234  Training loss = 1.9074  Test loss = 2.7022  \n",
      "\n",
      "Epoch: 235  Training loss = 1.9073  Test loss = 2.7022  \n",
      "\n",
      "Epoch: 236  Training loss = 1.9073  Test loss = 2.7021  \n",
      "\n",
      "Epoch: 237  Training loss = 1.9073  Test loss = 2.7021  \n",
      "\n",
      "Epoch: 238  Training loss = 1.9073  Test loss = 2.7021  \n",
      "\n",
      "Epoch: 239  Training loss = 1.9073  Test loss = 2.7021  \n",
      "\n",
      "Epoch: 240  Training loss = 1.9073  Test loss = 2.7021  \n",
      "\n",
      "Epoch: 241  Training loss = 1.9072  Test loss = 2.7020  \n",
      "\n",
      "Epoch: 242  Training loss = 1.9072  Test loss = 2.7020  \n",
      "\n",
      "Epoch: 243  Training loss = 1.9072  Test loss = 2.7020  \n",
      "\n",
      "Epoch: 244  Training loss = 1.9072  Test loss = 2.7020  \n",
      "\n",
      "Epoch: 245  Training loss = 1.9072  Test loss = 2.7019  \n",
      "\n",
      "Epoch: 246  Training loss = 1.9071  Test loss = 2.7019  \n",
      "\n",
      "Epoch: 247  Training loss = 1.9071  Test loss = 2.7019  \n",
      "\n",
      "Epoch: 248  Training loss = 1.9071  Test loss = 2.7019  \n",
      "\n",
      "Epoch: 249  Training loss = 1.9071  Test loss = 2.7018  \n",
      "\n",
      "Epoch: 250  Training loss = 1.9071  Test loss = 2.7018  \n",
      "\n",
      "Epoch: 251  Training loss = 1.9071  Test loss = 2.7018  \n",
      "\n",
      "Epoch: 252  Training loss = 1.9070  Test loss = 2.7018  \n",
      "\n",
      "Epoch: 253  Training loss = 1.9070  Test loss = 2.7018  \n",
      "\n",
      "Epoch: 254  Training loss = 1.9070  Test loss = 2.7017  \n",
      "\n",
      "Epoch: 255  Training loss = 1.9070  Test loss = 2.7017  \n",
      "\n",
      "Epoch: 256  Training loss = 1.9070  Test loss = 2.7017  \n",
      "\n",
      "Epoch: 257  Training loss = 1.9070  Test loss = 2.7017  \n",
      "\n",
      "Epoch: 258  Training loss = 1.9069  Test loss = 2.7016  \n",
      "\n",
      "Epoch: 259  Training loss = 1.9069  Test loss = 2.7016  \n",
      "\n",
      "Epoch: 260  Training loss = 1.9069  Test loss = 2.7016  \n",
      "\n",
      "Epoch: 261  Training loss = 1.9069  Test loss = 2.7016  \n",
      "\n",
      "Epoch: 262  Training loss = 1.9069  Test loss = 2.7016  \n",
      "\n",
      "Epoch: 263  Training loss = 1.9068  Test loss = 2.7015  \n",
      "\n",
      "Epoch: 264  Training loss = 1.9068  Test loss = 2.7015  \n",
      "\n",
      "Epoch: 265  Training loss = 1.9068  Test loss = 2.7015  \n",
      "\n",
      "Epoch: 266  Training loss = 1.9068  Test loss = 2.7015  \n",
      "\n",
      "Epoch: 267  Training loss = 1.9068  Test loss = 2.7014  \n",
      "\n",
      "Epoch: 268  Training loss = 1.9068  Test loss = 2.7014  \n",
      "\n",
      "Epoch: 269  Training loss = 1.9067  Test loss = 2.7014  \n",
      "\n",
      "Epoch: 270  Training loss = 1.9067  Test loss = 2.7014  \n",
      "\n",
      "Epoch: 271  Training loss = 1.9067  Test loss = 2.7014  \n",
      "\n",
      "Epoch: 272  Training loss = 1.9067  Test loss = 2.7013  \n",
      "\n",
      "Epoch: 273  Training loss = 1.9067  Test loss = 2.7013  \n",
      "\n",
      "Epoch: 274  Training loss = 1.9067  Test loss = 2.7013  \n",
      "\n",
      "Epoch: 275  Training loss = 1.9066  Test loss = 2.7013  \n",
      "\n",
      "Epoch: 276  Training loss = 1.9066  Test loss = 2.7012  \n",
      "\n",
      "Epoch: 277  Training loss = 1.9066  Test loss = 2.7012  \n",
      "\n",
      "Epoch: 278  Training loss = 1.9066  Test loss = 2.7012  \n",
      "\n",
      "Epoch: 279  Training loss = 1.9066  Test loss = 2.7012  \n",
      "\n",
      "Epoch: 280  Training loss = 1.9066  Test loss = 2.7012  \n",
      "\n",
      "Epoch: 281  Training loss = 1.9065  Test loss = 2.7011  \n",
      "\n",
      "Epoch: 282  Training loss = 1.9065  Test loss = 2.7011  \n",
      "\n",
      "Epoch: 283  Training loss = 1.9065  Test loss = 2.7011  \n",
      "\n",
      "Epoch: 284  Training loss = 1.9065  Test loss = 2.7011  \n",
      "\n",
      "Epoch: 285  Training loss = 1.9065  Test loss = 2.7010  \n",
      "\n",
      "Epoch: 286  Training loss = 1.9064  Test loss = 2.7010  \n",
      "\n",
      "Epoch: 287  Training loss = 1.9064  Test loss = 2.7010  \n",
      "\n",
      "Epoch: 288  Training loss = 1.9064  Test loss = 2.7010  \n",
      "\n",
      "Epoch: 289  Training loss = 1.9064  Test loss = 2.7010  \n",
      "\n",
      "Epoch: 290  Training loss = 1.9064  Test loss = 2.7009  \n",
      "\n",
      "Epoch: 291  Training loss = 1.9064  Test loss = 2.7009  \n",
      "\n",
      "Epoch: 292  Training loss = 1.9063  Test loss = 2.7009  \n",
      "\n",
      "Epoch: 293  Training loss = 1.9063  Test loss = 2.7009  \n",
      "\n",
      "Epoch: 294  Training loss = 1.9063  Test loss = 2.7008  \n",
      "\n",
      "Epoch: 295  Training loss = 1.9063  Test loss = 2.7008  \n",
      "\n",
      "Epoch: 296  Training loss = 1.9063  Test loss = 2.7008  \n",
      "\n",
      "Epoch: 297  Training loss = 1.9063  Test loss = 2.7008  \n",
      "\n",
      "Epoch: 298  Training loss = 1.9062  Test loss = 2.7008  \n",
      "\n",
      "Epoch: 299  Training loss = 1.9062  Test loss = 2.7007  \n",
      "\n",
      "Epoch: 300  Training loss = 1.9062  Test loss = 2.7007  \n",
      "\n",
      "Epoch: 301  Training loss = 1.9062  Test loss = 2.7007  \n",
      "\n",
      "Epoch: 302  Training loss = 1.9062  Test loss = 2.7007  \n",
      "\n",
      "Epoch: 303  Training loss = 1.9061  Test loss = 2.7006  \n",
      "\n",
      "Epoch: 304  Training loss = 1.9061  Test loss = 2.7006  \n",
      "\n",
      "Epoch: 305  Training loss = 1.9061  Test loss = 2.7006  \n",
      "\n",
      "Epoch: 306  Training loss = 1.9061  Test loss = 2.7006  \n",
      "\n",
      "Epoch: 307  Training loss = 1.9061  Test loss = 2.7006  \n",
      "\n",
      "Epoch: 308  Training loss = 1.9061  Test loss = 2.7005  \n",
      "\n",
      "Epoch: 309  Training loss = 1.9060  Test loss = 2.7005  \n",
      "\n",
      "Epoch: 310  Training loss = 1.9060  Test loss = 2.7005  \n",
      "\n",
      "Epoch: 311  Training loss = 1.9060  Test loss = 2.7005  \n",
      "\n",
      "Epoch: 312  Training loss = 1.9060  Test loss = 2.7004  \n",
      "\n",
      "Epoch: 313  Training loss = 1.9060  Test loss = 2.7004  \n",
      "\n",
      "Epoch: 314  Training loss = 1.9060  Test loss = 2.7004  \n",
      "\n",
      "Epoch: 315  Training loss = 1.9059  Test loss = 2.7004  \n",
      "\n",
      "Epoch: 316  Training loss = 1.9059  Test loss = 2.7004  \n",
      "\n",
      "Epoch: 317  Training loss = 1.9059  Test loss = 2.7003  \n",
      "\n",
      "Epoch: 318  Training loss = 1.9059  Test loss = 2.7003  \n",
      "\n",
      "Epoch: 319  Training loss = 1.9059  Test loss = 2.7003  \n",
      "\n",
      "Epoch: 320  Training loss = 1.9058  Test loss = 2.7003  \n",
      "\n",
      "Epoch: 321  Training loss = 1.9058  Test loss = 2.7002  \n",
      "\n",
      "Epoch: 322  Training loss = 1.9058  Test loss = 2.7002  \n",
      "\n",
      "Epoch: 323  Training loss = 1.9058  Test loss = 2.7002  \n",
      "\n",
      "Epoch: 324  Training loss = 1.9058  Test loss = 2.7002  \n",
      "\n",
      "Epoch: 325  Training loss = 1.9058  Test loss = 2.7002  \n",
      "\n",
      "Epoch: 326  Training loss = 1.9057  Test loss = 2.7001  \n",
      "\n",
      "Epoch: 327  Training loss = 1.9057  Test loss = 2.7001  \n",
      "\n",
      "Epoch: 328  Training loss = 1.9057  Test loss = 2.7001  \n",
      "\n",
      "Epoch: 329  Training loss = 1.9057  Test loss = 2.7001  \n",
      "\n",
      "Epoch: 330  Training loss = 1.9057  Test loss = 2.7000  \n",
      "\n",
      "Epoch: 331  Training loss = 1.9057  Test loss = 2.7000  \n",
      "\n",
      "Epoch: 332  Training loss = 1.9056  Test loss = 2.7000  \n",
      "\n",
      "Epoch: 333  Training loss = 1.9056  Test loss = 2.7000  \n",
      "\n",
      "Epoch: 334  Training loss = 1.9056  Test loss = 2.7000  \n",
      "\n",
      "Epoch: 335  Training loss = 1.9056  Test loss = 2.6999  \n",
      "\n",
      "Epoch: 336  Training loss = 1.9056  Test loss = 2.6999  \n",
      "\n",
      "Epoch: 337  Training loss = 1.9056  Test loss = 2.6999  \n",
      "\n",
      "Epoch: 338  Training loss = 1.9055  Test loss = 2.6999  \n",
      "\n",
      "Epoch: 339  Training loss = 1.9055  Test loss = 2.6998  \n",
      "\n",
      "Epoch: 340  Training loss = 1.9055  Test loss = 2.6998  \n",
      "\n",
      "Epoch: 341  Training loss = 1.9055  Test loss = 2.6998  \n",
      "\n",
      "Epoch: 342  Training loss = 1.9055  Test loss = 2.6998  \n",
      "\n",
      "Epoch: 343  Training loss = 1.9054  Test loss = 2.6998  \n",
      "\n",
      "Epoch: 344  Training loss = 1.9054  Test loss = 2.6997  \n",
      "\n",
      "Epoch: 345  Training loss = 1.9054  Test loss = 2.6997  \n",
      "\n",
      "Epoch: 346  Training loss = 1.9054  Test loss = 2.6997  \n",
      "\n",
      "Epoch: 347  Training loss = 1.9054  Test loss = 2.6997  \n",
      "\n",
      "Epoch: 348  Training loss = 1.9054  Test loss = 2.6996  \n",
      "\n",
      "Epoch: 349  Training loss = 1.9053  Test loss = 2.6996  \n",
      "\n",
      "Epoch: 350  Training loss = 1.9053  Test loss = 2.6996  \n",
      "\n",
      "Epoch: 351  Training loss = 1.9053  Test loss = 2.6996  \n",
      "\n",
      "Epoch: 352  Training loss = 1.9053  Test loss = 2.6996  \n",
      "\n",
      "Epoch: 353  Training loss = 1.9053  Test loss = 2.6995  \n",
      "\n",
      "Epoch: 354  Training loss = 1.9053  Test loss = 2.6995  \n",
      "\n",
      "Epoch: 355  Training loss = 1.9052  Test loss = 2.6995  \n",
      "\n",
      "Epoch: 356  Training loss = 1.9052  Test loss = 2.6995  \n",
      "\n",
      "Epoch: 357  Training loss = 1.9052  Test loss = 2.6994  \n",
      "\n",
      "Epoch: 358  Training loss = 1.9052  Test loss = 2.6994  \n",
      "\n",
      "Epoch: 359  Training loss = 1.9052  Test loss = 2.6994  \n",
      "\n",
      "Epoch: 360  Training loss = 1.9052  Test loss = 2.6994  \n",
      "\n",
      "Epoch: 361  Training loss = 1.9051  Test loss = 2.6994  \n",
      "\n",
      "Epoch: 362  Training loss = 1.9051  Test loss = 2.6993  \n",
      "\n",
      "Epoch: 363  Training loss = 1.9051  Test loss = 2.6993  \n",
      "\n",
      "Epoch: 364  Training loss = 1.9051  Test loss = 2.6993  \n",
      "\n",
      "Epoch: 365  Training loss = 1.9051  Test loss = 2.6993  \n",
      "\n",
      "Epoch: 366  Training loss = 1.9050  Test loss = 2.6992  \n",
      "\n",
      "Epoch: 367  Training loss = 1.9050  Test loss = 2.6992  \n",
      "\n",
      "Epoch: 368  Training loss = 1.9050  Test loss = 2.6992  \n",
      "\n",
      "Epoch: 369  Training loss = 1.9050  Test loss = 2.6992  \n",
      "\n",
      "Epoch: 370  Training loss = 1.9050  Test loss = 2.6992  \n",
      "\n",
      "Epoch: 371  Training loss = 1.9050  Test loss = 2.6991  \n",
      "\n",
      "Epoch: 372  Training loss = 1.9049  Test loss = 2.6991  \n",
      "\n",
      "Epoch: 373  Training loss = 1.9049  Test loss = 2.6991  \n",
      "\n",
      "Epoch: 374  Training loss = 1.9049  Test loss = 2.6991  \n",
      "\n",
      "Epoch: 375  Training loss = 1.9049  Test loss = 2.6990  \n",
      "\n",
      "Epoch: 376  Training loss = 1.9049  Test loss = 2.6990  \n",
      "\n",
      "Epoch: 377  Training loss = 1.9049  Test loss = 2.6990  \n",
      "\n",
      "Epoch: 378  Training loss = 1.9048  Test loss = 2.6990  \n",
      "\n",
      "Epoch: 379  Training loss = 1.9048  Test loss = 2.6990  \n",
      "\n",
      "Epoch: 380  Training loss = 1.9048  Test loss = 2.6989  \n",
      "\n",
      "Epoch: 381  Training loss = 1.9048  Test loss = 2.6989  \n",
      "\n",
      "Epoch: 382  Training loss = 1.9048  Test loss = 2.6989  \n",
      "\n",
      "Epoch: 383  Training loss = 1.9047  Test loss = 2.6989  \n",
      "\n",
      "Epoch: 384  Training loss = 1.9047  Test loss = 2.6988  \n",
      "\n",
      "Epoch: 385  Training loss = 1.9047  Test loss = 2.6988  \n",
      "\n",
      "Epoch: 386  Training loss = 1.9047  Test loss = 2.6988  \n",
      "\n",
      "Epoch: 387  Training loss = 1.9047  Test loss = 2.6988  \n",
      "\n",
      "Epoch: 388  Training loss = 1.9047  Test loss = 2.6988  \n",
      "\n",
      "Epoch: 389  Training loss = 1.9046  Test loss = 2.6987  \n",
      "\n",
      "Epoch: 390  Training loss = 1.9046  Test loss = 2.6987  \n",
      "\n",
      "Epoch: 391  Training loss = 1.9046  Test loss = 2.6987  \n",
      "\n",
      "Epoch: 392  Training loss = 1.9046  Test loss = 2.6987  \n",
      "\n",
      "Epoch: 393  Training loss = 1.9046  Test loss = 2.6987  \n",
      "\n",
      "Epoch: 394  Training loss = 1.9046  Test loss = 2.6986  \n",
      "\n",
      "Epoch: 395  Training loss = 1.9045  Test loss = 2.6986  \n",
      "\n",
      "Epoch: 396  Training loss = 1.9045  Test loss = 2.6986  \n",
      "\n",
      "Epoch: 397  Training loss = 1.9045  Test loss = 2.6986  \n",
      "\n",
      "Epoch: 398  Training loss = 1.9045  Test loss = 2.6985  \n",
      "\n",
      "Epoch: 399  Training loss = 1.9045  Test loss = 2.6985  \n",
      "\n",
      "Epoch: 400  Training loss = 1.9045  Test loss = 2.6985  \n",
      "\n",
      "Epoch: 401  Training loss = 1.9044  Test loss = 2.6985  \n",
      "\n",
      "Epoch: 402  Training loss = 1.9044  Test loss = 2.6985  \n",
      "\n",
      "Epoch: 403  Training loss = 1.9044  Test loss = 2.6984  \n",
      "\n",
      "Epoch: 404  Training loss = 1.9044  Test loss = 2.6984  \n",
      "\n",
      "Epoch: 405  Training loss = 1.9044  Test loss = 2.6984  \n",
      "\n",
      "Epoch: 406  Training loss = 1.9043  Test loss = 2.6984  \n",
      "\n",
      "Epoch: 407  Training loss = 1.9043  Test loss = 2.6983  \n",
      "\n",
      "Epoch: 408  Training loss = 1.9043  Test loss = 2.6983  \n",
      "\n",
      "Epoch: 409  Training loss = 1.9043  Test loss = 2.6983  \n",
      "\n",
      "Epoch: 410  Training loss = 1.9043  Test loss = 2.6983  \n",
      "\n",
      "Epoch: 411  Training loss = 1.9043  Test loss = 2.6983  \n",
      "\n",
      "Epoch: 412  Training loss = 1.9042  Test loss = 2.6982  \n",
      "\n",
      "Epoch: 413  Training loss = 1.9042  Test loss = 2.6982  \n",
      "\n",
      "Epoch: 414  Training loss = 1.9042  Test loss = 2.6982  \n",
      "\n",
      "Epoch: 415  Training loss = 1.9042  Test loss = 2.6982  \n",
      "\n",
      "Epoch: 416  Training loss = 1.9042  Test loss = 2.6981  \n",
      "\n",
      "Epoch: 417  Training loss = 1.9042  Test loss = 2.6981  \n",
      "\n",
      "Epoch: 418  Training loss = 1.9041  Test loss = 2.6981  \n",
      "\n",
      "Epoch: 419  Training loss = 1.9041  Test loss = 2.6981  \n",
      "\n",
      "Epoch: 420  Training loss = 1.9041  Test loss = 2.6981  \n",
      "\n",
      "Epoch: 421  Training loss = 1.9041  Test loss = 2.6980  \n",
      "\n",
      "Epoch: 422  Training loss = 1.9041  Test loss = 2.6980  \n",
      "\n",
      "Epoch: 423  Training loss = 1.9041  Test loss = 2.6980  \n",
      "\n",
      "Epoch: 424  Training loss = 1.9040  Test loss = 2.6980  \n",
      "\n",
      "Epoch: 425  Training loss = 1.9040  Test loss = 2.6980  \n",
      "\n",
      "Epoch: 426  Training loss = 1.9040  Test loss = 2.6979  \n",
      "\n",
      "Epoch: 427  Training loss = 1.9040  Test loss = 2.6979  \n",
      "\n",
      "Epoch: 428  Training loss = 1.9040  Test loss = 2.6979  \n",
      "\n",
      "Epoch: 429  Training loss = 1.9040  Test loss = 2.6979  \n",
      "\n",
      "Epoch: 430  Training loss = 1.9039  Test loss = 2.6978  \n",
      "\n",
      "Epoch: 431  Training loss = 1.9039  Test loss = 2.6978  \n",
      "\n",
      "Epoch: 432  Training loss = 1.9039  Test loss = 2.6978  \n",
      "\n",
      "Epoch: 433  Training loss = 1.9039  Test loss = 2.6978  \n",
      "\n",
      "Epoch: 434  Training loss = 1.9039  Test loss = 2.6978  \n",
      "\n",
      "Epoch: 435  Training loss = 1.9038  Test loss = 2.6977  \n",
      "\n",
      "Epoch: 436  Training loss = 1.9038  Test loss = 2.6977  \n",
      "\n",
      "Epoch: 437  Training loss = 1.9038  Test loss = 2.6977  \n",
      "\n",
      "Epoch: 438  Training loss = 1.9038  Test loss = 2.6977  \n",
      "\n",
      "Epoch: 439  Training loss = 1.9038  Test loss = 2.6976  \n",
      "\n",
      "Epoch: 440  Training loss = 1.9038  Test loss = 2.6976  \n",
      "\n",
      "Epoch: 441  Training loss = 1.9037  Test loss = 2.6976  \n",
      "\n",
      "Epoch: 442  Training loss = 1.9037  Test loss = 2.6976  \n",
      "\n",
      "Epoch: 443  Training loss = 1.9037  Test loss = 2.6976  \n",
      "\n",
      "Epoch: 444  Training loss = 1.9037  Test loss = 2.6975  \n",
      "\n",
      "Epoch: 445  Training loss = 1.9037  Test loss = 2.6975  \n",
      "\n",
      "Epoch: 446  Training loss = 1.9037  Test loss = 2.6975  \n",
      "\n",
      "Epoch: 447  Training loss = 1.9036  Test loss = 2.6975  \n",
      "\n",
      "Epoch: 448  Training loss = 1.9036  Test loss = 2.6975  \n",
      "\n",
      "Epoch: 449  Training loss = 1.9036  Test loss = 2.6974  \n",
      "\n",
      "Epoch: 450  Training loss = 1.9036  Test loss = 2.6974  \n",
      "\n",
      "Epoch: 451  Training loss = 1.9036  Test loss = 2.6974  \n",
      "\n",
      "Epoch: 452  Training loss = 1.9036  Test loss = 2.6974  \n",
      "\n",
      "Epoch: 453  Training loss = 1.9035  Test loss = 2.6973  \n",
      "\n",
      "Epoch: 454  Training loss = 1.9035  Test loss = 2.6973  \n",
      "\n",
      "Epoch: 455  Training loss = 1.9035  Test loss = 2.6973  \n",
      "\n",
      "Epoch: 456  Training loss = 1.9035  Test loss = 2.6973  \n",
      "\n",
      "Epoch: 457  Training loss = 1.9035  Test loss = 2.6973  \n",
      "\n",
      "Epoch: 458  Training loss = 1.9034  Test loss = 2.6972  \n",
      "\n",
      "Epoch: 459  Training loss = 1.9034  Test loss = 2.6972  \n",
      "\n",
      "Epoch: 460  Training loss = 1.9034  Test loss = 2.6972  \n",
      "\n",
      "Epoch: 461  Training loss = 1.9034  Test loss = 2.6972  \n",
      "\n",
      "Epoch: 462  Training loss = 1.9034  Test loss = 2.6971  \n",
      "\n",
      "Epoch: 463  Training loss = 1.9034  Test loss = 2.6971  \n",
      "\n",
      "Epoch: 464  Training loss = 1.9033  Test loss = 2.6971  \n",
      "\n",
      "Epoch: 465  Training loss = 1.9033  Test loss = 2.6971  \n",
      "\n",
      "Epoch: 466  Training loss = 1.9033  Test loss = 2.6971  \n",
      "\n",
      "Epoch: 467  Training loss = 1.9033  Test loss = 2.6970  \n",
      "\n",
      "Epoch: 468  Training loss = 1.9033  Test loss = 2.6970  \n",
      "\n",
      "Epoch: 469  Training loss = 1.9033  Test loss = 2.6970  \n",
      "\n",
      "Epoch: 470  Training loss = 1.9032  Test loss = 2.6970  \n",
      "\n",
      "Epoch: 471  Training loss = 1.9032  Test loss = 2.6970  \n",
      "\n",
      "Epoch: 472  Training loss = 1.9032  Test loss = 2.6969  \n",
      "\n",
      "Epoch: 473  Training loss = 1.9032  Test loss = 2.6969  \n",
      "\n",
      "Epoch: 474  Training loss = 1.9032  Test loss = 2.6969  \n",
      "\n",
      "Epoch: 475  Training loss = 1.9032  Test loss = 2.6969  \n",
      "\n",
      "Epoch: 476  Training loss = 1.9031  Test loss = 2.6968  \n",
      "\n",
      "Epoch: 477  Training loss = 1.9031  Test loss = 2.6968  \n",
      "\n",
      "Epoch: 478  Training loss = 1.9031  Test loss = 2.6968  \n",
      "\n",
      "Epoch: 479  Training loss = 1.9031  Test loss = 2.6968  \n",
      "\n",
      "Epoch: 480  Training loss = 1.9031  Test loss = 2.6968  \n",
      "\n",
      "Epoch: 481  Training loss = 1.9031  Test loss = 2.6967  \n",
      "\n",
      "Epoch: 482  Training loss = 1.9030  Test loss = 2.6967  \n",
      "\n",
      "Epoch: 483  Training loss = 1.9030  Test loss = 2.6967  \n",
      "\n",
      "Epoch: 484  Training loss = 1.9030  Test loss = 2.6967  \n",
      "\n",
      "Epoch: 485  Training loss = 1.9030  Test loss = 2.6967  \n",
      "\n",
      "Epoch: 486  Training loss = 1.9030  Test loss = 2.6966  \n",
      "\n",
      "Epoch: 487  Training loss = 1.9029  Test loss = 2.6966  \n",
      "\n",
      "Epoch: 488  Training loss = 1.9029  Test loss = 2.6966  \n",
      "\n",
      "Epoch: 489  Training loss = 1.9029  Test loss = 2.6966  \n",
      "\n",
      "Epoch: 490  Training loss = 1.9029  Test loss = 2.6965  \n",
      "\n",
      "Epoch: 491  Training loss = 1.9029  Test loss = 2.6965  \n",
      "\n",
      "Epoch: 492  Training loss = 1.9029  Test loss = 2.6965  \n",
      "\n",
      "Epoch: 493  Training loss = 1.9028  Test loss = 2.6965  \n",
      "\n",
      "Epoch: 494  Training loss = 1.9028  Test loss = 2.6965  \n",
      "\n",
      "Epoch: 495  Training loss = 1.9028  Test loss = 2.6964  \n",
      "\n",
      "Epoch: 496  Training loss = 1.9028  Test loss = 2.6964  \n",
      "\n",
      "Epoch: 497  Training loss = 1.9028  Test loss = 2.6964  \n",
      "\n",
      "Epoch: 498  Training loss = 1.9028  Test loss = 2.6964  \n",
      "\n",
      "Epoch: 499  Training loss = 1.9027  Test loss = 2.6964  \n",
      "\n",
      "Epoch: 500  Training loss = 1.9027  Test loss = 2.6963  \n",
      "\n",
      "Epoch: 501  Training loss = 1.9027  Test loss = 2.6963  \n",
      "\n",
      "Epoch: 502  Training loss = 1.9027  Test loss = 2.6963  \n",
      "\n",
      "Epoch: 503  Training loss = 1.9027  Test loss = 2.6963  \n",
      "\n",
      "Epoch: 504  Training loss = 1.9027  Test loss = 2.6962  \n",
      "\n",
      "Epoch: 505  Training loss = 1.9026  Test loss = 2.6962  \n",
      "\n",
      "Epoch: 506  Training loss = 1.9026  Test loss = 2.6962  \n",
      "\n",
      "Epoch: 507  Training loss = 1.9026  Test loss = 2.6962  \n",
      "\n",
      "Epoch: 508  Training loss = 1.9026  Test loss = 2.6962  \n",
      "\n",
      "Epoch: 509  Training loss = 1.9026  Test loss = 2.6961  \n",
      "\n",
      "Epoch: 510  Training loss = 1.9026  Test loss = 2.6961  \n",
      "\n",
      "Epoch: 511  Training loss = 1.9025  Test loss = 2.6961  \n",
      "\n",
      "Epoch: 512  Training loss = 1.9025  Test loss = 2.6961  \n",
      "\n",
      "Epoch: 513  Training loss = 1.9025  Test loss = 2.6960  \n",
      "\n",
      "Epoch: 514  Training loss = 1.9025  Test loss = 2.6960  \n",
      "\n",
      "Epoch: 515  Training loss = 1.9025  Test loss = 2.6960  \n",
      "\n",
      "Epoch: 516  Training loss = 1.9025  Test loss = 2.6960  \n",
      "\n",
      "Epoch: 517  Training loss = 1.9024  Test loss = 2.6960  \n",
      "\n",
      "Epoch: 518  Training loss = 1.9024  Test loss = 2.6959  \n",
      "\n",
      "Epoch: 519  Training loss = 1.9024  Test loss = 2.6959  \n",
      "\n",
      "Epoch: 520  Training loss = 1.9024  Test loss = 2.6959  \n",
      "\n",
      "Epoch: 521  Training loss = 1.9024  Test loss = 2.6959  \n",
      "\n",
      "Epoch: 522  Training loss = 1.9023  Test loss = 2.6959  \n",
      "\n",
      "Epoch: 523  Training loss = 1.9023  Test loss = 2.6958  \n",
      "\n",
      "Epoch: 524  Training loss = 1.9023  Test loss = 2.6958  \n",
      "\n",
      "Epoch: 525  Training loss = 1.9023  Test loss = 2.6958  \n",
      "\n",
      "Epoch: 526  Training loss = 1.9023  Test loss = 2.6958  \n",
      "\n",
      "Epoch: 527  Training loss = 1.9023  Test loss = 2.6957  \n",
      "\n",
      "Epoch: 528  Training loss = 1.9022  Test loss = 2.6957  \n",
      "\n",
      "Epoch: 529  Training loss = 1.9022  Test loss = 2.6957  \n",
      "\n",
      "Epoch: 530  Training loss = 1.9022  Test loss = 2.6957  \n",
      "\n",
      "Epoch: 531  Training loss = 1.9022  Test loss = 2.6957  \n",
      "\n",
      "Epoch: 532  Training loss = 1.9022  Test loss = 2.6956  \n",
      "\n",
      "Epoch: 533  Training loss = 1.9022  Test loss = 2.6956  \n",
      "\n",
      "Epoch: 534  Training loss = 1.9021  Test loss = 2.6956  \n",
      "\n",
      "Epoch: 535  Training loss = 1.9021  Test loss = 2.6956  \n",
      "\n",
      "Epoch: 536  Training loss = 1.9021  Test loss = 2.6956  \n",
      "\n",
      "Epoch: 537  Training loss = 1.9021  Test loss = 2.6955  \n",
      "\n",
      "Epoch: 538  Training loss = 1.9021  Test loss = 2.6955  \n",
      "\n",
      "Epoch: 539  Training loss = 1.9021  Test loss = 2.6955  \n",
      "\n",
      "Epoch: 540  Training loss = 1.9020  Test loss = 2.6955  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1f9b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXlclNX+xz9nYAYUZBM33EBAUBAxFdzKfV8ybTMrtXKr\nbPf+0pZbt6yb95a3bmlauZRa5lKmJebedRdxCdFYlMUVVDaRbZjz++PMM8wMszIzDAzf9+vlC3nm\nWc4Mz3ye7/luh3HOQRAEQbgOMmcPgCAIgrAvJOwEQRAuBgk7QRCEi0HCThAE4WKQsBMEQbgYJOwE\nQRAuBgk7QRCEi0HCThAE4WKQsBMEQbgY7s64aGBgIA8ODnbGpQmCIBosJ0+evMk5b2FuP6cIe3Bw\nMBITE51xaYIgiAYLYyzLkv3IFUMQBOFikLATBEG4GCTsBEEQLgYJO0EQhItBwk4QBOFikLATBEG4\nGCTsBEEQLgYJO0HYicLCQqxZs8bZwyAIEnaCsBeffvoppk+fjsuXLzt7KEQjxy7CzhjzY4xtYoxd\nYIydZ4z1tcd5icbF2bNnMWfOHFRVVTl7KLVi+/btAIDS0lInj4Ro7NjLYv8UQALnPBJAdwDn7XRe\nohGxdetWLF++HFlZFlVN1yuuXbuGEydOAAAqKyudPBqisWOzsDPGfAHcB+AbAOCcV3DOC2w9L9H4\nuHHjBgAgMzPTuQOpBb/++qvm/yTshLOxh8UeAiAPwCrG2CnG2NeMMS87nJdoZOTm5gIALl265OSR\nWI/khgFI2AnnYw9hdwdwD4BlnPMeAEoAvK6/E2NsFmMskTGWmJeXZ4fLEq5GQ7XYy8rKsGvXLoSG\nhgIgYSecjz2E/TKAy5zzY+rfN0EIvQ6c8xWc816c814tWphtJ0w0QiRhb2gW+759+3D37l1MmjQJ\nAAk74XxsFnbO+XUAOYyxCPWmoQBSbD0v0fhoqBb7tm3b4OXlhREjRgAAKioqnDwiorFjr4U25gFY\nxxhTALgIYIadzks0EioqKlBQIGLuDcli55xj+/btGD58OLy9vQGQxU44H7ukO3LOT6vdLDGc84mc\n83x7nJdoPEiB03bt2uHq1asoKytz8ogs4+zZs8jJycH48eMhl8sBkLATzocqT4l6geSGiY+PBwBk\nZ2c7czgWI2XDjBkzhoSdqDeQsBP1Aslil4S9obhjtm3bhri4OLRu3RoKhQIACTvhfEjYiXqBvsXe\nEAKoN27cwPHjxzFu3DgA0FjsFDwlnA0JO1EvkIQ9NjYWcrm8QVjs27ZtA+e8hrCTxU44GxJ2ol6Q\nm5uLpk2bwsfHBx07dmwQFvv69esRFhaG2NhYACTsRP2BhJ2oF9y4cQOtWrUCAAQHB9d7i/3y5cvY\nv38/Hn/8cTDGAJCwE/UHEnaiXqAt7CEhIfVe2L///ntwzjF16lTNNgqeEvUFEnaiXpCbm4uWLVsC\nEMKel5eHkpISp47p0qVLmD9/PsrLy2u8tm7dOsTHxyMsLEyzzWzwlHOAFuEg6gASdqJeoO+KARyQ\nGZOeDsydC6RY1vFi06ZN+Pe//41PPvlEZ3tycjLOnDmjY60DFrhivv4aCAkB6vlshGj4kLATTqeq\nqgp5eXk6rhjAAcK+Zg3w5ZdATAzw4otAvukCackd9P777+ssd7du3Tq4ubnhkUce0dnfzc0NgBFh\n5xz4/HNAqQR27rTxjRC1orISWLUKMDADczVI2J0J58KK3LUL+Oor4M03gY8/dv6Y6phbt25BpVJp\nXDGSxW53P/upU0BYGDBzphDZ8HDxuRshMzMT7dq1g0qlwmuvvQYAUKlUWL9+PUaMGKEZrwRjDHK5\n3LCwHzsGnD0r/r9rl93eEmEFO3cCTz0F/Pe/zh6JwyFhdyZvvy3EZcQIYNYsYNEi4LXXgOPHnTOe\n1auBzp2BOk41lKpOJYu9VatW8PT0tL+wnz4N9OkDLFsGJCWhonNnYNYs8F9+Mbj7pUuXEBcXh9df\nfx0bNmzA/v37cfDgQWRnZ9dww0gYFfblywFvb+Dhh4G9e4F6sK5rfn4+vvnmG6hUKvM737ghHoIv\nvwxcvGjZBXJygEmTgOvXbRuoNmZmWSb56y/x86OPgOJi+4ynnkLC7iwuXQIWLwYmTgQOHACysoDb\ntwEfH+DTT+t+PJWV4kGTng488ABw926dXVoqTpKEnTGG4ODgmq6Yigph7a5bJ6yud98FPvvMMpHM\nywOuXAHUOefo3h3zIiNxDoDyuecAvQWoOefIzMxEcHAw/va3vyE4OBjz5s3DmjVr4OXlhYkTJxq8\njEKhqCnsBQXAhg3A1Knisy0oAE6eND9me1NeDpwXyxEXFxdj5MiReOaZZzRrtdZAqQT+8x9gwACg\nTRthfHz2mXBlrVhhfnaXkAD89JO4r+zBwYNAYCBw5Ejtjk9NBRQK4OZN17faOed1/q9nz5680fPo\no5w3acL55cu6219+mXN395rbHc3atZwDnM+bxzljnE+dyrlKVSeXXrduHQfAU1JSNNtGjx7Ne/To\nobvjBx+IMer/e+MN8xf5/Xex7+7dnHPOc3NzuYeHBx8knePtt3V2v3btGgfA//vf/3LOOd+yZQsH\nwAHwqVOnGr1MixYt+Jw5c3Q3fvaZuEZSEuc3boj/L1pkfsz2IiOD87/9jfPAQM4BXrZrFx84cKDm\n/axevdrwcdK4Y2M5f/ddzs+c4Twri/OhQ8X20aM5v3LF+HVfeUXsJ5Nxfu6c7e/jrbfE+aZPr93x\ngwdz3qcP5+PGce7nx3l+vu1jqmMAJHILNJaE3RkcP25ckC5eFF+EBQvqbjwqlfjydunCeVUV5++9\nJ8b3n//UyeWXLFnCAfBbt25pts2dO5f7+/vrjrFLF87j4zm/cIHzvDzOKys5f/ppMdZffjF9kcWL\nxX43b3LOOX/vvfc0wnb+nns49/DgPC1Ns/uRI0c4AL5t2zb15VV8+PDhHADfsWOH0csEBQXxp59+\nWnfcUVGc9+5dvS02VoiMozl/XogvY5y7uXH+wANc1bw5P9KqFWeM8TVr1nB3d3e+wNC9plJxHhPD\nuaHvalUV5//9rzBMmjcXDytDjB3LeUgI5z4+QkxtZcgQ8Tds2pTzoiLrj2/XjvMnnxQPWAMP84YA\nCXt9RaXi/L77OG/Z0vjNOWkS5wEBnJeU2Pfamzdz3qsX51ev6m7ftUvcCl9/LX6vquJ84kQhBvv2\n1fpyBw4c4OPHj+eVlZUm93v99de5u7s7V2nNEBYvXswB8IKCArHh9GkxxmXLdA8uLeX8nns49/XV\nEeYaPPYY5+3bc845Ly8v561bt+YjRozgvr6+fMG0aZw3ayZEUD2G9evXcwA8OTlZc4qsrCz+j3/8\ngyuVSqOX6dixI3/yySerNxw8KMb91VfV2157jXOFwv5/X21+/lm8p+bNOf/73znPyeFKpZJv6tqV\nVwH8+3ff5ZxzHhERwSdNmlTz+JMnxbi/+ML4NfbsEfts2WL49dBQzh95hPMPPxT72XAv8cpKzr28\nxANS+161lJIScdx774nfJ08Wn4/6Qd9QIGGvr2zdKj72pUuN7/PHH2Kf5cvte+2nnhLn7d1bV1RG\njuS8VSvOy8qqtxUWch4ZyXmLFrWess6bN48D4BkZGSb3mzFjBg8KCtLZ9uOPP3IA/PTp02LD/PnC\nRZWXV/MEly6JB2FMjHGx7NKF8wkTOOecf/fddxrLu3fv3nz48OGcf/KJ+Gx++olzzvkHH3zAAfDi\n4mKr3nNYWBifMmVK9YYnnhACon2ehARxrYQEq85tEVVV1S6LXr04z87WvLRu3TreEuCV7u6cq91F\nEyZM4F27dq15nueeE7OY27eNX6ukRMwG1A8JHUpLxczz73/n/O5d8VDt1UuMrzYkJor39P334r7s\n39+648+cEcdv2CB+T04WY3/99dqNx0nUubADcANwCsB2c/s2WmGvqOA8IkL8q6gwvp9KJazQLl3s\n6ueu7NmTlwUEiBv6wQfFl0y64Q35fKUp61tv1ep6gwcP5gD4rl27TO43duzYGv70EydOcAD8p59+\nEuNs105M7Y2xY4d4X088UfO1khIhMm+/zVUqFb/nnnt4ZGQkr6qq4o899hjv2LGj+HtER3PeoQPn\n5eV81qxZPDAw0Or33LVrV/7ggw+KX27dEuI4d27N8SgUwnK3J3fuiM8I4HzGDCGuWjz88MO8devW\nXPX005x7enKem8vnz5/PFQqF7iyktFT4oLUfUMYICxP3kj5//lktxJxzvmaN7u/W8umn4vjsbM4/\n+kj8/8IFy4/fuJFr4hwSU6YIt05ubu3G5AQsFXZ7ZsW8COC8Hc/X8PnhB2DMGGDQICA+HoiOFilX\nH30EqKsUDcIY8NJLIoPBXjnPnEP555/4Jj8fyg8/BDZtEtkKH38MNG0KzJlT85gePUR63iefAOqU\nRGtITk4GYD4fXbvqVEIqUrp06ZLIhrh8GXjsMeMnGTUKWLgQ+O676nxxiT//BFQqIDYWhw4dQlJS\nEl588UXIZDJ07twZ2dnZKKuqAhYsALKzgXPncOnSJc0YrEEul1e3FPj2W5GJMnu27k5NmwL9+9s/\nn33VKuDXX0XGxzffAJ6empcqKyuRkJCAsWPHgr36KlBWBixbhsjISFRUVOhmIP38s8jcefpp89fs\n1k18vvpcuCB+RkaKn1OnAt27i8+4NgVChw4B7duLf088Abi5ifRcS0lLEz/Dw6u3vfCCyP46eND6\n8dRz7CLsjLF2AMYC+Noe56s1nDu0wKagoEAjViYpLRWpYVOmVN9Q/v5A167Ae+8BEyaYP8cjjwCt\nWwNLltg2aImcHHhWVOBPznFr2jRRpLNoEbB2rfgCBwQYPu4f/xDv55//tOpyubm5yMvLAwBcNJP3\nbEjYAwIC4O3tLQRn/XohhuY+txdeAGQy4McfdbefPi1+9uiBTz/9FP7+/njiiScAAOHh4eCcizF2\n7y72S0nRpDpaiyaPXaUCli4F+vWrPq82w4YBZ87U6oFplIQEIDQUeP55YRxocfDgQRQVFYne8V26\nCIPjiy8QqX6Pf0k53gCwciXQsSMweLD5a3brJu5xvXRRjbB37ix+urmJ9NTMTOCPP6x7X5wLYe/X\nT/zepo0Y/5o1IiVTorAQ2LhRfPb6pKaK49QLjgMQhpb2WF0Ie1ns/wHwNwAWVDo4kI8+En889TqU\n9mbBggXo3bs38k0VSaSmAn37imKO118XVvf+/dU5vW++WeNLZxCFApg+XVTL6X9pasO5c+IHgILC\nQuCLL4AhQ4QQvvyy8eMiIsQ4li4VBScWov0ANCXsnHOdBmASjDGEhIQgJyNDfFnvv1/3S2mIli2F\nGP34o+4D/vRpwNcXWQC2bNmCWbNmwcvLC4AQdgBITU0V1py7O3hyMrKysmptsVdWVgJ79gjBe/ZZ\nwzsOHy5+7tlj9TUMUl4O7NsHjBxp8OXt27dDoVBg2LBhYsNrrwG5ueh25gwALWHPygJ27wZmzBD3\nhjm6dRNCel5vsn7hgng4NG1avW3QIHHvW1uAl5MjahD696/eNmMGcO1adXuGAwdEfv3DDwO//Vbz\nHGlp1Q8ZCW9voG3b6sIlF8JmYWeMjQOQyzk3WXHBGJvFGEtkjCVKlpzd2bZNVMiNHy9cGXbsCcE5\nx9atW1FWVoaNGzca3mnfPqBnT3Ej/vor8OGHgLu75uW//voLq62ZPnbrJgTKDhWYZUlJANTCXlAg\nXEG//Sa+kOYE7O23xTjee8/0frm5oqrz8GGcP3UKANC9e3eTwl5UVITy8vIaFjsgWgsEJSeLwi0j\nlZ41ePhh8SVWCxYA0UogNha//vYbVCoVnnnmGc1LkrCnpaWJh2l4OMpOnUJFRYVtFvvSpaKY5sEH\nDe94zz2An58QUXtw6JBwK5gQ9sGDB8NbejgOGgT06IFmX32Fjn5+uCBZrWvWiJ/Tp1t23W7dxE99\nd8yFC9VuGAlfX7Ht2DHD57pyBXjoIfEd1ubQIfFTW9jHjgVatBAVvX/7m3igKxTivjbkWpEe3PpE\nRrqkxW6PoOmHAC4DyARwHcBdAGtNHeOQ4Gl5uQhUPfecKLKRCiusCbCY4OTJkxwAl8lkfMCAATV3\nqKoSwbewMJ1MBG0efvhhDoBftrT46OhRblGOtgXkjh3Lr6nzthNqk43xwgsi/fGvv4zvs2CB5Azj\nFTIZP+7uzn/r0YOHa+ej6/HXX39xAPy7774zcMkX+AZ3d65q3tx0sJlznp+fz+fPn88nDxzIVW5u\n1dkOSqXIt37pJb5o0SIOgJdpZ/9wUVQ0c+ZM8cuDD/K77dqZzVc3xrBhw/jEnj1FsNZcxsWkSSJb\nxB4B8vnzOZfLDabQSp+xVGylQR1QLGOM7wsMFBlBwcGcDxtm+XWVShGIffXV6m0qlUhNfPHFmvtP\nmyYysAy95yVLxP2jf9xzz4nz6afNvvyy5n7js2aJzKP4eM71v5/5+WKfxYtrXvPZZ0WguI6K8WwF\ndRU85Zwv4Jy345wHA3gUwF7O+eO2ntdqzpwRFvqgQaLs+ZdfhOVsxIKxlu3bt8MfwEePPYaDBw/W\nDAhu2wYkJ+P6nDkiwKNHeXk5duzYAQD4zdBU0RChoeJnRoYNIxfwlBScU//fpCvJGAsXAh4ewN//\nbnyfw4dFyf6WLdjQujU8mjbFyNOncTw/H6Xvv29wBiW1E9B3xQBA56AgjFUqUTp2rNFgc2VlJT77\n7DOEhobiX//6FzYfOICy/v2r3TGS/zc2FkVFRVAoFPDw8NA5R3h4uHDFAEDXrvC4cgWeQK0t9nFX\nr4prGwpIazN8uLhH7WEx7twpLNpmzWq89OuvvwIAxo4dq/vCgw8Cx47hf5GRiL59W7Q7yMwUjbIs\nxc1NxI60LfYrV4CSEuHG0ycuTljkhtx6+/eLn8uXCzeLxKFDoseP1uwXADBvHjB0qPjuSb14BgwA\nTpzQvdcMBU4lIiJEoNiesY56gOv0ijl6VPzs00f8HD9eROClHiw2sn37dnzdqhVe/eEHdAewdu3a\n6hc5Bz74ANe9vND5rbeEq0OPAwcOoLi4GDKZTPNFM0vz5qJ3jK3Czjl8Ll/WCLuh8ZmlVSsRlNuw\nwfCXoLJS+E4HDgSfOBHPFhdjxRNPYPcnn+AQgCZvvSWCdl99BezYIXyiiYkoUvs3DbliRqamwgtA\nitTfRY/09HRERUXhxRdfRI8ePfDWW28BAG4PHSoaVSUlCTcMAPTogaKiIvj4+NQ4T+fOnYUrBgCi\noiDjHBEAOnbsaPoz+fZbEdBLTNRsauLmhol5ecC4ccLHbAr1ItjYutX0fua4dk1kAplww0RFRRmO\nGcTF4eS0aWijUqFk40bhPpw82brrR0frCrt+Roze9QDU9LOrVCKoOniwuJcWLxbbi4vFe9N2w0iE\nhAhXlvQ5AmK/8nLdXjzS31bfx649xtr42XNzRUD/6lXrj3UwdhV2zvl+zvk483s6gKNHRSCkXbvq\nbdITWvrD1pLr16/jxIkTGH73LphSic1eXvh+zRrJFSUCYMeP4+2SEhSXluJH/awMAFu3bkXTpk3x\n5JNPYvfu3QZX5akBY8JqT0+3afzIzoZnZSXy27QBUEthB4RFx7kQZX3OnhWWcd++yMnJQXFxMaKj\noxF4330YB+Dg228Li2rWrOoU0N69MXr2bLwBoFVgYPW5OAfefBNhK1fiJwAHtDMftFi5ciUuXbqE\n7du3Y9euXRgwYAAA4Erv3sK6+/FHEThVKIDISBQWFhoU9vDwcFy9ehV37twR1ieAfr6+aNKkieHP\ngXOR4TFtmhD1e+8VmTsABuTmorlSaTxoqk27dkDv3iKobgu//y5+jhpV46XCwkL88ccfIhvGCBER\nEVACONehgwj4q5f4s5hu3cTD5dYt8bspYY+JETM/fT/7n3+Kzo0zZgBPPin65l+7Jr7XKpVhYTeE\nlDkj+eUB4V9nDOjUqeb+0qyiNrOmn34Ss4XNm60/1sG4jsV+7Fi1tS5hJ2H/7bffEAugWXEx8OCD\nCC0pwcMZGTimvjn5++8j190d+9q3R0REBNZIASg1nHP88ssvGDlyJB588EGUlJTggCFxNERoqO0W\nuzojRh4bCw8Pj9q5YgARGPb2FkFifaSOe/36aTJioqOj0Un9ZTrm4yOs5+Rkse+ePcAvv+Bcly54\nH0CrKVPE9FypBJ55RqRizpyJF1q3xlkjKaZJSUmIiooSudmMaUT7FiDSCX/8UVwzKgpQKFBUVARf\nX98a55ECqOnp6UDnzqhiDPHGMnAqK0V66DvviABjZqawQqdOBV5/HaMvXkS2XC5aMVvCxInCer1y\nBRUVFTh69Gi1wWApCQliRhUTU+OlnTt3QqlUmhV2QC/l0Rr0A6gXLoiZZuvWNfdVKER9hL7FLn0f\nBg4E3nij2mo/dEhk5+h/t43RqpXoua8t7GlpYvakldevoX17oEmT2lnse/eKn5ILqR7hGsKelyfE\nLz5ed3tIiHhS2yjs27dvx2M+PuCMAZ9/joqHH8YbAPYtWQIcPgx24AA+VCrx/r/+haeffhqHDx+u\n9tkCOHXqFC5fvowJEyZg8ODB8PT0tNwdExoqxMOG/t0l6i+Rb9++8PPzq7XFnp6VhdRWrVBlKEXv\nyBExY2rfHufUD5KoqCj4+fnB399fZMa4uQmR7dNHpFqOH4+lAwbgOW9vsFOnRL730KEij/rtt4Hl\nyxEdG4sz2hkuajjnOHnyJO655x7NNknYi4qKRB1AZqb48vXoodluzBUDVGfGXHJ3R1dDKaklJWLa\nv2qViDWsXAkEBYlCo9mzgY8+QuTNm1jr7W1ZqiAgZkEAsHUrvvvuO/Tt2xcfW7PYSlWVuP6IEQav\nuX37dgQEBKCPCWEMDQ2Fm5ubfYU9MtJ4Wm9cnJjpaM/EDhwAgoOBDh3EPf/EE8Jq37pVnN/A380o\n/fsLYZcekMYyYgDxmXXubL3FrlJVGzh//GE4d96JuIawS9M6/ZvX01PcKDa4MsrKyvD7779jcpMm\nYL17A61aQbFsGe54emL85s2oePNN3GQMyX374uGHH8bjjz8OmUyGb7/9VnOOrVu3QiaTYdy4cWja\ntCmGDBmCX3/91TLLLDRUWC9W5JDrU3zsGK4BCIuLs0nYly9fjq8yMuCWmoqL2hYRIAKnffsCEDns\nbdu2hb+/PwCgU6dORlMeb+Tm4kDHjsKyDg0VqWrLlglXB2Po3r07UlJSaiwQffnyZdy8eRM9e/bU\nbJOs8cLCQpH3LpcL4VP76I0Ju7QgdVpaGpRKJc4olQgx1I9+2TLh9vjmG2GxS8KlUAgRWroUqa1a\nYb0hy9AYkZFCWH7+WTOLmz9/Pn744QfLjk9KEi4QA/71qqoq/Pbbbxg9ejTc9QOPWigUCnTq1Kn2\nwt6mjShw0xd2Y8TFidRMKfddpRLCPmhQ9T6S1X76tOVuGIkBA0TP9dTU6gC6If+6RGSk9Rb7uXPC\noBw4UFzLwnV06wrXEPajR4U1qPUl1xAebpPFfuDAATQpKUFIbq7InQWAgABkzJ+P6KoqKPbtw384\nx0effw7GGNq0aYORI0fi22+/1axMs3XrVvTv3x+Baj/y2LFjkZGRoWPVG8UOmTEydUZMVFQU/P39\nay3sKSkp+LN5cwDAByNGYKdUHHL9urCOtYQ9Wqrqg2gPYFTYb9wQGTFhYeLhkJmpk00SExODysrK\nGqJzUh0cM2qx+/tXu0PMCLuXlxeCgoKQmpqKK1eu4BznCMjPF2X32mzfLtwdxrJG5s7FkgceQK6R\nmIBBGBNW+759OHvgAMaMGYP77rsP06ZNw35LpvgJCeIcBlw/x48fx61bt0y6YSQiIiKqc9mthbHq\n1gLFxSIrxpywA9UGWUqKeDgNHFi9T1iYsNqBar+5pUgPgkOHhOgWFhq32AHhZ790ybq6F8kN8+67\n4qeFrtVaPzytxHWEvXt33So3CUnYa9lqYPv27bhfLgfjvFrYAcS+/Ta+9/TEDQCFjz+uIzDTpk1D\nTk4O9u3bh6ysLJw5cwYTtMrhpbQzi9wxJoT9xo0b+F0KnBlDpYLP1atIVyjQtm1b+Pn51drHfv78\neQQMHYqqZs0wytMTY8aMwSeffFLtX+/bF1VVVUhJSdER9k6dOiEzM9PgEmy5ubnVGTFyeY1U0e7q\ncnx9d0xSUhJkMpnmdQDw9vYGY0wIOyACmJGRZl0xQHVmTGZmJs4BkHGua8UVFIjZhH7KoB5Gl8Yz\nxcSJgFKJ6OxsDB06FD///DPCwsIwceJE8y0sdu4UxU4tWtR4SXr43XfffWaHEBERgbS0NFTV1uXX\nrZuIn5gKnEqEhYkHr+Rnlx5g2sIOCNGcMkUE260hIkLMIA4dElY7YN5iV6msm9nv3Su+m/fdJ7wC\nZh7Cd+/exSuvvIIuXbrgFyNLMdqThi/sVVXiBjHmQwwPF19KKWJvBZxzbN++HdNatBDTTbVAAIC7\nuztOz5uHnr6+ePPf/9Y57v7774evry9Wr16t+SPef//9mtc7duyIqKgoy4S9XTsheAaE/ZNPPsHI\nkSNx1VS6VXY2PJVKFLVvD8ZYrV0xd+/eRWZmJiKjouA2aBAm+ftj4sSJePXVV3F182bhjrjnHly8\neBFlZWU1hL2iosLgOA31idEmIiICCoXCoLB36dIFTbUe5lIAtbCwUGwYM0ZM99WBUFPCHh4ejrS0\nNFy6dAmaSbX29HrXLnGvOULY4+JQ6u+PiQD69+8Pf39/7NixA15eXhg9ejRKSkoMH1dYKIwaI2mO\naWlp8Pb2Rht1NpQpIiIiUF5ejuzsbOvGLtGtG3DnTnWJvylhZ0xY7ZKwHzggxFG/bqBDB5FtpHbp\nWYxMJqz8Q4dM57BLWJsZo1QKIR8yRLyXgQOFn92I8XjgwAHExMRgyZIlmDNnDgZb0oPHRhq+sF+4\nIKZ/+oFTCROZMdnZ2Vi6dCnWr1+PnTt3IjExEZcuXUJhYSE450hJScHlzEzE5ecLkdALTr2/aBHO\nXrxYQ5g8PT3x6KOPYvPmzVi3bh26dOmiybyQGDt2LP74449q69IYbm4iTcuAsEvW3HYTvXG4eh+m\nFlpTwl42SdQaAAAgAElEQVRSUoI/DXXqg5hCcs7RtWtXYPBgyDIysGbRIgQGBiL/11+FG8zDQycj\nRkLKjNF3x5SWlqK4uNhgcZKEu7s7oqKicFavY6N+4FTCx8fH4GdaXl6OiooKk8Kel5eH06dPIw0A\nd3PTZBMBEC0i/P2N32dqaiXsMhlOtm+P0QB6qAWxQ4cO+Oyzz3D58mWjfxPs2CEeNiaEPSwsDMyC\n3kSR6uvaHEDduFHcs9JM0xhxccLCLykRwj5woGU9lCylf38x4zp8WKS+mio2k6x5S9/7qVNAUZEQ\ndkCMPTe3xoOhqqoK8+bNw6BBg8A5x969e7F06VI0M1BEZm8avrDrFybpIwmqgWnWP/7xDzz33HOY\nOnUqRo0ahd69e6NTp07w8/ODXC5Hnz590B+AR2mpQUtNLpcjwEhXxOnTp6O0tBTHjh3TccNIjB07\nFkqlErssad1qJOUxRW1RmpraFas/Hz+1n9Lf3x/5+fkGA7fLli1Dz549DQr/eXWgq0uXLpquf94n\nTuD1V15BaEEBrnToAEA8bBhjYj81UmGMvrDnqgudTFnsgHDHaFvs165dw/Xr13UCpxK+vr7VFrsW\nktibcsUAwK5du9CiXTuwsLBqi12lEiI6alTN6kc9pMWsrU1Z/KG0FF4AFFqdDyWxNdr2+MsvRRqf\nkeBiWlqa5n2Zw+aUR+lBfvasuF/N5cLHxYmH0rp11UFIe6KuacCGDcIwMvV38/YWM2NLLXbJvy5Z\n3lLQV88dk5CQgM8//xxz5szB2bNn68RSl3ANYff3Nz7VCgkRlrYBi/3kyZMYPHgwLly4gEOHDmHr\n1q1YuXIl/v3vf+P//u//MHXqVHx0333CFSJ1xbOQ+Ph4zZdK2w0j0a9fP/j5+VnuZ8/I0Jnq3b17\nF1lZWfDw8MCePXuMTtfvHDuGqwDC1QErPz8/KJVK3DWQ9ZGdnY3KykqNb1ablJQUuLm5iZlHTIzw\nYe7bh2f79YMngK/V1m1ycjI6deqk6Z4ICOtTJpPVEHapnYAlwn7jxg3N/oYCpxLGLHZzwi7NqFJS\nUkQrgaioaov95ElhkVng65XL5eCcW+WrLikpwTcZGSj18NApVpJaGhgU9rNnhaX77LPCQtajsrIS\nly5dqjFTNEaLFi3gp90MzFqaNau2ig21EtBHCqBKbkztjBh70KuXeLgUFZl2w0hYkxmzd6+4P6T7\ntlMnkeqrF0Ddv38/PDw8sGTJEp3vQ13gGsLep4/xaZxCIawaPWEvKytDcnIy+vTpg4iICPTr1w8T\nJkzAjBkz8Oqrr2LRokX48ssvEZ+XJ246K6dPjDHMnz8f/fr1Q5x0E2vh7u6OUaNG4bfffjNv3YWG\nCnfTzZuaTZJrZMaMGSgrK8NuI10C3S5c0GTEAELYAcPVp5IFnahVIi9x/vx5hIWFQaFQiAflwIHA\nvn1oou51vjw5Gfv376+REQMIK7Z9+/Y1BMpUnxhtYtSFN5LVnpSUBMYYYg20GvD19TUo7JIVb0zY\nO3XqpHFZhISEiArU9HSRKfHrr+L+MlDZqY9c3dPGGnfM8ePHUaZS4XbfvqLHkTqrxsvLCy1btjQs\n7F98IdJ5jSyGcenSJVRVVVks7IwxRERE2Ja1IbljTPnXJVq2FA+CtDQhioaqQm3B07M6S86SWUtE\nhLDYzX0XKyqA//2v2g0DiHtj0CBhsWsdv3//fsTHx8PTmvRXO9Gwhb2oSFhV5qrSDKQ8JicnQ6lU\nGrT6NFy8KIJvZgJmxnjmmWdw6NAhuBmwqADg3nvvxY0bN3DlyhXTJzKQGSO5YWbPng1fX1/D7hiV\nCn7Xr+NSkyZooc6aMCXsUjvlEydO1Hjt/PnzOu4VDB4sUhPXr4eqfXugTRssXLgQqampNYQdMJzL\nbo0rBoDGz37y5El07tzZoK9SJ3iqhTmL3dPTU9MbRmOxq1TCivv1V3GPabc9MEJthP2QuibAd/p0\nEeTXcseEhITorm4EiNL7tWvFilLq9FN9pN43lgo7gLoVdqDaapf6tNsbyUVlyWcQESH0RL9lsD7H\njonWGUOH6m4fOFAcq87CKSwsRFJSEgbZeyZiIQ1b2E+cEE9IMwEtQymP0nRex0+bni4KT158UfSs\nkHqA11LYzaFviRrFgLCfP38eoTIZog8exOhRo7Bt27aa0/+sLHgolShW+78BaIqGDKU8SkKrL+yV\nlZVIS0urKewAcPw4ZP36YeHChThy5AiUSqVBYTeUy7579274+PiYzdpo3rw52rZtq2OxG/KvA+Zd\nMYZaCkhIIqix2AFRXZiYaHHKXW2FPSoqCt4PPQR4eQm/sJqQkJCaFvvKlaLAZ948o+eUaiQs9bED\nwqd/9epVFBcXW3yMDlLWmPrvr1KpcERKhTWEJOwW+tcrKyuxYcMGy91c0nnVs1WTSA8jc66ovXur\nZ6yGrqX2sx86dAgqlYqE3WJu3xa+rM8/F/1EgOobxBjh4eJprOXKSEpKgr+/f3Vr1qtXheXw7rti\nLcU9e4T746mnRN6tA+imtnD0Mz5qILVG0AoAp6Sk4L9eXnCfNw8LVCrk5eXhuF7/DZU6m0Km1UPE\nnMXu5uaG7OxsjcgDooeKUqkUGTESUVHVudN9++KZZ55BO3UDNmMW+/Xr1zW+/ezsbGzcuBEzZ84U\n7h0zSAHU3NxcXL582ehMq7bBU6Ba2IODg4UFJ5MB//mPeNHCh7v0XiwV9qqqKhw+fFg0MGvaVHQl\n3bxZ444JDg5GdnZ2tZhVVYlFPAYM0BReGSItLQ1+fn5obsSiN4R0Px4+fNjiY3R44AGR7ti7NwDg\n22+/Rb9+/bDPUG8hQLzXnj0t/mw3bNiARx991GCTPYOMHSsezPfea35fKS5gbsayd2/1IinahIeL\nlGi1n33//v1QKBQmWzk4koYl7M8/L6aegwYJa+XMGbF2p7k8VwMpj1K6HGNMWD8TJoh899OnRX5w\ndrZIx/rmG4e9HV9fXwQHB5sXdk9P4YfUstizk5MxpKQE8PFBzMaNmCSTYdu2bdXHlJejdNkyAECA\nVtaEMWFXqVS4efMm+qmzZ7T97DoZMRKSXxEA+vaFp6cnFi9ejNjYWINWopTyKLkVPv/8c3DOMc+E\n1alNTEwMzp8/j6PqLB9jwu7j44PS0tIawmqJsEvvLzQ0VHQgDAsT7qY2bUyKqDaSxa7fAsEY586d\nQ1FREfpLf6NHHhHuGHXmRUhICCorK6vddTt2CBfh88+bPG9aWhrCw8MtSnWUGD58OAICArBq1SqL\nj9HBzU1UwKqvuXLlSgAwvuJY585iNhQUZNHpExISAKBGkz2jSPeoJZ9Bu3biwWrMYudctAA/ckTX\nv659rYEDhbBzrvGv1+gQev26ZWO3kYYl7KNHi45vCQmibPnmTWDFCvPHSRa3WtgrKirw559/CnFQ\nqUTpclIS8P33hhcediAxMTHmXTGATspjRUUFumdkwEOlEk2S4uKwljGclyyZ3Fxg2DB4JSTgDQCd\ntWY0xlwx+fn5qKqqwsiRI8EY03HHSP78SH3f6ZNPikIQtehNmTIFp06dMmiBa+ey37lzBytWrMDk\nyZPN9zxX0717dyiVSqxbtw4A0EOrWEwbydWi746xRNifeuopJCQkoIPkupKm8GPGWOwDttYVI/nX\nNcI+apRoeKV2x0ipohp3zOefCyGcNMnkeSVhtwYPDw9MnToVP/30E27VoqBPm/T0dPzvf/+DQqHA\nTz/9ZLDq2BpUKhV27twJuVyOXbt2mY9LWYvUDEzbYr92DXjlFfFwaN5cBHsrK4137hw0CLh6FXf+\n+AMnT56s6Yb5/nsRJFYvuONIGpawjx0LzJ8vCjKCgiwPuISECGtCLeznzp1DRUWF8NO+8QawZQvw\n8cdialjHxMTE4K+//kKZfl8SfbSEPT09HY+oVChu2VJYCT/9hCpvb3ySkYGra9cCcXHgiYl4LyoK\nHzKm40KRhE/fYpcCp506dUJkZKSOsJ8/fx4dO3asmbI1bpyo7rPAlaIt7KtXr0ZhYSFeNrWIth5S\nAPXnn39GaGioZuahj06/GC2Kiorg7u5uMkOhadOmGKld7CMJuxUxltoIe+vWrasXwfD0FA3MtmwB\nKip0hf3CBeHqmDPH6IpSgMj4ys7Otsq/LvH000+joqIC69X95WvLt99+C5lMhvfffx/Xr1/XzLRq\nS1JSEm7evIk333wTKpVKd6GbWqJUKrFq1arq2ZX2+qfbtom03i++EJlRDz0kHqqHD+tY7Le1F/EZ\nPx4IDITHmDEYo+1f5xz46CMR7O7d2/IWxDbQsIS9tsjl1alVEDcJANx37Rrwz3+KlqsvveSUocXE\nxEClUmmsYqOEhoqo+507uHj4MIYCuDN+vHi4BQWhYNUqtAEQ9MQTKC0uxnAPD3yQkYFly5bpBAzl\ncjm8vLxqCLvkU2/RogV69+6NxMRETRpmjYyYWhAYGAgvLy+kp6fj008/RXx8PPqqm4ZZQnh4ODw8\nPKofyEYwJew+Pj5WuSYwfrz4Eg8fbvEh1gr7wYMH0b9/f91xPfywcAvu3o0OHTqAMYbMixdFznqz\nZmKxEhNkZGSAc261xQ6IB2jPnj3xzTffWN8XXo1KpcKaNWswYsQIzJ49GwqFApttXIwiISEBjDHM\nnTsXAwYMwOrVq2s9Pok//vgDTz31VHUn1oiI6iZ0EyYI9+fp08L9snw58NxzotGd+m919uxZBAYG\nYtOmTeL4oCAgMRE3mjXDNgD37tol0iOffVYsYPLoo6I7qLUtEmqBzcLOGGvPGNvHGEthjJ1jjL1o\nj4HZnfBwTfDx5MmT8G/WDK0/+0wEb/77X8ekW1mAfiqfUaTMmIsXodiyBW4AfOfO1bzc7oEH8H/t\n22OruzvCbt/G7U6dcPLkScyePbvGqQy1FZAs9pYtW6J37964ceMGLl++DJVKhQsXLtgs7IwxdOrU\nCWvXrkV6ejpeeeUVq453d3fXBGVNpajqtO7VwlSfGKPExYkgurFFNwxgTfD0ypUryMrK0qz8pGHE\nCBGc27ABCoUC7dq1Q6eEBBEI/OST6sIYI9Qm1VGbp556CmfOnNEYQBK3b9/GF198YTYrZd++fcjO\nzsb06dPh4+ODYcOGYcuWLTYJcUJCAnr16oUWLVpg2rRpuHDhgsG0XGu4qU6m0MQUIiOFdb18uXDB\nHDsmlnM0wqlTp8A5xyuvvFJdINixI6a0b49fW7aE/J//FDU0X34phH3dOhG7qQPsYbErAbzKOe8K\noA+A5xhjXc0cU/dopTwmJSXhlbZtwS5dAt56y+S01tGEhoaiSZMm5v3sUpwgIwOhx44hWaFAUz3L\ntfkzz2CSSoXpCxfi6NGjulksWkhtBbSRhL1Fixbo1asXAJH2mJWVhdLSUqPnsoZOnTohPz8fHTp0\nwCQzPmJDSA9BWyx2R2ONxS6twNVPvy2tQiEyTH7+GSgrQ/9WrfDQyZPC/26kIEkbW4X9scceg6en\nJ77RShwoLS3F+PHj8fzzz2OvVFJvhNWrV8PX11dTcT158mRkZmbitLqYzRgZGRno3bs3MvTaZ+Tn\n5+PIkSMaN9lDDz2EJk2aYPXq1bV4d9VIxo1mYZyhQ0WnzZ07hWvWjAinqw3FnJwc/POf/wQAFBcX\n48ipUzg6c6YQdKVS9PH/8EPLF1+xAzZfiXN+jXOepP5/MYDzANraet7a8NVXX2HAgAGGqzDDw4Hi\nYiivXsXZ06fxdF6e8KE6wa+ujZubG6Kjoy232BMSEHr7No4YqNRbuHAhcnJysGjRIpMphIYsdskV\nExgYiNjYWLi7u+PEiROGM2JqieRnnzdvnsmFH4xx7733wsvLy6Sw29VirwXWZMVcV2dIaFJutXnk\nEZGiu2MH3snORgXnYiFwC2aWqampmhYBtcHPzw+TJ0/G+vXrUVpaiqqqKjz++OM4cuQIGGM4ePCg\n0WOLioqwefNmTJkyRRPPmDBhAtzc3My6Yw4ePIjExETNouQSe/bsgUqlwih15a+vry8mTZqE77//\n3nxsygTSd4AxJh4SLVqIlg4WLmuYkZGB4OBgTJ06Ff/6179w8eJFHDp0CFVVVRg0eLBw8ebm6qwv\nUFfY9RHCGAsG0APAMdN72p/Kykq88847OHToEIYPH477779f80QFoEl5zNq9G8PKy9Hm1i1gwYI6\nfYoaQ8qMMTlV9fMDAgLAV62CCsBVA7m57u7uCLIgdcyYK8bf3x9yuRyenp7o1q0bEhMTNb5/ewj7\nfffdh/DwcDzzzDO1Ov7JJ59ETk6OJrPHEMYsdmMLWdsbayx26W9gsGhqyBCRiTF7NiJyc/EC5yg3\n0HPdELXJiNHnqaeeQmFhIbZs2YJXX30VW7Zswccff4zY2FiTwv7jjz+itLQU06dP12wLDAzEwIED\nsWXLFpPXlFoG//DDDzodLRMSEuDr64t4rULEadOmoaCgQDfF10oKCgrg7u6OMWPG4Ntvv7W6F316\nejrCwsLw0Ucfwd3dHa+88gr2798PuVxeHT9ykovXbqrGGPMGsBnAS5zzGqV/jLFZjLFExliiNO23\nJ9u2bcPVq1exYcMGfPDBB9i7dy+6du2Kd955Rwim2pVx7Y8/sBBARbt2wiqqB3Tv3h23bt3SWHBG\nCQ0Fq6zEfgBtzRVlmcDQYhu5ubmatgMANAHUlJQUtGrVymgXS2uYOHEiUlNTa21JymQyk6IOmHbF\nmKo6tRfWCnuTJk3gYWjKL5eLlMa8POTExuJbwOJe6fYQ9kGDBiEkJAQvvvgiPv30U7z44ot4+eWX\nMWDAABw7dszo+1u9ejW6dOlSoz/SpEmTcP78ec0M0BDZ2dnw8/NDs2bNNFY75xwJCQkYPny4zixv\nyJAhaNeunU3umIKCAvj5+WHGjBm4cuWK0X5LxpCEvW3btnjrrbewdetWfP3114iLi9NZJ8AZ2EXY\nGWNyCFFfxzk3+FjmnK/gnPfinPdqYaHlYQ1Lly5Fhw4dMHnyZCxYsACpqamYPHky3n33XRH1Dg4G\n3N0RtGMH+gBwX7DAbAvWusLa1gLrAZt83oaWx8vLy9NpxtWrVy8UFBRgx44ddrHW64omTZrA3d3d\n6a4YS4Xd5EPuueeAYcNw5e23AZho36vFnTt3cPXq1VqlOmojk8kwY8YM3Lp1C5MmTdIssD1gwACU\nlJQYvFfT0tJw6NAhTJ8+vUb20QPqRbtNWe1ZWVno3LkzXnvtNWzduhXHjx/HuXPncOXKFY0bRsLN\nzQ1PPPEEdu7ciWvXrtXqPebn58Pf3x/jxo2zujDr9u3byM/P16yX+9JLLyE8PBy3bt1yWhsBbeyR\nFcMAfAPgPOf8E9uHZD1//fUX9uzZg9mzZ2sabrVp0wZr167FoEGD8NxzzyH14kUgJASdrl3DLbkc\nMmPrVjoBi1sLdO+OCoUCm2Gba8TPzw+FhYU6RSOGLHZA+IEbkrBLqyg5K3hqTVaMWWHv3h3YtQtt\n1cFsS4Rdcj/aarEDwMsvv4wvv/wSa9eu1XyvpEIqQ+6YDeqiqqlSjyUtgoKC0LdvX5PCnp2djQ4d\nOuCll15CYGAg3njjDU216UgDi4nMmDEDVVVVmgpXa5E+f6kw6+eff7Z42UgpwBuqNrY8PDzw2Wef\nQSaTYfTo0bUajz2xh8XeH8ATAIYwxk6r/1m5SKFtfPnll5DL5XhaL2PAzc0Na9eu1axoVKUO3h2M\nixOFIPWEgIAAtGvXzrywv/wyXn/gAXi0amXWJWEKPz8/cM51mj3l5eXpCHtUVJQm+GWPjJi6RL9f\nTEVFBcrKyupd8NSssKsJCgqCXC63SNhtzYjRxtvbG7Nnz9Ypi2/bti1CQkIMCvumTZvQr18/tG1r\nOHdi0qRJSEpKQlZWVo3XOOcaYW/WrBkWLFiA3bt3Y8mSJYiOjtb0IdImPDwcw4YNw/Lly2u1Vqv2\n5z99+nSUl5fjhx9+sOhY6QEaptVHatSoUbh9+3Z1FbETsUdWzEHOOeOcx3DOY9X/frPH4CyhpKQE\nq1atwuTJkw22f23bti1WrVqFU6dO4ceMDNwAUCKtfl6P6N69u3lh9/DA4cxMm4VWv62A1CdG2xUj\nl8s1/c4bksUO1OzwKD3AGpwrRo2bmxs6dOhQs32vASRhD3NQ4zpAuGMOHjyoE+xPT0/HmTNn8OCD\nDxo97l51wN+QG+fWrVsoLS3VtJiYO3cugoKCcPXq1RpuGG3mzp2LnJwcyxas0UP78+/RowdiYmIs\ndsdIFnsnvey0uojjWILzU0Js5IcffkBhYSGeffZZo/uMHz8eL7zwAp5MT0cEgJh68ETVR2pyVV5e\nbnQfzrldqkD1G4Hdvn0bKpUK+rEPyR3T0IXdkj4x9sIRwg4Yad9rgNTUVAQFBcHbiqIqaxkwYABu\n3Lihk28upTJOnjzZ6HHSLCLNyPrDADR9epo0aYK31bGFsSZaOkyYMAFBQUFYpm54Zw3anz9jDDNm\nzMCJEyfMV4FDPMiCgoKcHiQ1RoMWds45li5diujo6JrVe3osXrwY0bGxqPL2rtnMqh4QExMDpVJp\ncmmya9euoaioyGaLXV/YtatOtXn++eexePFii1a5r0/ou2Iak7DbIyPGHNJ3Tdsds2nTJvTu3bu6\ngZoBAgICEBAQYFDYJfeM9vGzZs1CYmKiyWCku7s7Zs6ciZ07d9bo928OKXgqIT2Udu7cafZYKSOm\nvtKghf3EiRNISkrC3LlzzfYA8fDwwM6dO7F3795aFcc4GikzxpQ7xl455ZKYSK4Y7T4x2nTu3Bnz\n58+3rr9KPcCZFrulwVPOudXCnpeXhzt37pjcry6EPTIyEgEBARphz8rKQmJiokk3jER4eLhufYka\nfYsdEFa0qWI0iZkzZ0Imk2H58uWWvgWUlZWhvLxc5/Nv3749wsPDzVbWAsIVQ8LuIBYtWgRvb288\n/vjjFu0v9UGpj3Tu3BkeHh4mhd1eVaCSlWLOYm+o1AeL3VzwVOoZb6lPVuryaMrPXlBQgLy8PIcL\nu0wmQ//+/TXCbokbRiIsLMyoK6ZJkyZWLQwi0bZtW0yYMAErV660uBJVuvf1H6xDhgzBgQMHoFQv\ndGKIO3fu4Pr165qMmPpIgxX2rVu34pdffsFbb71VJ19YR+Pu7o6oqCiTuexnz55FQEAAWrdubdO1\njLliHFFf4Awago/dmLAYo0ZfdgNIgmlrDrslDBgwAH/99Rfy8vKwadMmxMbGWiR04eHhyMnJqSHA\n2dnZ6NixY61nh3PnzsXNmzerOy2awZSwFxcXa5bONIQUWyCL3c7cuXMH8+bNQ3R0tFU9ves75hbd\nSEpKql71yQak9rXSzS25YmpjLdVHfHx8UFFRoQlES9Z7fao8tVbYpX4ypoRdmtHVhbBLKX0bN27E\nkSNHLHLDAELYOec1/OFZWVkm/fPmGDp0KMLCwiwOohr7/CV/vil3DAm7g3j33XeRk5OD5cuXa75I\nrkCPHj00a3rqU1FRgeTkZJMtay1FJpPBx8dH42PPy8tDQECAy3yW+o3AXMFib9myJZo2bWpS2I8e\nPYpmzZohQlq/04H06tULHh4eeOeddwDAKmEHambGSDnstUUmk2HOnDk4fPiwybYFEtK9r18P0rJl\nS3Tr1s2ksEsxAnLF2JEzZ85gyZIlmDlzZs12pw0cqcmR1M5Vm5SUFFRUVNhF2AHdtgL6VacNHf1+\nMUVFRZDJZHWSmsYYg7u7u92FnTGG4OBgkz72w4cPo0+fPpoqUUfi4eGB3r17Iy8vD1FRURY/TCQr\nV1vYy8rKcOPGDZuEHQDGjBF1kdrr9RrD1Oc/ZMgQHDx40GjqcXp6OgIDA+tNzrohGpSwq1QqzJkz\nBwEBAZr+x65EbGwsFAoFjh8/XuM1adEDY2t9Wot2h0f9PjENHUMWu9WrJ9mAXC43Gzy1VtgB0ymP\nRUVF+PPPP+vU2JHSHi211gFhUDRv3lxH2KUZqqXr3xojLCwMCoUCycnJZvc1J+xlZWVGl/Or7xkx\nQAMT9q+++gpHjx7Fxx9/bJdug/UNDw8PxMbGGrTYT506BW9vb7vdUNodHhuDxV6XAXa5XG53ix2o\nFnZD7Z2PHz8OlUpVp8I+btw4NGnSBFOmTLHqOP2UR0M57LVBLpcjMjLSZmG/7777IJPJjLpj6nsO\nO9DAhL28vBxjx461OL2xIRIfH4/ExMQavS+SkpLQo0cPyOzUP17bFaPfJ6ahI4m4vsVeV1gj7NZM\n50NCQlBUVGSwUdXhw4fBGNPpWe5o+vfvj+LiYqt9+uHh4ToWu6Ec9toSFRWFc+fOmd0vPz8fnp6e\nBhc39/PzQ8+ePQ0Ke3l5OXJycuq1fx1oYML+wgsvYNu2bQ2uYMYa4uLiUFJSonNzVlVV4fTp03Zz\nwwDVrpiqqircunXLJV0x9d1iNyYsxpC6gBpqwHX48GFER0fXud+3Nv78sLAw5OTkoLS0FIAQdsaY\n0eZh1hAdHY2srCydBneGMFccNmTIEBw9erR6LVM10oyJLHY748qiDhgOoKampuLu3bt2C5wC1cJu\nrE9MQ8bZrhiFQmGRsFu74MigQYPg7++PjRs36mxXqVQ4cuRIg0kmkDJjpJTH7OxstG7d2vCCI1Yi\nLXhurt+LJcKuVCprPEQNdXWsjzQ4YXd1wsLCEBAQoBNAPXXqFADYXdilRRkA16k6BRqOK8ZaYZfL\n5XjggQfwyy+/6GRspKSkoKioqMEJu+SOkYqT7EFUVBQAmPWzm/v8+/fvD7lcXsMdQ8JO1ArGGOLi\n4nQs9qSkJHh4eNi1eZmUvyt9uVzJYvfw8ICHh4dTXTGWZMXUZonAhx56CEVFRfj999812w4fPgwA\nDUbY9VMebS1O0iYkJARNmjSxWdi9vLzQp0+fGsKekZEBHx+fel/MR8JeD4mPj8e5c+c0DZ+SkpIQ\nExNj1wIi6aZ2RWEHhNUuWeyFhYV16nt2lMUOiApLfXfM4cOH0aJFi3of0JPw8/NDYGAg0tLSdBbY\nsF/3brYAABJ4SURBVAcymcyiAKp+Z0dDDBkyBElJSTrBaikjpr67hEnY6yHx8fFQqVRITEwE5xyn\nTp2yqxsGqBb21NRUAK7ligFEALWoqAhKpRJ37951CVeMdO6JEydi69atGnfM4cOH0b9//3ovNtpI\nKY95eXkoLy+3m7ADwh1jq8UOiIInlUqFUaNGaeIBDSHVEbDfYtajGGN/McbSGWOv2+OcjRmpA+Wx\nY8eQmZmJgoICu2bEADWFvb5PLa1FagRWl6snSThS2AFdd0xeXh7S0tIajBtGQkp5lFId7eVjB0QA\n9dq1a7h9+7bB1y1tmRwXF4dNmzYhNTUVPXr0wLp165CZmdkgZkb2WMzaDcAXAEYD6ApgCmOsYS2S\nWc8IDAxEaGgojh8/rqk4tbfFru1jb968eb3sUW8LUuveuuwTI2EuK8baXuz6aLtjjhw5AqDh+Ncl\nwsLCcPnyZc3CMva22AEYdcfcvXsXSqXSos9/8uTJOH36NKKiovD4449DqVQ2Gos9DkA65/wi57wC\nwA8A7rfDeRs18fHxOHbsGE6dOgU3NzdNDrO9kG5qVytOkpAsdmcIu7ngqdSLvbbCrlAoNO6Yffv2\nQS6XW7QgRX1CyozZt28fAPsKu5TyaMwdY23Vb8eOHXHgwAEsXLgQTZs2rdMisNpiD2FvCyBH6/fL\n6m2EDcTHx+PKlSvYtm0boqKirCpksQTtm9pVhd1ZFrs5V0xt2gnoI7ljVqxYgZ49e9r9/nA0krDv\n2bMHXl5eZgOZ1tCuXTv4+PgYtdiNdXY0hVwux6JFi3Dnzh3NjKA+U2fBU8bYLMZYImMsUVrYgTCO\nZBWcPXvW7v51QKRzSe4XVwucAtXBU1cV9qFDh8LPzw93795tcG4YoDrlMSsry6YFNgzBGDMZQLXl\n828oAWp7CPsVAO21fm+n3qYD53wF57wX57yXK1qI9kbq9AjY378OiBtUurFd8e8huWKklMf6JOzS\nmGwRdskdAzQ8/zogHrzSfWdPN4xEdHQ0kpOTDTZMs8eDtb5jD2E/ASCcMRbCGFMAeBTAL3Y4b6NG\n6vQIOEbYgeob21Ut9qqqKly/fh1A/Qqe2ktY5syZg27dumlW/WloSO4YRwn7rVu3NKuDaUPCbgGc\ncyWA5wHsBHAewI+cc/Pt1Qiz9OnTBzKZDN27d3fI+V3dYgeqe33Xp+BpbTo7GiI+Ph5nz55tsKmq\njhR2U60FauNjb2jYxcfOOf+Nc96Zcx7KOV9kj3MSwMKFC5GQkIBmzZo55PzSje3Kwp6TkwPGGLy9\nvevs2nXhY3cFHG2xA4ZTHu31YK3PUOVpPaZVq1YYPny4w87v6q4YQAh7s2bN7NbH3hJI2C1DEnZp\noW570rJlSwQGBhq02AsKCuDl5eUya/wagoS9EdNYXDF16YYBLBN2Dw+PBpeiaG/uv/9+LF++3CHB\nX1OZMbYUhzUUSNgbMZIrxpUt9qtXr9a5sFsSPHV1YbEEDw8PzJo1y2GLb0dHR+PcuXM1MmMaw+dP\nwt6I6d69O8LCwhps8M0UkphXVVXVS4vd1YWlPhAVFYWioiJNAF3Cks6ODR0S9kbMY489hrS0NIdZ\nTM5EW8ydIezmsmJI2B2PsdYCjeHzJ2EnXBJnC7tKpYJKpTL4emMQlvoACTtBuBju7u5o2rQpAOcI\nOwCj7pjGICz1AX9/f7Rt25aEnSBcCSmA6ozgKUDCXh+QWgtIqFQqFBYWuvznT8JOuCySoNcni93W\nXuyEdURHRyMlJQVVVVUAgOLiYqhUKgqeEkRDxdnCbiiAWlZWhoqKChL2OiI6OhplZWXIyMgA0HiK\nw0jYCZdFcsXUdem4KYu9sQhLfUE/gNpYPn8SdsJlcbbFTsLufLp27QrGGAk7QbgKzgqekrDXH5o2\nbYrQ0FASdoJwFZxlsZvKimkswlKf0M6MaQwtewESdsKFcbYrxlDwlIS97omOjkZqairKy8sbzedP\nwk64LOSKIQAh7FVVVbhw4YLm86/re6KuIWEnXJYRI0Zg6tSpCAoKqtPrkrDXL7QzYwoKCuDj4+OS\n/ZG0sUnYGWP/YoxdYIydZYz9xBiju5WoN3Tr1g1r166Fu7t7nV7XnLBTL/a6pXPnzpDL5UhOTm4U\nnR0B2y32XQCiOecxAFIBLLB9SATRsDEXPCVrvW6Ry+WIjIzUWOyN4fO3Sdg557+rF7MGgKMA2tk+\nJIJo2Jiz2BuDsNQ3oqOj8eeffzaaz9+ePvanAOyw4/kIokFiLivGlRdRrq9ER0cjKysL2dnZJOwA\nwBjbzRhLNvDvfq193gCgBLDOxHlmMcYSGWOJeXl59hk9QdRDyGKvf0gB1MzMzEbx+ZuNKnHOh5l6\nnTE2HcA4AEO5/uKCuudZAWAFAPTq1cvofgTR0DEn7MHBwXU8IkISdsD1i5MA27NiRgH4G4AJnPO7\n9hkSQTRsKHha/wgODoaXlxeAxpFqaquP/XMAzQDsYoydZox9aYcxEUSDxpjFTr3YnYdMJkNUVBSA\nxiHsNiX4cs7D7DUQgnAVjAVPqRe7c4mOjsbx48cbxedPlacEYWeMWexUdepcJD97Y/j8SdgJws6Q\nsNdP4uPjAQAdO3Z08kgcT93WWhNEI8BY8LSwsBAACbuz6NevHy5evIiQkBBnD8XhkMVOEHaGLPb6\nS2MQdYCEnSDsjkwmg0wmqxE8JWEn6goSdoJwAHK53KgrxtV7gRPOh4SdIByAIWEvLi4GADRr1swZ\nQyIaESTsBOEATAm7t7e3M4ZENCJI2AnCASgUCoPC7uXlBZmMvnaEY6E7jCAcgFwurxE8LS4uJjcM\nUSeQsBOEAzDmiiFhJ+oCEnaCcAAk7IQzIWEnCAdAwk44ExJ2gnAAxoKnJOxEXUDCThAOgCx2wpmQ\nsBOEA6CsGMKZkLAThAMgi51wJnYRdsbYq4wxzhgLtMf5CKKhoy/sSqUSpaWlJOxEnWCzsDPG2gMY\nASDb9uEQhGugHzy9c+cOAOoTQ9QN9rDYlwD4GwBuh3MRhEugb7FTAzCiLrFJ2Blj9wO4wjk/Y6fx\nEIRLoB88JWEn6hKzS+MxxnYDaG3gpTcALIRww5iFMTYLwCwA6NChgxVDJIiGB1nshDMxK+yc82GG\ntjPGugEIAXCGMQYA7QAkMcbiOOfXDZxnBYAVANCrVy9y2xAuDQk74UxqvZg15/xPAC2l3xljmQB6\ncc5v2mFcBNGgIWEnnAnlsROEA9DPiiFhJ+qSWlvs+nDOg+11LoJo6FDwlHAmZLEThAMgVwzhTEjY\nCcIBGBJ2mUyGJk2aOHFURGOBhJ0gHIBcLodSqQTnIgFM6hOjziAjCIdCwk4QDkChUAAQPWIAagBG\n1C0k7AThAORyOQBo3DEk7ERdQsJOEA5AEnYpM4aEnahLSNgJwgGQxU44ExJ2gnAAJOyEMyFhJwgH\nIAVPSdgJZ0DCThAOgCx2wpmQsBOEA6DgKeFMSNgJwgFoW+zl5eWorKwkYSfqDBJ2gnAA2sJOfWKI\nuoaEnSAcgHbwlISdqGtI2AnCAZDFTjgTEnaCcADawVMSdqKusdtCGwRBVKNtsUuNwEjYibrCZoud\nMTaPMXaBMXaOMbbYHoMiiIYOuWIIZ2KTxc4YGwzgfgDdOefljLGW5o4hiMYACTvhTGy12OcC+Cfn\nvBwAOOe5tg+JIBo+lBVDOBNbhb0zgHsZY8cYYwcYY73tMSiCaOiQxU44E7OuGMbYbgCtDbz0hvr4\nAAB9APQG8CNjrBOX1gPTPc8sALMAoEOHDraMmSDqPfpZMQqFQmPFE4SjMSvsnPNhxl5jjM0FsEUt\n5McZYyoAgQDyDJxnBYAVANCrV68awk8QroS+xU7WOlGX2OqK+RnAYABgjHUGoABw09ZBEURDh4Sd\ncCa25rGvBLCSMZYMoALANENuGIJobOgHT0nYibrEJmHnnFcAeNxOYyEIl4EsdsKZUEsBgnAA+sFT\nEnaiLiFhJwgH4ObmBoAsdsI5kLAThANgjEEul5OwE06BhJ0gHIRCoSBhJ5wCCTtBOAi5XI6Kigrc\nuXOHhJ2oU0jYCcJByOVyFBYWQqVSkbATdQoJO0E4CLlcjtu3bwOgPjFE3ULCThAOQi6XIz8/HwAJ\nO1G3kLAThINQKBRksRNOgYSdIBwEuWIIZ0HCThAOQi6X49atWwBI2Im6hYSdIByEXC6nhawJp0DC\nThAOQuoXA5CwE3ULCTtBOAgSdsJZkLAThIPQXgrP29vbiSMhGhsk7AThICSLvWnTpppujwRRF5Cw\nE4SDkISd3DBEXWOTsDPGYhljRxljpxljiYyxOHsNjCAaOiTshLOw1WJfDOBdznksgLfVvxMEARJ2\nwnnYKuwcgI/6/74Artp4PoJwGaTgKQk7UdfYtJg1gJcA7GSM/RviIdHP9iERhGtAFjvhLMwKO2Ns\nN4DWBl56A8BQAC9zzjczxh4G8A2AYUbOMwvALADo0KFDrQdMEA0FEnbCWZgVds65QaEGAMbYtwBe\nVP+6EcDXJs6zAsAKAOjVqxe3bpgE0fAgYSecha0+9qsABqr/PwRAmo3nIwiXgYSdcBa2+thnAviU\nMeYOoAxqVwtBEBQ8JZyHTcLOOT8IoKedxkIQLgVZ7ISzoMpTgnAQJOyEsyBhJwgHQcJOOAsSdoJw\nECTshLMgYScIB0HCTjgLEnaCcBCUFUM4CxJ2gnAQJOyEsyBhJwgHMXr0aLzxxhsIDQ119lCIRgbj\nvO6r+3v16sUTExPr/LoEQRANGcbYSc55L3P7kcVOEAThYpCwEwRBuBgk7ARBEC4GCTtBEISLQcJO\nEAThYpCwEwRBuBgk7ARBEC4GCTtBEISL4ZQCJcZYHoCsWh4eCOCmHYdjb2h8tkHjsw0an+3U5zF2\n5Jy3MLeTU4TdFhhjiZZUXjkLGp9t0Phsg8ZnOw1hjOYgVwxBEISLQcJOEAThYjREYV/h7AGYgcZn\nGzQ+26Dx2U5DGKNJGpyPnSAIgjBNQ7TYCYIgCBM0KGFnjI1ijP3FGEtnjL1eD8azkjGWyxhL1toW\nwBjbxRhLU//0d+L42jPG9jHGUhhj5xhjL9anMTLG/r99swmxsgrj+O+Pk31M4fSFDE0wRqLMQkcD\nP1CijEIlXLVIWrgQ2rhICKQhCFq2qVxEm6Q2YZJ9ySz6mlq1GPNjrKlp+sABR9SJSISCyPq3OOfS\ny0Wiq4tz7uX5weGe85y7+PE+9z73fZ/3vTdIOirpVPZ7PseXSZrMeT4kaXEJv4bnIkknJY3X5idp\nTtLXkqYkHcuxKvKbXQYkHZb0naQZSRtr8ZO0Ih+31rgkaW8tftdC1xR2SYuAV4BtwAiwU9JIWSve\nALa2xZ4BJmwvBybyuhSXgadtjwAbgD35mNXi+AewxfZqYBTYKmkD8ALwku17gV+B3YX8WjwFzDTW\ntfk9aHu08YheLfkF2A98aHslsJp0HKvwsz2bj9socB/wO/BeLX7XhO2uGMBG4KPGegwYq8BrGJhu\nrGeBwTwfBGZLOzbcPgAertERuAk4Aawn/Tmk70p5L+A1RPpybwHGAVXmNwfc0RarIr/AEuA0+V5e\nbX5tTo8AX9Tq1+nomjN24C7gTGM9n2O1sdT2uTw/DywtKdNC0jCwBpikIsfc5pgCFoBPgJ+Ai7Yv\n57eUzvPLwD7g77y+nbr8DHws6bikJ3OslvwuA34GXs+trNck9Vfk1+Rx4GCe1+jXEd1U2LsOp5/8\n4o8dSboZeAfYa/tSc6+0o+2/nC6Fh4B1wMpSLu1IehRYsH28tMt/sNn2WlKLco+k+5ubhfPbB6wF\nXrW9BviNtrZG6c8fQL5HsgN4u32vBr+roZsK+1ng7sZ6KMdq44KkQYD8ulBSRtJ1pKL+pu13c7gq\nRwDbF4HPSa2NAUl9eatknjcBOyTNAW+R2jH7qccP22fz6wKpP7yOevI7D8zbnszrw6RCX4tfi23A\nCdsX8ro2v47ppsL+JbA8P5GwmHTpdKSw05U4AuzK812kvnYRJAk4AMzYfrGxVYWjpDslDeT5jaT+\n/wypwD9W2s/2mO0h28Okz9tntp+oxU9Sv6RbWnNSn3iaSvJr+zxwRtKKHHoI+JZK/Brs5N82DNTn\n1zmlm/wd3uDYDnxP6sM+W4HPQeAc8Cfp7GQ3qQc7AfwAfArcVtBvM+ky8itgKo/ttTgCq4CT2W8a\neC7H7wGOAj+SLo+vryDXDwDjNfllj1N5fNP6TtSS3+wyChzLOX4fuLUyv37gF2BJI1aN39WO+Odp\nEARBj9FNrZggCILgfxCFPQiCoMeIwh4EQdBjRGEPgiDoMaKwB0EQ9BhR2IMgCHqMKOxBEAQ9RhT2\nIAiCHuMfxKAsi4feimYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6c19e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.69547204212 \n",
      "Fixed scheme MAE:  1.85369466724\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.9020  Test loss = 1.7066  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.8988  Test loss = 1.2650  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.8837  Test loss = 1.9304  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.8937  Test loss = 1.8828  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.7954  Test loss = 0.1757  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.7568  Test loss = 0.6765  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.7337  Test loss = 0.3120  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.7341  Test loss = 0.2739  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.6789  Test loss = 0.5040  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.6775  Test loss = 0.0269  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.6325  Test loss = 0.0587  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.6283  Test loss = 0.8589  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.5973  Test loss = 0.1318  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.5973  Test loss = 1.6211  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.5991  Test loss = 2.8233  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.6340  Test loss = 4.0896  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.6848  Test loss = 0.4628  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.6825  Test loss = 0.4940  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.6607  Test loss = 0.2399  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.4597  Test loss = 0.1263  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.4354  Test loss = 0.4121  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.4318  Test loss = 4.4179  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.5100  Test loss = 0.8988  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.4945  Test loss = 2.4169  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.5132  Test loss = 0.0188  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.5099  Test loss = 0.6018  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.5101  Test loss = 0.7594  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.5103  Test loss = 1.0265  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.4964  Test loss = 0.9657  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.4816  Test loss = 0.1396  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.4599  Test loss = 3.3071  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.4838  Test loss = 0.9198  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.4727  Test loss = 1.7636  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.4869  Test loss = 0.0059  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.4276  Test loss = 0.2577  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.4265  Test loss = 4.8706  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.4428  Test loss = 0.1203  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.3851  Test loss = 0.9728  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.3893  Test loss = 1.3262  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.3990  Test loss = 2.5931  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.4109  Test loss = 1.4260  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.4217  Test loss = 2.5272  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.4554  Test loss = 3.4480  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.5169  Test loss = 12.3748  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.1464  Test loss = 6.2820  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2831  Test loss = 1.0865  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2858  Test loss = 0.8639  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2876  Test loss = 0.9444  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.2337  Test loss = 1.4042  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.2386  Test loss = 2.7631  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.2616  Test loss = 1.7415  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.2687  Test loss = 0.2610  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.2345  Test loss = 0.9659  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.2377  Test loss = 1.1594  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.2405  Test loss = 0.8693  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.2424  Test loss = 1.1842  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.2333  Test loss = 0.7556  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.2340  Test loss = 1.9331  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.2467  Test loss = 0.5011  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.2470  Test loss = 0.6391  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.2413  Test loss = 1.1489  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.2450  Test loss = 2.9026  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.2736  Test loss = 1.2978  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.2671  Test loss = 1.3572  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.2600  Test loss = 0.4562  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.2598  Test loss = 1.4503  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.2596  Test loss = 1.6993  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.2666  Test loss = 3.1567  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.2879  Test loss = 6.0599  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.4051  Test loss = 0.5544  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.4058  Test loss = 0.6274  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.4041  Test loss = 1.8139  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.4041  Test loss = 2.0268  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.4157  Test loss = 0.1372  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.4118  Test loss = 0.3461  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.4083  Test loss = 0.8974  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.3524  Test loss = 1.1307  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGXRRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcbc3588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.36873357527 \n",
      "Updating scheme MAE:  1.52789884401\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"../../../models/lstm/1Q/2_cells/1q_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(\"../../../models/lstm/1Q/2_cells/1q_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
